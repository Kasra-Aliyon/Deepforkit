{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from large_scale_prediction import large_scale_predictor, large_scale_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone = 'PT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:08:38,819]\u001b[0m Using an existing study with name 'PT_2018' instead of creating a new one.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\1 - Consolidated Data\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:08:50,228]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:09:03,043]\u001b[0m Trial 6 finished with value: 5.80874198110854 and parameters: {'n_hidden': 4, 'learning_rate': 0.036404019720836435, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11803620828107345, 'dropout_rate_Layer_2': 0.10397938130064036, 'dropout_rate_Layer_3': 0.0275994033792379, 'dropout_rate_Layer_4': 0.2639278366572629, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.334697688744944e-05, 'l1_Layer_2': 5.352681913272838e-05, 'l1_Layer_3': 6.154592811670217e-05, 'l1_Layer_4': 6.151968046156624e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 115, 'n_units_Layer_3': 240, 'n_units_Layer_4': 110}. Best is trial 0 with value: 5.327251135410543.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.81 | sMAPE for Validation Set is: 11.15% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 6.28 | sMAPE for Test Set is: 12.43% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:09:05,521]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:09:10,516]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:09:22,286]\u001b[0m Trial 4 finished with value: 5.145173338494044 and parameters: {'n_hidden': 4, 'learning_rate': 0.029311255275965824, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10340368363391393, 'dropout_rate_Layer_2': 0.07064553330153243, 'dropout_rate_Layer_3': 0.3683334610939262, 'dropout_rate_Layer_4': 0.25918946658643216, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.2320778919018592e-05, 'l1_Layer_2': 1.851699843504542e-05, 'l1_Layer_3': 2.804321853643051e-05, 'l1_Layer_4': 0.00019279248543530998, 'n_units_Layer_1': 135, 'n_units_Layer_2': 220, 'n_units_Layer_3': 240, 'n_units_Layer_4': 210}. Best is trial 4 with value: 5.145173338494044.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.15 | sMAPE for Validation Set is: 10.23% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 6.11 | sMAPE for Test Set is: 12.46% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:09:27,690]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:09:31,800]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:09:35,808]\u001b[0m Trial 5 finished with value: 4.639452462338425 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023294503499933705, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31795167440235095, 'dropout_rate_Layer_2': 0.34493392633825637, 'dropout_rate_Layer_3': 0.04305004110077562, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 6.180045590534825e-05, 'l1_Layer_2': 0.06443108896729725, 'l1_Layer_3': 1.0638810744183721e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 145, 'n_units_Layer_3': 185}. Best is trial 5 with value: 4.639452462338425.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.64 | sMAPE for Validation Set is: 8.98% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 5.33 | sMAPE for Test Set is: 10.63% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:09:41,268]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:09:45,409]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:09:49,596]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:09:51,975]\u001b[0m Trial 11 finished with value: 5.271000225255388 and parameters: {'n_hidden': 3, 'learning_rate': 0.008072640490152553, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.014584327807082431, 'dropout_rate_Layer_2': 0.15601403951277906, 'dropout_rate_Layer_3': 0.25326613113707624, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.8871787585970746e-05, 'l1_Layer_2': 1.1701190026717969e-05, 'l1_Layer_3': 0.003646315052094251, 'n_units_Layer_1': 255, 'n_units_Layer_2': 75, 'n_units_Layer_3': 55}. Best is trial 5 with value: 4.639452462338425.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.27 | sMAPE for Validation Set is: 10.24% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 5.91 | sMAPE for Test Set is: 11.89% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:09:53,960]\u001b[0m Trial 8 finished with value: 5.347526413288864 and parameters: {'n_hidden': 4, 'learning_rate': 0.018421238049192552, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.092703261212107, 'dropout_rate_Layer_2': 0.11687789654210215, 'dropout_rate_Layer_3': 0.3442318176743451, 'dropout_rate_Layer_4': 0.20858616075981048, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 8.373793441800131e-05, 'l1_Layer_2': 0.00016805057631057643, 'l1_Layer_3': 0.0035306371447210707, 'l1_Layer_4': 0.015250184824292575, 'n_units_Layer_1': 115, 'n_units_Layer_2': 215, 'n_units_Layer_3': 95, 'n_units_Layer_4': 270}. Best is trial 5 with value: 4.639452462338425.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.35 | sMAPE for Validation Set is: 10.25% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 7.03 | sMAPE for Test Set is: 13.69% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:09:57,603]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:10:01,248]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:10:05,863]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:10:11,029]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:10:12,830]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:10:15,887]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:10:18,255]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:10:22,322]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:10:23,435]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:10:28,717]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:10:28,869]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:10:33,422]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:10:37,243]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:10:37,623]\u001b[0m Trial 14 finished with value: 5.042983089265877 and parameters: {'n_hidden': 3, 'learning_rate': 0.009016206649086205, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11323942981741837, 'dropout_rate_Layer_2': 0.39282871790388996, 'dropout_rate_Layer_3': 0.28502167756778707, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 1.6593521239497885e-05, 'l1_Layer_2': 0.04707056275678334, 'l1_Layer_3': 0.01940544638964519, 'n_units_Layer_1': 85, 'n_units_Layer_2': 135, 'n_units_Layer_3': 185}. Best is trial 5 with value: 4.639452462338425.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.04 | sMAPE for Validation Set is: 9.70% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 5.49 | sMAPE for Test Set is: 10.99% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:10:38,331]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:10:45,277]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:10:45,631]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:10:48,999]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:10:49,561]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:10:54,385]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:10:57,691]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:10:58,989]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:11:02,143]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:11:05,933]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:11:08,401]\u001b[0m Trial 36 finished with value: 5.579798660082968 and parameters: {'n_hidden': 3, 'learning_rate': 0.016364047289176023, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.005416582354472177, 'dropout_rate_Layer_2': 0.005658642232484343, 'dropout_rate_Layer_3': 0.30147429800276243, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0005525083603474915, 'l1_Layer_2': 1.226053073217068e-05, 'l1_Layer_3': 0.00037225946053408217, 'n_units_Layer_1': 170, 'n_units_Layer_2': 145, 'n_units_Layer_3': 275}. Best is trial 5 with value: 4.639452462338425.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.58 | sMAPE for Validation Set is: 10.67% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 6.53 | sMAPE for Test Set is: 12.93% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:11:12,952]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:11:13,185]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:11:15,296]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:11:19,176]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:11:22,477]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:11:24,511]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:11:25,139]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:11:28,499]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:11:31,701]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:11:33,096]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:11:35,952]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:11:39,924]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:11:40,131]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:11:45,330]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:11:51,570]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:11:56,231]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:12:00,878]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:12:04,188]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:12:04,257]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:12:09,534]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:12:09,632]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:12:10,171]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:12:16,735]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:12:17,053]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:12:19,231]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:12:23,778]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:12:27,694]\u001b[0m Trial 54 finished with value: 4.5533443607520345 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010164414532345305, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04026822926059839, 'dropout_rate_Layer_2': 0.32925822898540175, 'dropout_rate_Layer_3': 0.34491782421952316, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 5.026133915996098e-05, 'l1_Layer_2': 0.0020827419549250318, 'l1_Layer_3': 0.0006627266547640866, 'n_units_Layer_1': 90, 'n_units_Layer_2': 280, 'n_units_Layer_3': 120}. Best is trial 54 with value: 4.5533443607520345.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.55 | sMAPE for Validation Set is: 8.96% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 5.19 | sMAPE for Test Set is: 10.35% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:12:28,087]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:12:28,715]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:12:35,708]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:12:36,031]\u001b[0m Trial 69 finished with value: 8.266063522733125 and parameters: {'n_hidden': 4, 'learning_rate': 0.018619430338918695, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10016189578434523, 'dropout_rate_Layer_2': 0.0260204753065314, 'dropout_rate_Layer_3': 0.15820171456920884, 'dropout_rate_Layer_4': 0.27304291805738984, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0005155037974824654, 'l1_Layer_2': 0.012509588735967315, 'l1_Layer_3': 0.03407160637504699, 'l1_Layer_4': 0.05720796805125137, 'n_units_Layer_1': 85, 'n_units_Layer_2': 280, 'n_units_Layer_3': 70, 'n_units_Layer_4': 80}. Best is trial 54 with value: 4.5533443607520345.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.27 | sMAPE for Validation Set is: 15.84% | rMAE for Validation Set is: 1.27\n",
      "MAE for Test Set is: 12.80 | sMAPE for Test Set is: 24.57% | rMAE for Test Set is: 1.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:12:36,524]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:12:37,312]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:12:47,477]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:12:47,953]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:12:48,037]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:12:54,362]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:12:56,779]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:12:57,384]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:13:03,909]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:13:06,002]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:13:07,008]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:13:08,824]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:13:12,787]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:13:16,717]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:13:20,529]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:13:25,569]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:13:34,185]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:13:34,277]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:13:38,772]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:13:42,615]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:13:46,803]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:13:50,640]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:13:52,842]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:13:53,640]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:13:55,880]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:13:59,346]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:14:03,679]\u001b[0m Trial 94 finished with value: 4.465110300044552 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034579520360506835, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07250877609035346, 'dropout_rate_Layer_2': 0.09250905954945361, 'dropout_rate_Layer_3': 0.07885440232738057, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.007932688730960176, 'l1_Layer_2': 0.0004613828406790919, 'l1_Layer_3': 2.2670422763592784e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 265, 'n_units_Layer_3': 195}. Best is trial 94 with value: 4.465110300044552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.47 | sMAPE for Validation Set is: 8.59% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 5.25 | sMAPE for Test Set is: 10.41% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:14:07,548]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:14:11,799]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:14:11,809]\u001b[0m Trial 100 finished with value: 4.3256377635987775 and parameters: {'n_hidden': 3, 'learning_rate': 0.00800948119081116, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1951129957975581, 'dropout_rate_Layer_2': 0.15047242353677115, 'dropout_rate_Layer_3': 0.01811638655553699, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0789258306205994e-05, 'l1_Layer_2': 7.430062467218727e-05, 'l1_Layer_3': 0.00017196097025165758, 'n_units_Layer_1': 115, 'n_units_Layer_2': 260, 'n_units_Layer_3': 160}. Best is trial 100 with value: 4.3256377635987775.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.33 | sMAPE for Validation Set is: 8.53% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.70 | sMAPE for Test Set is: 11.48% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:14:15,197]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:14:19,224]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:14:24,192]\u001b[0m Trial 101 finished with value: 4.849538472742119 and parameters: {'n_hidden': 3, 'learning_rate': 0.005284735925304741, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07916030564947639, 'dropout_rate_Layer_2': 0.09801254997947029, 'dropout_rate_Layer_3': 0.010067679228632297, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001786795442593449, 'l1_Layer_2': 0.000435324214141498, 'l1_Layer_3': 2.140089967099387e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 215, 'n_units_Layer_3': 130}. Best is trial 100 with value: 4.3256377635987775.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.85 | sMAPE for Validation Set is: 9.24% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 5.28 | sMAPE for Test Set is: 10.38% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:14:28,362]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:14:32,940]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:14:33,447]\u001b[0m Trial 106 finished with value: 4.562180563315778 and parameters: {'n_hidden': 3, 'learning_rate': 0.01343721105903763, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.174720365228318, 'dropout_rate_Layer_2': 0.20370439189496325, 'dropout_rate_Layer_3': 0.019899402789904208, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.1783838581098185e-05, 'l1_Layer_2': 6.404143412125623e-05, 'l1_Layer_3': 6.21892353213942e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 260, 'n_units_Layer_3': 155}. Best is trial 100 with value: 4.3256377635987775.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.56 | sMAPE for Validation Set is: 8.96% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 5.72 | sMAPE for Test Set is: 11.37% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:14:39,131]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:14:41,493]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:14:42,194]\u001b[0m Trial 108 finished with value: 4.2993393855210345 and parameters: {'n_hidden': 3, 'learning_rate': 0.004620318519496929, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06868528040752928, 'dropout_rate_Layer_2': 0.005206537452553867, 'dropout_rate_Layer_3': 0.008033501377843755, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001610798216706741, 'l1_Layer_2': 0.00044644597320819276, 'l1_Layer_3': 1.003410533672884e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 205, 'n_units_Layer_3': 130}. Best is trial 108 with value: 4.2993393855210345.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.30 | sMAPE for Validation Set is: 8.35% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.93 | sMAPE for Test Set is: 9.83% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:14:44,662]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:14:46,968]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:14:50,190]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:14:52,297]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:14:56,241]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:15:08,278]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:15:13,888]\u001b[0m Trial 116 finished with value: 4.166207826612605 and parameters: {'n_hidden': 3, 'learning_rate': 0.001926902224107037, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03721172146230172, 'dropout_rate_Layer_2': 0.0044229805826268564, 'dropout_rate_Layer_3': 0.04205825672054543, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005021583763372889, 'l1_Layer_2': 0.0001296538535615135, 'l1_Layer_3': 8.186141543558876e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 180, 'n_units_Layer_3': 240}. Best is trial 116 with value: 4.166207826612605.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.17 | sMAPE for Validation Set is: 8.09% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.84 | sMAPE for Test Set is: 9.63% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:15:18,075]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:15:20,858]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:15:21,226]\u001b[0m Trial 120 finished with value: 4.865732021340667 and parameters: {'n_hidden': 4, 'learning_rate': 0.002361921999457649, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.012561916020593804, 'dropout_rate_Layer_2': 0.16517090470890772, 'dropout_rate_Layer_3': 0.04403387479766497, 'dropout_rate_Layer_4': 0.37464179403051157, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.04045434411356821, 'l1_Layer_2': 4.3366193856652476e-05, 'l1_Layer_3': 9.837792978215572e-05, 'l1_Layer_4': 1.2054117241787261e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 290, 'n_units_Layer_3': 260, 'n_units_Layer_4': 55}. Best is trial 116 with value: 4.166207826612605.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.87 | sMAPE for Validation Set is: 9.47% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 4.95 | sMAPE for Test Set is: 10.09% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:15:26,186]\u001b[0m Trial 114 finished with value: 4.046794364971822 and parameters: {'n_hidden': 3, 'learning_rate': 0.0037885053649225416, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13512397944615173, 'dropout_rate_Layer_2': 0.26932950740280437, 'dropout_rate_Layer_3': 0.2225189855401617, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0872304412563967e-05, 'l1_Layer_2': 0.003475279899283905, 'l1_Layer_3': 0.00017648496395917033, 'n_units_Layer_1': 50, 'n_units_Layer_2': 155, 'n_units_Layer_3': 220}. Best is trial 114 with value: 4.046794364971822.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.05 | sMAPE for Validation Set is: 7.89% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.16 | sMAPE for Test Set is: 10.34% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:15:30,114]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:15:49,646]\u001b[0m Trial 125 finished with value: 4.134618896603362 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011035062629620009, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04719196537384416, 'dropout_rate_Layer_2': 0.03138481563127844, 'dropout_rate_Layer_3': 0.004936030851644034, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015945169466934707, 'l1_Layer_2': 0.0002892442346372767, 'l1_Layer_3': 5.173321574230579e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 150, 'n_units_Layer_3': 205}. Best is trial 114 with value: 4.046794364971822.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.13 | sMAPE for Validation Set is: 8.06% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.81 | sMAPE for Test Set is: 9.62% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:16:04,821]\u001b[0m Trial 123 finished with value: 4.090377689233706 and parameters: {'n_hidden': 3, 'learning_rate': 0.001086952111493586, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.005270257493170963, 'dropout_rate_Layer_2': 0.039280643270402794, 'dropout_rate_Layer_3': 0.00624331121458406, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013061458758635673, 'l1_Layer_2': 6.273479709626044e-05, 'l1_Layer_3': 0.00020222570599891669, 'n_units_Layer_1': 220, 'n_units_Layer_2': 295, 'n_units_Layer_3': 260}. Best is trial 114 with value: 4.046794364971822.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.09 | sMAPE for Validation Set is: 8.03% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.13 | sMAPE for Test Set is: 10.20% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:16:16,587]\u001b[0m Trial 127 finished with value: 4.034148461752098 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013146815504805297, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04821690826774834, 'dropout_rate_Layer_2': 0.031146637137973318, 'dropout_rate_Layer_3': 0.013684226159886834, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012393235210314895, 'l1_Layer_2': 0.000253208145971717, 'l1_Layer_3': 6.319045724407534e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 160, 'n_units_Layer_3': 260}. Best is trial 127 with value: 4.034148461752098.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.03 | sMAPE for Validation Set is: 7.91% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.97 | sMAPE for Test Set is: 9.97% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:16:36,714]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:16:40,161]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:17:50,142]\u001b[0m Trial 128 finished with value: 4.009567519814831 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023681005094686727, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16213380068544433, 'dropout_rate_Layer_2': 0.26643077443735946, 'dropout_rate_Layer_3': 0.1800447032406562, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015858637060492783, 'l1_Layer_2': 0.003569536710596501, 'l1_Layer_3': 0.00018163611492321476, 'n_units_Layer_1': 140, 'n_units_Layer_2': 185, 'n_units_Layer_3': 240}. Best is trial 128 with value: 4.009567519814831.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.01 | sMAPE for Validation Set is: 7.97% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.65 | sMAPE for Test Set is: 9.45% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:17:53,874]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:17:57,632]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:18:00,961]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:18:04,124]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.39 | sMAPE for Validation Set is: 8.69% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.90 | sMAPE for Test Set is: 9.87% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:18:06,391]\u001b[0m Trial 124 finished with value: 4.3899650313556755 and parameters: {'n_hidden': 4, 'learning_rate': 0.01390565905734818, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25604431448931425, 'dropout_rate_Layer_2': 0.01201960189939049, 'dropout_rate_Layer_3': 0.34909957065651165, 'dropout_rate_Layer_4': 0.3248580433928986, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00010406243227984008, 'l1_Layer_2': 2.5755469471833774e-05, 'l1_Layer_3': 1.4916959683974943e-05, 'l1_Layer_4': 0.0009929441065134707, 'n_units_Layer_1': 140, 'n_units_Layer_2': 50, 'n_units_Layer_3': 140, 'n_units_Layer_4': 55}. Best is trial 128 with value: 4.009567519814831.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:18:09,016]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:18:11,673]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:18:13,897]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:18:16,357]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:18:18,412]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:18:26,897]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:18:27,001]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:18:31,429]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:18:34,481]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:18:34,735]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:18:40,126]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:18:40,296]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:18:45,906]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:18:46,353]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:18:49,025]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:18:52,561]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:18:54,007]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:18:56,772]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:19:00,480]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:19:02,015]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:19:07,270]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:19:10,560]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:19:14,811]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:19:17,870]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:19:19,580]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:19:29,127]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:19:44,183]\u001b[0m Trial 163 finished with value: 4.186664034667628 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020681532917397653, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0933902258930632, 'dropout_rate_Layer_2': 0.017897048374279176, 'dropout_rate_Layer_3': 0.05810747694441343, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002884109352968473, 'l1_Layer_2': 7.179530998877084e-05, 'l1_Layer_3': 1.6986489325840033e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 210, 'n_units_Layer_3': 255}. Best is trial 128 with value: 4.009567519814831.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.19 | sMAPE for Validation Set is: 8.20% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.77 | sMAPE for Test Set is: 9.55% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:19:47,992]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:19:50,572]\u001b[0m Trial 162 finished with value: 4.038144432668136 and parameters: {'n_hidden': 3, 'learning_rate': 0.001210841289275615, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0939459966037264, 'dropout_rate_Layer_2': 0.0015602399241603504, 'dropout_rate_Layer_3': 0.013929721557466206, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011282314123939867, 'l1_Layer_2': 9.149918536749508e-05, 'l1_Layer_3': 1.604715628281635e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 185, 'n_units_Layer_3': 230}. Best is trial 128 with value: 4.009567519814831.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.04 | sMAPE for Validation Set is: 7.89% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.80 | sMAPE for Test Set is: 9.60% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:19:54,855]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:19:55,301]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:19:58,514]\u001b[0m Trial 129 finished with value: 4.087538093321816 and parameters: {'n_hidden': 4, 'learning_rate': 0.014170435278549455, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27328041766317, 'dropout_rate_Layer_2': 0.01972711773571567, 'dropout_rate_Layer_3': 0.35497510035760654, 'dropout_rate_Layer_4': 0.3688766725953345, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 7.700065462389355e-05, 'l1_Layer_2': 1.0638692155500641e-05, 'l1_Layer_3': 1.374465069205633e-05, 'l1_Layer_4': 0.0006431855385159212, 'n_units_Layer_1': 140, 'n_units_Layer_2': 55, 'n_units_Layer_3': 135, 'n_units_Layer_4': 290}. Best is trial 128 with value: 4.009567519814831.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.09 | sMAPE for Validation Set is: 8.02% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.33 | sMAPE for Test Set is: 8.92% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:20:00,231]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:20:01,249]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:20:05,311]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:20:07,630]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:20:45,486]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:20:48,930]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:20:54,462]\u001b[0m Trial 170 finished with value: 4.239823166023197 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023764929207353235, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3917222856927996, 'dropout_rate_Layer_2': 0.23769634649991805, 'dropout_rate_Layer_3': 0.18285451676029177, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00019436902936026474, 'l1_Layer_2': 0.013142460509789546, 'l1_Layer_3': 1.101305509558886e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 180, 'n_units_Layer_3': 235}. Best is trial 128 with value: 4.009567519814831.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.24 | sMAPE for Validation Set is: 8.41% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 4.70 | sMAPE for Test Set is: 9.62% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:21:00,763]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:21:04,540]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:21:10,620]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:21:15,722]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:21:20,347]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:21:23,867]\u001b[0m Trial 174 finished with value: 4.223296991096086 and parameters: {'n_hidden': 4, 'learning_rate': 0.009481710855002606, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26363335928745596, 'dropout_rate_Layer_2': 0.2353120787388129, 'dropout_rate_Layer_3': 0.3120151126015852, 'dropout_rate_Layer_4': 0.3995668959900355, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 6.245422837060529e-05, 'l1_Layer_2': 5.225350732699224e-05, 'l1_Layer_3': 6.0256536283597425e-05, 'l1_Layer_4': 0.008891208028822865, 'n_units_Layer_1': 90, 'n_units_Layer_2': 100, 'n_units_Layer_3': 85, 'n_units_Layer_4': 120}. Best is trial 128 with value: 4.009567519814831.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.22 | sMAPE for Validation Set is: 8.39% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 4.27 | sMAPE for Test Set is: 8.84% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:21:27,638]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:21:32,571]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:21:36,255]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:21:40,963]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:21:43,145]\u001b[0m Trial 164 finished with value: 4.189716972896284 and parameters: {'n_hidden': 4, 'learning_rate': 0.010719279167550036, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26595630817639104, 'dropout_rate_Layer_2': 0.24116804034608086, 'dropout_rate_Layer_3': 0.39771409814743325, 'dropout_rate_Layer_4': 0.24931328666000968, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.594346041756316e-05, 'l1_Layer_2': 4.464980184645313e-05, 'l1_Layer_3': 4.3526489782732624e-05, 'l1_Layer_4': 0.008468232372176414, 'n_units_Layer_1': 140, 'n_units_Layer_2': 110, 'n_units_Layer_3': 200, 'n_units_Layer_4': 215}. Best is trial 128 with value: 4.009567519814831.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.19 | sMAPE for Validation Set is: 8.23% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 4.34 | sMAPE for Test Set is: 9.16% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:21:46,873]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:21:48,596]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:21:53,560]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:21:56,679]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:22:03,727]\u001b[0m Trial 176 finished with value: 4.081293571603587 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026893105696196118, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23053902069701954, 'dropout_rate_Layer_2': 0.18346589797518847, 'dropout_rate_Layer_3': 0.09563359526398917, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007197718978073167, 'l1_Layer_2': 0.0013118160603323977, 'l1_Layer_3': 0.00016828591914021127, 'n_units_Layer_1': 150, 'n_units_Layer_2': 180, 'n_units_Layer_3': 285}. Best is trial 128 with value: 4.009567519814831.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.08 | sMAPE for Validation Set is: 8.09% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.72 | sMAPE for Test Set is: 9.64% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:22:09,777]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:22:14,626]\u001b[0m Trial 192 finished with value: 6.020000611275048 and parameters: {'n_hidden': 4, 'learning_rate': 0.0033812850281263497, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3974821392234016, 'dropout_rate_Layer_2': 0.26234533228277807, 'dropout_rate_Layer_3': 0.39465795852975327, 'dropout_rate_Layer_4': 0.143515788975254, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00033474669105254214, 'l1_Layer_2': 7.197535329207107e-05, 'l1_Layer_3': 5.4486658057940984e-05, 'l1_Layer_4': 0.006203828647651752, 'n_units_Layer_1': 160, 'n_units_Layer_2': 95, 'n_units_Layer_3': 195, 'n_units_Layer_4': 300}. Best is trial 128 with value: 4.009567519814831.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.02 | sMAPE for Validation Set is: 11.53% | rMAE for Validation Set is: 0.93\n",
      "MAE for Test Set is: 7.33 | sMAPE for Test Set is: 14.36% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:22:16,782]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:22:18,464]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:22:24,567]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:22:36,636]\u001b[0m Trial 189 finished with value: 4.149510652654886 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013548947209219497, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.052539676094407586, 'dropout_rate_Layer_2': 0.04287878205512263, 'dropout_rate_Layer_3': 0.06504359379378953, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002962503741798388, 'l1_Layer_2': 6.634636842015359e-05, 'l1_Layer_3': 1.9442446796474775e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 225, 'n_units_Layer_3': 250}. Best is trial 128 with value: 4.009567519814831.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.15 | sMAPE for Validation Set is: 8.14% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.83 | sMAPE for Test Set is: 9.67% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:22:41,537]\u001b[0m Trial 198 finished with value: 5.518801047016123 and parameters: {'n_hidden': 3, 'learning_rate': 0.008152624708418802, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2638028929931158, 'dropout_rate_Layer_2': 0.19377919050567766, 'dropout_rate_Layer_3': 0.3211422942687572, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00039715682658731375, 'l1_Layer_2': 1.7081259274393548e-05, 'l1_Layer_3': 0.00031915492574043677, 'n_units_Layer_1': 150, 'n_units_Layer_2': 120, 'n_units_Layer_3': 240}. Best is trial 128 with value: 4.009567519814831.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.52 | sMAPE for Validation Set is: 10.65% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 6.50 | sMAPE for Test Set is: 12.84% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:22:45,847]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:23:01,753]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:23:05,329]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:23:06,717]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:23:08,977]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:23:12,339]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:23:12,486]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:23:18,567]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:23:18,669]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:23:18,741]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:23:26,980]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:23:28,636]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:23:28,894]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:23:33,929]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:23:35,137]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:23:35,829]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:23:41,535]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:23:45,210]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:23:49,897]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:23:59,073]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:24:02,436]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:24:04,593]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:24:10,656]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:24:10,927]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:24:15,365]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:24:19,212]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:24:21,588]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:24:29,372]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:24:31,688]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:24:34,606]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:24:35,201]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:24:35,544]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:24:47,647]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:24:50,869]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:24:55,731]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:25:01,542]\u001b[0m Trial 231 finished with value: 4.281291090363231 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024203721486725956, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10165112463927004, 'dropout_rate_Layer_2': 0.01910932492143431, 'dropout_rate_Layer_3': 0.05985049911739484, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002093877718838422, 'l1_Layer_2': 0.00010166881134432757, 'l1_Layer_3': 1.294208757661578e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 155, 'n_units_Layer_3': 255}. Best is trial 128 with value: 4.009567519814831.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.28 | sMAPE for Validation Set is: 8.35% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.04 | sMAPE for Test Set is: 10.12% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:25:04,912]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:25:05,365]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:25:09,995]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:25:11,200]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:25:29,610]\u001b[0m Trial 226 finished with value: 3.697290035333048 and parameters: {'n_hidden': 3, 'learning_rate': 0.005496304925806968, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16109836680186232, 'dropout_rate_Layer_2': 0.2805837571969886, 'dropout_rate_Layer_3': 0.22284622110209887, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014194584427060827, 'l1_Layer_2': 0.0053504710418059405, 'l1_Layer_3': 0.00228586189656736, 'n_units_Layer_1': 210, 'n_units_Layer_2': 100, 'n_units_Layer_3': 165}. Best is trial 226 with value: 3.697290035333048.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.70 | sMAPE for Validation Set is: 7.38% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.24 | sMAPE for Test Set is: 8.83% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:25:41,245]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:25:45,606]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:25:49,613]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:25:53,457]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:25:57,993]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:26:01,845]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:26:06,790]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:26:08,235]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:26:12,113]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:26:23,355]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:26:36,043]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:26:43,547]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:26:48,220]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:26:53,813]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:27:01,484]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:27:05,212]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:27:11,832]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:27:13,117]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:27:23,085]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:27:23,534]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:27:30,923]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:27:32,361]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:27:36,455]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:27:41,203]\u001b[0m Trial 255 finished with value: 3.8636112716966053 and parameters: {'n_hidden': 3, 'learning_rate': 0.00763502788632795, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1597560257803977, 'dropout_rate_Layer_2': 0.21531438031134464, 'dropout_rate_Layer_3': 0.20976028852747958, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001425883050315624, 'l1_Layer_2': 0.0066863462515867195, 'l1_Layer_3': 0.00182919411473658, 'n_units_Layer_1': 285, 'n_units_Layer_2': 100, 'n_units_Layer_3': 160}. Best is trial 226 with value: 3.697290035333048.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.86 | sMAPE for Validation Set is: 7.65% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.42 | sMAPE for Test Set is: 8.98% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:27:49,138]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:27:52,690]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:27:54,139]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.72 | sMAPE for Validation Set is: 7.41% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.18 | sMAPE for Test Set is: 8.63% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:27:54,390]\u001b[0m Trial 249 finished with value: 3.7161253658486477 and parameters: {'n_hidden': 3, 'learning_rate': 0.007643165976093121, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15913565338139096, 'dropout_rate_Layer_2': 0.268618586046662, 'dropout_rate_Layer_3': 0.2073838378786855, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013420784985606186, 'l1_Layer_2': 0.00695739430148469, 'l1_Layer_3': 0.0003317188778137024, 'n_units_Layer_1': 280, 'n_units_Layer_2': 100, 'n_units_Layer_3': 160}. Best is trial 226 with value: 3.697290035333048.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:28:01,898]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:28:02,171]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:28:09,612]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:28:09,700]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:28:15,073]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:28:15,275]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:28:16,571]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:28:25,846]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:28:27,378]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:28:28,486]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:28:32,473]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:28:38,089]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:28:41,628]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:28:45,875]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:28:48,833]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:28:49,396]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:28:56,485]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:29:03,070]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:29:06,551]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:29:13,801]\u001b[0m Trial 262 finished with value: 3.717644491470948 and parameters: {'n_hidden': 3, 'learning_rate': 0.009928982238788875, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14406644267251711, 'dropout_rate_Layer_2': 0.2199078803004349, 'dropout_rate_Layer_3': 0.19973389971440175, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012797972267611208, 'l1_Layer_2': 0.006276128269052627, 'l1_Layer_3': 5.7625031950304135e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 95, 'n_units_Layer_3': 160}. Best is trial 226 with value: 3.697290035333048.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.72 | sMAPE for Validation Set is: 7.42% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.25 | sMAPE for Test Set is: 8.90% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:29:18,731]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:29:22,416]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:29:26,311]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:29:30,846]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:29:34,765]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:29:40,775]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:29:46,477]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:29:59,171]\u001b[0m Trial 288 finished with value: 4.091882165823569 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015196554932100765, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03428135984954293, 'dropout_rate_Layer_2': 0.008386332567969779, 'dropout_rate_Layer_3': 0.05374315631598843, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005615589755369421, 'l1_Layer_2': 0.0005772523989121242, 'l1_Layer_3': 2.3553537060271546e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 160, 'n_units_Layer_3': 265}. Best is trial 226 with value: 3.697290035333048.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.09 | sMAPE for Validation Set is: 7.93% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.13 | sMAPE for Test Set is: 10.36% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:30:03,259]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:30:03,487]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:30:08,839]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:30:09,163]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:30:15,071]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:30:16,918]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:30:58,963]\u001b[0m Trial 302 finished with value: 3.749350398647941 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011868213047760076, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03249889613935052, 'dropout_rate_Layer_2': 0.028313610168871572, 'dropout_rate_Layer_3': 0.18498575406693774, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005515974015306844, 'l1_Layer_2': 0.00048630718593963224, 'l1_Layer_3': 8.933725116768874e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 170, 'n_units_Layer_3': 175}. Best is trial 226 with value: 3.697290035333048.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 7.53% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.69 | sMAPE for Test Set is: 9.55% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:31:02,620]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:31:17,288]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:31:19,905]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:31:38,889]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:31:42,574]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:31:50,382]\u001b[0m Trial 306 finished with value: 3.8973456541963585 and parameters: {'n_hidden': 3, 'learning_rate': 0.03361854096855113, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20933134301240947, 'dropout_rate_Layer_2': 0.1540904385247468, 'dropout_rate_Layer_3': 0.14295721331997674, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003037226621508245, 'l1_Layer_2': 0.021142031189503845, 'l1_Layer_3': 5.7650610334593126e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 50, 'n_units_Layer_3': 145}. Best is trial 226 with value: 3.697290035333048.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.90 | sMAPE for Validation Set is: 7.65% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.07 | sMAPE for Test Set is: 8.39% | rMAE for Test Set is: 0.63\n",
      "MAE for Validation Set is: 4.34 | sMAPE for Validation Set is: 8.64% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 4.79 | sMAPE for Test Set is: 9.83% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:31:51,509]\u001b[0m Trial 303 finished with value: 4.337394932279818 and parameters: {'n_hidden': 4, 'learning_rate': 0.007445825738938606, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.250891841045082, 'dropout_rate_Layer_2': 0.03842142083217645, 'dropout_rate_Layer_3': 0.34141198756442365, 'dropout_rate_Layer_4': 0.31799252885970813, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 7.485550671251181e-05, 'l1_Layer_2': 2.4689647881413442e-05, 'l1_Layer_3': 1.9309908255075917e-05, 'l1_Layer_4': 0.013180320149764327, 'n_units_Layer_1': 130, 'n_units_Layer_2': 65, 'n_units_Layer_3': 135, 'n_units_Layer_4': 145}. Best is trial 226 with value: 3.697290035333048.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:32:11,481]\u001b[0m Trial 311 finished with value: 3.6700652696034095 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011295578077898287, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.029894197391691718, 'dropout_rate_Layer_2': 0.038581130167776076, 'dropout_rate_Layer_3': 0.02428996317951769, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005690934574214105, 'l1_Layer_2': 0.0008413399194257004, 'l1_Layer_3': 0.0001372237716653267, 'n_units_Layer_1': 190, 'n_units_Layer_2': 170, 'n_units_Layer_3': 145}. Best is trial 311 with value: 3.6700652696034095.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.67 | sMAPE for Validation Set is: 7.27% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.39 | sMAPE for Test Set is: 8.79% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:32:15,542]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:32:18,731]\u001b[0m Trial 284 finished with value: 4.313718681450885 and parameters: {'n_hidden': 4, 'learning_rate': 0.013197766933007709, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26024593752123554, 'dropout_rate_Layer_2': 0.04335783540687819, 'dropout_rate_Layer_3': 0.3234288522585149, 'dropout_rate_Layer_4': 0.3253802283639218, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.4081561912077516e-05, 'l1_Layer_2': 2.3907757765727228e-05, 'l1_Layer_3': 5.231809619935063e-05, 'l1_Layer_4': 0.0010782214154536603, 'n_units_Layer_1': 135, 'n_units_Layer_2': 50, 'n_units_Layer_3': 65, 'n_units_Layer_4': 80}. Best is trial 311 with value: 3.6700652696034095.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.31 | sMAPE for Validation Set is: 8.47% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.84 | sMAPE for Test Set is: 9.82% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:32:20,240]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 7.47% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.58 | sMAPE for Test Set is: 9.27% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:32:22,454]\u001b[0m Trial 310 finished with value: 3.7494664300442633 and parameters: {'n_hidden': 3, 'learning_rate': 0.001000601349965767, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03654226681643462, 'dropout_rate_Layer_2': 0.0015124362958001299, 'dropout_rate_Layer_3': 0.19679678754400243, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005385324839297202, 'l1_Layer_2': 0.0006095610715890929, 'l1_Layer_3': 8.49978037857099e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 170, 'n_units_Layer_3': 155}. Best is trial 311 with value: 3.6700652696034095.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:32:23,550]\u001b[0m Trial 309 finished with value: 3.6360495572649563 and parameters: {'n_hidden': 3, 'learning_rate': 0.03161562800352151, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2081249133586977, 'dropout_rate_Layer_2': 0.3066413567161132, 'dropout_rate_Layer_3': 0.15529114245617243, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00041469270848371135, 'l1_Layer_2': 1.168483928201228e-05, 'l1_Layer_3': 4.378062138457491e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 50, 'n_units_Layer_3': 150}. Best is trial 309 with value: 3.6360495572649563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.64 | sMAPE for Validation Set is: 7.28% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.12 | sMAPE for Test Set is: 8.78% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:32:25,671]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:32:30,449]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:32:30,674]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:32:31,381]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:32:37,082]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:32:47,569]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:32:53,033]\u001b[0m Trial 319 finished with value: 5.454889924166589 and parameters: {'n_hidden': 3, 'learning_rate': 0.006947364247655898, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28758154976144445, 'dropout_rate_Layer_2': 0.13326035725868335, 'dropout_rate_Layer_3': 0.03005123899247393, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0005225488679145971, 'l1_Layer_2': 2.7243137610746325e-05, 'l1_Layer_3': 4.168423484422445e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 125, 'n_units_Layer_3': 165}. Best is trial 309 with value: 3.6360495572649563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.45 | sMAPE for Validation Set is: 10.45% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 5.91 | sMAPE for Test Set is: 11.79% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:32:55,649]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:32:57,174]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:33:00,118]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:33:00,976]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:33:07,483]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:33:12,298]\u001b[0m Trial 322 finished with value: 3.7059002691141054 and parameters: {'n_hidden': 3, 'learning_rate': 0.001217045844720688, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 9.412917097987184e-05, 'dropout_rate_Layer_2': 0.08747731706826355, 'dropout_rate_Layer_3': 0.1887486889388812, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006924213294268337, 'l1_Layer_2': 0.0018328938950221115, 'l1_Layer_3': 9.190570503808909e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 170, 'n_units_Layer_3': 175}. Best is trial 309 with value: 3.6360495572649563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.71 | sMAPE for Validation Set is: 7.40% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.46 | sMAPE for Test Set is: 9.10% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:33:18,719]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:33:21,821]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:33:23,620]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:33:29,528]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:33:32,469]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:33:36,271]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:33:41,814]\u001b[0m Trial 326 finished with value: 3.7979460729300647 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011758882522646208, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0013347667626121135, 'dropout_rate_Layer_2': 0.09063879819993526, 'dropout_rate_Layer_3': 0.1587569611112391, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00041261338477478375, 'l1_Layer_2': 0.0017958452432307837, 'l1_Layer_3': 0.00016138324471958574, 'n_units_Layer_1': 190, 'n_units_Layer_2': 170, 'n_units_Layer_3': 170}. Best is trial 309 with value: 3.6360495572649563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.80 | sMAPE for Validation Set is: 7.55% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.32 | sMAPE for Test Set is: 8.82% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:33:41,964]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:33:47,380]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:33:49,749]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:33:53,904]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:33:54,031]\u001b[0m Trial 327 finished with value: 4.4734418691958355 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025055026824298827, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22028495664505354, 'dropout_rate_Layer_2': 0.13504945608742908, 'dropout_rate_Layer_3': 0.22410654459122412, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.442078776865006e-05, 'l1_Layer_2': 2.929533996105673e-05, 'l1_Layer_3': 2.233744253852633e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 135, 'n_units_Layer_3': 245}. Best is trial 309 with value: 3.6360495572649563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.47 | sMAPE for Validation Set is: 8.84% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 5.67 | sMAPE for Test Set is: 11.31% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:33:59,900]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:34:00,433]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:34:05,394]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:34:15,823]\u001b[0m Trial 334 finished with value: 3.7057328228621955 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007449481663500869, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008676345470024691, 'dropout_rate_Layer_2': 0.00020483385522138196, 'dropout_rate_Layer_3': 0.24771475348251337, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009557957857785156, 'l1_Layer_2': 0.0005363820769948392, 'l1_Layer_3': 0.00010811410934445347, 'n_units_Layer_1': 190, 'n_units_Layer_2': 65, 'n_units_Layer_3': 165}. Best is trial 309 with value: 3.6360495572649563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.71 | sMAPE for Validation Set is: 7.45% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.94 | sMAPE for Test Set is: 9.75% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:34:18,552]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:34:23,713]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:34:27,426]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:34:27,846]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:34:30,942]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:34:33,556]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:34:35,338]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:34:40,297]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:34:41,959]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:34:42,541]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:34:44,250]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:34:49,228]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:34:50,058]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:34:53,668]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:34:54,501]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:34:57,779]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:35:03,115]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:35:11,448]\u001b[0m Trial 347 finished with value: 3.8511235309845913 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007172120689200998, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0011606900757802586, 'dropout_rate_Layer_2': 0.00798426810466199, 'dropout_rate_Layer_3': 0.2469666135437639, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009319347939764905, 'l1_Layer_2': 0.000492547038396882, 'l1_Layer_3': 0.00011122215924173189, 'n_units_Layer_1': 190, 'n_units_Layer_2': 60, 'n_units_Layer_3': 175}. Best is trial 309 with value: 3.6360495572649563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.85 | sMAPE for Validation Set is: 7.65% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.00 | sMAPE for Test Set is: 9.81% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:35:15,665]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:35:26,534]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:35:30,348]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:35:34,010]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:35:38,184]\u001b[0m Trial 360 finished with value: 3.758873394232667 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007707878350488122, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02182613666893309, 'dropout_rate_Layer_2': 0.009941221846901365, 'dropout_rate_Layer_3': 0.1802353620379149, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006160589260258675, 'l1_Layer_2': 0.0020612234027839226, 'l1_Layer_3': 0.00032942143769524657, 'n_units_Layer_1': 195, 'n_units_Layer_2': 105, 'n_units_Layer_3': 160}. Best is trial 309 with value: 3.6360495572649563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.76 | sMAPE for Validation Set is: 7.50% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.58 | sMAPE for Test Set is: 9.14% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:35:38,786]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:35:43,643]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:35:44,700]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:35:50,600]\u001b[0m Trial 363 finished with value: 3.815194418381491 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007549537276511167, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.018491860912685357, 'dropout_rate_Layer_2': 0.011619589041380576, 'dropout_rate_Layer_3': 0.2544422892505904, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005984919267359797, 'l1_Layer_2': 0.0022142628932053845, 'l1_Layer_3': 0.00033728461316103446, 'n_units_Layer_1': 195, 'n_units_Layer_2': 65, 'n_units_Layer_3': 145}. Best is trial 309 with value: 3.6360495572649563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.82 | sMAPE for Validation Set is: 7.62% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.45 | sMAPE for Test Set is: 9.00% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:35:54,652]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:35:56,822]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:35:58,982]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:35:59,982]\u001b[0m Trial 361 finished with value: 3.752634371641184 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007554453841346938, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.015342911143754225, 'dropout_rate_Layer_2': 0.008605395928869757, 'dropout_rate_Layer_3': 0.26653305941899164, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007314406894108771, 'l1_Layer_2': 0.002440692923720262, 'l1_Layer_3': 0.00028732180648951427, 'n_units_Layer_1': 195, 'n_units_Layer_2': 105, 'n_units_Layer_3': 160}. Best is trial 309 with value: 3.6360495572649563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 7.52% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.48 | sMAPE for Test Set is: 9.07% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:36:01,661]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:36:05,158]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:36:07,107]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:36:10,969]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:36:14,511]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:36:19,162]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:36:23,962]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:36:27,705]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:36:33,705]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:36:40,373]\u001b[0m Trial 371 finished with value: 3.727071751384983 and parameters: {'n_hidden': 3, 'learning_rate': 0.011640526864683426, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.202097684756094, 'dropout_rate_Layer_2': 0.2916410844062596, 'dropout_rate_Layer_3': 0.19533928537470358, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.355723270045392e-05, 'l1_Layer_2': 0.0014867344083351185, 'l1_Layer_3': 3.6829262421208965e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 105, 'n_units_Layer_3': 180}. Best is trial 309 with value: 3.6360495572649563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.73 | sMAPE for Validation Set is: 7.38% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 3.92 | sMAPE for Test Set is: 8.25% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:36:43,578]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:36:50,207]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:36:54,678]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:36:57,714]\u001b[0m Trial 383 finished with value: 3.6418235151106195 and parameters: {'n_hidden': 3, 'learning_rate': 0.01053167603548744, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20276956027266424, 'dropout_rate_Layer_2': 0.2895494781512276, 'dropout_rate_Layer_3': 0.19548869692571808, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.31988648875287e-05, 'l1_Layer_2': 7.02513413643941e-05, 'l1_Layer_3': 2.959584399422162e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 105, 'n_units_Layer_3': 175}. Best is trial 309 with value: 3.6360495572649563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.64 | sMAPE for Validation Set is: 7.31% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.11 | sMAPE for Test Set is: 8.62% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:37:01,293]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:37:05,559]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:37:11,692]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:37:15,077]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:37:18,467]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:37:21,319]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:37:21,990]\u001b[0m Trial 388 finished with value: 3.6010169628789748 and parameters: {'n_hidden': 3, 'learning_rate': 0.009826643469628612, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1126979049659186, 'dropout_rate_Layer_2': 0.222222923826823, 'dropout_rate_Layer_3': 0.2659615119449431, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.8772173102478557e-05, 'l1_Layer_2': 3.8260421257213075e-05, 'l1_Layer_3': 7.151933056965535e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 50, 'n_units_Layer_3': 150}. Best is trial 388 with value: 3.6010169628789748.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.60 | sMAPE for Validation Set is: 7.19% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 3.99 | sMAPE for Test Set is: 8.47% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:37:22,526]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:37:30,161]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:37:34,896]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:37:37,615]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:37:53,154]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:37:55,801]\u001b[0m Trial 385 finished with value: 4.159071413862416 and parameters: {'n_hidden': 4, 'learning_rate': 0.006002030193030998, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24343832367092097, 'dropout_rate_Layer_2': 0.07566201461121658, 'dropout_rate_Layer_3': 0.3544504185741944, 'dropout_rate_Layer_4': 0.21507397995466435, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 6.064842862395922e-05, 'l1_Layer_2': 3.684764919767326e-05, 'l1_Layer_3': 0.001460294604880231, 'l1_Layer_4': 0.015040960677604765, 'n_units_Layer_1': 120, 'n_units_Layer_2': 75, 'n_units_Layer_3': 100, 'n_units_Layer_4': 105}. Best is trial 388 with value: 3.6010169628789748.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.16 | sMAPE for Validation Set is: 8.20% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.46 | sMAPE for Test Set is: 9.20% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:37:57,003]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:38:00,572]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:38:10,627]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:38:14,802]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:38:19,555]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:38:20,066]\u001b[0m Trial 402 finished with value: 3.606941886214571 and parameters: {'n_hidden': 3, 'learning_rate': 0.015864642814138116, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08282012351054668, 'dropout_rate_Layer_2': 0.3641995677231439, 'dropout_rate_Layer_3': 0.2755338455509812, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.4771036162071347e-05, 'l1_Layer_2': 4.155542190551816e-05, 'l1_Layer_3': 2.323187431315003e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 50, 'n_units_Layer_3': 200}. Best is trial 388 with value: 3.6010169628789748.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.61 | sMAPE for Validation Set is: 7.16% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 3.97 | sMAPE for Test Set is: 8.63% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:38:21,845]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:38:26,722]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:38:29,178]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:38:32,472]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:38:32,936]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:38:38,074]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:38:39,816]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:38:47,763]\u001b[0m Trial 411 finished with value: 5.473908628467297 and parameters: {'n_hidden': 3, 'learning_rate': 0.008706069802628153, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27361438214001615, 'dropout_rate_Layer_2': 0.2388804140129948, 'dropout_rate_Layer_3': 0.222963930518443, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 9.385558697825737e-05, 'l1_Layer_2': 1.9893834314805415e-05, 'l1_Layer_3': 5.350695890497013e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 190, 'n_units_Layer_3': 245}. Best is trial 388 with value: 3.6010169628789748.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.47 | sMAPE for Validation Set is: 10.58% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 6.22 | sMAPE for Test Set is: 12.38% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:38:49,420]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:38:49,566]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:38:54,843]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:39:00,095]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:39:01,299]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:39:12,163]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:39:17,482]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:39:17,693]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:39:17,939]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:39:25,941]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:39:26,388]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:39:26,788]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:39:33,243]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:39:35,763]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:39:37,673]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:39:39,647]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:39:40,676]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:39:46,174]\u001b[0m Trial 425 finished with value: 4.346436704097514 and parameters: {'n_hidden': 3, 'learning_rate': 0.01658363285913891, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07000144599256114, 'dropout_rate_Layer_2': 0.37477915344043244, 'dropout_rate_Layer_3': 0.2931762845327231, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.764787724217332e-05, 'l1_Layer_2': 5.578487376628408e-05, 'l1_Layer_3': 2.139635168578381e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 50, 'n_units_Layer_3': 195}. Best is trial 388 with value: 3.6010169628789748.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.35 | sMAPE for Validation Set is: 8.38% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.17 | sMAPE for Test Set is: 10.31% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:39:47,926]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:39:52,090]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:39:55,276]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:39:55,388]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:39:58,202]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:40:04,539]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:40:08,485]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:40:14,683]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:40:18,989]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:40:19,366]\u001b[0m Trial 436 finished with value: 4.941885445264465 and parameters: {'n_hidden': 3, 'learning_rate': 0.008613002973287669, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11162926476030276, 'dropout_rate_Layer_2': 0.28645220778310915, 'dropout_rate_Layer_3': 0.03318681843565803, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 8.352341553306505e-05, 'l1_Layer_2': 3.206813834709143e-05, 'l1_Layer_3': 3.498519004979126e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 170, 'n_units_Layer_3': 190}. Best is trial 388 with value: 3.6010169628789748.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.94 | sMAPE for Validation Set is: 9.51% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 5.89 | sMAPE for Test Set is: 11.82% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:40:23,420]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:40:29,031]\u001b[0m Trial 445 finished with value: 8.271436701833204 and parameters: {'n_hidden': 3, 'learning_rate': 0.04627641341431666, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10487647446864411, 'dropout_rate_Layer_2': 0.3565331279499, 'dropout_rate_Layer_3': 0.25865748578351333, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.0168788705103272e-05, 'l1_Layer_2': 1.0070913337028197e-05, 'l1_Layer_3': 1.9463496418739472e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 65, 'n_units_Layer_3': 210}. Best is trial 388 with value: 3.6010169628789748.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.27 | sMAPE for Validation Set is: 15.84% | rMAE for Validation Set is: 1.27\n",
      "MAE for Test Set is: 11.72 | sMAPE for Test Set is: 22.54% | rMAE for Test Set is: 1.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:40:31,670]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:40:34,019]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:40:42,167]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:40:43,793]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:40:47,851]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:40:52,755]\u001b[0m Trial 446 finished with value: 4.920107608436429 and parameters: {'n_hidden': 3, 'learning_rate': 0.00807709228469811, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1088462938536341, 'dropout_rate_Layer_2': 0.2757159885136395, 'dropout_rate_Layer_3': 0.020837429968361233, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0001467570053052651, 'l1_Layer_2': 3.8502939432098e-05, 'l1_Layer_3': 2.9120297720899114e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 165, 'n_units_Layer_3': 195}. Best is trial 388 with value: 3.6010169628789748.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.92 | sMAPE for Validation Set is: 9.51% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 5.56 | sMAPE for Test Set is: 11.19% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:40:58,623]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:40:58,951]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:41:04,386]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:41:08,417]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:41:15,063]\u001b[0m Trial 451 finished with value: 4.963685178778913 and parameters: {'n_hidden': 3, 'learning_rate': 0.008080488478386072, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10731199324646866, 'dropout_rate_Layer_2': 0.34116313823930405, 'dropout_rate_Layer_3': 0.019714387097788534, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 8.250590267918805e-05, 'l1_Layer_2': 2.7767537343225058e-05, 'l1_Layer_3': 4.938817144003398e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 170, 'n_units_Layer_3': 185}. Best is trial 388 with value: 3.6010169628789748.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.96 | sMAPE for Validation Set is: 9.63% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 5.78 | sMAPE for Test Set is: 11.60% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:41:17,513]\u001b[0m Trial 452 finished with value: 3.549475602055839 and parameters: {'n_hidden': 3, 'learning_rate': 0.02361048015148, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12445605356546972, 'dropout_rate_Layer_2': 0.31046878609760475, 'dropout_rate_Layer_3': 0.36367605814797016, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.6672967859177213e-05, 'l1_Layer_2': 2.5731003229080572e-05, 'l1_Layer_3': 7.194666740590336e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 80, 'n_units_Layer_3': 135}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.55 | sMAPE for Validation Set is: 7.11% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 3.93 | sMAPE for Test Set is: 8.64% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:41:21,446]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:41:25,469]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:41:27,746]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:41:30,192]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:41:38,091]\u001b[0m Trial 460 finished with value: 5.39624516907129 and parameters: {'n_hidden': 3, 'learning_rate': 0.00964738934434836, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09816196278016288, 'dropout_rate_Layer_2': 0.3454282085189518, 'dropout_rate_Layer_3': 0.02557998808436416, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00014757438141523298, 'l1_Layer_2': 3.914758302657283e-05, 'l1_Layer_3': 5.983958196662318e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 175, 'n_units_Layer_3': 185}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.40 | sMAPE for Validation Set is: 10.37% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 5.86 | sMAPE for Test Set is: 11.71% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:41:40,906]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:41:46,229]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:41:50,379]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:41:59,362]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:42:00,280]\u001b[0m Trial 463 finished with value: 4.7626841675991 and parameters: {'n_hidden': 3, 'learning_rate': 0.007144798326883203, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08806275611188227, 'dropout_rate_Layer_2': 0.018867639161960242, 'dropout_rate_Layer_3': 0.010689494080348024, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00012173264875388845, 'l1_Layer_2': 3.183846618231951e-05, 'l1_Layer_3': 4.0718659169870514e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 170, 'n_units_Layer_3': 185}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.76 | sMAPE for Validation Set is: 9.20% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 5.26 | sMAPE for Test Set is: 10.55% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:42:06,547]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:42:10,090]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:42:10,776]\u001b[0m Trial 464 finished with value: 3.6391779979691603 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009858346524801783, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07438459062325142, 'dropout_rate_Layer_2': 0.02355591279261187, 'dropout_rate_Layer_3': 0.23322454344840293, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005546477847970678, 'l1_Layer_2': 0.0009671993024410629, 'l1_Layer_3': 5.333817616037242e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 175, 'n_units_Layer_3': 150}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.64 | sMAPE for Validation Set is: 7.27% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 3.90 | sMAPE for Test Set is: 8.10% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:42:17,357]\u001b[0m Trial 471 finished with value: 6.5623105281424925 and parameters: {'n_hidden': 3, 'learning_rate': 0.02332017130035953, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11483612002884216, 'dropout_rate_Layer_2': 0.3392227504074334, 'dropout_rate_Layer_3': 0.37187581834682976, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 4.3746499091412605e-05, 'l1_Layer_2': 1.8393486038314235e-05, 'l1_Layer_3': 8.196788036891855e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 80, 'n_units_Layer_3': 140}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.56 | sMAPE for Validation Set is: 12.57% | rMAE for Validation Set is: 1.01\n",
      "MAE for Test Set is: 7.01 | sMAPE for Test Set is: 13.75% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:42:17,780]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.80 | sMAPE for Validation Set is: 7.62% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.44 | sMAPE for Test Set is: 9.03% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:42:20,906]\u001b[0m Trial 458 finished with value: 3.8003039544032724 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008376674180793938, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01051736962730669, 'dropout_rate_Layer_2': 0.02231207124907083, 'dropout_rate_Layer_3': 0.2310858800060015, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008173668634785804, 'l1_Layer_2': 0.0021854039528012943, 'l1_Layer_3': 0.0018379151857822826, 'n_units_Layer_1': 190, 'n_units_Layer_2': 70, 'n_units_Layer_3': 160}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:42:24,604]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:42:27,760]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:42:29,800]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:42:29,995]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:42:30,717]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:42:36,467]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:42:41,622]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:42:44,134]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:42:44,213]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:42:45,438]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:42:49,579]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:42:50,056]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:42:57,772]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:42:57,983]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:43:03,694]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:43:06,496]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:43:07,325]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:43:12,195]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:43:14,267]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:43:16,250]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:43:20,054]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:43:20,467]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:43:24,108]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:43:27,764]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:43:31,687]\u001b[0m Trial 492 finished with value: 5.439626187789819 and parameters: {'n_hidden': 3, 'learning_rate': 0.012159118859481392, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10154147378167722, 'dropout_rate_Layer_2': 0.37099462782866555, 'dropout_rate_Layer_3': 0.016020278894441946, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0001364773118631029, 'l1_Layer_2': 2.610928943271466e-05, 'l1_Layer_3': 6.312285001676837e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 170, 'n_units_Layer_3': 190}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.44 | sMAPE for Validation Set is: 10.37% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 5.84 | sMAPE for Test Set is: 11.69% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:43:32,357]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:43:37,607]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:43:38,055]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:43:42,132]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:43:44,290]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:43:46,531]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:43:46,841]\u001b[0m Trial 494 finished with value: 4.987117101813163 and parameters: {'n_hidden': 3, 'learning_rate': 0.010218371172234113, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10894288962740899, 'dropout_rate_Layer_2': 0.3647876332483188, 'dropout_rate_Layer_3': 0.015925915410859262, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0001303685101357776, 'l1_Layer_2': 2.302886835864735e-05, 'l1_Layer_3': 7.02582675453116e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 170, 'n_units_Layer_3': 190}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.99 | sMAPE for Validation Set is: 9.65% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 5.63 | sMAPE for Test Set is: 11.40% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:43:51,969]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:43:54,638]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:43:59,179]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:44:05,603]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:44:10,141]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:44:16,045]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:44:27,236]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:44:30,716]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:44:30,951]\u001b[0m Trial 506 finished with value: 4.547963163972567 and parameters: {'n_hidden': 3, 'learning_rate': 0.007345784803901753, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08259299402233422, 'dropout_rate_Layer_2': 0.3892776438477564, 'dropout_rate_Layer_3': 0.02176326309771702, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002117747760794956, 'l1_Layer_2': 3.891002682476233e-05, 'l1_Layer_3': 0.0001232065056669329, 'n_units_Layer_1': 205, 'n_units_Layer_2': 175, 'n_units_Layer_3': 180}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.55 | sMAPE for Validation Set is: 8.82% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 5.30 | sMAPE for Test Set is: 10.48% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:44:31,525]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:44:39,794]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:44:44,852]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:44:49,019]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:44:53,496]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:44:57,551]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:45:01,403]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:45:09,057]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:45:10,160]\u001b[0m Trial 508 finished with value: 4.443300789996455 and parameters: {'n_hidden': 4, 'learning_rate': 0.00865650700734277, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2514887304494064, 'dropout_rate_Layer_2': 0.027517804709498054, 'dropout_rate_Layer_3': 0.3322299862581021, 'dropout_rate_Layer_4': 0.36016783001527564, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00010883429282286094, 'l1_Layer_2': 2.8631101096622184e-05, 'l1_Layer_3': 7.083833703507379e-05, 'l1_Layer_4': 0.01745219265967704, 'n_units_Layer_1': 130, 'n_units_Layer_2': 60, 'n_units_Layer_3': 130, 'n_units_Layer_4': 130}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.44 | sMAPE for Validation Set is: 8.86% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.75 | sMAPE for Test Set is: 10.06% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:45:14,120]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:45:16,590]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:45:22,388]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:45:27,733]\u001b[0m Trial 524 finished with value: 3.6874150353614623 and parameters: {'n_hidden': 3, 'learning_rate': 0.028564400746606596, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0531508601082101, 'dropout_rate_Layer_2': 0.2491286598984375, 'dropout_rate_Layer_3': 0.2467805174578156, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.51588075950485e-05, 'l1_Layer_2': 1.669131527318811e-05, 'l1_Layer_3': 3.685377640831144e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 75, 'n_units_Layer_3': 150}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.69 | sMAPE for Validation Set is: 7.38% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.22 | sMAPE for Test Set is: 9.09% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:45:37,788]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:45:38,082]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:45:44,399]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:45:44,657]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:45:50,223]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:45:55,613]\u001b[0m Trial 516 finished with value: 3.7157141388639174 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007517630104921872, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.040969103054060235, 'dropout_rate_Layer_2': 0.023803458380870647, 'dropout_rate_Layer_3': 0.184452746161127, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011778616394807146, 'l1_Layer_2': 0.0003903845011725256, 'l1_Layer_3': 0.003583239354463397, 'n_units_Layer_1': 185, 'n_units_Layer_2': 65, 'n_units_Layer_3': 140}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.72 | sMAPE for Validation Set is: 7.41% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.55 | sMAPE for Test Set is: 9.19% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:45:56,150]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:45:57,787]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:46:00,206]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:46:05,411]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:46:07,414]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:46:11,580]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:46:13,411]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:46:16,663]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:46:18,592]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:46:23,415]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:46:25,372]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:46:27,350]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:46:35,318]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:46:41,282]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:46:45,937]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:47:29,400]\u001b[0m Trial 548 finished with value: 4.584832806951285 and parameters: {'n_hidden': 3, 'learning_rate': 0.006086973512934427, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07349275212871217, 'dropout_rate_Layer_2': 0.033300550949591785, 'dropout_rate_Layer_3': 0.19806831716949058, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011480125931798172, 'l1_Layer_2': 6.549833341838372e-05, 'l1_Layer_3': 2.1749471916350274e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 195, 'n_units_Layer_3': 190}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.58 | sMAPE for Validation Set is: 8.90% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 5.99 | sMAPE for Test Set is: 11.85% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:47:33,160]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:47:48,051]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:47:59,367]\u001b[0m Trial 544 finished with value: 4.249841350186027 and parameters: {'n_hidden': 4, 'learning_rate': 0.006459169748447742, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26474304873384863, 'dropout_rate_Layer_2': 0.04904558421605559, 'dropout_rate_Layer_3': 0.37557267245825887, 'dropout_rate_Layer_4': 0.383163415727167, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.459104276805338e-05, 'l1_Layer_2': 1.093073426626559e-05, 'l1_Layer_3': 1.4294813550573963e-05, 'l1_Layer_4': 0.0049891014622415585, 'n_units_Layer_1': 85, 'n_units_Layer_2': 55, 'n_units_Layer_3': 225, 'n_units_Layer_4': 165}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.25 | sMAPE for Validation Set is: 8.38% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 4.55 | sMAPE for Test Set is: 9.39% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:48:03,025]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:48:09,149]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:48:12,388]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:48:22,675]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:48:26,918]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:48:30,960]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:48:36,427]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:48:37,379]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:48:43,493]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:48:48,327]\u001b[0m Trial 557 finished with value: 4.363879702246611 and parameters: {'n_hidden': 3, 'learning_rate': 0.001976624729399591, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07636137368191345, 'dropout_rate_Layer_2': 0.021072637926689543, 'dropout_rate_Layer_3': 0.0028659964283700816, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.756116036203489e-05, 'l1_Layer_2': 8.411523156823277e-05, 'l1_Layer_3': 0.00010017492205531409, 'n_units_Layer_1': 115, 'n_units_Layer_2': 190, 'n_units_Layer_3': 205}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.36 | sMAPE for Validation Set is: 8.43% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.74 | sMAPE for Test Set is: 11.42% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:48:57,179]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:49:03,749]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:49:07,769]\u001b[0m Trial 554 finished with value: 3.7497920886986313 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010112462001456268, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04301634776992944, 'dropout_rate_Layer_2': 0.017583498718012465, 'dropout_rate_Layer_3': 0.25259666738369413, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001606899926069893, 'l1_Layer_2': 0.0006029325844047299, 'l1_Layer_3': 0.00044698527980677633, 'n_units_Layer_1': 195, 'n_units_Layer_2': 115, 'n_units_Layer_3': 155}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 7.40% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.23 | sMAPE for Test Set is: 10.04% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:49:08,006]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:49:13,382]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:49:14,893]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:49:15,409]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:49:16,460]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:49:25,079]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:49:28,575]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:49:32,146]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:49:35,685]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:49:38,307]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:49:38,879]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:49:39,259]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:49:47,923]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:49:48,057]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:50:02,347]\u001b[0m Trial 578 finished with value: 4.630362144519942 and parameters: {'n_hidden': 3, 'learning_rate': 0.008573107871916622, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1104150223666347, 'dropout_rate_Layer_2': 0.04139098199582392, 'dropout_rate_Layer_3': 0.014438184851167477, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00023481070186659895, 'l1_Layer_2': 3.132970304383641e-05, 'l1_Layer_3': 5.381744110893169e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 190, 'n_units_Layer_3': 185}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.63 | sMAPE for Validation Set is: 8.94% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 5.21 | sMAPE for Test Set is: 10.36% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:50:05,816]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:50:16,047]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:50:16,271]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:50:20,761]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:50:22,599]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:50:23,487]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:50:25,553]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:50:29,059]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:50:32,137]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:50:35,265]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:50:37,456]\u001b[0m Trial 589 finished with value: 8.957718846695828 and parameters: {'n_hidden': 3, 'learning_rate': 0.09769872703934311, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.029038988840955487, 'dropout_rate_Layer_2': 0.29384042654884496, 'dropout_rate_Layer_3': 0.29616243704803236, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00028529533289222705, 'l1_Layer_2': 9.770411703047326e-05, 'l1_Layer_3': 0.000360062469830141, 'n_units_Layer_1': 255, 'n_units_Layer_2': 85, 'n_units_Layer_3': 200}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.96 | sMAPE for Validation Set is: 17.59% | rMAE for Validation Set is: 1.38\n",
      "MAE for Test Set is: 11.57 | sMAPE for Test Set is: 22.61% | rMAE for Test Set is: 1.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:50:38,396]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:50:44,073]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:50:49,671]\u001b[0m Trial 590 finished with value: 3.9380381309875125 and parameters: {'n_hidden': 3, 'learning_rate': 0.0047753934372054925, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01722362486280713, 'dropout_rate_Layer_2': 0.030065139120927408, 'dropout_rate_Layer_3': 0.00015436434806653104, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00019658790032045867, 'l1_Layer_2': 4.777281318691147e-05, 'l1_Layer_3': 2.174400372635735e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 200, 'n_units_Layer_3': 180}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.94 | sMAPE for Validation Set is: 7.90% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.31 | sMAPE for Test Set is: 8.90% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:50:50,458]\u001b[0m Trial 566 finished with value: 4.131809591243609 and parameters: {'n_hidden': 4, 'learning_rate': 0.004638235188387218, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2633144321642757, 'dropout_rate_Layer_2': 0.25258053152326077, 'dropout_rate_Layer_3': 0.326346724973785, 'dropout_rate_Layer_4': 0.34567505569156654, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 9.382205883793012e-05, 'l1_Layer_2': 1.853904725299946e-05, 'l1_Layer_3': 2.1331055322360506e-05, 'l1_Layer_4': 0.009703255882144796, 'n_units_Layer_1': 150, 'n_units_Layer_2': 70, 'n_units_Layer_3': 235, 'n_units_Layer_4': 165}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.13 | sMAPE for Validation Set is: 8.13% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.35 | sMAPE for Test Set is: 9.03% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:50:54,473]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:50:57,150]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:51:00,424]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:51:03,198]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:51:12,850]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:51:16,492]\u001b[0m Trial 599 finished with value: 3.912487632655564 and parameters: {'n_hidden': 3, 'learning_rate': 0.004866777530300957, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08804432749842814, 'dropout_rate_Layer_2': 0.046475070042406474, 'dropout_rate_Layer_3': 0.009934156622766548, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002847050527009337, 'l1_Layer_2': 5.1639951264829885e-05, 'l1_Layer_3': 1.266528770341561e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 195, 'n_units_Layer_3': 185}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.91 | sMAPE for Validation Set is: 7.87% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.34 | sMAPE for Test Set is: 8.94% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:51:29,199]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:51:32,076]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:51:34,037]\u001b[0m Trial 596 finished with value: 3.9786275639969104 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012781725238847372, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06962644178492158, 'dropout_rate_Layer_2': 0.04438664909061537, 'dropout_rate_Layer_3': 0.032445409250384305, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001576825124288641, 'l1_Layer_2': 4.8617663334153826e-05, 'l1_Layer_3': 0.00015534505428273858, 'n_units_Layer_1': 125, 'n_units_Layer_2': 270, 'n_units_Layer_3': 175}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.98 | sMAPE for Validation Set is: 7.80% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.87 | sMAPE for Test Set is: 9.72% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:51:37,263]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:51:40,645]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:51:59,118]\u001b[0m Trial 609 finished with value: 3.767462775898158 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014231982312051467, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0760578808983461, 'dropout_rate_Layer_2': 0.04713345568379701, 'dropout_rate_Layer_3': 0.04515975489777056, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014128293596587445, 'l1_Layer_2': 3.7019203930106565e-05, 'l1_Layer_3': 1.5987733889339065e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 195, 'n_units_Layer_3': 175}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.77 | sMAPE for Validation Set is: 7.57% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.68 | sMAPE for Test Set is: 9.51% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:52:02,731]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:52:14,006]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:52:31,366]\u001b[0m Trial 612 finished with value: 3.836808960584289 and parameters: {'n_hidden': 3, 'learning_rate': 0.001248738822148326, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0699087989065093, 'dropout_rate_Layer_2': 0.04810068779575594, 'dropout_rate_Layer_3': 0.05044439784665834, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012955392052862338, 'l1_Layer_2': 3.9373427655928306e-05, 'l1_Layer_3': 1.475468522462541e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 270, 'n_units_Layer_3': 285}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.84 | sMAPE for Validation Set is: 7.68% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.72 | sMAPE for Test Set is: 9.46% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:52:39,724]\u001b[0m Trial 594 finished with value: 3.7933608007342237 and parameters: {'n_hidden': 4, 'learning_rate': 0.007057608925435996, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23987909997071677, 'dropout_rate_Layer_2': 0.01726964730473358, 'dropout_rate_Layer_3': 0.370716056447281, 'dropout_rate_Layer_4': 0.3365082879956515, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00010065573112147053, 'l1_Layer_2': 2.3003453978346228e-05, 'l1_Layer_3': 1.007423245813186e-05, 'l1_Layer_4': 0.00035822954585842563, 'n_units_Layer_1': 60, 'n_units_Layer_2': 60, 'n_units_Layer_3': 80, 'n_units_Layer_4': 140}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:52:39,762]\u001b[0m Trial 607 finished with value: 4.003239499630209 and parameters: {'n_hidden': 4, 'learning_rate': 0.003481238153765051, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20443900445040492, 'dropout_rate_Layer_2': 0.27760818939325876, 'dropout_rate_Layer_3': 0.2734488382265738, 'dropout_rate_Layer_4': 0.338884182417426, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00010318980927393063, 'l1_Layer_2': 2.0145504586182002e-05, 'l1_Layer_3': 2.9719199047710746e-05, 'l1_Layer_4': 0.003675124739458492, 'n_units_Layer_1': 265, 'n_units_Layer_2': 55, 'n_units_Layer_3': 255, 'n_units_Layer_4': 250}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.79 | sMAPE for Validation Set is: 7.49% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.07 | sMAPE for Test Set is: 8.58% | rMAE for Test Set is: 0.63\n",
      "MAE for Validation Set is: 4.00 | sMAPE for Validation Set is: 7.98% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.44 | sMAPE for Test Set is: 9.39% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:52:47,861]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:52:57,426]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:53:00,818]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:53:01,809]\u001b[0m Trial 615 finished with value: 3.8884798377940997 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015847786028967386, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.054533254753842846, 'dropout_rate_Layer_2': 0.0463814194898944, 'dropout_rate_Layer_3': 0.04241323024512318, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001340380177372653, 'l1_Layer_2': 3.757987813206522e-05, 'l1_Layer_3': 1.5738943046098183e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 270, 'n_units_Layer_3': 295}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.89 | sMAPE for Validation Set is: 7.81% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.10 | sMAPE for Test Set is: 10.28% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:53:14,935]\u001b[0m Trial 603 finished with value: 4.466509432774905 and parameters: {'n_hidden': 3, 'learning_rate': 0.007942487749703402, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11739660252094591, 'dropout_rate_Layer_2': 0.3142340271979138, 'dropout_rate_Layer_3': 0.3997745832200928, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.260525361472306e-05, 'l1_Layer_2': 1.9819267844260325e-05, 'l1_Layer_3': 2.6915911787047454e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 75, 'n_units_Layer_3': 150}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.47 | sMAPE for Validation Set is: 8.70% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 5.18 | sMAPE for Test Set is: 10.42% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:53:31,457]\u001b[0m Trial 619 finished with value: 3.6168859223324943 and parameters: {'n_hidden': 3, 'learning_rate': 0.001203687917080227, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05949965573691704, 'dropout_rate_Layer_2': 0.044660369492000994, 'dropout_rate_Layer_3': 0.05388481643283954, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012933887537236623, 'l1_Layer_2': 4.303165417915377e-05, 'l1_Layer_3': 1.2538855358595098e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 275, 'n_units_Layer_3': 200}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.62 | sMAPE for Validation Set is: 7.23% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.57 | sMAPE for Test Set is: 9.25% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:53:34,978]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:53:38,369]\u001b[0m Trial 613 finished with value: 3.7357958816727233 and parameters: {'n_hidden': 3, 'learning_rate': 0.001001474377349795, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0005307426785146081, 'dropout_rate_Layer_2': 0.007992909732054373, 'dropout_rate_Layer_3': 0.22983365614895135, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011458430805322153, 'l1_Layer_2': 0.0007881362539422761, 'l1_Layer_3': 0.0007262541647977484, 'n_units_Layer_1': 200, 'n_units_Layer_2': 165, 'n_units_Layer_3': 135}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.74 | sMAPE for Validation Set is: 7.43% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.61 | sMAPE for Test Set is: 9.23% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:53:51,853]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.81 | sMAPE for Validation Set is: 7.59% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.58 | sMAPE for Test Set is: 9.21% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:53:53,120]\u001b[0m Trial 623 finished with value: 3.807825618678187 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013208931933989241, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05789066636346264, 'dropout_rate_Layer_2': 0.0503268667522548, 'dropout_rate_Layer_3': 0.06011816125253424, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001327920705144485, 'l1_Layer_2': 4.350114919745307e-05, 'l1_Layer_3': 1.2980321560488973e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 275, 'n_units_Layer_3': 295}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:53:56,474]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:53:59,849]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:54:05,397]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:54:10,033]\u001b[0m Trial 618 finished with value: 3.6995413604484155 and parameters: {'n_hidden': 3, 'learning_rate': 0.001025446750913922, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01437980476301843, 'dropout_rate_Layer_2': 0.0003357676397028578, 'dropout_rate_Layer_3': 0.2405577087633319, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007771730389170367, 'l1_Layer_2': 0.0012248803388743563, 'l1_Layer_3': 0.0007370789689599635, 'n_units_Layer_1': 200, 'n_units_Layer_2': 165, 'n_units_Layer_3': 145}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.70 | sMAPE for Validation Set is: 7.32% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.77 | sMAPE for Test Set is: 9.45% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:54:16,424]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:54:25,013]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:54:30,144]\u001b[0m Trial 628 finished with value: 3.7938831797924792 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012525799788509063, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.047530107266893155, 'dropout_rate_Layer_2': 0.047998515794526776, 'dropout_rate_Layer_3': 0.07743479915225752, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013542133586313916, 'l1_Layer_2': 4.3637081815302406e-05, 'l1_Layer_3': 1.143386465874063e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 270, 'n_units_Layer_3': 295}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.79 | sMAPE for Validation Set is: 7.69% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.41 | sMAPE for Test Set is: 9.10% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:54:33,466]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:54:41,128]\u001b[0m Trial 630 finished with value: 3.789411591195972 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014336678854432797, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05466232372503266, 'dropout_rate_Layer_2': 0.05854752157804019, 'dropout_rate_Layer_3': 0.058156487349546496, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001450936319836332, 'l1_Layer_2': 4.442841168179523e-05, 'l1_Layer_3': 1.3448892510378124e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 270, 'n_units_Layer_3': 300}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.79 | sMAPE for Validation Set is: 7.66% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.54 | sMAPE for Test Set is: 9.35% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:54:44,819]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:54:47,706]\u001b[0m Trial 632 finished with value: 3.827037621023935 and parameters: {'n_hidden': 3, 'learning_rate': 0.001329883300294242, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.059197433286609, 'dropout_rate_Layer_2': 0.047637583049588844, 'dropout_rate_Layer_3': 0.05505549643122479, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013991380167815645, 'l1_Layer_2': 4.562540161099886e-05, 'l1_Layer_3': 1.2684186762914156e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 270, 'n_units_Layer_3': 295}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.83 | sMAPE for Validation Set is: 7.66% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.78 | sMAPE for Test Set is: 9.58% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:54:48,295]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:54:53,741]\u001b[0m Trial 633 finished with value: 3.744454152526359 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013100917135731916, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05965583611310886, 'dropout_rate_Layer_2': 0.050652395466366205, 'dropout_rate_Layer_3': 0.06259812598949208, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001478592106441786, 'l1_Layer_2': 4.397973805330372e-05, 'l1_Layer_3': 1.1968509989641968e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 270, 'n_units_Layer_3': 295}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.74 | sMAPE for Validation Set is: 7.59% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.78 | sMAPE for Test Set is: 9.79% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:55:03,800]\u001b[0m Trial 629 finished with value: 3.7161771361876688 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008817554398313968, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01169666923933073, 'dropout_rate_Layer_2': 0.0005374713746091022, 'dropout_rate_Layer_3': 0.22125531603205062, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006619858822549984, 'l1_Layer_2': 0.0015118993474706856, 'l1_Layer_3': 0.0007314860507625896, 'n_units_Layer_1': 190, 'n_units_Layer_2': 135, 'n_units_Layer_3': 135}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.72 | sMAPE for Validation Set is: 7.48% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.31 | sMAPE for Test Set is: 8.85% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:55:05,899]\u001b[0m Trial 636 finished with value: 3.9528064527280726 and parameters: {'n_hidden': 3, 'learning_rate': 0.029552107537487982, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06024018589085086, 'dropout_rate_Layer_2': 0.24843120323987608, 'dropout_rate_Layer_3': 0.24463240294802546, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.704593556812833e-05, 'l1_Layer_2': 1.6094181528378723e-05, 'l1_Layer_3': 3.481882521102333e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 60, 'n_units_Layer_3': 150}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.95 | sMAPE for Validation Set is: 7.94% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.39 | sMAPE for Test Set is: 9.47% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:55:07,145]\u001b[0m Trial 637 finished with value: 3.5881694344124533 and parameters: {'n_hidden': 3, 'learning_rate': 0.001330876702269038, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06061527721942077, 'dropout_rate_Layer_2': 0.04773389942306759, 'dropout_rate_Layer_3': 0.056251517734844075, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016786807633793616, 'l1_Layer_2': 5.351863953039727e-05, 'l1_Layer_3': 1.2357481661034142e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 270, 'n_units_Layer_3': 300}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.59 | sMAPE for Validation Set is: 7.20% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.50 | sMAPE for Test Set is: 9.19% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:55:13,940]\u001b[0m Trial 638 finished with value: 3.6735413992116346 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013419218671990854, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.058902147142669725, 'dropout_rate_Layer_2': 0.04927928136952521, 'dropout_rate_Layer_3': 0.06897405760301123, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001660534772742877, 'l1_Layer_2': 5.4634246040934885e-05, 'l1_Layer_3': 1.2855616786497298e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 275, 'n_units_Layer_3': 300}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.67 | sMAPE for Validation Set is: 7.38% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.33 | sMAPE for Test Set is: 8.89% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:55:17,787]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:55:18,041]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:55:18,640]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:55:27,022]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:55:30,606]\u001b[0m Trial 641 finished with value: 3.6612931706607896 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012973696381990234, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05920092804162501, 'dropout_rate_Layer_2': 0.046835051562763144, 'dropout_rate_Layer_3': 0.07630430194422483, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00019272282692187656, 'l1_Layer_2': 5.430889034410529e-05, 'l1_Layer_3': 1.2650159999882534e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 275, 'n_units_Layer_3': 300}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.66 | sMAPE for Validation Set is: 7.32% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.71 | sMAPE for Test Set is: 9.65% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:55:47,148]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:55:50,433]\u001b[0m Trial 646 finished with value: 3.586307176300489 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015791792693815993, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05552658690061974, 'dropout_rate_Layer_2': 0.056717655545222574, 'dropout_rate_Layer_3': 0.06455279438087988, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016478605190645257, 'l1_Layer_2': 5.244723184318659e-05, 'l1_Layer_3': 1.110845730222761e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 280, 'n_units_Layer_3': 295}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.59 | sMAPE for Validation Set is: 7.19% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.35 | sMAPE for Test Set is: 8.93% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:55:56,937]\u001b[0m Trial 647 finished with value: 3.600019891657199 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015643649750900267, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.054878309370668184, 'dropout_rate_Layer_2': 0.05641245163595049, 'dropout_rate_Layer_3': 0.06556137094723172, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020509399153085126, 'l1_Layer_2': 5.3816280194116675e-05, 'l1_Layer_3': 1.0226710444756732e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 280, 'n_units_Layer_3': 295}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.60 | sMAPE for Validation Set is: 7.20% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.29 | sMAPE for Test Set is: 8.83% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:56:10,785]\u001b[0m Trial 649 finished with value: 3.7222377194683425 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015237120172949847, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.052687697167130204, 'dropout_rate_Layer_2': 0.05728693130596436, 'dropout_rate_Layer_3': 0.0612999874297446, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001664786972294907, 'l1_Layer_2': 5.7794968370724695e-05, 'l1_Layer_3': 1.0038911106550687e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 280, 'n_units_Layer_3': 295}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.72 | sMAPE for Validation Set is: 7.39% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.62 | sMAPE for Test Set is: 9.30% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:56:34,340]\u001b[0m Trial 651 finished with value: 3.671120639832992 and parameters: {'n_hidden': 3, 'learning_rate': 0.03858467411619008, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05006200942410967, 'dropout_rate_Layer_2': 0.2521795851929354, 'dropout_rate_Layer_3': 0.24084703471385044, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.46126402242028e-05, 'l1_Layer_2': 1.5688629902512047e-05, 'l1_Layer_3': 2.2809173012988706e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 75, 'n_units_Layer_3': 135}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.67 | sMAPE for Validation Set is: 7.35% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.14 | sMAPE for Test Set is: 8.83% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:56:45,548]\u001b[0m Trial 650 finished with value: 3.6988102516604098 and parameters: {'n_hidden': 3, 'learning_rate': 0.027235230658500014, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05108969149487834, 'dropout_rate_Layer_2': 0.2549399361338103, 'dropout_rate_Layer_3': 0.23782607139509002, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.6786269846841755e-05, 'l1_Layer_2': 1.4353098154887663e-05, 'l1_Layer_3': 3.569142450798738e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 75, 'n_units_Layer_3': 135}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.70 | sMAPE for Validation Set is: 7.47% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.35 | sMAPE for Test Set is: 9.39% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:56:47,489]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:56:49,925]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:56:53,819]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:57:00,795]\u001b[0m Trial 652 finished with value: 3.6069669483582625 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015418512399782518, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05899420277555525, 'dropout_rate_Layer_2': 0.06334718513012438, 'dropout_rate_Layer_3': 0.05861495480719365, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020966398668946677, 'l1_Layer_2': 6.695921115592664e-05, 'l1_Layer_3': 1.0785039111632032e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 285, 'n_units_Layer_3': 295}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.61 | sMAPE for Validation Set is: 7.26% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.46 | sMAPE for Test Set is: 9.10% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:57:03,805]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:57:06,432]\u001b[0m Trial 648 finished with value: 4.019014704640351 and parameters: {'n_hidden': 4, 'learning_rate': 0.007058158612947725, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24289573633478795, 'dropout_rate_Layer_2': 0.27241762217844967, 'dropout_rate_Layer_3': 0.38666876038532216, 'dropout_rate_Layer_4': 0.36984075753302176, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.0795106326318315e-05, 'l1_Layer_2': 1.1908526332355063e-05, 'l1_Layer_3': 1.63605541341633e-05, 'l1_Layer_4': 0.000767458587512613, 'n_units_Layer_1': 60, 'n_units_Layer_2': 70, 'n_units_Layer_3': 285, 'n_units_Layer_4': 265}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.02 | sMAPE for Validation Set is: 7.97% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.43 | sMAPE for Test Set is: 9.19% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:57:11,290]\u001b[0m Trial 656 finished with value: 3.749213955726482 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015560423581267857, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.053380487316728564, 'dropout_rate_Layer_2': 0.06058374726521642, 'dropout_rate_Layer_3': 0.06093511806156686, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020912600003297567, 'l1_Layer_2': 6.558499814814969e-05, 'l1_Layer_3': 1.0563565560184705e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 285, 'n_units_Layer_3': 295}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 7.48% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.55 | sMAPE for Test Set is: 9.22% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:57:13,685]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:57:21,849]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:57:22,327]\u001b[0m Trial 658 finished with value: 3.7198284148725946 and parameters: {'n_hidden': 3, 'learning_rate': 0.00155308502653162, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05536575846037316, 'dropout_rate_Layer_2': 0.06544942777859925, 'dropout_rate_Layer_3': 0.08441456170392161, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020204594574689113, 'l1_Layer_2': 6.935613513634981e-05, 'l1_Layer_3': 1.0221960483741018e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 285, 'n_units_Layer_3': 295}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.72 | sMAPE for Validation Set is: 7.49% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.86 | sMAPE for Test Set is: 9.89% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:57:22,527]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:57:29,505]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:57:36,686]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:57:39,823]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:57:42,744]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:57:47,396]\u001b[0m Trial 665 finished with value: 3.7320859606794357 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013347949241097835, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05980222366985028, 'dropout_rate_Layer_2': 0.0687727287603054, 'dropout_rate_Layer_3': 0.06633708711233313, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001774843699628564, 'l1_Layer_2': 8.408773255019879e-05, 'l1_Layer_3': 1.0126142862666437e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 280, 'n_units_Layer_3': 295}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.73 | sMAPE for Validation Set is: 7.53% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.56 | sMAPE for Test Set is: 9.49% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:57:52,919]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:57:56,066]\u001b[0m Trial 662 finished with value: 3.6278374203800934 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013337280014400293, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0430330152787968, 'dropout_rate_Layer_2': 0.06672280759364313, 'dropout_rate_Layer_3': 0.06778778116449437, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017377701845667763, 'l1_Layer_2': 5.578377485029901e-05, 'l1_Layer_3': 1.3205904858276724e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 280, 'n_units_Layer_3': 295}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.63 | sMAPE for Validation Set is: 7.27% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.52 | sMAPE for Test Set is: 9.21% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:57:59,408]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:58:08,225]\u001b[0m Trial 667 finished with value: 3.585140449650017 and parameters: {'n_hidden': 3, 'learning_rate': 0.001066146010909088, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05857280844990192, 'dropout_rate_Layer_2': 0.053584933706552165, 'dropout_rate_Layer_3': 0.06769167228381107, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020814210918971532, 'l1_Layer_2': 5.4650986812795e-05, 'l1_Layer_3': 1.3736242780143061e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 270, 'n_units_Layer_3': 285}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.59 | sMAPE for Validation Set is: 7.17% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.38 | sMAPE for Test Set is: 8.95% | rMAE for Test Set is: 0.68\n",
      "MAE for Validation Set is: 3.65 | sMAPE for Validation Set is: 7.36% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.32 | sMAPE for Test Set is: 8.91% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:58:08,236]\u001b[0m Trial 668 finished with value: 3.646983611028732 and parameters: {'n_hidden': 3, 'learning_rate': 0.001169598395150347, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06014047573486688, 'dropout_rate_Layer_2': 0.055317812772750656, 'dropout_rate_Layer_3': 0.07157454658848124, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002118969537247633, 'l1_Layer_2': 8.345622010580008e-05, 'l1_Layer_3': 1.373537566036073e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 270, 'n_units_Layer_3': 285}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:58:14,186]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:58:19,020]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:58:22,136]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:58:22,587]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.69 | sMAPE for Validation Set is: 7.45% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.38 | sMAPE for Test Set is: 9.11% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:58:24,904]\u001b[0m Trial 672 finished with value: 3.689767553473319 and parameters: {'n_hidden': 3, 'learning_rate': 0.001107017268000865, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.058430469447550634, 'dropout_rate_Layer_2': 0.05581394937988789, 'dropout_rate_Layer_3': 0.0708140384777659, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017073628425782415, 'l1_Layer_2': 8.419330043532753e-05, 'l1_Layer_3': 1.2954319940891007e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 270, 'n_units_Layer_3': 285}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:58:33,864]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:58:39,480]\u001b[0m Trial 677 finished with value: 3.70534758846631 and parameters: {'n_hidden': 3, 'learning_rate': 0.001079054585859046, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04424832934999321, 'dropout_rate_Layer_2': 0.06445527563031903, 'dropout_rate_Layer_3': 0.0824056976857139, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001670105895813262, 'l1_Layer_2': 8.691833969141407e-05, 'l1_Layer_3': 1.2305131933438273e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 280, 'n_units_Layer_3': 300}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.71 | sMAPE for Validation Set is: 7.43% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.61 | sMAPE for Test Set is: 9.57% | rMAE for Test Set is: 0.71\n",
      "MAE for Validation Set is: 3.64 | sMAPE for Validation Set is: 7.32% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.57 | sMAPE for Test Set is: 9.33% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:58:41,422]\u001b[0m Trial 675 finished with value: 3.6399221577191487 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011113667399958798, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04578898542651534, 'dropout_rate_Layer_2': 0.07013581768433673, 'dropout_rate_Layer_3': 0.08074973711378353, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017183177326450394, 'l1_Layer_2': 8.875947775509853e-05, 'l1_Layer_3': 1.2887227263815489e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 290, 'n_units_Layer_3': 300}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:58:42,928]\u001b[0m Trial 679 finished with value: 3.6176691575378896 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011601516625042896, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04325085814817792, 'dropout_rate_Layer_2': 0.0716762575560597, 'dropout_rate_Layer_3': 0.08394065695673521, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001751935674854097, 'l1_Layer_2': 8.192714434574173e-05, 'l1_Layer_3': 1.2199756122315079e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 280, 'n_units_Layer_3': 300}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.62 | sMAPE for Validation Set is: 7.25% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.42 | sMAPE for Test Set is: 9.01% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:58:50,196]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:58:54,841]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:58:55,737]\u001b[0m Trial 680 finished with value: 3.6332112647967634 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011243965263903904, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.045322877896146405, 'dropout_rate_Layer_2': 0.06935226834016975, 'dropout_rate_Layer_3': 0.0831312956021302, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001766431522045369, 'l1_Layer_2': 9.956440366062978e-05, 'l1_Layer_3': 1.2472367000789666e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 290, 'n_units_Layer_3': 300}. Best is trial 452 with value: 3.549475602055839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.63 | sMAPE for Validation Set is: 7.35% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.45 | sMAPE for Test Set is: 9.37% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:59:00,799]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:59:13,622]\u001b[0m Trial 681 finished with value: 3.537419642771645 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011218129007466943, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04184651103461573, 'dropout_rate_Layer_2': 0.06977447468939367, 'dropout_rate_Layer_3': 0.0825793696132891, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016473293079088125, 'l1_Layer_2': 9.895230355813815e-05, 'l1_Layer_3': 1.2390154056678128e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 290, 'n_units_Layer_3': 300}. Best is trial 681 with value: 3.537419642771645.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.54 | sMAPE for Validation Set is: 7.15% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.48 | sMAPE for Test Set is: 9.27% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:59:16,177]\u001b[0m Trial 684 finished with value: 3.5647717362497993 and parameters: {'n_hidden': 3, 'learning_rate': 0.001127450998266304, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04563978668067674, 'dropout_rate_Layer_2': 0.06976808514602204, 'dropout_rate_Layer_3': 0.08397593377129715, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015710291091610858, 'l1_Layer_2': 0.00011793906197964109, 'l1_Layer_3': 1.0005429991074744e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 290, 'n_units_Layer_3': 300}. Best is trial 681 with value: 3.537419642771645.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.56 | sMAPE for Validation Set is: 7.15% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.33 | sMAPE for Test Set is: 8.99% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:59:18,592]\u001b[0m Trial 685 finished with value: 3.5842772951339215 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009809313862542308, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04853710868599781, 'dropout_rate_Layer_2': 0.065785861782488, 'dropout_rate_Layer_3': 0.09144557079897064, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00024277652288688892, 'l1_Layer_2': 0.00014806172413024609, 'l1_Layer_3': 1.2413857462354578e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 290, 'n_units_Layer_3': 300}. Best is trial 681 with value: 3.537419642771645.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.58 | sMAPE for Validation Set is: 7.26% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.41 | sMAPE for Test Set is: 9.12% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:59:22,541]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:59:26,270]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:59:28,979]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:59:31,323]\u001b[0m Trial 687 finished with value: 3.613016635195059 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009515090044525025, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.040565034229315976, 'dropout_rate_Layer_2': 0.07551350664016189, 'dropout_rate_Layer_3': 0.09011169612504595, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016328229125274122, 'l1_Layer_2': 8.592768310110305e-05, 'l1_Layer_3': 1.1959524672000945e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 280, 'n_units_Layer_3': 290}. Best is trial 681 with value: 3.537419642771645.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.61 | sMAPE for Validation Set is: 7.31% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.44 | sMAPE for Test Set is: 9.15% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 15:59:33,978]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:59:35,492]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:59:41,810]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:59:47,574]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 15:59:53,985]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:00:03,632]\u001b[0m Trial 688 finished with value: 3.6733909742792226 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006920299459532922, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03608309380834312, 'dropout_rate_Layer_2': 0.007285246277551715, 'dropout_rate_Layer_3': 0.21844701560986002, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015328370685074681, 'l1_Layer_2': 0.0006848966683083282, 'l1_Layer_3': 0.0007486732904805158, 'n_units_Layer_1': 200, 'n_units_Layer_2': 150, 'n_units_Layer_3': 155}. Best is trial 681 with value: 3.537419642771645.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.67 | sMAPE for Validation Set is: 7.31% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.25 | sMAPE for Test Set is: 8.71% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:00:08,947]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:00:19,722]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:00:23,302]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:00:25,104]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:00:31,055]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:00:31,684]\u001b[0m Trial 700 finished with value: 3.6073339137107534 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010811156943059477, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04656465304395839, 'dropout_rate_Layer_2': 0.06743712700754807, 'dropout_rate_Layer_3': 0.107413744315244, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016806341001286202, 'l1_Layer_2': 9.765828932707785e-05, 'l1_Layer_3': 1.6541148505991128e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 280, 'n_units_Layer_3': 300}. Best is trial 681 with value: 3.537419642771645.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.61 | sMAPE for Validation Set is: 7.27% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.53 | sMAPE for Test Set is: 9.33% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:00:36,677]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:00:37,113]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:00:45,008]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:00:45,510]\u001b[0m Trial 702 finished with value: 3.62670722019295 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010542080859559158, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04728296046291701, 'dropout_rate_Layer_2': 0.06518666897586235, 'dropout_rate_Layer_3': 0.06964696773693395, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001723806749646632, 'l1_Layer_2': 0.00010179341321502707, 'l1_Layer_3': 1.6752341959257472e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 280, 'n_units_Layer_3': 300}. Best is trial 681 with value: 3.537419642771645.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.63 | sMAPE for Validation Set is: 7.25% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.35 | sMAPE for Test Set is: 9.00% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:00:49,652]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:00:58,449]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:01:00,815]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:01:03,197]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.76 | sMAPE for Validation Set is: 7.61% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.82 | sMAPE for Test Set is: 10.01% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:01:05,118]\u001b[0m Trial 709 finished with value: 3.7568790085222474 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011244500883261545, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06217379228394102, 'dropout_rate_Layer_2': 0.07201338096290735, 'dropout_rate_Layer_3': 0.07931024913980977, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002529446850491598, 'l1_Layer_2': 0.0001547705166051856, 'l1_Layer_3': 1.3811739572141794e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 290, 'n_units_Layer_3': 290}. Best is trial 681 with value: 3.537419642771645.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:01:08,328]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:01:12,247]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:01:16,381]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:01:19,846]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:01:20,318]\u001b[0m Trial 707 finished with value: 3.7954036636015114 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007765474979977373, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0234265159882108, 'dropout_rate_Layer_2': 0.0008815072329790806, 'dropout_rate_Layer_3': 0.22026972798644925, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007336522509944059, 'l1_Layer_2': 0.0011530216789031543, 'l1_Layer_3': 0.0007580897552325478, 'n_units_Layer_1': 215, 'n_units_Layer_2': 135, 'n_units_Layer_3': 135}. Best is trial 681 with value: 3.537419642771645.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.80 | sMAPE for Validation Set is: 7.55% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.36 | sMAPE for Test Set is: 8.97% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:01:25,005]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:01:36,756]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:01:37,995]\u001b[0m Trial 715 finished with value: 3.640753723025544 and parameters: {'n_hidden': 3, 'learning_rate': 0.000875959385499161, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03809014392720253, 'dropout_rate_Layer_2': 0.0586975409427014, 'dropout_rate_Layer_3': 0.06676716595250899, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00019762442261189283, 'l1_Layer_2': 8.273165849643559e-05, 'l1_Layer_3': 1.2058932926234973e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 280, 'n_units_Layer_3': 300}. Best is trial 681 with value: 3.537419642771645.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.64 | sMAPE for Validation Set is: 7.34% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.43 | sMAPE for Test Set is: 9.07% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:01:46,611]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:01:54,583]\u001b[0m Trial 721 finished with value: 3.624325531519103 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013822853721407785, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04011578247414171, 'dropout_rate_Layer_2': 0.055746387534847654, 'dropout_rate_Layer_3': 0.08717559337947264, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001594846409840078, 'l1_Layer_2': 9.527472827659934e-05, 'l1_Layer_3': 1.6104441018343078e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 275, 'n_units_Layer_3': 300}. Best is trial 681 with value: 3.537419642771645.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.62 | sMAPE for Validation Set is: 7.26% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.24 | sMAPE for Test Set is: 8.68% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:01:58,300]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:02:01,948]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:02:04,436]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:02:08,475]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:02:18,586]\u001b[0m Trial 714 finished with value: 3.9361618058153147 and parameters: {'n_hidden': 4, 'learning_rate': 0.009809871621391015, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20535094854725428, 'dropout_rate_Layer_2': 0.2246895441240244, 'dropout_rate_Layer_3': 0.04778319609814824, 'dropout_rate_Layer_4': 0.3437003987141295, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.4185175118336404e-05, 'l1_Layer_2': 2.2306350316782384e-05, 'l1_Layer_3': 0.000223937797312857, 'l1_Layer_4': 0.000174431856293719, 'n_units_Layer_1': 60, 'n_units_Layer_2': 100, 'n_units_Layer_3': 80, 'n_units_Layer_4': 120}. Best is trial 681 with value: 3.537419642771645.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.94 | sMAPE for Validation Set is: 7.73% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.19 | sMAPE for Test Set is: 8.88% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:02:19,449]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:02:25,964]\u001b[0m Trial 729 finished with value: 3.762297146102791 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017239786016297585, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04109594860104531, 'dropout_rate_Layer_2': 0.05730832503950691, 'dropout_rate_Layer_3': 0.09005269904792676, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020213841950506072, 'l1_Layer_2': 0.00010766815883928061, 'l1_Layer_3': 1.5317431333015884e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 300, 'n_units_Layer_3': 300}. Best is trial 681 with value: 3.537419642771645.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.76 | sMAPE for Validation Set is: 7.58% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.80 | sMAPE for Test Set is: 9.96% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:02:29,403]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:02:33,196]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:02:33,933]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:02:34,045]\u001b[0m Trial 728 finished with value: 3.730121362950771 and parameters: {'n_hidden': 3, 'learning_rate': 0.03703246489146999, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06360987738125332, 'dropout_rate_Layer_2': 0.23098699035303824, 'dropout_rate_Layer_3': 0.22932630362552198, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.603652586220152e-05, 'l1_Layer_2': 1.9247387498609738e-05, 'l1_Layer_3': 3.819436214233836e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 80, 'n_units_Layer_3': 155}. Best is trial 681 with value: 3.537419642771645.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.73 | sMAPE for Validation Set is: 7.48% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.56 | sMAPE for Test Set is: 9.35% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:02:39,925]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:02:43,094]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:02:49,671]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:02:50,379]\u001b[0m Trial 731 finished with value: 3.753954505725057 and parameters: {'n_hidden': 3, 'learning_rate': 0.037338503786873936, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05929270968536164, 'dropout_rate_Layer_2': 0.19556001719653374, 'dropout_rate_Layer_3': 0.23010707274943726, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.596679865163369e-05, 'l1_Layer_2': 2.0389527092778316e-05, 'l1_Layer_3': 4.0892869499638875e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 80, 'n_units_Layer_3': 150}. Best is trial 681 with value: 3.537419642771645.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 7.49% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.52 | sMAPE for Test Set is: 9.49% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:02:50,604]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:02:52,482]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:02:57,798]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:03:14,232]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:03:20,429]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:03:31,887]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:03:37,994]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:03:48,112]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:03:50,980]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:03:51,510]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:03:56,752]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:03:57,164]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:04:02,219]\u001b[0m Trial 747 finished with value: 3.6505876529594157 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009972832683364887, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03916621129364395, 'dropout_rate_Layer_2': 0.05558246914317401, 'dropout_rate_Layer_3': 0.08227732736873404, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00028745983116925435, 'l1_Layer_2': 7.112905221580825e-05, 'l1_Layer_3': 1.1977229724210561e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 275, 'n_units_Layer_3': 275}. Best is trial 681 with value: 3.537419642771645.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.65 | sMAPE for Validation Set is: 7.32% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.44 | sMAPE for Test Set is: 9.09% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:04:05,200]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:04:05,837]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:04:10,316]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:04:13,925]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:04:14,273]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:04:16,932]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:04:19,389]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:04:24,588]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:04:26,505]\u001b[0m Trial 751 finished with value: 3.6946103347213577 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012044443551176085, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05566132337147167, 'dropout_rate_Layer_2': 0.055371252544326996, 'dropout_rate_Layer_3': 0.06867332185447486, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022423087644121305, 'l1_Layer_2': 7.358251068912977e-05, 'l1_Layer_3': 1.0004547184967837e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 275, 'n_units_Layer_3': 275}. Best is trial 681 with value: 3.537419642771645.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.69 | sMAPE for Validation Set is: 7.42% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.58 | sMAPE for Test Set is: 9.36% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:04:26,605]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:04:27,671]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:04:35,340]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:04:41,945]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:04:46,566]\u001b[0m Trial 759 finished with value: 3.621184656793179 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008062857639319325, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03010576113978055, 'dropout_rate_Layer_2': 0.03954734559600044, 'dropout_rate_Layer_3': 0.11064850092243456, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002956046290641889, 'l1_Layer_2': 6.885434732136248e-05, 'l1_Layer_3': 1.4596091877544317e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 285, 'n_units_Layer_3': 300}. Best is trial 681 with value: 3.537419642771645.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.62 | sMAPE for Validation Set is: 7.26% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.41 | sMAPE for Test Set is: 9.08% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:04:58,125]\u001b[0m Trial 763 finished with value: 3.6477824246728 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008735404856494368, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.027516462693126742, 'dropout_rate_Layer_2': 0.05057141627479394, 'dropout_rate_Layer_3': 0.07289874413941293, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003053922062711329, 'l1_Layer_2': 0.0001292477621910346, 'l1_Layer_3': 1.1824244661629412e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 300, 'n_units_Layer_3': 285}. Best is trial 681 with value: 3.537419642771645.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.65 | sMAPE for Validation Set is: 7.33% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.50 | sMAPE for Test Set is: 9.22% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:05:02,193]\u001b[0m Trial 766 finished with value: 3.7348636852029977 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008865091307781395, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02902461024415026, 'dropout_rate_Layer_2': 0.052897075850854056, 'dropout_rate_Layer_3': 0.07194974949772676, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015477870936341095, 'l1_Layer_2': 7.015936131197742e-05, 'l1_Layer_3': 1.2130625864266656e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 300, 'n_units_Layer_3': 285}. Best is trial 681 with value: 3.537419642771645.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.73 | sMAPE for Validation Set is: 7.53% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.67 | sMAPE for Test Set is: 9.67% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:05:06,414]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:05:08,965]\u001b[0m Trial 767 finished with value: 3.619306592106597 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008923838201762614, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.023687259179851785, 'dropout_rate_Layer_2': 0.03997614213880026, 'dropout_rate_Layer_3': 0.10464510273372377, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00031823495033665857, 'l1_Layer_2': 6.989763959617608e-05, 'l1_Layer_3': 1.819257903752247e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 300, 'n_units_Layer_3': 285}. Best is trial 681 with value: 3.537419642771645.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.62 | sMAPE for Validation Set is: 7.29% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.44 | sMAPE for Test Set is: 9.13% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:05:14,505]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:05:23,952]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:05:24,414]\u001b[0m Trial 768 finished with value: 3.6358509165303894 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008679157947384329, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.023679496079919003, 'dropout_rate_Layer_2': 0.0446056857169877, 'dropout_rate_Layer_3': 0.11214307265933507, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003246786204211535, 'l1_Layer_2': 0.00012932297463247403, 'l1_Layer_3': 1.851692260384575e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 295, 'n_units_Layer_3': 285}. Best is trial 681 with value: 3.537419642771645.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.64 | sMAPE for Validation Set is: 7.27% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.46 | sMAPE for Test Set is: 9.12% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:05:25,040]\u001b[0m Trial 771 finished with value: 3.6616081830243155 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007836340786780646, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.026159544905863894, 'dropout_rate_Layer_2': 0.03821233983962569, 'dropout_rate_Layer_3': 0.11124761862923917, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00032892137866038845, 'l1_Layer_2': 0.00012297617467631487, 'l1_Layer_3': 1.9008055113888806e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 300, 'n_units_Layer_3': 295}. Best is trial 681 with value: 3.537419642771645.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.66 | sMAPE for Validation Set is: 7.37% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.70 | sMAPE for Test Set is: 9.75% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:05:30,422]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:05:32,859]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:05:35,870]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:05:38,267]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:05:39,968]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:05:43,429]\u001b[0m Trial 772 finished with value: 3.6381711829485623 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007729103389752278, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.023075642368103177, 'dropout_rate_Layer_2': 0.03824352130831095, 'dropout_rate_Layer_3': 0.11263589812730097, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002980581466922354, 'l1_Layer_2': 0.00013632562559937137, 'l1_Layer_3': 1.8553533728309175e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 295, 'n_units_Layer_3': 295}. Best is trial 681 with value: 3.537419642771645.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.64 | sMAPE for Validation Set is: 7.27% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.31 | sMAPE for Test Set is: 8.81% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:05:45,097]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:05:46,953]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:06:05,204]\u001b[0m Trial 782 finished with value: 3.6821159933488015 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009613660328508011, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.027829916134142773, 'dropout_rate_Layer_2': 0.07849817544959667, 'dropout_rate_Layer_3': 0.12512468917908176, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002877104407531054, 'l1_Layer_2': 0.00026857995406999636, 'l1_Layer_3': 1.4653781525192208e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 300, 'n_units_Layer_3': 290}. Best is trial 681 with value: 3.537419642771645.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.68 | sMAPE for Validation Set is: 7.35% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.46 | sMAPE for Test Set is: 9.07% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:06:11,860]\u001b[0m Trial 779 finished with value: 3.6089350347323577 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009342819100963193, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.035955698174880854, 'dropout_rate_Layer_2': 0.08123254821945415, 'dropout_rate_Layer_3': 0.10837239056547765, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003936104143291353, 'l1_Layer_2': 0.00010637164920107635, 'l1_Layer_3': 1.520752403866294e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 300, 'n_units_Layer_3': 295}. Best is trial 681 with value: 3.537419642771645.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.61 | sMAPE for Validation Set is: 7.23% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.31 | sMAPE for Test Set is: 8.81% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:06:12,498]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:06:18,801]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:06:18,920]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:06:23,149]\u001b[0m Trial 781 finished with value: 3.8206290492443173 and parameters: {'n_hidden': 3, 'learning_rate': 0.026417244185788943, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08130153655516868, 'dropout_rate_Layer_2': 0.27657680565199466, 'dropout_rate_Layer_3': 0.2113408830434243, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3564474357581836e-05, 'l1_Layer_2': 7.324643006363153e-05, 'l1_Layer_3': 1.6030904716538482e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 70, 'n_units_Layer_3': 190}. Best is trial 681 with value: 3.537419642771645.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.82 | sMAPE for Validation Set is: 7.61% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.23 | sMAPE for Test Set is: 10.50% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:06:24,257]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:06:34,175]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:06:42,189]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:06:43,108]\u001b[0m Trial 790 finished with value: 3.627832762054003 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008618486790853977, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.020910525789656024, 'dropout_rate_Layer_2': 0.06238066391084621, 'dropout_rate_Layer_3': 0.11128700441534348, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002560731878128158, 'l1_Layer_2': 0.00010516167623950953, 'l1_Layer_3': 1.610288400384977e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 290, 'n_units_Layer_3': 290}. Best is trial 681 with value: 3.537419642771645.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.63 | sMAPE for Validation Set is: 7.27% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.48 | sMAPE for Test Set is: 9.18% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:06:51,951]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:06:53,036]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:06:54,163]\u001b[0m Trial 786 finished with value: 3.617353730343796 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007753452892260196, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03571304608304722, 'dropout_rate_Layer_2': 0.09288764123094315, 'dropout_rate_Layer_3': 0.1234561690754832, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00047394799708727826, 'l1_Layer_2': 0.00014861008953834161, 'l1_Layer_3': 2.1058301280177266e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 300, 'n_units_Layer_3': 295}. Best is trial 681 with value: 3.537419642771645.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.62 | sMAPE for Validation Set is: 7.28% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.42 | sMAPE for Test Set is: 9.14% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:07:12,762]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:07:21,636]\u001b[0m Trial 795 finished with value: 3.5323729591973447 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008084861698796628, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02255738462437215, 'dropout_rate_Layer_2': 0.0877590439130674, 'dropout_rate_Layer_3': 0.11289532706405829, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003870895378681537, 'l1_Layer_2': 0.00013612244865479005, 'l1_Layer_3': 2.0723930731742587e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 290, 'n_units_Layer_3': 300}. Best is trial 795 with value: 3.5323729591973447.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.53 | sMAPE for Validation Set is: 7.09% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.44 | sMAPE for Test Set is: 9.10% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:07:25,461]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:07:39,609]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:07:43,919]\u001b[0m Trial 797 finished with value: 3.6023560074676575 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007908751165381139, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02141644975808206, 'dropout_rate_Layer_2': 0.09176015388271212, 'dropout_rate_Layer_3': 0.12443590180341627, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000460552647334368, 'l1_Layer_2': 0.00016398382984592118, 'l1_Layer_3': 2.175339621221012e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 290, 'n_units_Layer_3': 300}. Best is trial 795 with value: 3.5323729591973447.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.60 | sMAPE for Validation Set is: 7.22% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.32 | sMAPE for Test Set is: 8.82% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:07:58,862]\u001b[0m Trial 794 finished with value: 4.099403629258581 and parameters: {'n_hidden': 4, 'learning_rate': 0.006632613885822744, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26268198593385733, 'dropout_rate_Layer_2': 0.02363911414310553, 'dropout_rate_Layer_3': 0.39142961843106205, 'dropout_rate_Layer_4': 0.3857482195355231, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.683353554249357e-05, 'l1_Layer_2': 1.1952382509771182e-05, 'l1_Layer_3': 1.6511418874597827e-05, 'l1_Layer_4': 2.4518684156466073e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 55, 'n_units_Layer_3': 240, 'n_units_Layer_4': 185}. Best is trial 795 with value: 3.5323729591973447.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.10 | sMAPE for Validation Set is: 8.12% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.40 | sMAPE for Test Set is: 9.13% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:08:04,061]\u001b[0m Trial 800 finished with value: 3.607210770763276 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007814698130951621, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02250360114788155, 'dropout_rate_Layer_2': 0.08305902263660975, 'dropout_rate_Layer_3': 0.10758726153409043, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00037621743339017643, 'l1_Layer_2': 0.00013780073620557156, 'l1_Layer_3': 2.289373918712215e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 295, 'n_units_Layer_3': 300}. Best is trial 795 with value: 3.5323729591973447.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.61 | sMAPE for Validation Set is: 7.24% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.34 | sMAPE for Test Set is: 8.95% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:08:09,731]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:08:14,948]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:08:28,232]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:08:28,562]\u001b[0m Trial 802 finished with value: 3.6802232554682583 and parameters: {'n_hidden': 3, 'learning_rate': 0.013046278585886242, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.020684791914064186, 'dropout_rate_Layer_2': 0.30058063706495297, 'dropout_rate_Layer_3': 0.3065702208612398, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.160357382700143e-05, 'l1_Layer_2': 0.0004903993691219746, 'l1_Layer_3': 2.4409357591523198e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 90, 'n_units_Layer_3': 165}. Best is trial 795 with value: 3.5323729591973447.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.68 | sMAPE for Validation Set is: 7.37% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.04 | sMAPE for Test Set is: 8.58% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:08:29,798]\u001b[0m Trial 801 finished with value: 3.8077531291119886 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009409027938831066, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.015320026197344431, 'dropout_rate_Layer_2': 0.0072669970287257725, 'dropout_rate_Layer_3': 0.1872721419897818, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006214990483171651, 'l1_Layer_2': 0.000688595888775496, 'l1_Layer_3': 3.894215624854393e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 110, 'n_units_Layer_3': 165}. Best is trial 795 with value: 3.5323729591973447.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.81 | sMAPE for Validation Set is: 7.55% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.83 | sMAPE for Test Set is: 9.62% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:08:34,111]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:08:35,886]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:08:41,523]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:08:44,370]\u001b[0m Trial 796 finished with value: 3.973278937526255 and parameters: {'n_hidden': 4, 'learning_rate': 0.006847716246285209, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2632398522035608, 'dropout_rate_Layer_2': 0.25158085149850773, 'dropout_rate_Layer_3': 0.3725505847821608, 'dropout_rate_Layer_4': 0.3867465729124229, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.606209138185758e-05, 'l1_Layer_2': 1.2820322328321956e-05, 'l1_Layer_3': 1.4311554266554353e-05, 'l1_Layer_4': 0.0002463452240229815, 'n_units_Layer_1': 85, 'n_units_Layer_2': 55, 'n_units_Layer_3': 215, 'n_units_Layer_4': 185}. Best is trial 795 with value: 3.5323729591973447.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.97 | sMAPE for Validation Set is: 7.90% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.30 | sMAPE for Test Set is: 8.87% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:08:50,212]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:08:53,227]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:08:58,185]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:09:02,202]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:09:06,380]\u001b[0m Trial 811 finished with value: 3.631121801948193 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008616871402154246, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03245506005571298, 'dropout_rate_Layer_2': 0.10154400582144357, 'dropout_rate_Layer_3': 0.10342726618665417, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00038184613220447336, 'l1_Layer_2': 0.00011445647435549982, 'l1_Layer_3': 1.62602162034505e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 290, 'n_units_Layer_3': 290}. Best is trial 795 with value: 3.5323729591973447.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.63 | sMAPE for Validation Set is: 7.27% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.34 | sMAPE for Test Set is: 8.89% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:09:13,690]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:09:20,722]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:09:27,104]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:09:27,436]\u001b[0m Trial 815 finished with value: 3.6349402451382002 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008275871202750093, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03334837775044423, 'dropout_rate_Layer_2': 0.08032467664235529, 'dropout_rate_Layer_3': 0.10420440251126785, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005027811287192753, 'l1_Layer_2': 0.00022434947728089717, 'l1_Layer_3': 1.6113882593189942e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 290, 'n_units_Layer_3': 290}. Best is trial 795 with value: 3.5323729591973447.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.63 | sMAPE for Validation Set is: 7.30% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.46 | sMAPE for Test Set is: 9.07% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:09:27,749]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:09:33,895]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:09:37,162]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:09:39,740]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:09:44,229]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:09:46,490]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:09:49,037]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:09:51,872]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:09:53,993]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:09:58,123]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:10:00,355]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:10:05,964]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:10:07,946]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:10:11,727]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:10:32,114]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:11:38,520]\u001b[0m Trial 836 finished with value: 3.642090255952193 and parameters: {'n_hidden': 3, 'learning_rate': 0.006565717191399754, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0180339883877825, 'dropout_rate_Layer_2': 0.2997053962166416, 'dropout_rate_Layer_3': 0.2933059002372141, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.842343642310712e-05, 'l1_Layer_2': 0.0007746550191879465, 'l1_Layer_3': 2.6589487588802852e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 145, 'n_units_Layer_3': 170}. Best is trial 795 with value: 3.5323729591973447.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.64 | sMAPE for Validation Set is: 7.23% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.28 | sMAPE for Test Set is: 8.80% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:11:42,209]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:11:46,269]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:12:04,179]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:12:21,887]\u001b[0m Trial 835 finished with value: 3.9796977429771783 and parameters: {'n_hidden': 4, 'learning_rate': 0.006689649046841066, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25492882707649817, 'dropout_rate_Layer_2': 0.2749301345036141, 'dropout_rate_Layer_3': 0.35175634091260277, 'dropout_rate_Layer_4': 0.3785880126616476, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 7.07894510369977e-05, 'l1_Layer_2': 2.1058756126568774e-05, 'l1_Layer_3': 1.880167887028924e-05, 'l1_Layer_4': 0.0002628681159791016, 'n_units_Layer_1': 95, 'n_units_Layer_2': 55, 'n_units_Layer_3': 200, 'n_units_Layer_4': 180}. Best is trial 795 with value: 3.5323729591973447.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.98 | sMAPE for Validation Set is: 7.90% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.33 | sMAPE for Test Set is: 9.26% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:12:27,883]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:12:33,859]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:12:39,003]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:12:41,790]\u001b[0m Trial 828 finished with value: 4.070150327771292 and parameters: {'n_hidden': 4, 'learning_rate': 0.006548380172206558, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26964038912316607, 'dropout_rate_Layer_2': 0.277746090650957, 'dropout_rate_Layer_3': 0.3537676372208334, 'dropout_rate_Layer_4': 0.37381706574939094, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 7.633973300437806e-05, 'l1_Layer_2': 2.1405475246707465e-05, 'l1_Layer_3': 1.829275624046441e-05, 'l1_Layer_4': 0.00013772768076756965, 'n_units_Layer_1': 190, 'n_units_Layer_2': 55, 'n_units_Layer_3': 200, 'n_units_Layer_4': 180}. Best is trial 795 with value: 3.5323729591973447.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.07 | sMAPE for Validation Set is: 8.00% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.76 | sMAPE for Test Set is: 9.60% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:12:43,219]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:12:49,545]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:12:54,360]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:13:19,420]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:13:24,704]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:13:26,223]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:13:32,602]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:13:36,060]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:13:41,911]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:13:45,188]\u001b[0m Trial 841 finished with value: 3.5448364804354906 and parameters: {'n_hidden': 3, 'learning_rate': 0.00614059226733708, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0047594583376896135, 'dropout_rate_Layer_2': 0.27015015745815557, 'dropout_rate_Layer_3': 0.2859257233641814, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014816621815128064, 'l1_Layer_2': 0.0002694670145907773, 'l1_Layer_3': 0.0009190315974948192, 'n_units_Layer_1': 275, 'n_units_Layer_2': 55, 'n_units_Layer_3': 210}. Best is trial 795 with value: 3.5323729591973447.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.54 | sMAPE for Validation Set is: 7.05% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 3.90 | sMAPE for Test Set is: 8.19% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:13:48,987]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:13:49,363]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:13:50,039]\u001b[0m Trial 851 finished with value: 3.563409222126895 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013474176552911979, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02907972791150015, 'dropout_rate_Layer_2': 0.0710347197679121, 'dropout_rate_Layer_3': 0.05419589680314357, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00028490802536366083, 'l1_Layer_2': 0.00014357855363915606, 'l1_Layer_3': 1.568909365645952e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 285, 'n_units_Layer_3': 295}. Best is trial 795 with value: 3.5323729591973447.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.56 | sMAPE for Validation Set is: 7.16% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.34 | sMAPE for Test Set is: 8.91% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:13:56,936]\u001b[0m Trial 845 finished with value: 3.752510863291706 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035314136646324846, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12795877939748734, 'dropout_rate_Layer_2': 0.2598744241279996, 'dropout_rate_Layer_3': 0.3353675588191945, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0020872764993506406, 'l1_Layer_2': 3.5346812866519196e-05, 'l1_Layer_3': 0.0006181253442907291, 'n_units_Layer_1': 270, 'n_units_Layer_2': 210, 'n_units_Layer_3': 170}. Best is trial 795 with value: 3.5323729591973447.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 7.51% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.27 | sMAPE for Test Set is: 9.09% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:14:00,827]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:14:06,758]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:14:07,591]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:14:11,184]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:14:13,789]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:14:17,606]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:14:21,834]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:14:34,371]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:14:37,452]\u001b[0m Trial 857 finished with value: 3.552159664954997 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007086506876067086, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00962468395830881, 'dropout_rate_Layer_2': 0.08195595173459858, 'dropout_rate_Layer_3': 0.052187671527251664, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003183367774952001, 'l1_Layer_2': 0.00018461576054521685, 'l1_Layer_3': 1.675918861117621e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 280, 'n_units_Layer_3': 290}. Best is trial 795 with value: 3.5323729591973447.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.55 | sMAPE for Validation Set is: 7.16% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.23 | sMAPE for Test Set is: 8.75% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:14:41,790]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:14:45,158]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:14:47,911]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:14:49,837]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:14:59,522]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:15:05,478]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:15:28,366]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:15:28,603]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:15:48,295]\u001b[0m Trial 876 finished with value: 3.587212071685151 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009192502541999465, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.011294814669130248, 'dropout_rate_Layer_2': 0.08441626848451161, 'dropout_rate_Layer_3': 0.06034205676185465, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00027688704919478786, 'l1_Layer_2': 8.333093069746775e-05, 'l1_Layer_3': 1.007517763827479e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 285, 'n_units_Layer_3': 295}. Best is trial 795 with value: 3.5323729591973447.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.59 | sMAPE for Validation Set is: 7.18% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.43 | sMAPE for Test Set is: 9.05% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:15:51,830]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:15:54,217]\u001b[0m Trial 875 finished with value: 3.5801152460002377 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016399889793090824, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008777309818562902, 'dropout_rate_Layer_2': 0.08300816614535711, 'dropout_rate_Layer_3': 0.051376480095334694, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002679206637361193, 'l1_Layer_2': 0.00013638025023786997, 'l1_Layer_3': 1.1616058416127138e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 270, 'n_units_Layer_3': 295}. Best is trial 795 with value: 3.5323729591973447.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.58 | sMAPE for Validation Set is: 7.20% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.30 | sMAPE for Test Set is: 8.84% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:16:07,048]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:16:09,340]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:16:13,730]\u001b[0m Trial 878 finished with value: 3.618338188219337 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007770578745292747, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.009279274021357812, 'dropout_rate_Layer_2': 0.09143371283161536, 'dropout_rate_Layer_3': 0.05984060737603968, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003596325063487389, 'l1_Layer_2': 8.107358710061459e-05, 'l1_Layer_3': 1.1594727145372488e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 285, 'n_units_Layer_3': 285}. Best is trial 795 with value: 3.5323729591973447.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.62 | sMAPE for Validation Set is: 7.28% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.51 | sMAPE for Test Set is: 9.19% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:16:31,119]\u001b[0m Trial 880 finished with value: 3.6059449699604307 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015858756516019896, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008116550927188715, 'dropout_rate_Layer_2': 0.08687785551097522, 'dropout_rate_Layer_3': 0.0494764005740965, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004342372704133838, 'l1_Layer_2': 0.00018926100652088784, 'l1_Layer_3': 1.1492929443426834e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 270, 'n_units_Layer_3': 300}. Best is trial 795 with value: 3.5323729591973447.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.61 | sMAPE for Validation Set is: 7.25% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.39 | sMAPE for Test Set is: 8.98% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:16:31,772]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:17:09,750]\u001b[0m Trial 863 finished with value: 3.975319594786376 and parameters: {'n_hidden': 4, 'learning_rate': 0.0053250337664746935, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28833226919861876, 'dropout_rate_Layer_2': 0.2928320442695393, 'dropout_rate_Layer_3': 0.3469882894307848, 'dropout_rate_Layer_4': 0.32395894116882085, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 9.648356059554582e-05, 'l1_Layer_2': 1.4418561885354513e-05, 'l1_Layer_3': 2.7688251040032864e-05, 'l1_Layer_4': 0.00013276921698543575, 'n_units_Layer_1': 195, 'n_units_Layer_2': 60, 'n_units_Layer_3': 185, 'n_units_Layer_4': 165}. Best is trial 795 with value: 3.5323729591973447.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.98 | sMAPE for Validation Set is: 7.92% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.49 | sMAPE for Test Set is: 9.33% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:17:13,653]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:17:17,677]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:17:19,387]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:17:46,966]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:17:50,195]\u001b[0m Trial 887 finished with value: 3.6063503067275886 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006016285444013354, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.002630692604543015, 'dropout_rate_Layer_2': 0.0914099876274268, 'dropout_rate_Layer_3': 0.05363781561807936, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005814996806827644, 'l1_Layer_2': 0.00019151009119318946, 'l1_Layer_3': 1.0425130944950522e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 270, 'n_units_Layer_3': 285}. Best is trial 795 with value: 3.5323729591973447.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.61 | sMAPE for Validation Set is: 7.26% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.34 | sMAPE for Test Set is: 8.94% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:17:59,346]\u001b[0m Trial 888 finished with value: 3.4877348039669704 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005965016748107583, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.010728266872627141, 'dropout_rate_Layer_2': 0.08428245396760511, 'dropout_rate_Layer_3': 0.05072435004519546, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005595213032843632, 'l1_Layer_2': 0.00017397044525460073, 'l1_Layer_3': 1.0024883406055226e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 275, 'n_units_Layer_3': 270}. Best is trial 888 with value: 3.4877348039669704.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.49 | sMAPE for Validation Set is: 7.02% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.29 | sMAPE for Test Set is: 8.84% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:18:03,444]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:18:19,578]\u001b[0m Trial 890 finished with value: 3.5952083087100664 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006648178866243137, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00773838591633878, 'dropout_rate_Layer_2': 0.08677025685508172, 'dropout_rate_Layer_3': 0.059336843425797335, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005943657906531176, 'l1_Layer_2': 0.00024375519889577218, 'l1_Layer_3': 1.0252463327141022e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 270, 'n_units_Layer_3': 285}. Best is trial 888 with value: 3.4877348039669704.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.60 | sMAPE for Validation Set is: 7.21% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.52 | sMAPE for Test Set is: 9.26% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:18:22,601]\u001b[0m Trial 889 finished with value: 3.6495483343650066 and parameters: {'n_hidden': 3, 'learning_rate': 0.0044674740122837495, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.021865674145422665, 'dropout_rate_Layer_2': 0.2812760356798701, 'dropout_rate_Layer_3': 0.2642770053005573, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005333225757561843, 'l1_Layer_2': 0.0009338287602252187, 'l1_Layer_3': 1.3020234281257576e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 70, 'n_units_Layer_3': 190}. Best is trial 888 with value: 3.4877348039669704.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.65 | sMAPE for Validation Set is: 7.27% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 3.89 | sMAPE for Test Set is: 8.26% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:18:25,572]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:18:28,170]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:18:48,306]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:19:00,021]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:19:04,917]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:19:05,434]\u001b[0m Trial 895 finished with value: 3.611181412826482 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005725054975369333, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.004238668742988803, 'dropout_rate_Layer_2': 0.10576516917996515, 'dropout_rate_Layer_3': 0.05016588233596109, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006951763257711199, 'l1_Layer_2': 0.0002634431716702353, 'l1_Layer_3': 1.0038611683086697e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 270, 'n_units_Layer_3': 275}. Best is trial 888 with value: 3.4877348039669704.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.61 | sMAPE for Validation Set is: 7.25% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.09 | sMAPE for Test Set is: 8.46% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:19:14,046]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:19:14,221]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:19:19,906]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:19:23,905]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:19:27,964]\u001b[0m Trial 897 finished with value: 3.5392726171838063 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005765255751957507, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0031852585153912087, 'dropout_rate_Layer_2': 0.0833238527228604, 'dropout_rate_Layer_3': 0.05075632896801127, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005391419780065044, 'l1_Layer_2': 0.00023158224981283348, 'l1_Layer_3': 1.0093847176095727e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 265, 'n_units_Layer_3': 275}. Best is trial 888 with value: 3.4877348039669704.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.54 | sMAPE for Validation Set is: 7.14% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.12 | sMAPE for Test Set is: 8.50% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:19:29,375]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:19:41,670]\u001b[0m Trial 883 finished with value: 3.9310926971400026 and parameters: {'n_hidden': 4, 'learning_rate': 0.009490638870471848, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25180321918584375, 'dropout_rate_Layer_2': 0.28352537759303614, 'dropout_rate_Layer_3': 0.36979125058084317, 'dropout_rate_Layer_4': 0.08649713165016365, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 6.002060600317569e-05, 'l1_Layer_2': 1.7536049550641445e-05, 'l1_Layer_3': 2.7047706633097275e-05, 'l1_Layer_4': 0.0005300905306126594, 'n_units_Layer_1': 190, 'n_units_Layer_2': 65, 'n_units_Layer_3': 220, 'n_units_Layer_4': 155}. Best is trial 888 with value: 3.4877348039669704.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.93 | sMAPE for Validation Set is: 7.75% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.19 | sMAPE for Test Set is: 8.64% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:19:48,358]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:19:52,238]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:19:56,452]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:20:03,382]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:20:10,491]\u001b[0m Trial 905 finished with value: 3.679936501318295 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036271532670842277, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02359433350101673, 'dropout_rate_Layer_2': 0.2831429864220874, 'dropout_rate_Layer_3': 0.2919463557872987, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007300710822608327, 'l1_Layer_2': 0.0022106842702437402, 'l1_Layer_3': 1.224698158759064e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 165, 'n_units_Layer_3': 190}. Best is trial 888 with value: 3.4877348039669704.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.68 | sMAPE for Validation Set is: 7.30% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.20 | sMAPE for Test Set is: 8.64% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:20:16,549]\u001b[0m Trial 903 finished with value: 3.5309851081233674 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005979165290716835, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.010998740074814894, 'dropout_rate_Layer_2': 0.08485084693904252, 'dropout_rate_Layer_3': 0.05625801289547365, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007554359721865756, 'l1_Layer_2': 0.0002526570059277141, 'l1_Layer_3': 1.146910869754494e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 270, 'n_units_Layer_3': 265}. Best is trial 888 with value: 3.4877348039669704.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.53 | sMAPE for Validation Set is: 7.08% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.22 | sMAPE for Test Set is: 8.69% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:20:17,175]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:20:21,738]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:20:22,534]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:20:30,966]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:20:37,237]\u001b[0m Trial 911 finished with value: 3.600567998308931 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006140975406885109, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.009998388047635675, 'dropout_rate_Layer_2': 0.0891673333272174, 'dropout_rate_Layer_3': 0.06069491652539555, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005953737397661117, 'l1_Layer_2': 0.00021864773968489838, 'l1_Layer_3': 1.1861385981267651e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 260, 'n_units_Layer_3': 265}. Best is trial 888 with value: 3.4877348039669704.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.60 | sMAPE for Validation Set is: 7.24% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.33 | sMAPE for Test Set is: 8.89% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:20:50,608]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:20:53,084]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:20:55,008]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:20:59,947]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:21:00,291]\u001b[0m Trial 915 finished with value: 3.483217609394862 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006494715148147764, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.005147987116802529, 'dropout_rate_Layer_2': 0.09703677744754957, 'dropout_rate_Layer_3': 0.04236216871523521, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005959270673519047, 'l1_Layer_2': 0.0001914878031632199, 'l1_Layer_3': 1.2263937097306219e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 270, 'n_units_Layer_3': 275}. Best is trial 915 with value: 3.483217609394862.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.48 | sMAPE for Validation Set is: 6.99% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.12 | sMAPE for Test Set is: 8.52% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:21:08,041]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:21:10,572]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:21:10,909]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:21:17,518]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:21:19,808]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:21:24,946]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:21:28,996]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:21:31,329]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:21:33,747]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:21:38,385]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:21:40,169]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:21:43,354]\u001b[0m Trial 926 finished with value: 3.611146687218153 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006721137704356989, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.009221162584383498, 'dropout_rate_Layer_2': 0.09706726136430927, 'dropout_rate_Layer_3': 0.04096032708684601, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005430438182171324, 'l1_Layer_2': 0.00018506839847767873, 'l1_Layer_3': 1.3909687696697236e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 255, 'n_units_Layer_3': 265}. Best is trial 915 with value: 3.483217609394862.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.61 | sMAPE for Validation Set is: 7.26% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.72 | sMAPE for Test Set is: 9.74% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:21:47,165]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:21:49,284]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:21:52,208]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:22:03,434]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:22:05,300]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:22:10,566]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:22:12,810]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:22:16,489]\u001b[0m Trial 935 finished with value: 3.601040590666304 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006110370690408576, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.020096348755272164, 'dropout_rate_Layer_2': 0.08231611721480332, 'dropout_rate_Layer_3': 0.049300840575690084, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006214715687881873, 'l1_Layer_2': 0.0002230870689968436, 'l1_Layer_3': 1.4664878232838053e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 270, 'n_units_Layer_3': 285}. Best is trial 915 with value: 3.483217609394862.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:22:16,621]\u001b[0m Trial 929 finished with value: 3.535502355538267 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005445829947117637, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00896848498189307, 'dropout_rate_Layer_2': 0.09598851340891293, 'dropout_rate_Layer_3': 0.06328924558818744, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000635956146599763, 'l1_Layer_2': 0.00017347148433471314, 'l1_Layer_3': 1.176469196752e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 275, 'n_units_Layer_3': 285}. Best is trial 915 with value: 3.483217609394862.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.60 | sMAPE for Validation Set is: 7.21% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.37 | sMAPE for Test Set is: 8.89% | rMAE for Test Set is: 0.68\n",
      "MAE for Validation Set is: 3.54 | sMAPE for Validation Set is: 7.12% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.20 | sMAPE for Test Set is: 8.73% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:22:23,246]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:22:26,502]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:22:29,321]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:22:29,916]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:22:30,326]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:22:38,707]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:22:41,333]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:22:41,980]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:22:46,622]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:22:50,607]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:22:57,366]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:23:20,040]\u001b[0m Trial 952 finished with value: 3.587345781521646 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007042570793795559, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.013145406332922022, 'dropout_rate_Layer_2': 0.09202487435410804, 'dropout_rate_Layer_3': 0.060844520124505676, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008229202255199223, 'l1_Layer_2': 0.0002449013147327109, 'l1_Layer_3': 1.3532991820233824e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 275, 'n_units_Layer_3': 260}. Best is trial 915 with value: 3.483217609394862.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.59 | sMAPE for Validation Set is: 7.20% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.35 | sMAPE for Test Set is: 8.88% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:23:24,350]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:23:30,113]\u001b[0m Trial 950 finished with value: 3.551183840806702 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005953467305517661, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00839336887058321, 'dropout_rate_Layer_2': 0.10695646731088873, 'dropout_rate_Layer_3': 0.0391183530947533, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007838092933204322, 'l1_Layer_2': 0.00028812035125192457, 'l1_Layer_3': 1.164306778453201e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 275, 'n_units_Layer_3': 280}. Best is trial 915 with value: 3.483217609394862.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.55 | sMAPE for Validation Set is: 7.15% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.22 | sMAPE for Test Set is: 8.67% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:23:35,172]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:23:37,301]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:23:41,528]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:23:48,812]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:24:03,159]\u001b[0m Trial 955 finished with value: 3.5627269991904886 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006494992815366913, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 7.141524250624514e-05, 'dropout_rate_Layer_2': 0.08511987503163554, 'dropout_rate_Layer_3': 0.03719570662980656, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008667757073793224, 'l1_Layer_2': 0.00016673760619342028, 'l1_Layer_3': 1.379293668903711e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 275, 'n_units_Layer_3': 260}. Best is trial 915 with value: 3.483217609394862.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.56 | sMAPE for Validation Set is: 7.15% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.36 | sMAPE for Test Set is: 8.81% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:24:03,809]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:24:37,584]\u001b[0m Trial 963 finished with value: 3.4994563117195994 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007080008531642647, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01894577852992868, 'dropout_rate_Layer_2': 0.10162606449472236, 'dropout_rate_Layer_3': 0.03810774681509034, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012304070642597548, 'l1_Layer_2': 0.00016312005607522598, 'l1_Layer_3': 1.5805303453613273e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 275, 'n_units_Layer_3': 255}. Best is trial 915 with value: 3.483217609394862.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.50 | sMAPE for Validation Set is: 7.03% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.26 | sMAPE for Test Set is: 8.79% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:24:40,831]\u001b[0m Trial 964 finished with value: 3.573054132816734 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007243409168445514, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01764911715052335, 'dropout_rate_Layer_2': 0.10160493510967528, 'dropout_rate_Layer_3': 0.03752586984822322, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010848002316582721, 'l1_Layer_2': 0.00032743700050924795, 'l1_Layer_3': 1.6643080805201458e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 275, 'n_units_Layer_3': 265}. Best is trial 915 with value: 3.483217609394862.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.57 | sMAPE for Validation Set is: 7.15% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.26 | sMAPE for Test Set is: 8.77% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:24:43,876]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:24:44,191]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:24:50,451]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:25:05,308]\u001b[0m Trial 968 finished with value: 3.8151127737993638 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030872280002718234, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21392587932429097, 'dropout_rate_Layer_2': 0.3331448326517913, 'dropout_rate_Layer_3': 0.27672711409272727, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00047971577185649264, 'l1_Layer_2': 0.000726753416545661, 'l1_Layer_3': 1.8522023872404697e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 60, 'n_units_Layer_3': 185}. Best is trial 915 with value: 3.483217609394862.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.82 | sMAPE for Validation Set is: 7.61% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.07 | sMAPE for Test Set is: 8.56% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:25:05,896]\u001b[0m Trial 960 finished with value: 3.449424966842326 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006639562031426037, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015312452810766913, 'dropout_rate_Layer_2': 0.09250395405282402, 'dropout_rate_Layer_3': 0.040687337807242104, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014177542129331468, 'l1_Layer_2': 0.0002983837301374223, 'l1_Layer_3': 1.6140126784942003e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 270, 'n_units_Layer_3': 260}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.45 | sMAPE for Validation Set is: 6.93% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 4.23 | sMAPE for Test Set is: 8.70% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:25:14,267]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:25:21,448]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:25:24,463]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:25:29,884]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:25:35,526]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:25:39,112]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:25:46,860]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:25:54,671]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:25:58,841]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:26:14,520]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:26:31,914]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:26:35,538]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:26:39,559]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:26:47,008]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:26:52,187]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:26:57,444]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.65 | sMAPE for Validation Set is: 7.32% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.23 | sMAPE for Test Set is: 8.68% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:26:59,415]\u001b[0m Trial 975 finished with value: 3.650524451035583 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008694129312146027, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02195570020003448, 'dropout_rate_Layer_2': 7.977776154885312e-05, 'dropout_rate_Layer_3': 0.21558076038313723, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012998178709554356, 'l1_Layer_2': 0.0013135377140368405, 'l1_Layer_3': 0.0003430848415496054, 'n_units_Layer_1': 195, 'n_units_Layer_2': 160, 'n_units_Layer_3': 165}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:27:06,859]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:27:12,130]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:27:17,741]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:27:21,873]\u001b[0m Trial 969 finished with value: 3.867780406959008 and parameters: {'n_hidden': 4, 'learning_rate': 0.0029233756428320157, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27236266210144944, 'dropout_rate_Layer_2': 0.2857063425311087, 'dropout_rate_Layer_3': 0.3415889027833438, 'dropout_rate_Layer_4': 0.38335141266220973, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 8.864437218753859e-05, 'l1_Layer_2': 1.8591700432183525e-05, 'l1_Layer_3': 1.34033653242833e-05, 'l1_Layer_4': 0.00037813491676523753, 'n_units_Layer_1': 185, 'n_units_Layer_2': 65, 'n_units_Layer_3': 205, 'n_units_Layer_4': 170}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.87 | sMAPE for Validation Set is: 7.63% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.46 | sMAPE for Test Set is: 9.53% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:27:48,895]\u001b[0m Trial 990 finished with value: 3.47778279441251 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005588202414989435, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00048484527191912635, 'dropout_rate_Layer_2': 0.08955532069086129, 'dropout_rate_Layer_3': 0.04458788221864993, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009654542659117591, 'l1_Layer_2': 0.00020517339632496607, 'l1_Layer_3': 1.1824230585319021e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 280, 'n_units_Layer_3': 250}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.48 | sMAPE for Validation Set is: 7.01% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.24 | sMAPE for Test Set is: 8.76% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:27:57,751]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:28:02,062]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:28:08,757]\u001b[0m Trial 971 finished with value: 3.904049557938034 and parameters: {'n_hidden': 4, 'learning_rate': 0.0030319317019901764, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28940423621930145, 'dropout_rate_Layer_2': 0.28638630377145524, 'dropout_rate_Layer_3': 0.3448582998061681, 'dropout_rate_Layer_4': 0.3226673055324054, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 8.7231043364079e-05, 'l1_Layer_2': 1.2291901764195559e-05, 'l1_Layer_3': 3.419948799815459e-05, 'l1_Layer_4': 0.00014007976680626634, 'n_units_Layer_1': 175, 'n_units_Layer_2': 65, 'n_units_Layer_3': 195, 'n_units_Layer_4': 155}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.90 | sMAPE for Validation Set is: 7.86% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.36 | sMAPE for Test Set is: 9.30% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:28:13,320]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:28:25,425]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:28:35,123]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:28:40,019]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:28:59,364]\u001b[0m Trial 992 finished with value: 3.570404161794226 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005632279471314689, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.017910211110372533, 'dropout_rate_Layer_2': 0.08494811123698481, 'dropout_rate_Layer_3': 0.04539161462356333, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002154360219780402, 'l1_Layer_2': 0.00025812190219504663, 'l1_Layer_3': 1.2006971701425167e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 280, 'n_units_Layer_3': 250}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.57 | sMAPE for Validation Set is: 7.16% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.18 | sMAPE for Test Set is: 8.69% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:29:04,250]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:29:09,485]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:29:14,445]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:29:22,166]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:29:25,391]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:29:25,518]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:30:20,377]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:30:28,144]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:30:56,943]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:31:04,468]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:31:28,415]\u001b[0m Trial 998 finished with value: 3.8641086270422904 and parameters: {'n_hidden': 4, 'learning_rate': 0.002361345104922158, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2857246629900004, 'dropout_rate_Layer_2': 0.2885071294872031, 'dropout_rate_Layer_3': 0.34415976214288035, 'dropout_rate_Layer_4': 0.32126819394419254, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00012858531881670352, 'l1_Layer_2': 1.5875290281059297e-05, 'l1_Layer_3': 1.230962368590116e-05, 'l1_Layer_4': 0.00012812568440372392, 'n_units_Layer_1': 180, 'n_units_Layer_2': 80, 'n_units_Layer_3': 195, 'n_units_Layer_4': 155}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.86 | sMAPE for Validation Set is: 7.68% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.29 | sMAPE for Test Set is: 9.05% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:31:36,296]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:31:41,634]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:31:42,755]\u001b[0m Trial 1011 finished with value: 3.5126877439577044 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006844757771826583, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.018168096027427548, 'dropout_rate_Layer_2': 0.07708357275321003, 'dropout_rate_Layer_3': 0.05400736014643704, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008736289148322898, 'l1_Layer_2': 0.00035737079538021897, 'l1_Layer_3': 1.3897578510831898e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 275, 'n_units_Layer_3': 250}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.51 | sMAPE for Validation Set is: 7.07% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.25 | sMAPE for Test Set is: 8.84% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:32:00,892]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:32:03,455]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:32:07,807]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:32:15,719]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:32:24,759]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:32:29,170]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:32:34,204]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:32:34,531]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:32:41,145]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:32:51,777]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:32:58,427]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:33:02,380]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:33:09,208]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:33:13,379]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:33:18,422]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:33:22,086]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:33:25,882]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:33:28,266]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:33:32,419]\u001b[0m Trial 1009 finished with value: 3.9115155255195155 and parameters: {'n_hidden': 4, 'learning_rate': 0.0026471477256232922, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2993435656210533, 'dropout_rate_Layer_2': 0.2843963159425798, 'dropout_rate_Layer_3': 0.3433493627652469, 'dropout_rate_Layer_4': 0.3207496173230372, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00019079075259296568, 'l1_Layer_2': 1.5061583007689943e-05, 'l1_Layer_3': 3.553665344401813e-05, 'l1_Layer_4': 0.00020025195335230097, 'n_units_Layer_1': 175, 'n_units_Layer_2': 60, 'n_units_Layer_3': 195, 'n_units_Layer_4': 155}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.91 | sMAPE for Validation Set is: 7.78% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.38 | sMAPE for Test Set is: 8.96% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:33:35,797]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:33:41,194]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:33:45,346]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:33:51,368]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:34:15,281]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:34:33,006]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:34:44,202]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:34:53,435]\u001b[0m Trial 1038 finished with value: 3.5709702593343446 and parameters: {'n_hidden': 3, 'learning_rate': 0.00068403430129553, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02234614656083279, 'dropout_rate_Layer_2': 0.09106495863914113, 'dropout_rate_Layer_3': 0.05849957131974298, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012238732304281222, 'l1_Layer_2': 0.00017262342228366559, 'l1_Layer_3': 1.5165012638855343e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 280, 'n_units_Layer_3': 245}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.57 | sMAPE for Validation Set is: 7.17% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.44 | sMAPE for Test Set is: 9.12% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:34:58,881]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:35:01,717]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:35:02,741]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:35:10,962]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:35:31,234]\u001b[0m Trial 1042 finished with value: 3.647236645297187 and parameters: {'n_hidden': 3, 'learning_rate': 0.020606655630210552, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2383047677325921, 'dropout_rate_Layer_2': 0.27051745753132767, 'dropout_rate_Layer_3': 0.21701404610924657, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011397599769211368, 'l1_Layer_2': 6.9993959461623e-05, 'l1_Layer_3': 2.4516063520705437e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 55, 'n_units_Layer_3': 220}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.65 | sMAPE for Validation Set is: 7.24% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.03 | sMAPE for Test Set is: 8.41% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:35:35,916]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:35:39,638]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.97 | sMAPE for Validation Set is: 7.80% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.44 | sMAPE for Test Set is: 9.01% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:35:42,117]\u001b[0m Trial 1000 finished with value: 3.968919342962723 and parameters: {'n_hidden': 4, 'learning_rate': 0.002663977621411454, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2864236282693015, 'dropout_rate_Layer_2': 0.28545425071409863, 'dropout_rate_Layer_3': 0.3411058148722741, 'dropout_rate_Layer_4': 0.3669549839653751, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00014501363077914367, 'l1_Layer_2': 1.6952108458961037e-05, 'l1_Layer_3': 3.340118864913837e-05, 'l1_Layer_4': 0.00038957145052860944, 'n_units_Layer_1': 185, 'n_units_Layer_2': 60, 'n_units_Layer_3': 195, 'n_units_Layer_4': 155}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:35:45,193]\u001b[0m Trial 1045 finished with value: 3.5406354074282795 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006565989322916528, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.026837303781276238, 'dropout_rate_Layer_2': 0.10965252855704717, 'dropout_rate_Layer_3': 0.0737298410652711, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011295097981688681, 'l1_Layer_2': 0.00022379706459048368, 'l1_Layer_3': 2.3166875346294098e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 285, 'n_units_Layer_3': 245}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.54 | sMAPE for Validation Set is: 7.08% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.10 | sMAPE for Test Set is: 8.54% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:35:49,228]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:35:53,685]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:35:57,016]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:35:57,530]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:36:09,233]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:36:14,648]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:36:18,416]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:36:22,960]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:36:26,152]\u001b[0m Trial 1046 finished with value: 3.5541293091036983 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007566369824532268, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.019355898470073418, 'dropout_rate_Layer_2': 0.07924231045863545, 'dropout_rate_Layer_3': 0.07860741205157129, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0018250872187969315, 'l1_Layer_2': 0.00023419680341498994, 'l1_Layer_3': 1.7236505391571155e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 280, 'n_units_Layer_3': 255}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.55 | sMAPE for Validation Set is: 7.12% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.27 | sMAPE for Test Set is: 8.79% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:36:29,123]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:37:19,050]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:37:24,368]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:37:34,182]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:37:38,781]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:37:43,984]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:38:19,668]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:39:14,787]\u001b[0m Trial 1067 finished with value: 3.7988716180719693 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008478398536020907, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014939683871453321, 'dropout_rate_Layer_2': 0.00012873920470657732, 'dropout_rate_Layer_3': 0.13512096014351507, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008195120890121353, 'l1_Layer_2': 0.00043518253880799003, 'l1_Layer_3': 0.000998910520984459, 'n_units_Layer_1': 205, 'n_units_Layer_2': 170, 'n_units_Layer_3': 155}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.80 | sMAPE for Validation Set is: 7.56% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.42 | sMAPE for Test Set is: 9.08% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:40:08,708]\u001b[0m Trial 1068 finished with value: 3.6609124875113057 and parameters: {'n_hidden': 3, 'learning_rate': 0.011926126690818863, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2469866905246746, 'dropout_rate_Layer_2': 0.16616773787919262, 'dropout_rate_Layer_3': 0.21338102033717496, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001092452725947547, 'l1_Layer_2': 0.00019927296784605115, 'l1_Layer_3': 1.016659203019012e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 55, 'n_units_Layer_3': 220}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.66 | sMAPE for Validation Set is: 7.34% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.10 | sMAPE for Test Set is: 8.62% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:40:12,949]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:40:56,283]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:41:02,037]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:41:03,951]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:41:08,902]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:41:11,798]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:41:15,802]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:41:16,606]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:41:21,972]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:41:22,213]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:41:26,774]\u001b[0m Trial 1066 finished with value: 4.043071064602729 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016444617545649312, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2968481486666059, 'dropout_rate_Layer_2': 0.3085339370879455, 'dropout_rate_Layer_3': 0.29796165683424564, 'dropout_rate_Layer_4': 0.280739433614749, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00015637172410123235, 'l1_Layer_2': 1.4003892386373663e-05, 'l1_Layer_3': 4.6935076778214046e-05, 'l1_Layer_4': 0.00035886671144419463, 'n_units_Layer_1': 295, 'n_units_Layer_2': 65, 'n_units_Layer_3': 205, 'n_units_Layer_4': 160}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.04 | sMAPE for Validation Set is: 8.01% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.19 | sMAPE for Test Set is: 10.36% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:41:28,051]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:41:49,770]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:41:52,874]\u001b[0m Trial 1071 finished with value: 3.81121830955342 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008557650981369246, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01373871246979727, 'dropout_rate_Layer_2': 0.08616571069707359, 'dropout_rate_Layer_3': 0.14715199049486744, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001012443933281213, 'l1_Layer_2': 0.00028741979829554536, 'l1_Layer_3': 0.0008785392097619353, 'n_units_Layer_1': 215, 'n_units_Layer_2': 180, 'n_units_Layer_3': 155}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.81 | sMAPE for Validation Set is: 7.57% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.43 | sMAPE for Test Set is: 9.02% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:41:54,878]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:41:58,845]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:41:59,528]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:42:04,615]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:42:08,471]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:42:13,033]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:42:16,600]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:42:23,558]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:42:30,918]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:42:39,358]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:42:48,290]\u001b[0m Trial 1081 finished with value: 3.6887162249758703 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023580031710350707, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24436976864016147, 'dropout_rate_Layer_2': 0.26266317243141224, 'dropout_rate_Layer_3': 0.32734682633400297, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010415626283491046, 'l1_Layer_2': 3.621450185983355e-05, 'l1_Layer_3': 3.400936007673708e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 75, 'n_units_Layer_3': 225}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.69 | sMAPE for Validation Set is: 7.46% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.26 | sMAPE for Test Set is: 9.02% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:42:55,964]\u001b[0m Trial 1090 finished with value: 3.633827472674336 and parameters: {'n_hidden': 3, 'learning_rate': 0.007249969254867397, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27471202881059636, 'dropout_rate_Layer_2': 0.28066690452433474, 'dropout_rate_Layer_3': 0.20270977950381808, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014357139876561368, 'l1_Layer_2': 8.376230256730521e-05, 'l1_Layer_3': 0.00010217484029522029, 'n_units_Layer_1': 275, 'n_units_Layer_2': 70, 'n_units_Layer_3': 180}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.63 | sMAPE for Validation Set is: 7.24% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 3.90 | sMAPE for Test Set is: 8.12% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:43:00,635]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:43:14,151]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:43:24,719]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:43:27,906]\u001b[0m Trial 1088 finished with value: 3.7386884903330597 and parameters: {'n_hidden': 3, 'learning_rate': 0.002149961523777595, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3294812768730821, 'dropout_rate_Layer_2': 0.2675122945186664, 'dropout_rate_Layer_3': 0.3261432272875487, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00019135485591431335, 'l1_Layer_2': 3.462072401204689e-05, 'l1_Layer_3': 3.617465769015622e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 60, 'n_units_Layer_3': 195}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.74 | sMAPE for Validation Set is: 7.54% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.18 | sMAPE for Test Set is: 8.78% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:43:28,745]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:43:32,823]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:43:40,278]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:43:45,687]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:43:48,880]\u001b[0m Trial 1099 finished with value: 7.314088239394532 and parameters: {'n_hidden': 4, 'learning_rate': 0.006945017514550479, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30754176204328637, 'dropout_rate_Layer_2': 0.2668075723871219, 'dropout_rate_Layer_3': 0.1386786974246685, 'dropout_rate_Layer_4': 0.0262023517957804, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 6.262723630710445e-05, 'l1_Layer_2': 7.762522863603522e-05, 'l1_Layer_3': 0.00015104432285427023, 'l1_Layer_4': 0.007518632854151688, 'n_units_Layer_1': 295, 'n_units_Layer_2': 60, 'n_units_Layer_3': 165, 'n_units_Layer_4': 230}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.31 | sMAPE for Validation Set is: 13.93% | rMAE for Validation Set is: 1.13\n",
      "MAE for Test Set is: 10.82 | sMAPE for Test Set is: 20.67% | rMAE for Test Set is: 1.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:43:49,581]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:43:49,599]\u001b[0m Trial 1093 finished with value: 3.552052268955295 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006226630957799664, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.018028804556127404, 'dropout_rate_Layer_2': 0.11641536246702153, 'dropout_rate_Layer_3': 0.03818120928354665, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010177840443621243, 'l1_Layer_2': 0.00019783418720295697, 'l1_Layer_3': 1.4437825391667226e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 280, 'n_units_Layer_3': 235}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.55 | sMAPE for Validation Set is: 7.14% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.48 | sMAPE for Test Set is: 9.13% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:44:20,461]\u001b[0m Trial 1104 finished with value: 3.7796981806550836 and parameters: {'n_hidden': 3, 'learning_rate': 0.007687148388703124, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.233334559601044, 'dropout_rate_Layer_2': 0.3484828917458908, 'dropout_rate_Layer_3': 0.18911525756224862, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00024866020427641414, 'l1_Layer_2': 4.8500996913379586e-05, 'l1_Layer_3': 0.00021485574550750264, 'n_units_Layer_1': 275, 'n_units_Layer_2': 85, 'n_units_Layer_3': 200}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.78 | sMAPE for Validation Set is: 7.53% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.30 | sMAPE for Test Set is: 9.11% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:44:36,062]\u001b[0m Trial 1101 finished with value: 3.792268972219258 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009823699836044467, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34636843998728306, 'dropout_rate_Layer_2': 0.26033210037025817, 'dropout_rate_Layer_3': 0.33300575014673706, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00032746676796169673, 'l1_Layer_2': 4.62937453888916e-05, 'l1_Layer_3': 3.6577988792178174e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 75, 'n_units_Layer_3': 195}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.79 | sMAPE for Validation Set is: 7.58% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.24 | sMAPE for Test Set is: 8.93% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:44:36,589]\u001b[0m Trial 1106 finished with value: 3.823418841495194 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009973579268800275, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007727937407609139, 'dropout_rate_Layer_2': 0.08615870277733047, 'dropout_rate_Layer_3': 0.1935257142619911, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001168062158640715, 'l1_Layer_2': 0.00038180261821619226, 'l1_Layer_3': 0.0006503720017251055, 'n_units_Layer_1': 195, 'n_units_Layer_2': 195, 'n_units_Layer_3': 160}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.82 | sMAPE for Validation Set is: 7.58% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.51 | sMAPE for Test Set is: 9.02% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:44:37,085]\u001b[0m Trial 1105 finished with value: 3.686117242195087 and parameters: {'n_hidden': 3, 'learning_rate': 0.008144110270426738, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2596852172658961, 'dropout_rate_Layer_2': 0.225365574216762, 'dropout_rate_Layer_3': 0.18237272028853443, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00016194808579683738, 'l1_Layer_2': 3.1045131935981236e-05, 'l1_Layer_3': 9.094068728517768e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 85, 'n_units_Layer_3': 200}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.69 | sMAPE for Validation Set is: 7.36% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 3.96 | sMAPE for Test Set is: 8.56% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:44:45,905]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:44:49,819]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:44:58,949]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:45:02,633]\u001b[0m Trial 1107 finished with value: 3.639084607351647 and parameters: {'n_hidden': 3, 'learning_rate': 0.015497164600578548, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25845627867696364, 'dropout_rate_Layer_2': 0.23267746456889005, 'dropout_rate_Layer_3': 0.20327744014061344, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00016747119090377698, 'l1_Layer_2': 8.587365568778644e-05, 'l1_Layer_3': 6.212753854752107e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 165, 'n_units_Layer_3': 245}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.64 | sMAPE for Validation Set is: 7.26% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.09 | sMAPE for Test Set is: 8.81% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:45:03,012]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:46:08,370]\u001b[0m Trial 1114 finished with value: 3.813262326197917 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021759729970139813, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3447426361257506, 'dropout_rate_Layer_2': 0.2605560190422996, 'dropout_rate_Layer_3': 0.32547918898317846, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003928326736380444, 'l1_Layer_2': 3.565859136266429e-05, 'l1_Layer_3': 3.438059494376692e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 75, 'n_units_Layer_3': 190}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.81 | sMAPE for Validation Set is: 7.65% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.32 | sMAPE for Test Set is: 9.09% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:46:16,216]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:46:33,536]\u001b[0m Trial 1108 finished with value: 3.726252261948541 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011280243736014415, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3429354818617614, 'dropout_rate_Layer_2': 0.26527028812760695, 'dropout_rate_Layer_3': 0.33148661918618794, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000388316338463309, 'l1_Layer_2': 4.713038116387014e-05, 'l1_Layer_3': 3.531946373831103e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 75, 'n_units_Layer_3': 195}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.73 | sMAPE for Validation Set is: 7.50% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.36 | sMAPE for Test Set is: 9.14% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:46:40,954]\u001b[0m Trial 1112 finished with value: 3.6922766227029555 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009532253166885968, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3342531660702949, 'dropout_rate_Layer_2': 0.2619812311532745, 'dropout_rate_Layer_3': 0.3333918755383061, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003324374585873262, 'l1_Layer_2': 3.163332443503922e-05, 'l1_Layer_3': 3.6060055995118424e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 75, 'n_units_Layer_3': 195}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.69 | sMAPE for Validation Set is: 7.42% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.27 | sMAPE for Test Set is: 8.90% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:46:42,475]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:46:47,845]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:46:50,653]\u001b[0m Trial 1115 finished with value: 3.7437211286999434 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008804335618552366, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3531034477277997, 'dropout_rate_Layer_2': 0.2646499709067468, 'dropout_rate_Layer_3': 0.3323863175644156, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003495761686620153, 'l1_Layer_2': 4.6056395235893575e-05, 'l1_Layer_3': 6.485569918631143e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 75, 'n_units_Layer_3': 195}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.74 | sMAPE for Validation Set is: 7.52% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.31 | sMAPE for Test Set is: 9.07% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:46:52,998]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:47:01,130]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:47:04,096]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:47:08,786]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:47:12,547]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:47:39,799]\u001b[0m Trial 1123 finished with value: 3.5610200804438676 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005907327604226729, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.000847878763815862, 'dropout_rate_Layer_2': 0.12062911908774163, 'dropout_rate_Layer_3': 0.046984841396624816, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011164476057821556, 'l1_Layer_2': 0.0003474493549768311, 'l1_Layer_3': 1.1903635300890665e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 290, 'n_units_Layer_3': 240}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.56 | sMAPE for Validation Set is: 7.12% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.28 | sMAPE for Test Set is: 8.77% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:47:43,910]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:47:44,946]\u001b[0m Trial 1126 finished with value: 3.607873990238268 and parameters: {'n_hidden': 3, 'learning_rate': 0.015229960186092528, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2827502277802245, 'dropout_rate_Layer_2': 0.3112952693853022, 'dropout_rate_Layer_3': 0.22008818277816108, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011819205842161245, 'l1_Layer_2': 0.00018010188159094196, 'l1_Layer_3': 4.467268070403302e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 155, 'n_units_Layer_3': 245}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.61 | sMAPE for Validation Set is: 7.20% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 3.87 | sMAPE for Test Set is: 8.40% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:47:49,352]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:47:51,709]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:47:54,873]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:47:55,562]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:48:01,172]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:48:05,829]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:48:08,851]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:48:11,493]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:48:12,208]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:48:12,327]\u001b[0m Trial 1117 finished with value: 3.7077663394547926 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011008340500066852, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35270331172528147, 'dropout_rate_Layer_2': 0.26295149704372606, 'dropout_rate_Layer_3': 0.3292168159351203, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00037948898218219103, 'l1_Layer_2': 3.47801268764707e-05, 'l1_Layer_3': 3.4472674575059004e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 75, 'n_units_Layer_3': 195}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.71 | sMAPE for Validation Set is: 7.50% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.14 | sMAPE for Test Set is: 8.94% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:48:17,939]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:48:21,656]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:48:22,378]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:48:28,828]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:48:29,254]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:48:36,595]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:48:37,212]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:48:39,483]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:48:42,968]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:48:49,166]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:48:53,015]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:48:56,731]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:49:00,656]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:49:05,657]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:49:09,662]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:49:14,084]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:49:26,370]\u001b[0m Trial 1149 finished with value: 3.5206839308481204 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006087875225297585, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.006951266469746976, 'dropout_rate_Layer_2': 0.08633230612559871, 'dropout_rate_Layer_3': 0.0466170169293327, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006548637012133737, 'l1_Layer_2': 0.000681241980824808, 'l1_Layer_3': 1.7606002194951662e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 285, 'n_units_Layer_3': 255}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.52 | sMAPE for Validation Set is: 7.09% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.18 | sMAPE for Test Set is: 8.72% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:49:29,996]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:49:32,562]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:49:36,439]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:49:38,938]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:49:42,822]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:49:43,282]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:50:00,712]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:50:09,371]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:50:12,595]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:50:18,825]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:50:26,109]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:50:29,588]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:50:34,008]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:50:37,609]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:50:40,081]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:50:47,529]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:50:51,892]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:50:57,601]\u001b[0m Trial 1147 finished with value: 3.6345642563306644 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009224207780027066, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3508414937177352, 'dropout_rate_Layer_2': 0.263192900792255, 'dropout_rate_Layer_3': 0.33148581209858097, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006331102048756725, 'l1_Layer_2': 5.335005629946485e-05, 'l1_Layer_3': 3.885608999817556e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 80, 'n_units_Layer_3': 190}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.63 | sMAPE for Validation Set is: 7.20% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.58 | sMAPE for Test Set is: 9.38% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:50:59,310]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:51:03,414]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:51:13,530]\u001b[0m Trial 1169 finished with value: 3.551089691520847 and parameters: {'n_hidden': 3, 'learning_rate': 0.013508983411729557, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28796212741816746, 'dropout_rate_Layer_2': 0.30898459997412836, 'dropout_rate_Layer_3': 0.20433335122353752, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.117045432931043e-05, 'l1_Layer_2': 8.798199405746458e-05, 'l1_Layer_3': 4.620188264218501e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 170, 'n_units_Layer_3': 270}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.55 | sMAPE for Validation Set is: 7.07% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 3.94 | sMAPE for Test Set is: 8.50% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:51:16,081]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:51:20,562]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:51:20,675]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:51:22,247]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:51:28,623]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:51:30,971]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:51:31,126]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:51:32,526]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:51:40,473]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:51:50,885]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:51:55,865]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:51:56,182]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:52:02,514]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:52:08,802]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:52:12,891]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:52:16,550]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:52:20,794]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:52:23,664]\u001b[0m Trial 1181 finished with value: 3.6380689318442037 and parameters: {'n_hidden': 3, 'learning_rate': 0.014089015515701877, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2926448024632435, 'dropout_rate_Layer_2': 0.19135345369700327, 'dropout_rate_Layer_3': 0.20199255303508726, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.416290994728888e-05, 'l1_Layer_2': 0.00017385397591992662, 'l1_Layer_3': 8.01688684929496e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 195, 'n_units_Layer_3': 275}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.64 | sMAPE for Validation Set is: 7.28% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.28 | sMAPE for Test Set is: 8.96% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:52:25,835]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:52:28,234]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:52:29,845]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:52:37,293]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:52:40,028]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:52:46,948]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:52:49,607]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:52:50,146]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:52:52,223]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.69 | sMAPE for Validation Set is: 7.35% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.03 | sMAPE for Test Set is: 8.44% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:52:58,764]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:52:58,784]\u001b[0m Trial 1191 finished with value: 3.6939986041315884 and parameters: {'n_hidden': 3, 'learning_rate': 0.01576227164815911, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33015389742430495, 'dropout_rate_Layer_2': 0.3132414711936944, 'dropout_rate_Layer_3': 0.20132581295234123, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.937748904255095e-05, 'l1_Layer_2': 0.0001547226891794984, 'l1_Layer_3': 0.00010103859810894643, 'n_units_Layer_1': 270, 'n_units_Layer_2': 170, 'n_units_Layer_3': 270}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:52:58,904]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:53:06,027]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:53:11,107]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:53:11,305]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:53:17,889]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:53:23,194]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:53:26,462]\u001b[0m Trial 1209 finished with value: 4.713810709148812 and parameters: {'n_hidden': 3, 'learning_rate': 0.013289246643275543, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2826627727036452, 'dropout_rate_Layer_2': 0.21710134890118776, 'dropout_rate_Layer_3': 0.1525058007806805, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001885349394449761, 'l1_Layer_2': 0.00012061794427649555, 'l1_Layer_3': 6.559320629895171e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 195, 'n_units_Layer_3': 285}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.71 | sMAPE for Validation Set is: 9.36% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 5.99 | sMAPE for Test Set is: 12.42% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:53:31,754]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:53:40,752]\u001b[0m Trial 1205 finished with value: 3.4951072704592234 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006053926795913312, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007733011043437266, 'dropout_rate_Layer_2': 0.10648860250189869, 'dropout_rate_Layer_3': 0.051396527197199136, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005372106444762759, 'l1_Layer_2': 0.00019319495996356412, 'l1_Layer_3': 1.6808008824990396e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 280, 'n_units_Layer_3': 220}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.50 | sMAPE for Validation Set is: 7.03% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.38 | sMAPE for Test Set is: 9.13% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:53:45,693]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:54:03,737]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:54:09,303]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:54:14,740]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:54:21,222]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:54:30,509]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:54:51,226]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:54:59,760]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:55:05,539]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:55:14,038]\u001b[0m Trial 1215 finished with value: 3.7146286330143172 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013013518791364245, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35668621132451006, 'dropout_rate_Layer_2': 0.2676185049315417, 'dropout_rate_Layer_3': 0.33652054343617116, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003617653588101751, 'l1_Layer_2': 3.547273490062051e-05, 'l1_Layer_3': 4.850242407874267e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 70, 'n_units_Layer_3': 210}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.71 | sMAPE for Validation Set is: 7.48% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.22 | sMAPE for Test Set is: 8.95% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:55:14,314]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:55:22,815]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:55:23,210]\u001b[0m Trial 1221 finished with value: 3.4725949498483817 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006472276279001848, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.019229891597571155, 'dropout_rate_Layer_2': 0.1128303726489967, 'dropout_rate_Layer_3': 0.0581106848203757, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005432359356142914, 'l1_Layer_2': 0.0003120376945302773, 'l1_Layer_3': 2.0228192772162853e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 280, 'n_units_Layer_3': 235}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.47 | sMAPE for Validation Set is: 7.00% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 4.02 | sMAPE for Test Set is: 8.31% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:55:24,223]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:55:26,814]\u001b[0m Trial 1214 finished with value: 3.6688755488528884 and parameters: {'n_hidden': 3, 'learning_rate': 0.001110035644613859, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.361966556093084, 'dropout_rate_Layer_2': 0.26842655445037206, 'dropout_rate_Layer_3': 0.3349204871272313, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004562803164681778, 'l1_Layer_2': 3.4465334290689324e-05, 'l1_Layer_3': 4.965090940905145e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 70, 'n_units_Layer_3': 210}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.67 | sMAPE for Validation Set is: 7.35% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.32 | sMAPE for Test Set is: 8.90% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:55:37,293]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:55:37,957]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:55:41,394]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:55:46,067]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:55:50,762]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:56:00,809]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:56:18,866]\u001b[0m Trial 1236 finished with value: 3.5855114962490795 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006099350346205359, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 1.1866719693293538e-05, 'dropout_rate_Layer_2': 0.13461337344044527, 'dropout_rate_Layer_3': 0.07922753387688097, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005828773914815045, 'l1_Layer_2': 0.00026784097458626074, 'l1_Layer_3': 1.914373774598301e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 285, 'n_units_Layer_3': 240}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.59 | sMAPE for Validation Set is: 7.22% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.35 | sMAPE for Test Set is: 8.97% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:56:19,772]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:56:23,170]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:56:26,559]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:56:27,222]\u001b[0m Trial 1233 finished with value: 3.732465334888721 and parameters: {'n_hidden': 3, 'learning_rate': 0.019448045106047446, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28027086069169194, 'dropout_rate_Layer_2': 0.20885848140040264, 'dropout_rate_Layer_3': 0.23609268288409402, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001500706651795591, 'l1_Layer_2': 9.161133573121637e-05, 'l1_Layer_3': 0.00014868152832119564, 'n_units_Layer_1': 240, 'n_units_Layer_2': 185, 'n_units_Layer_3': 255}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.73 | sMAPE for Validation Set is: 7.46% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.98 | sMAPE for Test Set is: 10.09% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:56:33,319]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:56:35,571]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:56:40,778]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:56:45,294]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:57:00,303]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:57:20,422]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:57:25,883]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:57:29,622]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:57:35,118]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:57:40,747]\u001b[0m Trial 1243 finished with value: 3.683710815173954 and parameters: {'n_hidden': 3, 'learning_rate': 0.01038300280823595, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26373086892313063, 'dropout_rate_Layer_2': 0.237305496140043, 'dropout_rate_Layer_3': 0.22109029822256998, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.686945029210639e-05, 'l1_Layer_2': 4.502846986037859e-05, 'l1_Layer_3': 3.339542162084239e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 155, 'n_units_Layer_3': 300}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.68 | sMAPE for Validation Set is: 7.32% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.07 | sMAPE for Test Set is: 8.39% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:57:44,843]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:57:48,066]\u001b[0m Trial 1240 finished with value: 3.7270202022957393 and parameters: {'n_hidden': 3, 'learning_rate': 0.01039265688885245, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25648176523739746, 'dropout_rate_Layer_2': 0.28875207409727915, 'dropout_rate_Layer_3': 0.2219926203310495, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.057174902707348e-05, 'l1_Layer_2': 8.909040640048849e-05, 'l1_Layer_3': 0.0001655863191366356, 'n_units_Layer_1': 265, 'n_units_Layer_2': 225, 'n_units_Layer_3': 245}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.73 | sMAPE for Validation Set is: 7.41% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.30 | sMAPE for Test Set is: 8.89% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:57:52,016]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:57:52,591]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:57:58,304]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:58:00,948]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:58:04,619]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:58:09,767]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:58:18,805]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:58:22,945]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:58:27,863]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:58:31,612]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:58:43,016]\u001b[0m Trial 1251 finished with value: 3.647620866569504 and parameters: {'n_hidden': 3, 'learning_rate': 0.011276055578683858, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2587131139235762, 'dropout_rate_Layer_2': 0.23286842195433327, 'dropout_rate_Layer_3': 0.22301308593482075, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.9621216952050583e-05, 'l1_Layer_2': 5.8804615324840534e-05, 'l1_Layer_3': 3.374799551680116e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 240, 'n_units_Layer_3': 290}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.65 | sMAPE for Validation Set is: 7.26% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.12 | sMAPE for Test Set is: 8.68% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:58:47,719]\u001b[0m Trial 1247 finished with value: 3.7323355968482446 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011776168279182529, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3859127345656156, 'dropout_rate_Layer_2': 0.25411296843123554, 'dropout_rate_Layer_3': 0.31836884945663885, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004719988478121694, 'l1_Layer_2': 5.923233348730288e-05, 'l1_Layer_3': 4.982446568039062e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 75, 'n_units_Layer_3': 170}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.73 | sMAPE for Validation Set is: 7.53% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.22 | sMAPE for Test Set is: 8.87% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:58:52,127]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:59:02,485]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:59:09,883]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:59:13,958]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:59:17,706]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:59:19,628]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:59:27,940]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:59:43,398]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:59:48,739]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:59:52,578]\u001b[0m Trial 1262 finished with value: 4.099395566776923 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011677794965481538, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3897729054057272, 'dropout_rate_Layer_2': 0.25384895482392544, 'dropout_rate_Layer_3': 0.31945878906642977, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005036959446325251, 'l1_Layer_2': 5.723143241028677e-05, 'l1_Layer_3': 5.399922848361212e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 75, 'n_units_Layer_3': 210}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.10 | sMAPE for Validation Set is: 8.10% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.97 | sMAPE for Test Set is: 10.11% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 16:59:56,816]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 16:59:57,636]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:00:10,270]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:00:12,730]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:00:25,888]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:00:28,811]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:00:29,698]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:00:34,813]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:00:51,849]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:00:56,009]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:01:11,075]\u001b[0m Trial 1265 finished with value: 3.619301923906337 and parameters: {'n_hidden': 3, 'learning_rate': 0.001083303647659394, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.327099868160107, 'dropout_rate_Layer_2': 0.24765171675003192, 'dropout_rate_Layer_3': 0.3187409672940232, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00046326961263585674, 'l1_Layer_2': 6.094597821994328e-05, 'l1_Layer_3': 5.432953223866305e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 85, 'n_units_Layer_3': 210}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.62 | sMAPE for Validation Set is: 7.30% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.09 | sMAPE for Test Set is: 8.67% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 17:01:16,266]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:01:20,124]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:01:24,044]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:01:27,169]\u001b[0m Trial 1285 finished with value: 3.6983199924774453 and parameters: {'n_hidden': 3, 'learning_rate': 0.009074148790792535, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3490524836453412, 'dropout_rate_Layer_2': 0.33730832980069997, 'dropout_rate_Layer_3': 0.24979056416498296, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.639264812225461e-05, 'l1_Layer_2': 0.0001237121453055218, 'l1_Layer_3': 4.343516800604924e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 190, 'n_units_Layer_3': 265}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:01:27,231]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.70 | sMAPE for Validation Set is: 7.40% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.03 | sMAPE for Test Set is: 8.78% | rMAE for Test Set is: 0.62\n",
      "MAE for Validation Set is: 3.67 | sMAPE for Validation Set is: 7.37% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.29 | sMAPE for Test Set is: 9.00% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 17:01:32,007]\u001b[0m Trial 1271 finished with value: 3.666040140814399 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011291018800539672, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3636632010003914, 'dropout_rate_Layer_2': 0.24700684343445165, 'dropout_rate_Layer_3': 0.31870089903738097, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00033647867240323457, 'l1_Layer_2': 6.244707497145299e-05, 'l1_Layer_3': 6.405317433285466e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 85, 'n_units_Layer_3': 210}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:01:35,046]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:01:35,658]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:01:41,677]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:01:44,305]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:01:51,503]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:02:06,560]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:02:11,502]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:02:32,878]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:02:52,023]\u001b[0m Trial 1286 finished with value: 3.721052364983372 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009819245607042895, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3506433996872303, 'dropout_rate_Layer_2': 0.2583867430715305, 'dropout_rate_Layer_3': 0.33789840429207996, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007685351404082989, 'l1_Layer_2': 6.394335491503896e-05, 'l1_Layer_3': 3.355363146966991e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 85, 'n_units_Layer_3': 190}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.72 | sMAPE for Validation Set is: 7.47% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.48 | sMAPE for Test Set is: 9.27% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 17:02:56,530]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:02:57,324]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:03:05,668]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:03:09,277]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:03:13,381]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:03:20,433]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:03:23,698]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:03:26,861]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:03:27,351]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:03:36,335]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:03:40,476]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:03:44,820]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:03:49,842]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:03:53,649]\u001b[0m Trial 1297 finished with value: 3.725198221535212 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009829103656639729, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35039500097240395, 'dropout_rate_Layer_2': 0.23657190612160275, 'dropout_rate_Layer_3': 0.2927514434394611, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006889370086150044, 'l1_Layer_2': 6.888687409811567e-05, 'l1_Layer_3': 7.819163093324418e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 85, 'n_units_Layer_3': 215}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.73 | sMAPE for Validation Set is: 7.51% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.32 | sMAPE for Test Set is: 9.17% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 17:03:55,632]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:03:57,895]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:04:01,067]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:04:03,412]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:04:07,708]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:04:13,392]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:04:24,205]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:04:27,034]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:04:30,295]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:04:38,552]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:04:42,015]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:04:44,004]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:04:46,831]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:04:47,641]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:04:48,963]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:04:55,307]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:05:02,588]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:05:02,617]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:05:09,983]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:05:13,268]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:05:15,763]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:05:17,936]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:05:20,502]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:05:23,686]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:05:27,768]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:05:41,059]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:05:51,283]\u001b[0m Trial 1321 finished with value: 4.13113506285172 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010937992102474214, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35633838366861276, 'dropout_rate_Layer_2': 0.22293964943572547, 'dropout_rate_Layer_3': 0.3159314248776906, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000839113057204108, 'l1_Layer_2': 7.198982984350296e-05, 'l1_Layer_3': 7.945464156874278e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 85, 'n_units_Layer_3': 230}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.13 | sMAPE for Validation Set is: 8.07% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.25 | sMAPE for Test Set is: 10.49% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 17:05:55,662]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:05:59,595]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:06:00,236]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:06:06,572]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:06:23,300]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:06:48,568]\u001b[0m Trial 1339 finished with value: 3.7197221271951775 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009082565691383131, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3434241211511959, 'dropout_rate_Layer_2': 0.25912457897706054, 'dropout_rate_Layer_3': 0.33196310637483056, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007464869540720518, 'l1_Layer_2': 6.078394769851048e-05, 'l1_Layer_3': 4.710727587527534e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 75, 'n_units_Layer_3': 205}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.72 | sMAPE for Validation Set is: 7.45% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.55 | sMAPE for Test Set is: 9.30% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 17:07:13,421]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.56 | sMAPE for Validation Set is: 7.08% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 3.97 | sMAPE for Test Set is: 8.44% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 17:07:15,714]\u001b[0m Trial 1348 finished with value: 3.5551687399013527 and parameters: {'n_hidden': 3, 'learning_rate': 0.007322086707499, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17182650406897246, 'dropout_rate_Layer_2': 0.32687215294034166, 'dropout_rate_Layer_3': 0.12587841896024682, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00029171854120132676, 'l1_Layer_2': 0.00031679262759865977, 'l1_Layer_3': 2.9738873919934675e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 160, 'n_units_Layer_3': 155}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:07:20,295]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:07:43,450]\u001b[0m Trial 1349 finished with value: 3.690189771989649 and parameters: {'n_hidden': 3, 'learning_rate': 0.016384900650509373, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10976263966315103, 'dropout_rate_Layer_2': 0.3273021149116415, 'dropout_rate_Layer_3': 0.17818983458621152, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003068826297973154, 'l1_Layer_2': 0.0002101791892851361, 'l1_Layer_3': 3.0671686861553235e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 175, 'n_units_Layer_3': 155}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.69 | sMAPE for Validation Set is: 7.36% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 3.99 | sMAPE for Test Set is: 8.59% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 17:07:50,868]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:07:51,155]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:07:58,289]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:08:03,357]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:08:07,446]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:08:08,112]\u001b[0m Trial 1352 finished with value: 3.751226226675222 and parameters: {'n_hidden': 3, 'learning_rate': 0.016716731483941278, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17278757337691872, 'dropout_rate_Layer_2': 0.3320844334065052, 'dropout_rate_Layer_3': 0.12043854487457058, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003241159237639084, 'l1_Layer_2': 0.00040522468239614294, 'l1_Layer_3': 6.915688963172034e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 300, 'n_units_Layer_3': 155}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 7.51% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.31 | sMAPE for Test Set is: 9.05% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 17:08:13,778]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:08:17,125]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:08:22,121]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:08:26,048]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:08:30,046]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:08:34,983]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:08:38,646]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:08:44,008]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:08:49,117]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:08:52,973]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:08:58,090]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:09:05,585]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:09:12,047]\u001b[0m Trial 1354 finished with value: 3.582526479504406 and parameters: {'n_hidden': 3, 'learning_rate': 0.00748437258354884, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1687070717337673, 'dropout_rate_Layer_2': 0.35959928713243394, 'dropout_rate_Layer_3': 0.10482891359540908, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00027956411758796, 'l1_Layer_2': 0.0003059401119128793, 'l1_Layer_3': 7.749069651143976e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 160, 'n_units_Layer_3': 265}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.58 | sMAPE for Validation Set is: 7.14% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.07 | sMAPE for Test Set is: 8.78% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 17:09:23,899]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:09:24,162]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:09:30,639]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:09:33,784]\u001b[0m Trial 1350 finished with value: 3.7210175941243517 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009042692697923422, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3730802713154146, 'dropout_rate_Layer_2': 0.23827148971686274, 'dropout_rate_Layer_3': 0.3347218207470545, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007385146643349426, 'l1_Layer_2': 5.698749579445865e-05, 'l1_Layer_3': 4.408342191724216e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 80, 'n_units_Layer_3': 200}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.72 | sMAPE for Validation Set is: 7.51% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.30 | sMAPE for Test Set is: 9.10% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 17:09:36,202]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:09:41,164]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:09:45,255]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:09:50,218]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:09:52,948]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:09:58,627]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:10:02,517]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:10:07,468]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.66 | sMAPE for Validation Set is: 7.27% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 3.90 | sMAPE for Test Set is: 8.55% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 17:10:10,573]\u001b[0m Trial 1375 finished with value: 3.658309940679113 and parameters: {'n_hidden': 3, 'learning_rate': 0.004980405615989258, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.119052604922208, 'dropout_rate_Layer_2': 0.3629809135333274, 'dropout_rate_Layer_3': 0.09199202157777164, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00021151212654980069, 'l1_Layer_2': 0.0003112402168312446, 'l1_Layer_3': 0.00013606427500646398, 'n_units_Layer_1': 185, 'n_units_Layer_2': 160, 'n_units_Layer_3': 275}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:10:11,742]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:10:13,943]\u001b[0m Trial 1372 finished with value: 3.6247907122198213 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010660948514506898, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01260565727844309, 'dropout_rate_Layer_2': 0.014033388345770306, 'dropout_rate_Layer_3': 0.1778273320187175, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008675801956916679, 'l1_Layer_2': 0.0017269506352761092, 'l1_Layer_3': 0.00019712995095460831, 'n_units_Layer_1': 185, 'n_units_Layer_2': 155, 'n_units_Layer_3': 160}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.62 | sMAPE for Validation Set is: 7.21% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 3.92 | sMAPE for Test Set is: 8.22% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 17:10:20,106]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:10:20,200]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:10:30,878]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:10:34,655]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:10:37,525]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:10:38,459]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:10:41,689]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:10:46,668]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:10:48,205]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:10:51,711]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:10:54,554]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:10:58,889]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:11:02,880]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:11:04,641]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:11:20,232]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:11:25,107]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:11:29,980]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:11:34,059]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:11:38,042]\u001b[0m Trial 1389 finished with value: 3.8009005795910373 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011801600576403454, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3993922458725603, 'dropout_rate_Layer_2': 0.27330940520478364, 'dropout_rate_Layer_3': 0.2985820270507212, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011397089688263055, 'l1_Layer_2': 0.00015876045417616763, 'l1_Layer_3': 5.51826259743346e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 90, 'n_units_Layer_3': 160}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.80 | sMAPE for Validation Set is: 7.58% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.26 | sMAPE for Test Set is: 8.82% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 17:11:42,011]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:11:46,048]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.64 | sMAPE for Validation Set is: 7.25% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 3.88 | sMAPE for Test Set is: 8.11% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 17:11:47,261]\u001b[0m Trial 1400 finished with value: 3.6445973133818836 and parameters: {'n_hidden': 3, 'learning_rate': 0.005590876347835566, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29808977009194726, 'dropout_rate_Layer_2': 0.38839941904352543, 'dropout_rate_Layer_3': 0.11574402613609049, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00038723013677974293, 'l1_Layer_2': 0.00025711885294341504, 'l1_Layer_3': 7.303989146021717e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 170, 'n_units_Layer_3': 260}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:11:52,427]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:11:53,112]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:11:53,413]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:12:01,912]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:12:06,028]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:12:07,083]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:12:07,341]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:12:14,032]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:12:14,650]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:12:20,414]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:12:20,589]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:12:25,656]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:12:29,048]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:12:33,720]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:12:34,225]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:12:40,416]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:12:47,960]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:12:57,004]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:13:01,722]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:13:06,649]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:13:14,523]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:13:19,125]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:13:27,573]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:13:42,630]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:13:48,157]\u001b[0m Trial 1405 finished with value: 3.7479279051413084 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011650225445618623, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3220705167927359, 'dropout_rate_Layer_2': 0.2732897048995448, 'dropout_rate_Layer_3': 0.29978053360096557, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011083390175792736, 'l1_Layer_2': 4.153918941053011e-05, 'l1_Layer_3': 5.79454102907449e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 80, 'n_units_Layer_3': 165}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 7.54% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.12 | sMAPE for Test Set is: 8.92% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 17:13:51,664]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:13:55,894]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:13:59,901]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:14:06,709]\u001b[0m Trial 1422 finished with value: 3.589877935867736 and parameters: {'n_hidden': 3, 'learning_rate': 0.009555768247227309, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16938442320684555, 'dropout_rate_Layer_2': 0.3758482970102516, 'dropout_rate_Layer_3': 0.08166022806466122, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00018289406529205335, 'l1_Layer_2': 0.00021860167994147643, 'l1_Layer_3': 5.3144740712291156e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 150, 'n_units_Layer_3': 275}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.59 | sMAPE for Validation Set is: 7.17% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 3.98 | sMAPE for Test Set is: 8.65% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 17:14:26,508]\u001b[0m Trial 1437 finished with value: 3.5404309181394527 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008275291817023791, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.026187897408306685, 'dropout_rate_Layer_2': 0.06951042749226345, 'dropout_rate_Layer_3': 0.039761138967167646, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007283654658590647, 'l1_Layer_2': 0.00015415231602592218, 'l1_Layer_3': 1.9203911291966773e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 270, 'n_units_Layer_3': 250}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.54 | sMAPE for Validation Set is: 7.13% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.39 | sMAPE for Test Set is: 8.97% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 17:14:27,562]\u001b[0m Trial 1433 finished with value: 3.7397963480354464 and parameters: {'n_hidden': 3, 'learning_rate': 0.012155720744976173, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.095613764713987, 'dropout_rate_Layer_2': 0.28468147471529404, 'dropout_rate_Layer_3': 0.10858398085588616, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007103401838453845, 'l1_Layer_2': 0.0001436085078338539, 'l1_Layer_3': 3.858963155082678e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 50, 'n_units_Layer_3': 160}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.74 | sMAPE for Validation Set is: 7.44% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.32 | sMAPE for Test Set is: 9.19% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 17:14:32,779]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:14:34,649]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:14:35,047]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:14:37,344]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:14:41,511]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:14:44,718]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:14:46,466]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:14:54,203]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:15:01,470]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:15:01,613]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:15:11,461]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:15:21,514]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:15:26,514]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:15:44,180]\u001b[0m Trial 1449 finished with value: 3.7541613746976936 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012193829379381473, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.016092453496076686, 'dropout_rate_Layer_2': 0.12228018584459792, 'dropout_rate_Layer_3': 0.20231461701947473, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005662465101823837, 'l1_Layer_2': 0.0004863305793843135, 'l1_Layer_3': 0.003234309172233174, 'n_units_Layer_1': 195, 'n_units_Layer_2': 155, 'n_units_Layer_3': 155}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 7.47% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.21 | sMAPE for Test Set is: 8.70% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 17:16:05,628]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:16:13,916]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:16:19,050]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:16:24,303]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:16:35,443]\u001b[0m Trial 1447 finished with value: 3.7817394197186953 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009275755340220275, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3226469378363844, 'dropout_rate_Layer_2': 0.26714440668716877, 'dropout_rate_Layer_3': 0.3195558230343021, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023083738841764325, 'l1_Layer_2': 3.9912468329078555e-05, 'l1_Layer_3': 2.9049263042465264e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 70, 'n_units_Layer_3': 160}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.78 | sMAPE for Validation Set is: 7.58% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.29 | sMAPE for Test Set is: 9.06% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 17:16:42,810]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:16:43,114]\u001b[0m Trial 1454 finished with value: 3.7857782415393566 and parameters: {'n_hidden': 3, 'learning_rate': 0.001310990732701229, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3609133442010273, 'dropout_rate_Layer_2': 0.2544246577945703, 'dropout_rate_Layer_3': 0.32717172113947135, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005433225119379309, 'l1_Layer_2': 3.061222891481857e-05, 'l1_Layer_3': 5.575778909301726e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 75, 'n_units_Layer_3': 190}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.79 | sMAPE for Validation Set is: 7.55% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.33 | sMAPE for Test Set is: 9.03% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 17:16:43,701]\u001b[0m Trial 1451 finished with value: 3.511862427935254 and parameters: {'n_hidden': 3, 'learning_rate': 0.007457548467035271, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15990449510068971, 'dropout_rate_Layer_2': 0.34307290574577465, 'dropout_rate_Layer_3': 0.0810667816936127, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000280387240991447, 'l1_Layer_2': 0.00039468323148493544, 'l1_Layer_3': 5.966789401334298e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 165, 'n_units_Layer_3': 295}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.51 | sMAPE for Validation Set is: 7.03% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.15 | sMAPE for Test Set is: 8.78% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 17:16:48,055]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:16:54,214]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:16:57,751]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:16:58,832]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:17:03,992]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:17:04,748]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:17:10,984]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:17:11,291]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:17:11,466]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:17:23,526]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:17:25,734]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:17:26,829]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:17:26,990]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:17:30,108]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:17:34,002]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:17:35,634]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:17:42,962]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:17:43,805]\u001b[0m Trial 1458 finished with value: 3.627367229914532 and parameters: {'n_hidden': 3, 'learning_rate': 0.008517591433759089, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15946185029869636, 'dropout_rate_Layer_2': 0.38240970866047863, 'dropout_rate_Layer_3': 0.08370797079451665, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00018354128056389287, 'l1_Layer_2': 0.00028737039655275657, 'l1_Layer_3': 8.434464985625873e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 165, 'n_units_Layer_3': 295}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.63 | sMAPE for Validation Set is: 7.20% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 3.91 | sMAPE for Test Set is: 8.53% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 17:17:52,407]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:17:55,553]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:18:02,153]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:18:06,771]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:18:11,256]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:18:11,441]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:18:16,549]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:18:16,708]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:18:17,601]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:18:17,845]\u001b[0m Trial 1476 finished with value: 3.559738794491944 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005010445262598172, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00909335880334141, 'dropout_rate_Layer_2': 0.07403249548202367, 'dropout_rate_Layer_3': 0.027665951938383903, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006397277449828179, 'l1_Layer_2': 0.00033259194053270996, 'l1_Layer_3': 1.7717371196305183e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 295, 'n_units_Layer_3': 240}. Best is trial 960 with value: 3.449424966842326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.56 | sMAPE for Validation Set is: 7.14% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.27 | sMAPE for Test Set is: 8.87% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 17:18:27,132]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:18:31,263]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:18:31,485]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:18:32,476]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:18:40,380]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:18:41,283]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:18:45,535]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:18:49,703]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:18:56,861]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:18:57,283]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:19:00,334]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:19:02,873]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:19:09,885]\u001b[0m Trial 1501 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:19:16,919]\u001b[0m Trial 1500 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:19:21,917]\u001b[0m Trial 1503 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:19:25,053]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 17:19:32,995]\u001b[0m Trial 1502 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-01-01, MAE is:11.57 & sMAPE is:39.22% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :11.57 & 39.22% & 0.51\n",
      "for 2018-01-02, MAE is:5.66 & sMAPE is:13.93% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :8.61 & 26.58% & 0.51\n",
      "for 2018-01-03, MAE is:3.25 & sMAPE is:7.79% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 20.31% & 0.54\n",
      "WARNING:tensorflow:5 out of the last 28 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001EC9D1A24C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "for 2018-01-04, MAE is:5.66 & sMAPE is:12.90% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :6.54 & 18.46% & 0.59\n",
      "WARNING:tensorflow:6 out of the last 29 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001EBC1F19EE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "for 2018-01-05, MAE is:8.57 & sMAPE is:23.53% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 19.47% & 0.71\n",
      "for 2018-01-06, MAE is:9.13 & sMAPE is:18.70% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :7.31 & 19.35% & 0.83\n",
      "for 2018-01-07, MAE is:9.72 & sMAPE is:21.67% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :7.65 & 19.68% & 0.77\n",
      "for 2018-01-08, MAE is:4.72 & sMAPE is:7.71% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :7.29 & 18.18% & 0.69\n",
      "for 2018-01-09, MAE is:17.58 & sMAPE is:25.98% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :8.43 & 19.05% & 0.72\n",
      "for 2018-01-10, MAE is:12.29 & sMAPE is:20.33% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :8.82 & 19.18% & 0.78\n",
      "for 2018-01-11, MAE is:3.57 & sMAPE is:7.63% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :8.34 & 18.13% & 0.75\n",
      "for 2018-01-12, MAE is:3.51 & sMAPE is:6.17% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :7.94 & 17.13% & 0.70\n",
      "for 2018-01-13, MAE is:2.70 & sMAPE is:4.93% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :7.53 & 16.19% & 0.67\n",
      "for 2018-01-14, MAE is:4.37 & sMAPE is:8.22% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :7.31 & 15.62% & 0.67\n",
      "for 2018-01-15, MAE is:6.55 & sMAPE is:10.54% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :7.26 & 15.28% & 0.69\n",
      "for 2018-01-16, MAE is:4.72 & sMAPE is:9.07% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :7.10 & 14.90% & 0.69\n",
      "for 2018-01-17, MAE is:3.49 & sMAPE is:6.84% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 14.42% & 0.67\n",
      "for 2018-01-18, MAE is:2.07 & sMAPE is:3.72% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 13.83% & 0.65\n",
      "for 2018-01-19, MAE is:3.05 & sMAPE is:5.56% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.43 & 13.39% & 0.65\n",
      "for 2018-01-20, MAE is:5.16 & sMAPE is:10.22% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.37 & 13.23% & 0.65\n",
      "for 2018-01-21, MAE is:5.80 & sMAPE is:12.80% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :6.34 & 13.21% & 0.66\n",
      "for 2018-01-22, MAE is:3.62 & sMAPE is:6.56% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.22 & 12.91% & 0.67\n",
      "for 2018-01-23, MAE is:3.42 & sMAPE is:6.62% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 12.64% & 0.67\n",
      "for 2018-01-24, MAE is:4.32 & sMAPE is:7.48% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.02 & 12.42% & 0.66\n",
      "for 2018-01-25, MAE is:4.10 & sMAPE is:7.65% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :5.94 & 12.23% & 0.67\n",
      "for 2018-01-26, MAE is:4.32 & sMAPE is:8.89% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 12.10% & 0.67\n",
      "for 2018-01-27, MAE is:4.79 & sMAPE is:10.12% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :5.84 & 12.03% & 0.68\n",
      "for 2018-01-28, MAE is:2.68 & sMAPE is:5.49% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :5.73 & 11.80% & 0.68\n",
      "for 2018-01-29, MAE is:4.76 & sMAPE is:9.13% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :5.69 & 11.70% & 0.72\n",
      "for 2018-01-30, MAE is:2.32 & sMAPE is:4.43% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :5.58 & 11.46% & 0.72\n",
      "for 2018-01-31, MAE is:2.20 & sMAPE is:4.03% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :5.47 & 11.22% & 0.72\n",
      "for 2018-02-01, MAE is:5.88 & sMAPE is:10.50% & rMAE is:1.82 ||| daily mean of MAE & sMAPE & rMAE till now are :5.49 & 11.20% & 0.76\n",
      "for 2018-02-02, MAE is:4.13 & sMAPE is:8.41% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :5.44 & 11.11% & 0.79\n",
      "for 2018-02-03, MAE is:4.02 & sMAPE is:8.06% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :5.40 & 11.02% & 0.79\n",
      "for 2018-02-04, MAE is:7.80 & sMAPE is:16.05% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :5.47 & 11.17% & 0.81\n",
      "for 2018-02-05, MAE is:3.81 & sMAPE is:6.68% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :5.43 & 11.04% & 0.83\n",
      "for 2018-02-06, MAE is:3.51 & sMAPE is:6.69% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :5.37 & 10.93% & 0.85\n",
      "for 2018-02-07, MAE is:3.75 & sMAPE is:6.77% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :5.33 & 10.82% & 0.85\n",
      "for 2018-02-08, MAE is:2.26 & sMAPE is:3.69% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :5.25 & 10.63% & 0.83\n",
      "for 2018-02-09, MAE is:9.87 & sMAPE is:15.11% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :5.37 & 10.75% & 0.83\n",
      "for 2018-02-10, MAE is:4.03 & sMAPE is:7.74% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :5.33 & 10.67% & 0.84\n",
      "for 2018-02-11, MAE is:3.65 & sMAPE is:7.31% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :5.29 & 10.59% & 0.84\n",
      "for 2018-02-12, MAE is:4.51 & sMAPE is:8.42% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :5.28 & 10.54% & 0.85\n",
      "for 2018-02-13, MAE is:5.54 & sMAPE is:10.84% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :5.28 & 10.55% & 0.87\n",
      "for 2018-02-14, MAE is:3.36 & sMAPE is:7.07% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :5.24 & 10.47% & 0.86\n",
      "for 2018-02-15, MAE is:5.38 & sMAPE is:10.19% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :5.24 & 10.47% & 0.85\n",
      "for 2018-02-16, MAE is:5.29 & sMAPE is:9.77% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :5.24 & 10.45% & 0.87\n",
      "for 2018-02-17, MAE is:6.16 & sMAPE is:11.89% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :5.26 & 10.48% & 0.88\n",
      "for 2018-02-18, MAE is:4.49 & sMAPE is:9.09% & rMAE is:1.95 ||| daily mean of MAE & sMAPE & rMAE till now are :5.25 & 10.45% & 0.90\n",
      "for 2018-02-19, MAE is:2.50 & sMAPE is:4.52% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :5.19 & 10.33% & 0.90\n",
      "for 2018-02-20, MAE is:3.36 & sMAPE is:6.35% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :5.16 & 10.26% & 0.90\n",
      "for 2018-02-21, MAE is:4.14 & sMAPE is:8.20% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :5.14 & 10.22% & 0.91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-02-22, MAE is:3.37 & sMAPE is:6.41% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :5.10 & 10.14% & 0.92\n",
      "for 2018-02-23, MAE is:4.73 & sMAPE is:8.42% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :5.10 & 10.11% & 0.93\n",
      "for 2018-02-24, MAE is:6.28 & sMAPE is:11.33% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :5.12 & 10.13% & 0.92\n",
      "for 2018-02-25, MAE is:6.05 & sMAPE is:11.15% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :5.13 & 10.15% & 0.92\n",
      "for 2018-02-26, MAE is:4.33 & sMAPE is:7.57% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :5.12 & 10.11% & 0.93\n",
      "for 2018-02-27, MAE is:5.25 & sMAPE is:8.36% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :5.12 & 10.08% & 0.92\n",
      "for 2018-02-28, MAE is:6.76 & sMAPE is:11.28% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :5.15 & 10.10% & 0.92\n",
      "for 2018-03-01, MAE is:4.83 & sMAPE is:9.56% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :5.15 & 10.09% & 0.92\n",
      "for 2018-03-02, MAE is:7.57 & sMAPE is:15.18% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :5.19 & 10.17% & 0.92\n",
      "for 2018-03-03, MAE is:4.60 & sMAPE is:10.10% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :5.18 & 10.17% & 0.91\n",
      "for 2018-03-04, MAE is:3.26 & sMAPE is:7.23% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :5.15 & 10.12% & 0.90\n",
      "for 2018-03-05, MAE is:5.28 & sMAPE is:13.03% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :5.15 & 10.17% & 0.90\n",
      "for 2018-03-06, MAE is:2.76 & sMAPE is:5.79% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :5.11 & 10.10% & 0.89\n",
      "for 2018-03-07, MAE is:3.20 & sMAPE is:6.77% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :5.08 & 10.05% & 0.88\n",
      "for 2018-03-08, MAE is:3.48 & sMAPE is:7.45% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :5.06 & 10.01% & 0.88\n",
      "for 2018-03-09, MAE is:4.66 & sMAPE is:10.01% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :5.05 & 10.01% & 0.87\n",
      "for 2018-03-10, MAE is:3.61 & sMAPE is:10.98% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :5.03 & 10.03% & 0.86\n",
      "for 2018-03-11, MAE is:19.43 & sMAPE is:117.60% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :5.24 & 11.56% & 0.86\n",
      "for 2018-03-12, MAE is:9.90 & sMAPE is:30.78% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :5.30 & 11.83% & 0.86\n",
      "for 2018-03-13, MAE is:5.21 & sMAPE is:11.04% & rMAE is:1.77 ||| daily mean of MAE & sMAPE & rMAE till now are :5.30 & 11.82% & 0.87\n",
      "for 2018-03-14, MAE is:12.40 & sMAPE is:30.66% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :5.40 & 12.08% & 0.87\n",
      "for 2018-03-15, MAE is:6.65 & sMAPE is:29.55% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :5.42 & 12.32% & 0.86\n",
      "for 2018-03-16, MAE is:6.82 & sMAPE is:17.16% & rMAE is:1.99 ||| daily mean of MAE & sMAPE & rMAE till now are :5.43 & 12.38% & 0.88\n",
      "for 2018-03-17, MAE is:8.55 & sMAPE is:19.87% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :5.48 & 12.48% & 0.88\n",
      "for 2018-03-18, MAE is:6.54 & sMAPE is:16.24% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :5.49 & 12.53% & 0.87\n",
      "for 2018-03-19, MAE is:4.54 & sMAPE is:10.50% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :5.48 & 12.50% & 0.86\n",
      "for 2018-03-20, MAE is:5.82 & sMAPE is:14.10% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :5.48 & 12.52% & 0.86\n",
      "for 2018-03-21, MAE is:4.31 & sMAPE is:9.38% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :5.47 & 12.48% & 0.85\n",
      "for 2018-03-22, MAE is:2.58 & sMAPE is:5.16% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :5.43 & 12.39% & 0.84\n",
      "for 2018-03-23, MAE is:5.15 & sMAPE is:10.86% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :5.43 & 12.37% & 0.85\n",
      "for 2018-03-24, MAE is:15.89 & sMAPE is:59.33% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :5.55 & 12.94% & 0.85\n",
      "for 2018-03-25, MAE is:17.09 & sMAPE is:50.38% & rMAE is:4.05 ||| daily mean of MAE & sMAPE & rMAE till now are :5.69 & 13.39% & 0.89\n",
      "for 2018-03-26, MAE is:3.37 & sMAPE is:6.95% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :5.66 & 13.31% & 0.88\n",
      "for 2018-03-27, MAE is:5.42 & sMAPE is:11.64% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :5.66 & 13.29% & 0.88\n",
      "for 2018-03-28, MAE is:2.93 & sMAPE is:6.63% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :5.63 & 13.21% & 0.88\n",
      "for 2018-03-29, MAE is:15.09 & sMAPE is:46.23% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :5.74 & 13.59% & 0.87\n",
      "for 2018-03-30, MAE is:20.76 & sMAPE is:139.78% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 15.01% & 0.87\n",
      "for 2018-03-31, MAE is:9.21 & sMAPE is:78.97% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :5.94 & 15.72% & 0.87\n",
      "for 2018-04-01, MAE is:3.21 & sMAPE is:13.30% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 15.69% & 0.86\n",
      "for 2018-04-02, MAE is:12.34 & sMAPE is:35.94% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :5.98 & 15.91% & 0.86\n",
      "for 2018-04-03, MAE is:7.82 & sMAPE is:25.69% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 16.02% & 0.85\n",
      "for 2018-04-04, MAE is:3.87 & sMAPE is:13.02% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :5.98 & 15.98% & 0.85\n",
      "for 2018-04-05, MAE is:11.29 & sMAPE is:27.45% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.03 & 16.11% & 0.85\n",
      "for 2018-04-06, MAE is:12.57 & sMAPE is:29.68% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.10 & 16.25% & 0.84\n",
      "for 2018-04-07, MAE is:4.03 & sMAPE is:9.87% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 16.18% & 0.83\n",
      "for 2018-04-08, MAE is:7.43 & sMAPE is:21.42% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :6.10 & 16.23% & 0.84\n",
      "for 2018-04-09, MAE is:8.35 & sMAPE is:19.14% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.12 & 16.26% & 0.83\n",
      "for 2018-04-10, MAE is:4.09 & sMAPE is:10.00% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.10 & 16.20% & 0.83\n",
      "for 2018-04-11, MAE is:9.50 & sMAPE is:21.91% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :6.13 & 16.26% & 0.83\n",
      "for 2018-04-12, MAE is:6.82 & sMAPE is:15.48% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :6.14 & 16.25% & 0.83\n",
      "for 2018-04-13, MAE is:6.64 & sMAPE is:12.18% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.14 & 16.21% & 0.82\n",
      "for 2018-04-14, MAE is:3.57 & sMAPE is:7.22% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :6.12 & 16.12% & 0.82\n",
      "for 2018-04-15, MAE is:5.17 & sMAPE is:13.07% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :6.11 & 16.10% & 0.82\n",
      "for 2018-04-16, MAE is:5.52 & sMAPE is:11.40% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.10 & 16.05% & 0.83\n",
      "for 2018-04-17, MAE is:4.84 & sMAPE is:9.57% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 15.99% & 0.82\n",
      "for 2018-04-18, MAE is:4.10 & sMAPE is:7.71% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 15.91% & 0.82\n",
      "for 2018-04-19, MAE is:2.50 & sMAPE is:5.37% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 15.82% & 0.82\n",
      "for 2018-04-20, MAE is:3.89 & sMAPE is:9.45% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.02 & 15.76% & 0.81\n",
      "for 2018-04-21, MAE is:2.55 & sMAPE is:6.64% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :5.99 & 15.68% & 0.81\n",
      "for 2018-04-22, MAE is:7.32 & sMAPE is:19.26% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 15.71% & 0.81\n",
      "for 2018-04-23, MAE is:10.01 & sMAPE is:22.49% & rMAE is:1.96 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 15.77% & 0.82\n",
      "for 2018-04-24, MAE is:1.75 & sMAPE is:3.70% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 15.66% & 0.82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-04-25, MAE is:3.97 & sMAPE is:8.60% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :5.98 & 15.60% & 0.82\n",
      "for 2018-04-26, MAE is:5.54 & sMAPE is:11.94% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :5.98 & 15.57% & 0.82\n",
      "for 2018-04-27, MAE is:3.69 & sMAPE is:7.29% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :5.96 & 15.50% & 0.81\n",
      "for 2018-04-28, MAE is:4.75 & sMAPE is:11.31% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :5.95 & 15.46% & 0.81\n",
      "for 2018-04-29, MAE is:12.70 & sMAPE is:48.13% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :6.01 & 15.74% & 0.81\n",
      "for 2018-04-30, MAE is:5.71 & sMAPE is:13.87% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 15.72% & 0.82\n",
      "for 2018-05-01, MAE is:4.79 & sMAPE is:11.93% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :5.99 & 15.69% & 0.81\n",
      "for 2018-05-02, MAE is:2.32 & sMAPE is:5.28% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :5.96 & 15.61% & 0.81\n",
      "for 2018-05-03, MAE is:6.07 & sMAPE is:13.16% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :5.96 & 15.59% & 0.81\n",
      "for 2018-05-04, MAE is:2.82 & sMAPE is:6.91% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :5.94 & 15.52% & 0.81\n",
      "for 2018-05-05, MAE is:2.72 & sMAPE is:6.08% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 15.44% & 0.81\n",
      "for 2018-05-06, MAE is:7.14 & sMAPE is:16.28% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :5.92 & 15.45% & 0.80\n",
      "for 2018-05-07, MAE is:6.93 & sMAPE is:13.29% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :5.93 & 15.43% & 0.80\n",
      "for 2018-05-08, MAE is:2.38 & sMAPE is:4.34% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :5.90 & 15.34% & 0.80\n",
      "for 2018-05-09, MAE is:2.30 & sMAPE is:4.29% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :5.87 & 15.26% & 0.79\n",
      "for 2018-05-10, MAE is:6.87 & sMAPE is:13.55% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 15.25% & 0.79\n",
      "for 2018-05-11, MAE is:2.56 & sMAPE is:4.46% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :5.86 & 15.16% & 0.79\n",
      "for 2018-05-12, MAE is:10.95 & sMAPE is:23.49% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :5.90 & 15.23% & 0.79\n",
      "for 2018-05-13, MAE is:2.58 & sMAPE is:6.76% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :5.87 & 15.16% & 0.78\n",
      "for 2018-05-14, MAE is:1.93 & sMAPE is:3.73% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :5.84 & 15.08% & 0.78\n",
      "for 2018-05-15, MAE is:3.15 & sMAPE is:6.68% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :5.82 & 15.01% & 0.78\n",
      "for 2018-05-16, MAE is:4.88 & sMAPE is:9.68% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :5.81 & 14.98% & 0.78\n",
      "for 2018-05-17, MAE is:3.51 & sMAPE is:6.70% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :5.80 & 14.92% & 0.78\n",
      "for 2018-05-18, MAE is:2.98 & sMAPE is:5.38% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :5.78 & 14.85% & 0.78\n",
      "for 2018-05-19, MAE is:4.53 & sMAPE is:7.91% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :5.77 & 14.80% & 0.78\n",
      "for 2018-05-20, MAE is:4.54 & sMAPE is:8.12% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :5.76 & 14.75% & 0.78\n",
      "for 2018-05-21, MAE is:4.42 & sMAPE is:7.44% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :5.75 & 14.70% & 0.77\n",
      "for 2018-05-22, MAE is:2.79 & sMAPE is:4.40% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :5.73 & 14.62% & 0.77\n",
      "for 2018-05-23, MAE is:1.75 & sMAPE is:2.72% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :5.70 & 14.54% & 0.77\n",
      "for 2018-05-24, MAE is:3.13 & sMAPE is:4.75% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :5.68 & 14.47% & 0.76\n",
      "for 2018-05-25, MAE is:4.01 & sMAPE is:6.50% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :5.67 & 14.42% & 0.76\n",
      "for 2018-05-26, MAE is:2.56 & sMAPE is:4.28% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :5.65 & 14.35% & 0.76\n",
      "for 2018-05-27, MAE is:4.04 & sMAPE is:6.82% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :5.64 & 14.30% & 0.76\n",
      "for 2018-05-28, MAE is:1.91 & sMAPE is:3.20% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :5.61 & 14.22% & 0.76\n",
      "for 2018-05-29, MAE is:3.59 & sMAPE is:5.76% & rMAE is:1.77 ||| daily mean of MAE & sMAPE & rMAE till now are :5.60 & 14.17% & 0.77\n",
      "for 2018-05-30, MAE is:2.01 & sMAPE is:3.21% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :5.58 & 14.09% & 0.78\n",
      "for 2018-05-31, MAE is:3.73 & sMAPE is:6.11% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :5.56 & 14.04% & 0.78\n",
      "for 2018-06-01, MAE is:3.42 & sMAPE is:5.42% & rMAE is:2.14 ||| daily mean of MAE & sMAPE & rMAE till now are :5.55 & 13.98% & 0.79\n",
      "for 2018-06-02, MAE is:3.15 & sMAPE is:5.32% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :5.53 & 13.93% & 0.79\n",
      "for 2018-06-03, MAE is:4.53 & sMAPE is:8.23% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :5.53 & 13.89% & 0.79\n",
      "for 2018-06-04, MAE is:2.88 & sMAPE is:4.93% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :5.51 & 13.83% & 0.79\n",
      "for 2018-06-05, MAE is:1.41 & sMAPE is:2.44% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :5.48 & 13.76% & 0.79\n",
      "for 2018-06-06, MAE is:5.09 & sMAPE is:8.74% & rMAE is:1.90 ||| daily mean of MAE & sMAPE & rMAE till now are :5.48 & 13.73% & 0.80\n",
      "for 2018-06-07, MAE is:2.45 & sMAPE is:4.05% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :5.46 & 13.67% & 0.80\n",
      "for 2018-06-08, MAE is:1.97 & sMAPE is:3.08% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :5.44 & 13.60% & 0.80\n",
      "for 2018-06-09, MAE is:2.42 & sMAPE is:4.25% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :5.42 & 13.54% & 0.80\n",
      "for 2018-06-10, MAE is:2.39 & sMAPE is:4.21% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :5.40 & 13.48% & 0.80\n",
      "for 2018-06-11, MAE is:2.05 & sMAPE is:3.70% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :5.38 & 13.42% & 0.80\n",
      "for 2018-06-12, MAE is:3.64 & sMAPE is:6.52% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :5.37 & 13.38% & 0.80\n",
      "for 2018-06-13, MAE is:2.01 & sMAPE is:3.95% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :5.35 & 13.32% & 0.80\n",
      "for 2018-06-14, MAE is:5.50 & sMAPE is:10.28% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :5.35 & 13.30% & 0.80\n",
      "for 2018-06-15, MAE is:2.43 & sMAPE is:4.11% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :5.33 & 13.25% & 0.80\n",
      "for 2018-06-16, MAE is:3.52 & sMAPE is:6.94% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :5.32 & 13.21% & 0.80\n",
      "for 2018-06-17, MAE is:3.73 & sMAPE is:7.76% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.31 & 13.18% & 0.80\n",
      "for 2018-06-18, MAE is:5.93 & sMAPE is:11.41% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :5.32 & 13.17% & 0.80\n",
      "for 2018-06-19, MAE is:4.97 & sMAPE is:9.27% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :5.32 & 13.14% & 0.80\n",
      "for 2018-06-20, MAE is:4.99 & sMAPE is:8.63% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :5.31 & 13.12% & 0.80\n",
      "for 2018-06-21, MAE is:3.01 & sMAPE is:5.18% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :5.30 & 13.07% & 0.80\n",
      "for 2018-06-22, MAE is:2.19 & sMAPE is:3.73% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :5.28 & 13.02% & 0.80\n",
      "for 2018-06-23, MAE is:4.49 & sMAPE is:8.08% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :5.28 & 12.99% & 0.80\n",
      "for 2018-06-24, MAE is:7.04 & sMAPE is:12.95% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :5.29 & 12.99% & 0.80\n",
      "for 2018-06-25, MAE is:2.90 & sMAPE is:5.04% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :5.27 & 12.94% & 0.80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-06-26, MAE is:3.87 & sMAPE is:6.67% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :5.27 & 12.91% & 0.80\n",
      "for 2018-06-27, MAE is:2.42 & sMAPE is:4.05% & rMAE is:2.12 ||| daily mean of MAE & sMAPE & rMAE till now are :5.25 & 12.86% & 0.80\n",
      "for 2018-06-28, MAE is:1.78 & sMAPE is:2.91% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :5.23 & 12.80% & 0.81\n",
      "for 2018-06-29, MAE is:3.70 & sMAPE is:6.35% & rMAE is:1.81 ||| daily mean of MAE & sMAPE & rMAE till now are :5.22 & 12.77% & 0.81\n",
      "for 2018-06-30, MAE is:3.10 & sMAPE is:5.40% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :5.21 & 12.73% & 0.81\n",
      "for 2018-07-01, MAE is:3.46 & sMAPE is:6.18% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :5.20 & 12.69% & 0.81\n",
      "for 2018-07-02, MAE is:4.03 & sMAPE is:6.51% & rMAE is:2.35 ||| daily mean of MAE & sMAPE & rMAE till now are :5.19 & 12.66% & 0.82\n",
      "for 2018-07-03, MAE is:1.98 & sMAPE is:3.33% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :5.18 & 12.61% & 0.82\n",
      "for 2018-07-04, MAE is:3.05 & sMAPE is:5.11% & rMAE is:1.79 ||| daily mean of MAE & sMAPE & rMAE till now are :5.17 & 12.57% & 0.83\n",
      "for 2018-07-05, MAE is:2.32 & sMAPE is:3.90% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :5.15 & 12.52% & 0.83\n",
      "for 2018-07-06, MAE is:2.70 & sMAPE is:4.76% & rMAE is:2.06 ||| daily mean of MAE & sMAPE & rMAE till now are :5.14 & 12.48% & 0.83\n",
      "for 2018-07-07, MAE is:5.78 & sMAPE is:10.13% & rMAE is:2.27 ||| daily mean of MAE & sMAPE & rMAE till now are :5.14 & 12.47% & 0.84\n",
      "for 2018-07-08, MAE is:3.55 & sMAPE is:6.33% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :5.13 & 12.43% & 0.84\n",
      "for 2018-07-09, MAE is:2.15 & sMAPE is:3.71% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :5.12 & 12.39% & 0.84\n",
      "for 2018-07-10, MAE is:1.83 & sMAPE is:3.21% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :5.10 & 12.34% & 0.85\n",
      "for 2018-07-11, MAE is:1.96 & sMAPE is:3.30% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :5.08 & 12.29% & 0.84\n",
      "for 2018-07-12, MAE is:2.90 & sMAPE is:4.84% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :5.07 & 12.25% & 0.84\n",
      "for 2018-07-13, MAE is:2.73 & sMAPE is:4.53% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :5.06 & 12.21% & 0.84\n",
      "for 2018-07-14, MAE is:6.63 & sMAPE is:11.37% & rMAE is:4.01 ||| daily mean of MAE & sMAPE & rMAE till now are :5.07 & 12.21% & 0.86\n",
      "for 2018-07-15, MAE is:5.15 & sMAPE is:8.94% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :5.07 & 12.19% & 0.86\n",
      "for 2018-07-16, MAE is:2.34 & sMAPE is:3.82% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :5.05 & 12.15% & 0.86\n",
      "for 2018-07-17, MAE is:2.40 & sMAPE is:4.08% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :5.04 & 12.11% & 0.86\n",
      "for 2018-07-18, MAE is:3.69 & sMAPE is:6.07% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :5.03 & 12.08% & 0.87\n",
      "for 2018-07-19, MAE is:2.58 & sMAPE is:4.11% & rMAE is:1.75 ||| daily mean of MAE & sMAPE & rMAE till now are :5.02 & 12.04% & 0.87\n",
      "for 2018-07-20, MAE is:1.59 & sMAPE is:2.63% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :5.01 & 11.99% & 0.87\n",
      "for 2018-07-21, MAE is:8.12 & sMAPE is:14.21% & rMAE is:5.29 ||| daily mean of MAE & sMAPE & rMAE till now are :5.02 & 12.00% & 0.89\n",
      "for 2018-07-22, MAE is:1.80 & sMAPE is:3.05% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :5.00 & 11.96% & 0.89\n",
      "for 2018-07-23, MAE is:2.01 & sMAPE is:3.48% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.99 & 11.92% & 0.89\n",
      "for 2018-07-24, MAE is:2.22 & sMAPE is:3.62% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :4.98 & 11.88% & 0.89\n",
      "for 2018-07-25, MAE is:1.89 & sMAPE is:3.08% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :4.96 & 11.83% & 0.90\n",
      "for 2018-07-26, MAE is:2.40 & sMAPE is:3.81% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :4.95 & 11.80% & 0.90\n",
      "for 2018-07-27, MAE is:2.47 & sMAPE is:3.98% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :4.94 & 11.76% & 0.90\n",
      "for 2018-07-28, MAE is:9.40 & sMAPE is:16.10% & rMAE is:4.73 ||| daily mean of MAE & sMAPE & rMAE till now are :4.96 & 11.78% & 0.92\n",
      "for 2018-07-29, MAE is:3.52 & sMAPE is:5.81% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :4.95 & 11.75% & 0.92\n",
      "for 2018-07-30, MAE is:1.88 & sMAPE is:3.17% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :4.94 & 11.71% & 0.92\n",
      "for 2018-07-31, MAE is:2.53 & sMAPE is:3.99% & rMAE is:2.11 ||| daily mean of MAE & sMAPE & rMAE till now are :4.93 & 11.67% & 0.93\n",
      "for 2018-08-01, MAE is:1.96 & sMAPE is:3.14% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :4.91 & 11.63% & 0.93\n",
      "for 2018-08-02, MAE is:3.76 & sMAPE is:5.93% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :4.91 & 11.61% & 0.93\n",
      "for 2018-08-03, MAE is:4.63 & sMAPE is:7.20% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :4.91 & 11.59% & 0.93\n",
      "for 2018-08-04, MAE is:5.25 & sMAPE is:8.49% & rMAE is:2.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.91 & 11.57% & 0.94\n",
      "for 2018-08-05, MAE is:4.97 & sMAPE is:8.22% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :4.91 & 11.56% & 0.94\n",
      "for 2018-08-06, MAE is:2.31 & sMAPE is:3.47% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 11.52% & 0.94\n",
      "for 2018-08-07, MAE is:2.78 & sMAPE is:4.38% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :4.89 & 11.49% & 0.94\n",
      "for 2018-08-08, MAE is:2.38 & sMAPE is:3.86% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 11.45% & 0.94\n",
      "for 2018-08-09, MAE is:3.79 & sMAPE is:5.80% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 11.43% & 0.94\n",
      "for 2018-08-10, MAE is:6.03 & sMAPE is:9.42% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 11.42% & 0.94\n",
      "for 2018-08-11, MAE is:3.71 & sMAPE is:6.12% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 11.39% & 0.94\n",
      "for 2018-08-12, MAE is:3.19 & sMAPE is:5.38% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.86 & 11.37% & 0.94\n",
      "for 2018-08-13, MAE is:2.39 & sMAPE is:3.76% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.85 & 11.33% & 0.94\n",
      "for 2018-08-14, MAE is:2.13 & sMAPE is:3.47% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :4.84 & 11.30% & 0.94\n",
      "for 2018-08-15, MAE is:4.04 & sMAPE is:6.93% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :4.84 & 11.28% & 0.94\n",
      "for 2018-08-16, MAE is:2.21 & sMAPE is:3.51% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :4.82 & 11.24% & 0.94\n",
      "for 2018-08-17, MAE is:3.33 & sMAPE is:5.50% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :4.82 & 11.22% & 0.94\n",
      "for 2018-08-18, MAE is:4.49 & sMAPE is:7.99% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.82 & 11.21% & 0.94\n",
      "for 2018-08-19, MAE is:4.98 & sMAPE is:8.72% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :4.82 & 11.19% & 0.93\n",
      "for 2018-08-20, MAE is:3.66 & sMAPE is:5.92% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :4.81 & 11.17% & 0.94\n",
      "for 2018-08-21, MAE is:3.90 & sMAPE is:6.02% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :4.81 & 11.15% & 0.93\n",
      "for 2018-08-22, MAE is:4.70 & sMAPE is:7.09% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :4.81 & 11.13% & 0.93\n",
      "for 2018-08-23, MAE is:3.96 & sMAPE is:5.68% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 11.11% & 0.93\n",
      "for 2018-08-24, MAE is:3.14 & sMAPE is:4.82% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 11.08% & 0.93\n",
      "for 2018-08-25, MAE is:1.48 & sMAPE is:2.41% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :4.78 & 11.05% & 0.93\n",
      "for 2018-08-26, MAE is:2.84 & sMAPE is:4.59% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :4.77 & 11.02% & 0.93\n",
      "for 2018-08-27, MAE is:5.38 & sMAPE is:7.65% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.78 & 11.01% & 0.93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-08-28, MAE is:2.13 & sMAPE is:3.17% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :4.77 & 10.97% & 0.93\n",
      "for 2018-08-29, MAE is:2.83 & sMAPE is:4.13% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :4.76 & 10.94% & 0.93\n",
      "for 2018-08-30, MAE is:2.68 & sMAPE is:3.96% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :4.75 & 10.92% & 0.93\n",
      "for 2018-08-31, MAE is:3.31 & sMAPE is:4.89% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :4.74 & 10.89% & 0.93\n",
      "for 2018-09-01, MAE is:3.35 & sMAPE is:5.21% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :4.74 & 10.87% & 0.93\n",
      "for 2018-09-02, MAE is:2.59 & sMAPE is:4.10% & rMAE is:2.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.73 & 10.84% & 0.94\n",
      "for 2018-09-03, MAE is:1.87 & sMAPE is:2.76% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.72 & 10.81% & 0.94\n",
      "for 2018-09-04, MAE is:1.34 & sMAPE is:1.92% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :4.70 & 10.77% & 0.93\n",
      "for 2018-09-05, MAE is:2.53 & sMAPE is:3.35% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 10.74% & 0.93\n",
      "for 2018-09-06, MAE is:7.27 & sMAPE is:9.66% & rMAE is:2.69 ||| daily mean of MAE & sMAPE & rMAE till now are :4.71 & 10.74% & 0.94\n",
      "for 2018-09-07, MAE is:3.85 & sMAPE is:5.70% & rMAE is:2.92 ||| daily mean of MAE & sMAPE & rMAE till now are :4.70 & 10.72% & 0.95\n",
      "for 2018-09-08, MAE is:2.70 & sMAPE is:3.97% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 10.69% & 0.95\n",
      "for 2018-09-09, MAE is:3.30 & sMAPE is:4.80% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 10.67% & 0.94\n",
      "for 2018-09-10, MAE is:2.33 & sMAPE is:3.26% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 10.64% & 0.94\n",
      "for 2018-09-11, MAE is:2.93 & sMAPE is:4.01% & rMAE is:2.86 ||| daily mean of MAE & sMAPE & rMAE till now are :4.67 & 10.61% & 0.95\n",
      "for 2018-09-12, MAE is:2.24 & sMAPE is:3.02% & rMAE is:2.45 ||| daily mean of MAE & sMAPE & rMAE till now are :4.66 & 10.58% & 0.96\n",
      "for 2018-09-13, MAE is:3.09 & sMAPE is:4.06% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :4.66 & 10.56% & 0.96\n",
      "for 2018-09-14, MAE is:2.24 & sMAPE is:3.14% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :4.65 & 10.53% & 0.96\n",
      "for 2018-09-15, MAE is:2.54 & sMAPE is:3.70% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.64 & 10.50% & 0.96\n",
      "for 2018-09-16, MAE is:2.83 & sMAPE is:4.11% & rMAE is:2.61 ||| daily mean of MAE & sMAPE & rMAE till now are :4.63 & 10.48% & 0.96\n",
      "for 2018-09-17, MAE is:4.20 & sMAPE is:5.67% & rMAE is:2.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.63 & 10.46% & 0.97\n",
      "for 2018-09-18, MAE is:3.52 & sMAPE is:4.57% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :4.63 & 10.43% & 0.97\n",
      "for 2018-09-19, MAE is:2.36 & sMAPE is:3.13% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :4.62 & 10.41% & 0.97\n",
      "for 2018-09-20, MAE is:3.01 & sMAPE is:4.01% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :4.61 & 10.38% & 0.97\n",
      "for 2018-09-21, MAE is:2.02 & sMAPE is:2.76% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :4.60 & 10.35% & 0.97\n",
      "for 2018-09-22, MAE is:2.77 & sMAPE is:3.93% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :4.59 & 10.33% & 0.97\n",
      "for 2018-09-23, MAE is:4.45 & sMAPE is:6.55% & rMAE is:1.85 ||| daily mean of MAE & sMAPE & rMAE till now are :4.59 & 10.31% & 0.98\n",
      "for 2018-09-24, MAE is:4.82 & sMAPE is:7.45% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :4.59 & 10.30% & 0.97\n",
      "for 2018-09-25, MAE is:4.79 & sMAPE is:7.46% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :4.60 & 10.29% & 0.97\n",
      "for 2018-09-26, MAE is:2.87 & sMAPE is:4.11% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :4.59 & 10.27% & 0.97\n",
      "for 2018-09-27, MAE is:2.52 & sMAPE is:3.48% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :4.58 & 10.25% & 0.97\n",
      "for 2018-09-28, MAE is:2.51 & sMAPE is:3.36% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 10.22% & 0.97\n",
      "for 2018-09-29, MAE is:3.33 & sMAPE is:4.81% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 10.20% & 0.97\n",
      "for 2018-09-30, MAE is:3.26 & sMAPE is:4.69% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :4.56 & 10.18% & 0.97\n",
      "for 2018-10-01, MAE is:7.17 & sMAPE is:10.57% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 10.18% & 0.97\n",
      "for 2018-10-02, MAE is:2.82 & sMAPE is:4.27% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 10.16% & 0.97\n",
      "for 2018-10-03, MAE is:2.77 & sMAPE is:4.01% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :4.56 & 10.14% & 0.97\n",
      "for 2018-10-04, MAE is:3.21 & sMAPE is:4.42% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :4.56 & 10.12% & 0.98\n",
      "for 2018-10-05, MAE is:4.42 & sMAPE is:6.07% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :4.56 & 10.10% & 0.98\n",
      "for 2018-10-06, MAE is:5.69 & sMAPE is:8.48% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :4.56 & 10.10% & 0.98\n",
      "for 2018-10-07, MAE is:4.72 & sMAPE is:7.55% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :4.56 & 10.09% & 0.97\n",
      "for 2018-10-08, MAE is:4.51 & sMAPE is:6.97% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :4.56 & 10.08% & 0.97\n",
      "for 2018-10-09, MAE is:6.18 & sMAPE is:8.48% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 10.07% & 0.97\n",
      "for 2018-10-10, MAE is:4.67 & sMAPE is:6.87% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 10.06% & 0.97\n",
      "for 2018-10-11, MAE is:3.43 & sMAPE is:5.52% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :4.56 & 10.04% & 0.97\n",
      "for 2018-10-12, MAE is:7.62 & sMAPE is:11.74% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 10.05% & 0.97\n",
      "for 2018-10-13, MAE is:3.40 & sMAPE is:5.60% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 10.03% & 0.97\n",
      "for 2018-10-14, MAE is:12.12 & sMAPE is:21.69% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.60 & 10.07% & 0.97\n",
      "for 2018-10-15, MAE is:3.58 & sMAPE is:5.36% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :4.59 & 10.06% & 0.97\n",
      "for 2018-10-16, MAE is:4.19 & sMAPE is:6.35% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :4.59 & 10.05% & 0.97\n",
      "for 2018-10-17, MAE is:3.00 & sMAPE is:4.27% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :4.58 & 10.03% & 0.97\n",
      "for 2018-10-18, MAE is:4.66 & sMAPE is:6.91% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :4.59 & 10.01% & 0.97\n",
      "for 2018-10-19, MAE is:3.32 & sMAPE is:5.44% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :4.58 & 10.00% & 0.97\n",
      "for 2018-10-20, MAE is:3.46 & sMAPE is:5.76% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :4.58 & 9.98% & 0.97\n",
      "for 2018-10-21, MAE is:5.24 & sMAPE is:8.83% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :4.58 & 9.98% & 0.97\n",
      "for 2018-10-22, MAE is:8.30 & sMAPE is:12.20% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :4.59 & 9.99% & 0.97\n",
      "for 2018-10-23, MAE is:2.82 & sMAPE is:4.50% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :4.59 & 9.97% & 0.97\n",
      "for 2018-10-24, MAE is:2.18 & sMAPE is:3.43% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :4.58 & 9.95% & 0.97\n",
      "for 2018-10-25, MAE is:3.63 & sMAPE is:5.45% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 9.93% & 0.97\n",
      "for 2018-10-26, MAE is:4.24 & sMAPE is:6.32% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 9.92% & 0.97\n",
      "for 2018-10-27, MAE is:3.34 & sMAPE is:5.49% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 9.91% & 0.96\n",
      "for 2018-10-28, MAE is:3.32 & sMAPE is:6.04% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 9.89% & 0.96\n",
      "for 2018-10-29, MAE is:8.16 & sMAPE is:13.53% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :4.58 & 9.90% & 0.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-10-30, MAE is:3.87 & sMAPE is:5.99% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 9.89% & 0.97\n",
      "for 2018-10-31, MAE is:2.47 & sMAPE is:3.71% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 9.87% & 0.96\n",
      "for 2018-11-01, MAE is:6.85 & sMAPE is:10.54% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :4.58 & 9.87% & 0.96\n",
      "for 2018-11-02, MAE is:4.06 & sMAPE is:6.50% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 9.86% & 0.96\n",
      "for 2018-11-03, MAE is:2.15 & sMAPE is:3.31% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 9.84% & 0.96\n",
      "for 2018-11-04, MAE is:4.89 & sMAPE is:7.93% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 9.84% & 0.96\n",
      "for 2018-11-05, MAE is:3.68 & sMAPE is:6.39% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :4.56 & 9.82% & 0.96\n",
      "for 2018-11-06, MAE is:4.99 & sMAPE is:8.53% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 9.82% & 0.96\n",
      "for 2018-11-07, MAE is:4.94 & sMAPE is:8.55% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 9.82% & 0.96\n",
      "for 2018-11-08, MAE is:4.84 & sMAPE is:7.48% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 9.81% & 0.96\n",
      "for 2018-11-09, MAE is:5.34 & sMAPE is:9.01% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 9.81% & 0.96\n",
      "for 2018-11-10, MAE is:3.26 & sMAPE is:6.43% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 9.79% & 0.96\n",
      "for 2018-11-11, MAE is:6.21 & sMAPE is:11.52% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 9.80% & 0.95\n",
      "for 2018-11-12, MAE is:4.57 & sMAPE is:6.97% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 9.79% & 0.96\n",
      "for 2018-11-13, MAE is:3.84 & sMAPE is:6.02% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 9.78% & 0.95\n",
      "for 2018-11-14, MAE is:3.27 & sMAPE is:5.29% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :4.56 & 9.77% & 0.95\n",
      "for 2018-11-15, MAE is:2.72 & sMAPE is:4.46% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :4.56 & 9.75% & 0.95\n",
      "for 2018-11-16, MAE is:3.08 & sMAPE is:4.94% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.55 & 9.73% & 0.95\n",
      "for 2018-11-17, MAE is:4.46 & sMAPE is:7.63% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :4.55 & 9.73% & 0.95\n",
      "for 2018-11-18, MAE is:3.23 & sMAPE is:5.74% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.55 & 9.71% & 0.95\n",
      "for 2018-11-19, MAE is:3.95 & sMAPE is:6.14% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :4.55 & 9.70% & 0.95\n",
      "for 2018-11-20, MAE is:4.59 & sMAPE is:6.99% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :4.55 & 9.70% & 0.95\n",
      "for 2018-11-21, MAE is:4.01 & sMAPE is:5.94% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :4.55 & 9.68% & 0.95\n",
      "for 2018-11-22, MAE is:3.06 & sMAPE is:4.61% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :4.54 & 9.67% & 0.95\n",
      "for 2018-11-23, MAE is:3.29 & sMAPE is:4.97% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :4.54 & 9.65% & 0.95\n",
      "for 2018-11-24, MAE is:3.18 & sMAPE is:5.11% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :4.53 & 9.64% & 0.95\n",
      "for 2018-11-25, MAE is:6.61 & sMAPE is:11.66% & rMAE is:2.23 ||| daily mean of MAE & sMAPE & rMAE till now are :4.54 & 9.65% & 0.96\n",
      "for 2018-11-26, MAE is:6.47 & sMAPE is:10.21% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :4.55 & 9.65% & 0.96\n",
      "for 2018-11-27, MAE is:2.91 & sMAPE is:4.63% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :4.54 & 9.63% & 0.96\n",
      "for 2018-11-28, MAE is:3.28 & sMAPE is:5.35% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :4.54 & 9.62% & 0.96\n",
      "for 2018-11-29, MAE is:5.71 & sMAPE is:9.01% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :4.54 & 9.62% & 0.96\n",
      "for 2018-11-30, MAE is:2.83 & sMAPE is:4.52% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :4.54 & 9.60% & 0.96\n",
      "for 2018-12-01, MAE is:3.14 & sMAPE is:5.10% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :4.53 & 9.59% & 0.96\n",
      "for 2018-12-02, MAE is:2.62 & sMAPE is:4.62% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :4.53 & 9.57% & 0.96\n",
      "for 2018-12-03, MAE is:5.17 & sMAPE is:7.99% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :4.53 & 9.57% & 0.96\n",
      "for 2018-12-04, MAE is:4.59 & sMAPE is:6.85% & rMAE is:2.15 ||| daily mean of MAE & sMAPE & rMAE till now are :4.53 & 9.56% & 0.96\n",
      "for 2018-12-05, MAE is:5.20 & sMAPE is:7.78% & rMAE is:2.06 ||| daily mean of MAE & sMAPE & rMAE till now are :4.53 & 9.56% & 0.97\n",
      "for 2018-12-06, MAE is:5.27 & sMAPE is:8.18% & rMAE is:2.50 ||| daily mean of MAE & sMAPE & rMAE till now are :4.53 & 9.55% & 0.97\n",
      "for 2018-12-07, MAE is:4.32 & sMAPE is:7.23% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :4.53 & 9.55% & 0.97\n",
      "for 2018-12-08, MAE is:5.52 & sMAPE is:9.44% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.53 & 9.55% & 0.97\n",
      "for 2018-12-09, MAE is:3.50 & sMAPE is:6.08% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :4.53 & 9.54% & 0.97\n",
      "for 2018-12-10, MAE is:5.60 & sMAPE is:8.38% & rMAE is:2.59 ||| daily mean of MAE & sMAPE & rMAE till now are :4.53 & 9.53% & 0.98\n",
      "for 2018-12-11, MAE is:3.06 & sMAPE is:4.96% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :4.53 & 9.52% & 0.98\n",
      "for 2018-12-12, MAE is:2.41 & sMAPE is:3.87% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :4.52 & 9.50% & 0.98\n",
      "for 2018-12-13, MAE is:2.86 & sMAPE is:4.95% & rMAE is:1.94 ||| daily mean of MAE & sMAPE & rMAE till now are :4.52 & 9.49% & 0.98\n",
      "for 2018-12-14, MAE is:2.86 & sMAPE is:4.78% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :4.51 & 9.48% & 0.98\n",
      "for 2018-12-15, MAE is:2.83 & sMAPE is:4.63% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :4.51 & 9.46% & 0.98\n",
      "for 2018-12-16, MAE is:4.37 & sMAPE is:8.03% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :4.51 & 9.46% & 0.98\n",
      "for 2018-12-17, MAE is:3.71 & sMAPE is:6.11% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :4.51 & 9.45% & 0.98\n",
      "for 2018-12-18, MAE is:3.05 & sMAPE is:5.17% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :4.50 & 9.44% & 0.98\n",
      "for 2018-12-19, MAE is:3.04 & sMAPE is:5.20% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :4.50 & 9.42% & 0.98\n",
      "for 2018-12-20, MAE is:2.25 & sMAPE is:3.78% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :4.49 & 9.41% & 0.98\n",
      "for 2018-12-21, MAE is:4.92 & sMAPE is:7.82% & rMAE is:1.90 ||| daily mean of MAE & sMAPE & rMAE till now are :4.49 & 9.40% & 0.98\n",
      "for 2018-12-22, MAE is:6.12 & sMAPE is:10.39% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :4.50 & 9.41% & 0.98\n",
      "for 2018-12-23, MAE is:4.40 & sMAPE is:7.41% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :4.50 & 9.40% & 0.98\n",
      "for 2018-12-24, MAE is:4.22 & sMAPE is:6.84% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :4.50 & 9.39% & 0.98\n",
      "for 2018-12-25, MAE is:5.00 & sMAPE is:8.28% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :4.50 & 9.39% & 0.98\n",
      "for 2018-12-26, MAE is:3.84 & sMAPE is:6.12% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :4.50 & 9.38% & 0.98\n",
      "for 2018-12-27, MAE is:4.31 & sMAPE is:6.64% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :4.50 & 9.37% & 0.98\n",
      "for 2018-12-28, MAE is:3.98 & sMAPE is:6.09% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :4.49 & 9.36% & 0.98\n",
      "for 2018-12-29, MAE is:2.22 & sMAPE is:3.87% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.49 & 9.35% & 0.98\n",
      "for 2018-12-30, MAE is:3.26 & sMAPE is:5.81% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :4.49 & 9.34% & 0.98\n",
      "for 2018-12-31, MAE is:3.27 & sMAPE is:5.13% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :4.48 & 9.33% & 0.98\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\1 - Consolidated Data\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:18:16,087]\u001b[0m A new study created in RDB with name: PT_2019\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:18:33,633]\u001b[0m Trial 3 finished with value: 5.216076492765988 and parameters: {'n_hidden': 3, 'learning_rate': 0.01323238726198758, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25622383273345156, 'dropout_rate_Layer_2': 0.005098884899482581, 'dropout_rate_Layer_3': 0.047141780746872676, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.18831352096974e-05, 'l1_Layer_2': 0.007435635433768443, 'l1_Layer_3': 0.0012185894240321318, 'n_units_Layer_1': 70, 'n_units_Layer_2': 65, 'n_units_Layer_3': 110}. Best is trial 3 with value: 5.216076492765988.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.22 | sMAPE for Validation Set is: 10.55% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 5.21 | sMAPE for Test Set is: 12.76% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:18:33,943]\u001b[0m Trial 2 pruned. Trial was pruned at epoch 41.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:18:50,698]\u001b[0m Trial 0 finished with value: 5.115227914651238 and parameters: {'n_hidden': 4, 'learning_rate': 0.02007484932008388, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.044415245096769154, 'dropout_rate_Layer_2': 0.11910104091238556, 'dropout_rate_Layer_3': 0.051253769282095046, 'dropout_rate_Layer_4': 0.1809462724551633, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.009946052308726992, 'l1_Layer_2': 0.0022713642423640907, 'l1_Layer_3': 0.012826533689250479, 'l1_Layer_4': 6.762734042538209e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 65, 'n_units_Layer_3': 255, 'n_units_Layer_4': 175}. Best is trial 0 with value: 5.115227914651238.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.12 | sMAPE for Validation Set is: 10.40% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 4.87 | sMAPE for Test Set is: 11.95% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:18:53,713]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:18:54,363]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:18:58,828]\u001b[0m Trial 1 finished with value: 4.635385160495006 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006057624581857626, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11310926622804601, 'dropout_rate_Layer_2': 0.022064317366701627, 'dropout_rate_Layer_3': 0.0851106331865394, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00027208059683849004, 'l1_Layer_2': 0.03328438964966772, 'l1_Layer_3': 2.9369652834564934e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 255, 'n_units_Layer_3': 240}. Best is trial 1 with value: 4.635385160495006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.64 | sMAPE for Validation Set is: 9.50% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 4.30 | sMAPE for Test Set is: 11.06% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:18:59,045]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:19:05,077]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:19:07,294]\u001b[0m Trial 4 finished with value: 4.503075226898301 and parameters: {'n_hidden': 3, 'learning_rate': 0.01751959652209484, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13092563312359223, 'dropout_rate_Layer_2': 0.010620817480747969, 'dropout_rate_Layer_3': 0.38526147810603883, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 1.2278619626707089e-05, 'l1_Layer_2': 0.0005856921511731817, 'l1_Layer_3': 0.04280536342701388, 'n_units_Layer_1': 275, 'n_units_Layer_2': 100, 'n_units_Layer_3': 225}. Best is trial 4 with value: 4.503075226898301.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.50 | sMAPE for Validation Set is: 9.22% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 4.77 | sMAPE for Test Set is: 11.80% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:19:10,227]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:19:11,290]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:19:15,836]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:19:18,969]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:19:22,825]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:19:23,155]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:19:26,955]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:19:30,620]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:19:33,300]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:19:35,958]\u001b[0m Trial 18 finished with value: 5.59789575489318 and parameters: {'n_hidden': 3, 'learning_rate': 0.01803370903720303, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36943224251434603, 'dropout_rate_Layer_2': 0.2286514340260935, 'dropout_rate_Layer_3': 0.38115358585655396, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.011387018094178076, 'l1_Layer_2': 0.00036387532577464, 'l1_Layer_3': 7.925616906737226e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 215, 'n_units_Layer_3': 245}. Best is trial 4 with value: 4.503075226898301.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.60 | sMAPE for Validation Set is: 11.23% | rMAE for Validation Set is: 0.87\n",
      "MAE for Test Set is: 4.68 | sMAPE for Test Set is: 11.82% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:19:38,280]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:19:40,894]\u001b[0m Trial 7 finished with value: 13.29919530257611 and parameters: {'n_hidden': 4, 'learning_rate': 0.001972068689589486, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38935315907393236, 'dropout_rate_Layer_2': 0.32901063911559236, 'dropout_rate_Layer_3': 0.006466490903849875, 'dropout_rate_Layer_4': 0.13905616106389812, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00012501131217206566, 'l1_Layer_2': 6.253423524622358e-05, 'l1_Layer_3': 0.0033266153411418914, 'l1_Layer_4': 0.0004203637530291894, 'n_units_Layer_1': 280, 'n_units_Layer_2': 85, 'n_units_Layer_3': 175, 'n_units_Layer_4': 50}. Best is trial 4 with value: 4.503075226898301.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.30 | sMAPE for Validation Set is: 25.41% | rMAE for Validation Set is: 2.06\n",
      "MAE for Test Set is: 7.44 | sMAPE for Test Set is: 17.13% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:19:45,167]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:19:45,289]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:19:48,183]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:19:49,237]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:19:55,021]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:19:55,287]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:19:56,050]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:20:03,084]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:20:03,293]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:20:05,893]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:20:12,098]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:20:15,500]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:20:19,999]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:20:23,865]\u001b[0m Trial 34 finished with value: 4.55376142128442 and parameters: {'n_hidden': 4, 'learning_rate': 0.005965355581218905, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2723732227793169, 'dropout_rate_Layer_2': 0.19410337227161978, 'dropout_rate_Layer_3': 0.130932051970545, 'dropout_rate_Layer_4': 0.39751856377544237, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0007116022920212507, 'l1_Layer_2': 0.014030066412823118, 'l1_Layer_3': 1.1061195374989737e-05, 'l1_Layer_4': 0.09590747943414563, 'n_units_Layer_1': 100, 'n_units_Layer_2': 230, 'n_units_Layer_3': 95, 'n_units_Layer_4': 205}. Best is trial 4 with value: 4.503075226898301.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.55 | sMAPE for Validation Set is: 9.49% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 4.61 | sMAPE for Test Set is: 11.80% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:20:29,454]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:20:34,593]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:20:43,187]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:20:43,526]\u001b[0m Trial 33 finished with value: 6.112861861854071 and parameters: {'n_hidden': 3, 'learning_rate': 0.022132418377355332, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13146221826822196, 'dropout_rate_Layer_2': 0.015338895807417341, 'dropout_rate_Layer_3': 0.1371403269138692, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001575874392364475, 'l1_Layer_2': 0.00018445440512246, 'l1_Layer_3': 0.0038417864376509435, 'n_units_Layer_1': 190, 'n_units_Layer_2': 95, 'n_units_Layer_3': 160}. Best is trial 4 with value: 4.503075226898301.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.11 | sMAPE for Validation Set is: 12.07% | rMAE for Validation Set is: 0.95\n",
      "MAE for Test Set is: 5.54 | sMAPE for Test Set is: 13.53% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:20:48,799]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:20:52,818]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:20:56,750]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:20:56,844]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:21:01,985]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:21:05,339]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:21:06,638]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:21:13,044]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:21:13,285]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:21:20,235]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:21:23,447]\u001b[0m Trial 41 finished with value: 5.211082882252931 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019282259094113182, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24246034761422913, 'dropout_rate_Layer_2': 0.03634236279553953, 'dropout_rate_Layer_3': 0.3762940067597708, 'dropout_rate_Layer_4': 0.3568183762027155, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00021491477683852097, 'l1_Layer_2': 0.00038517922375780637, 'l1_Layer_3': 0.00029869756467732096, 'l1_Layer_4': 1.7000180833347625e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 145, 'n_units_Layer_3': 170, 'n_units_Layer_4': 195}. Best is trial 4 with value: 4.503075226898301.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.21 | sMAPE for Validation Set is: 10.88% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 4.91 | sMAPE for Test Set is: 12.38% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:21:23,713]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:21:27,627]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:21:30,674]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:21:35,246]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:21:41,811]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:21:44,698]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:21:47,396]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:21:52,450]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:21:57,427]\u001b[0m Trial 51 finished with value: 4.572724279451639 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007029874255287902, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3258394305754399, 'dropout_rate_Layer_2': 0.3003961796537166, 'dropout_rate_Layer_3': 0.16707719101614207, 'dropout_rate_Layer_4': 0.2295098313874025, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.008628898432378157, 'l1_Layer_2': 1.0125697235277217e-05, 'l1_Layer_3': 0.00010154152317967989, 'l1_Layer_4': 0.000266056424188107, 'n_units_Layer_1': 85, 'n_units_Layer_2': 210, 'n_units_Layer_3': 300, 'n_units_Layer_4': 285}. Best is trial 4 with value: 4.503075226898301.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.57 | sMAPE for Validation Set is: 9.50% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 4.39 | sMAPE for Test Set is: 11.22% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:22:02,132]\u001b[0m Trial 61 finished with value: 6.097322874353367 and parameters: {'n_hidden': 3, 'learning_rate': 0.023323723037317372, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2239601383485211, 'dropout_rate_Layer_2': 0.03301945230431211, 'dropout_rate_Layer_3': 0.3101114178909715, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0005885548321005151, 'l1_Layer_2': 7.825713929310002e-05, 'l1_Layer_3': 2.9257857564763763e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 200, 'n_units_Layer_3': 135}. Best is trial 4 with value: 4.503075226898301.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.10 | sMAPE for Validation Set is: 12.23% | rMAE for Validation Set is: 0.94\n",
      "MAE for Test Set is: 5.73 | sMAPE for Test Set is: 13.86% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:22:07,469]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:22:11,205]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:22:13,724]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:22:29,031]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:22:32,064]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:22:32,518]\u001b[0m Trial 32 finished with value: 4.278329991583386 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017581752706571317, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0023187460358632616, 'dropout_rate_Layer_2': 0.24490829037476256, 'dropout_rate_Layer_3': 0.05365190420715247, 'dropout_rate_Layer_4': 0.26812435060671097, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.002742526552428103, 'l1_Layer_2': 0.034153383599154784, 'l1_Layer_3': 0.003133924564787819, 'l1_Layer_4': 0.0002886803096550753, 'n_units_Layer_1': 130, 'n_units_Layer_2': 235, 'n_units_Layer_3': 80, 'n_units_Layer_4': 105}. Best is trial 32 with value: 4.278329991583386.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.28 | sMAPE for Validation Set is: 9.13% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.05 | sMAPE for Test Set is: 10.59% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:22:37,697]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.18 | sMAPE for Validation Set is: 8.68% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.06 | sMAPE for Test Set is: 12.35% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:22:38,695]\u001b[0m Trial 62 finished with value: 4.177304756270663 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015361434406691576, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29218279208145637, 'dropout_rate_Layer_2': 0.3910248598086965, 'dropout_rate_Layer_3': 0.28147785099960704, 'dropout_rate_Layer_4': 0.24703755903222194, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0034172634439253477, 'l1_Layer_2': 1.1213152533858251e-05, 'l1_Layer_3': 0.0711448252511975, 'l1_Layer_4': 0.00032048599842266124, 'n_units_Layer_1': 65, 'n_units_Layer_2': 295, 'n_units_Layer_3': 50, 'n_units_Layer_4': 300}. Best is trial 62 with value: 4.177304756270663.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:22:46,589]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:22:50,686]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:22:55,386]\u001b[0m Trial 66 finished with value: 4.874646208659233 and parameters: {'n_hidden': 3, 'learning_rate': 0.008328863631662402, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3989081217718048, 'dropout_rate_Layer_2': 0.08550024806868006, 'dropout_rate_Layer_3': 0.17602660710449758, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004030446836841724, 'l1_Layer_2': 0.00029512524109670746, 'l1_Layer_3': 0.0006583591765113665, 'n_units_Layer_1': 175, 'n_units_Layer_2': 200, 'n_units_Layer_3': 270}. Best is trial 62 with value: 4.177304756270663.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.87 | sMAPE for Validation Set is: 9.99% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 4.41 | sMAPE for Test Set is: 11.16% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:23:07,091]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:23:10,090]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:23:16,069]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:23:17,611]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:23:20,640]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:23:21,447]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:23:22,470]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:23:24,890]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:23:26,258]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:23:29,262]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:23:32,544]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:23:34,555]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:23:36,654]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:23:39,688]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:23:41,136]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:23:43,105]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:23:46,371]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:23:48,179]\u001b[0m Trial 81 finished with value: 5.397566253086712 and parameters: {'n_hidden': 3, 'learning_rate': 0.007136976472365543, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24930243867064902, 'dropout_rate_Layer_2': 0.1302595054966814, 'dropout_rate_Layer_3': 0.12307160182239525, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.831906062563062e-05, 'l1_Layer_2': 0.002442735257444381, 'l1_Layer_3': 0.02309356566584608, 'n_units_Layer_1': 215, 'n_units_Layer_2': 185, 'n_units_Layer_3': 235}. Best is trial 62 with value: 4.177304756270663.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.40 | sMAPE for Validation Set is: 10.89% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 5.07 | sMAPE for Test Set is: 12.44% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:23:49,662]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:23:52,164]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:23:52,916]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:23:53,903]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:23:57,477]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:23:58,201]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:24:02,221]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:24:03,055]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:24:07,993]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:24:12,105]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:24:12,431]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:24:15,911]\u001b[0m Trial 91 finished with value: 4.293678311040726 and parameters: {'n_hidden': 3, 'learning_rate': 0.005767697750548833, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19451742560334348, 'dropout_rate_Layer_2': 0.18904899624806595, 'dropout_rate_Layer_3': 0.050875808724922644, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.2646981911651514e-05, 'l1_Layer_2': 0.011789496799244868, 'l1_Layer_3': 3.7275194339777775e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 85, 'n_units_Layer_3': 285}. Best is trial 62 with value: 4.177304756270663.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.29 | sMAPE for Validation Set is: 8.91% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.59 | sMAPE for Test Set is: 11.42% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:24:18,995]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:24:20,740]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:24:22,472]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:24:25,615]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:24:27,259]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:24:31,613]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:24:34,436]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:24:35,107]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:24:40,135]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:24:42,282]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:24:44,870]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:24:46,676]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:24:47,454]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:24:49,533]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:24:51,992]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:24:54,581]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:24:56,726]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:24:57,350]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:24:57,746]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:25:03,189]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:25:04,877]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:25:07,501]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:25:10,881]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:25:11,638]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:25:12,782]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:25:16,458]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:25:19,381]\u001b[0m Trial 111 finished with value: 4.633136490008464 and parameters: {'n_hidden': 4, 'learning_rate': 0.004773930384687793, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19943543009587972, 'dropout_rate_Layer_2': 0.13250963153020215, 'dropout_rate_Layer_3': 0.1296874468498486, 'dropout_rate_Layer_4': 0.0619193174491183, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.0167465214122192e-05, 'l1_Layer_2': 0.03453539194574623, 'l1_Layer_3': 0.014741651393224508, 'l1_Layer_4': 0.08870207660257136, 'n_units_Layer_1': 140, 'n_units_Layer_2': 125, 'n_units_Layer_3': 100, 'n_units_Layer_4': 140}. Best is trial 62 with value: 4.177304756270663.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.63 | sMAPE for Validation Set is: 9.60% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 4.52 | sMAPE for Test Set is: 11.43% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:25:20,900]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:25:23,016]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:25:27,883]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:25:29,539]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:25:29,842]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:25:30,252]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:25:40,194]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:25:43,815]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:25:45,631]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:25:50,048]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:25:53,222]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:25:56,582]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:26:07,658]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:26:11,045]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:26:12,093]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:26:15,939]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:26:16,574]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:26:20,981]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:26:25,480]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:26:28,229]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:26:30,168]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:26:34,875]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:26:41,490]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:26:46,880]\u001b[0m Trial 152 finished with value: 4.7535703123348405 and parameters: {'n_hidden': 3, 'learning_rate': 0.011690709483423031, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39146961706808386, 'dropout_rate_Layer_2': 0.10434273991656934, 'dropout_rate_Layer_3': 0.11150230526972121, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00040552524547615595, 'l1_Layer_2': 0.0005593886052743779, 'l1_Layer_3': 0.000638894900968812, 'n_units_Layer_1': 195, 'n_units_Layer_2': 180, 'n_units_Layer_3': 265}. Best is trial 62 with value: 4.177304756270663.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.75 | sMAPE for Validation Set is: 9.91% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 4.63 | sMAPE for Test Set is: 11.77% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:26:50,227]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:27:03,995]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:27:08,366]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:27:13,497]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:27:21,910]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:27:22,565]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:27:23,710]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:27:48,743]\u001b[0m Trial 158 finished with value: 4.544963205884069 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033132807816406355, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35937729466565727, 'dropout_rate_Layer_2': 0.1365832166355394, 'dropout_rate_Layer_3': 0.07569749368107093, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00017257759907941987, 'l1_Layer_2': 0.00040814284530042667, 'l1_Layer_3': 0.0001754473567804759, 'n_units_Layer_1': 205, 'n_units_Layer_2': 145, 'n_units_Layer_3': 285}. Best is trial 62 with value: 4.177304756270663.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.54 | sMAPE for Validation Set is: 9.30% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 4.18 | sMAPE for Test Set is: 10.70% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:27:52,066]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:27:57,027]\u001b[0m Trial 162 finished with value: 4.711071373830297 and parameters: {'n_hidden': 3, 'learning_rate': 0.005102238731568103, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34463030379541193, 'dropout_rate_Layer_2': 0.1321941321895184, 'dropout_rate_Layer_3': 0.05989343410624619, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001633608734047731, 'l1_Layer_2': 0.00040279723415897453, 'l1_Layer_3': 0.0001555677238585065, 'n_units_Layer_1': 205, 'n_units_Layer_2': 185, 'n_units_Layer_3': 285}. Best is trial 62 with value: 4.177304756270663.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.71 | sMAPE for Validation Set is: 9.77% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 4.33 | sMAPE for Test Set is: 10.97% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:28:02,663]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:28:10,821]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:28:26,599]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:28:32,129]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:28:36,408]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:28:36,850]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:28:41,319]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:28:44,720]\u001b[0m Trial 168 finished with value: 4.2180365699141165 and parameters: {'n_hidden': 3, 'learning_rate': 0.005845656432379981, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2357241184923407, 'dropout_rate_Layer_2': 0.12474068430283493, 'dropout_rate_Layer_3': 0.06268962776239592, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.5368318823803767e-05, 'l1_Layer_2': 0.014668151239900673, 'l1_Layer_3': 3.93049871694607e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 85, 'n_units_Layer_3': 240}. Best is trial 62 with value: 4.177304756270663.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.22 | sMAPE for Validation Set is: 8.78% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 4.25 | sMAPE for Test Set is: 10.70% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:28:49,576]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:28:53,059]\u001b[0m Trial 170 finished with value: 4.169470087414126 and parameters: {'n_hidden': 3, 'learning_rate': 0.006569171746140392, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23226593232326745, 'dropout_rate_Layer_2': 0.11950541353793095, 'dropout_rate_Layer_3': 0.05802806355794635, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.179669903625785e-05, 'l1_Layer_2': 0.015579096877980203, 'l1_Layer_3': 3.0745391191949146e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 90, 'n_units_Layer_3': 240}. Best is trial 170 with value: 4.169470087414126.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.17 | sMAPE for Validation Set is: 8.78% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 4.22 | sMAPE for Test Set is: 10.93% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:28:57,399]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:28:59,594]\u001b[0m Trial 172 finished with value: 4.08440344251956 and parameters: {'n_hidden': 3, 'learning_rate': 0.006297074345716939, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24394656705042422, 'dropout_rate_Layer_2': 0.12453992482554453, 'dropout_rate_Layer_3': 0.06075313289602909, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.526554147066427e-05, 'l1_Layer_2': 0.010459266932584754, 'l1_Layer_3': 2.566545345140797e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 90, 'n_units_Layer_3': 235}. Best is trial 172 with value: 4.08440344251956.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.08 | sMAPE for Validation Set is: 8.59% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.17 | sMAPE for Test Set is: 10.62% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:29:01,624]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:29:03,661]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:29:04,017]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:29:08,308]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:29:10,135]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:29:13,303]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:29:13,547]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:29:21,703]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:29:24,364]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:29:25,042]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:29:28,914]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:29:29,401]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:29:33,531]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:29:33,682]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:29:37,426]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:29:39,695]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:29:43,154]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:29:44,559]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:29:45,295]\u001b[0m Trial 185 finished with value: 4.408973249698707 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022907887465048998, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18829449144641855, 'dropout_rate_Layer_2': 0.07444075982278342, 'dropout_rate_Layer_3': 0.07993583455681941, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.9989809162656188e-05, 'l1_Layer_2': 0.022048364274885428, 'l1_Layer_3': 1.8288361261135395e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 65, 'n_units_Layer_3': 270}. Best is trial 172 with value: 4.08440344251956.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.41 | sMAPE for Validation Set is: 9.14% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.51 | sMAPE for Test Set is: 11.30% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:29:46,894]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:29:50,638]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:29:54,317]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:30:00,735]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:30:00,901]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:30:05,910]\u001b[0m Trial 195 finished with value: 3.997575743407067 and parameters: {'n_hidden': 3, 'learning_rate': 0.005884404225752628, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23091887413812032, 'dropout_rate_Layer_2': 0.14792462346016572, 'dropout_rate_Layer_3': 0.05293964559981643, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013292762064305946, 'l1_Layer_2': 0.011616091119431928, 'l1_Layer_3': 1.373439246282773e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 85, 'n_units_Layer_3': 285}. Best is trial 195 with value: 3.997575743407067.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.00 | sMAPE for Validation Set is: 8.45% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.21 | sMAPE for Test Set is: 10.69% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:30:06,199]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:30:10,113]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:30:10,677]\u001b[0m Trial 198 finished with value: 4.095447257357603 and parameters: {'n_hidden': 3, 'learning_rate': 0.005657995302022418, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22861512740289763, 'dropout_rate_Layer_2': 0.08540542801115081, 'dropout_rate_Layer_3': 0.051668384179979356, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.716453937580329e-05, 'l1_Layer_2': 0.01974690085276512, 'l1_Layer_3': 1.5687419546490896e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 80, 'n_units_Layer_3': 280}. Best is trial 195 with value: 3.997575743407067.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.10 | sMAPE for Validation Set is: 8.58% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.24 | sMAPE for Test Set is: 10.71% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:30:13,275]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:30:14,887]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:30:18,640]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:30:22,746]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:30:22,894]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:30:28,398]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:30:28,623]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:30:33,215]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:30:34,572]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.09 | sMAPE for Validation Set is: 8.59% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.29 | sMAPE for Test Set is: 10.90% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:30:36,463]\u001b[0m Trial 207 finished with value: 4.090408349754202 and parameters: {'n_hidden': 3, 'learning_rate': 0.005446270027318421, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.234957944727486, 'dropout_rate_Layer_2': 0.15202820086253566, 'dropout_rate_Layer_3': 0.04722546152763658, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.51794545163481e-05, 'l1_Layer_2': 0.011703096710627888, 'l1_Layer_3': 1.3515812006171473e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 85, 'n_units_Layer_3': 285}. Best is trial 195 with value: 3.997575743407067.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:30:36,922]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:30:39,990]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:30:42,654]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:30:47,138]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:30:47,933]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:30:51,054]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:30:53,571]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:30:53,898]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:30:56,579]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:30:56,955]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:30:58,377]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:31:00,813]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:31:01,713]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:31:02,396]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:31:06,331]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:31:09,068]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:31:09,258]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:31:09,462]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:31:10,218]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:31:16,394]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:31:16,531]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:31:17,090]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:31:24,750]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:31:25,076]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:31:25,260]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:31:28,891]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:31:29,587]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:31:31,384]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:31:36,857]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:31:39,926]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:31:42,003]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:31:42,029]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:31:49,453]\u001b[0m Trial 241 finished with value: 4.260411750573241 and parameters: {'n_hidden': 3, 'learning_rate': 0.005756575290540476, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20299066287486592, 'dropout_rate_Layer_2': 0.15715633945246388, 'dropout_rate_Layer_3': 0.04612112315809718, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.9989051456793278e-05, 'l1_Layer_2': 0.022105608736232338, 'l1_Layer_3': 2.6352472867284816e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 70, 'n_units_Layer_3': 265}. Best is trial 195 with value: 3.997575743407067.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.26 | sMAPE for Validation Set is: 8.87% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.39 | sMAPE for Test Set is: 10.97% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:31:54,447]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:31:58,825]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:32:03,243]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:32:07,788]\u001b[0m Trial 246 finished with value: 3.8548179487764727 and parameters: {'n_hidden': 3, 'learning_rate': 0.005014237516495335, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1732340909567972, 'dropout_rate_Layer_2': 0.21910480068179417, 'dropout_rate_Layer_3': 0.026611371860937157, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.929696518847543e-05, 'l1_Layer_2': 0.013158248095693121, 'l1_Layer_3': 0.00013183697744758926, 'n_units_Layer_1': 105, 'n_units_Layer_2': 80, 'n_units_Layer_3': 260}. Best is trial 246 with value: 3.8548179487764727.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.85 | sMAPE for Validation Set is: 8.15% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.01 | sMAPE for Test Set is: 10.30% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:32:07,975]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:32:08,977]\u001b[0m Trial 245 finished with value: 4.6953702492598515 and parameters: {'n_hidden': 4, 'learning_rate': 0.0020563741169995057, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2922392584096325, 'dropout_rate_Layer_2': 0.3642480409547544, 'dropout_rate_Layer_3': 0.09052664906904728, 'dropout_rate_Layer_4': 0.16658828263359382, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.956501463205486e-05, 'l1_Layer_2': 0.016434022235260203, 'l1_Layer_3': 0.026006056258304294, 'l1_Layer_4': 3.394869956939436e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 215, 'n_units_Layer_3': 200, 'n_units_Layer_4': 110}. Best is trial 246 with value: 3.8548179487764727.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.70 | sMAPE for Validation Set is: 9.73% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 4.49 | sMAPE for Test Set is: 11.38% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:32:14,186]\u001b[0m Trial 247 finished with value: 3.8856152554175494 and parameters: {'n_hidden': 3, 'learning_rate': 0.00503456915474488, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1750483802689241, 'dropout_rate_Layer_2': 0.14109087351373456, 'dropout_rate_Layer_3': 0.032976005951882915, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.643312160427177e-05, 'l1_Layer_2': 0.013574055174721418, 'l1_Layer_3': 0.00014846383277376904, 'n_units_Layer_1': 105, 'n_units_Layer_2': 85, 'n_units_Layer_3': 260}. Best is trial 246 with value: 3.8548179487764727.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.89 | sMAPE for Validation Set is: 8.18% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.02 | sMAPE for Test Set is: 10.31% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:32:15,833]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:32:16,464]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:32:17,661]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:32:22,115]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:32:25,908]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:32:30,478]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:32:33,137]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:32:33,590]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:32:42,603]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:32:45,472]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:32:48,918]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:32:49,477]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:32:57,576]\u001b[0m Trial 262 finished with value: 3.9137067353459045 and parameters: {'n_hidden': 3, 'learning_rate': 0.004217641287753939, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22160498678043367, 'dropout_rate_Layer_2': 0.13525603680494594, 'dropout_rate_Layer_3': 0.025831941694300545, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.56198364859973e-05, 'l1_Layer_2': 0.013680830834852699, 'l1_Layer_3': 7.19386144091933e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 80, 'n_units_Layer_3': 270}. Best is trial 246 with value: 3.8548179487764727.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.91 | sMAPE for Validation Set is: 8.24% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.04 | sMAPE for Test Set is: 10.28% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:32:58,579]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:33:02,472]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:33:05,341]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:33:12,379]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:33:20,129]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:33:24,803]\u001b[0m Trial 261 finished with value: 4.700942816676599 and parameters: {'n_hidden': 3, 'learning_rate': 0.002758230325408165, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2570050578025888, 'dropout_rate_Layer_2': 0.09349206530960165, 'dropout_rate_Layer_3': 0.03407787447098261, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013429605343123497, 'l1_Layer_2': 0.00026263323541036066, 'l1_Layer_3': 0.00013044126345147902, 'n_units_Layer_1': 225, 'n_units_Layer_2': 195, 'n_units_Layer_3': 285}. Best is trial 246 with value: 3.8548179487764727.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.70 | sMAPE for Validation Set is: 9.84% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 4.17 | sMAPE for Test Set is: 10.77% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:33:32,552]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:33:39,623]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:33:43,258]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:33:45,600]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:33:49,409]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:33:52,317]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:33:55,418]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:33:55,746]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:34:08,482]\u001b[0m Trial 281 finished with value: 4.3496906655371985 and parameters: {'n_hidden': 3, 'learning_rate': 0.00983916380359411, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.284212011675998, 'dropout_rate_Layer_2': 0.27818954175868155, 'dropout_rate_Layer_3': 0.046248412136171924, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0165217736853862, 'l1_Layer_2': 0.019729032293197116, 'l1_Layer_3': 0.00045732730760813796, 'n_units_Layer_1': 95, 'n_units_Layer_2': 95, 'n_units_Layer_3': 155}. Best is trial 246 with value: 3.8548179487764727.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.35 | sMAPE for Validation Set is: 9.13% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 4.37 | sMAPE for Test Set is: 11.12% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:34:13,115]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:34:18,017]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:34:34,005]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:34:37,440]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:34:39,533]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:34:42,889]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:34:45,153]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:34:51,540]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:34:59,338]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:35:02,179]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:35:06,902]\u001b[0m Trial 266 finished with value: 4.235957693030271 and parameters: {'n_hidden': 3, 'learning_rate': 0.001093162985279288, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3354963304165624, 'dropout_rate_Layer_2': 0.15121642399237167, 'dropout_rate_Layer_3': 0.01698139104560714, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00022163933553886247, 'l1_Layer_2': 8.626488704148672e-05, 'l1_Layer_3': 0.0013003927983377818, 'n_units_Layer_1': 145, 'n_units_Layer_2': 200, 'n_units_Layer_3': 290}. Best is trial 246 with value: 3.8548179487764727.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.24 | sMAPE for Validation Set is: 8.78% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.22 | sMAPE for Test Set is: 10.80% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:35:10,237]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:35:11,759]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:35:15,211]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:35:17,950]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:35:19,743]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:35:24,200]\u001b[0m Trial 291 finished with value: 4.626654750155338 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007905916648624421, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31883188036471616, 'dropout_rate_Layer_2': 0.29330314284139714, 'dropout_rate_Layer_3': 0.18012035994170753, 'dropout_rate_Layer_4': 0.2429730150234012, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.004314791484561372, 'l1_Layer_2': 1.0068177446299988e-05, 'l1_Layer_3': 5.402416911590006e-05, 'l1_Layer_4': 0.00021428484496354582, 'n_units_Layer_1': 80, 'n_units_Layer_2': 210, 'n_units_Layer_3': 275, 'n_units_Layer_4': 300}. Best is trial 246 with value: 3.8548179487764727.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.63 | sMAPE for Validation Set is: 9.65% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 4.65 | sMAPE for Test Set is: 11.77% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:35:27,221]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:35:34,269]\u001b[0m Trial 290 finished with value: 4.696355371817087 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007360337386706482, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3223344914553269, 'dropout_rate_Layer_2': 0.29777118696480454, 'dropout_rate_Layer_3': 0.17595920395099757, 'dropout_rate_Layer_4': 0.2404155217894807, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.004832156829200171, 'l1_Layer_2': 1.2918475142588659e-05, 'l1_Layer_3': 6.204496574393703e-05, 'l1_Layer_4': 0.00016617388032139676, 'n_units_Layer_1': 80, 'n_units_Layer_2': 205, 'n_units_Layer_3': 265, 'n_units_Layer_4': 300}. Best is trial 246 with value: 3.8548179487764727.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.70 | sMAPE for Validation Set is: 9.60% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 4.79 | sMAPE for Test Set is: 11.82% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:35:34,555]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:35:38,172]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:35:40,837]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:35:48,121]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:35:54,528]\u001b[0m Trial 299 finished with value: 4.568536795544226 and parameters: {'n_hidden': 4, 'learning_rate': 0.000767952054954999, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3210782288946632, 'dropout_rate_Layer_2': 0.29256056752032394, 'dropout_rate_Layer_3': 0.1696366699185617, 'dropout_rate_Layer_4': 0.2428435772252672, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.006154228012965435, 'l1_Layer_2': 1.0848718338811445e-05, 'l1_Layer_3': 5.957177630604555e-05, 'l1_Layer_4': 0.00016629720399754036, 'n_units_Layer_1': 75, 'n_units_Layer_2': 215, 'n_units_Layer_3': 300, 'n_units_Layer_4': 295}. Best is trial 246 with value: 3.8548179487764727.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.57 | sMAPE for Validation Set is: 9.45% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 4.78 | sMAPE for Test Set is: 11.87% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:35:57,611]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:36:02,942]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:36:07,981]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:36:11,051]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:36:15,784]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:36:22,995]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:36:24,421]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:36:27,856]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:36:31,822]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:36:36,405]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:36:36,935]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:36:40,898]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:36:43,001]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:37:28,191]\u001b[0m Trial 319 finished with value: 4.1263423131564485 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014622092285008236, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17834202680587777, 'dropout_rate_Layer_2': 0.24300407960050738, 'dropout_rate_Layer_3': 0.25688734642851474, 'dropout_rate_Layer_4': 0.29975398197265823, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005541031090427943, 'l1_Layer_2': 2.835139892281291e-05, 'l1_Layer_3': 0.000496132278165271, 'l1_Layer_4': 7.064452060117241e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 140, 'n_units_Layer_3': 150, 'n_units_Layer_4': 265}. Best is trial 246 with value: 3.8548179487764727.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.13 | sMAPE for Validation Set is: 8.72% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.23 | sMAPE for Test Set is: 10.87% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:37:32,468]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:37:35,143]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:37:38,176]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:37:49,491]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:38:00,468]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:38:03,470]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:38:09,462]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:38:14,414]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:38:17,257]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:38:24,440]\u001b[0m Trial 320 finished with value: 4.368444775667048 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017313267737038955, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2513811377835591, 'dropout_rate_Layer_2': 0.2402916334637412, 'dropout_rate_Layer_3': 0.25579622390449863, 'dropout_rate_Layer_4': 0.30267894599837847, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005588912756445526, 'l1_Layer_2': 0.0001348877770039441, 'l1_Layer_3': 0.0004998931141069925, 'l1_Layer_4': 8.38178519459213e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 145, 'n_units_Layer_3': 200, 'n_units_Layer_4': 260}. Best is trial 246 with value: 3.8548179487764727.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.37 | sMAPE for Validation Set is: 8.96% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.60 | sMAPE for Test Set is: 11.56% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:38:56,326]\u001b[0m Trial 307 finished with value: 4.234540228945806 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012283832001371822, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.225337089126999, 'dropout_rate_Layer_2': 0.24125679315446555, 'dropout_rate_Layer_3': 0.015045335631757237, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012228687144939714, 'l1_Layer_2': 0.00043941408021848187, 'l1_Layer_3': 0.0016122615205751084, 'n_units_Layer_1': 150, 'n_units_Layer_2': 210, 'n_units_Layer_3': 275}. Best is trial 246 with value: 3.8548179487764727.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.23 | sMAPE for Validation Set is: 8.78% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.26 | sMAPE for Test Set is: 10.79% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:39:01,414]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:39:09,265]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:39:25,859]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:39:42,305]\u001b[0m Trial 326 finished with value: 4.1833117801827875 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005344215335318152, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33891665901106094, 'dropout_rate_Layer_2': 0.0654383351542871, 'dropout_rate_Layer_3': 0.01573380015966963, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00018016314773656032, 'l1_Layer_2': 0.00040291834578105336, 'l1_Layer_3': 3.077761283008001e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 215, 'n_units_Layer_3': 285}. Best is trial 246 with value: 3.8548179487764727.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.18 | sMAPE for Validation Set is: 8.76% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 4.02 | sMAPE for Test Set is: 10.45% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:39:47,503]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:39:57,692]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:39:58,201]\u001b[0m Trial 330 finished with value: 4.393584203822209 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007654807562664104, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3424833107531422, 'dropout_rate_Layer_2': 0.12571051445381312, 'dropout_rate_Layer_3': 0.026771876280218123, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010477474625142392, 'l1_Layer_2': 0.00010031384982472989, 'l1_Layer_3': 0.0009511705191920249, 'n_units_Layer_1': 175, 'n_units_Layer_2': 130, 'n_units_Layer_3': 275}. Best is trial 246 with value: 3.8548179487764727.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.39 | sMAPE for Validation Set is: 9.17% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.11 | sMAPE for Test Set is: 10.60% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:40:05,094]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:40:08,390]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:40:08,924]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:40:10,621]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:40:14,041]\u001b[0m Trial 331 finished with value: 4.516753477943676 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007668896250871603, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34111675920458145, 'dropout_rate_Layer_2': 0.12854445329343933, 'dropout_rate_Layer_3': 0.028142403215853505, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00018063238756411208, 'l1_Layer_2': 0.00010143899445253752, 'l1_Layer_3': 0.001611969981760265, 'n_units_Layer_1': 175, 'n_units_Layer_2': 130, 'n_units_Layer_3': 270}. Best is trial 246 with value: 3.8548179487764727.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.52 | sMAPE for Validation Set is: 9.36% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 4.23 | sMAPE for Test Set is: 10.74% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:40:14,936]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:40:18,900]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:40:23,938]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:40:27,494]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:40:27,987]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:40:31,354]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:40:34,489]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:40:37,086]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:40:40,271]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:40:40,521]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:40:46,966]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:40:47,407]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:40:47,541]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:40:56,040]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:40:56,203]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:40:56,526]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:41:03,232]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:41:03,531]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:41:04,198]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:41:10,029]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:41:13,020]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:41:13,351]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:41:20,420]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:41:20,954]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:41:27,163]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:41:33,667]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:41:33,795]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:41:39,662]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:41:41,886]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:41:45,500]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:41:49,236]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:41:54,461]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:41:54,631]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:41:58,994]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:41:59,306]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:42:04,543]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:42:06,294]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:42:10,897]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:42:16,448]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:42:26,780]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:42:32,031]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:42:36,403]\u001b[0m Trial 356 finished with value: 4.286209108938276 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014529728686442818, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1899646622646492, 'dropout_rate_Layer_2': 0.3530449258975226, 'dropout_rate_Layer_3': 0.214199895946654, 'dropout_rate_Layer_4': 0.3416926720816614, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.016867811109233573, 'l1_Layer_2': 8.508046230352504e-05, 'l1_Layer_3': 0.0022763859787901576, 'l1_Layer_4': 1.4494559226554786e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 235, 'n_units_Layer_3': 100, 'n_units_Layer_4': 270}. Best is trial 246 with value: 3.8548179487764727.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.29 | sMAPE for Validation Set is: 8.89% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.17 | sMAPE for Test Set is: 10.56% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:42:38,105]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:42:41,404]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:42:43,561]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:42:46,864]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:42:50,315]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:42:53,192]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:42:53,525]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:43:03,851]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:43:07,128]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:43:12,522]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:43:15,943]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:43:19,410]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:43:22,413]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:43:27,020]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:43:31,917]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:43:41,388]\u001b[0m Trial 381 finished with value: 4.449780695691455 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015542784901787484, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04718475532526058, 'dropout_rate_Layer_2': 0.35553622939739343, 'dropout_rate_Layer_3': 0.03990731926176305, 'dropout_rate_Layer_4': 0.19459680164380072, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.254125101006821e-05, 'l1_Layer_2': 9.993895904802446e-05, 'l1_Layer_3': 0.0016142077948581644, 'l1_Layer_4': 1.5821992845067506e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 240, 'n_units_Layer_3': 110, 'n_units_Layer_4': 50}. Best is trial 246 with value: 3.8548179487764727.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.45 | sMAPE for Validation Set is: 9.24% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.45 | sMAPE for Test Set is: 11.25% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:43:41,789]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:43:45,399]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:43:48,325]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:43:53,010]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:43:53,662]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:43:59,444]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:44:03,002]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:44:03,175]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:44:03,436]\u001b[0m Trial 393 finished with value: 4.139082666291427 and parameters: {'n_hidden': 4, 'learning_rate': 0.002527075327356782, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04686887312957744, 'dropout_rate_Layer_2': 0.3312015830700803, 'dropout_rate_Layer_3': 0.0331675840020845, 'dropout_rate_Layer_4': 0.20143102944304256, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.064074860482197e-05, 'l1_Layer_2': 0.0007714877748192842, 'l1_Layer_3': 0.0006942822495845592, 'l1_Layer_4': 0.001741786690779147, 'n_units_Layer_1': 115, 'n_units_Layer_2': 265, 'n_units_Layer_3': 115, 'n_units_Layer_4': 55}. Best is trial 246 with value: 3.8548179487764727.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.14 | sMAPE for Validation Set is: 8.69% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.09 | sMAPE for Test Set is: 10.51% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:44:09,661]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:44:10,260]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:44:11,164]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:44:17,082]\u001b[0m Trial 361 finished with value: 4.101244237185412 and parameters: {'n_hidden': 4, 'learning_rate': 0.001219880714729031, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04162562364850387, 'dropout_rate_Layer_2': 0.3376204984050961, 'dropout_rate_Layer_3': 0.21188098193057822, 'dropout_rate_Layer_4': 0.20063385758399677, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.01699871690654461, 'l1_Layer_2': 9.06908697188557e-05, 'l1_Layer_3': 0.0018218666767528474, 'l1_Layer_4': 1.2335559611287934e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 245, 'n_units_Layer_3': 110, 'n_units_Layer_4': 270}. Best is trial 246 with value: 3.8548179487764727.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.10 | sMAPE for Validation Set is: 8.59% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.24 | sMAPE for Test Set is: 10.98% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:44:21,080]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:44:21,405]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:44:22,168]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:44:28,187]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:44:28,343]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:44:32,788]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:44:36,790]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:44:39,986]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:44:42,894]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:44:45,083]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:44:51,655]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:44:58,250]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:44:58,662]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:45:02,752]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:45:09,385]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:45:14,458]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:45:17,632]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:45:20,606]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:45:25,296]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:45:30,957]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:45:31,736]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:45:32,902]\u001b[0m Trial 425 finished with value: 4.381522179693262 and parameters: {'n_hidden': 4, 'learning_rate': 0.002355311901193908, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39743538723425154, 'dropout_rate_Layer_2': 0.38661578575591116, 'dropout_rate_Layer_3': 0.2247890207091217, 'dropout_rate_Layer_4': 0.1598630663761197, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 8.192903521767317e-05, 'l1_Layer_2': 0.0008706870318776735, 'l1_Layer_3': 0.00022927271547234788, 'l1_Layer_4': 0.0019203980098478164, 'n_units_Layer_1': 150, 'n_units_Layer_2': 300, 'n_units_Layer_3': 140, 'n_units_Layer_4': 280}. Best is trial 246 with value: 3.8548179487764727.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.38 | sMAPE for Validation Set is: 9.07% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.19 | sMAPE for Test Set is: 10.67% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:45:37,248]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:45:38,784]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:45:43,026]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:45:44,763]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:45:45,194]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:45:45,827]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:45:51,855]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:45:53,049]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:45:59,637]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:46:04,272]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:46:09,844]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:46:19,337]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:46:22,514]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:46:24,218]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:46:26,931]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:46:30,033]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:46:30,558]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:46:36,385]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:46:39,457]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:46:39,747]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:47:03,703]\u001b[0m Trial 444 finished with value: 4.142637501446674 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005125116283014294, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17037580752247178, 'dropout_rate_Layer_2': 0.369461165296006, 'dropout_rate_Layer_3': 0.08681308579062862, 'dropout_rate_Layer_4': 0.09945952069017573, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.024020465385553705, 'l1_Layer_2': 5.355793014578772e-05, 'l1_Layer_3': 0.0002593324351393231, 'l1_Layer_4': 0.0004428735139645638, 'n_units_Layer_1': 90, 'n_units_Layer_2': 95, 'n_units_Layer_3': 110, 'n_units_Layer_4': 190}. Best is trial 246 with value: 3.8548179487764727.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.14 | sMAPE for Validation Set is: 8.64% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.17 | sMAPE for Test Set is: 10.79% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:47:06,961]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:47:09,872]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:47:16,693]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:47:21,588]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:47:41,491]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:47:59,129]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:48:13,524]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:48:22,143]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:48:31,370]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:48:33,991]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:48:37,502]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:48:41,294]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:48:46,336]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:48:49,697]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:48:52,895]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:48:56,612]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:49:01,397]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:49:05,603]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:49:09,866]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:49:12,647]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:49:15,630]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:49:17,790]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:49:23,144]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:49:26,441]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:49:35,846]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:49:44,716]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:49:47,859]\u001b[0m Trial 464 finished with value: 4.2434404420408685 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005198960822515616, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13836357481205785, 'dropout_rate_Layer_2': 0.2657921022872704, 'dropout_rate_Layer_3': 0.08844156701457276, 'dropout_rate_Layer_4': 0.16880844955767016, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.012639980544143796, 'l1_Layer_2': 0.00015043712684383484, 'l1_Layer_3': 0.0008306275086179758, 'l1_Layer_4': 1.0242569585618064e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 115, 'n_units_Layer_3': 125, 'n_units_Layer_4': 190}. Best is trial 246 with value: 3.8548179487764727.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.24 | sMAPE for Validation Set is: 8.96% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.31 | sMAPE for Test Set is: 11.18% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:49:52,316]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:50:10,084]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:50:14,763]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:50:15,340]\u001b[0m Trial 457 finished with value: 3.979191111386155 and parameters: {'n_hidden': 4, 'learning_rate': 0.00376128990610377, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1281918205970365, 'dropout_rate_Layer_2': 0.34103688444320596, 'dropout_rate_Layer_3': 0.36883409084895746, 'dropout_rate_Layer_4': 0.07818844281061284, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00029713514320382073, 'l1_Layer_2': 0.0001915576960454652, 'l1_Layer_3': 0.0057621431831731485, 'l1_Layer_4': 0.00010344687441346953, 'n_units_Layer_1': 140, 'n_units_Layer_2': 290, 'n_units_Layer_3': 160, 'n_units_Layer_4': 190}. Best is trial 246 with value: 3.8548179487764727.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.98 | sMAPE for Validation Set is: 8.71% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.14 | sMAPE for Test Set is: 10.60% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:50:22,139]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:50:25,016]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:50:27,289]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:50:29,018]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:50:33,466]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:50:43,784]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:50:51,470]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:51:01,166]\u001b[0m Trial 492 finished with value: 4.514106584778353 and parameters: {'n_hidden': 4, 'learning_rate': 0.004009945969113533, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2131518038936599, 'dropout_rate_Layer_2': 0.31445376681557247, 'dropout_rate_Layer_3': 0.39543304517749184, 'dropout_rate_Layer_4': 0.08964105021450204, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00012926616208116834, 'l1_Layer_2': 0.0005964914202948679, 'l1_Layer_3': 0.005739507499819201, 'l1_Layer_4': 0.00013572947029035366, 'n_units_Layer_1': 115, 'n_units_Layer_2': 140, 'n_units_Layer_3': 210, 'n_units_Layer_4': 170}. Best is trial 246 with value: 3.8548179487764727.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.51 | sMAPE for Validation Set is: 9.25% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 4.33 | sMAPE for Test Set is: 10.94% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:51:09,448]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:51:09,824]\u001b[0m Trial 479 finished with value: 4.294517766686791 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005893035520344727, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13320617771626558, 'dropout_rate_Layer_2': 0.2708057618813439, 'dropout_rate_Layer_3': 0.0248848651619651, 'dropout_rate_Layer_4': 0.14522945512983523, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003408092120797954, 'l1_Layer_2': 0.0004971356276276752, 'l1_Layer_3': 0.0007738784193730718, 'l1_Layer_4': 0.0012761803163646157, 'n_units_Layer_1': 90, 'n_units_Layer_2': 120, 'n_units_Layer_3': 130, 'n_units_Layer_4': 280}. Best is trial 246 with value: 3.8548179487764727.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.29 | sMAPE for Validation Set is: 9.15% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.37 | sMAPE for Test Set is: 10.88% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:51:16,058]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:51:16,735]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:51:18,093]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:51:21,421]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:51:23,464]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:51:24,047]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:51:25,582]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:51:29,582]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:51:30,323]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:51:35,422]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:51:35,846]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:51:41,131]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:51:43,927]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:51:44,418]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:51:52,649]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:51:53,302]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:51:58,028]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:52:01,870]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:52:04,348]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:52:04,949]\u001b[0m Trial 484 finished with value: 4.31069602831005 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006086021916837131, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34724737547648665, 'dropout_rate_Layer_2': 0.17633865203145987, 'dropout_rate_Layer_3': 0.042225485651971616, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001556417676984905, 'l1_Layer_2': 6.518929554020991e-05, 'l1_Layer_3': 4.43446874593161e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 190, 'n_units_Layer_3': 265}. Best is trial 246 with value: 3.8548179487764727.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:52:05,020]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.31 | sMAPE for Validation Set is: 8.91% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 4.08 | sMAPE for Test Set is: 10.49% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:52:13,409]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:52:44,783]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:52:48,306]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:52:52,857]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:52:53,163]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:53:01,058]\u001b[0m Trial 504 finished with value: 3.8881820825230697 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011323526707725596, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26755543628107775, 'dropout_rate_Layer_2': 0.20285612806732525, 'dropout_rate_Layer_3': 0.36134963381582424, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012153262778543522, 'l1_Layer_2': 0.0003508915431231755, 'l1_Layer_3': 4.1887162472599726e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 220, 'n_units_Layer_3': 285}. Best is trial 246 with value: 3.8548179487764727.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.89 | sMAPE for Validation Set is: 8.12% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 3.99 | sMAPE for Test Set is: 10.31% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:53:03,342]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:53:03,820]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:53:06,118]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:53:11,237]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:53:13,145]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:53:18,371]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:53:22,841]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:53:27,333]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:53:36,267]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:53:47,715]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:53:55,452]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:54:03,022]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:54:04,779]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:54:38,593]\u001b[0m Trial 539 finished with value: 4.402808176383405 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009247394158628296, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1849935351705042, 'dropout_rate_Layer_2': 0.09148407030337571, 'dropout_rate_Layer_3': 0.016504623156637213, 'dropout_rate_Layer_4': 0.025565450967661746, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.804704036273055e-05, 'l1_Layer_2': 0.01430976021320164, 'l1_Layer_3': 0.0024739684225489143, 'l1_Layer_4': 1.4548241304482686e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 190, 'n_units_Layer_3': 245, 'n_units_Layer_4': 90}. Best is trial 246 with value: 3.8548179487764727.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.40 | sMAPE for Validation Set is: 9.27% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.61 | sMAPE for Test Set is: 11.55% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:54:45,140]\u001b[0m Trial 523 finished with value: 3.8161902251345707 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005797287612093054, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3463311672249633, 'dropout_rate_Layer_2': 0.1865285449979958, 'dropout_rate_Layer_3': 0.031025017987915363, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0036798068225948996, 'l1_Layer_2': 7.097502108485465e-05, 'l1_Layer_3': 4.317973463503001e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 190, 'n_units_Layer_3': 260}. Best is trial 523 with value: 3.8161902251345707.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.82 | sMAPE for Validation Set is: 8.05% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.75 | sMAPE for Test Set is: 9.75% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:55:04,585]\u001b[0m Trial 533 finished with value: 3.9019502873416285 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005008656254252886, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1386101562962877, 'dropout_rate_Layer_2': 0.18562860180289867, 'dropout_rate_Layer_3': 0.02814410892620854, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012937814508028948, 'l1_Layer_2': 8.222899561516797e-05, 'l1_Layer_3': 2.600362011143519e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 220, 'n_units_Layer_3': 260}. Best is trial 523 with value: 3.8161902251345707.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.90 | sMAPE for Validation Set is: 8.11% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 3.96 | sMAPE for Test Set is: 10.16% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:55:08,026]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:55:19,174]\u001b[0m Trial 538 finished with value: 4.030811997933983 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007926089887524417, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2533848998275612, 'dropout_rate_Layer_2': 0.19113545036132035, 'dropout_rate_Layer_3': 0.028816961909407846, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00550163868572441, 'l1_Layer_2': 4.8023607017762136e-05, 'l1_Layer_3': 4.9834501948940296e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 245, 'n_units_Layer_3': 255}. Best is trial 523 with value: 3.8161902251345707.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.03 | sMAPE for Validation Set is: 8.40% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.04 | sMAPE for Test Set is: 10.32% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:55:23,627]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:55:57,298]\u001b[0m Trial 540 finished with value: 3.979866397440766 and parameters: {'n_hidden': 3, 'learning_rate': 0.001352659557264541, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2536131428660806, 'dropout_rate_Layer_2': 0.19593508843978436, 'dropout_rate_Layer_3': 0.027735413719900796, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0033595523566623034, 'l1_Layer_2': 4.6245160463915594e-05, 'l1_Layer_3': 4.485348927847784e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 180, 'n_units_Layer_3': 260}. Best is trial 523 with value: 3.8161902251345707.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.98 | sMAPE for Validation Set is: 8.29% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 3.99 | sMAPE for Test Set is: 10.23% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:56:05,407]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:56:10,817]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:56:24,305]\u001b[0m Trial 541 finished with value: 3.888878719697896 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007943625457538453, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12332829462252709, 'dropout_rate_Layer_2': 0.1957146670392512, 'dropout_rate_Layer_3': 0.02591327626008375, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0037927523352179952, 'l1_Layer_2': 4.5979111999227344e-05, 'l1_Layer_3': 5.07466382966543e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 180, 'n_units_Layer_3': 270}. Best is trial 523 with value: 3.8161902251345707.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.89 | sMAPE for Validation Set is: 8.12% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 3.81 | sMAPE for Test Set is: 9.84% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:56:29,743]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:56:39,596]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:56:42,778]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:56:48,632]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:56:56,355]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:57:04,691]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:57:13,244]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:57:29,718]\u001b[0m Trial 549 finished with value: 4.331360005986093 and parameters: {'n_hidden': 4, 'learning_rate': 0.001219123972475055, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21575220070531226, 'dropout_rate_Layer_2': 0.13891236915042607, 'dropout_rate_Layer_3': 0.019552634777643546, 'dropout_rate_Layer_4': 0.030813333189067954, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.2554433468086844e-05, 'l1_Layer_2': 0.015696664172134108, 'l1_Layer_3': 0.002436002801898565, 'l1_Layer_4': 1.4420050847826755e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 180, 'n_units_Layer_3': 245, 'n_units_Layer_4': 90}. Best is trial 523 with value: 3.8161902251345707.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.33 | sMAPE for Validation Set is: 9.13% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 4.41 | sMAPE for Test Set is: 11.16% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:57:30,004]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:57:35,275]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:57:41,321]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:58:14,382]\u001b[0m Trial 559 finished with value: 4.380932824882494 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009221761205267418, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2216552556048857, 'dropout_rate_Layer_2': 0.08569819996841047, 'dropout_rate_Layer_3': 0.022082920722950435, 'dropout_rate_Layer_4': 0.03201154283625171, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.5004989987488179e-05, 'l1_Layer_2': 0.012463311456784807, 'l1_Layer_3': 0.0022743835450299674, 'l1_Layer_4': 1.427908012973457e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 185, 'n_units_Layer_3': 240, 'n_units_Layer_4': 90}. Best is trial 523 with value: 3.8161902251345707.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.38 | sMAPE for Validation Set is: 9.22% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.53 | sMAPE for Test Set is: 11.39% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:58:17,798]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:58:24,079]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:58:29,762]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:58:33,205]\u001b[0m Trial 543 finished with value: 3.7043298503200166 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005007263982436719, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11377038109917761, 'dropout_rate_Layer_2': 0.1912052744760203, 'dropout_rate_Layer_3': 0.02409310399961316, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003934214723080472, 'l1_Layer_2': 9.745871981574416e-05, 'l1_Layer_3': 2.4614886616176898e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 220, 'n_units_Layer_3': 265}. Best is trial 543 with value: 3.7043298503200166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.70 | sMAPE for Validation Set is: 8.00% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 3.70 | sMAPE for Test Set is: 9.66% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:58:36,055]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:58:36,633]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:58:44,796]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:58:48,811]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:58:53,011]\u001b[0m Trial 557 finished with value: 4.347313884685382 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010322972982370383, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1832272875906939, 'dropout_rate_Layer_2': 0.08360798291051395, 'dropout_rate_Layer_3': 0.009762917294285745, 'dropout_rate_Layer_4': 0.0312237566128838, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.9158526850902837e-05, 'l1_Layer_2': 0.012903027043178573, 'l1_Layer_3': 0.00257869585657131, 'l1_Layer_4': 1.615760298458414e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 195, 'n_units_Layer_3': 245, 'n_units_Layer_4': 90}. Best is trial 543 with value: 3.7043298503200166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.35 | sMAPE for Validation Set is: 9.14% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 4.43 | sMAPE for Test Set is: 11.19% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:59:00,568]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:59:06,146]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:59:37,641]\u001b[0m Trial 567 finished with value: 4.372459254442426 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009785228547383791, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18787690334858004, 'dropout_rate_Layer_2': 0.08450789905175286, 'dropout_rate_Layer_3': 0.013038565989980553, 'dropout_rate_Layer_4': 0.02990798582255652, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.4396182818168014e-05, 'l1_Layer_2': 0.014014268847293556, 'l1_Layer_3': 0.0020037986753191983, 'l1_Layer_4': 1.5950932770490077e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 185, 'n_units_Layer_3': 245, 'n_units_Layer_4': 90}. Best is trial 543 with value: 3.7043298503200166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.37 | sMAPE for Validation Set is: 9.20% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.51 | sMAPE for Test Set is: 11.34% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:59:49,137]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:59:52,022]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 19:59:54,781]\u001b[0m Trial 560 finished with value: 3.8818006248915045 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012753679211178208, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11325706009261449, 'dropout_rate_Layer_2': 0.20600944588212913, 'dropout_rate_Layer_3': 0.028211244513561613, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0032378791737796776, 'l1_Layer_2': 5.552169455507216e-05, 'l1_Layer_3': 3.2824695911936776e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 180, 'n_units_Layer_3': 265}. Best is trial 543 with value: 3.7043298503200166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.88 | sMAPE for Validation Set is: 8.10% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 3.88 | sMAPE for Test Set is: 9.96% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 19:59:55,737]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:00:00,054]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:00:03,960]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:00:06,826]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:00:07,435]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:00:09,936]\u001b[0m Trial 569 finished with value: 4.249184709181334 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009753932985855345, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18172524280475574, 'dropout_rate_Layer_2': 0.08674213915398023, 'dropout_rate_Layer_3': 0.017327984398126838, 'dropout_rate_Layer_4': 0.03798295604846505, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.963408402349675e-05, 'l1_Layer_2': 0.013381372139971943, 'l1_Layer_3': 0.00118944081851691, 'l1_Layer_4': 1.630094663980465e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 195, 'n_units_Layer_3': 245, 'n_units_Layer_4': 95}. Best is trial 543 with value: 3.7043298503200166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.25 | sMAPE for Validation Set is: 8.95% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.24 | sMAPE for Test Set is: 10.82% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:00:14,856]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:00:47,753]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:00:54,134]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:00:57,488]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:00:58,956]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:01:06,165]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:01:45,594]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:01:53,306]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:01:58,381]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:02:05,712]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:02:13,126]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:02:20,769]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:02:28,021]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:02:39,541]\u001b[0m Trial 582 finished with value: 3.71176370483537 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005074936420450774, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09598311547359052, 'dropout_rate_Layer_2': 0.19049517387274728, 'dropout_rate_Layer_3': 0.012380683899955894, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003513239214425265, 'l1_Layer_2': 3.366590477737329e-05, 'l1_Layer_3': 2.7099558914734508e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 165, 'n_units_Layer_3': 260}. Best is trial 543 with value: 3.7043298503200166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.71 | sMAPE for Validation Set is: 7.80% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 3.69 | sMAPE for Test Set is: 9.57% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:02:41,060]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:03:10,816]\u001b[0m Trial 584 finished with value: 3.7466747969921745 and parameters: {'n_hidden': 3, 'learning_rate': 0.000508987425472597, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0946447644628659, 'dropout_rate_Layer_2': 0.2010111355155645, 'dropout_rate_Layer_3': 0.02889740193558507, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00458283397011298, 'l1_Layer_2': 3.3123004568155005e-05, 'l1_Layer_3': 6.753732448903582e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 170, 'n_units_Layer_3': 265}. Best is trial 543 with value: 3.7043298503200166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 7.89% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 3.88 | sMAPE for Test Set is: 10.10% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:03:13,949]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:03:21,930]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:03:27,655]\u001b[0m Trial 588 finished with value: 3.705349621841583 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005045443710879366, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11877319934801735, 'dropout_rate_Layer_2': 0.20162095756941115, 'dropout_rate_Layer_3': 0.005420021459904077, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005717330562214379, 'l1_Layer_2': 0.007634219259600949, 'l1_Layer_3': 2.2976560113487057e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 185, 'n_units_Layer_3': 250}. Best is trial 543 with value: 3.7043298503200166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.71 | sMAPE for Validation Set is: 7.80% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 3.88 | sMAPE for Test Set is: 10.08% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:03:54,146]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:04:01,884]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:04:04,775]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:04:19,544]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:04:26,844]\u001b[0m Trial 600 finished with value: 4.453258160630196 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007701975295092301, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21819566323288758, 'dropout_rate_Layer_2': 0.03826130816609538, 'dropout_rate_Layer_3': 0.024371853157416183, 'dropout_rate_Layer_4': 0.023536662833589895, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 6.435755316146613e-05, 'l1_Layer_2': 0.01932834071927198, 'l1_Layer_3': 0.0021650698371566772, 'l1_Layer_4': 1.9280930611358954e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 200, 'n_units_Layer_3': 250, 'n_units_Layer_4': 60}. Best is trial 543 with value: 3.7043298503200166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.45 | sMAPE for Validation Set is: 9.33% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.71 | sMAPE for Test Set is: 11.72% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:04:35,918]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:04:36,765]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:04:46,773]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:04:49,803]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:04:52,730]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:05:00,507]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:05:05,284]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:05:09,447]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:05:15,255]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:05:50,040]\u001b[0m Trial 596 finished with value: 3.702898179516891 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005122466885652296, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12872374174737294, 'dropout_rate_Layer_2': 0.17966874777231867, 'dropout_rate_Layer_3': 0.011564482757100016, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0030059058178091946, 'l1_Layer_2': 2.4992397253166242e-05, 'l1_Layer_3': 2.6276265844279367e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 160, 'n_units_Layer_3': 255}. Best is trial 596 with value: 3.702898179516891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.70 | sMAPE for Validation Set is: 7.77% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 3.78 | sMAPE for Test Set is: 9.74% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:05:57,747]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:06:14,455]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:06:19,893]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:06:20,430]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:06:30,675]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:06:31,108]\u001b[0m Trial 615 finished with value: 4.455218443719591 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006211567921155006, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21977356051464939, 'dropout_rate_Layer_2': 0.013745138336131446, 'dropout_rate_Layer_3': 0.006857763418854275, 'dropout_rate_Layer_4': 0.01930494289037893, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.557047532737314e-05, 'l1_Layer_2': 0.010669201381030172, 'l1_Layer_3': 0.0032512054761316945, 'l1_Layer_4': 1.0040532504506133e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 185, 'n_units_Layer_3': 260, 'n_units_Layer_4': 75}. Best is trial 596 with value: 3.702898179516891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.46 | sMAPE for Validation Set is: 9.32% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.56 | sMAPE for Test Set is: 11.41% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:06:36,294]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:06:39,626]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:06:43,714]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:07:38,175]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:07:41,762]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:07:45,364]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:07:47,850]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.47 | sMAPE for Validation Set is: 9.37% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.43 | sMAPE for Test Set is: 11.21% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:07:50,660]\u001b[0m Trial 625 finished with value: 4.474846983120208 and parameters: {'n_hidden': 4, 'learning_rate': 0.000587064625459493, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2185660324838395, 'dropout_rate_Layer_2': 0.0029317057569497058, 'dropout_rate_Layer_3': 0.0048876860971116265, 'dropout_rate_Layer_4': 0.017972196818062263, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.5372866546512793e-05, 'l1_Layer_2': 0.010794070386768065, 'l1_Layer_3': 0.004149499615985357, 'l1_Layer_4': 1.0116057301019325e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 185, 'n_units_Layer_3': 260, 'n_units_Layer_4': 75}. Best is trial 596 with value: 3.702898179516891.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:07:54,507]\u001b[0m Trial 622 finished with value: 3.810031790768857 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007716248708827092, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11885201592362653, 'dropout_rate_Layer_2': 0.1714721187382519, 'dropout_rate_Layer_3': 0.05333685673968125, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004041076910104951, 'l1_Layer_2': 3.4965767247090617e-05, 'l1_Layer_3': 2.6884630538191435e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 160, 'n_units_Layer_3': 275}. Best is trial 596 with value: 3.702898179516891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.81 | sMAPE for Validation Set is: 8.05% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.80 | sMAPE for Test Set is: 9.83% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:07:55,336]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:07:59,592]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:08:03,032]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:08:04,855]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:08:09,366]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:08:15,256]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:08:18,480]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:08:27,690]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:08:31,445]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:08:43,671]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:08:46,765]\u001b[0m Trial 640 finished with value: 4.1083638723913305 and parameters: {'n_hidden': 3, 'learning_rate': 0.007649812459295768, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18587778466405364, 'dropout_rate_Layer_2': 0.17924715791391355, 'dropout_rate_Layer_3': 0.06031257037272472, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.728513415681576e-05, 'l1_Layer_2': 0.03033424061851747, 'l1_Layer_3': 3.4504196689588655e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 85, 'n_units_Layer_3': 280}. Best is trial 596 with value: 3.702898179516891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.11 | sMAPE for Validation Set is: 8.67% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.43 | sMAPE for Test Set is: 11.11% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:09:01,533]\u001b[0m Trial 642 finished with value: 4.345121305068779 and parameters: {'n_hidden': 3, 'learning_rate': 0.007841296199880018, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18676639045785376, 'dropout_rate_Layer_2': 0.19086831343523059, 'dropout_rate_Layer_3': 0.06289830283747802, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5758371032528774e-05, 'l1_Layer_2': 0.03202576812902008, 'l1_Layer_3': 3.327228652724895e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 85, 'n_units_Layer_3': 275}. Best is trial 596 with value: 3.702898179516891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.35 | sMAPE for Validation Set is: 9.13% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 4.33 | sMAPE for Test Set is: 10.96% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:09:10,598]\u001b[0m Trial 634 finished with value: 4.433888183892107 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006334325431799275, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21525727620136462, 'dropout_rate_Layer_2': 0.03126792952626571, 'dropout_rate_Layer_3': 0.01550507532916615, 'dropout_rate_Layer_4': 0.04559447282727255, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.63134477979063e-05, 'l1_Layer_2': 0.013293284832227602, 'l1_Layer_3': 0.004724777435645654, 'l1_Layer_4': 1.015833712278834e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 175, 'n_units_Layer_3': 260, 'n_units_Layer_4': 95}. Best is trial 596 with value: 3.702898179516891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.43 | sMAPE for Validation Set is: 9.30% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.68 | sMAPE for Test Set is: 11.66% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:09:14,527]\u001b[0m Trial 643 finished with value: 4.340962185602172 and parameters: {'n_hidden': 3, 'learning_rate': 0.00781903952147529, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18541821154646002, 'dropout_rate_Layer_2': 0.20401907571326852, 'dropout_rate_Layer_3': 0.08588399534138971, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3116969523252613e-05, 'l1_Layer_2': 0.03230956004446394, 'l1_Layer_3': 3.710367759000298e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 85, 'n_units_Layer_3': 275}. Best is trial 596 with value: 3.702898179516891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.34 | sMAPE for Validation Set is: 9.10% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 4.29 | sMAPE for Test Set is: 10.94% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:09:34,510]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:09:39,801]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:09:47,172]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:09:47,616]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:09:55,626]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:10:01,573]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:10:07,193]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:10:17,237]\u001b[0m Trial 641 finished with value: 3.8052899275145724 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007772440440311714, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13213620950905508, 'dropout_rate_Layer_2': 0.18646478999849594, 'dropout_rate_Layer_3': 0.016244084722454068, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002789347923497819, 'l1_Layer_2': 3.5882254196424326e-05, 'l1_Layer_3': 2.0241051446526724e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 180, 'n_units_Layer_3': 265}. Best is trial 596 with value: 3.702898179516891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.81 | sMAPE for Validation Set is: 8.00% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.92 | sMAPE for Test Set is: 10.03% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:10:21,106]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:10:36,542]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:10:36,655]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:10:42,265]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:10:44,991]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:10:52,450]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:10:52,467]\u001b[0m Trial 644 finished with value: 3.7658942427937103 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005027848474190271, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11575427431999591, 'dropout_rate_Layer_2': 0.18379993955231402, 'dropout_rate_Layer_3': 0.014861033469445749, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003883339492434863, 'l1_Layer_2': 3.305003665297531e-05, 'l1_Layer_3': 1.7912325381198667e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 155, 'n_units_Layer_3': 265}. Best is trial 596 with value: 3.702898179516891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.77 | sMAPE for Validation Set is: 7.94% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 3.74 | sMAPE for Test Set is: 9.71% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:10:53,805]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:11:05,187]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:11:08,666]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:11:11,837]\u001b[0m Trial 661 finished with value: 5.259277183685448 and parameters: {'n_hidden': 4, 'learning_rate': 0.002442666101692111, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19586671958763455, 'dropout_rate_Layer_2': 0.3200608170238445, 'dropout_rate_Layer_3': 0.1916868315818789, 'dropout_rate_Layer_4': 0.02606822936486721, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00037695534545445627, 'l1_Layer_2': 4.886831367287682e-05, 'l1_Layer_3': 1.0556590972410341e-05, 'l1_Layer_4': 0.00028303170087200816, 'n_units_Layer_1': 125, 'n_units_Layer_2': 60, 'n_units_Layer_3': 95, 'n_units_Layer_4': 255}. Best is trial 596 with value: 3.702898179516891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.26 | sMAPE for Validation Set is: 10.73% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 4.74 | sMAPE for Test Set is: 11.88% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:11:26,451]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:11:39,072]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:11:39,176]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:11:44,987]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:11:50,393]\u001b[0m Trial 653 finished with value: 3.7448150318694524 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007449367291285789, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15136597852631278, 'dropout_rate_Layer_2': 0.1822369246801105, 'dropout_rate_Layer_3': 0.0006240126703472449, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002862231514349187, 'l1_Layer_2': 3.623029965328661e-05, 'l1_Layer_3': 1.3169423569393597e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 180, 'n_units_Layer_3': 250}. Best is trial 596 with value: 3.702898179516891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.74 | sMAPE for Validation Set is: 7.91% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 3.74 | sMAPE for Test Set is: 9.70% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:11:54,285]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:11:59,223]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:12:07,481]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:12:13,997]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:12:17,723]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:12:23,331]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:12:28,494]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:12:29,808]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:12:35,076]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:12:39,049]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:12:39,788]\u001b[0m Trial 665 finished with value: 4.153081318936979 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005767139975352348, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14140587119243286, 'dropout_rate_Layer_2': 0.2594621363804156, 'dropout_rate_Layer_3': 0.08689848911487663, 'dropout_rate_Layer_4': 0.17822222387971484, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.013280721001536665, 'l1_Layer_2': 0.00013997613108575175, 'l1_Layer_3': 0.0008374967309657673, 'l1_Layer_4': 1.0130588921456257e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 130, 'n_units_Layer_3': 125, 'n_units_Layer_4': 175}. Best is trial 596 with value: 3.702898179516891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.15 | sMAPE for Validation Set is: 8.67% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 3.87 | sMAPE for Test Set is: 10.05% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:12:45,655]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:12:56,865]\u001b[0m Trial 670 finished with value: 4.485644674509821 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014696328504099038, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20973190206037023, 'dropout_rate_Layer_2': 0.02710299534203261, 'dropout_rate_Layer_3': 0.02227797989482865, 'dropout_rate_Layer_4': 0.05877867611795068, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 6.653696414154826e-05, 'l1_Layer_2': 0.04480524650494584, 'l1_Layer_3': 0.004868878807326477, 'l1_Layer_4': 1.4454517587861508e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 205, 'n_units_Layer_3': 260, 'n_units_Layer_4': 65}. Best is trial 596 with value: 3.702898179516891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.49 | sMAPE for Validation Set is: 9.39% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.57 | sMAPE for Test Set is: 11.47% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:13:20,416]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:13:23,858]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:13:27,874]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:13:41,933]\u001b[0m Trial 682 finished with value: 4.4319355625369266 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006703744390557735, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15573616100365115, 'dropout_rate_Layer_2': 0.0858503964939629, 'dropout_rate_Layer_3': 0.03690766777689999, 'dropout_rate_Layer_4': 0.0001824725861958379, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.815203824641627e-05, 'l1_Layer_2': 0.016032191153937964, 'l1_Layer_3': 0.0013710158449742982, 'l1_Layer_4': 2.1962642193976708e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 160, 'n_units_Layer_3': 230, 'n_units_Layer_4': 95}. Best is trial 596 with value: 3.702898179516891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.43 | sMAPE for Validation Set is: 9.31% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.69 | sMAPE for Test Set is: 11.71% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:14:09,246]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:14:12,615]\u001b[0m Trial 676 finished with value: 3.690434710990561 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005001550766717234, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1258129257857791, 'dropout_rate_Layer_2': 0.1843273082366137, 'dropout_rate_Layer_3': 0.014740463727378849, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0018939390884679895, 'l1_Layer_2': 6.312860985396486e-05, 'l1_Layer_3': 1.058609104554936e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 165, 'n_units_Layer_3': 250}. Best is trial 676 with value: 3.690434710990561.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.69 | sMAPE for Validation Set is: 7.76% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 3.89 | sMAPE for Test Set is: 9.99% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:14:17,240]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:14:28,622]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:14:36,401]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:15:35,322]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:15:41,883]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:15:53,342]\u001b[0m Trial 681 finished with value: 3.6760639053846766 and parameters: {'n_hidden': 3, 'learning_rate': 0.000503338962847449, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13780624655211754, 'dropout_rate_Layer_2': 0.20122025582416977, 'dropout_rate_Layer_3': 0.0001940764962486772, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0017558104983869923, 'l1_Layer_2': 4.0712392930217286e-05, 'l1_Layer_3': 3.695841025697934e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 175, 'n_units_Layer_3': 255}. Best is trial 681 with value: 3.6760639053846766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.68 | sMAPE for Validation Set is: 7.71% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 3.80 | sMAPE for Test Set is: 9.75% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:15:56,914]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:16:02,633]\u001b[0m Trial 691 finished with value: 4.460705774878214 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006508568459918524, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15256568291596312, 'dropout_rate_Layer_2': 0.0936706750576248, 'dropout_rate_Layer_3': 0.014507477935800955, 'dropout_rate_Layer_4': 0.035500187834166495, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.771396724753813e-05, 'l1_Layer_2': 0.014797850117138177, 'l1_Layer_3': 0.0015645178553236588, 'l1_Layer_4': 5.3667662005682795e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 160, 'n_units_Layer_3': 230, 'n_units_Layer_4': 90}. Best is trial 681 with value: 3.6760639053846766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.46 | sMAPE for Validation Set is: 9.34% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.53 | sMAPE for Test Set is: 11.38% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:16:05,907]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:16:08,219]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:16:10,657]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:16:20,586]\u001b[0m Trial 689 finished with value: 3.734070797752402 and parameters: {'n_hidden': 3, 'learning_rate': 0.000501657518488532, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13382338623077258, 'dropout_rate_Layer_2': 0.17952141405709413, 'dropout_rate_Layer_3': 0.009552272445878862, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0026420216941107177, 'l1_Layer_2': 7.885756243882394e-05, 'l1_Layer_3': 1.1365164363641514e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 165, 'n_units_Layer_3': 240}. Best is trial 681 with value: 3.6760639053846766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.73 | sMAPE for Validation Set is: 7.84% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 3.86 | sMAPE for Test Set is: 9.92% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:16:43,380]\u001b[0m Trial 693 finished with value: 4.462084619168686 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006706865834770094, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13272832729294712, 'dropout_rate_Layer_2': 0.11492331890656142, 'dropout_rate_Layer_3': 0.030762233832670488, 'dropout_rate_Layer_4': 0.0022547376712683705, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.567794311758717e-05, 'l1_Layer_2': 0.01333980534088199, 'l1_Layer_3': 0.0019646961780621914, 'l1_Layer_4': 2.3894727217108782e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 165, 'n_units_Layer_3': 230, 'n_units_Layer_4': 100}. Best is trial 681 with value: 3.6760639053846766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.46 | sMAPE for Validation Set is: 9.36% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.50 | sMAPE for Test Set is: 11.34% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:16:48,792]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:16:51,170]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:17:06,236]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:17:12,334]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:17:21,526]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:17:31,468]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:17:39,225]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:17:47,732]\u001b[0m Trial 698 finished with value: 3.6763546290444267 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005873340261117576, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1284044993571776, 'dropout_rate_Layer_2': 0.1937841361463533, 'dropout_rate_Layer_3': 0.00022468878267792986, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016077372439188432, 'l1_Layer_2': 5.594999568440402e-05, 'l1_Layer_3': 1.603816355623597e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 155, 'n_units_Layer_3': 265}. Best is trial 681 with value: 3.6760639053846766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.68 | sMAPE for Validation Set is: 7.77% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 3.81 | sMAPE for Test Set is: 9.87% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:17:55,997]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:18:04,070]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:18:07,281]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:18:15,361]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:18:19,386]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:18:20,123]\u001b[0m Trial 700 finished with value: 3.6417186725117427 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005747921505210681, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13837867565296408, 'dropout_rate_Layer_2': 0.17750716280093207, 'dropout_rate_Layer_3': 0.014458891150330331, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0020210218755506697, 'l1_Layer_2': 7.293206528478539e-05, 'l1_Layer_3': 1.0460381168862901e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 170, 'n_units_Layer_3': 245}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.64 | sMAPE for Validation Set is: 7.67% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 3.68 | sMAPE for Test Set is: 9.58% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:18:24,921]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:18:34,388]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:18:39,098]\u001b[0m Trial 703 finished with value: 3.7352644416895218 and parameters: {'n_hidden': 3, 'learning_rate': 0.000553377844353229, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13426511622998202, 'dropout_rate_Layer_2': 0.1777964811159565, 'dropout_rate_Layer_3': 0.00772849392541157, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003267879306192856, 'l1_Layer_2': 6.762136730035808e-05, 'l1_Layer_3': 1.4965740328935161e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 170, 'n_units_Layer_3': 260}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.74 | sMAPE for Validation Set is: 7.91% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 3.88 | sMAPE for Test Set is: 10.00% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:18:43,194]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:18:49,156]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:18:58,699]\u001b[0m Trial 708 finished with value: 4.560106352796326 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007975956201752342, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15119024548936555, 'dropout_rate_Layer_2': 0.19951046315793403, 'dropout_rate_Layer_3': 0.05841162544297543, 'dropout_rate_Layer_4': 0.17697915836952044, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.005285288939932421, 'l1_Layer_2': 3.743226695978647e-05, 'l1_Layer_3': 0.0003940926338422015, 'l1_Layer_4': 2.6988676546991826e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 160, 'n_units_Layer_3': 170, 'n_units_Layer_4': 85}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.56 | sMAPE for Validation Set is: 9.39% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 4.21 | sMAPE for Test Set is: 10.68% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:19:06,904]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:19:10,149]\u001b[0m Trial 714 finished with value: 4.631789687572247 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005713480208559134, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2317057361373826, 'dropout_rate_Layer_2': 0.020307141862113652, 'dropout_rate_Layer_3': 0.03653875373029728, 'dropout_rate_Layer_4': 0.020458850108624013, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.386517887238786e-05, 'l1_Layer_2': 0.0058137924017237705, 'l1_Layer_3': 0.00249807565371531, 'l1_Layer_4': 2.487727455136911e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 190, 'n_units_Layer_3': 250, 'n_units_Layer_4': 80}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.63 | sMAPE for Validation Set is: 9.60% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 4.55 | sMAPE for Test Set is: 11.41% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:19:17,405]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:19:26,365]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:19:28,376]\u001b[0m Trial 717 finished with value: 4.575919148757694 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005788955764654054, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23078628802258278, 'dropout_rate_Layer_2': 0.0456819675603421, 'dropout_rate_Layer_3': 0.00026796101829260066, 'dropout_rate_Layer_4': 0.020462696681545236, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.4534006109787066e-05, 'l1_Layer_2': 0.0057107354518318105, 'l1_Layer_3': 0.0035955288934727075, 'l1_Layer_4': 2.8543135266882755e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 190, 'n_units_Layer_3': 275, 'n_units_Layer_4': 100}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.58 | sMAPE for Validation Set is: 9.51% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 4.74 | sMAPE for Test Set is: 11.78% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:19:35,993]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:19:51,725]\u001b[0m Trial 727 finished with value: 4.202972346293418 and parameters: {'n_hidden': 3, 'learning_rate': 0.0052377704004310565, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21640324834021168, 'dropout_rate_Layer_2': 0.2011590990491866, 'dropout_rate_Layer_3': 0.050307774392318816, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.595154786731998e-05, 'l1_Layer_2': 0.023005327203073262, 'l1_Layer_3': 1.8881929776224017e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 75, 'n_units_Layer_3': 290}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.20 | sMAPE for Validation Set is: 8.90% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 4.23 | sMAPE for Test Set is: 10.84% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:20:00,255]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:20:08,647]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:20:13,809]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:20:19,430]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:20:22,458]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:20:26,644]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:20:34,405]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:20:34,621]\u001b[0m Trial 721 finished with value: 3.6971935539349947 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005053578332901193, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13273877705124246, 'dropout_rate_Layer_2': 0.18978302519253828, 'dropout_rate_Layer_3': 0.0011434644867510564, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0019717837883192037, 'l1_Layer_2': 4.022546368397727e-05, 'l1_Layer_3': 1.0101035968871682e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 165, 'n_units_Layer_3': 245}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.70 | sMAPE for Validation Set is: 7.83% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 3.86 | sMAPE for Test Set is: 10.06% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:20:39,698]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:20:54,861]\u001b[0m Trial 724 finished with value: 3.7553537385001987 and parameters: {'n_hidden': 3, 'learning_rate': 0.000566084833066525, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13365821283169246, 'dropout_rate_Layer_2': 0.18271375916103405, 'dropout_rate_Layer_3': 0.013848932591744911, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0031496266808789634, 'l1_Layer_2': 2.6701635274057613e-05, 'l1_Layer_3': 1.517631213785596e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 170, 'n_units_Layer_3': 255}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.76 | sMAPE for Validation Set is: 7.94% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 3.81 | sMAPE for Test Set is: 9.96% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:20:57,877]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:21:02,178]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:21:18,810]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:21:28,183]\u001b[0m Trial 726 finished with value: 3.723712806532948 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005624813384834512, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16110929274818273, 'dropout_rate_Layer_2': 0.3067684221399457, 'dropout_rate_Layer_3': 0.00041301512551820616, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0024419499788182384, 'l1_Layer_2': 3.523386841443478e-05, 'l1_Layer_3': 1.4579361013104961e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 160, 'n_units_Layer_3': 250}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.72 | sMAPE for Validation Set is: 7.84% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 3.68 | sMAPE for Test Set is: 9.60% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:21:37,186]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:21:40,948]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:22:08,036]\u001b[0m Trial 740 finished with value: 4.561712186749423 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006620881035775098, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11743294584427767, 'dropout_rate_Layer_2': 0.25130907017253895, 'dropout_rate_Layer_3': 0.2518673490894328, 'dropout_rate_Layer_4': 0.1537501865567171, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.015050216488355682, 'l1_Layer_2': 1.4134693997020693e-05, 'l1_Layer_3': 0.001647012835970356, 'l1_Layer_4': 4.028487571311868e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 130, 'n_units_Layer_3': 145, 'n_units_Layer_4': 160}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.56 | sMAPE for Validation Set is: 9.36% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 4.68 | sMAPE for Test Set is: 11.57% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:22:16,174]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:22:24,265]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:22:27,920]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:22:33,605]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:22:33,984]\u001b[0m Trial 741 finished with value: 4.484432196239742 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006609083659433482, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2638864554234804, 'dropout_rate_Layer_2': 0.21669876348963107, 'dropout_rate_Layer_3': 0.11512214555362728, 'dropout_rate_Layer_4': 0.2927693404531127, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.014167453942990798, 'l1_Layer_2': 8.374325423791361e-05, 'l1_Layer_3': 0.004119068255865432, 'l1_Layer_4': 3.7578532302072305e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 90, 'n_units_Layer_3': 145, 'n_units_Layer_4': 180}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.48 | sMAPE for Validation Set is: 9.29% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.29 | sMAPE for Test Set is: 11.10% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:22:40,261]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:22:40,954]\u001b[0m Trial 737 finished with value: 3.7165920848442418 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005543852406737818, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14309868857295846, 'dropout_rate_Layer_2': 0.23805033040986456, 'dropout_rate_Layer_3': 0.010420895831487803, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0019080263803628577, 'l1_Layer_2': 2.1738917286549196e-05, 'l1_Layer_3': 1.3231411856972945e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 155, 'n_units_Layer_3': 240}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.72 | sMAPE for Validation Set is: 7.79% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 3.80 | sMAPE for Test Set is: 9.86% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:22:46,001]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:22:46,863]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:22:55,149]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:23:01,257]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:23:16,273]\u001b[0m Trial 746 finished with value: 4.447656322311423 and parameters: {'n_hidden': 4, 'learning_rate': 0.001237850123332223, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1755794095757193, 'dropout_rate_Layer_2': 0.0622319308033744, 'dropout_rate_Layer_3': 0.05351609936131024, 'dropout_rate_Layer_4': 0.0425666275008231, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.686299851273726e-05, 'l1_Layer_2': 0.007333848972030674, 'l1_Layer_3': 0.001970384155211704, 'l1_Layer_4': 1.2422705356272206e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 220, 'n_units_Layer_3': 225, 'n_units_Layer_4': 115}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:23:16,427]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.45 | sMAPE for Validation Set is: 9.29% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.83 | sMAPE for Test Set is: 11.92% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:23:37,172]\u001b[0m Trial 749 finished with value: 4.406440249794689 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011972539438541024, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17290050679856112, 'dropout_rate_Layer_2': 0.07758052792411892, 'dropout_rate_Layer_3': 0.010126257241141357, 'dropout_rate_Layer_4': 0.008840888544812693, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.1603259470877835e-05, 'l1_Layer_2': 0.008621841169232907, 'l1_Layer_3': 0.0020577112213897675, 'l1_Layer_4': 1.3124560756042488e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 220, 'n_units_Layer_3': 240, 'n_units_Layer_4': 70}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.41 | sMAPE for Validation Set is: 9.25% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.56 | sMAPE for Test Set is: 11.42% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:23:42,379]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:24:04,116]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:24:04,840]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:24:09,935]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:24:26,571]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:24:48,044]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:24:51,074]\u001b[0m Trial 754 finished with value: 3.754490693627789 and parameters: {'n_hidden': 3, 'learning_rate': 0.000558456312220899, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14782100816665109, 'dropout_rate_Layer_2': 0.19904743018178517, 'dropout_rate_Layer_3': 0.014377017797805557, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012460802501650038, 'l1_Layer_2': 1.9969603044045785e-05, 'l1_Layer_3': 1.3959305486966867e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 150, 'n_units_Layer_3': 250}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 7.82% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 3.78 | sMAPE for Test Set is: 9.74% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:24:56,646]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:25:04,528]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:25:08,542]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:25:15,795]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:25:21,695]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:25:24,962]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:25:32,844]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:25:33,081]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:25:37,066]\u001b[0m Trial 763 finished with value: 3.8220303234485726 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005577302569530908, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13388698612935168, 'dropout_rate_Layer_2': 0.185735363978989, 'dropout_rate_Layer_3': 0.0215995805243999, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0034469286874541276, 'l1_Layer_2': 3.1105726058782976e-05, 'l1_Layer_3': 2.3386023379305496e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 170, 'n_units_Layer_3': 235}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.82 | sMAPE for Validation Set is: 8.04% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.90 | sMAPE for Test Set is: 10.00% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:25:54,362]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:25:57,601]\u001b[0m Trial 769 finished with value: 4.408660235245136 and parameters: {'n_hidden': 4, 'learning_rate': 0.001158353301072096, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14267251207524945, 'dropout_rate_Layer_2': 0.07706488189515723, 'dropout_rate_Layer_3': 0.051102828225353586, 'dropout_rate_Layer_4': 0.04397462575497142, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.979807924047853e-05, 'l1_Layer_2': 0.007659818199673956, 'l1_Layer_3': 0.001732521521250345, 'l1_Layer_4': 1.3356595324270243e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 225, 'n_units_Layer_3': 220, 'n_units_Layer_4': 115}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.41 | sMAPE for Validation Set is: 9.26% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.67 | sMAPE for Test Set is: 11.65% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:26:01,151]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:26:06,025]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:26:12,818]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:26:36,885]\u001b[0m Trial 773 finished with value: 3.687354996077842 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005036040606868534, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1293334173867572, 'dropout_rate_Layer_2': 0.20404067559448652, 'dropout_rate_Layer_3': 0.02073475683283066, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0018945357683721295, 'l1_Layer_2': 2.6640621820411408e-05, 'l1_Layer_3': 2.444168020349245e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 165, 'n_units_Layer_3': 250}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.69 | sMAPE for Validation Set is: 7.81% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 3.82 | sMAPE for Test Set is: 9.80% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:26:40,216]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:26:40,468]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:26:55,312]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:26:55,627]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:27:02,851]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:27:03,207]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:27:04,284]\u001b[0m Trial 780 finished with value: 3.6780481920373287 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006811267552308771, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12806917932032857, 'dropout_rate_Layer_2': 0.20231698802793213, 'dropout_rate_Layer_3': 0.01917687413251222, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0020394309502011153, 'l1_Layer_2': 2.765461351884384e-05, 'l1_Layer_3': 2.215762806285315e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 165, 'n_units_Layer_3': 235}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.68 | sMAPE for Validation Set is: 7.73% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 3.73 | sMAPE for Test Set is: 9.65% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:27:08,323]\u001b[0m Trial 779 finished with value: 3.758820219859065 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006719130700418582, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13043085688199327, 'dropout_rate_Layer_2': 0.2041673316465439, 'dropout_rate_Layer_3': 0.01822331026641364, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0028781362937272364, 'l1_Layer_2': 2.7465533521619474e-05, 'l1_Layer_3': 2.211329929271946e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 165, 'n_units_Layer_3': 240}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.76 | sMAPE for Validation Set is: 7.90% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 3.93 | sMAPE for Test Set is: 10.03% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:27:11,447]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:27:12,334]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:27:14,146]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:27:18,137]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:27:22,577]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:27:26,967]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:27:31,350]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:28:23,673]\u001b[0m Trial 792 finished with value: 4.165714646322546 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005517624829453841, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1373733459965037, 'dropout_rate_Layer_2': 0.2315027584504157, 'dropout_rate_Layer_3': 0.09368922780348779, 'dropout_rate_Layer_4': 0.1694649247477476, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.01136343212904075, 'l1_Layer_2': 0.00015158107860797833, 'l1_Layer_3': 0.0004158361508561755, 'l1_Layer_4': 1.4872260841710018e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 100, 'n_units_Layer_3': 120, 'n_units_Layer_4': 175}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.17 | sMAPE for Validation Set is: 8.85% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.40 | sMAPE for Test Set is: 11.34% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:28:26,454]\u001b[0m Trial 786 finished with value: 4.31663487416628 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009090739081261117, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19024393549773352, 'dropout_rate_Layer_2': 0.10474730628021811, 'dropout_rate_Layer_3': 0.034103469809477496, 'dropout_rate_Layer_4': 0.04891923252962656, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.7164395502799916e-05, 'l1_Layer_2': 0.004042603792882437, 'l1_Layer_3': 0.0014732331904989307, 'l1_Layer_4': 3.7711438397850464e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 225, 'n_units_Layer_3': 225, 'n_units_Layer_4': 85}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.32 | sMAPE for Validation Set is: 9.00% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 4.19 | sMAPE for Test Set is: 10.70% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:28:45,035]\u001b[0m Trial 796 finished with value: 4.522380130983599 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005146159678891365, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13880444021466226, 'dropout_rate_Layer_2': 0.26807201860900187, 'dropout_rate_Layer_3': 0.09163955484550448, 'dropout_rate_Layer_4': 0.17883751775622522, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.027706612550545153, 'l1_Layer_2': 0.00014685073305589826, 'l1_Layer_3': 0.0004332626658552676, 'l1_Layer_4': 1.1537366545255846e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 100, 'n_units_Layer_3': 120, 'n_units_Layer_4': 165}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.52 | sMAPE for Validation Set is: 9.36% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 4.68 | sMAPE for Test Set is: 11.88% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:28:47,577]\u001b[0m Trial 790 finished with value: 4.355378418168542 and parameters: {'n_hidden': 4, 'learning_rate': 0.000895234042390751, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16302415884391736, 'dropout_rate_Layer_2': 0.10642592961369667, 'dropout_rate_Layer_3': 0.06968259201706788, 'dropout_rate_Layer_4': 0.0484801866913954, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00016910383480505162, 'l1_Layer_2': 0.0038309154190496434, 'l1_Layer_3': 0.0015888320415282228, 'l1_Layer_4': 3.385881144991117e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 170, 'n_units_Layer_3': 220, 'n_units_Layer_4': 115}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.36 | sMAPE for Validation Set is: 9.01% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 4.48 | sMAPE for Test Set is: 11.17% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:28:47,998]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:28:49,323]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:28:57,053]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:29:27,390]\u001b[0m Trial 798 finished with value: 3.6804515165767637 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006014322494426263, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12944388645995675, 'dropout_rate_Layer_2': 0.1947639130457798, 'dropout_rate_Layer_3': 0.013803345522892481, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002144625376675774, 'l1_Layer_2': 2.6409906408437423e-05, 'l1_Layer_3': 1.8560642081365712e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 165, 'n_units_Layer_3': 230}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.68 | sMAPE for Validation Set is: 7.74% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 3.90 | sMAPE for Test Set is: 9.97% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:29:42,507]\u001b[0m Trial 801 finished with value: 3.6853796543755357 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006047326120001101, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1398599302833285, 'dropout_rate_Layer_2': 0.2092178068081199, 'dropout_rate_Layer_3': 0.013862433840389616, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016973068209721722, 'l1_Layer_2': 2.011674241234828e-05, 'l1_Layer_3': 1.0185308898024863e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 155, 'n_units_Layer_3': 235}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.69 | sMAPE for Validation Set is: 7.79% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 3.72 | sMAPE for Test Set is: 9.63% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:29:46,586]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:29:51,755]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:29:52,281]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:29:57,232]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:29:58,431]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:30:00,267]\u001b[0m Trial 803 finished with value: 3.6733421332964915 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006970482443012577, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14724281071151343, 'dropout_rate_Layer_2': 0.16362454248401817, 'dropout_rate_Layer_3': 0.0193592483507325, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002784805856485416, 'l1_Layer_2': 2.042802496822757e-05, 'l1_Layer_3': 1.0008322135184348e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 155, 'n_units_Layer_3': 235}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.67 | sMAPE for Validation Set is: 7.78% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 3.80 | sMAPE for Test Set is: 9.78% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:30:04,916]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:30:06,597]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:30:11,330]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:30:22,754]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:30:25,336]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:30:28,095]\u001b[0m Trial 800 finished with value: 4.194696617956713 and parameters: {'n_hidden': 4, 'learning_rate': 0.00091093024831604, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16116311192113572, 'dropout_rate_Layer_2': 0.10298523156313494, 'dropout_rate_Layer_3': 0.066322413175231, 'dropout_rate_Layer_4': 0.00943736805167887, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0001546498954509541, 'l1_Layer_2': 0.003889345833335067, 'l1_Layer_3': 0.0014363486151784898, 'l1_Layer_4': 3.837323810305644e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 235, 'n_units_Layer_3': 215, 'n_units_Layer_4': 85}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.19 | sMAPE for Validation Set is: 8.78% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 4.30 | sMAPE for Test Set is: 10.79% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:30:30,497]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:30:35,073]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:30:35,256]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:30:36,492]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:30:42,177]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:30:42,449]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:30:48,392]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:30:50,588]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:30:56,135]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:31:00,377]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:31:09,821]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:31:14,300]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:31:18,819]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:31:20,790]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:31:23,269]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:31:23,687]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:31:28,374]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:31:33,469]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:31:37,627]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:31:46,088]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:31:48,351]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:31:49,142]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:31:54,521]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:31:54,862]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:31:59,836]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:32:00,777]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:32:08,899]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:32:12,003]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:32:14,211]\u001b[0m Trial 840 finished with value: 4.09189694607946 and parameters: {'n_hidden': 3, 'learning_rate': 0.006208632056453452, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18833526853388155, 'dropout_rate_Layer_2': 0.19078560712807408, 'dropout_rate_Layer_3': 0.04668210387040729, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00041715530762190635, 'l1_Layer_2': 0.04451254013087225, 'l1_Layer_3': 5.012743561731266e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 75, 'n_units_Layer_3': 260}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.09 | sMAPE for Validation Set is: 8.66% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.15 | sMAPE for Test Set is: 10.63% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:32:17,156]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:32:20,653]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:32:21,317]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:32:25,428]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:32:32,492]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:32:36,626]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:32:45,519]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:32:46,015]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:32:53,826]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:32:55,898]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:32:56,779]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:33:03,203]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:33:05,167]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:33:08,875]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:33:12,205]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:33:17,519]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:33:31,510]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:33:34,969]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:33:35,661]\u001b[0m Trial 862 finished with value: 4.250561393537114 and parameters: {'n_hidden': 3, 'learning_rate': 0.006895811914166267, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21384062900084042, 'dropout_rate_Layer_2': 0.20509011082388753, 'dropout_rate_Layer_3': 0.048078487005405, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006076780211382312, 'l1_Layer_2': 0.030767583532171284, 'l1_Layer_3': 4.023995243255962e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 65, 'n_units_Layer_3': 285}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.25 | sMAPE for Validation Set is: 8.91% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.27 | sMAPE for Test Set is: 10.97% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:33:44,601]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:33:51,734]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:33:53,868]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:33:56,751]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:33:56,908]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:34:02,160]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:34:02,617]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:34:10,952]\u001b[0m Trial 868 finished with value: 4.295002846127339 and parameters: {'n_hidden': 3, 'learning_rate': 0.007169101106954168, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2138435834176056, 'dropout_rate_Layer_2': 0.19997083289528347, 'dropout_rate_Layer_3': 0.059005164302898545, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00046446639870587297, 'l1_Layer_2': 0.034780156493759186, 'l1_Layer_3': 3.065771252411356e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 60, 'n_units_Layer_3': 275}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.30 | sMAPE for Validation Set is: 8.91% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.13 | sMAPE for Test Set is: 10.50% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:34:16,171]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:34:22,225]\u001b[0m Trial 859 finished with value: 4.489610964656987 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007947489188255778, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19988846153777876, 'dropout_rate_Layer_2': 0.08878854106572764, 'dropout_rate_Layer_3': 0.028822056779369665, 'dropout_rate_Layer_4': 0.055414055144225975, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.2008605378724167e-05, 'l1_Layer_2': 0.025173858977496036, 'l1_Layer_3': 0.001651270372945842, 'l1_Layer_4': 2.2758772126969517e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 170, 'n_units_Layer_3': 245, 'n_units_Layer_4': 120}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.49 | sMAPE for Validation Set is: 9.37% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.88 | sMAPE for Test Set is: 12.02% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:34:23,749]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:34:25,228]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:34:31,065]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:34:38,808]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:34:42,027]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:34:42,294]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:34:42,894]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:34:50,003]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:34:50,331]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:34:50,783]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:34:56,635]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:34:58,474]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:35:03,509]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:35:04,092]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:35:04,378]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:35:13,081]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:35:16,287]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:35:16,318]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:35:16,816]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:35:22,910]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:35:27,591]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:35:28,038]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:35:32,822]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:35:34,771]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:35:37,384]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:35:41,663]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:35:41,849]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:35:43,260]\u001b[0m Trial 871 finished with value: 4.409079551576904 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008064666641065956, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18731807815529672, 'dropout_rate_Layer_2': 0.07798719102584982, 'dropout_rate_Layer_3': 0.04524075462000105, 'dropout_rate_Layer_4': 0.032348546245402246, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00032572490478737875, 'l1_Layer_2': 0.009649797407268557, 'l1_Layer_3': 0.00122448310320006, 'l1_Layer_4': 2.7602478141290756e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 245, 'n_units_Layer_3': 205, 'n_units_Layer_4': 120}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.41 | sMAPE for Validation Set is: 9.25% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.55 | sMAPE for Test Set is: 11.42% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:36:01,137]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:36:06,328]\u001b[0m Trial 894 finished with value: 3.8157545666529806 and parameters: {'n_hidden': 3, 'learning_rate': 0.00611962430015842, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22210601273924038, 'dropout_rate_Layer_2': 0.1278140124036089, 'dropout_rate_Layer_3': 0.04658640598389605, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006438963967436911, 'l1_Layer_2': 0.016501181016862806, 'l1_Layer_3': 2.4778583228410705e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 95, 'n_units_Layer_3': 225}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.82 | sMAPE for Validation Set is: 8.11% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.76 | sMAPE for Test Set is: 9.74% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:36:06,962]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:36:16,610]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:36:20,420]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:36:21,237]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:36:26,001]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:36:31,359]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:36:33,347]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:36:36,091]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:36:36,575]\u001b[0m Trial 901 finished with value: 4.4952318939049105 and parameters: {'n_hidden': 4, 'learning_rate': 0.00278972810913225, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.105753787330535, 'dropout_rate_Layer_2': 0.25228209092668097, 'dropout_rate_Layer_3': 0.2173610772208665, 'dropout_rate_Layer_4': 0.2030663412969868, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.100420535954633e-05, 'l1_Layer_2': 5.62965319672606e-05, 'l1_Layer_3': 0.00013081149349960974, 'l1_Layer_4': 1.7031310002173203e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 85, 'n_units_Layer_3': 135, 'n_units_Layer_4': 290}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.50 | sMAPE for Validation Set is: 9.42% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 4.79 | sMAPE for Test Set is: 12.19% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:36:37,176]\u001b[0m Trial 903 finished with value: 4.373854334438757 and parameters: {'n_hidden': 4, 'learning_rate': 0.004469448530766243, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04315594559272865, 'dropout_rate_Layer_2': 0.2500477645834782, 'dropout_rate_Layer_3': 0.08022962468954332, 'dropout_rate_Layer_4': 0.21334169336128914, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.784900552675827e-05, 'l1_Layer_2': 9.070109164978672e-05, 'l1_Layer_3': 0.0002633949393718434, 'l1_Layer_4': 1.848285864524554e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 90, 'n_units_Layer_3': 140, 'n_units_Layer_4': 75}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.37 | sMAPE for Validation Set is: 8.97% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.28 | sMAPE for Test Set is: 10.84% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:36:39,035]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:36:40,935]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:36:49,194]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:36:52,037]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:36:55,087]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:37:00,211]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:37:04,743]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:37:13,216]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:37:17,767]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:37:25,652]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:37:26,322]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:37:29,986]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:37:33,998]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:37:34,043]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:37:39,425]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:37:42,796]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:37:42,860]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:37:51,228]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:37:54,564]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:38:37,294]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:38:45,531]\u001b[0m Trial 932 finished with value: 3.8089854711771456 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008078972866834528, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12721450975128118, 'dropout_rate_Layer_2': 0.17360669041085153, 'dropout_rate_Layer_3': 0.011033761141501439, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002083285776775134, 'l1_Layer_2': 2.7692306655657886e-05, 'l1_Layer_3': 1.3800844171760474e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 145, 'n_units_Layer_3': 245}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.81 | sMAPE for Validation Set is: 7.98% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.86 | sMAPE for Test Set is: 9.94% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:38:51,168]\u001b[0m Trial 915 finished with value: 3.800400564974692 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007480180264984095, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11030112096121131, 'dropout_rate_Layer_2': 0.23545980989201987, 'dropout_rate_Layer_3': 0.0068122369953818864, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0051636385773761295, 'l1_Layer_2': 1.8887650062307898e-05, 'l1_Layer_3': 1.0008711240072237e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 180, 'n_units_Layer_3': 255}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.80 | sMAPE for Validation Set is: 8.07% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.04 | sMAPE for Test Set is: 10.44% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:38:54,909]\u001b[0m Trial 930 finished with value: 4.204004699504576 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005580809976662834, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1412058053385022, 'dropout_rate_Layer_2': 0.2708382260730199, 'dropout_rate_Layer_3': 0.25996714975138735, 'dropout_rate_Layer_4': 0.17328078811509517, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.004490613672148626, 'l1_Layer_2': 0.00016738738222622595, 'l1_Layer_3': 0.0008759219640103369, 'l1_Layer_4': 1.1699584059526521e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 115, 'n_units_Layer_3': 125, 'n_units_Layer_4': 190}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.20 | sMAPE for Validation Set is: 8.76% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 4.49 | sMAPE for Test Set is: 11.27% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:38:57,208]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:38:57,894]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:38:59,759]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:39:02,707]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:39:04,562]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:39:09,416]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:39:13,849]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:39:13,949]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:39:15,262]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:39:22,383]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:39:27,436]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:39:29,134]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:39:34,659]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:39:39,733]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:39:42,475]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:39:44,335]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:39:47,954]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:39:50,741]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:39:53,424]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:39:55,621]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:39:58,465]\u001b[0m Trial 935 finished with value: 4.177237003551073 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005072458365432983, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1343526849935003, 'dropout_rate_Layer_2': 0.2605465551974759, 'dropout_rate_Layer_3': 0.0522811193648436, 'dropout_rate_Layer_4': 0.17168225980910337, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.012074112888980706, 'l1_Layer_2': 0.00016958501482429488, 'l1_Layer_3': 0.000838157212513961, 'l1_Layer_4': 1.1369338176843974e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 110, 'n_units_Layer_3': 120, 'n_units_Layer_4': 190}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.18 | sMAPE for Validation Set is: 8.86% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 4.53 | sMAPE for Test Set is: 11.53% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:39:58,816]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:40:00,048]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:40:04,154]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:40:09,939]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:40:18,395]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:40:20,568]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:40:23,761]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:40:24,629]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:40:29,971]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:40:34,792]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:40:36,309]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:40:38,993]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:40:43,405]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:40:46,839]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:40:58,986]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:40:59,718]\u001b[0m Trial 956 finished with value: 3.701385151033518 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006534506680306655, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15070800188646105, 'dropout_rate_Layer_2': 0.16464994055669946, 'dropout_rate_Layer_3': 0.005671415167211152, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016245472309533737, 'l1_Layer_2': 1.5028159417905628e-05, 'l1_Layer_3': 1.0157025473426351e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 170, 'n_units_Layer_3': 265}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.70 | sMAPE for Validation Set is: 7.78% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 3.94 | sMAPE for Test Set is: 10.03% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:41:05,394]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:41:09,026]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:41:13,774]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:41:18,377]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:41:18,513]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:41:21,449]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:41:25,391]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:41:25,575]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:41:26,237]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:41:32,915]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:41:33,175]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:41:40,378]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:41:44,109]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:41:47,073]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:41:50,644]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:41:52,886]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:41:56,292]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:41:58,176]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:42:03,654]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:42:04,206]\u001b[0m Trial 973 finished with value: 4.472217417065216 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008677444197104999, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1310504291672242, 'dropout_rate_Layer_2': 0.21005031992185225, 'dropout_rate_Layer_3': 0.02704192316466829, 'dropout_rate_Layer_4': 0.11776974214980847, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.01612636857744822, 'l1_Layer_2': 0.0001203213438406201, 'l1_Layer_3': 0.0005246433339149136, 'l1_Layer_4': 1.4804556531986251e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 105, 'n_units_Layer_3': 115, 'n_units_Layer_4': 150}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.47 | sMAPE for Validation Set is: 9.32% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.43 | sMAPE for Test Set is: 11.39% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:42:09,792]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:42:10,471]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:42:16,669]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:42:20,687]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:42:22,324]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:42:38,863]\u001b[0m Trial 982 finished with value: 3.6696446327405883 and parameters: {'n_hidden': 3, 'learning_rate': 0.000685592813933337, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17089719470438053, 'dropout_rate_Layer_2': 0.15278401299058414, 'dropout_rate_Layer_3': 0.01443544297343445, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001654557299544687, 'l1_Layer_2': 3.5911697087503805e-05, 'l1_Layer_3': 1.631972929012855e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 170, 'n_units_Layer_3': 260}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.67 | sMAPE for Validation Set is: 7.79% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 3.71 | sMAPE for Test Set is: 9.58% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:42:41,854]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:42:45,927]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:43:03,487]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:43:06,655]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:43:10,870]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:43:11,012]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:43:16,840]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:43:20,911]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:43:25,005]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:43:29,331]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:43:31,575]\u001b[0m Trial 993 finished with value: 3.700514388214277 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006871343615421793, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13358874098752638, 'dropout_rate_Layer_2': 0.17126774577532292, 'dropout_rate_Layer_3': 0.01937832903160529, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016957652370623879, 'l1_Layer_2': 4.387577711705192e-05, 'l1_Layer_3': 1.4915949346733746e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 145, 'n_units_Layer_3': 235}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.70 | sMAPE for Validation Set is: 7.76% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 3.77 | sMAPE for Test Set is: 9.76% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:43:35,846]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:43:43,256]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:43:47,511]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:43:49,869]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:43:50,928]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:43:52,374]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:43:54,810]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:43:58,411]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:43:58,793]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:44:04,995]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:44:07,869]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:44:13,597]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:44:18,577]\u001b[0m Trial 999 finished with value: 3.691417351563772 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005469048378825966, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1584294283457805, 'dropout_rate_Layer_2': 0.19640771869588514, 'dropout_rate_Layer_3': 1.2534440847311373e-05, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0021058420260460283, 'l1_Layer_2': 6.464723129994189e-05, 'l1_Layer_3': 1.2252318660305671e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 155, 'n_units_Layer_3': 230}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.69 | sMAPE for Validation Set is: 7.79% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 3.76 | sMAPE for Test Set is: 9.79% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:44:18,963]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:44:26,307]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:44:31,878]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:44:32,707]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:44:39,703]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:44:44,591]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:44:51,544]\u001b[0m Trial 1020 finished with value: 4.358335289500058 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010207364083325635, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06900743784388363, 'dropout_rate_Layer_2': 0.2903147294190039, 'dropout_rate_Layer_3': 0.03921363639928308, 'dropout_rate_Layer_4': 0.16175470310843784, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.011119297531628351, 'l1_Layer_2': 8.689889655007364e-05, 'l1_Layer_3': 0.002402492034404287, 'l1_Layer_4': 3.0493662262935658e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 255, 'n_units_Layer_3': 105, 'n_units_Layer_4': 195}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.36 | sMAPE for Validation Set is: 9.17% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 4.33 | sMAPE for Test Set is: 11.18% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:44:53,957]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:44:58,841]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:45:06,656]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:45:11,666]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:45:15,429]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:45:18,441]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:45:21,387]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:45:24,514]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:45:31,843]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:45:38,689]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:45:41,433]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:45:46,978]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:46:02,097]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:46:07,758]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:46:07,856]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:46:14,464]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:46:19,789]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:46:32,339]\u001b[0m Trial 1029 finished with value: 3.691755327163906 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005009925193078065, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15533196599421448, 'dropout_rate_Layer_2': 0.16668274734443123, 'dropout_rate_Layer_3': 0.007091499371004963, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002018361997702699, 'l1_Layer_2': 7.086575246391897e-05, 'l1_Layer_3': 1.010761904608171e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 145, 'n_units_Layer_3': 220}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.69 | sMAPE for Validation Set is: 7.75% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 3.84 | sMAPE for Test Set is: 9.87% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:46:33,497]\u001b[0m Trial 1032 finished with value: 3.7036070976110818 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005501660411797285, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15140196571470238, 'dropout_rate_Layer_2': 0.17600121817872583, 'dropout_rate_Layer_3': 0.010329001642433716, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0020511927030519516, 'l1_Layer_2': 7.191812225590208e-05, 'l1_Layer_3': 1.408805482148541e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 150, 'n_units_Layer_3': 230}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.70 | sMAPE for Validation Set is: 7.79% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 3.87 | sMAPE for Test Set is: 9.92% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:46:39,159]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:46:42,518]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:46:45,888]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:46:47,759]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:46:48,926]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:46:51,613]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:46:55,775]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:46:57,651]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:47:00,699]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:47:01,516]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:47:10,792]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:47:17,543]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:47:20,087]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:47:24,884]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:47:28,030]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:47:43,703]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:48:00,230]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:48:00,737]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:48:07,545]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:48:15,967]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:48:23,938]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:48:28,942]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:48:34,948]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:48:41,085]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:48:43,773]\u001b[0m Trial 1061 finished with value: 3.778664225328791 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006049222199671756, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15451203235962488, 'dropout_rate_Layer_2': 0.16956920063616115, 'dropout_rate_Layer_3': 0.0076404351795919916, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002727207797122499, 'l1_Layer_2': 0.00011662087701607796, 'l1_Layer_3': 1.7709002237633587e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 145, 'n_units_Layer_3': 215}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.78 | sMAPE for Validation Set is: 7.95% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 3.94 | sMAPE for Test Set is: 10.08% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:48:44,928]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:48:48,148]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:48:50,666]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:48:54,196]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:49:00,368]\u001b[0m Trial 1069 finished with value: 3.728374013252543 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005488580406710964, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17130839043901355, 'dropout_rate_Layer_2': 0.15513123905152046, 'dropout_rate_Layer_3': 0.021383387427845686, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002997003623478157, 'l1_Layer_2': 5.728818334422731e-05, 'l1_Layer_3': 2.070527210774389e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 165, 'n_units_Layer_3': 230}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.73 | sMAPE for Validation Set is: 7.90% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 3.78 | sMAPE for Test Set is: 9.77% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:49:03,048]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:49:07,289]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:49:07,565]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:49:13,647]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:49:19,488]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:49:20,376]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:49:24,819]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:49:31,802]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:49:35,099]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:49:39,696]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:49:57,263]\u001b[0m Trial 1050 finished with value: 3.6921692255144904 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005440008766995153, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16854558462023095, 'dropout_rate_Layer_2': 0.1596717347975591, 'dropout_rate_Layer_3': 0.006838914880983828, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00204531845961029, 'l1_Layer_2': 0.00012711025120685154, 'l1_Layer_3': 1.1302642713259313e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 140, 'n_units_Layer_3': 225}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.69 | sMAPE for Validation Set is: 7.69% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 3.67 | sMAPE for Test Set is: 9.56% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:50:00,629]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:50:12,370]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:50:18,783]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:50:38,110]\u001b[0m Trial 1088 finished with value: 4.110886099955667 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005392440706588999, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14141534592283309, 'dropout_rate_Layer_2': 0.2575960228576619, 'dropout_rate_Layer_3': 0.2798497669908204, 'dropout_rate_Layer_4': 0.15293407599198774, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0038066709314054674, 'l1_Layer_2': 0.00016359833795798263, 'l1_Layer_3': 0.0008211235364984372, 'l1_Layer_4': 1.2144026697649543e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 115, 'n_units_Layer_3': 120, 'n_units_Layer_4': 190}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.11 | sMAPE for Validation Set is: 8.70% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.30 | sMAPE for Test Set is: 10.98% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:50:42,275]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:50:42,544]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:50:48,761]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:51:15,691]\u001b[0m Trial 1091 finished with value: 3.6418886152459264 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005567773890242706, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1189672873462895, 'dropout_rate_Layer_2': 0.14194421287130227, 'dropout_rate_Layer_3': 0.02215789567875544, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002326180221541222, 'l1_Layer_2': 5.195304937088388e-05, 'l1_Layer_3': 2.0187280176980637e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 165, 'n_units_Layer_3': 235}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.64 | sMAPE for Validation Set is: 7.69% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 3.83 | sMAPE for Test Set is: 9.90% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:51:21,350]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:51:23,765]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:51:28,122]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:51:31,602]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:51:35,853]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:51:38,896]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:51:44,117]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:51:44,483]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:51:52,878]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:51:57,275]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:51:57,387]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:52:04,373]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:52:05,554]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:52:10,046]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:52:14,442]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:52:16,977]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:52:20,421]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:52:22,960]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:52:26,130]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:52:29,393]\u001b[0m Trial 1085 finished with value: 4.4418217235659325 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005159843446886509, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05644759402821983, 'dropout_rate_Layer_2': 0.1825420007894474, 'dropout_rate_Layer_3': 0.0010216283379376745, 'dropout_rate_Layer_4': 0.25237502390448585, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.04383787934015025, 'l1_Layer_2': 0.0032350657357074685, 'l1_Layer_3': 0.004872684781553613, 'l1_Layer_4': 0.0006069770994681077, 'n_units_Layer_1': 95, 'n_units_Layer_2': 295, 'n_units_Layer_3': 195, 'n_units_Layer_4': 240}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.44 | sMAPE for Validation Set is: 9.22% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.53 | sMAPE for Test Set is: 11.42% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:52:32,568]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:52:35,029]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:52:35,865]\u001b[0m Trial 1099 finished with value: 4.416332589048248 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006997843507317258, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2075159842479505, 'dropout_rate_Layer_2': 0.10114122128660291, 'dropout_rate_Layer_3': 0.02765751289918637, 'dropout_rate_Layer_4': 0.0592329897857448, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.0299768442766388e-05, 'l1_Layer_2': 0.012027616381758652, 'l1_Layer_3': 0.0014684412133115655, 'l1_Layer_4': 1.0949572419923803e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 240, 'n_units_Layer_3': 255, 'n_units_Layer_4': 90}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:52:35,956]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.42 | sMAPE for Validation Set is: 9.25% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.53 | sMAPE for Test Set is: 11.38% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:52:43,810]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:52:43,989]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:52:51,245]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:52:54,577]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:52:58,176]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:53:03,149]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:53:03,949]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:53:08,059]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:53:09,162]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:53:23,588]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:53:26,696]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:53:41,218]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:53:51,341]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:53:54,714]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:53:55,602]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:54:00,853]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:54:03,067]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:54:05,577]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:54:11,222]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:54:18,746]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:54:20,704]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:54:25,377]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:54:29,026]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:54:33,550]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:54:37,212]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:54:41,434]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:54:47,669]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:54:59,983]\u001b[0m Trial 1131 finished with value: 4.169960642069634 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005021219007538337, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10900937772436722, 'dropout_rate_Layer_2': 0.32569352314127853, 'dropout_rate_Layer_3': 0.2817775210755869, 'dropout_rate_Layer_4': 0.15042685179475235, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0007022579627242243, 'l1_Layer_2': 0.0002714050742384734, 'l1_Layer_3': 0.0008002872027535966, 'l1_Layer_4': 1.284717499015869e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 100, 'n_units_Layer_3': 100, 'n_units_Layer_4': 165}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.17 | sMAPE for Validation Set is: 8.69% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 4.06 | sMAPE for Test Set is: 10.41% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:55:05,064]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:55:06,930]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:55:11,818]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:55:16,585]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:55:17,540]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:55:34,188]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:55:43,069]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:55:51,846]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:56:03,252]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:56:13,671]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:56:16,626]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:56:17,340]\u001b[0m Trial 1151 finished with value: 4.224683214037555 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006426543701829968, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.030974915585414597, 'dropout_rate_Layer_2': 0.24449042617950822, 'dropout_rate_Layer_3': 0.37521251052684407, 'dropout_rate_Layer_4': 0.15120362683353072, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0007097520240060797, 'l1_Layer_2': 0.000276077771076178, 'l1_Layer_3': 0.0003893578682243736, 'l1_Layer_4': 1.0698934254387931e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 125, 'n_units_Layer_3': 120, 'n_units_Layer_4': 165}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.22 | sMAPE for Validation Set is: 8.72% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 4.19 | sMAPE for Test Set is: 10.62% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:56:24,629]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:56:25,430]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:56:27,814]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:56:33,537]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:56:36,498]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:56:37,072]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:56:38,580]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:56:42,896]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:56:47,093]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:56:47,486]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:56:57,058]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:56:59,795]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:57:00,328]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:57:03,565]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:57:07,210]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:57:13,427]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:57:17,297]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:57:20,116]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:57:23,797]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:57:46,301]\u001b[0m Trial 1156 finished with value: 3.7455464433247374 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005474026827302225, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11928666623264995, 'dropout_rate_Layer_2': 0.21798930971190547, 'dropout_rate_Layer_3': 0.0007258380904325429, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002112705709720813, 'l1_Layer_2': 3.850161008084246e-05, 'l1_Layer_3': 2.6515062066812365e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 140, 'n_units_Layer_3': 245}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 7.86% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 3.82 | sMAPE for Test Set is: 9.84% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:57:52,958]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:58:02,054]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:58:08,005]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:58:12,915]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:58:18,889]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:58:24,758]\u001b[0m Trial 1179 finished with value: 4.2992818284167935 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005149340332053196, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14425136156932944, 'dropout_rate_Layer_2': 0.30934532682961324, 'dropout_rate_Layer_3': 0.34168736773249964, 'dropout_rate_Layer_4': 0.13491123259853555, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0006107399496074075, 'l1_Layer_2': 0.00023307689012020904, 'l1_Layer_3': 0.001221515194689558, 'l1_Layer_4': 2.2562372953667032e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 100, 'n_units_Layer_3': 105, 'n_units_Layer_4': 200}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.30 | sMAPE for Validation Set is: 8.91% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 3.95 | sMAPE for Test Set is: 10.14% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:58:24,943]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:58:29,540]\u001b[0m Trial 1183 finished with value: 4.369101985797315 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011094399556873097, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16576868106561504, 'dropout_rate_Layer_2': 0.04126390450572199, 'dropout_rate_Layer_3': 0.00792708937556821, 'dropout_rate_Layer_4': 0.056290329741129075, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.302605506838638e-05, 'l1_Layer_2': 0.006637169728527546, 'l1_Layer_3': 0.0011073669189088043, 'l1_Layer_4': 1.2041310387827364e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 200, 'n_units_Layer_3': 215, 'n_units_Layer_4': 60}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.37 | sMAPE for Validation Set is: 9.19% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.32 | sMAPE for Test Set is: 11.03% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:58:32,242]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:58:33,412]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:58:39,539]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:58:40,889]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:58:45,952]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:58:50,303]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:58:58,885]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:59:06,779]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:59:12,276]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:59:20,469]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:59:24,907]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:59:29,851]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:59:34,652]\u001b[0m Trial 1181 finished with value: 3.780891652106129 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005598487830532533, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1184480721485526, 'dropout_rate_Layer_2': 0.1567729860942479, 'dropout_rate_Layer_3': 1.4715285850689389e-05, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003441720463892673, 'l1_Layer_2': 5.3550106995944094e-05, 'l1_Layer_3': 1.699725342629766e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 170, 'n_units_Layer_3': 260}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.78 | sMAPE for Validation Set is: 7.89% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.66 | sMAPE for Test Set is: 9.51% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 20:59:36,701]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:59:39,423]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:59:43,582]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:59:45,890]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:59:53,947]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:59:56,420]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 20:59:59,560]\u001b[0m Trial 1196 finished with value: 4.31029027177857 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007516837250381084, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09814237737234983, 'dropout_rate_Layer_2': 0.3214885141939977, 'dropout_rate_Layer_3': 0.2977681604880825, 'dropout_rate_Layer_4': 0.1603985679842274, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0004072137741405585, 'l1_Layer_2': 0.00018347436827463568, 'l1_Layer_3': 0.000583109023517293, 'l1_Layer_4': 1.5497442869414566e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 90, 'n_units_Layer_3': 110, 'n_units_Layer_4': 210}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.31 | sMAPE for Validation Set is: 9.02% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 4.14 | sMAPE for Test Set is: 10.66% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 21:00:00,573]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:00:03,975]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:00:06,941]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:00:09,538]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:00:13,237]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:00:15,108]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:00:20,319]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:00:33,386]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:00:36,239]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:00:40,735]\u001b[0m Trial 1195 finished with value: 3.776188600184032 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005029446115961776, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13995875792802812, 'dropout_rate_Layer_2': 0.18990828552307118, 'dropout_rate_Layer_3': 0.0004336329354717031, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002027784619825074, 'l1_Layer_2': 3.342482358982251e-05, 'l1_Layer_3': 1.0023259917014929e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 165, 'n_units_Layer_3': 225}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.78 | sMAPE for Validation Set is: 7.93% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 3.82 | sMAPE for Test Set is: 9.84% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 21:00:45,935]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:00:48,952]\u001b[0m Trial 1211 finished with value: 4.191731653404414 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011477440110642884, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15439696742126732, 'dropout_rate_Layer_2': 0.06438849397153136, 'dropout_rate_Layer_3': 0.0068931045856379936, 'dropout_rate_Layer_4': 0.06348079234011848, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 6.80151800919843e-05, 'l1_Layer_2': 0.007445514321704413, 'l1_Layer_3': 1.038710556665983e-05, 'l1_Layer_4': 1.2282554246314304e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 210, 'n_units_Layer_3': 220, 'n_units_Layer_4': 60}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.19 | sMAPE for Validation Set is: 8.77% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 4.28 | sMAPE for Test Set is: 10.80% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 21:00:52,401]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:00:52,446]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:00:53,806]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:01:05,005]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:01:08,143]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:01:14,531]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:01:18,255]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:01:18,697]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:01:24,711]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:01:33,532]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:01:39,577]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:01:46,249]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:01:53,104]\u001b[0m Trial 1232 finished with value: 4.348069422324944 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014106804780158896, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13840662086677372, 'dropout_rate_Layer_2': 0.06626726256359733, 'dropout_rate_Layer_3': 0.022221010330563434, 'dropout_rate_Layer_4': 0.03036653642852475, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 8.437798509201035e-05, 'l1_Layer_2': 0.010314555559725946, 'l1_Layer_3': 2.7742969736546366e-05, 'l1_Layer_4': 2.5656305553806415e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 225, 'n_units_Layer_3': 205, 'n_units_Layer_4': 60}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.35 | sMAPE for Validation Set is: 9.16% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 4.48 | sMAPE for Test Set is: 11.30% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 21:01:57,014]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.15 | sMAPE for Validation Set is: 8.77% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.44 | sMAPE for Test Set is: 11.23% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 21:01:58,643]\u001b[0m Trial 1227 finished with value: 4.149851936765668 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005707714732098638, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13175657859852202, 'dropout_rate_Layer_2': 0.3344941775050497, 'dropout_rate_Layer_3': 0.26141649779047466, 'dropout_rate_Layer_4': 0.08446693945592472, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00028269281993078383, 'l1_Layer_2': 0.0001361308840683921, 'l1_Layer_3': 0.0009495290760259624, 'l1_Layer_4': 3.3436768530345635e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 110, 'n_units_Layer_3': 95, 'n_units_Layer_4': 185}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:02:02,153]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:02:05,971]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:02:09,034]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:02:10,060]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:02:15,235]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:02:16,860]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:02:20,783]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:02:24,891]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:02:27,360]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:02:33,432]\u001b[0m Trial 1228 finished with value: 4.214178144128185 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005739820148828204, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13634207318884964, 'dropout_rate_Layer_2': 0.33088181054478405, 'dropout_rate_Layer_3': 0.31685590221744636, 'dropout_rate_Layer_4': 0.10897916285101317, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0015829838605298492, 'l1_Layer_2': 0.00013510226796127603, 'l1_Layer_3': 0.0002660618671869478, 'l1_Layer_4': 3.103703758192581e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 110, 'n_units_Layer_3': 90, 'n_units_Layer_4': 185}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.21 | sMAPE for Validation Set is: 8.79% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 3.98 | sMAPE for Test Set is: 10.21% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 21:02:34,624]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:02:38,983]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:02:39,970]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:02:43,901]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:02:55,118]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:03:01,166]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:03:28,270]\u001b[0m Trial 1248 finished with value: 4.2096556020005025 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012506145266199256, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1635220691743076, 'dropout_rate_Layer_2': 0.06924508679564376, 'dropout_rate_Layer_3': 0.020259671213724892, 'dropout_rate_Layer_4': 0.062435542827829246, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 7.075988086853808e-05, 'l1_Layer_2': 0.006334187519248584, 'l1_Layer_3': 1.9605403179531237e-05, 'l1_Layer_4': 1.8700260420854613e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 230, 'n_units_Layer_3': 210, 'n_units_Layer_4': 65}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.21 | sMAPE for Validation Set is: 8.79% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 4.13 | sMAPE for Test Set is: 10.52% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 21:03:37,223]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:03:41,368]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:03:49,996]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:03:55,418]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:03:58,373]\u001b[0m Trial 1236 finished with value: 3.74164540962578 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006055533993567322, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11482726803509827, 'dropout_rate_Layer_2': 0.17472906270598484, 'dropout_rate_Layer_3': 0.028670491338518834, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014534330014026851, 'l1_Layer_2': 1.764682214035413e-05, 'l1_Layer_3': 2.0961388894051746e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 140, 'n_units_Layer_3': 215}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.74 | sMAPE for Validation Set is: 7.83% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 3.69 | sMAPE for Test Set is: 9.63% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 21:04:06,494]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:04:12,683]\u001b[0m Trial 1255 finished with value: 4.5877349694880705 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009406655966769981, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0824842804458685, 'dropout_rate_Layer_2': 0.36649336040507363, 'dropout_rate_Layer_3': 0.2618644093828449, 'dropout_rate_Layer_4': 0.0798655809344072, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003077253677261802, 'l1_Layer_2': 0.0011203708457832287, 'l1_Layer_3': 0.002371907285222109, 'l1_Layer_4': 4.715590528845848e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 65, 'n_units_Layer_3': 80, 'n_units_Layer_4': 160}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.59 | sMAPE for Validation Set is: 9.46% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 4.04 | sMAPE for Test Set is: 10.45% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 21:04:16,467]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:04:19,434]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:04:22,380]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:04:28,993]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:04:34,352]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:04:42,514]\u001b[0m Trial 1261 finished with value: 6.359858141717969 and parameters: {'n_hidden': 4, 'learning_rate': 0.06161414859541697, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11825577533441328, 'dropout_rate_Layer_2': 0.34906712292075337, 'dropout_rate_Layer_3': 0.23401416117785945, 'dropout_rate_Layer_4': 0.08396482684683396, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00028222328480002136, 'l1_Layer_2': 0.00010205746738101517, 'l1_Layer_3': 0.0004342113036275028, 'l1_Layer_4': 4.8478019513571625e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 120, 'n_units_Layer_3': 85, 'n_units_Layer_4': 160}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.36 | sMAPE for Validation Set is: 12.53% | rMAE for Validation Set is: 0.98\n",
      "MAE for Test Set is: 7.74 | sMAPE for Test Set is: 17.62% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 21:04:46,996]\u001b[0m Trial 1253 finished with value: 3.693536131621739 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005456846837611848, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15685469284481113, 'dropout_rate_Layer_2': 0.15458285628609175, 'dropout_rate_Layer_3': 0.021859064514216063, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002551071904355781, 'l1_Layer_2': 4.80699754798182e-05, 'l1_Layer_3': 2.5205724594766865e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 175, 'n_units_Layer_3': 255}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.69 | sMAPE for Validation Set is: 7.80% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 3.97 | sMAPE for Test Set is: 10.14% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 21:04:49,940]\u001b[0m Trial 1266 finished with value: 4.337817605958084 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015491046235494236, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1708138614768087, 'dropout_rate_Layer_2': 0.07495233744218946, 'dropout_rate_Layer_3': 0.016034641111942846, 'dropout_rate_Layer_4': 0.09155765632479544, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.090662372566501e-05, 'l1_Layer_2': 0.004245588292048495, 'l1_Layer_3': 1.1770334767875023e-05, 'l1_Layer_4': 1.339539337693464e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 230, 'n_units_Layer_3': 215, 'n_units_Layer_4': 60}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.34 | sMAPE for Validation Set is: 9.05% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 4.35 | sMAPE for Test Set is: 10.96% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 21:04:50,796]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:04:54,010]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:04:56,815]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:04:57,511]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:05:02,511]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:05:08,348]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:05:14,153]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:05:14,947]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:05:24,040]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:05:26,898]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:05:27,258]\u001b[0m Trial 1274 finished with value: 4.425578609691654 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012675391265380947, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16643654118779727, 'dropout_rate_Layer_2': 0.07406574203698446, 'dropout_rate_Layer_3': 0.018233507065709018, 'dropout_rate_Layer_4': 0.09581955193542979, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.375032755745572e-05, 'l1_Layer_2': 0.00445509609839337, 'l1_Layer_3': 1.7384054187750473e-05, 'l1_Layer_4': 1.3543355654062613e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 230, 'n_units_Layer_3': 215, 'n_units_Layer_4': 60}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.43 | sMAPE for Validation Set is: 9.28% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.19 | sMAPE for Test Set is: 10.75% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 21:05:32,554]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:05:33,309]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:05:35,937]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:05:41,093]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:05:53,676]\u001b[0m Trial 1276 finished with value: 4.362194139176021 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007039872616544032, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13007509773021264, 'dropout_rate_Layer_2': 0.33794801328098734, 'dropout_rate_Layer_3': 0.2727232038573926, 'dropout_rate_Layer_4': 0.06166657333002096, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00022120157350324112, 'l1_Layer_2': 0.00013835620854820173, 'l1_Layer_3': 0.0009753269283753643, 'l1_Layer_4': 1.0213096434255979e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 100, 'n_units_Layer_3': 100, 'n_units_Layer_4': 195}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.36 | sMAPE for Validation Set is: 9.21% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.36 | sMAPE for Test Set is: 11.19% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 21:06:00,040]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:06:02,859]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:06:03,569]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:06:13,846]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:06:15,970]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:06:20,891]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:06:24,780]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:06:32,469]\u001b[0m Trial 1284 finished with value: 4.308886449412483 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006728042948732381, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12769849936250466, 'dropout_rate_Layer_2': 0.33475809511292265, 'dropout_rate_Layer_3': 0.2814078347274244, 'dropout_rate_Layer_4': 0.06239017362644713, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0009070021585227676, 'l1_Layer_2': 0.0001406725406421866, 'l1_Layer_3': 0.0009126857818633497, 'l1_Layer_4': 1.9706883324260844e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 100, 'n_units_Layer_3': 100, 'n_units_Layer_4': 190}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.31 | sMAPE for Validation Set is: 9.18% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 4.16 | sMAPE for Test Set is: 10.74% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 21:06:34,801]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:06:42,221]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:06:45,028]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:06:46,998]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:06:49,628]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:06:52,729]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:06:55,184]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:07:02,827]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:07:11,096]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:07:15,871]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:07:20,136]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:07:25,880]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:07:31,423]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:07:34,814]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:07:40,743]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:07:41,054]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:07:51,092]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:07:54,225]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:08:02,659]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:08:06,152]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:08:09,047]\u001b[0m Trial 1289 finished with value: 3.7191684879781595 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006544636944396217, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.130351446146341, 'dropout_rate_Layer_2': 0.18477895074479883, 'dropout_rate_Layer_3': 0.012546017953485195, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015938203651987594, 'l1_Layer_2': 4.766064427082496e-05, 'l1_Layer_3': 1.0051513710704076e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 135, 'n_units_Layer_3': 250}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.72 | sMAPE for Validation Set is: 7.83% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 3.89 | sMAPE for Test Set is: 10.03% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 21:08:13,662]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:08:22,296]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:08:24,512]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:08:31,892]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:08:34,305]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:08:40,785]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:08:46,516]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:08:50,372]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:08:50,699]\u001b[0m Trial 1321 finished with value: 4.260495506398505 and parameters: {'n_hidden': 3, 'learning_rate': 0.00787315324316467, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09831793222221161, 'dropout_rate_Layer_2': 0.1055933448632567, 'dropout_rate_Layer_3': 0.05199288529096893, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006778912809731607, 'l1_Layer_2': 0.013636132131869858, 'l1_Layer_3': 9.815813206414919e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 240, 'n_units_Layer_3': 295}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.26 | sMAPE for Validation Set is: 8.97% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.47 | sMAPE for Test Set is: 11.35% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 21:09:16,007]\u001b[0m Trial 1324 finished with value: 4.359647755982491 and parameters: {'n_hidden': 4, 'learning_rate': 0.00149705517360991, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10830963897210442, 'dropout_rate_Layer_2': 0.08347434231647471, 'dropout_rate_Layer_3': 0.024623197324954202, 'dropout_rate_Layer_4': 0.049082990662467046, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 6.73057427048438e-05, 'l1_Layer_2': 0.009089457863829791, 'l1_Layer_3': 1.4762936323246442e-05, 'l1_Layer_4': 2.2651653653672934e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 200, 'n_units_Layer_3': 205, 'n_units_Layer_4': 50}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.36 | sMAPE for Validation Set is: 9.15% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 4.49 | sMAPE for Test Set is: 11.30% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 21:09:16,472]\u001b[0m Trial 1325 finished with value: 4.378409703703567 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011758435574303469, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16091784416477167, 'dropout_rate_Layer_2': 0.07970621347038727, 'dropout_rate_Layer_3': 0.025034914794238573, 'dropout_rate_Layer_4': 0.039093897837751995, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 6.819061377246683e-05, 'l1_Layer_2': 0.010600624138297668, 'l1_Layer_3': 1.3920762873196807e-05, 'l1_Layer_4': 2.2280683198419225e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 200, 'n_units_Layer_3': 205, 'n_units_Layer_4': 50}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.38 | sMAPE for Validation Set is: 9.18% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.54 | sMAPE for Test Set is: 11.40% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 21:09:16,738]\u001b[0m Trial 1305 finished with value: 3.787397156389954 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005016197740620812, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12882808743673269, 'dropout_rate_Layer_2': 0.14541966668898357, 'dropout_rate_Layer_3': 0.000508562938920985, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002435685499621251, 'l1_Layer_2': 4.4088572494994725e-05, 'l1_Layer_3': 2.908310134333252e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 150, 'n_units_Layer_3': 260}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.79 | sMAPE for Validation Set is: 7.95% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.85 | sMAPE for Test Set is: 9.89% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 21:09:24,501]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:09:27,166]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:09:32,213]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:09:36,917]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:09:41,282]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:09:42,449]\u001b[0m Trial 1330 finished with value: 4.3412615067643605 and parameters: {'n_hidden': 3, 'learning_rate': 0.01127937000693404, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.043667321700909534, 'dropout_rate_Layer_2': 0.08710336112501585, 'dropout_rate_Layer_3': 0.07510932922665431, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.775448493092465e-05, 'l1_Layer_2': 0.007650907557878505, 'l1_Layer_3': 9.598340340357357e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 85, 'n_units_Layer_3': 290}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.34 | sMAPE for Validation Set is: 9.04% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 4.37 | sMAPE for Test Set is: 10.97% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 21:09:43,009]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:09:48,595]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:09:58,645]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:10:03,736]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:10:10,173]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.66 | sMAPE for Validation Set is: 7.71% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 3.68 | sMAPE for Test Set is: 9.63% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 21:10:12,125]\u001b[0m Trial 1314 finished with value: 3.6566013389481746 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005010335039970059, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16406069354638955, 'dropout_rate_Layer_2': 0.16303952788166787, 'dropout_rate_Layer_3': 0.025504306618398077, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0019666955583199494, 'l1_Layer_2': 3.190367221136563e-05, 'l1_Layer_3': 1.7335775812111164e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 150, 'n_units_Layer_3': 255}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:10:14,936]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:10:15,667]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:10:22,305]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:10:26,990]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:10:29,827]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:10:38,087]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:10:38,326]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:10:44,866]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.42 | sMAPE for Validation Set is: 9.28% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.57 | sMAPE for Test Set is: 11.46% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 21:10:46,599]\u001b[0m Trial 1340 finished with value: 4.417334857799489 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012745627159005924, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1575104302058182, 'dropout_rate_Layer_2': 0.08445678882835994, 'dropout_rate_Layer_3': 0.023231270959514855, 'dropout_rate_Layer_4': 0.0403963407561242, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.5512386295435026e-05, 'l1_Layer_2': 0.007741884333752962, 'l1_Layer_3': 2.203992161774525e-05, 'l1_Layer_4': 1.5866049782502597e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 190, 'n_units_Layer_3': 205, 'n_units_Layer_4': 55}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:10:53,816]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:11:02,962]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:11:09,561]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:11:19,567]\u001b[0m Trial 1352 finished with value: 4.349556848727571 and parameters: {'n_hidden': 3, 'learning_rate': 0.009045004782655472, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0317936131296456, 'dropout_rate_Layer_2': 0.0963662149860793, 'dropout_rate_Layer_3': 0.09245482061065469, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.014593663038289146, 'l1_Layer_2': 0.007460459489356098, 'l1_Layer_3': 6.99015091935527e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 90, 'n_units_Layer_3': 300}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.35 | sMAPE for Validation Set is: 9.15% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 4.32 | sMAPE for Test Set is: 11.06% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 21:11:24,174]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:11:29,838]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:11:30,378]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:11:36,699]\u001b[0m Trial 1348 finished with value: 4.406943579350549 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015702250430267505, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.159039446993168, 'dropout_rate_Layer_2': 0.08432759987714729, 'dropout_rate_Layer_3': 0.023113690781653158, 'dropout_rate_Layer_4': 0.04797422216902996, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.6680252950110504e-05, 'l1_Layer_2': 0.007827030511401182, 'l1_Layer_3': 1.4600188850774946e-05, 'l1_Layer_4': 1.5032439850938576e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 200, 'n_units_Layer_3': 205, 'n_units_Layer_4': 55}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.41 | sMAPE for Validation Set is: 9.25% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.50 | sMAPE for Test Set is: 11.33% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 21:11:41,901]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:11:46,435]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:11:46,617]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:11:52,792]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:11:58,823]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:11:58,976]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:12:03,408]\u001b[0m Trial 1355 finished with value: 4.290740190717763 and parameters: {'n_hidden': 4, 'learning_rate': 0.001596188066067544, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1254386121217116, 'dropout_rate_Layer_2': 0.0674605901333218, 'dropout_rate_Layer_3': 0.0337392108680557, 'dropout_rate_Layer_4': 0.06886315210110318, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 7.106412034539748e-05, 'l1_Layer_2': 0.0043635658959436325, 'l1_Layer_3': 1.5683864219133223e-05, 'l1_Layer_4': 1.938648072991238e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 205, 'n_units_Layer_3': 225, 'n_units_Layer_4': 50}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.29 | sMAPE for Validation Set is: 8.98% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.36 | sMAPE for Test Set is: 11.00% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 21:12:06,743]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:12:09,895]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:12:13,702]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:12:17,556]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:12:17,895]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:12:22,302]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:12:26,908]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:12:27,099]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:12:35,572]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:12:39,972]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:12:43,210]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:13:04,123]\u001b[0m Trial 1336 finished with value: 3.781807081328369 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008010928159237099, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01313707449857945, 'dropout_rate_Layer_2': 0.27499944428432577, 'dropout_rate_Layer_3': 0.01863403748518558, 'dropout_rate_Layer_4': 0.38804839955229686, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.012304601238451627, 'l1_Layer_2': 0.00033098110962602613, 'l1_Layer_3': 0.001830164752946391, 'l1_Layer_4': 1.5181791282433087e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 85, 'n_units_Layer_3': 120, 'n_units_Layer_4': 220}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.78 | sMAPE for Validation Set is: 7.97% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.88 | sMAPE for Test Set is: 9.95% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 21:13:08,603]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:13:12,406]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:13:16,466]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:13:21,911]\u001b[0m Trial 1375 finished with value: 4.3205599014275125 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013775878788040916, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09089641536100515, 'dropout_rate_Layer_2': 0.057029237980165196, 'dropout_rate_Layer_3': 0.032564748675306975, 'dropout_rate_Layer_4': 0.08009972207586526, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 9.120265476311714e-05, 'l1_Layer_2': 0.002976103878064102, 'l1_Layer_3': 1.9871059498692116e-05, 'l1_Layer_4': 3.211700510252481e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 195, 'n_units_Layer_3': 225, 'n_units_Layer_4': 60}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.32 | sMAPE for Validation Set is: 8.96% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 4.07 | sMAPE for Test Set is: 10.41% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 21:13:22,301]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:13:27,502]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:13:33,225]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:13:37,530]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:13:38,181]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:13:43,852]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:13:48,670]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:13:49,198]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:13:56,412]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:13:58,658]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:13:59,652]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:14:05,492]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:14:05,618]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:14:06,490]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:14:18,408]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:14:21,122]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:14:21,573]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:14:26,709]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:14:29,454]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:14:30,732]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:14:30,834]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:14:35,046]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:14:38,512]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:14:41,021]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:14:41,275]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:14:42,804]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:14:50,303]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:14:50,347]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:14:57,841]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:15:00,140]\u001b[0m Trial 1398 finished with value: 4.369129342824166 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012034895894995825, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1074222455840443, 'dropout_rate_Layer_2': 0.07273627124489733, 'dropout_rate_Layer_3': 0.017457621000541167, 'dropout_rate_Layer_4': 0.06955997223806729, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.6117250513046354e-05, 'l1_Layer_2': 0.004997700546533588, 'l1_Layer_3': 2.705518844245885e-05, 'l1_Layer_4': 1.803729496958152e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 210, 'n_units_Layer_3': 235, 'n_units_Layer_4': 65}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.37 | sMAPE for Validation Set is: 9.17% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.52 | sMAPE for Test Set is: 11.38% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 21:15:02,905]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:15:03,049]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:15:09,726]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:15:10,982]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:15:19,759]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:15:25,300]\u001b[0m Trial 1407 finished with value: 4.344171310174844 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012397049324888339, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09862246934778758, 'dropout_rate_Layer_2': 0.0755224650529004, 'dropout_rate_Layer_3': 0.016657805029422414, 'dropout_rate_Layer_4': 0.0709411207221612, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 6.0316517334003276e-05, 'l1_Layer_2': 0.00625003755463556, 'l1_Layer_3': 2.7552747362830046e-05, 'l1_Layer_4': 2.5443315643956925e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 210, 'n_units_Layer_3': 235, 'n_units_Layer_4': 65}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.34 | sMAPE for Validation Set is: 9.10% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 4.31 | sMAPE for Test Set is: 10.94% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 21:15:25,623]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:15:31,133]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:15:33,193]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:15:37,705]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:15:44,045]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:15:47,164]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:15:51,890]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:15:54,646]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:15:57,959]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:16:01,476]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:16:03,886]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:16:08,110]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:16:08,360]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:16:13,563]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:16:15,589]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:16:21,783]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:16:25,726]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:16:26,369]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:16:33,736]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:16:46,464]\u001b[0m Trial 1430 finished with value: 4.391604379835077 and parameters: {'n_hidden': 4, 'learning_rate': 0.0021510410873611346, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1093552812411112, 'dropout_rate_Layer_2': 0.06301014655445024, 'dropout_rate_Layer_3': 0.03813133222382494, 'dropout_rate_Layer_4': 0.07664531815993837, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 8.157456415084026e-05, 'l1_Layer_2': 0.006001442218562388, 'l1_Layer_3': 2.8379879953889655e-05, 'l1_Layer_4': 2.5339144535903315e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 205, 'n_units_Layer_3': 230, 'n_units_Layer_4': 50}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.39 | sMAPE for Validation Set is: 9.23% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.45 | sMAPE for Test Set is: 11.24% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 21:16:50,329]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:16:53,295]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:16:56,010]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:16:59,492]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:17:05,030]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:17:05,629]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:17:06,018]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:17:17,097]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:17:17,488]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:17:26,132]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:17:30,979]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:17:37,433]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:17:41,884]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:17:44,909]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:18:03,291]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:18:15,321]\u001b[0m Trial 1444 finished with value: 4.04319027361035 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006119221096209786, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.030466514183201066, 'dropout_rate_Layer_2': 0.22338399830368266, 'dropout_rate_Layer_3': 0.2644194968476849, 'dropout_rate_Layer_4': 0.09697676400645623, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.013674882831177617, 'l1_Layer_2': 0.00025869663137971966, 'l1_Layer_3': 0.0003606412244619999, 'l1_Layer_4': 1.0174606367790705e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 95, 'n_units_Layer_3': 110, 'n_units_Layer_4': 185}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.04 | sMAPE for Validation Set is: 8.46% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 3.87 | sMAPE for Test Set is: 10.01% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 21:18:23,966]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:18:24,668]\u001b[0m Trial 1415 finished with value: 3.89551741338753 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007534856166421897, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0363026084002826, 'dropout_rate_Layer_2': 0.22410981374761263, 'dropout_rate_Layer_3': 0.05635602263110589, 'dropout_rate_Layer_4': 0.10071405449220577, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.018569678254156983, 'l1_Layer_2': 0.00047504153695042547, 'l1_Layer_3': 0.0010767056655916747, 'l1_Layer_4': 1.7220398234036294e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 70, 'n_units_Layer_3': 135, 'n_units_Layer_4': 180}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.90 | sMAPE for Validation Set is: 8.15% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 3.77 | sMAPE for Test Set is: 9.74% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 21:18:29,579]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:18:32,000]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:18:32,853]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:18:37,994]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:18:42,961]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:18:46,527]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:18:49,872]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:18:53,862]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:18:55,659]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:19:02,985]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:19:04,076]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:19:20,266]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:19:28,082]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:19:29,095]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:19:35,321]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:19:37,170]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:19:40,841]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:19:43,373]\u001b[0m Trial 1459 finished with value: 3.995090443445872 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010503063393359053, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10710608104290598, 'dropout_rate_Layer_2': 0.0711427405680681, 'dropout_rate_Layer_3': 0.006596442464842523, 'dropout_rate_Layer_4': 0.059125776440429226, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 9.285074031067426e-05, 'l1_Layer_2': 0.0028624145056645118, 'l1_Layer_3': 1.8254877116532012e-05, 'l1_Layer_4': 1.9093528550357675e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 215, 'n_units_Layer_3': 235, 'n_units_Layer_4': 65}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.00 | sMAPE for Validation Set is: 8.33% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.06 | sMAPE for Test Set is: 10.32% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 21:19:54,142]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:20:00,295]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:20:02,164]\u001b[0m Trial 1471 finished with value: 3.8593932380978178 and parameters: {'n_hidden': 3, 'learning_rate': 0.006174770541267825, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22772215320418507, 'dropout_rate_Layer_2': 0.14849043003937124, 'dropout_rate_Layer_3': 0.05822025050439732, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1716634867795932e-05, 'l1_Layer_2': 0.019553590985982, 'l1_Layer_3': 2.498855159022554e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 80, 'n_units_Layer_3': 255}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.86 | sMAPE for Validation Set is: 8.20% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.08 | sMAPE for Test Set is: 10.57% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 21:20:08,496]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:20:12,158]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:20:12,520]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:20:18,486]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:20:27,622]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:20:31,452]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:20:36,136]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:20:36,533]\u001b[0m Trial 1478 finished with value: 3.9199442712155137 and parameters: {'n_hidden': 3, 'learning_rate': 0.0063511721029472345, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2312446046668355, 'dropout_rate_Layer_2': 0.1494510135611923, 'dropout_rate_Layer_3': 0.056458146067089036, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002386878231535172, 'l1_Layer_2': 0.018776483533971114, 'l1_Layer_3': 2.5973881723495818e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 70, 'n_units_Layer_3': 250}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.92 | sMAPE for Validation Set is: 8.29% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.34 | sMAPE for Test Set is: 10.94% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 21:20:43,167]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:20:43,661]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:20:44,395]\u001b[0m Trial 1451 finished with value: 3.738055828713172 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006172093108195881, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1284858788147923, 'dropout_rate_Layer_2': 0.18958567294628545, 'dropout_rate_Layer_3': 0.00032021625346852385, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0020318857587177854, 'l1_Layer_2': 7.583649291412341e-05, 'l1_Layer_3': 3.449616405980846e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 150, 'n_units_Layer_3': 255}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.74 | sMAPE for Validation Set is: 7.79% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 3.79 | sMAPE for Test Set is: 9.74% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 21:20:52,014]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:20:55,210]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:20:57,883]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:21:04,163]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:21:16,409]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:21:30,287]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:21:34,952]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:21:39,187]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:21:44,999]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:21:49,173]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:21:49,573]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:21:54,997]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:21:59,031]\u001b[0m Trial 1488 finished with value: 3.876760782938541 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011843874937894384, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0757302164454725, 'dropout_rate_Layer_2': 0.0595964065924248, 'dropout_rate_Layer_3': 0.01590294146188552, 'dropout_rate_Layer_4': 0.06258561053870114, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00016936747654139193, 'l1_Layer_2': 0.002927981189799819, 'l1_Layer_3': 1.1988349664616802e-05, 'l1_Layer_4': 0.00022098505669397012, 'n_units_Layer_1': 145, 'n_units_Layer_2': 220, 'n_units_Layer_3': 145, 'n_units_Layer_4': 60}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.88 | sMAPE for Validation Set is: 8.12% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 3.87 | sMAPE for Test Set is: 9.90% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 21:22:02,289]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:22:04,173]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:22:08,981]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 21:22:10,849]\u001b[0m Trial 1491 finished with value: 4.1471065056461365 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006229446364899543, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04141917381996627, 'dropout_rate_Layer_2': 0.2216795322888043, 'dropout_rate_Layer_3': 0.2536970325309103, 'dropout_rate_Layer_4': 0.08479419033050908, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.007594441381970805, 'l1_Layer_2': 0.0006906715361702743, 'l1_Layer_3': 0.0003514968905289234, 'l1_Layer_4': 7.610335925041609e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 50, 'n_units_Layer_3': 130, 'n_units_Layer_4': 215}. Best is trial 700 with value: 3.6417186725117427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.15 | sMAPE for Validation Set is: 8.90% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.29 | sMAPE for Test Set is: 10.91% | rMAE for Test Set is: 0.64\n",
      "for 2019-01-01, MAE is:3.59 & sMAPE is:5.94% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :3.59 & 5.94% & 1.72\n",
      "for 2019-01-02, MAE is:4.43 & sMAPE is:6.86% & rMAE is:2.05 ||| daily mean of MAE & sMAPE & rMAE till now are :4.01 & 6.40% & 1.89\n",
      "for 2019-01-03, MAE is:3.61 & sMAPE is:5.58% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :3.88 & 6.13% & 1.58\n",
      "for 2019-01-04, MAE is:2.68 & sMAPE is:3.99% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :3.58 & 5.59% & 1.38\n",
      "for 2019-01-05, MAE is:4.02 & sMAPE is:6.29% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :3.67 & 5.73% & 1.20\n",
      "for 2019-01-06, MAE is:3.47 & sMAPE is:6.01% & rMAE is:1.82 ||| daily mean of MAE & sMAPE & rMAE till now are :3.63 & 5.78% & 1.30\n",
      "for 2019-01-07, MAE is:4.00 & sMAPE is:6.23% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :3.69 & 5.84% & 1.33\n",
      "for 2019-01-08, MAE is:3.41 & sMAPE is:5.49% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :3.65 & 5.80% & 1.25\n",
      "for 2019-01-09, MAE is:2.31 & sMAPE is:3.75% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :3.50 & 5.57% & 1.21\n",
      "for 2019-01-10, MAE is:2.69 & sMAPE is:4.48% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :3.42 & 5.46% & 1.23\n",
      "for 2019-01-11, MAE is:2.20 & sMAPE is:3.52% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :3.31 & 5.29% & 1.18\n",
      "for 2019-01-12, MAE is:3.98 & sMAPE is:6.41% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :3.37 & 5.38% & 1.15\n",
      "for 2019-01-13, MAE is:4.34 & sMAPE is:7.21% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :3.44 & 5.52% & 1.21\n",
      "for 2019-01-14, MAE is:4.25 & sMAPE is:6.54% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :3.50 & 5.59% & 1.19\n",
      "for 2019-01-15, MAE is:3.94 & sMAPE is:6.04% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :3.53 & 5.62% & 1.17\n",
      "for 2019-01-16, MAE is:3.16 & sMAPE is:4.89% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :3.51 & 5.58% & 1.12\n",
      "for 2019-01-17, MAE is:3.94 & sMAPE is:5.86% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :3.53 & 5.59% & 1.13\n",
      "for 2019-01-18, MAE is:2.43 & sMAPE is:3.81% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :3.47 & 5.49% & 1.10\n",
      "for 2019-01-19, MAE is:2.26 & sMAPE is:3.48% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :3.41 & 5.39% & 1.08\n",
      "for 2019-01-20, MAE is:5.90 & sMAPE is:10.05% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :3.53 & 5.62% & 1.09\n",
      "for 2019-01-21, MAE is:3.26 & sMAPE is:5.29% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :3.52 & 5.61% & 1.07\n",
      "for 2019-01-22, MAE is:4.98 & sMAPE is:7.52% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :3.58 & 5.69% & 1.09\n",
      "for 2019-01-23, MAE is:3.74 & sMAPE is:6.92% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :3.59 & 5.75% & 1.06\n",
      "for 2019-01-24, MAE is:2.88 & sMAPE is:5.36% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :3.56 & 5.73% & 1.04\n",
      "for 2019-01-25, MAE is:2.89 & sMAPE is:4.72% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :3.53 & 5.69% & 1.02\n",
      "for 2019-01-26, MAE is:3.15 & sMAPE is:5.04% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :3.52 & 5.66% & 1.02\n",
      "for 2019-01-27, MAE is:8.00 & sMAPE is:15.35% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :3.69 & 6.02% & 1.01\n",
      "for 2019-01-28, MAE is:5.73 & sMAPE is:9.72% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :3.76 & 6.16% & 1.00\n",
      "for 2019-01-29, MAE is:5.66 & sMAPE is:8.76% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :3.82 & 6.24% & 1.01\n",
      "for 2019-01-30, MAE is:5.38 & sMAPE is:9.00% & rMAE is:2.14 ||| daily mean of MAE & sMAPE & rMAE till now are :3.88 & 6.34% & 1.04\n",
      "for 2019-01-31, MAE is:3.88 & sMAPE is:7.38% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :3.88 & 6.37% & 1.03\n",
      "for 2019-02-01, MAE is:3.67 & sMAPE is:7.15% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :3.87 & 6.39% & 1.01\n",
      "for 2019-02-02, MAE is:11.76 & sMAPE is:27.97% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :4.11 & 7.05% & 0.99\n",
      "for 2019-02-03, MAE is:8.40 & sMAPE is:19.05% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :4.23 & 7.40% & 1.01\n",
      "for 2019-02-04, MAE is:4.35 & sMAPE is:7.79% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :4.24 & 7.41% & 1.01\n",
      "for 2019-02-05, MAE is:2.19 & sMAPE is:3.68% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :4.18 & 7.31% & 1.00\n",
      "for 2019-02-06, MAE is:3.20 & sMAPE is:5.31% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :4.15 & 7.25% & 0.99\n",
      "for 2019-02-07, MAE is:2.22 & sMAPE is:3.92% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.10 & 7.17% & 0.98\n",
      "for 2019-02-08, MAE is:6.07 & sMAPE is:9.84% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :4.15 & 7.24% & 0.98\n",
      "for 2019-02-09, MAE is:4.47 & sMAPE is:8.16% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :4.16 & 7.26% & 0.96\n",
      "for 2019-02-10, MAE is:11.75 & sMAPE is:30.98% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :4.35 & 7.84% & 0.96\n",
      "for 2019-02-11, MAE is:3.71 & sMAPE is:6.86% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 7.81% & 0.96\n",
      "for 2019-02-12, MAE is:3.79 & sMAPE is:6.85% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :4.32 & 7.79% & 0.98\n",
      "for 2019-02-13, MAE is:5.95 & sMAPE is:9.69% & rMAE is:2.88 ||| daily mean of MAE & sMAPE & rMAE till now are :4.36 & 7.83% & 1.02\n",
      "for 2019-02-14, MAE is:6.34 & sMAPE is:10.63% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :4.40 & 7.90% & 1.03\n",
      "for 2019-02-15, MAE is:5.23 & sMAPE is:9.19% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 7.92% & 1.03\n",
      "for 2019-02-16, MAE is:5.37 & sMAPE is:9.79% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :4.44 & 7.96% & 1.04\n",
      "for 2019-02-17, MAE is:4.05 & sMAPE is:8.23% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :4.43 & 7.97% & 1.02\n",
      "for 2019-02-18, MAE is:3.40 & sMAPE is:6.11% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :4.41 & 7.93% & 1.02\n",
      "for 2019-02-19, MAE is:3.73 & sMAPE is:6.77% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :4.40 & 7.91% & 1.04\n",
      "for 2019-02-20, MAE is:4.85 & sMAPE is:8.27% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :4.40 & 7.92% & 1.04\n",
      "for 2019-02-21, MAE is:5.50 & sMAPE is:9.47% & rMAE is:2.85 ||| daily mean of MAE & sMAPE & rMAE till now are :4.43 & 7.95% & 1.07\n",
      "for 2019-02-22, MAE is:5.80 & sMAPE is:10.19% & rMAE is:2.04 ||| daily mean of MAE & sMAPE & rMAE till now are :4.45 & 7.99% & 1.09\n",
      "for 2019-02-23, MAE is:2.74 & sMAPE is:5.28% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 7.94% & 1.08\n",
      "for 2019-02-24, MAE is:1.60 & sMAPE is:3.05% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :4.37 & 7.85% & 1.07\n",
      "for 2019-02-25, MAE is:4.00 & sMAPE is:6.99% & rMAE is:2.75 ||| daily mean of MAE & sMAPE & rMAE till now are :4.36 & 7.83% & 1.10\n",
      "for 2019-02-26, MAE is:6.72 & sMAPE is:11.85% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :4.40 & 7.90% & 1.10\n",
      "for 2019-02-27, MAE is:2.29 & sMAPE is:4.74% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.37 & 7.85% & 1.09\n",
      "for 2019-02-28, MAE is:5.89 & sMAPE is:10.40% & rMAE is:1.81 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 7.89% & 1.10\n",
      "for 2019-03-01, MAE is:4.44 & sMAPE is:8.41% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 7.90% & 1.11\n",
      "for 2019-03-02, MAE is:3.43 & sMAPE is:7.02% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.38 & 7.89% & 1.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-03-03, MAE is:11.65 & sMAPE is:27.15% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :4.50 & 8.20% & 1.09\n",
      "for 2019-03-04, MAE is:6.50 & sMAPE is:17.52% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.53 & 8.35% & 1.09\n",
      "for 2019-03-05, MAE is:6.71 & sMAPE is:13.60% & rMAE is:2.30 ||| daily mean of MAE & sMAPE & rMAE till now are :4.56 & 8.43% & 1.10\n",
      "for 2019-03-06, MAE is:10.52 & sMAPE is:25.05% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :4.65 & 8.68% & 1.10\n",
      "for 2019-03-07, MAE is:10.02 & sMAPE is:22.55% & rMAE is:3.72 ||| daily mean of MAE & sMAPE & rMAE till now are :4.73 & 8.89% & 1.14\n",
      "for 2019-03-08, MAE is:2.99 & sMAPE is:5.68% & rMAE is:1.75 ||| daily mean of MAE & sMAPE & rMAE till now are :4.71 & 8.85% & 1.15\n",
      "for 2019-03-09, MAE is:3.04 & sMAPE is:5.85% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 8.80% & 1.14\n",
      "for 2019-03-10, MAE is:3.54 & sMAPE is:7.33% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.67 & 8.78% & 1.13\n",
      "for 2019-03-11, MAE is:2.48 & sMAPE is:4.80% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :4.64 & 8.72% & 1.12\n",
      "for 2019-03-12, MAE is:8.74 & sMAPE is:15.94% & rMAE is:4.12 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 8.83% & 1.16\n",
      "for 2019-03-13, MAE is:5.81 & sMAPE is:12.12% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :4.71 & 8.87% & 1.15\n",
      "for 2019-03-14, MAE is:3.12 & sMAPE is:6.64% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 8.84% & 1.15\n",
      "for 2019-03-15, MAE is:2.65 & sMAPE is:5.09% & rMAE is:3.63 ||| daily mean of MAE & sMAPE & rMAE till now are :4.66 & 8.79% & 1.18\n",
      "for 2019-03-16, MAE is:4.56 & sMAPE is:9.04% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.66 & 8.79% & 1.19\n",
      "for 2019-03-17, MAE is:7.13 & sMAPE is:17.59% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 8.91% & 1.18\n",
      "for 2019-03-18, MAE is:3.12 & sMAPE is:7.46% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :4.67 & 8.89% & 1.18\n",
      "for 2019-03-19, MAE is:3.32 & sMAPE is:6.38% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :4.65 & 8.86% & 1.17\n",
      "for 2019-03-20, MAE is:3.53 & sMAPE is:7.06% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :4.64 & 8.84% & 1.17\n",
      "for 2019-03-21, MAE is:3.02 & sMAPE is:6.10% & rMAE is:2.01 ||| daily mean of MAE & sMAPE & rMAE till now are :4.62 & 8.80% & 1.18\n",
      "for 2019-03-22, MAE is:3.39 & sMAPE is:6.17% & rMAE is:2.70 ||| daily mean of MAE & sMAPE & rMAE till now are :4.60 & 8.77% & 1.20\n",
      "for 2019-03-23, MAE is:2.79 & sMAPE is:5.34% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :4.58 & 8.73% & 1.20\n",
      "for 2019-03-24, MAE is:2.97 & sMAPE is:6.53% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :4.56 & 8.70% & 1.19\n",
      "for 2019-03-25, MAE is:6.04 & sMAPE is:12.58% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :4.58 & 8.75% & 1.19\n",
      "for 2019-03-26, MAE is:3.64 & sMAPE is:8.91% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 8.75% & 1.18\n",
      "for 2019-03-27, MAE is:5.72 & sMAPE is:13.58% & rMAE is:3.09 ||| daily mean of MAE & sMAPE & rMAE till now are :4.58 & 8.80% & 1.21\n",
      "for 2019-03-28, MAE is:2.20 & sMAPE is:4.54% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :4.56 & 8.76% & 1.21\n",
      "for 2019-03-29, MAE is:2.44 & sMAPE is:4.88% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :4.53 & 8.71% & 1.20\n",
      "for 2019-03-30, MAE is:2.17 & sMAPE is:4.22% & rMAE is:1.67 ||| daily mean of MAE & sMAPE & rMAE till now are :4.50 & 8.66% & 1.21\n",
      "for 2019-03-31, MAE is:4.01 & sMAPE is:8.17% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :4.50 & 8.66% & 1.20\n",
      "for 2019-04-01, MAE is:2.83 & sMAPE is:5.26% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :4.48 & 8.62% & 1.19\n",
      "for 2019-04-02, MAE is:5.10 & sMAPE is:8.59% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :4.49 & 8.62% & 1.18\n",
      "for 2019-04-03, MAE is:4.46 & sMAPE is:8.68% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :4.49 & 8.62% & 1.17\n",
      "for 2019-04-04, MAE is:4.08 & sMAPE is:7.62% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :4.48 & 8.61% & 1.18\n",
      "for 2019-04-05, MAE is:4.52 & sMAPE is:8.76% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :4.48 & 8.61% & 1.18\n",
      "for 2019-04-06, MAE is:4.24 & sMAPE is:9.44% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :4.48 & 8.62% & 1.17\n",
      "for 2019-04-07, MAE is:2.43 & sMAPE is:5.18% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.46 & 8.58% & 1.16\n",
      "for 2019-04-08, MAE is:3.77 & sMAPE is:7.16% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :4.45 & 8.57% & 1.16\n",
      "for 2019-04-09, MAE is:6.29 & sMAPE is:11.84% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :4.47 & 8.60% & 1.15\n",
      "for 2019-04-10, MAE is:2.79 & sMAPE is:5.59% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :4.45 & 8.57% & 1.15\n",
      "for 2019-04-11, MAE is:3.59 & sMAPE is:6.85% & rMAE is:2.32 ||| daily mean of MAE & sMAPE & rMAE till now are :4.45 & 8.55% & 1.16\n",
      "for 2019-04-12, MAE is:2.97 & sMAPE is:5.36% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.43 & 8.52% & 1.15\n",
      "for 2019-04-13, MAE is:3.69 & sMAPE is:6.68% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 8.51% & 1.15\n",
      "for 2019-04-14, MAE is:3.66 & sMAPE is:6.96% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 8.49% & 1.14\n",
      "for 2019-04-15, MAE is:7.14 & sMAPE is:12.89% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :4.44 & 8.53% & 1.15\n",
      "for 2019-04-16, MAE is:4.97 & sMAPE is:8.90% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.45 & 8.54% & 1.14\n",
      "for 2019-04-17, MAE is:7.10 & sMAPE is:14.57% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :4.47 & 8.59% & 1.14\n",
      "for 2019-04-18, MAE is:5.91 & sMAPE is:11.26% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :4.49 & 8.62% & 1.15\n",
      "for 2019-04-19, MAE is:11.94 & sMAPE is:26.90% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.55 & 8.78% & 1.14\n",
      "for 2019-04-20, MAE is:3.99 & sMAPE is:11.07% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :4.55 & 8.81% & 1.13\n",
      "for 2019-04-21, MAE is:3.66 & sMAPE is:8.79% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :4.54 & 8.81% & 1.13\n",
      "for 2019-04-22, MAE is:5.05 & sMAPE is:9.87% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.55 & 8.81% & 1.13\n",
      "for 2019-04-23, MAE is:4.38 & sMAPE is:9.20% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :4.54 & 8.82% & 1.12\n",
      "for 2019-04-24, MAE is:10.79 & sMAPE is:24.99% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :4.60 & 8.96% & 1.13\n",
      "for 2019-04-25, MAE is:7.87 & sMAPE is:33.30% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :4.63 & 9.17% & 1.12\n",
      "for 2019-04-26, MAE is:8.36 & sMAPE is:17.67% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :4.66 & 9.24% & 1.11\n",
      "for 2019-04-27, MAE is:2.94 & sMAPE is:5.52% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :4.64 & 9.21% & 1.11\n",
      "for 2019-04-28, MAE is:3.57 & sMAPE is:7.05% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :4.64 & 9.19% & 1.10\n",
      "for 2019-04-29, MAE is:3.60 & sMAPE is:6.32% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :4.63 & 9.17% & 1.10\n",
      "for 2019-04-30, MAE is:4.78 & sMAPE is:7.98% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :4.63 & 9.16% & 1.10\n",
      "for 2019-05-01, MAE is:6.80 & sMAPE is:13.36% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :4.65 & 9.20% & 1.09\n",
      "for 2019-05-02, MAE is:3.46 & sMAPE is:8.01% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :4.64 & 9.19% & 1.09\n",
      "for 2019-05-03, MAE is:5.07 & sMAPE is:10.13% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :4.64 & 9.19% & 1.08\n",
      "for 2019-05-04, MAE is:4.82 & sMAPE is:10.16% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :4.64 & 9.20% & 1.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-05-05, MAE is:8.09 & sMAPE is:20.71% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :4.67 & 9.29% & 1.07\n",
      "for 2019-05-06, MAE is:2.17 & sMAPE is:4.29% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :4.65 & 9.25% & 1.07\n",
      "for 2019-05-07, MAE is:3.99 & sMAPE is:7.74% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :4.64 & 9.24% & 1.06\n",
      "for 2019-05-08, MAE is:7.76 & sMAPE is:18.07% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :4.67 & 9.31% & 1.06\n",
      "for 2019-05-09, MAE is:3.79 & sMAPE is:8.55% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :4.66 & 9.30% & 1.06\n",
      "for 2019-05-10, MAE is:3.56 & sMAPE is:7.67% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :4.65 & 9.29% & 1.06\n",
      "for 2019-05-11, MAE is:3.85 & sMAPE is:7.89% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :4.65 & 9.28% & 1.06\n",
      "for 2019-05-12, MAE is:8.45 & sMAPE is:22.57% & rMAE is:2.23 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 9.38% & 1.07\n",
      "for 2019-05-13, MAE is:4.45 & sMAPE is:9.43% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :4.67 & 9.38% & 1.07\n",
      "for 2019-05-14, MAE is:2.15 & sMAPE is:4.44% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :4.66 & 9.35% & 1.06\n",
      "for 2019-05-15, MAE is:3.87 & sMAPE is:7.02% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :4.65 & 9.33% & 1.05\n",
      "for 2019-05-16, MAE is:6.63 & sMAPE is:13.04% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :4.66 & 9.36% & 1.05\n",
      "for 2019-05-17, MAE is:5.66 & sMAPE is:12.50% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :4.67 & 9.38% & 1.06\n",
      "for 2019-05-18, MAE is:4.71 & sMAPE is:10.52% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :4.67 & 9.39% & 1.06\n",
      "for 2019-05-19, MAE is:4.47 & sMAPE is:9.68% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :4.67 & 9.39% & 1.05\n",
      "for 2019-05-20, MAE is:2.65 & sMAPE is:5.14% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.66 & 9.36% & 1.05\n",
      "for 2019-05-21, MAE is:3.74 & sMAPE is:7.01% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :4.65 & 9.34% & 1.05\n",
      "for 2019-05-22, MAE is:3.25 & sMAPE is:5.94% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :4.64 & 9.32% & 1.04\n",
      "for 2019-05-23, MAE is:3.06 & sMAPE is:5.46% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :4.63 & 9.29% & 1.04\n",
      "for 2019-05-24, MAE is:4.41 & sMAPE is:8.67% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :4.63 & 9.29% & 1.04\n",
      "for 2019-05-25, MAE is:3.97 & sMAPE is:8.86% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :4.62 & 9.28% & 1.04\n",
      "for 2019-05-26, MAE is:3.68 & sMAPE is:8.47% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :4.62 & 9.28% & 1.03\n",
      "for 2019-05-27, MAE is:5.50 & sMAPE is:11.27% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :4.62 & 9.29% & 1.03\n",
      "for 2019-05-28, MAE is:2.75 & sMAPE is:5.91% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :4.61 & 9.27% & 1.03\n",
      "for 2019-05-29, MAE is:2.19 & sMAPE is:4.73% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :4.59 & 9.24% & 1.02\n",
      "for 2019-05-30, MAE is:1.92 & sMAPE is:3.87% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :4.58 & 9.20% & 1.02\n",
      "for 2019-05-31, MAE is:2.44 & sMAPE is:4.39% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :4.56 & 9.17% & 1.01\n",
      "for 2019-06-01, MAE is:3.86 & sMAPE is:7.35% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :4.56 & 9.16% & 1.01\n",
      "for 2019-06-02, MAE is:2.55 & sMAPE is:5.33% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :4.54 & 9.13% & 1.01\n",
      "for 2019-06-03, MAE is:2.50 & sMAPE is:4.70% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :4.53 & 9.10% & 1.01\n",
      "for 2019-06-04, MAE is:5.09 & sMAPE is:9.94% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :4.53 & 9.11% & 1.01\n",
      "for 2019-06-05, MAE is:4.21 & sMAPE is:9.00% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :4.53 & 9.11% & 1.01\n",
      "for 2019-06-06, MAE is:9.98 & sMAPE is:21.30% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 9.19% & 1.01\n",
      "for 2019-06-07, MAE is:3.68 & sMAPE is:9.11% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :4.56 & 9.19% & 1.00\n",
      "for 2019-06-08, MAE is:3.05 & sMAPE is:6.52% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :4.55 & 9.17% & 1.00\n",
      "for 2019-06-09, MAE is:2.98 & sMAPE is:6.86% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :4.54 & 9.16% & 1.00\n",
      "for 2019-06-10, MAE is:4.01 & sMAPE is:9.27% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.54 & 9.16% & 0.99\n",
      "for 2019-06-11, MAE is:3.97 & sMAPE is:8.65% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :4.53 & 9.15% & 0.99\n",
      "for 2019-06-12, MAE is:3.00 & sMAPE is:6.63% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.52 & 9.14% & 0.99\n",
      "for 2019-06-13, MAE is:2.50 & sMAPE is:5.34% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :4.51 & 9.11% & 0.99\n",
      "for 2019-06-14, MAE is:5.37 & sMAPE is:11.71% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :4.52 & 9.13% & 0.98\n",
      "for 2019-06-15, MAE is:2.82 & sMAPE is:6.17% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :4.51 & 9.11% & 0.99\n",
      "for 2019-06-16, MAE is:1.49 & sMAPE is:3.20% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :4.49 & 9.08% & 0.98\n",
      "for 2019-06-17, MAE is:2.89 & sMAPE is:5.92% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :4.48 & 9.06% & 0.98\n",
      "for 2019-06-18, MAE is:5.09 & sMAPE is:10.69% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :4.48 & 9.07% & 0.98\n",
      "for 2019-06-19, MAE is:1.65 & sMAPE is:3.71% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :4.47 & 9.04% & 0.98\n",
      "for 2019-06-20, MAE is:2.76 & sMAPE is:5.85% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.46 & 9.02% & 0.98\n",
      "for 2019-06-21, MAE is:1.19 & sMAPE is:2.65% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :4.44 & 8.98% & 0.98\n",
      "for 2019-06-22, MAE is:1.97 & sMAPE is:4.39% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 8.95% & 0.98\n",
      "for 2019-06-23, MAE is:3.52 & sMAPE is:8.08% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 8.95% & 0.98\n",
      "for 2019-06-24, MAE is:3.67 & sMAPE is:7.40% & rMAE is:3.83 ||| daily mean of MAE & sMAPE & rMAE till now are :4.41 & 8.94% & 0.99\n",
      "for 2019-06-25, MAE is:3.08 & sMAPE is:6.15% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :4.41 & 8.92% & 0.99\n",
      "for 2019-06-26, MAE is:3.33 & sMAPE is:6.83% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.40 & 8.91% & 1.00\n",
      "for 2019-06-27, MAE is:2.21 & sMAPE is:4.45% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 8.89% & 0.99\n",
      "for 2019-06-28, MAE is:2.12 & sMAPE is:4.32% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.38 & 8.86% & 0.99\n",
      "for 2019-06-29, MAE is:1.47 & sMAPE is:2.98% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :4.36 & 8.83% & 0.99\n",
      "for 2019-06-30, MAE is:1.45 & sMAPE is:3.14% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 8.80% & 0.98\n",
      "for 2019-07-01, MAE is:3.91 & sMAPE is:7.71% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 8.79% & 0.99\n",
      "for 2019-07-02, MAE is:1.52 & sMAPE is:3.17% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 8.76% & 0.98\n",
      "for 2019-07-03, MAE is:1.72 & sMAPE is:3.47% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.31 & 8.73% & 0.98\n",
      "for 2019-07-04, MAE is:1.45 & sMAPE is:2.81% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.30 & 8.70% & 0.98\n",
      "for 2019-07-05, MAE is:2.00 & sMAPE is:3.78% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.28 & 8.67% & 0.98\n",
      "for 2019-07-06, MAE is:3.22 & sMAPE is:6.27% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :4.28 & 8.66% & 0.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-07-07, MAE is:2.54 & sMAPE is:5.07% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :4.27 & 8.64% & 0.97\n",
      "for 2019-07-08, MAE is:1.75 & sMAPE is:3.51% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :4.26 & 8.61% & 0.97\n",
      "for 2019-07-09, MAE is:2.73 & sMAPE is:5.01% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :4.25 & 8.60% & 0.97\n",
      "for 2019-07-10, MAE is:1.97 & sMAPE is:3.89% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :4.24 & 8.57% & 0.97\n",
      "for 2019-07-11, MAE is:2.07 & sMAPE is:4.07% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.22 & 8.55% & 0.98\n",
      "for 2019-07-12, MAE is:3.08 & sMAPE is:5.74% & rMAE is:2.03 ||| daily mean of MAE & sMAPE & rMAE till now are :4.22 & 8.53% & 0.98\n",
      "for 2019-07-13, MAE is:2.69 & sMAPE is:5.20% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :4.21 & 8.52% & 0.98\n",
      "for 2019-07-14, MAE is:1.35 & sMAPE is:2.67% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 8.49% & 0.98\n",
      "for 2019-07-15, MAE is:2.93 & sMAPE is:5.57% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 8.47% & 0.98\n",
      "for 2019-07-16, MAE is:1.34 & sMAPE is:2.58% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :4.17 & 8.44% & 0.98\n",
      "for 2019-07-17, MAE is:1.62 & sMAPE is:3.21% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :4.16 & 8.41% & 0.98\n",
      "for 2019-07-18, MAE is:2.11 & sMAPE is:4.04% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :4.15 & 8.39% & 0.98\n",
      "for 2019-07-19, MAE is:2.69 & sMAPE is:5.05% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :4.14 & 8.38% & 0.98\n",
      "for 2019-07-20, MAE is:3.07 & sMAPE is:6.13% & rMAE is:1.81 ||| daily mean of MAE & sMAPE & rMAE till now are :4.14 & 8.36% & 0.99\n",
      "for 2019-07-21, MAE is:2.70 & sMAPE is:5.53% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :4.13 & 8.35% & 0.99\n",
      "for 2019-07-22, MAE is:3.43 & sMAPE is:6.47% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :4.13 & 8.34% & 0.99\n",
      "for 2019-07-23, MAE is:2.72 & sMAPE is:4.79% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :4.12 & 8.32% & 0.99\n",
      "for 2019-07-24, MAE is:1.81 & sMAPE is:3.25% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.11 & 8.30% & 0.98\n",
      "for 2019-07-25, MAE is:4.43 & sMAPE is:8.04% & rMAE is:2.22 ||| daily mean of MAE & sMAPE & rMAE till now are :4.11 & 8.30% & 0.99\n",
      "for 2019-07-26, MAE is:2.03 & sMAPE is:3.90% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :4.10 & 8.28% & 0.99\n",
      "for 2019-07-27, MAE is:5.13 & sMAPE is:10.73% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :4.11 & 8.29% & 0.99\n",
      "for 2019-07-28, MAE is:2.62 & sMAPE is:5.55% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :4.10 & 8.28% & 0.99\n",
      "for 2019-07-29, MAE is:6.26 & sMAPE is:12.29% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :4.11 & 8.29% & 0.99\n",
      "for 2019-07-30, MAE is:3.10 & sMAPE is:6.52% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.11 & 8.29% & 0.99\n",
      "for 2019-07-31, MAE is:3.51 & sMAPE is:7.11% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.10 & 8.28% & 0.98\n",
      "for 2019-08-01, MAE is:1.36 & sMAPE is:2.99% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :4.09 & 8.26% & 0.98\n",
      "for 2019-08-02, MAE is:1.51 & sMAPE is:3.10% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :4.08 & 8.23% & 0.98\n",
      "for 2019-08-03, MAE is:1.81 & sMAPE is:3.84% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :4.07 & 8.21% & 0.98\n",
      "for 2019-08-04, MAE is:3.18 & sMAPE is:7.15% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :4.06 & 8.21% & 0.98\n",
      "for 2019-08-05, MAE is:2.92 & sMAPE is:5.83% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :4.06 & 8.20% & 0.98\n",
      "for 2019-08-06, MAE is:2.76 & sMAPE is:5.47% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :4.05 & 8.18% & 0.98\n",
      "for 2019-08-07, MAE is:1.73 & sMAPE is:3.59% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 8.16% & 0.97\n",
      "for 2019-08-08, MAE is:3.77 & sMAPE is:7.62% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 8.16% & 0.98\n",
      "for 2019-08-09, MAE is:5.58 & sMAPE is:12.22% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :4.05 & 8.18% & 0.98\n",
      "for 2019-08-10, MAE is:1.56 & sMAPE is:3.29% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 8.16% & 0.98\n",
      "for 2019-08-11, MAE is:2.76 & sMAPE is:6.46% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :4.03 & 8.15% & 0.97\n",
      "for 2019-08-12, MAE is:1.81 & sMAPE is:4.03% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :4.02 & 8.13% & 0.97\n",
      "for 2019-08-13, MAE is:2.75 & sMAPE is:6.39% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :4.01 & 8.12% & 0.97\n",
      "for 2019-08-14, MAE is:1.59 & sMAPE is:3.71% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :4.00 & 8.10% & 0.97\n",
      "for 2019-08-15, MAE is:4.15 & sMAPE is:9.83% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :4.00 & 8.11% & 0.96\n",
      "for 2019-08-16, MAE is:1.86 & sMAPE is:4.34% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :3.99 & 8.09% & 0.96\n",
      "for 2019-08-17, MAE is:3.15 & sMAPE is:7.39% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :3.99 & 8.09% & 0.96\n",
      "for 2019-08-18, MAE is:1.79 & sMAPE is:4.56% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :3.98 & 8.08% & 0.96\n",
      "for 2019-08-19, MAE is:2.89 & sMAPE is:7.02% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :3.98 & 8.07% & 0.96\n",
      "for 2019-08-20, MAE is:2.74 & sMAPE is:6.77% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :3.97 & 8.07% & 0.96\n",
      "for 2019-08-21, MAE is:3.52 & sMAPE is:8.85% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :3.97 & 8.07% & 0.96\n",
      "for 2019-08-22, MAE is:3.87 & sMAPE is:9.58% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :3.97 & 8.08% & 0.96\n",
      "for 2019-08-23, MAE is:2.56 & sMAPE is:6.16% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :3.96 & 8.07% & 0.96\n",
      "for 2019-08-24, MAE is:1.95 & sMAPE is:4.70% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :3.95 & 8.05% & 0.96\n",
      "for 2019-08-25, MAE is:2.83 & sMAPE is:7.20% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :3.95 & 8.05% & 0.96\n",
      "for 2019-08-26, MAE is:2.39 & sMAPE is:5.64% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :3.94 & 8.04% & 0.96\n",
      "for 2019-08-27, MAE is:3.15 & sMAPE is:6.56% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :3.94 & 8.03% & 0.96\n",
      "for 2019-08-28, MAE is:3.12 & sMAPE is:6.39% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :3.94 & 8.03% & 0.95\n",
      "for 2019-08-29, MAE is:1.87 & sMAPE is:3.86% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :3.93 & 8.01% & 0.95\n",
      "for 2019-08-30, MAE is:2.49 & sMAPE is:4.93% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :3.92 & 8.00% & 0.95\n",
      "for 2019-08-31, MAE is:3.48 & sMAPE is:7.78% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :3.92 & 7.99% & 0.95\n",
      "for 2019-09-01, MAE is:3.83 & sMAPE is:9.43% & rMAE is:2.57 ||| daily mean of MAE & sMAPE & rMAE till now are :3.92 & 8.00% & 0.96\n",
      "for 2019-09-02, MAE is:4.76 & sMAPE is:12.60% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :3.92 & 8.02% & 0.96\n",
      "for 2019-09-03, MAE is:2.88 & sMAPE is:6.92% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :3.92 & 8.02% & 0.96\n",
      "for 2019-09-04, MAE is:4.77 & sMAPE is:10.50% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :3.92 & 8.03% & 0.95\n",
      "for 2019-09-05, MAE is:3.73 & sMAPE is:9.64% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :3.92 & 8.03% & 0.95\n",
      "for 2019-09-06, MAE is:4.45 & sMAPE is:11.65% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :3.92 & 8.05% & 0.95\n",
      "for 2019-09-07, MAE is:5.15 & sMAPE is:14.63% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :3.93 & 8.07% & 0.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-09-08, MAE is:3.51 & sMAPE is:10.24% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :3.93 & 8.08% & 0.95\n",
      "for 2019-09-09, MAE is:4.53 & sMAPE is:10.89% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :3.93 & 8.09% & 0.94\n",
      "for 2019-09-10, MAE is:4.27 & sMAPE is:11.80% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :3.93 & 8.11% & 0.94\n",
      "for 2019-09-11, MAE is:3.32 & sMAPE is:9.28% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :3.93 & 8.11% & 0.94\n",
      "for 2019-09-12, MAE is:2.63 & sMAPE is:7.09% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :3.92 & 8.11% & 0.94\n",
      "for 2019-09-13, MAE is:3.10 & sMAPE is:8.21% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :3.92 & 8.11% & 0.94\n",
      "for 2019-09-14, MAE is:3.38 & sMAPE is:9.00% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :3.92 & 8.11% & 0.94\n",
      "for 2019-09-15, MAE is:2.72 & sMAPE is:7.14% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :3.91 & 8.11% & 0.94\n",
      "for 2019-09-16, MAE is:2.64 & sMAPE is:5.57% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :3.91 & 8.10% & 0.94\n",
      "for 2019-09-17, MAE is:4.52 & sMAPE is:9.54% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :3.91 & 8.10% & 0.93\n",
      "for 2019-09-18, MAE is:2.30 & sMAPE is:4.76% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :3.90 & 8.09% & 0.93\n",
      "for 2019-09-19, MAE is:2.08 & sMAPE is:4.11% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :3.90 & 8.08% & 0.93\n",
      "for 2019-09-20, MAE is:3.76 & sMAPE is:7.51% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :3.90 & 8.07% & 0.93\n",
      "for 2019-09-21, MAE is:5.98 & sMAPE is:14.32% & rMAE is:1.77 ||| daily mean of MAE & sMAPE & rMAE till now are :3.90 & 8.10% & 0.93\n",
      "for 2019-09-22, MAE is:3.85 & sMAPE is:9.90% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :3.90 & 8.10% & 0.93\n",
      "for 2019-09-23, MAE is:5.25 & sMAPE is:10.82% & rMAE is:1.78 ||| daily mean of MAE & sMAPE & rMAE till now are :3.91 & 8.11% & 0.93\n",
      "for 2019-09-24, MAE is:3.87 & sMAPE is:9.07% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :3.91 & 8.12% & 0.93\n",
      "for 2019-09-25, MAE is:2.73 & sMAPE is:6.25% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :3.90 & 8.11% & 0.93\n",
      "for 2019-09-26, MAE is:3.27 & sMAPE is:7.05% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :3.90 & 8.11% & 0.93\n",
      "for 2019-09-27, MAE is:2.54 & sMAPE is:5.36% & rMAE is:2.36 ||| daily mean of MAE & sMAPE & rMAE till now are :3.90 & 8.10% & 0.94\n",
      "for 2019-09-28, MAE is:3.61 & sMAPE is:8.13% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :3.90 & 8.10% & 0.94\n",
      "for 2019-09-29, MAE is:3.43 & sMAPE is:8.02% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :3.89 & 8.10% & 0.94\n",
      "for 2019-09-30, MAE is:3.37 & sMAPE is:7.09% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :3.89 & 8.09% & 0.94\n",
      "for 2019-10-01, MAE is:4.55 & sMAPE is:10.04% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :3.90 & 8.10% & 0.94\n",
      "for 2019-10-02, MAE is:3.92 & sMAPE is:9.02% & rMAE is:1.96 ||| daily mean of MAE & sMAPE & rMAE till now are :3.90 & 8.10% & 0.94\n",
      "for 2019-10-03, MAE is:4.57 & sMAPE is:9.92% & rMAE is:2.57 ||| daily mean of MAE & sMAPE & rMAE till now are :3.90 & 8.11% & 0.95\n",
      "for 2019-10-04, MAE is:5.17 & sMAPE is:10.57% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :3.90 & 8.12% & 0.95\n",
      "for 2019-10-05, MAE is:3.21 & sMAPE is:6.64% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :3.90 & 8.11% & 0.95\n",
      "for 2019-10-06, MAE is:3.05 & sMAPE is:7.00% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :3.90 & 8.11% & 0.95\n",
      "for 2019-10-07, MAE is:3.54 & sMAPE is:7.33% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :3.90 & 8.11% & 0.95\n",
      "for 2019-10-08, MAE is:4.10 & sMAPE is:7.97% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :3.90 & 8.11% & 0.95\n",
      "for 2019-10-09, MAE is:2.58 & sMAPE is:5.26% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :3.89 & 8.10% & 0.95\n",
      "for 2019-10-10, MAE is:2.85 & sMAPE is:5.87% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :3.89 & 8.09% & 0.94\n",
      "for 2019-10-11, MAE is:4.22 & sMAPE is:8.39% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :3.89 & 8.09% & 0.94\n",
      "for 2019-10-12, MAE is:7.09 & sMAPE is:17.06% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :3.90 & 8.12% & 0.94\n",
      "for 2019-10-13, MAE is:3.67 & sMAPE is:8.88% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :3.90 & 8.12% & 0.94\n",
      "for 2019-10-14, MAE is:6.67 & sMAPE is:15.14% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :3.91 & 8.15% & 0.94\n",
      "for 2019-10-15, MAE is:4.92 & sMAPE is:11.63% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :3.91 & 8.16% & 0.94\n",
      "for 2019-10-16, MAE is:4.18 & sMAPE is:9.51% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :3.91 & 8.16% & 0.94\n",
      "for 2019-10-17, MAE is:3.54 & sMAPE is:7.60% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :3.91 & 8.16% & 0.94\n",
      "for 2019-10-18, MAE is:3.31 & sMAPE is:7.35% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :3.91 & 8.16% & 0.94\n",
      "for 2019-10-19, MAE is:3.90 & sMAPE is:9.12% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :3.91 & 8.16% & 0.94\n",
      "for 2019-10-20, MAE is:3.22 & sMAPE is:7.42% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :3.91 & 8.16% & 0.94\n",
      "for 2019-10-21, MAE is:4.95 & sMAPE is:9.76% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :3.91 & 8.17% & 0.94\n",
      "for 2019-10-22, MAE is:3.99 & sMAPE is:8.01% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :3.91 & 8.17% & 0.94\n",
      "for 2019-10-23, MAE is:4.44 & sMAPE is:9.99% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :3.91 & 8.17% & 0.94\n",
      "for 2019-10-24, MAE is:3.92 & sMAPE is:8.40% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :3.91 & 8.17% & 0.94\n",
      "for 2019-10-25, MAE is:3.83 & sMAPE is:7.64% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :3.91 & 8.17% & 0.94\n",
      "for 2019-10-26, MAE is:3.17 & sMAPE is:6.76% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :3.91 & 8.17% & 0.94\n",
      "for 2019-10-27, MAE is:2.80 & sMAPE is:5.92% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :3.91 & 8.16% & 0.94\n",
      "for 2019-10-28, MAE is:3.00 & sMAPE is:5.70% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :3.90 & 8.15% & 0.94\n",
      "for 2019-10-29, MAE is:2.86 & sMAPE is:5.18% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :3.90 & 8.14% & 0.94\n",
      "for 2019-10-30, MAE is:3.78 & sMAPE is:7.27% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :3.90 & 8.14% & 0.94\n",
      "for 2019-10-31, MAE is:4.71 & sMAPE is:9.57% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :3.90 & 8.14% & 0.94\n",
      "for 2019-11-01, MAE is:11.40 & sMAPE is:29.58% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :3.93 & 8.21% & 0.93\n",
      "for 2019-11-02, MAE is:5.70 & sMAPE is:17.96% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :3.93 & 8.24% & 0.93\n",
      "for 2019-11-03, MAE is:12.00 & sMAPE is:58.42% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :3.96 & 8.41% & 0.93\n",
      "for 2019-11-04, MAE is:7.70 & sMAPE is:36.88% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :3.97 & 8.50% & 0.93\n",
      "for 2019-11-05, MAE is:8.65 & sMAPE is:32.70% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :3.99 & 8.58% & 0.93\n",
      "for 2019-11-06, MAE is:3.50 & sMAPE is:9.42% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :3.99 & 8.58% & 0.92\n",
      "for 2019-11-07, MAE is:5.11 & sMAPE is:12.29% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :3.99 & 8.59% & 0.92\n",
      "for 2019-11-08, MAE is:3.59 & sMAPE is:9.44% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :3.99 & 8.60% & 0.92\n",
      "for 2019-11-09, MAE is:2.62 & sMAPE is:6.32% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :3.98 & 8.59% & 0.92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-11-10, MAE is:4.43 & sMAPE is:11.68% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :3.98 & 8.60% & 0.92\n",
      "for 2019-11-11, MAE is:3.23 & sMAPE is:7.11% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :3.98 & 8.59% & 0.92\n",
      "for 2019-11-12, MAE is:2.91 & sMAPE is:6.01% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :3.98 & 8.59% & 0.91\n",
      "for 2019-11-13, MAE is:2.98 & sMAPE is:6.32% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :3.98 & 8.58% & 0.91\n",
      "for 2019-11-14, MAE is:3.72 & sMAPE is:8.10% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :3.97 & 8.58% & 0.91\n",
      "for 2019-11-15, MAE is:2.85 & sMAPE is:5.82% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :3.97 & 8.57% & 0.91\n",
      "for 2019-11-16, MAE is:3.15 & sMAPE is:6.67% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :3.97 & 8.56% & 0.91\n",
      "for 2019-11-17, MAE is:5.43 & sMAPE is:11.96% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :3.97 & 8.57% & 0.91\n",
      "for 2019-11-18, MAE is:3.94 & sMAPE is:7.80% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :3.97 & 8.57% & 0.91\n",
      "for 2019-11-19, MAE is:3.82 & sMAPE is:6.81% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :3.97 & 8.57% & 0.91\n",
      "for 2019-11-20, MAE is:3.55 & sMAPE is:6.14% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :3.97 & 8.56% & 0.90\n",
      "for 2019-11-21, MAE is:4.44 & sMAPE is:8.29% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :3.97 & 8.56% & 0.90\n",
      "for 2019-11-22, MAE is:8.26 & sMAPE is:16.45% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :3.99 & 8.58% & 0.91\n",
      "for 2019-11-23, MAE is:4.91 & sMAPE is:13.24% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :3.99 & 8.60% & 0.90\n",
      "for 2019-11-24, MAE is:4.74 & sMAPE is:11.27% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :3.99 & 8.60% & 0.91\n",
      "for 2019-11-25, MAE is:3.29 & sMAPE is:7.23% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :3.99 & 8.60% & 0.91\n",
      "for 2019-11-26, MAE is:5.06 & sMAPE is:10.95% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :3.99 & 8.61% & 0.91\n",
      "for 2019-11-27, MAE is:3.50 & sMAPE is:8.23% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :3.99 & 8.61% & 0.90\n",
      "for 2019-11-28, MAE is:6.01 & sMAPE is:17.87% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :4.00 & 8.63% & 0.90\n",
      "for 2019-11-29, MAE is:3.95 & sMAPE is:8.72% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :4.00 & 8.63% & 0.90\n",
      "for 2019-11-30, MAE is:4.60 & sMAPE is:10.56% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :4.00 & 8.64% & 0.90\n",
      "for 2019-12-01, MAE is:4.40 & sMAPE is:10.60% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :4.00 & 8.65% & 0.90\n",
      "for 2019-12-02, MAE is:2.42 & sMAPE is:5.74% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :3.99 & 8.64% & 0.90\n",
      "for 2019-12-03, MAE is:4.54 & sMAPE is:9.28% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :4.00 & 8.64% & 0.90\n",
      "for 2019-12-04, MAE is:4.42 & sMAPE is:7.92% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :4.00 & 8.64% & 0.90\n",
      "for 2019-12-05, MAE is:4.83 & sMAPE is:9.60% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :4.00 & 8.64% & 0.90\n",
      "for 2019-12-06, MAE is:4.17 & sMAPE is:8.40% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :4.00 & 8.64% & 0.90\n",
      "for 2019-12-07, MAE is:2.66 & sMAPE is:5.58% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :4.00 & 8.63% & 0.90\n",
      "for 2019-12-08, MAE is:3.87 & sMAPE is:9.09% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :4.00 & 8.63% & 0.90\n",
      "for 2019-12-09, MAE is:4.74 & sMAPE is:11.71% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :4.00 & 8.64% & 0.90\n",
      "for 2019-12-10, MAE is:3.36 & sMAPE is:7.23% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :4.00 & 8.64% & 0.90\n",
      "for 2019-12-11, MAE is:4.47 & sMAPE is:10.11% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.00 & 8.64% & 0.90\n",
      "for 2019-12-12, MAE is:5.22 & sMAPE is:12.53% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :4.00 & 8.65% & 0.90\n",
      "for 2019-12-13, MAE is:10.44 & sMAPE is:39.48% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :4.02 & 8.74% & 0.90\n",
      "for 2019-12-14, MAE is:5.61 & sMAPE is:17.90% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :4.02 & 8.77% & 0.89\n",
      "for 2019-12-15, MAE is:9.21 & sMAPE is:41.98% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 8.86% & 0.89\n",
      "for 2019-12-16, MAE is:2.35 & sMAPE is:5.97% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :4.03 & 8.85% & 0.89\n",
      "for 2019-12-17, MAE is:4.54 & sMAPE is:10.64% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 8.86% & 0.89\n",
      "for 2019-12-18, MAE is:6.60 & sMAPE is:16.74% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 8.88% & 0.89\n",
      "for 2019-12-19, MAE is:15.78 & sMAPE is:65.62% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :4.08 & 9.04% & 0.89\n",
      "for 2019-12-20, MAE is:12.22 & sMAPE is:71.40% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :4.10 & 9.22% & 0.90\n",
      "for 2019-12-21, MAE is:25.99 & sMAPE is:174.03% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :4.16 & 9.68% & 0.90\n",
      "for 2019-12-22, MAE is:19.89 & sMAPE is:176.76% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :4.21 & 10.15% & 0.90\n",
      "for 2019-12-23, MAE is:8.16 & sMAPE is:54.59% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :4.22 & 10.28% & 0.89\n",
      "for 2019-12-24, MAE is:8.86 & sMAPE is:55.98% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.23 & 10.40% & 0.89\n",
      "for 2019-12-25, MAE is:12.81 & sMAPE is:72.81% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :4.25 & 10.58% & 0.89\n",
      "for 2019-12-26, MAE is:7.61 & sMAPE is:38.69% & rMAE is:1.98 ||| daily mean of MAE & sMAPE & rMAE till now are :4.26 & 10.66% & 0.90\n",
      "for 2019-12-27, MAE is:4.17 & sMAPE is:13.66% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :4.26 & 10.66% & 0.89\n",
      "for 2019-12-28, MAE is:6.95 & sMAPE is:22.15% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :4.27 & 10.70% & 0.89\n",
      "for 2019-12-29, MAE is:4.13 & sMAPE is:13.02% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :4.27 & 10.70% & 0.89\n",
      "for 2019-12-30, MAE is:5.42 & sMAPE is:15.98% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.27 & 10.72% & 0.89\n",
      "for 2019-12-31, MAE is:5.68 & sMAPE is:14.57% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :4.28 & 10.73% & 0.89\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\1 - Consolidated Data\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:31:24,813]\u001b[0m A new study created in RDB with name: PT_2020\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:31:47,881]\u001b[0m Trial 1 finished with value: 5.740596547846022 and parameters: {'n_hidden': 3, 'learning_rate': 0.06220516252166931, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37106717994088856, 'dropout_rate_Layer_2': 0.26123993052763633, 'dropout_rate_Layer_3': 0.19918273532158912, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00011119193574655929, 'l1_Layer_2': 1.4312230013079331e-05, 'l1_Layer_3': 0.035491280646952665, 'n_units_Layer_1': 95, 'n_units_Layer_2': 75, 'n_units_Layer_3': 70}. Best is trial 1 with value: 5.740596547846022.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.74 | sMAPE for Validation Set is: 13.90% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 12.53 | sMAPE for Test Set is: 36.08% | rMAE for Test Set is: 1.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:31:48,114]\u001b[0m Trial 3 pruned. Trial was pruned at epoch 48.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:31:48,273]\u001b[0m Trial 2 pruned. Trial was pruned at epoch 13.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:31:54,301]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:31:54,607]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:31:54,743]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.23 | sMAPE for Validation Set is: 12.83% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 12.17 | sMAPE for Test Set is: 35.29% | rMAE for Test Set is: 1.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:31:58,932]\u001b[0m Trial 0 finished with value: 5.23474045199389 and parameters: {'n_hidden': 3, 'learning_rate': 0.006779933257842089, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22467272284201886, 'dropout_rate_Layer_2': 0.3402978070089462, 'dropout_rate_Layer_3': 0.17080744594718633, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.013851301553046981, 'l1_Layer_2': 0.06576980321307567, 'l1_Layer_3': 0.033723453065653566, 'n_units_Layer_1': 230, 'n_units_Layer_2': 175, 'n_units_Layer_3': 265}. Best is trial 0 with value: 5.23474045199389.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:32:06,315]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:32:06,597]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:32:10,256]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:32:14,921]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:32:18,358]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:32:20,138]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:32:22,639]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:32:34,956]\u001b[0m Trial 17 finished with value: 5.3419754841341005 and parameters: {'n_hidden': 4, 'learning_rate': 0.02254358175217932, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2474200646609097, 'dropout_rate_Layer_2': 0.04841035509309584, 'dropout_rate_Layer_3': 0.3346060859143977, 'dropout_rate_Layer_4': 0.14103135626566737, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.005584061813491812, 'l1_Layer_2': 5.9653691384065606e-05, 'l1_Layer_3': 0.09596137410724662, 'l1_Layer_4': 0.0037803355250469826, 'n_units_Layer_1': 235, 'n_units_Layer_2': 70, 'n_units_Layer_3': 225, 'n_units_Layer_4': 110}. Best is trial 0 with value: 5.23474045199389.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.34 | sMAPE for Validation Set is: 13.04% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 12.05 | sMAPE for Test Set is: 35.08% | rMAE for Test Set is: 1.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:32:37,967]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:32:40,666]\u001b[0m Trial 7 finished with value: 3.9176774828593826 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010724591049980272, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37116232327586535, 'dropout_rate_Layer_2': 0.3161202220938689, 'dropout_rate_Layer_3': 0.07176877585333741, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003780503373091897, 'l1_Layer_2': 0.00011823630648637049, 'l1_Layer_3': 1.900966475252003e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 280, 'n_units_Layer_3': 195}. Best is trial 7 with value: 3.9176774828593826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.92 | sMAPE for Validation Set is: 10.30% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.80 | sMAPE for Test Set is: 19.81% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:32:44,974]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:32:50,296]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:32:52,351]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:32:52,788]\u001b[0m Trial 12 finished with value: 5.047853017696901 and parameters: {'n_hidden': 4, 'learning_rate': 0.005492800883893172, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.062361971627615545, 'dropout_rate_Layer_2': 0.21490808046805765, 'dropout_rate_Layer_3': 0.1287666807311217, 'dropout_rate_Layer_4': 0.3212341170324221, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 6.979895757283184e-05, 'l1_Layer_2': 3.6292104006269753e-05, 'l1_Layer_3': 0.0007865428811653157, 'l1_Layer_4': 0.03801939539013009, 'n_units_Layer_1': 270, 'n_units_Layer_2': 135, 'n_units_Layer_3': 75, 'n_units_Layer_4': 255}. Best is trial 7 with value: 3.9176774828593826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.05 | sMAPE for Validation Set is: 12.43% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 10.43 | sMAPE for Test Set is: 31.61% | rMAE for Test Set is: 1.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:32:54,692]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:33:00,192]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:33:01,188]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:33:02,842]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:33:05,197]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:33:10,377]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:33:12,434]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:33:15,153]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:33:15,407]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:33:16,475]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:33:22,809]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:33:26,271]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:33:30,061]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:33:33,379]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:33:36,921]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:33:37,618]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:33:41,661]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:33:44,514]\u001b[0m Trial 31 finished with value: 4.828801048259274 and parameters: {'n_hidden': 3, 'learning_rate': 0.016150850865674343, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22010384359294136, 'dropout_rate_Layer_2': 0.22237404564770996, 'dropout_rate_Layer_3': 0.3591049175667891, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.012513599878452807, 'l1_Layer_2': 7.380689380024263e-05, 'l1_Layer_3': 0.001038855714328727, 'n_units_Layer_1': 250, 'n_units_Layer_2': 180, 'n_units_Layer_3': 195}. Best is trial 7 with value: 3.9176774828593826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.83 | sMAPE for Validation Set is: 12.04% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 9.28 | sMAPE for Test Set is: 29.01% | rMAE for Test Set is: 1.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:33:46,340]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:33:47,816]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:33:52,086]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:33:52,540]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:33:54,283]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:33:56,806]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:33:58,907]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:33:59,187]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:34:01,443]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:34:04,087]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:34:07,300]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:34:08,174]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:34:11,097]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:34:12,434]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:34:15,856]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:34:17,702]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:34:19,860]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:34:24,646]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:34:28,945]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:34:31,458]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:34:33,705]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:34:37,060]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:34:40,021]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:34:44,190]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:34:44,657]\u001b[0m Trial 63 finished with value: 7.744120136630379 and parameters: {'n_hidden': 4, 'learning_rate': 0.00373293113502191, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3069305513737116, 'dropout_rate_Layer_2': 0.2557364287315074, 'dropout_rate_Layer_3': 0.22876714777059318, 'dropout_rate_Layer_4': 0.06797585807710319, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 6.0480652000271695e-05, 'l1_Layer_2': 0.00513508807786236, 'l1_Layer_3': 1.2075613562792625e-05, 'l1_Layer_4': 0.0017086163077333872, 'n_units_Layer_1': 205, 'n_units_Layer_2': 175, 'n_units_Layer_3': 295, 'n_units_Layer_4': 245}. Best is trial 7 with value: 3.9176774828593826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.74 | sMAPE for Validation Set is: 17.63% | rMAE for Validation Set is: 1.15\n",
      "MAE for Test Set is: 16.84 | sMAPE for Test Set is: 44.49% | rMAE for Test Set is: 2.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:34:47,790]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:34:48,616]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:34:53,657]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:34:55,027]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:34:57,950]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:35:01,017]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:35:02,723]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:35:05,950]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:35:09,788]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:35:10,884]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:35:12,614]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:35:14,347]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:35:20,664]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:35:26,824]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:35:42,232]\u001b[0m Trial 72 finished with value: 4.732549808225152 and parameters: {'n_hidden': 3, 'learning_rate': 0.0067527009223736275, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21040719795338048, 'dropout_rate_Layer_2': 0.08051143095951714, 'dropout_rate_Layer_3': 0.3111653429796332, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 3.201333661051768e-05, 'l1_Layer_2': 6.138194952738692e-05, 'l1_Layer_3': 0.0005049328717970849, 'n_units_Layer_1': 180, 'n_units_Layer_2': 225, 'n_units_Layer_3': 55}. Best is trial 7 with value: 3.9176774828593826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.73 | sMAPE for Validation Set is: 11.83% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 9.43 | sMAPE for Test Set is: 29.42% | rMAE for Test Set is: 1.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:35:46,563]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:35:50,776]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:35:56,074]\u001b[0m Trial 78 finished with value: 4.431015310074365 and parameters: {'n_hidden': 4, 'learning_rate': 0.004284676554517493, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34949017670072335, 'dropout_rate_Layer_2': 0.12816035060491832, 'dropout_rate_Layer_3': 0.010012043092552948, 'dropout_rate_Layer_4': 0.015555557763981875, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00029607671369417894, 'l1_Layer_2': 0.00010983612371829751, 'l1_Layer_3': 0.0006382780129726053, 'l1_Layer_4': 0.011504623180197132, 'n_units_Layer_1': 145, 'n_units_Layer_2': 200, 'n_units_Layer_3': 50, 'n_units_Layer_4': 115}. Best is trial 7 with value: 3.9176774828593826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.43 | sMAPE for Validation Set is: 11.25% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.49 | sMAPE for Test Set is: 22.01% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:35:56,779]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:36:02,775]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:36:07,562]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:36:18,600]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:36:22,284]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:36:26,407]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:36:31,907]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:36:33,679]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:36:38,666]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:36:41,871]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:36:49,132]\u001b[0m Trial 93 finished with value: 5.913627540545757 and parameters: {'n_hidden': 3, 'learning_rate': 0.02963481231437922, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18620447687431124, 'dropout_rate_Layer_2': 0.05674913280612257, 'dropout_rate_Layer_3': 0.19093136245734815, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 2.4844241720299113e-05, 'l1_Layer_2': 2.06513836841143e-05, 'l1_Layer_3': 0.0008530555417615822, 'n_units_Layer_1': 265, 'n_units_Layer_2': 100, 'n_units_Layer_3': 100}. Best is trial 7 with value: 3.9176774828593826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.91 | sMAPE for Validation Set is: 14.36% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 8.72 | sMAPE for Test Set is: 27.82% | rMAE for Test Set is: 1.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:36:52,620]\u001b[0m Trial 77 finished with value: 5.0661535139368015 and parameters: {'n_hidden': 4, 'learning_rate': 0.010747133801928311, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.022052104121071947, 'dropout_rate_Layer_2': 0.0180381018954916, 'dropout_rate_Layer_3': 0.12299359598450886, 'dropout_rate_Layer_4': 0.26301172035834897, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.08253910200278118, 'l1_Layer_2': 0.02684136739161053, 'l1_Layer_3': 0.022885529731342093, 'l1_Layer_4': 4.775203169682424e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 260, 'n_units_Layer_3': 210, 'n_units_Layer_4': 105}. Best is trial 7 with value: 3.9176774828593826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.07 | sMAPE for Validation Set is: 12.53% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 9.50 | sMAPE for Test Set is: 29.55% | rMAE for Test Set is: 1.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:36:58,188]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:37:00,776]\u001b[0m Trial 86 finished with value: 5.183267602849495 and parameters: {'n_hidden': 3, 'learning_rate': 0.010722057345144392, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30899568865088084, 'dropout_rate_Layer_2': 0.045374731195314724, 'dropout_rate_Layer_3': 0.34411263024418776, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.028615016608239594, 'l1_Layer_2': 2.2729728609423628e-05, 'l1_Layer_3': 0.00091432719826821, 'n_units_Layer_1': 235, 'n_units_Layer_2': 300, 'n_units_Layer_3': 100}. Best is trial 7 with value: 3.9176774828593826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.18 | sMAPE for Validation Set is: 12.62% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 9.81 | sMAPE for Test Set is: 30.32% | rMAE for Test Set is: 1.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:37:03,754]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:37:04,146]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:37:05,108]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:37:10,503]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:37:14,010]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:37:17,430]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:37:18,643]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:37:18,867]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:37:31,862]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:37:34,665]\u001b[0m Trial 107 finished with value: 5.263533983949843 and parameters: {'n_hidden': 3, 'learning_rate': 0.02202750143942163, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21050692449133065, 'dropout_rate_Layer_2': 0.22994627305709306, 'dropout_rate_Layer_3': 0.3654346148729237, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 1.0056101986631788e-05, 'l1_Layer_2': 0.005549957744598539, 'l1_Layer_3': 0.0007158126464126204, 'n_units_Layer_1': 265, 'n_units_Layer_2': 75, 'n_units_Layer_3': 295}. Best is trial 7 with value: 3.9176774828593826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.26 | sMAPE for Validation Set is: 12.90% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 9.78 | sMAPE for Test Set is: 30.06% | rMAE for Test Set is: 1.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:37:35,140]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:37:40,483]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:37:46,272]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:37:46,532]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:37:53,383]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.33 | sMAPE for Validation Set is: 11.04% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 8.64 | sMAPE for Test Set is: 27.45% | rMAE for Test Set is: 1.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:37:55,113]\u001b[0m Trial 105 finished with value: 4.326788906105404 and parameters: {'n_hidden': 4, 'learning_rate': 0.004863208045483083, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2540726055302082, 'dropout_rate_Layer_2': 0.041181503973971224, 'dropout_rate_Layer_3': 0.2706049855381632, 'dropout_rate_Layer_4': 0.1259247575519121, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.332041054537204e-05, 'l1_Layer_2': 6.224528246072558e-05, 'l1_Layer_3': 0.0014374424660032843, 'l1_Layer_4': 1.5019734263932132e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 100, 'n_units_Layer_3': 250, 'n_units_Layer_4': 100}. Best is trial 7 with value: 3.9176774828593826.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:37:59,237]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:38:06,191]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:38:11,864]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:38:16,338]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:38:22,283]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:38:25,985]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:38:28,961]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:38:32,208]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:38:45,722]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:38:48,197]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:38:49,961]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:38:50,847]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:38:52,655]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:38:57,150]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:39:04,002]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:39:09,500]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:39:09,507]\u001b[0m Trial 127 finished with value: 4.837388273040233 and parameters: {'n_hidden': 3, 'learning_rate': 0.029743651360382845, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3524737737643294, 'dropout_rate_Layer_2': 0.3798229756955017, 'dropout_rate_Layer_3': 0.27737271184222523, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.013095552157670182, 'l1_Layer_2': 0.0005470568268882663, 'l1_Layer_3': 0.02841679925073993, 'n_units_Layer_1': 95, 'n_units_Layer_2': 85, 'n_units_Layer_3': 260}. Best is trial 7 with value: 3.9176774828593826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.84 | sMAPE for Validation Set is: 12.07% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 7.65 | sMAPE for Test Set is: 25.04% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:39:16,472]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:39:18,362]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:39:19,240]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:39:22,547]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:39:24,217]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:39:27,868]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:39:28,854]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:39:34,403]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:39:39,208]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:39:44,223]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:39:44,687]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:39:44,767]\u001b[0m Trial 139 finished with value: 4.527458107404869 and parameters: {'n_hidden': 3, 'learning_rate': 0.020906964620501133, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36050871092653675, 'dropout_rate_Layer_2': 0.35674733480502335, 'dropout_rate_Layer_3': 0.24689054820732192, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00740981491931868, 'l1_Layer_2': 0.001120400958089922, 'l1_Layer_3': 0.003907001599883437, 'n_units_Layer_1': 100, 'n_units_Layer_2': 105, 'n_units_Layer_3': 245}. Best is trial 7 with value: 3.9176774828593826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.53 | sMAPE for Validation Set is: 11.43% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.80 | sMAPE for Test Set is: 22.94% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:39:51,295]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:39:55,305]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:39:59,216]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:40:02,124]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:40:05,639]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:40:10,292]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:40:10,307]\u001b[0m Trial 142 finished with value: 4.453269305122632 and parameters: {'n_hidden': 3, 'learning_rate': 0.01989236764047923, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35590224614498517, 'dropout_rate_Layer_2': 0.3589872369235183, 'dropout_rate_Layer_3': 0.24837315691873607, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.007060066560210144, 'l1_Layer_2': 0.0008897864678783569, 'l1_Layer_3': 0.0115027147568543, 'n_units_Layer_1': 120, 'n_units_Layer_2': 95, 'n_units_Layer_3': 255}. Best is trial 7 with value: 3.9176774828593826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.45 | sMAPE for Validation Set is: 11.30% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 7.18 | sMAPE for Test Set is: 23.91% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:40:19,696]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:40:21,259]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:40:25,756]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:40:31,822]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:40:39,380]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:40:44,469]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:40:55,047]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:41:04,813]\u001b[0m Trial 154 finished with value: 4.610949560117456 and parameters: {'n_hidden': 4, 'learning_rate': 0.0027977210607572525, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26661236699862195, 'dropout_rate_Layer_2': 0.3087881426683334, 'dropout_rate_Layer_3': 0.18134461192628684, 'dropout_rate_Layer_4': 0.11297930228851444, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.08506912970061233, 'l1_Layer_2': 0.0010226372611080907, 'l1_Layer_3': 0.00019649394285438398, 'l1_Layer_4': 0.0006644640396417208, 'n_units_Layer_1': 185, 'n_units_Layer_2': 255, 'n_units_Layer_3': 50, 'n_units_Layer_4': 170}. Best is trial 7 with value: 3.9176774828593826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.61 | sMAPE for Validation Set is: 11.62% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 8.59 | sMAPE for Test Set is: 27.55% | rMAE for Test Set is: 1.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:41:10,218]\u001b[0m Trial 146 finished with value: 4.107535009476837 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017742661319090393, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1061911680943236, 'dropout_rate_Layer_2': 0.13625997054690087, 'dropout_rate_Layer_3': 0.291189412827729, 'dropout_rate_Layer_4': 0.3272339420896309, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0005957607077749861, 'l1_Layer_2': 0.00021023616862621817, 'l1_Layer_3': 0.005024077564025599, 'l1_Layer_4': 1.15302138738336e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 170, 'n_units_Layer_3': 215, 'n_units_Layer_4': 110}. Best is trial 7 with value: 3.9176774828593826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.11 | sMAPE for Validation Set is: 10.61% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.23 | sMAPE for Test Set is: 19.58% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:41:13,638]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:41:14,595]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:41:29,268]\u001b[0m Trial 161 finished with value: 4.44873917906422 and parameters: {'n_hidden': 3, 'learning_rate': 0.018395964090251224, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30861854554802337, 'dropout_rate_Layer_2': 0.37340050726208823, 'dropout_rate_Layer_3': 0.22659253872837137, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.015846237051897194, 'l1_Layer_2': 0.0007871407118412205, 'l1_Layer_3': 0.015982141063723573, 'n_units_Layer_1': 235, 'n_units_Layer_2': 90, 'n_units_Layer_3': 255}. Best is trial 7 with value: 3.9176774828593826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.45 | sMAPE for Validation Set is: 11.29% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.41 | sMAPE for Test Set is: 21.90% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:41:34,005]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:41:47,877]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:41:54,275]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:41:57,134]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:42:03,956]\u001b[0m Trial 141 finished with value: 4.042155908164144 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017968088293347378, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11701587292143718, 'dropout_rate_Layer_2': 0.12760487133767745, 'dropout_rate_Layer_3': 0.2757368176316399, 'dropout_rate_Layer_4': 0.3385883375870664, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0004928228526953559, 'l1_Layer_2': 0.00018462315661043412, 'l1_Layer_3': 0.004876394010416155, 'l1_Layer_4': 1.1302106981558257e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 185, 'n_units_Layer_3': 230, 'n_units_Layer_4': 110}. Best is trial 7 with value: 3.9176774828593826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.04 | sMAPE for Validation Set is: 10.36% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.23 | sMAPE for Test Set is: 20.50% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:42:18,597]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:42:29,668]\u001b[0m Trial 167 finished with value: 4.546139078673039 and parameters: {'n_hidden': 4, 'learning_rate': 0.004824966096476143, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25099317362465257, 'dropout_rate_Layer_2': 0.3118738029488028, 'dropout_rate_Layer_3': 0.15380753811909775, 'dropout_rate_Layer_4': 0.09032419668973062, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.001132732320885714, 'l1_Layer_2': 0.002316169533945907, 'l1_Layer_3': 0.00035443829920289526, 'l1_Layer_4': 0.000164544668401515, 'n_units_Layer_1': 225, 'n_units_Layer_2': 200, 'n_units_Layer_3': 65, 'n_units_Layer_4': 210}. Best is trial 7 with value: 3.9176774828593826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.55 | sMAPE for Validation Set is: 11.42% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 8.24 | sMAPE for Test Set is: 26.47% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:42:32,346]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:42:37,729]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:42:37,986]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:42:42,560]\u001b[0m Trial 159 finished with value: 4.255758880769741 and parameters: {'n_hidden': 4, 'learning_rate': 0.0020663829548853143, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09926978871650721, 'dropout_rate_Layer_2': 0.12101350176478576, 'dropout_rate_Layer_3': 0.28156454743337045, 'dropout_rate_Layer_4': 0.3302499103828517, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0005781988356472662, 'l1_Layer_2': 0.00024271463360980654, 'l1_Layer_3': 0.007294350244310508, 'l1_Layer_4': 1.1180959004251754e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 170, 'n_units_Layer_3': 230, 'n_units_Layer_4': 110}. Best is trial 7 with value: 3.9176774828593826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.26 | sMAPE for Validation Set is: 10.95% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.49 | sMAPE for Test Set is: 18.63% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:42:43,884]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:42:47,702]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:42:48,300]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:42:52,086]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:42:52,240]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:42:57,807]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:42:58,994]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:43:05,362]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:43:17,838]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:43:24,080]\u001b[0m Trial 172 finished with value: 4.338729212133134 and parameters: {'n_hidden': 4, 'learning_rate': 0.0021483693071140627, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24770074192742556, 'dropout_rate_Layer_2': 0.32605398436323596, 'dropout_rate_Layer_3': 0.15609321114621674, 'dropout_rate_Layer_4': 0.054410822591523245, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0035448499108116866, 'l1_Layer_2': 0.0029024927186821685, 'l1_Layer_3': 0.00011127587059926435, 'l1_Layer_4': 0.00011931399490206288, 'n_units_Layer_1': 230, 'n_units_Layer_2': 160, 'n_units_Layer_3': 105, 'n_units_Layer_4': 215}. Best is trial 7 with value: 3.9176774828593826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.34 | sMAPE for Validation Set is: 11.07% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.44 | sMAPE for Test Set is: 21.76% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:43:24,539]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:43:29,505]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:43:30,833]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:43:33,244]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:43:33,805]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:43:37,575]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:43:38,032]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:43:41,773]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:43:42,616]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:43:44,909]\u001b[0m Trial 164 finished with value: 3.753164926907204 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006026188890233101, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33844450568293716, 'dropout_rate_Layer_2': 0.3646228153340195, 'dropout_rate_Layer_3': 0.15742939901045142, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015491525681939659, 'l1_Layer_2': 0.0008158250875792404, 'l1_Layer_3': 3.777483757611507e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 135, 'n_units_Layer_3': 285}. Best is trial 164 with value: 3.753164926907204.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 9.73% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.42 | sMAPE for Test Set is: 19.12% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:43:47,080]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:43:51,980]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:43:55,388]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:44:00,484]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:44:03,344]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:44:12,523]\u001b[0m Trial 197 finished with value: 4.3311598221017 and parameters: {'n_hidden': 3, 'learning_rate': 0.014962871375974551, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2789506239850065, 'dropout_rate_Layer_2': 0.3202694224327448, 'dropout_rate_Layer_3': 0.22979599228995343, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.003199361625478278, 'l1_Layer_2': 0.003286963863068066, 'l1_Layer_3': 0.008972356703172446, 'n_units_Layer_1': 95, 'n_units_Layer_2': 80, 'n_units_Layer_3': 245}. Best is trial 164 with value: 3.753164926907204.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.33 | sMAPE for Validation Set is: 11.07% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.43 | sMAPE for Test Set is: 21.93% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:44:30,679]\u001b[0m Trial 200 finished with value: 4.30230425425304 and parameters: {'n_hidden': 3, 'learning_rate': 0.013349279195355451, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2779820863465961, 'dropout_rate_Layer_2': 0.38383407830451083, 'dropout_rate_Layer_3': 0.22802815512333605, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0021442936020257875, 'l1_Layer_2': 0.005370829930499449, 'l1_Layer_3': 0.003361034614151051, 'n_units_Layer_1': 95, 'n_units_Layer_2': 80, 'n_units_Layer_3': 225}. Best is trial 164 with value: 3.753164926907204.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.30 | sMAPE for Validation Set is: 10.97% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.18 | sMAPE for Test Set is: 18.19% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:44:40,129]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:44:58,591]\u001b[0m Trial 193 finished with value: 3.815572070866768 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005970168004471942, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.362867024664082, 'dropout_rate_Layer_2': 0.3768889223801772, 'dropout_rate_Layer_3': 0.10329435974458215, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006077785438380895, 'l1_Layer_2': 0.00032805384526123283, 'l1_Layer_3': 5.274486208886823e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 130, 'n_units_Layer_3': 270}. Best is trial 164 with value: 3.753164926907204.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.82 | sMAPE for Validation Set is: 9.91% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.19 | sMAPE for Test Set is: 20.59% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:44:59,103]\u001b[0m Trial 194 finished with value: 4.370903329913621 and parameters: {'n_hidden': 4, 'learning_rate': 0.001342758116691645, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13819080407285014, 'dropout_rate_Layer_2': 0.16818561884883437, 'dropout_rate_Layer_3': 0.26413741797321133, 'dropout_rate_Layer_4': 0.3147636566756333, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003471680894172295, 'l1_Layer_2': 0.00018604064846043056, 'l1_Layer_3': 0.06859290815683332, 'l1_Layer_4': 6.93302281787891e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 145, 'n_units_Layer_3': 175, 'n_units_Layer_4': 50}. Best is trial 164 with value: 3.753164926907204.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.37 | sMAPE for Validation Set is: 11.17% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.14 | sMAPE for Test Set is: 17.11% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:45:08,565]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:45:11,852]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:45:15,041]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:45:17,716]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:45:19,178]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:45:21,773]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:45:26,848]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:45:27,370]\u001b[0m Trial 203 finished with value: 4.37018647465626 and parameters: {'n_hidden': 3, 'learning_rate': 0.015625753540053217, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2693116819660049, 'dropout_rate_Layer_2': 0.36354061176008223, 'dropout_rate_Layer_3': 0.22312221796213555, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0035739310034443098, 'l1_Layer_2': 0.0008147389084937157, 'l1_Layer_3': 0.003155970915223341, 'n_units_Layer_1': 75, 'n_units_Layer_2': 65, 'n_units_Layer_3': 225}. Best is trial 164 with value: 3.753164926907204.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.37 | sMAPE for Validation Set is: 11.09% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.47 | sMAPE for Test Set is: 19.01% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:46:10,430]\u001b[0m Trial 199 finished with value: 3.786993547951043 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005061437627148834, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38837095144265493, 'dropout_rate_Layer_2': 0.3794285247924106, 'dropout_rate_Layer_3': 0.10500892126736605, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0029954734613627165, 'l1_Layer_2': 0.0007212643694541531, 'l1_Layer_3': 3.295344731551303e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 130, 'n_units_Layer_3': 270}. Best is trial 164 with value: 3.753164926907204.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.79 | sMAPE for Validation Set is: 9.84% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.81 | sMAPE for Test Set is: 20.28% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:46:13,441]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:46:25,318]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:46:25,559]\u001b[0m Trial 209 finished with value: 3.724562206348228 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008009023627819691, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3924615899676505, 'dropout_rate_Layer_2': 0.3375457753082867, 'dropout_rate_Layer_3': 0.16699018694188456, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002454064595640707, 'l1_Layer_2': 0.0007719009350634274, 'l1_Layer_3': 0.00010370201333228026, 'n_units_Layer_1': 135, 'n_units_Layer_2': 155, 'n_units_Layer_3': 270}. Best is trial 209 with value: 3.724562206348228.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.72 | sMAPE for Validation Set is: 9.67% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.83 | sMAPE for Test Set is: 17.34% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:46:30,387]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:46:30,992]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:46:36,000]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:46:45,863]\u001b[0m Trial 212 finished with value: 3.711858091159018 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007965664700581585, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17595530528636624, 'dropout_rate_Layer_2': 0.38752987852581466, 'dropout_rate_Layer_3': 0.17272371845257428, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012519784815856361, 'l1_Layer_2': 0.0006791709992665858, 'l1_Layer_3': 5.178939457063808e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 135, 'n_units_Layer_3': 270}. Best is trial 212 with value: 3.711858091159018.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.71 | sMAPE for Validation Set is: 9.67% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 5.52 | sMAPE for Test Set is: 19.48% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:46:49,847]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:46:51,701]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:46:53,866]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:46:59,966]\u001b[0m Trial 219 finished with value: 4.360816693643396 and parameters: {'n_hidden': 3, 'learning_rate': 0.017657031531554946, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24544342074900893, 'dropout_rate_Layer_2': 0.3810661013783642, 'dropout_rate_Layer_3': 0.24285956176658657, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.004429451493217519, 'l1_Layer_2': 0.00044440468646032513, 'l1_Layer_3': 0.00864756230232848, 'n_units_Layer_1': 55, 'n_units_Layer_2': 90, 'n_units_Layer_3': 250}. Best is trial 212 with value: 3.711858091159018.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.36 | sMAPE for Validation Set is: 11.09% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.69 | sMAPE for Test Set is: 22.67% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:47:05,785]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:47:09,611]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:47:14,477]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:47:17,424]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:47:18,253]\u001b[0m Trial 223 finished with value: 4.398075647336367 and parameters: {'n_hidden': 3, 'learning_rate': 0.008772066274505658, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30083399616060535, 'dropout_rate_Layer_2': 0.3680196914801936, 'dropout_rate_Layer_3': 0.2629976870494095, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.002166395028271635, 'l1_Layer_2': 0.000457077209523361, 'l1_Layer_3': 0.0028065000200229156, 'n_units_Layer_1': 80, 'n_units_Layer_2': 90, 'n_units_Layer_3': 280}. Best is trial 212 with value: 3.711858091159018.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.40 | sMAPE for Validation Set is: 11.20% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.71 | sMAPE for Test Set is: 22.51% | rMAE for Test Set is: 1.01\n",
      "MAE for Validation Set is: 4.41 | sMAPE for Validation Set is: 11.24% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.87 | sMAPE for Test Set is: 22.95% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:47:18,359]\u001b[0m Trial 222 finished with value: 4.412974710295765 and parameters: {'n_hidden': 3, 'learning_rate': 0.009616091945679328, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3814994477418619, 'dropout_rate_Layer_2': 0.3442059480552717, 'dropout_rate_Layer_3': 0.24746879936063662, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.006040850758169701, 'l1_Layer_2': 0.0004473226607572809, 'l1_Layer_3': 0.003516221019846262, 'n_units_Layer_1': 115, 'n_units_Layer_2': 75, 'n_units_Layer_3': 260}. Best is trial 212 with value: 3.711858091159018.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:47:24,012]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:47:26,662]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:47:30,305]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:47:30,557]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:47:31,710]\u001b[0m Trial 216 finished with value: 3.834452257880064 and parameters: {'n_hidden': 4, 'learning_rate': 0.001955360762031296, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2628829224911154, 'dropout_rate_Layer_2': 0.3123816745637168, 'dropout_rate_Layer_3': 0.11171142036702385, 'dropout_rate_Layer_4': 0.12327184248889964, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00010041845551033803, 'l1_Layer_2': 0.0006955146428462345, 'l1_Layer_3': 0.00016756984699521245, 'l1_Layer_4': 0.00030166061021938764, 'n_units_Layer_1': 200, 'n_units_Layer_2': 205, 'n_units_Layer_3': 70, 'n_units_Layer_4': 180}. Best is trial 212 with value: 3.711858091159018.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.83 | sMAPE for Validation Set is: 9.95% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.38 | sMAPE for Test Set is: 18.17% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:47:33,273]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:47:39,493]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:47:41,771]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:47:45,649]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:47:48,760]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:47:52,862]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:47:55,298]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:47:58,798]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:48:02,280]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:48:05,460]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:48:09,392]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:48:12,964]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:48:18,828]\u001b[0m Trial 240 finished with value: 4.482342761393144 and parameters: {'n_hidden': 4, 'learning_rate': 0.002090431659459105, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2981896661717836, 'dropout_rate_Layer_2': 0.237044953201057, 'dropout_rate_Layer_3': 0.11853602262585371, 'dropout_rate_Layer_4': 0.031874149413974776, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 8.663912073627143e-05, 'l1_Layer_2': 0.00047643400557177603, 'l1_Layer_3': 0.00012425349845810374, 'l1_Layer_4': 0.0003531162135144732, 'n_units_Layer_1': 205, 'n_units_Layer_2': 175, 'n_units_Layer_3': 75, 'n_units_Layer_4': 190}. Best is trial 212 with value: 3.711858091159018.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.48 | sMAPE for Validation Set is: 11.41% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 9.77 | sMAPE for Test Set is: 30.26% | rMAE for Test Set is: 1.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:48:34,978]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:48:52,428]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:48:58,467]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:49:08,927]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:49:14,822]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:49:30,670]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:49:37,469]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:49:54,021]\u001b[0m Trial 255 finished with value: 4.301191228461665 and parameters: {'n_hidden': 3, 'learning_rate': 0.011478446844709696, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23136634360305025, 'dropout_rate_Layer_2': 0.3704036169219804, 'dropout_rate_Layer_3': 0.20561727551653802, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0067855519562522925, 'l1_Layer_2': 0.0010467050686926314, 'l1_Layer_3': 0.005826352926310454, 'n_units_Layer_1': 125, 'n_units_Layer_2': 120, 'n_units_Layer_3': 240}. Best is trial 212 with value: 3.711858091159018.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.30 | sMAPE for Validation Set is: 10.98% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.86 | sMAPE for Test Set is: 20.02% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:50:16,300]\u001b[0m Trial 256 finished with value: 4.310873436918916 and parameters: {'n_hidden': 3, 'learning_rate': 0.012025350276317253, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23273865556180842, 'dropout_rate_Layer_2': 0.3718215540311682, 'dropout_rate_Layer_3': 0.20347998056246952, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.010581387865301944, 'l1_Layer_2': 0.0010925913140660466, 'l1_Layer_3': 0.005651337275181133, 'n_units_Layer_1': 120, 'n_units_Layer_2': 75, 'n_units_Layer_3': 240}. Best is trial 212 with value: 3.711858091159018.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.31 | sMAPE for Validation Set is: 11.01% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.70 | sMAPE for Test Set is: 22.67% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:50:33,081]\u001b[0m Trial 257 finished with value: 4.321453016892048 and parameters: {'n_hidden': 3, 'learning_rate': 0.011451846586945856, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2262251837872206, 'dropout_rate_Layer_2': 0.37965050971470754, 'dropout_rate_Layer_3': 0.2029190338995863, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.006455190968151938, 'l1_Layer_2': 0.0011800951145724216, 'l1_Layer_3': 0.005700779377408767, 'n_units_Layer_1': 135, 'n_units_Layer_2': 75, 'n_units_Layer_3': 240}. Best is trial 212 with value: 3.711858091159018.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.32 | sMAPE for Validation Set is: 11.04% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.33 | sMAPE for Test Set is: 18.69% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:50:35,905]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:50:39,609]\u001b[0m Trial 249 finished with value: 3.740657778283515 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005136213316138371, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3879104795229707, 'dropout_rate_Layer_2': 0.3809906500893678, 'dropout_rate_Layer_3': 0.18573883086289117, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002534786757505818, 'l1_Layer_2': 0.0007710817296094946, 'l1_Layer_3': 4.916082266110899e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 190, 'n_units_Layer_3': 270}. Best is trial 212 with value: 3.711858091159018.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.74 | sMAPE for Validation Set is: 9.74% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.91 | sMAPE for Test Set is: 17.57% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:50:43,422]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:50:47,116]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:50:50,196]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:50:53,877]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:51:01,305]\u001b[0m Trial 259 finished with value: 4.29625237939522 and parameters: {'n_hidden': 3, 'learning_rate': 0.011852738246262132, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2325315451327018, 'dropout_rate_Layer_2': 0.3767794616550213, 'dropout_rate_Layer_3': 0.20454508139450797, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.009720140028888945, 'l1_Layer_2': 0.0011498438764892228, 'l1_Layer_3': 0.006596148285244673, 'n_units_Layer_1': 125, 'n_units_Layer_2': 70, 'n_units_Layer_3': 240}. Best is trial 212 with value: 3.711858091159018.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.30 | sMAPE for Validation Set is: 10.99% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.31 | sMAPE for Test Set is: 18.63% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:51:04,302]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:51:09,901]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:52:12,639]\u001b[0m Trial 258 finished with value: 3.777991363016587 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008574304084648253, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3957358807439471, 'dropout_rate_Layer_2': 0.38029033936492973, 'dropout_rate_Layer_3': 0.18837021552951852, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001263685286957474, 'l1_Layer_2': 0.0006894292076783022, 'l1_Layer_3': 4.435205606312191e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 185, 'n_units_Layer_3': 270}. Best is trial 212 with value: 3.711858091159018.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.78 | sMAPE for Validation Set is: 9.80% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.17 | sMAPE for Test Set is: 18.37% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:52:13,071]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:52:18,528]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:52:22,036]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:52:25,856]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:52:45,254]\u001b[0m Trial 264 finished with value: 3.7674506691092673 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007796588852202929, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3688500427618491, 'dropout_rate_Layer_2': 0.3278967158596991, 'dropout_rate_Layer_3': 0.1893817876229678, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013173687862306522, 'l1_Layer_2': 0.0005266676532473513, 'l1_Layer_3': 4.229864720794047e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 140, 'n_units_Layer_3': 280}. Best is trial 212 with value: 3.711858091159018.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.77 | sMAPE for Validation Set is: 9.73% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.18 | sMAPE for Test Set is: 18.42% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:52:59,527]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:53:11,974]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:53:12,366]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:53:18,778]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:53:19,493]\u001b[0m Trial 274 finished with value: 4.553054499679438 and parameters: {'n_hidden': 4, 'learning_rate': 0.00334138204788042, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3256898823759267, 'dropout_rate_Layer_2': 0.2761435961695158, 'dropout_rate_Layer_3': 0.030119011996086603, 'dropout_rate_Layer_4': 0.0029300833208698654, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 4.217447873461289e-05, 'l1_Layer_2': 2.8913082659573355e-05, 'l1_Layer_3': 0.001996986090081754, 'l1_Layer_4': 4.227239281514052e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 185, 'n_units_Layer_3': 150, 'n_units_Layer_4': 175}. Best is trial 212 with value: 3.711858091159018.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.55 | sMAPE for Validation Set is: 11.48% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 7.51 | sMAPE for Test Set is: 24.77% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:53:23,631]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:53:26,775]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:53:27,188]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:53:27,238]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:53:32,250]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:53:36,197]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:53:36,485]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:53:40,987]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:53:44,466]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:53:44,896]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:53:50,495]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:53:51,017]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:53:56,866]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:54:02,802]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:54:06,646]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:54:08,842]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:54:09,375]\u001b[0m Trial 289 finished with value: 4.249891823505778 and parameters: {'n_hidden': 3, 'learning_rate': 0.017122329013320243, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1988636660896243, 'dropout_rate_Layer_2': 0.3880569917156501, 'dropout_rate_Layer_3': 0.19063171387981218, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00408242178472178, 'l1_Layer_2': 0.0010554760277561577, 'l1_Layer_3': 0.013539965222929398, 'n_units_Layer_1': 235, 'n_units_Layer_2': 85, 'n_units_Layer_3': 250}. Best is trial 212 with value: 3.711858091159018.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.25 | sMAPE for Validation Set is: 10.86% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.25 | sMAPE for Test Set is: 18.34% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:54:11,073]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:54:24,641]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:54:25,168]\u001b[0m Trial 294 finished with value: 4.192347141306716 and parameters: {'n_hidden': 3, 'learning_rate': 0.016316997094331875, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18993370415578523, 'dropout_rate_Layer_2': 0.3931219661140607, 'dropout_rate_Layer_3': 0.17370052148222423, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0042379669795587875, 'l1_Layer_2': 0.0010255760142207392, 'l1_Layer_3': 0.014138698966790946, 'n_units_Layer_1': 235, 'n_units_Layer_2': 80, 'n_units_Layer_3': 250}. Best is trial 212 with value: 3.711858091159018.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.19 | sMAPE for Validation Set is: 10.74% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.57 | sMAPE for Test Set is: 19.45% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:54:30,553]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:54:34,618]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:54:49,380]\u001b[0m Trial 291 finished with value: 3.862918146810941 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007311646228722572, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36189717378173475, 'dropout_rate_Layer_2': 0.3999340089890703, 'dropout_rate_Layer_3': 0.17224049137704994, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004692728670444674, 'l1_Layer_2': 0.0013315243791459975, 'l1_Layer_3': 4.194194199338828e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 205, 'n_units_Layer_3': 270}. Best is trial 212 with value: 3.711858091159018.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.86 | sMAPE for Validation Set is: 9.98% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.67 | sMAPE for Test Set is: 16.68% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:54:52,236]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:54:57,409]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:55:03,743]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:55:07,597]\u001b[0m Trial 302 finished with value: 4.240366340651415 and parameters: {'n_hidden': 3, 'learning_rate': 0.014122946359645238, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16421322550853193, 'dropout_rate_Layer_2': 0.3777405742514244, 'dropout_rate_Layer_3': 0.16687481255564546, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0029467602943440917, 'l1_Layer_2': 0.0015619591981870223, 'l1_Layer_3': 0.012125175759476553, 'n_units_Layer_1': 225, 'n_units_Layer_2': 75, 'n_units_Layer_3': 260}. Best is trial 212 with value: 3.711858091159018.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.24 | sMAPE for Validation Set is: 10.84% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.96 | sMAPE for Test Set is: 17.41% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:55:11,455]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:55:16,315]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:55:18,123]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:55:20,771]\u001b[0m Trial 305 finished with value: 4.308624518397134 and parameters: {'n_hidden': 3, 'learning_rate': 0.013436123156093348, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16603224132458244, 'dropout_rate_Layer_2': 0.3866117390111664, 'dropout_rate_Layer_3': 0.16797727799688686, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0027295037370455473, 'l1_Layer_2': 0.0015470352998325633, 'l1_Layer_3': 0.012596516173615211, 'n_units_Layer_1': 225, 'n_units_Layer_2': 70, 'n_units_Layer_3': 250}. Best is trial 212 with value: 3.711858091159018.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.31 | sMAPE for Validation Set is: 11.00% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.30 | sMAPE for Test Set is: 18.60% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:55:22,954]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:55:27,775]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:55:28,018]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:55:32,825]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:55:32,869]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:55:37,777]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:55:38,331]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:55:41,779]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:55:43,547]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:55:44,159]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:55:49,691]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:55:52,585]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.62 | sMAPE for Validation Set is: 11.66% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 9.33 | sMAPE for Test Set is: 29.25% | rMAE for Test Set is: 1.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:55:53,947]\u001b[0m Trial 311 finished with value: 4.62449922248194 and parameters: {'n_hidden': 4, 'learning_rate': 0.002286084140195169, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29468483679223123, 'dropout_rate_Layer_2': 0.37184529126565635, 'dropout_rate_Layer_3': 0.09825371537505427, 'dropout_rate_Layer_4': 0.10371350700010531, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0004223860874953912, 'l1_Layer_2': 0.0030476591403051385, 'l1_Layer_3': 0.0006216817320866036, 'l1_Layer_4': 0.00027842452666935737, 'n_units_Layer_1': 265, 'n_units_Layer_2': 235, 'n_units_Layer_3': 50, 'n_units_Layer_4': 240}. Best is trial 212 with value: 3.711858091159018.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:55:55,401]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:55:55,621]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:56:01,360]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:56:01,548]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:56:07,816]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:56:10,629]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:56:11,001]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:56:15,794]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:56:18,384]\u001b[0m Trial 324 finished with value: 4.322906315433246 and parameters: {'n_hidden': 3, 'learning_rate': 0.014857653576344021, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23682590479610227, 'dropout_rate_Layer_2': 0.3832681735548838, 'dropout_rate_Layer_3': 0.21134023217353032, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00334958400447474, 'l1_Layer_2': 0.0006164649598857594, 'l1_Layer_3': 0.005352950321615642, 'n_units_Layer_1': 110, 'n_units_Layer_2': 90, 'n_units_Layer_3': 265}. Best is trial 212 with value: 3.711858091159018.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.32 | sMAPE for Validation Set is: 10.99% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.81 | sMAPE for Test Set is: 16.88% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:56:18,887]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:56:19,775]\u001b[0m Trial 321 finished with value: 4.3057396891752 and parameters: {'n_hidden': 3, 'learning_rate': 0.014911535302951806, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23822224720945667, 'dropout_rate_Layer_2': 0.38264441919909353, 'dropout_rate_Layer_3': 0.17142226990676393, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0029898047492185856, 'l1_Layer_2': 0.0006105544597316022, 'l1_Layer_3': 0.02058062030870565, 'n_units_Layer_1': 230, 'n_units_Layer_2': 85, 'n_units_Layer_3': 265}. Best is trial 212 with value: 3.711858091159018.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.31 | sMAPE for Validation Set is: 10.99% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.59 | sMAPE for Test Set is: 19.37% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:56:26,954]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:56:28,769]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:56:31,361]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:56:34,456]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:56:37,821]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:56:42,484]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:56:45,468]\u001b[0m Trial 334 finished with value: 4.317809055419829 and parameters: {'n_hidden': 3, 'learning_rate': 0.014887853173057323, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21711344501817514, 'dropout_rate_Layer_2': 0.04432724707923985, 'dropout_rate_Layer_3': 0.1971252424833352, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.002501251193919197, 'l1_Layer_2': 0.002712886070323916, 'l1_Layer_3': 0.006445908479037876, 'n_units_Layer_1': 250, 'n_units_Layer_2': 80, 'n_units_Layer_3': 250}. Best is trial 212 with value: 3.711858091159018.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.32 | sMAPE for Validation Set is: 11.04% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.78 | sMAPE for Test Set is: 16.75% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:56:47,475]\u001b[0m Trial 331 finished with value: 4.344425973941051 and parameters: {'n_hidden': 3, 'learning_rate': 0.016810756426562837, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12772995591775815, 'dropout_rate_Layer_2': 0.36522386362649095, 'dropout_rate_Layer_3': 0.22008959852586382, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0019613852806558965, 'l1_Layer_2': 0.00034709976958816096, 'l1_Layer_3': 0.00343086497959217, 'n_units_Layer_1': 230, 'n_units_Layer_2': 70, 'n_units_Layer_3': 270}. Best is trial 212 with value: 3.711858091159018.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.34 | sMAPE for Validation Set is: 11.02% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.00 | sMAPE for Test Set is: 17.27% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:56:55,459]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:57:01,453]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:57:02,018]\u001b[0m Trial 341 finished with value: 4.24091043345311 and parameters: {'n_hidden': 3, 'learning_rate': 0.014283095317714514, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12206796314789405, 'dropout_rate_Layer_2': 0.04210100701597647, 'dropout_rate_Layer_3': 0.20049413755877485, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0014683205222853692, 'l1_Layer_2': 0.002950704941134676, 'l1_Layer_3': 0.006605583900503208, 'n_units_Layer_1': 255, 'n_units_Layer_2': 65, 'n_units_Layer_3': 275}. Best is trial 212 with value: 3.711858091159018.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.24 | sMAPE for Validation Set is: 10.85% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.42 | sMAPE for Test Set is: 18.87% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:57:07,528]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:57:12,183]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:57:14,803]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:57:16,927]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:57:22,978]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:57:25,164]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:57:28,126]\u001b[0m Trial 340 finished with value: 4.734819552814051 and parameters: {'n_hidden': 4, 'learning_rate': 0.002320142657359156, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.146435364127986, 'dropout_rate_Layer_2': 0.12060571525758924, 'dropout_rate_Layer_3': 0.2874550825216074, 'dropout_rate_Layer_4': 0.20358728847514843, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0007750113043493256, 'l1_Layer_2': 0.00043271250656260407, 'l1_Layer_3': 0.03025904555956238, 'l1_Layer_4': 1.0191445230752808e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 160, 'n_units_Layer_3': 240, 'n_units_Layer_4': 125}. Best is trial 212 with value: 3.711858091159018.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.73 | sMAPE for Validation Set is: 11.89% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 8.48 | sMAPE for Test Set is: 27.04% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:57:29,799]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:57:32,234]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:57:32,800]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:57:34,221]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:57:37,405]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:57:40,792]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:57:46,091]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:57:46,273]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:57:51,472]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:57:56,532]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:58:00,190]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:58:03,911]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:58:07,218]\u001b[0m Trial 359 finished with value: 4.362326225728296 and parameters: {'n_hidden': 3, 'learning_rate': 0.014003232199916437, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24571611399693907, 'dropout_rate_Layer_2': 0.054509034744589235, 'dropout_rate_Layer_3': 0.22274728337386815, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.003089871868469592, 'l1_Layer_2': 0.00028712395309786823, 'l1_Layer_3': 0.0023290441907008234, 'n_units_Layer_1': 235, 'n_units_Layer_2': 80, 'n_units_Layer_3': 255}. Best is trial 212 with value: 3.711858091159018.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.36 | sMAPE for Validation Set is: 11.05% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.66 | sMAPE for Test Set is: 19.56% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:58:10,119]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:58:15,176]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:58:18,439]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:58:25,874]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:58:28,952]\u001b[0m Trial 354 finished with value: 3.770648778799083 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012036588566715616, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36629726099000726, 'dropout_rate_Layer_2': 0.3907151145526103, 'dropout_rate_Layer_3': 0.22651637323585017, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0022684455674013937, 'l1_Layer_2': 0.0008426236770645237, 'l1_Layer_3': 5.810147129205501e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 230, 'n_units_Layer_3': 285}. Best is trial 212 with value: 3.711858091159018.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.77 | sMAPE for Validation Set is: 9.80% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.37 | sMAPE for Test Set is: 18.87% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:58:32,273]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:58:34,975]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:58:35,619]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:58:44,286]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:58:50,361]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:58:50,915]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:58:55,070]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:58:58,667]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:59:05,840]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:59:06,268]\u001b[0m Trial 348 finished with value: 3.9418304106509887 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012548430693435232, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3660923918348999, 'dropout_rate_Layer_2': 0.38963774644582566, 'dropout_rate_Layer_3': 0.1965685301739677, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004912735907611537, 'l1_Layer_2': 0.000565450479042354, 'l1_Layer_3': 3.5779926809882066e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 170, 'n_units_Layer_3': 275}. Best is trial 212 with value: 3.711858091159018.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.94 | sMAPE for Validation Set is: 10.17% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.55 | sMAPE for Test Set is: 22.30% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:59:21,243]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:59:24,748]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:59:24,929]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:59:26,023]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:59:31,581]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:59:31,708]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:59:32,069]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:59:37,760]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:59:38,289]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:59:45,146]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:59:45,220]\u001b[0m Trial 381 finished with value: 4.1974306532612955 and parameters: {'n_hidden': 3, 'learning_rate': 0.012011055085488371, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13690247373245534, 'dropout_rate_Layer_2': 0.015814103645091983, 'dropout_rate_Layer_3': 0.18320178060448072, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0021290636843642775, 'l1_Layer_2': 0.0003955829295507691, 'l1_Layer_3': 0.020285536884458485, 'n_units_Layer_1': 235, 'n_units_Layer_2': 75, 'n_units_Layer_3': 265}. Best is trial 212 with value: 3.711858091159018.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.20 | sMAPE for Validation Set is: 10.75% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.16 | sMAPE for Test Set is: 18.11% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 00:59:46,069]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:59:50,971]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:59:52,969]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:59:53,092]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 00:59:57,807]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:00:01,330]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:00:01,623]\u001b[0m Trial 384 finished with value: 4.202267229579237 and parameters: {'n_hidden': 4, 'learning_rate': 0.0054986390979948055, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22664738671309376, 'dropout_rate_Layer_2': 0.26096625949423713, 'dropout_rate_Layer_3': 0.02262404707549041, 'dropout_rate_Layer_4': 0.0009289002274590064, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 4.25147286345061e-05, 'l1_Layer_2': 2.9921789799989393e-05, 'l1_Layer_3': 0.0003035776200754012, 'l1_Layer_4': 3.7624452135281815e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 170, 'n_units_Layer_3': 150, 'n_units_Layer_4': 160}. Best is trial 212 with value: 3.711858091159018.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.20 | sMAPE for Validation Set is: 10.80% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 8.91 | sMAPE for Test Set is: 27.99% | rMAE for Test Set is: 1.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:00:02,551]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:00:06,163]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:00:07,408]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:00:14,626]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:00:15,525]\u001b[0m Trial 393 finished with value: 4.53276387560967 and parameters: {'n_hidden': 4, 'learning_rate': 0.004957630034214642, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30937769434817997, 'dropout_rate_Layer_2': 0.2327943103956727, 'dropout_rate_Layer_3': 0.03828940163441012, 'dropout_rate_Layer_4': 0.014557583153277528, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 4.816801521432398e-05, 'l1_Layer_2': 1.2220421174149112e-05, 'l1_Layer_3': 0.0033323406084640236, 'l1_Layer_4': 3.734002284709515e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 170, 'n_units_Layer_3': 150, 'n_units_Layer_4': 160}. Best is trial 212 with value: 3.711858091159018.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.53 | sMAPE for Validation Set is: 11.44% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.98 | sMAPE for Test Set is: 23.43% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:00:20,222]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:00:20,575]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:00:21,421]\u001b[0m Trial 399 finished with value: 4.412853177912409 and parameters: {'n_hidden': 3, 'learning_rate': 0.016939559920990173, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1814993635698454, 'dropout_rate_Layer_2': 0.3943109944470721, 'dropout_rate_Layer_3': 0.2143236939698151, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.005518240555598896, 'l1_Layer_2': 0.002407140683762653, 'l1_Layer_3': 0.011715325206259768, 'n_units_Layer_1': 230, 'n_units_Layer_2': 80, 'n_units_Layer_3': 260}. Best is trial 212 with value: 3.711858091159018.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.41 | sMAPE for Validation Set is: 11.21% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.23 | sMAPE for Test Set is: 21.32% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:00:27,236]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:00:31,002]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:00:32,471]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:00:36,710]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:00:39,608]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:00:52,619]\u001b[0m Trial 407 finished with value: 4.311076951089075 and parameters: {'n_hidden': 4, 'learning_rate': 0.006750598208246981, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3042149028872486, 'dropout_rate_Layer_2': 0.19766085277192644, 'dropout_rate_Layer_3': 0.044612010729292814, 'dropout_rate_Layer_4': 0.0016717612014013074, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.06522215398575e-05, 'l1_Layer_2': 1.188603438950398e-05, 'l1_Layer_3': 0.00010078833771253437, 'l1_Layer_4': 3.1646908004961016e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 170, 'n_units_Layer_3': 185, 'n_units_Layer_4': 115}. Best is trial 212 with value: 3.711858091159018.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.31 | sMAPE for Validation Set is: 10.92% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.30 | sMAPE for Test Set is: 21.66% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:00:54,347]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:00:54,439]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:00:56,417]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:01:02,359]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:01:03,112]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:01:04,833]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:01:05,355]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:01:11,975]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:01:12,575]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:01:15,808]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:01:16,520]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:01:16,634]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:01:16,749]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:01:20,993]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:01:24,064]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:01:26,251]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:01:27,978]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:01:31,130]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:01:33,926]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:01:37,440]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:01:39,114]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:01:39,156]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:01:39,686]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:01:41,501]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:01:48,288]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:01:52,472]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:01:55,811]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:01:56,447]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:01:59,937]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:02:02,874]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:02:19,174]\u001b[0m Trial 439 finished with value: 4.382250959926478 and parameters: {'n_hidden': 3, 'learning_rate': 0.015766936801371784, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2338114387615257, 'dropout_rate_Layer_2': 0.364798877925825, 'dropout_rate_Layer_3': 0.17486352090377394, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.010490107785328846, 'l1_Layer_2': 0.0013249862111589586, 'l1_Layer_3': 0.004373888121484439, 'n_units_Layer_1': 100, 'n_units_Layer_2': 85, 'n_units_Layer_3': 245}. Best is trial 212 with value: 3.711858091159018.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.38 | sMAPE for Validation Set is: 11.15% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.15 | sMAPE for Test Set is: 18.00% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:02:25,950]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:02:26,039]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:02:29,253]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:02:30,862]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:02:31,876]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:02:37,693]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:02:42,624]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:02:45,550]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:02:53,442]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:02:55,160]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:02:57,105]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:02:59,104]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:03:01,307]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:03:04,777]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:03:06,577]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:03:08,714]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:03:10,713]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:03:22,564]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:03:25,532]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:03:25,815]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:03:33,463]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:03:37,606]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:03:44,030]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:03:48,153]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:03:51,382]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:04:12,425]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:04:15,389]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:04:18,461]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:04:24,406]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:04:26,992]\u001b[0m Trial 465 finished with value: 4.52675675873428 and parameters: {'n_hidden': 4, 'learning_rate': 0.0023072607734879787, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2580952935948663, 'dropout_rate_Layer_2': 0.14784875039195622, 'dropout_rate_Layer_3': 0.37943415669765, 'dropout_rate_Layer_4': 0.308894888733957, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.1551240156330764e-05, 'l1_Layer_2': 2.7737698363972668e-05, 'l1_Layer_3': 0.00041293756911932127, 'l1_Layer_4': 0.0001505067554497876, 'n_units_Layer_1': 115, 'n_units_Layer_2': 120, 'n_units_Layer_3': 220, 'n_units_Layer_4': 85}. Best is trial 212 with value: 3.711858091159018.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.53 | sMAPE for Validation Set is: 11.38% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 8.48 | sMAPE for Test Set is: 27.13% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:04:33,914]\u001b[0m Trial 447 finished with value: 4.2630407492763736 and parameters: {'n_hidden': 4, 'learning_rate': 0.004103248073946066, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0653218299783089, 'dropout_rate_Layer_2': 0.0011678857823390343, 'dropout_rate_Layer_3': 0.3663663855764371, 'dropout_rate_Layer_4': 0.1437337327830741, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 7.331053290638435e-05, 'l1_Layer_2': 0.00011300623711515162, 'l1_Layer_3': 0.005573114040441329, 'l1_Layer_4': 2.074742427520219e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 120, 'n_units_Layer_3': 160, 'n_units_Layer_4': 80}. Best is trial 212 with value: 3.711858091159018.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.26 | sMAPE for Validation Set is: 10.83% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 8.08 | sMAPE for Test Set is: 26.07% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:04:34,326]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:04:35,737]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:04:40,377]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:04:43,470]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:04:44,024]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:04:45,930]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:04:48,574]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:04:51,407]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:04:52,162]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:04:57,171]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:04:57,677]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:05:05,252]\u001b[0m Trial 478 finished with value: 4.54169160425552 and parameters: {'n_hidden': 4, 'learning_rate': 0.0056366490667283465, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30353195799305244, 'dropout_rate_Layer_2': 0.15742403886780215, 'dropout_rate_Layer_3': 0.022766025747973075, 'dropout_rate_Layer_4': 0.0001966778976324763, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 3.73479074103097e-05, 'l1_Layer_2': 1.0676444983542892e-05, 'l1_Layer_3': 0.000821158513132509, 'l1_Layer_4': 1.537970037119503e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 190, 'n_units_Layer_3': 160, 'n_units_Layer_4': 140}. Best is trial 212 with value: 3.711858091159018.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.54 | sMAPE for Validation Set is: 11.45% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 7.03 | sMAPE for Test Set is: 23.51% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:05:05,680]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:05:09,328]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:05:11,406]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:05:13,032]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:05:13,716]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:05:16,446]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:05:19,848]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:05:22,400]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:05:25,389]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:05:27,283]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:05:30,913]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:05:31,243]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:05:38,997]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:05:42,764]\u001b[0m Trial 492 finished with value: 4.375847129599786 and parameters: {'n_hidden': 3, 'learning_rate': 0.013149376201496792, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3807118195081972, 'dropout_rate_Layer_2': 0.041333852032607185, 'dropout_rate_Layer_3': 0.19524007666443088, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0042906347716619156, 'l1_Layer_2': 0.001866325684534672, 'l1_Layer_3': 0.008256839101365624, 'n_units_Layer_1': 260, 'n_units_Layer_2': 75, 'n_units_Layer_3': 250}. Best is trial 212 with value: 3.711858091159018.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.38 | sMAPE for Validation Set is: 11.12% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.56 | sMAPE for Test Set is: 22.02% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:05:43,447]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:05:45,903]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:05:47,906]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:05:50,923]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:05:53,355]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:05:56,468]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:05:56,892]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:05:57,853]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:06:01,563]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:06:03,134]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:06:07,105]\u001b[0m Trial 433 finished with value: 4.1767807080359445 and parameters: {'n_hidden': 4, 'learning_rate': 0.0034940143954662194, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1714614901308949, 'dropout_rate_Layer_2': 0.20757333885509782, 'dropout_rate_Layer_3': 0.22958725382528763, 'dropout_rate_Layer_4': 0.2155935180599593, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0006141659735377175, 'l1_Layer_2': 0.0006999270992508364, 'l1_Layer_3': 0.04522252632679411, 'l1_Layer_4': 0.0006784562153463375, 'n_units_Layer_1': 110, 'n_units_Layer_2': 130, 'n_units_Layer_3': 150, 'n_units_Layer_4': 130}. Best is trial 212 with value: 3.711858091159018.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.18 | sMAPE for Validation Set is: 10.61% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 7.36 | sMAPE for Test Set is: 24.22% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:06:08,558]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:06:12,197]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:06:12,584]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:06:12,810]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:06:20,387]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:06:20,637]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:06:25,405]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:06:26,659]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:06:29,033]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:06:46,247]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:07:07,988]\u001b[0m Trial 517 finished with value: 4.342286507364093 and parameters: {'n_hidden': 4, 'learning_rate': 0.0027441123753161605, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1838966352074929, 'dropout_rate_Layer_2': 0.20568259392518623, 'dropout_rate_Layer_3': 0.21895457708933674, 'dropout_rate_Layer_4': 0.18132665606046192, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00027714388246669606, 'l1_Layer_2': 0.0008434420129201415, 'l1_Layer_3': 0.09282779414801531, 'l1_Layer_4': 0.0009341676394167048, 'n_units_Layer_1': 140, 'n_units_Layer_2': 55, 'n_units_Layer_3': 200, 'n_units_Layer_4': 120}. Best is trial 212 with value: 3.711858091159018.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.34 | sMAPE for Validation Set is: 11.21% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.73 | sMAPE for Test Set is: 22.64% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:07:10,674]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:07:14,576]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:07:18,424]\u001b[0m Trial 513 finished with value: 3.7383823374396603 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007703537142365582, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15743441789122423, 'dropout_rate_Layer_2': 0.3569566006101662, 'dropout_rate_Layer_3': 0.2407379519734067, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00205257188398112, 'l1_Layer_2': 0.0006340387713483879, 'l1_Layer_3': 1.9594146408557206e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 250, 'n_units_Layer_3': 280}. Best is trial 212 with value: 3.711858091159018.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.74 | sMAPE for Validation Set is: 9.73% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 5.00 | sMAPE for Test Set is: 17.75% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:07:21,505]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:07:25,009]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:07:27,412]\u001b[0m Trial 518 finished with value: 4.51112614576821 and parameters: {'n_hidden': 4, 'learning_rate': 0.009756235611632616, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1838067413779806, 'dropout_rate_Layer_2': 0.20629587655523238, 'dropout_rate_Layer_3': 0.20687914432093973, 'dropout_rate_Layer_4': 0.26942293493909514, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0002267034414372935, 'l1_Layer_2': 0.0008123959886465044, 'l1_Layer_3': 0.09001929796957374, 'l1_Layer_4': 0.09818264730217424, 'n_units_Layer_1': 135, 'n_units_Layer_2': 160, 'n_units_Layer_3': 130, 'n_units_Layer_4': 170}. Best is trial 212 with value: 3.711858091159018.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.51 | sMAPE for Validation Set is: 11.51% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.27 | sMAPE for Test Set is: 18.28% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:07:29,814]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:07:31,309]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:07:31,498]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:07:32,431]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:07:34,339]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:07:40,182]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:07:43,220]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:07:50,521]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:07:55,468]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:07:59,395]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:08:03,456]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:08:07,419]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:08:10,923]\u001b[0m Trial 532 finished with value: 4.087696340868815 and parameters: {'n_hidden': 4, 'learning_rate': 0.0065961894012666, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36847883782958263, 'dropout_rate_Layer_2': 0.010524671475691527, 'dropout_rate_Layer_3': 9.16864819158758e-05, 'dropout_rate_Layer_4': 0.03703760232585353, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 8.671747210227705e-05, 'l1_Layer_2': 5.6530017255627634e-05, 'l1_Layer_3': 0.0003780718970750606, 'l1_Layer_4': 7.986962869480501e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 155, 'n_units_Layer_3': 220, 'n_units_Layer_4': 165}. Best is trial 212 with value: 3.711858091159018.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.09 | sMAPE for Validation Set is: 10.50% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 9.25 | sMAPE for Test Set is: 28.85% | rMAE for Test Set is: 1.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:08:14,800]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:08:17,822]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:08:20,971]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:08:21,007]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:08:21,401]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:08:28,372]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:08:28,813]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:08:31,340]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:08:35,665]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:08:35,717]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:08:45,857]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:08:47,797]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:08:49,537]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:08:55,531]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:09:00,466]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:09:12,029]\u001b[0m Trial 553 finished with value: 4.013306167694 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016627839022440463, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2841046495854757, 'dropout_rate_Layer_2': 0.10053660132419989, 'dropout_rate_Layer_3': 0.05260942246653096, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.010132639352330768, 'l1_Layer_2': 0.00019756213982747388, 'l1_Layer_3': 0.00014227161977044633, 'n_units_Layer_1': 205, 'n_units_Layer_2': 215, 'n_units_Layer_3': 265}. Best is trial 212 with value: 3.711858091159018.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.01 | sMAPE for Validation Set is: 10.32% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.49 | sMAPE for Test Set is: 15.99% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:09:24,368]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:09:25,114]\u001b[0m Trial 548 finished with value: 3.68891186572098 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008307858522594592, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16080059597987756, 'dropout_rate_Layer_2': 0.3246991394246353, 'dropout_rate_Layer_3': 0.27660634643386733, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0018831614273197425, 'l1_Layer_2': 0.0006324275549700992, 'l1_Layer_3': 1.7698052058734784e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 255, 'n_units_Layer_3': 280}. Best is trial 548 with value: 3.68891186572098.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.69 | sMAPE for Validation Set is: 9.62% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 5.35 | sMAPE for Test Set is: 18.81% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:09:32,996]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:09:37,227]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:09:39,870]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:09:43,729]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:09:46,983]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:09:50,478]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:09:51,026]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:09:55,509]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:10:05,058]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:10:08,201]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:10:11,251]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:10:13,660]\u001b[0m Trial 565 finished with value: 3.879094190575335 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020599773271862973, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27977505728112123, 'dropout_rate_Layer_2': 0.10806074978001355, 'dropout_rate_Layer_3': 0.052921357742613556, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00752661575693568, 'l1_Layer_2': 0.00038565437584699706, 'l1_Layer_3': 0.00014350503142036982, 'n_units_Layer_1': 215, 'n_units_Layer_2': 210, 'n_units_Layer_3': 265}. Best is trial 548 with value: 3.68891186572098.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.88 | sMAPE for Validation Set is: 10.03% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.72 | sMAPE for Test Set is: 16.43% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:10:15,156]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:10:17,492]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:10:19,994]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:10:21,600]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:10:24,652]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:10:28,385]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:10:31,910]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:10:35,435]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:10:38,542]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:10:42,461]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:10:45,464]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:10:54,013]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:10:58,588]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:10:59,017]\u001b[0m Trial 555 finished with value: 3.8176871544733175 and parameters: {'n_hidden': 4, 'learning_rate': 0.001066795336670353, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04416850341763501, 'dropout_rate_Layer_2': 0.06754267390401172, 'dropout_rate_Layer_3': 0.18202308697449354, 'dropout_rate_Layer_4': 0.37922890522911457, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0008992608382462011, 'l1_Layer_2': 0.00031414558864436323, 'l1_Layer_3': 1.782627982227366e-05, 'l1_Layer_4': 0.00010199969834380298, 'n_units_Layer_1': 165, 'n_units_Layer_2': 230, 'n_units_Layer_3': 185, 'n_units_Layer_4': 130}. Best is trial 548 with value: 3.68891186572098.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.82 | sMAPE for Validation Set is: 9.87% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.91 | sMAPE for Test Set is: 20.40% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:11:01,481]\u001b[0m Trial 566 finished with value: 4.100233650775818 and parameters: {'n_hidden': 4, 'learning_rate': 0.003407668691725956, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0685039128344806, 'dropout_rate_Layer_2': 0.1512737383085755, 'dropout_rate_Layer_3': 0.35808115018830633, 'dropout_rate_Layer_4': 0.1645658056153301, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0004856006468312283, 'l1_Layer_2': 0.00010206284208277242, 'l1_Layer_3': 0.003810538915395463, 'l1_Layer_4': 2.4692977360793436e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 130, 'n_units_Layer_3': 160, 'n_units_Layer_4': 75}. Best is trial 548 with value: 3.68891186572098.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.10 | sMAPE for Validation Set is: 10.50% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.97 | sMAPE for Test Set is: 23.42% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:11:06,314]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:11:09,381]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:11:14,234]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:11:19,383]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:11:36,426]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:11:39,531]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:11:42,991]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:11:53,030]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:11:59,668]\u001b[0m Trial 583 finished with value: 3.848333780055162 and parameters: {'n_hidden': 4, 'learning_rate': 0.003444448102007516, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0799717729888442, 'dropout_rate_Layer_2': 0.07137672155993548, 'dropout_rate_Layer_3': 0.1690842933260423, 'dropout_rate_Layer_4': 0.3759474775442052, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000569500570324435, 'l1_Layer_2': 0.0006795140735482189, 'l1_Layer_3': 1.9288986120214022e-05, 'l1_Layer_4': 0.0001073337416255317, 'n_units_Layer_1': 210, 'n_units_Layer_2': 270, 'n_units_Layer_3': 230, 'n_units_Layer_4': 110}. Best is trial 548 with value: 3.68891186572098.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.85 | sMAPE for Validation Set is: 9.95% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.88 | sMAPE for Test Set is: 22.88% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:12:03,145]\u001b[0m Trial 574 finished with value: 3.913514884703653 and parameters: {'n_hidden': 4, 'learning_rate': 0.0036369425993489674, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06587466885430304, 'dropout_rate_Layer_2': 0.06530307858461826, 'dropout_rate_Layer_3': 0.3600556973513873, 'dropout_rate_Layer_4': 0.22540094649366443, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0004930288436867428, 'l1_Layer_2': 0.00010461653143925145, 'l1_Layer_3': 0.004994908400156139, 'l1_Layer_4': 2.675412421230255e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 130, 'n_units_Layer_3': 165, 'n_units_Layer_4': 70}. Best is trial 548 with value: 3.68891186572098.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.91 | sMAPE for Validation Set is: 10.07% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.52 | sMAPE for Test Set is: 19.36% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:12:06,278]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:12:09,282]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:12:11,356]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:12:12,880]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:12:14,985]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:12:17,468]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:12:21,369]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:12:31,358]\u001b[0m Trial 594 finished with value: 3.6683742701341324 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011088717972726097, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23292884327909175, 'dropout_rate_Layer_2': 0.09659708330515188, 'dropout_rate_Layer_3': 0.05605495717584664, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007009680818563384, 'l1_Layer_2': 0.0001406495892660959, 'l1_Layer_3': 4.944310493090079e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 210, 'n_units_Layer_3': 285}. Best is trial 594 with value: 3.6683742701341324.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.67 | sMAPE for Validation Set is: 9.58% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.71 | sMAPE for Test Set is: 16.33% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:12:33,056]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:12:41,167]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:12:44,465]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:12:47,291]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:12:47,805]\u001b[0m Trial 600 finished with value: 4.428107359680162 and parameters: {'n_hidden': 4, 'learning_rate': 0.015166668733844776, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02773648198348834, 'dropout_rate_Layer_2': 0.02996520059803611, 'dropout_rate_Layer_3': 0.16815529056184822, 'dropout_rate_Layer_4': 0.3842542664769319, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0010378741102247972, 'l1_Layer_2': 3.5072974223490304e-05, 'l1_Layer_3': 1.8486435790626342e-05, 'l1_Layer_4': 0.0002466602766936714, 'n_units_Layer_1': 215, 'n_units_Layer_2': 270, 'n_units_Layer_3': 190, 'n_units_Layer_4': 65}. Best is trial 594 with value: 3.6683742701341324.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.43 | sMAPE for Validation Set is: 11.16% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.13 | sMAPE for Test Set is: 21.15% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:12:52,688]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:12:55,764]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:12:56,118]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:13:01,991]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:13:04,121]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:13:06,246]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:13:11,219]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:13:16,224]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:13:16,401]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:13:21,587]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:13:21,873]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:13:23,127]\u001b[0m Trial 602 finished with value: 3.712749178897957 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008186305305594281, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19779895693119523, 'dropout_rate_Layer_2': 0.1852681932969486, 'dropout_rate_Layer_3': 0.18274979734681113, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016192003016620854, 'l1_Layer_2': 0.0006610682308180998, 'l1_Layer_3': 4.3570634210318625e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 265, 'n_units_Layer_3': 270}. Best is trial 594 with value: 3.6683742701341324.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.71 | sMAPE for Validation Set is: 9.68% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 5.19 | sMAPE for Test Set is: 18.40% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:13:28,079]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:13:45,117]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:13:48,004]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:13:57,013]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:14:02,327]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:14:08,149]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:14:11,517]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:14:13,056]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:14:14,951]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:14:16,967]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:14:18,005]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:14:18,685]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:14:24,269]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:14:34,560]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:14:35,209]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:14:41,438]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:14:45,105]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:14:46,991]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:15:02,603]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:15:06,825]\u001b[0m Trial 631 finished with value: 3.658257734582411 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007301342601853516, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24026447361142186, 'dropout_rate_Layer_2': 0.06123411884112121, 'dropout_rate_Layer_3': 0.05728470691511106, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007955443432050669, 'l1_Layer_2': 0.0001327505288987008, 'l1_Layer_3': 1.4017103198564111e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 245, 'n_units_Layer_3': 290}. Best is trial 631 with value: 3.658257734582411.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.66 | sMAPE for Validation Set is: 9.57% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 5.01 | sMAPE for Test Set is: 17.38% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:15:10,318]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:15:10,716]\u001b[0m Trial 638 finished with value: 4.232575304286218 and parameters: {'n_hidden': 3, 'learning_rate': 0.01455514873625575, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15807708512144542, 'dropout_rate_Layer_2': 0.360163867338809, 'dropout_rate_Layer_3': 0.21811127208871234, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.003997319388122719, 'l1_Layer_2': 0.0018617493497627652, 'l1_Layer_3': 0.018814544276157204, 'n_units_Layer_1': 235, 'n_units_Layer_2': 70, 'n_units_Layer_3': 240}. Best is trial 631 with value: 3.658257734582411.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.23 | sMAPE for Validation Set is: 10.82% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.71 | sMAPE for Test Set is: 16.66% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:15:16,050]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:15:19,338]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:15:26,533]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:15:29,855]\u001b[0m Trial 634 finished with value: 3.933869072072472 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017380844633365687, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0838446963873744, 'dropout_rate_Layer_2': 0.15216071896894248, 'dropout_rate_Layer_3': 0.32518330423549474, 'dropout_rate_Layer_4': 0.3616582645757732, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0023101129965214014, 'l1_Layer_2': 0.0002274220722474739, 'l1_Layer_3': 0.00352313130534309, 'l1_Layer_4': 8.523200762748735e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 220, 'n_units_Layer_3': 215, 'n_units_Layer_4': 300}. Best is trial 631 with value: 3.658257734582411.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.93 | sMAPE for Validation Set is: 10.34% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.05 | sMAPE for Test Set is: 14.11% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:15:38,639]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:15:42,234]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:15:47,238]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:15:50,938]\u001b[0m Trial 646 finished with value: 4.33273874762338 and parameters: {'n_hidden': 3, 'learning_rate': 0.015423467357833062, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14661872637678194, 'dropout_rate_Layer_2': 0.34951950638374046, 'dropout_rate_Layer_3': 0.1708208754261483, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00409900227294291, 'l1_Layer_2': 0.0021214062008763344, 'l1_Layer_3': 0.003835496114255181, 'n_units_Layer_1': 230, 'n_units_Layer_2': 70, 'n_units_Layer_3': 240}. Best is trial 631 with value: 3.658257734582411.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.33 | sMAPE for Validation Set is: 11.05% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.91 | sMAPE for Test Set is: 20.19% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:15:54,076]\u001b[0m Trial 644 finished with value: 3.635439742555724 and parameters: {'n_hidden': 3, 'learning_rate': 0.000824141008865646, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2789427663227341, 'dropout_rate_Layer_2': 0.1034783406973893, 'dropout_rate_Layer_3': 0.06063742232208122, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007560991915610556, 'l1_Layer_2': 0.00012404373729574576, 'l1_Layer_3': 1.2899248619085442e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 245, 'n_units_Layer_3': 285}. Best is trial 644 with value: 3.635439742555724.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.64 | sMAPE for Validation Set is: 9.58% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.03 | sMAPE for Test Set is: 13.93% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:15:59,410]\u001b[0m Trial 641 finished with value: 3.8228506003228646 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017646431557146105, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12264798830572461, 'dropout_rate_Layer_2': 0.15294151637363101, 'dropout_rate_Layer_3': 0.37888101820115627, 'dropout_rate_Layer_4': 0.364719331932637, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002557760249863279, 'l1_Layer_2': 0.0002722492741113947, 'l1_Layer_3': 0.0006357404098471091, 'l1_Layer_4': 8.358575237130441e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 220, 'n_units_Layer_3': 210, 'n_units_Layer_4': 110}. Best is trial 644 with value: 3.635439742555724.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.82 | sMAPE for Validation Set is: 9.93% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.14 | sMAPE for Test Set is: 14.25% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:16:03,960]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:16:07,903]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.25 | sMAPE for Validation Set is: 10.86% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.44 | sMAPE for Test Set is: 18.86% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:16:10,237]\u001b[0m Trial 650 finished with value: 4.247264552684692 and parameters: {'n_hidden': 3, 'learning_rate': 0.016169340252342266, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14241916845279914, 'dropout_rate_Layer_2': 0.053509228178133195, 'dropout_rate_Layer_3': 0.17252908874450368, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0034729595758539906, 'l1_Layer_2': 0.0019508475069289163, 'l1_Layer_3': 0.006932965172426114, 'n_units_Layer_1': 225, 'n_units_Layer_2': 65, 'n_units_Layer_3': 240}. Best is trial 644 with value: 3.635439742555724.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:16:12,148]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:16:15,832]\u001b[0m Trial 651 finished with value: 4.383471851748461 and parameters: {'n_hidden': 3, 'learning_rate': 0.01644162401057199, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1422670803233011, 'dropout_rate_Layer_2': 0.07284206832102821, 'dropout_rate_Layer_3': 0.17346675641855674, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0034273887178387264, 'l1_Layer_2': 0.0025082884722469273, 'l1_Layer_3': 0.00707910953007691, 'n_units_Layer_1': 225, 'n_units_Layer_2': 65, 'n_units_Layer_3': 240}. Best is trial 644 with value: 3.635439742555724.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.38 | sMAPE for Validation Set is: 11.16% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.87 | sMAPE for Test Set is: 22.88% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:16:16,049]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:16:18,642]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:16:21,068]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:16:22,344]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:16:23,568]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:16:29,799]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:16:32,939]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:16:35,779]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:16:35,810]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:16:40,083]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:16:43,618]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:16:45,939]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:16:47,654]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:16:51,869]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:16:57,408]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:17:01,150]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:17:01,822]\u001b[0m Trial 666 finished with value: 4.292369010266423 and parameters: {'n_hidden': 3, 'learning_rate': 0.017176850146422867, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1383041228932737, 'dropout_rate_Layer_2': 0.04802585542628468, 'dropout_rate_Layer_3': 0.17970035459909056, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0039141720786809095, 'l1_Layer_2': 0.0037952942983181972, 'l1_Layer_3': 0.009367631286100136, 'n_units_Layer_1': 230, 'n_units_Layer_2': 60, 'n_units_Layer_3': 245}. Best is trial 644 with value: 3.635439742555724.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.29 | sMAPE for Validation Set is: 10.97% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.97 | sMAPE for Test Set is: 20.58% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:17:07,119]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:17:12,015]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:17:14,137]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:17:16,914]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:17:19,327]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:17:21,904]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:17:26,021]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:17:29,413]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:17:34,396]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:17:37,917]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:18:21,654]\u001b[0m Trial 669 finished with value: 3.7060855466582487 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011888377933700059, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.003729830284758394, 'dropout_rate_Layer_2': 0.10845748578730122, 'dropout_rate_Layer_3': 0.3279095503368572, 'dropout_rate_Layer_4': 0.3673886092566823, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002717337362060519, 'l1_Layer_2': 0.0019509051987579757, 'l1_Layer_3': 8.34503212072715e-05, 'l1_Layer_4': 0.00014757010985276325, 'n_units_Layer_1': 250, 'n_units_Layer_2': 255, 'n_units_Layer_3': 235, 'n_units_Layer_4': 275}. Best is trial 644 with value: 3.635439742555724.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.71 | sMAPE for Validation Set is: 9.73% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.40 | sMAPE for Test Set is: 15.14% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:18:28,184]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:18:29,085]\u001b[0m Trial 678 finished with value: 3.7456089278617166 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010242859428463917, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17451042928470437, 'dropout_rate_Layer_2': 0.35851348027268637, 'dropout_rate_Layer_3': 0.25247550971474203, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0022758571224873792, 'l1_Layer_2': 0.000627895530143876, 'l1_Layer_3': 1.5949495155856126e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 245, 'n_units_Layer_3': 280}. Best is trial 644 with value: 3.635439742555724.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 9.73% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.26 | sMAPE for Test Set is: 18.57% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:18:39,790]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:18:42,147]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:18:45,172]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:18:48,548]\u001b[0m Trial 679 finished with value: 3.8377969130290963 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011961814797175666, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13479347218253443, 'dropout_rate_Layer_2': 0.10729623384200801, 'dropout_rate_Layer_3': 0.33138279953603866, 'dropout_rate_Layer_4': 0.36145480172319144, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.019575689320924114, 'l1_Layer_2': 0.0005207448426267572, 'l1_Layer_3': 0.0004909796763321683, 'l1_Layer_4': 0.00015664308401602548, 'n_units_Layer_1': 255, 'n_units_Layer_2': 250, 'n_units_Layer_3': 235, 'n_units_Layer_4': 255}. Best is trial 644 with value: 3.635439742555724.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.84 | sMAPE for Validation Set is: 10.07% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 3.92 | sMAPE for Test Set is: 13.67% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:18:49,168]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:18:49,504]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:18:56,574]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:18:57,347]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:18:57,893]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:19:03,575]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:19:05,291]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:19:05,992]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:19:07,461]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:19:12,066]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:19:14,732]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:19:15,299]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.24 | sMAPE for Validation Set is: 10.87% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.16 | sMAPE for Test Set is: 18.07% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:19:19,419]\u001b[0m Trial 691 finished with value: 4.244885894865964 and parameters: {'n_hidden': 3, 'learning_rate': 0.015582935858971353, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12389494173099204, 'dropout_rate_Layer_2': 0.08331151110531454, 'dropout_rate_Layer_3': 0.19756379794549372, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0030890658708126275, 'l1_Layer_2': 0.003908466444821878, 'l1_Layer_3': 0.004147619235254696, 'n_units_Layer_1': 265, 'n_units_Layer_2': 70, 'n_units_Layer_3': 240}. Best is trial 644 with value: 3.635439742555724.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:19:22,939]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:19:26,189]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:19:26,613]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:19:26,678]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:19:35,144]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:19:35,647]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:19:36,150]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:19:40,454]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:19:40,548]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:19:42,593]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:19:43,099]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:19:52,312]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:19:52,561]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:19:53,026]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:19:59,729]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:20:00,052]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:20:04,137]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:20:05,887]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:20:06,769]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:20:08,186]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:20:13,142]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:20:16,602]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:20:17,039]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:20:22,880]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:20:25,712]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:20:27,733]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:20:28,321]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:20:31,962]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:20:32,599]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:20:37,861]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:20:40,349]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:20:40,704]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:20:44,990]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:20:45,465]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:20:50,806]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:20:51,254]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:20:55,024]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:20:57,326]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:21:00,510]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:21:00,900]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:21:06,586]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:21:06,869]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:21:11,575]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:21:23,941]\u001b[0m Trial 726 finished with value: 3.7392184167600875 and parameters: {'n_hidden': 3, 'learning_rate': 0.001055023681389854, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18197171667996012, 'dropout_rate_Layer_2': 0.3596721592710972, 'dropout_rate_Layer_3': 0.2507529461989423, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0031822342454717375, 'l1_Layer_2': 4.6803644560456426e-05, 'l1_Layer_3': 1.829549506775863e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 235, 'n_units_Layer_3': 280}. Best is trial 644 with value: 3.635439742555724.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.74 | sMAPE for Validation Set is: 9.73% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 6.01 | sMAPE for Test Set is: 20.77% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:21:27,030]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:21:29,533]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:21:34,037]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:21:34,178]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:21:39,063]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:21:40,149]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:21:40,196]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:21:41,126]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:21:41,993]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:21:49,772]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:21:49,847]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:21:56,279]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:21:58,054]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:22:00,702]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:22:16,883]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.77 | sMAPE for Validation Set is: 9.83% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.52 | sMAPE for Test Set is: 19.08% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:22:18,927]\u001b[0m Trial 760 finished with value: 3.7659843220524287 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016284922669139693, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2677446473064109, 'dropout_rate_Layer_2': 0.029010435810830237, 'dropout_rate_Layer_3': 0.014856949125693155, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005145175938104018, 'l1_Layer_2': 0.00021179790381930266, 'l1_Layer_3': 0.0002525999629393991, 'n_units_Layer_1': 170, 'n_units_Layer_2': 245, 'n_units_Layer_3': 265}. Best is trial 644 with value: 3.635439742555724.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:22:19,601]\u001b[0m Trial 762 finished with value: 3.755719282498351 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015253692099086579, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26247277368576893, 'dropout_rate_Layer_2': 0.02294084818994731, 'dropout_rate_Layer_3': 0.015330431747713376, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005465223697188123, 'l1_Layer_2': 0.00010865745469121808, 'l1_Layer_3': 6.677908980811226e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 230, 'n_units_Layer_3': 260}. Best is trial 644 with value: 3.635439742555724.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.76 | sMAPE for Validation Set is: 9.81% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.61 | sMAPE for Test Set is: 19.28% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:22:20,380]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:22:26,732]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:22:30,218]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:22:34,268]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:22:37,976]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:22:39,826]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:22:45,040]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:22:45,432]\u001b[0m Trial 761 finished with value: 3.7574078068964085 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014003940124079654, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1323223975564444, 'dropout_rate_Layer_2': 0.13851139236945192, 'dropout_rate_Layer_3': 0.19097911157127817, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005564527632627705, 'l1_Layer_2': 1.9005355771740374e-05, 'l1_Layer_3': 1.5482931518972976e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 200, 'n_units_Layer_3': 270}. Best is trial 644 with value: 3.635439742555724.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.76 | sMAPE for Validation Set is: 9.71% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.99 | sMAPE for Test Set is: 17.76% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:22:45,665]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:22:52,583]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:22:56,120]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:22:58,841]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:23:02,910]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:23:09,628]\u001b[0m Trial 773 finished with value: 3.7776689518585775 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016444251249879986, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2625496165022588, 'dropout_rate_Layer_2': 0.030303836128608368, 'dropout_rate_Layer_3': 0.012740189995491211, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005247786916272128, 'l1_Layer_2': 0.00011994887976000903, 'l1_Layer_3': 6.21355287975015e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 255, 'n_units_Layer_3': 260}. Best is trial 644 with value: 3.635439742555724.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.78 | sMAPE for Validation Set is: 9.85% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.86 | sMAPE for Test Set is: 16.75% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:23:13,023]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:23:17,024]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:23:17,694]\u001b[0m Trial 769 finished with value: 3.7100683148746385 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010665871032431626, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1492005038516767, 'dropout_rate_Layer_2': 0.11492584778435821, 'dropout_rate_Layer_3': 0.25750021379299226, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004617117526854474, 'l1_Layer_2': 8.977298424724848e-05, 'l1_Layer_3': 2.1514715016158983e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 235, 'n_units_Layer_3': 280}. Best is trial 644 with value: 3.635439742555724.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.71 | sMAPE for Validation Set is: 9.66% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 5.39 | sMAPE for Test Set is: 18.98% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:23:17,806]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:23:22,697]\u001b[0m Trial 776 finished with value: 3.771104724131927 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016623437275473097, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26428143094766143, 'dropout_rate_Layer_2': 0.033137755703699215, 'dropout_rate_Layer_3': 0.012210033952108335, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005111196951947523, 'l1_Layer_2': 0.00010705711543261795, 'l1_Layer_3': 5.5687721098864476e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 240, 'n_units_Layer_3': 260}. Best is trial 644 with value: 3.635439742555724.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.77 | sMAPE for Validation Set is: 9.78% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.24 | sMAPE for Test Set is: 20.92% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:23:23,119]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:23:29,630]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:23:29,801]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:23:36,424]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:23:41,858]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:23:42,065]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:23:46,998]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:23:53,574]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:23:56,932]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:24:00,371]\u001b[0m Trial 783 finished with value: 3.776345967559813 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019398322604121286, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08565474969577515, 'dropout_rate_Layer_2': 0.12705862526548575, 'dropout_rate_Layer_3': 0.3269538666374201, 'dropout_rate_Layer_4': 0.36774420312402795, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.011676009171034242, 'l1_Layer_2': 0.0012076034267477736, 'l1_Layer_3': 7.500132776876347e-05, 'l1_Layer_4': 7.492295442864895e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 220, 'n_units_Layer_3': 225, 'n_units_Layer_4': 295}. Best is trial 644 with value: 3.635439742555724.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.78 | sMAPE for Validation Set is: 9.94% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 3.99 | sMAPE for Test Set is: 13.95% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:24:05,387]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:24:08,891]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:24:25,208]\u001b[0m Trial 794 finished with value: 3.716795003582868 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015561882228509309, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2670566099096625, 'dropout_rate_Layer_2': 0.02568253440191287, 'dropout_rate_Layer_3': 0.01502387519838344, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004863165631223009, 'l1_Layer_2': 0.00010473825353359962, 'l1_Layer_3': 6.130571699295654e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 255, 'n_units_Layer_3': 260}. Best is trial 644 with value: 3.635439742555724.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.72 | sMAPE for Validation Set is: 9.70% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 5.80 | sMAPE for Test Set is: 19.62% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:24:29,809]\u001b[0m Trial 782 finished with value: 3.689800593814981 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019171502990765043, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08442286168639752, 'dropout_rate_Layer_2': 0.11593842683658516, 'dropout_rate_Layer_3': 0.3220211525321548, 'dropout_rate_Layer_4': 0.3658419657917586, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.005619294763692765, 'l1_Layer_2': 0.0011181669508680435, 'l1_Layer_3': 2.6937358487575416e-05, 'l1_Layer_4': 7.233243916250246e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 220, 'n_units_Layer_3': 225, 'n_units_Layer_4': 300}. Best is trial 644 with value: 3.635439742555724.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.69 | sMAPE for Validation Set is: 9.66% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 3.98 | sMAPE for Test Set is: 14.47% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:24:31,958]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:24:34,023]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:24:53,865]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:25:12,122]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:25:17,594]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:25:21,475]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:25:24,795]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:26:00,034]\u001b[0m Trial 799 finished with value: 3.736705558102169 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009430089767299064, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14679962443841868, 'dropout_rate_Layer_2': 0.11936507794522482, 'dropout_rate_Layer_3': 0.30072309377319645, 'dropout_rate_Layer_4': 0.3991159026449384, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.005427918399987052, 'l1_Layer_2': 0.0011451386946774611, 'l1_Layer_3': 6.205666889326566e-05, 'l1_Layer_4': 6.089865213672733e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 200, 'n_units_Layer_3': 225, 'n_units_Layer_4': 285}. Best is trial 644 with value: 3.635439742555724.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.74 | sMAPE for Validation Set is: 9.83% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 3.81 | sMAPE for Test Set is: 13.23% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:26:03,556]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:26:07,572]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:26:10,506]\u001b[0m Trial 796 finished with value: 3.700025559392666 and parameters: {'n_hidden': 4, 'learning_rate': 0.002100564788591977, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05898690267404903, 'dropout_rate_Layer_2': 0.12433437164458327, 'dropout_rate_Layer_3': 0.3274055620865183, 'dropout_rate_Layer_4': 0.39532409161485776, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.005241273422024593, 'l1_Layer_2': 0.0011726942008086912, 'l1_Layer_3': 8.170982525924161e-05, 'l1_Layer_4': 6.3215398086334e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 200, 'n_units_Layer_3': 230, 'n_units_Layer_4': 285}. Best is trial 644 with value: 3.635439742555724.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.70 | sMAPE for Validation Set is: 9.74% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.33 | sMAPE for Test Set is: 15.04% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:26:11,858]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:26:12,594]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:26:13,617]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:26:18,639]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:26:19,027]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:26:19,794]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:26:26,116]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:26:26,160]\u001b[0m Trial 791 finished with value: 3.668811247702584 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019655248796311324, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014521589734285552, 'dropout_rate_Layer_2': 0.12752642325644536, 'dropout_rate_Layer_3': 0.3328500202113637, 'dropout_rate_Layer_4': 0.3661164864129283, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.005104712407335269, 'l1_Layer_2': 0.0011958118957812523, 'l1_Layer_3': 2.542819975249854e-05, 'l1_Layer_4': 7.018645030507213e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 225, 'n_units_Layer_3': 225, 'n_units_Layer_4': 300}. Best is trial 644 with value: 3.635439742555724.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.67 | sMAPE for Validation Set is: 9.66% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 3.83 | sMAPE for Test Set is: 13.41% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:26:31,410]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:26:31,875]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:26:32,091]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:26:32,133]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:26:39,429]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:26:41,339]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:26:43,847]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:26:45,086]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:26:48,145]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:26:51,648]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:26:51,903]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:26:59,386]\u001b[0m Trial 821 finished with value: 3.729207242099045 and parameters: {'n_hidden': 3, 'learning_rate': 0.001516369863704886, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2655114747451813, 'dropout_rate_Layer_2': 0.03273489335778321, 'dropout_rate_Layer_3': 0.02821703633468922, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0048474460535795185, 'l1_Layer_2': 0.00011397097548930124, 'l1_Layer_3': 6.126621817937907e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 255, 'n_units_Layer_3': 250}. Best is trial 644 with value: 3.635439742555724.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.73 | sMAPE for Validation Set is: 9.71% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 5.07 | sMAPE for Test Set is: 17.17% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:27:02,701]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:27:02,866]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:27:08,734]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:27:09,828]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:27:10,236]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:27:11,195]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:27:16,542]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:27:18,433]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:27:19,421]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:27:23,186]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:27:26,613]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:27:31,456]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:27:39,780]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:27:43,481]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:27:47,105]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:27:50,245]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:27:51,032]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:27:55,211]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:27:55,983]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:28:02,044]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:28:02,770]\u001b[0m Trial 841 finished with value: 3.7391509249734263 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015513070655874856, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2609774862244779, 'dropout_rate_Layer_2': 0.03217072741095176, 'dropout_rate_Layer_3': 0.027993875430816974, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0038255791188260284, 'l1_Layer_2': 9.266696054565583e-05, 'l1_Layer_3': 2.5852661184813083e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 245, 'n_units_Layer_3': 245}. Best is trial 644 with value: 3.635439742555724.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.74 | sMAPE for Validation Set is: 9.71% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 5.74 | sMAPE for Test Set is: 19.20% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:28:07,559]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:28:09,609]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:28:13,769]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:28:14,245]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:28:20,496]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:28:20,956]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:28:25,761]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:28:26,214]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:28:30,451]\u001b[0m Trial 851 finished with value: 4.326319393037196 and parameters: {'n_hidden': 3, 'learning_rate': 0.011909383472966014, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16341673843826224, 'dropout_rate_Layer_2': 0.3886414858180088, 'dropout_rate_Layer_3': 0.2176883977966105, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.003942007274426424, 'l1_Layer_2': 0.0027938721978240633, 'l1_Layer_3': 0.004451836630952772, 'n_units_Layer_1': 210, 'n_units_Layer_2': 65, 'n_units_Layer_3': 240}. Best is trial 644 with value: 3.635439742555724.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.33 | sMAPE for Validation Set is: 11.03% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.95 | sMAPE for Test Set is: 20.49% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:28:31,061]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:28:31,474]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:28:38,581]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:28:38,725]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:28:42,992]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:28:44,420]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:28:45,825]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:28:47,205]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.62 | sMAPE for Validation Set is: 9.41% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.04 | sMAPE for Test Set is: 13.97% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:28:53,215]\u001b[0m Trial 832 finished with value: 3.6244523769499146 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009401750178445422, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01397190570350805, 'dropout_rate_Layer_2': 0.13424212022889428, 'dropout_rate_Layer_3': 0.29968734517799284, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00471523624617893, 'l1_Layer_2': 0.003156013563606048, 'l1_Layer_3': 0.00012870991620786057, 'n_units_Layer_1': 275, 'n_units_Layer_2': 205, 'n_units_Layer_3': 255}. Best is trial 832 with value: 3.6244523769499146.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:28:54,377]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:28:56,334]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:29:01,212]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:29:06,472]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:29:10,295]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:29:15,085]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:29:16,698]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:29:19,247]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:29:22,477]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:29:24,072]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:29:29,374]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:29:33,410]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:29:43,960]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:29:44,843]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:29:48,974]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:29:49,578]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:29:49,811]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:29:49,895]\u001b[0m Trial 867 finished with value: 3.5990566017339964 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010527824561702031, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009556824361327113, 'dropout_rate_Layer_2': 0.18580316575113562, 'dropout_rate_Layer_3': 0.3010371569410666, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004949763261500157, 'l1_Layer_2': 0.0026052766895534995, 'l1_Layer_3': 0.00012305665606372849, 'n_units_Layer_1': 280, 'n_units_Layer_2': 205, 'n_units_Layer_3': 255}. Best is trial 867 with value: 3.5990566017339964.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.60 | sMAPE for Validation Set is: 9.42% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 4.24 | sMAPE for Test Set is: 14.74% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:29:56,342]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:29:58,114]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:30:01,845]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:30:04,321]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:30:05,124]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:30:06,096]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:30:15,218]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:30:20,997]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:30:26,146]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:30:32,533]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:30:33,315]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:30:38,875]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:30:41,354]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:30:42,200]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:30:46,092]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:30:46,627]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:30:50,985]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:30:53,154]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:30:53,619]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:30:55,617]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:31:01,498]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:31:02,356]\u001b[0m Trial 893 finished with value: 3.7797276950726073 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011061445536525783, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12260163490949484, 'dropout_rate_Layer_2': 0.3790532304930178, 'dropout_rate_Layer_3': 0.25494235926225445, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003394262677661567, 'l1_Layer_2': 6.377336990942998e-05, 'l1_Layer_3': 1.6548787976401673e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 150, 'n_units_Layer_3': 290}. Best is trial 867 with value: 3.5990566017339964.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.78 | sMAPE for Validation Set is: 9.80% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.82 | sMAPE for Test Set is: 17.16% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:31:05,323]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:31:07,243]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:31:09,248]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:31:13,112]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:31:15,870]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:31:19,057]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:31:27,625]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:31:30,730]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:31:31,343]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:31:36,011]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:31:39,325]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:31:42,775]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:31:44,510]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:31:48,012]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:31:51,959]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:31:52,167]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:31:58,564]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:32:02,468]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:32:07,764]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:32:11,192]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:32:15,385]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:32:17,961]\u001b[0m Trial 904 finished with value: 3.68972506201689 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009829800317885272, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1614653603181268, 'dropout_rate_Layer_2': 0.33657191309811574, 'dropout_rate_Layer_3': 0.23244822954341804, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002674566780844148, 'l1_Layer_2': 0.0005938903267391298, 'l1_Layer_3': 1.2953193086028516e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 250, 'n_units_Layer_3': 280}. Best is trial 867 with value: 3.5990566017339964.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.69 | sMAPE for Validation Set is: 9.63% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 5.55 | sMAPE for Test Set is: 19.39% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:32:19,943]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:32:24,602]\u001b[0m Trial 912 finished with value: 3.634232976416914 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023683354917408937, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03521728341192326, 'dropout_rate_Layer_2': 0.1620422838393747, 'dropout_rate_Layer_3': 0.3016526432036927, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006913384374424941, 'l1_Layer_2': 0.0015940082977822826, 'l1_Layer_3': 0.00016440287049184087, 'n_units_Layer_1': 270, 'n_units_Layer_2': 215, 'n_units_Layer_3': 275}. Best is trial 867 with value: 3.5990566017339964.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:32:24,700]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.63 | sMAPE for Validation Set is: 9.51% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 3.78 | sMAPE for Test Set is: 13.32% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:32:25,144]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:32:32,493]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:32:36,181]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:32:41,061]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:32:44,974]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:32:48,339]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:32:56,130]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:32:59,887]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:33:03,962]\u001b[0m Trial 924 finished with value: 3.573744779479321 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013279649759818397, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.032446144921526934, 'dropout_rate_Layer_2': 0.11835096899001613, 'dropout_rate_Layer_3': 0.3211784301666132, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004213038169995258, 'l1_Layer_2': 0.0023320924667298306, 'l1_Layer_3': 4.0141315174203665e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 215, 'n_units_Layer_3': 250}. Best is trial 924 with value: 3.573744779479321.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.57 | sMAPE for Validation Set is: 9.37% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 3.92 | sMAPE for Test Set is: 13.71% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:33:04,428]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:33:07,303]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.76 | sMAPE for Validation Set is: 9.78% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.09 | sMAPE for Test Set is: 20.53% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:33:08,908]\u001b[0m Trial 934 finished with value: 3.7646942298816346 and parameters: {'n_hidden': 3, 'learning_rate': 0.002504751104907914, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2927797916234963, 'dropout_rate_Layer_2': 0.0005002431469342816, 'dropout_rate_Layer_3': 0.037490960395553684, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006498500741938889, 'l1_Layer_2': 0.0001522354724921867, 'l1_Layer_3': 1.9041087486048475e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 240, 'n_units_Layer_3': 285}. Best is trial 924 with value: 3.573744779479321.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:33:10,916]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:33:15,845]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:33:16,431]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:33:21,537]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:33:21,876]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:33:22,240]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:33:33,687]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:33:34,431]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:33:39,770]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:33:44,091]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:33:46,888]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:33:50,510]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:33:50,906]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:33:51,391]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:33:57,865]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:33:58,293]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:34:03,717]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:34:07,158]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:34:09,359]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:34:12,215]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:34:17,881]\u001b[0m Trial 942 finished with value: 3.6091979161593053 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023403232692253205, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.030382331831287926, 'dropout_rate_Layer_2': 0.16665828994462828, 'dropout_rate_Layer_3': 0.313417811236375, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006494711040430847, 'l1_Layer_2': 0.0041566814079784615, 'l1_Layer_3': 0.00018965116490451966, 'n_units_Layer_1': 270, 'n_units_Layer_2': 210, 'n_units_Layer_3': 290}. Best is trial 924 with value: 3.573744779479321.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.61 | sMAPE for Validation Set is: 9.46% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 3.84 | sMAPE for Test Set is: 13.34% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:34:21,396]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:34:25,913]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:34:33,445]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:34:47,668]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:34:57,406]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:34:59,460]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:35:03,449]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:35:06,147]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:35:09,318]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:35:09,749]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:35:14,925]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:35:15,268]\u001b[0m Trial 965 finished with value: 3.639035326185701 and parameters: {'n_hidden': 3, 'learning_rate': 0.001458629618943441, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03111158055675519, 'dropout_rate_Layer_2': 0.1626599429742372, 'dropout_rate_Layer_3': 0.28428728485962074, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006536588614414157, 'l1_Layer_2': 0.0037999625747835134, 'l1_Layer_3': 0.00017601867440829313, 'n_units_Layer_1': 270, 'n_units_Layer_2': 210, 'n_units_Layer_3': 300}. Best is trial 924 with value: 3.573744779479321.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.64 | sMAPE for Validation Set is: 9.64% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 3.83 | sMAPE for Test Set is: 13.30% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:35:16,293]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:35:20,054]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:35:24,797]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:35:25,445]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:35:25,924]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:35:31,769]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:35:32,460]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:35:33,378]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:35:40,375]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:35:40,846]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:35:41,162]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:35:46,485]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:35:49,540]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:35:50,124]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:35:51,701]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:36:00,695]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:36:03,057]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:36:06,136]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:36:08,876]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:36:13,399]\u001b[0m Trial 992 finished with value: 4.281095225069554 and parameters: {'n_hidden': 3, 'learning_rate': 0.0163325719652755, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2373393900599975, 'dropout_rate_Layer_2': 0.38135982362564885, 'dropout_rate_Layer_3': 0.1787700322510727, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.004459282101089887, 'l1_Layer_2': 0.001697625620093535, 'l1_Layer_3': 0.005681612252571408, 'n_units_Layer_1': 220, 'n_units_Layer_2': 70, 'n_units_Layer_3': 265}. Best is trial 924 with value: 3.573744779479321.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.28 | sMAPE for Validation Set is: 10.94% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.99 | sMAPE for Test Set is: 20.40% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:36:13,659]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:36:20,869]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:36:20,983]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:36:21,570]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:36:28,920]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:36:33,174]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:36:34,035]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:36:34,291]\u001b[0m Trial 985 finished with value: 3.6581240387485683 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007896997747946405, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25847170561152655, 'dropout_rate_Layer_2': 0.056321925403862605, 'dropout_rate_Layer_3': 0.04037176526144314, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004364157638610321, 'l1_Layer_2': 0.00010894000413653052, 'l1_Layer_3': 2.2362784891529897e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 235, 'n_units_Layer_3': 255}. Best is trial 924 with value: 3.573744779479321.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.66 | sMAPE for Validation Set is: 9.52% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 5.28 | sMAPE for Test Set is: 17.91% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:36:37,454]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:36:39,203]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:36:47,142]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:36:48,384]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:36:53,771]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:36:54,568]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:36:55,928]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:37:02,559]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:37:05,462]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:37:09,196]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:37:14,146]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:37:14,291]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:37:16,455]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:37:22,810]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:37:23,601]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:37:24,080]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:37:24,610]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:37:33,935]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:37:34,772]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:37:34,792]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:37:42,855]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:37:43,036]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:37:46,756]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:37:50,217]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:37:51,256]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:37:52,104]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:37:57,488]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:38:00,425]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:38:01,924]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:38:05,881]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:38:09,652]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:38:12,810]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:38:13,307]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:38:20,495]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:38:24,379]\u001b[0m Trial 1023 finished with value: 3.6080241350559916 and parameters: {'n_hidden': 3, 'learning_rate': 0.000533813209923165, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2625462932853723, 'dropout_rate_Layer_2': 0.059096112836137256, 'dropout_rate_Layer_3': 0.030321073720175923, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0045352074860078575, 'l1_Layer_2': 3.908409039694917e-05, 'l1_Layer_3': 2.1984674002522947e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 245, 'n_units_Layer_3': 265}. Best is trial 924 with value: 3.573744779479321.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.61 | sMAPE for Validation Set is: 9.46% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.86 | sMAPE for Test Set is: 16.45% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:38:25,058]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:38:25,597]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:38:29,465]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:38:35,621]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:38:37,244]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:38:40,175]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:38:43,739]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:38:47,425]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:38:55,704]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:38:59,140]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:39:02,501]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:39:06,180]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:39:06,683]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:39:11,093]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:39:11,561]\u001b[0m Trial 1032 finished with value: 3.63244659427491 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022739808962224505, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05615322192313174, 'dropout_rate_Layer_2': 0.1361388987199708, 'dropout_rate_Layer_3': 0.308709757823867, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00327662342652995, 'l1_Layer_2': 0.007180400469619504, 'l1_Layer_3': 2.8459197460315504e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 215, 'n_units_Layer_3': 300}. Best is trial 924 with value: 3.573744779479321.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.63 | sMAPE for Validation Set is: 9.52% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 3.81 | sMAPE for Test Set is: 13.10% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:39:17,505]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:39:23,148]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:39:26,368]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:39:26,987]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:39:31,987]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:39:32,594]\u001b[0m Trial 1055 finished with value: 4.325069581703101 and parameters: {'n_hidden': 3, 'learning_rate': 0.015141107774552715, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15660199833050853, 'dropout_rate_Layer_2': 0.3591230813663141, 'dropout_rate_Layer_3': 0.1672145097356456, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0061772287347212, 'l1_Layer_2': 0.0017713325307091316, 'l1_Layer_3': 0.030656801721033158, 'n_units_Layer_1': 245, 'n_units_Layer_2': 95, 'n_units_Layer_3': 260}. Best is trial 924 with value: 3.573744779479321.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.33 | sMAPE for Validation Set is: 11.03% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.13 | sMAPE for Test Set is: 21.11% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:39:38,333]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:39:39,264]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:39:40,315]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:39:44,380]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:39:49,860]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:39:50,691]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:39:55,103]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:39:58,703]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:40:02,566]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:40:05,476]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:40:13,991]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:40:17,155]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:40:20,295]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:40:23,759]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:40:32,467]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:40:33,474]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:40:39,007]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:40:46,493]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:40:50,104]\u001b[0m Trial 1069 finished with value: 3.6520243339627654 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015946883434436406, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008859971899626121, 'dropout_rate_Layer_2': 0.16114179641402365, 'dropout_rate_Layer_3': 0.2937786000790053, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0032537306845263365, 'l1_Layer_2': 0.0015573983092886765, 'l1_Layer_3': 1.3245557101602201e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 225, 'n_units_Layer_3': 285}. Best is trial 924 with value: 3.573744779479321.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.65 | sMAPE for Validation Set is: 9.55% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 3.95 | sMAPE for Test Set is: 13.95% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:40:53,365]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:40:55,364]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:40:59,852]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:41:02,228]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:41:03,033]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:41:08,486]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:41:13,082]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:41:13,339]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:41:18,856]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:41:19,319]\u001b[0m Trial 1078 finished with value: 3.6974884665522416 and parameters: {'n_hidden': 3, 'learning_rate': 0.000702662782186118, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2899096816174207, 'dropout_rate_Layer_2': 0.09095388425884504, 'dropout_rate_Layer_3': 0.061461973262858065, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0018736083655050944, 'l1_Layer_2': 9.655450404360644e-05, 'l1_Layer_3': 2.6694986928525414e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 240, 'n_units_Layer_3': 290}. Best is trial 924 with value: 3.573744779479321.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.70 | sMAPE for Validation Set is: 9.53% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 6.52 | sMAPE for Test Set is: 21.70% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:41:29,667]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:41:35,495]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:41:37,786]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:41:40,733]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:41:43,432]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:41:47,978]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:41:49,236]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:41:52,024]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:41:57,548]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:41:58,215]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:42:00,472]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:42:02,658]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:42:08,297]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:42:11,612]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:42:12,306]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:42:14,657]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:42:17,148]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:42:18,360]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:42:24,325]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:42:24,561]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:42:27,274]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:42:32,414]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:42:34,483]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:42:35,597]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:42:37,327]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:42:42,643]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:42:46,859]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:42:48,002]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:42:48,002]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:42:54,758]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:42:56,338]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:42:59,611]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:43:02,316]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:43:05,717]\u001b[0m Trial 1086 finished with value: 3.6311973245272653 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007500991661741792, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17968547726247416, 'dropout_rate_Layer_2': 0.39186277558894134, 'dropout_rate_Layer_3': 0.2649653433657646, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0017253864395142177, 'l1_Layer_2': 0.0006153452647851944, 'l1_Layer_3': 2.3121362421854234e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 205, 'n_units_Layer_3': 270}. Best is trial 924 with value: 3.573744779479321.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.63 | sMAPE for Validation Set is: 9.49% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 5.07 | sMAPE for Test Set is: 17.97% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:43:09,363]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:43:17,555]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:43:18,461]\u001b[0m Trial 1124 finished with value: 4.31660099561876 and parameters: {'n_hidden': 3, 'learning_rate': 0.019236808516858574, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06327246922297178, 'dropout_rate_Layer_2': 0.37689864539574636, 'dropout_rate_Layer_3': 0.20144880463166867, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.006136990617728452, 'l1_Layer_2': 0.0024854607600729335, 'l1_Layer_3': 0.009078219645487764, 'n_units_Layer_1': 115, 'n_units_Layer_2': 60, 'n_units_Layer_3': 175}. Best is trial 924 with value: 3.573744779479321.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.32 | sMAPE for Validation Set is: 11.01% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.11 | sMAPE for Test Set is: 17.83% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:43:28,002]\u001b[0m Trial 1119 finished with value: 3.6700154550515074 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010334654191620678, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2747576080289482, 'dropout_rate_Layer_2': 0.04109434365570014, 'dropout_rate_Layer_3': 0.05109842351238705, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0058286119397778354, 'l1_Layer_2': 6.501150790601297e-05, 'l1_Layer_3': 4.8406293134653565e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 260, 'n_units_Layer_3': 290}. Best is trial 924 with value: 3.573744779479321.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.67 | sMAPE for Validation Set is: 9.60% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 5.79 | sMAPE for Test Set is: 19.76% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:43:30,277]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:43:48,306]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:43:49,449]\u001b[0m Trial 1128 finished with value: 3.663497208086028 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009917481679568923, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2723286841498848, 'dropout_rate_Layer_2': 0.024304827747287552, 'dropout_rate_Layer_3': 0.04817791376708444, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005954431307742522, 'l1_Layer_2': 0.0001796526688948524, 'l1_Layer_3': 5.1381947230850256e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 260, 'n_units_Layer_3': 255}. Best is trial 924 with value: 3.573744779479321.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.66 | sMAPE for Validation Set is: 9.58% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.55 | sMAPE for Test Set is: 15.85% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:43:55,873]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:44:01,556]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:44:06,957]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:44:07,387]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:44:28,644]\u001b[0m Trial 1135 finished with value: 3.6930243867008605 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010717037905261474, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28812169126394666, 'dropout_rate_Layer_2': 0.07149859179564245, 'dropout_rate_Layer_3': 0.0773887697698006, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0035570419563439454, 'l1_Layer_2': 4.6061119069670104e-05, 'l1_Layer_3': 2.9054537901348924e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 270, 'n_units_Layer_3': 280}. Best is trial 924 with value: 3.573744779479321.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.69 | sMAPE for Validation Set is: 9.58% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 5.48 | sMAPE for Test Set is: 18.33% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:44:31,333]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.72 | sMAPE for Validation Set is: 9.65% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.81 | sMAPE for Test Set is: 17.29% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:44:33,606]\u001b[0m Trial 1127 finished with value: 3.71876761167409 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008123396177831676, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19550336676305852, 'dropout_rate_Layer_2': 0.33313065170861106, 'dropout_rate_Layer_3': 0.2505286113536751, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002009785316135324, 'l1_Layer_2': 0.0007264876097987723, 'l1_Layer_3': 2.1200486022369808e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 200, 'n_units_Layer_3': 300}. Best is trial 924 with value: 3.573744779479321.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:44:36,009]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:44:41,230]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:44:44,191]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:44:47,553]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:44:47,971]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:44:53,776]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:44:56,901]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:45:01,102]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:45:01,384]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.64 | sMAPE for Validation Set is: 9.45% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.18 | sMAPE for Test Set is: 14.50% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:45:04,676]\u001b[0m Trial 1130 finished with value: 3.642213674245101 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018708698520342325, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.028378830192782187, 'dropout_rate_Layer_2': 0.19114536694410914, 'dropout_rate_Layer_3': 0.31901384595422566, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00464905947218451, 'l1_Layer_2': 0.0037897667763856203, 'l1_Layer_3': 2.7652706802650816e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 220, 'n_units_Layer_3': 285}. Best is trial 924 with value: 3.573744779479321.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:45:07,128]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:45:12,948]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:45:14,851]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:45:19,112]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:45:21,213]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:45:24,863]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:45:26,739]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:45:31,549]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:45:39,355]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:45:44,914]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:45:51,640]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:45:53,010]\u001b[0m Trial 1137 finished with value: 3.6181057181475715 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018793583635854966, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.027861170728306288, 'dropout_rate_Layer_2': 0.11668186645900898, 'dropout_rate_Layer_3': 0.31753686823143357, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004361685155271027, 'l1_Layer_2': 0.00215346116512899, 'l1_Layer_3': 2.5203088669890345e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 220, 'n_units_Layer_3': 285}. Best is trial 924 with value: 3.573744779479321.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.62 | sMAPE for Validation Set is: 9.47% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.15 | sMAPE for Test Set is: 14.47% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:45:57,394]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:45:59,672]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:46:02,678]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:46:05,424]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:46:07,806]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:46:10,195]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:46:10,273]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:46:15,908]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:46:17,266]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:46:23,480]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:46:26,772]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:46:33,043]\u001b[0m Trial 1158 finished with value: 3.607882678510597 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009300596697695492, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28233728252160617, 'dropout_rate_Layer_2': 0.0739954952973581, 'dropout_rate_Layer_3': 0.0512891236868825, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002640009584133187, 'l1_Layer_2': 8.253124456007686e-05, 'l1_Layer_3': 6.944550807065214e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 275, 'n_units_Layer_3': 300}. Best is trial 924 with value: 3.573744779479321.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.61 | sMAPE for Validation Set is: 9.37% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 5.97 | sMAPE for Test Set is: 19.81% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:46:37,105]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:46:37,915]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:46:44,096]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:46:48,147]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:46:54,305]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:46:54,662]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:47:02,665]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:47:02,907]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:47:08,806]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:47:13,510]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:47:13,915]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:47:19,329]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:47:22,491]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:47:24,076]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:47:29,735]\u001b[0m Trial 1180 finished with value: 3.871663450934617 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017271653079062475, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05917468302739112, 'dropout_rate_Layer_2': 0.15830633941594202, 'dropout_rate_Layer_3': 0.2901314557396166, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0018781005813381948, 'l1_Layer_2': 0.0021994816614493993, 'l1_Layer_3': 1.4182454798903444e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 240, 'n_units_Layer_3': 295}. Best is trial 924 with value: 3.573744779479321.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.87 | sMAPE for Validation Set is: 10.11% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 3.96 | sMAPE for Test Set is: 14.02% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:47:30,318]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:47:36,167]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:47:36,629]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:47:42,755]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:47:46,216]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:47:54,798]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:47:59,485]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:48:02,898]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:48:06,608]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:48:10,989]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:48:13,113]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:48:16,379]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:48:17,021]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:48:23,084]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:48:23,326]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:48:24,140]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:48:27,125]\u001b[0m Trial 1175 finished with value: 3.6891934389242245 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005863156396426643, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1923851960311497, 'dropout_rate_Layer_2': 0.39905586915501157, 'dropout_rate_Layer_3': 0.014153104574534892, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0034508184798672553, 'l1_Layer_2': 0.0009679873588580855, 'l1_Layer_3': 4.79131899889088e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 200, 'n_units_Layer_3': 285}. Best is trial 924 with value: 3.573744779479321.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.69 | sMAPE for Validation Set is: 9.62% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 5.02 | sMAPE for Test Set is: 17.95% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:48:30,015]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:48:32,353]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:48:39,822]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:48:40,493]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:48:41,244]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:48:44,473]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:48:46,173]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:48:49,746]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:48:50,807]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:48:54,373]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:48:58,519]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:49:01,059]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:49:02,505]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:49:09,163]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:49:12,813]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:49:15,476]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:49:18,717]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:49:19,067]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:49:20,119]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:49:25,058]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:49:28,248]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:49:29,210]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:49:30,408]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:49:30,564]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:49:38,674]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:49:41,286]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:49:41,845]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:49:46,418]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:49:49,239]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:49:51,702]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:49:53,509]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:49:56,712]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:50:05,044]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:50:09,246]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:50:15,926]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:50:18,070]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:50:22,656]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:50:23,700]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:50:26,968]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:50:32,073]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:50:36,284]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:50:36,645]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:50:43,797]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:50:43,944]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:50:44,579]\u001b[0m Trial 1233 finished with value: 3.640677537117812 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006402371210694157, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2708173429910796, 'dropout_rate_Layer_2': 0.04870680252398485, 'dropout_rate_Layer_3': 0.03858866969237069, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005853877773678947, 'l1_Layer_2': 6.628619762291633e-05, 'l1_Layer_3': 1.5562870622207338e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 250, 'n_units_Layer_3': 275}. Best is trial 924 with value: 3.573744779479321.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.64 | sMAPE for Validation Set is: 9.49% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 5.56 | sMAPE for Test Set is: 18.90% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:50:54,869]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:50:55,545]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:50:55,799]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:51:10,809]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:51:15,752]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:51:16,245]\u001b[0m Trial 1240 finished with value: 3.6469524286613844 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012650149459708568, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.015284228053373955, 'dropout_rate_Layer_2': 0.13322014494617512, 'dropout_rate_Layer_3': 0.35200149005799297, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00611706739027614, 'l1_Layer_2': 0.0032487315471867706, 'l1_Layer_3': 2.5591197114747318e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 225, 'n_units_Layer_3': 290}. Best is trial 924 with value: 3.573744779479321.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.65 | sMAPE for Validation Set is: 9.56% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 3.97 | sMAPE for Test Set is: 13.60% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:51:22,034]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:51:22,467]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:51:29,500]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:51:29,695]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:51:29,980]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:51:38,889]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:51:40,059]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:51:41,103]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:51:45,937]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:51:46,259]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:51:46,840]\u001b[0m Trial 1252 finished with value: 3.6245817212151707 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005970455347230691, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2813178068193583, 'dropout_rate_Layer_2': 0.061201063609062176, 'dropout_rate_Layer_3': 0.028006986896980442, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004343451348937824, 'l1_Layer_2': 3.7556263079370847e-05, 'l1_Layer_3': 2.1634551161628415e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 255, 'n_units_Layer_3': 255}. Best is trial 924 with value: 3.573744779479321.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.62 | sMAPE for Validation Set is: 9.46% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 5.24 | sMAPE for Test Set is: 17.79% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:51:47,127]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:51:55,369]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:51:57,358]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:51:58,181]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:52:00,402]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:52:05,710]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:52:06,732]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:52:13,130]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:52:15,603]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:52:17,220]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:52:21,094]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:52:21,745]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:52:24,355]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:52:29,678]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:52:29,899]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:52:30,594]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:52:34,434]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:52:39,094]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:52:44,072]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:52:44,353]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:52:45,616]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:52:53,410]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:52:54,316]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:53:00,370]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:53:04,843]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:53:05,163]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:53:06,061]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:53:13,503]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:53:13,835]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:53:17,363]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:53:22,674]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:53:25,451]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:53:30,868]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:53:31,641]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:53:33,073]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:53:35,394]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:53:38,625]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:53:43,352]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:53:45,572]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:53:50,765]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:53:52,514]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:53:54,529]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:53:55,943]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:54:02,485]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:54:04,957]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:54:05,633]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:54:10,492]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:54:11,484]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:54:17,057]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:54:20,680]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:54:21,157]\u001b[0m Trial 1296 finished with value: 3.7508967908206827 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008325107231151969, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04481392236496553, 'dropout_rate_Layer_2': 0.1723646539095493, 'dropout_rate_Layer_3': 0.3701788464541647, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0035909039983853582, 'l1_Layer_2': 0.003185383855808759, 'l1_Layer_3': 3.7076753393585096e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 215, 'n_units_Layer_3': 280}. Best is trial 924 with value: 3.573744779479321.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 9.85% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.13 | sMAPE for Test Set is: 15.48% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:54:21,913]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:54:27,514]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:54:30,963]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:54:31,030]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:54:37,640]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:54:40,043]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:54:42,873]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:54:43,772]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:54:45,125]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:54:47,156]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:54:49,836]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:54:53,614]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:54:56,627]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:54:59,642]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:55:03,271]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:55:07,953]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:55:08,646]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:55:09,334]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:55:16,863]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:55:19,106]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:55:23,247]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:55:23,708]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:55:27,052]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:55:30,652]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:55:31,194]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:55:31,989]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:55:37,564]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:55:43,014]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:55:43,422]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:55:43,988]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:55:44,676]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:55:53,222]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:55:53,977]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:55:59,524]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:56:00,895]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:56:04,653]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:56:04,728]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:56:05,697]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:56:05,915]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:56:15,102]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:56:15,350]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:56:15,500]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:56:24,329]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:56:25,132]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:56:30,909]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:56:34,220]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:56:34,886]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:56:40,956]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:56:45,747]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:56:46,400]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:56:52,085]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:56:52,097]\u001b[0m Trial 1358 finished with value: 4.2705397111565935 and parameters: {'n_hidden': 3, 'learning_rate': 0.012436350866727895, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.166892371943175, 'dropout_rate_Layer_2': 0.35836252894827425, 'dropout_rate_Layer_3': 0.22619063598656552, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.005047955853004066, 'l1_Layer_2': 0.000816854923767179, 'l1_Layer_3': 0.019231794420657543, 'n_units_Layer_1': 245, 'n_units_Layer_2': 70, 'n_units_Layer_3': 260}. Best is trial 924 with value: 3.573744779479321.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.27 | sMAPE for Validation Set is: 10.91% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.56 | sMAPE for Test Set is: 19.37% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:56:58,272]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:57:02,408]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:57:06,525]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:57:06,953]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:57:12,848]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:57:12,912]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:57:13,019]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:57:14,542]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:57:24,222]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:57:28,137]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:57:28,821]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:57:29,782]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:57:37,190]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:57:37,422]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:57:38,006]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:57:38,048]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:57:45,763]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:57:50,377]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:57:52,960]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:57:53,133]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:57:57,020]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:58:01,536]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:58:05,872]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:58:09,215]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:58:09,245]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:58:09,655]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:58:17,375]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:58:18,744]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:58:19,936]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:58:24,393]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:58:29,534]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:58:30,757]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:58:35,560]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:58:36,418]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:58:39,726]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:58:44,560]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:58:45,933]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:58:49,559]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:58:55,305]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:58:55,895]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:58:56,557]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:59:05,451]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:59:05,990]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:59:13,681]\u001b[0m Trial 1389 finished with value: 3.7202936960243425 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009349657185831942, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38532435905783124, 'dropout_rate_Layer_2': 0.3874596194960037, 'dropout_rate_Layer_3': 0.20343926574381396, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0037457800902726407, 'l1_Layer_2': 0.0007482954543111355, 'l1_Layer_3': 2.5990039097639687e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 250, 'n_units_Layer_3': 275}. Best is trial 924 with value: 3.573744779479321.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.72 | sMAPE for Validation Set is: 9.69% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.60 | sMAPE for Test Set is: 16.53% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 01:59:18,427]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:59:22,602]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:59:29,235]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:59:29,460]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:59:35,733]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:59:35,975]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:59:41,398]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:59:46,629]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:59:46,804]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:59:51,940]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:59:55,004]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:59:58,536]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 01:59:58,802]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:00:03,791]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:00:09,702]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:00:13,063]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:00:13,501]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:00:13,876]\u001b[0m Trial 1419 finished with value: 3.831997506289953 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014128273896455658, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30887046195680246, 'dropout_rate_Layer_2': 0.0262466822595352, 'dropout_rate_Layer_3': 0.06208257542586385, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01198823472422502, 'l1_Layer_2': 6.542330745098493e-05, 'l1_Layer_3': 1.0334590289310742e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 245, 'n_units_Layer_3': 280}. Best is trial 924 with value: 3.573744779479321.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.83 | sMAPE for Validation Set is: 9.93% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.85 | sMAPE for Test Set is: 16.87% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 02:00:20,186]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:00:22,502]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:00:23,406]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:00:24,182]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:00:33,324]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:00:33,833]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:00:34,591]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:00:41,734]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:00:52,591]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:00:57,356]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:01:01,201]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:01:01,456]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:01:06,797]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:01:11,418]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:01:26,208]\u001b[0m Trial 1444 finished with value: 3.7448847987398755 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019139752385116374, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2994090367429759, 'dropout_rate_Layer_2': 0.0942232290312722, 'dropout_rate_Layer_3': 0.008454334856546574, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003976060151616383, 'l1_Layer_2': 0.00011191347749096994, 'l1_Layer_3': 4.019781498021559e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 235, 'n_units_Layer_3': 295}. Best is trial 924 with value: 3.573744779479321.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.74 | sMAPE for Validation Set is: 9.80% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.11 | sMAPE for Test Set is: 20.79% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 02:01:30,211]\u001b[0m Trial 1433 finished with value: 3.634684519440602 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011441206883524178, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03217033256890334, 'dropout_rate_Layer_2': 0.20164197059060474, 'dropout_rate_Layer_3': 0.3058092289393622, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0062433268988359115, 'l1_Layer_2': 0.005479082748747301, 'l1_Layer_3': 1.8914060908660516e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 220, 'n_units_Layer_3': 270}. Best is trial 924 with value: 3.573744779479321.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.63 | sMAPE for Validation Set is: 9.54% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 3.88 | sMAPE for Test Set is: 13.40% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 02:01:32,838]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:01:36,663]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:01:37,723]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:01:42,259]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:01:45,427]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:01:47,819]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:01:49,543]\u001b[0m Trial 1446 finished with value: 3.638618447828892 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009840586808334507, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3006762502105425, 'dropout_rate_Layer_2': 0.09256967260208551, 'dropout_rate_Layer_3': 0.019038330031421587, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003998894059584581, 'l1_Layer_2': 0.00020128645178939882, 'l1_Layer_3': 3.988629452247877e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 235, 'n_units_Layer_3': 265}. Best is trial 924 with value: 3.573744779479321.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.64 | sMAPE for Validation Set is: 9.48% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 5.04 | sMAPE for Test Set is: 17.29% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 02:01:53,354]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:01:54,635]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:01:56,653]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:02:01,349]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:02:05,657]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:02:06,098]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:02:10,379]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:02:11,155]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:02:16,389]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:02:19,066]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:02:23,376]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:02:23,585]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:02:24,487]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:02:33,218]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:02:33,369]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:02:33,936]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:02:36,387]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:02:42,767]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:02:42,968]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:02:45,168]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:02:45,380]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:02:52,525]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:02:55,279]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:02:55,378]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:02:56,570]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:03:03,282]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:03:05,514]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:03:07,699]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:03:14,132]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:03:17,086]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:03:17,567]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:03:22,752]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:03:23,092]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:03:24,131]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:03:30,075]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:03:33,956]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:03:37,751]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:03:40,904]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:03:41,346]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:03:47,366]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:03:47,922]\u001b[0m Trial 1487 finished with value: 4.105193974125986 and parameters: {'n_hidden': 3, 'learning_rate': 0.03834842549567214, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006801706152825854, 'dropout_rate_Layer_2': 0.15760653835044625, 'dropout_rate_Layer_3': 0.3181292933087532, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005814347722662245, 'l1_Layer_2': 0.00385624727770143, 'l1_Layer_3': 2.879444631073e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 220, 'n_units_Layer_3': 260}. Best is trial 924 with value: 3.573744779479321.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.11 | sMAPE for Validation Set is: 10.42% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.45 | sMAPE for Test Set is: 15.11% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 02:03:48,977]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:03:54,691]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:03:57,753]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:04:01,662]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:04:01,732]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:04:01,802]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 02:04:07,701]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-01-01, MAE is:4.41 & sMAPE is:12.16% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :4.41 & 12.16% & 0.21\n",
      "for 2020-01-02, MAE is:3.25 & sMAPE is:8.53% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :3.83 & 10.34% & 0.22\n",
      "for 2020-01-03, MAE is:2.45 & sMAPE is:6.11% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :3.37 & 8.93% & 0.26\n",
      "for 2020-01-04, MAE is:4.67 & sMAPE is:12.68% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :3.70 & 9.87% & 0.45\n",
      "for 2020-01-05, MAE is:4.35 & sMAPE is:10.79% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :3.83 & 10.05% & 0.50\n",
      "for 2020-01-06, MAE is:4.79 & sMAPE is:10.99% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :3.99 & 10.21% & 0.56\n",
      "for 2020-01-07, MAE is:2.90 & sMAPE is:6.77% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :3.83 & 9.72% & 0.53\n",
      "for 2020-01-08, MAE is:3.56 & sMAPE is:7.88% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :3.80 & 9.49% & 0.50\n",
      "for 2020-01-09, MAE is:6.45 & sMAPE is:14.13% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :4.09 & 10.00% & 0.58\n",
      "for 2020-01-10, MAE is:6.98 & sMAPE is:17.14% & rMAE is:2.29 ||| daily mean of MAE & sMAPE & rMAE till now are :4.38 & 10.72% & 0.75\n",
      "for 2020-01-11, MAE is:4.06 & sMAPE is:9.21% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :4.35 & 10.58% & 0.75\n",
      "for 2020-01-12, MAE is:6.17 & sMAPE is:14.08% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :4.50 & 10.87% & 0.79\n",
      "for 2020-01-13, MAE is:5.80 & sMAPE is:12.06% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :4.60 & 10.96% & 0.80\n",
      "for 2020-01-14, MAE is:3.17 & sMAPE is:8.09% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.50 & 10.76% & 0.77\n",
      "for 2020-01-15, MAE is:4.07 & sMAPE is:11.96% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.47 & 10.84% & 0.75\n",
      "for 2020-01-16, MAE is:4.89 & sMAPE is:12.40% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :4.50 & 10.94% & 0.75\n",
      "for 2020-01-17, MAE is:2.82 & sMAPE is:7.07% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :4.40 & 10.71% & 0.78\n",
      "for 2020-01-18, MAE is:4.42 & sMAPE is:10.67% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :4.40 & 10.71% & 0.79\n",
      "for 2020-01-19, MAE is:4.48 & sMAPE is:13.95% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :4.40 & 10.88% & 0.76\n",
      "for 2020-01-20, MAE is:3.80 & sMAPE is:12.55% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.37 & 10.96% & 0.74\n",
      "for 2020-01-21, MAE is:2.22 & sMAPE is:5.77% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :4.27 & 10.71% & 0.76\n",
      "for 2020-01-22, MAE is:7.06 & sMAPE is:17.11% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :4.40 & 11.00% & 0.77\n",
      "for 2020-01-23, MAE is:5.97 & sMAPE is:12.34% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :4.47 & 11.06% & 0.75\n",
      "for 2020-01-24, MAE is:3.00 & sMAPE is:5.92% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :4.41 & 10.85% & 0.73\n",
      "for 2020-01-25, MAE is:4.76 & sMAPE is:9.46% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 10.79% & 0.72\n",
      "for 2020-01-26, MAE is:9.11 & sMAPE is:20.58% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :4.60 & 11.17% & 0.73\n",
      "for 2020-01-27, MAE is:4.04 & sMAPE is:10.60% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :4.58 & 11.15% & 0.73\n",
      "for 2020-01-28, MAE is:2.97 & sMAPE is:7.98% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :4.52 & 11.04% & 0.75\n",
      "for 2020-01-29, MAE is:5.02 & sMAPE is:11.77% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :4.54 & 11.06% & 0.75\n",
      "for 2020-01-30, MAE is:5.48 & sMAPE is:13.70% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 11.15% & 0.74\n",
      "for 2020-01-31, MAE is:4.39 & sMAPE is:10.86% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 11.14% & 0.72\n",
      "for 2020-02-01, MAE is:3.09 & sMAPE is:9.97% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :4.52 & 11.10% & 0.70\n",
      "for 2020-02-02, MAE is:4.36 & sMAPE is:14.40% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :4.51 & 11.20% & 0.70\n",
      "for 2020-02-03, MAE is:3.07 & sMAPE is:7.96% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :4.47 & 11.11% & 0.70\n",
      "for 2020-02-04, MAE is:4.36 & sMAPE is:11.24% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :4.47 & 11.11% & 0.71\n",
      "for 2020-02-05, MAE is:3.94 & sMAPE is:11.27% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :4.45 & 11.11% & 0.72\n",
      "for 2020-02-06, MAE is:4.02 & sMAPE is:10.44% & rMAE is:2.39 ||| daily mean of MAE & sMAPE & rMAE till now are :4.44 & 11.10% & 0.77\n",
      "for 2020-02-07, MAE is:4.40 & sMAPE is:10.73% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :4.44 & 11.09% & 0.78\n",
      "for 2020-02-08, MAE is:2.46 & sMAPE is:6.35% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 10.97% & 0.77\n",
      "for 2020-02-09, MAE is:8.27 & sMAPE is:23.73% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :4.49 & 11.28% & 0.79\n",
      "for 2020-02-10, MAE is:4.14 & sMAPE is:13.39% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.48 & 11.34% & 0.78\n",
      "for 2020-02-11, MAE is:4.46 & sMAPE is:11.60% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :4.48 & 11.34% & 0.79\n",
      "for 2020-02-12, MAE is:2.66 & sMAPE is:6.31% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :4.44 & 11.23% & 0.78\n",
      "for 2020-02-13, MAE is:5.29 & sMAPE is:13.15% & rMAE is:2.21 ||| daily mean of MAE & sMAPE & rMAE till now are :4.46 & 11.27% & 0.81\n",
      "for 2020-02-14, MAE is:4.09 & sMAPE is:9.91% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :4.45 & 11.24% & 0.83\n",
      "for 2020-02-15, MAE is:5.81 & sMAPE is:15.36% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.48 & 11.33% & 0.84\n",
      "for 2020-02-16, MAE is:5.39 & sMAPE is:19.88% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :4.50 & 11.51% & 0.84\n",
      "for 2020-02-17, MAE is:7.24 & sMAPE is:24.14% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.55 & 11.77% & 0.85\n",
      "for 2020-02-18, MAE is:2.33 & sMAPE is:6.29% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.51 & 11.66% & 0.85\n",
      "for 2020-02-19, MAE is:7.50 & sMAPE is:19.72% & rMAE is:2.65 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 11.82% & 0.88\n",
      "for 2020-02-20, MAE is:2.48 & sMAPE is:5.61% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.53 & 11.70% & 0.88\n",
      "for 2020-02-21, MAE is:3.46 & sMAPE is:8.69% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :4.51 & 11.64% & 0.88\n",
      "for 2020-02-22, MAE is:2.71 & sMAPE is:6.85% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :4.47 & 11.55% & 0.87\n",
      "for 2020-02-23, MAE is:4.41 & sMAPE is:11.88% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.47 & 11.56% & 0.87\n",
      "for 2020-02-24, MAE is:3.90 & sMAPE is:9.50% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :4.46 & 11.52% & 0.86\n",
      "for 2020-02-25, MAE is:4.38 & sMAPE is:12.65% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :4.46 & 11.54% & 0.86\n",
      "for 2020-02-26, MAE is:4.07 & sMAPE is:12.78% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :4.45 & 11.56% & 0.85\n",
      "for 2020-02-27, MAE is:4.76 & sMAPE is:14.13% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.46 & 11.61% & 0.84\n",
      "for 2020-02-28, MAE is:4.42 & sMAPE is:12.74% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :4.46 & 11.63% & 0.84\n",
      "for 2020-02-29, MAE is:8.78 & sMAPE is:42.32% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :4.53 & 12.14% & 0.84\n",
      "for 2020-03-01, MAE is:4.64 & sMAPE is:30.05% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :4.53 & 12.43% & 0.82\n",
      "for 2020-03-02, MAE is:3.64 & sMAPE is:18.38% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :4.52 & 12.53% & 0.81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-03-03, MAE is:4.66 & sMAPE is:17.51% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :4.52 & 12.61% & 0.81\n",
      "for 2020-03-04, MAE is:5.78 & sMAPE is:19.19% & rMAE is:3.06 ||| daily mean of MAE & sMAPE & rMAE till now are :4.54 & 12.71% & 0.85\n",
      "for 2020-03-05, MAE is:8.52 & sMAPE is:27.98% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.60 & 12.94% & 0.86\n",
      "for 2020-03-06, MAE is:6.13 & sMAPE is:25.39% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.62 & 13.13% & 0.85\n",
      "for 2020-03-07, MAE is:4.16 & sMAPE is:16.11% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :4.62 & 13.18% & 0.84\n",
      "for 2020-03-08, MAE is:4.06 & sMAPE is:14.13% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.61 & 13.19% & 0.83\n",
      "for 2020-03-09, MAE is:2.98 & sMAPE is:9.75% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :4.58 & 13.14% & 0.83\n",
      "for 2020-03-10, MAE is:2.75 & sMAPE is:7.52% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :4.56 & 13.06% & 0.82\n",
      "for 2020-03-11, MAE is:4.33 & sMAPE is:11.89% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :4.56 & 13.04% & 0.82\n",
      "for 2020-03-12, MAE is:3.59 & sMAPE is:8.92% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :4.54 & 12.99% & 0.81\n",
      "for 2020-03-13, MAE is:3.71 & sMAPE is:10.85% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :4.53 & 12.96% & 0.80\n",
      "for 2020-03-14, MAE is:3.50 & sMAPE is:10.50% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.52 & 12.92% & 0.80\n",
      "for 2020-03-15, MAE is:8.54 & sMAPE is:28.96% & rMAE is:2.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 13.14% & 0.82\n",
      "for 2020-03-16, MAE is:4.02 & sMAPE is:15.88% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :4.56 & 13.17% & 0.82\n",
      "for 2020-03-17, MAE is:4.10 & sMAPE is:13.71% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :4.56 & 13.18% & 0.82\n",
      "for 2020-03-18, MAE is:3.11 & sMAPE is:9.72% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :4.54 & 13.14% & 0.81\n",
      "for 2020-03-19, MAE is:4.30 & sMAPE is:13.41% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :4.54 & 13.14% & 0.81\n",
      "for 2020-03-20, MAE is:2.17 & sMAPE is:7.53% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :4.51 & 13.07% & 0.80\n",
      "for 2020-03-21, MAE is:3.07 & sMAPE is:11.58% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :4.49 & 13.05% & 0.80\n",
      "for 2020-03-22, MAE is:2.71 & sMAPE is:10.18% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :4.47 & 13.02% & 0.80\n",
      "for 2020-03-23, MAE is:3.73 & sMAPE is:13.24% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :4.46 & 13.02% & 0.80\n",
      "for 2020-03-24, MAE is:2.81 & sMAPE is:10.79% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :4.44 & 12.99% & 0.80\n",
      "for 2020-03-25, MAE is:3.41 & sMAPE is:11.22% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :4.43 & 12.97% & 0.80\n",
      "for 2020-03-26, MAE is:5.73 & sMAPE is:22.80% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :4.44 & 13.09% & 0.80\n",
      "for 2020-03-27, MAE is:3.48 & sMAPE is:13.93% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :4.43 & 13.10% & 0.81\n",
      "for 2020-03-28, MAE is:3.58 & sMAPE is:13.83% & rMAE is:2.28 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 13.10% & 0.82\n",
      "for 2020-03-29, MAE is:4.89 & sMAPE is:20.81% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :4.43 & 13.19% & 0.82\n",
      "for 2020-03-30, MAE is:2.80 & sMAPE is:13.40% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :4.41 & 13.19% & 0.82\n",
      "for 2020-03-31, MAE is:3.91 & sMAPE is:19.95% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.40 & 13.27% & 0.81\n",
      "for 2020-04-01, MAE is:2.22 & sMAPE is:8.67% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.38 & 13.22% & 0.81\n",
      "for 2020-04-02, MAE is:4.20 & sMAPE is:16.27% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :4.38 & 13.25% & 0.81\n",
      "for 2020-04-03, MAE is:2.98 & sMAPE is:12.60% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :4.36 & 13.24% & 0.82\n",
      "for 2020-04-04, MAE is:8.40 & sMAPE is:43.09% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :4.40 & 13.56% & 0.82\n",
      "for 2020-04-05, MAE is:5.12 & sMAPE is:54.30% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.41 & 13.98% & 0.82\n",
      "for 2020-04-06, MAE is:8.77 & sMAPE is:47.11% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :4.46 & 14.32% & 0.82\n",
      "for 2020-04-07, MAE is:3.43 & sMAPE is:13.84% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :4.45 & 14.32% & 0.82\n",
      "for 2020-04-08, MAE is:2.88 & sMAPE is:11.90% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :4.43 & 14.29% & 0.82\n",
      "for 2020-04-09, MAE is:4.02 & sMAPE is:16.31% & rMAE is:2.05 ||| daily mean of MAE & sMAPE & rMAE till now are :4.43 & 14.31% & 0.83\n",
      "for 2020-04-10, MAE is:4.19 & sMAPE is:19.09% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 14.36% & 0.84\n",
      "for 2020-04-11, MAE is:2.99 & sMAPE is:14.60% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.41 & 14.36% & 0.83\n",
      "for 2020-04-12, MAE is:3.32 & sMAPE is:17.16% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :4.40 & 14.39% & 0.83\n",
      "for 2020-04-13, MAE is:4.96 & sMAPE is:24.79% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :4.40 & 14.49% & 0.84\n",
      "for 2020-04-14, MAE is:2.86 & sMAPE is:12.82% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 14.48% & 0.84\n",
      "for 2020-04-15, MAE is:2.70 & sMAPE is:14.16% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.37 & 14.47% & 0.84\n",
      "for 2020-04-16, MAE is:4.62 & sMAPE is:29.18% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :4.38 & 14.61% & 0.83\n",
      "for 2020-04-17, MAE is:3.12 & sMAPE is:26.22% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :4.36 & 14.72% & 0.83\n",
      "for 2020-04-18, MAE is:3.03 & sMAPE is:14.96% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :4.35 & 14.72% & 0.84\n",
      "for 2020-04-19, MAE is:4.50 & sMAPE is:28.83% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :4.35 & 14.85% & 0.84\n",
      "for 2020-04-20, MAE is:2.82 & sMAPE is:25.15% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 14.94% & 0.83\n",
      "for 2020-04-21, MAE is:5.17 & sMAPE is:40.93% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.35 & 15.17% & 0.83\n",
      "for 2020-04-22, MAE is:4.19 & sMAPE is:64.45% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.35 & 15.61% & 0.82\n",
      "for 2020-04-23, MAE is:3.60 & sMAPE is:22.28% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 15.67% & 0.82\n",
      "for 2020-04-24, MAE is:4.86 & sMAPE is:29.09% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 15.78% & 0.83\n",
      "for 2020-04-25, MAE is:3.36 & sMAPE is:21.07% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 15.83% & 0.83\n",
      "for 2020-04-26, MAE is:2.70 & sMAPE is:17.08% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :4.32 & 15.84% & 0.83\n",
      "for 2020-04-27, MAE is:3.74 & sMAPE is:16.38% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :4.32 & 15.84% & 0.82\n",
      "for 2020-04-28, MAE is:3.22 & sMAPE is:17.24% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :4.31 & 15.86% & 0.82\n",
      "for 2020-04-29, MAE is:7.55 & sMAPE is:52.41% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 16.16% & 0.82\n",
      "for 2020-04-30, MAE is:2.99 & sMAPE is:34.46% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :4.32 & 16.31% & 0.82\n",
      "for 2020-05-01, MAE is:3.11 & sMAPE is:71.44% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :4.31 & 16.76% & 0.81\n",
      "for 2020-05-02, MAE is:3.98 & sMAPE is:42.47% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.31 & 16.97% & 0.81\n",
      "for 2020-05-03, MAE is:3.47 & sMAPE is:24.17% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :4.30 & 17.03% & 0.82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-05-04, MAE is:2.70 & sMAPE is:17.24% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :4.29 & 17.03% & 0.82\n",
      "for 2020-05-05, MAE is:2.09 & sMAPE is:11.93% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :4.27 & 16.99% & 0.82\n",
      "for 2020-05-06, MAE is:3.25 & sMAPE is:14.62% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :4.26 & 16.97% & 0.81\n",
      "for 2020-05-07, MAE is:3.17 & sMAPE is:14.45% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :4.26 & 16.95% & 0.81\n",
      "for 2020-05-08, MAE is:3.68 & sMAPE is:17.42% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :4.25 & 16.96% & 0.80\n",
      "for 2020-05-09, MAE is:3.61 & sMAPE is:18.17% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.25 & 16.97% & 0.80\n",
      "for 2020-05-10, MAE is:5.51 & sMAPE is:34.54% & rMAE is:2.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.26 & 17.10% & 0.81\n",
      "for 2020-05-11, MAE is:2.14 & sMAPE is:16.19% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :4.24 & 17.09% & 0.81\n",
      "for 2020-05-12, MAE is:4.79 & sMAPE is:22.10% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :4.24 & 17.13% & 0.81\n",
      "for 2020-05-13, MAE is:1.56 & sMAPE is:5.95% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :4.22 & 17.05% & 0.81\n",
      "for 2020-05-14, MAE is:2.57 & sMAPE is:11.10% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :4.21 & 17.00% & 0.81\n",
      "for 2020-05-15, MAE is:4.30 & sMAPE is:19.31% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.21 & 17.02% & 0.82\n",
      "for 2020-05-16, MAE is:2.88 & sMAPE is:17.91% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 17.03% & 0.82\n",
      "for 2020-05-17, MAE is:5.62 & sMAPE is:33.55% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.21 & 17.15% & 0.82\n",
      "for 2020-05-18, MAE is:4.72 & sMAPE is:20.59% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.22 & 17.17% & 0.82\n",
      "for 2020-05-19, MAE is:2.96 & sMAPE is:12.02% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :4.21 & 17.14% & 0.82\n",
      "for 2020-05-20, MAE is:1.94 & sMAPE is:7.36% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 17.07% & 0.82\n",
      "for 2020-05-21, MAE is:2.33 & sMAPE is:8.67% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :4.18 & 17.01% & 0.82\n",
      "for 2020-05-22, MAE is:3.87 & sMAPE is:14.06% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :4.18 & 16.99% & 0.82\n",
      "for 2020-05-23, MAE is:6.71 & sMAPE is:30.27% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 17.08% & 0.83\n",
      "for 2020-05-24, MAE is:4.52 & sMAPE is:34.25% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 17.20% & 0.83\n",
      "for 2020-05-25, MAE is:3.45 & sMAPE is:14.95% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 17.18% & 0.83\n",
      "for 2020-05-26, MAE is:2.40 & sMAPE is:10.74% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.18 & 17.14% & 0.83\n",
      "for 2020-05-27, MAE is:2.86 & sMAPE is:11.99% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :4.17 & 17.10% & 0.83\n",
      "for 2020-05-28, MAE is:2.15 & sMAPE is:7.10% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :4.16 & 17.04% & 0.84\n",
      "for 2020-05-29, MAE is:3.68 & sMAPE is:11.75% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :4.15 & 17.00% & 0.84\n",
      "for 2020-05-30, MAE is:3.66 & sMAPE is:12.67% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :4.15 & 16.97% & 0.84\n",
      "for 2020-05-31, MAE is:2.67 & sMAPE is:9.23% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :4.14 & 16.92% & 0.83\n",
      "for 2020-06-01, MAE is:2.18 & sMAPE is:6.30% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :4.13 & 16.85% & 0.83\n",
      "for 2020-06-02, MAE is:2.34 & sMAPE is:6.40% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :4.12 & 16.78% & 0.83\n",
      "for 2020-06-03, MAE is:4.83 & sMAPE is:14.32% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :4.12 & 16.77% & 0.82\n",
      "for 2020-06-04, MAE is:6.19 & sMAPE is:23.71% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :4.13 & 16.81% & 0.83\n",
      "for 2020-06-05, MAE is:3.42 & sMAPE is:13.10% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :4.13 & 16.79% & 0.82\n",
      "for 2020-06-06, MAE is:3.60 & sMAPE is:12.94% & rMAE is:2.22 ||| daily mean of MAE & sMAPE & rMAE till now are :4.13 & 16.76% & 0.83\n",
      "for 2020-06-07, MAE is:7.21 & sMAPE is:32.26% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :4.15 & 16.86% & 0.83\n",
      "for 2020-06-08, MAE is:1.95 & sMAPE is:7.47% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :4.13 & 16.80% & 0.83\n",
      "for 2020-06-09, MAE is:3.01 & sMAPE is:10.50% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :4.12 & 16.76% & 0.83\n",
      "for 2020-06-10, MAE is:5.04 & sMAPE is:17.58% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :4.13 & 16.77% & 0.83\n",
      "for 2020-06-11, MAE is:4.76 & sMAPE is:18.85% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :4.13 & 16.78% & 0.83\n",
      "for 2020-06-12, MAE is:3.61 & sMAPE is:16.13% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.13 & 16.78% & 0.83\n",
      "for 2020-06-13, MAE is:2.77 & sMAPE is:13.16% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :4.12 & 16.76% & 0.83\n",
      "for 2020-06-14, MAE is:4.04 & sMAPE is:16.03% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :4.12 & 16.75% & 0.83\n",
      "for 2020-06-15, MAE is:2.96 & sMAPE is:9.62% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.12 & 16.71% & 0.83\n",
      "for 2020-06-16, MAE is:2.78 & sMAPE is:9.26% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :4.11 & 16.66% & 0.83\n",
      "for 2020-06-17, MAE is:4.58 & sMAPE is:14.50% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :4.11 & 16.65% & 0.83\n",
      "for 2020-06-18, MAE is:3.34 & sMAPE is:9.95% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :4.11 & 16.61% & 0.83\n",
      "for 2020-06-19, MAE is:2.49 & sMAPE is:7.34% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :4.10 & 16.56% & 0.82\n",
      "for 2020-06-20, MAE is:3.29 & sMAPE is:10.89% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.09 & 16.53% & 0.82\n",
      "for 2020-06-21, MAE is:3.05 & sMAPE is:11.18% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :4.09 & 16.49% & 0.82\n",
      "for 2020-06-22, MAE is:3.15 & sMAPE is:10.50% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :4.08 & 16.46% & 0.82\n",
      "for 2020-06-23, MAE is:2.87 & sMAPE is:8.24% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :4.07 & 16.41% & 0.82\n",
      "for 2020-06-24, MAE is:2.62 & sMAPE is:7.20% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :4.07 & 16.36% & 0.82\n",
      "for 2020-06-25, MAE is:2.92 & sMAPE is:7.72% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.06 & 16.31% & 0.82\n",
      "for 2020-06-26, MAE is:2.96 & sMAPE is:7.85% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :4.05 & 16.26% & 0.82\n",
      "for 2020-06-27, MAE is:4.62 & sMAPE is:14.74% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :4.06 & 16.26% & 0.82\n",
      "for 2020-06-28, MAE is:3.77 & sMAPE is:12.27% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :4.05 & 16.23% & 0.83\n",
      "for 2020-06-29, MAE is:4.99 & sMAPE is:14.57% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :4.06 & 16.22% & 0.82\n",
      "for 2020-06-30, MAE is:2.72 & sMAPE is:7.53% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :4.05 & 16.18% & 0.82\n",
      "for 2020-07-01, MAE is:3.14 & sMAPE is:8.78% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :4.05 & 16.14% & 0.83\n",
      "for 2020-07-02, MAE is:3.84 & sMAPE is:11.36% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :4.05 & 16.11% & 0.83\n",
      "for 2020-07-03, MAE is:3.10 & sMAPE is:8.99% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 16.07% & 0.83\n",
      "for 2020-07-04, MAE is:4.02 & sMAPE is:13.31% & rMAE is:1.94 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 16.06% & 0.83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-07-05, MAE is:3.34 & sMAPE is:12.20% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 16.04% & 0.83\n",
      "for 2020-07-06, MAE is:3.82 & sMAPE is:13.96% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 16.03% & 0.83\n",
      "for 2020-07-07, MAE is:2.78 & sMAPE is:8.07% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :4.03 & 15.98% & 0.83\n",
      "for 2020-07-08, MAE is:2.34 & sMAPE is:6.36% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.02 & 15.93% & 0.83\n",
      "for 2020-07-09, MAE is:2.69 & sMAPE is:7.04% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :4.01 & 15.89% & 0.83\n",
      "for 2020-07-10, MAE is:3.46 & sMAPE is:8.95% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :4.01 & 15.85% & 0.83\n",
      "for 2020-07-11, MAE is:3.48 & sMAPE is:11.57% & rMAE is:2.17 ||| daily mean of MAE & sMAPE & rMAE till now are :4.01 & 15.83% & 0.84\n",
      "for 2020-07-12, MAE is:3.39 & sMAPE is:11.69% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :4.00 & 15.81% & 0.84\n",
      "for 2020-07-13, MAE is:3.01 & sMAPE is:9.09% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.00 & 15.77% & 0.84\n",
      "for 2020-07-14, MAE is:3.63 & sMAPE is:10.51% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :4.00 & 15.75% & 0.84\n",
      "for 2020-07-15, MAE is:2.74 & sMAPE is:8.58% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :3.99 & 15.71% & 0.84\n",
      "for 2020-07-16, MAE is:2.19 & sMAPE is:6.30% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :3.98 & 15.66% & 0.84\n",
      "for 2020-07-17, MAE is:4.61 & sMAPE is:13.47% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :3.99 & 15.65% & 0.84\n",
      "for 2020-07-18, MAE is:5.25 & sMAPE is:16.56% & rMAE is:2.83 ||| daily mean of MAE & sMAPE & rMAE till now are :3.99 & 15.65% & 0.85\n",
      "for 2020-07-19, MAE is:5.24 & sMAPE is:16.68% & rMAE is:2.25 ||| daily mean of MAE & sMAPE & rMAE till now are :4.00 & 15.66% & 0.85\n",
      "for 2020-07-20, MAE is:3.06 & sMAPE is:8.92% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :3.99 & 15.63% & 0.86\n",
      "for 2020-07-21, MAE is:2.93 & sMAPE is:8.54% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :3.99 & 15.59% & 0.86\n",
      "for 2020-07-22, MAE is:2.41 & sMAPE is:6.20% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :3.98 & 15.55% & 0.85\n",
      "for 2020-07-23, MAE is:2.20 & sMAPE is:5.44% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :3.97 & 15.50% & 0.85\n",
      "for 2020-07-24, MAE is:4.55 & sMAPE is:12.42% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :3.97 & 15.48% & 0.85\n",
      "for 2020-07-25, MAE is:3.99 & sMAPE is:12.43% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :3.97 & 15.47% & 0.85\n",
      "for 2020-07-26, MAE is:2.37 & sMAPE is:7.87% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :3.97 & 15.43% & 0.85\n",
      "for 2020-07-27, MAE is:2.53 & sMAPE is:6.97% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :3.96 & 15.39% & 0.85\n",
      "for 2020-07-28, MAE is:1.49 & sMAPE is:4.20% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :3.95 & 15.34% & 0.85\n",
      "for 2020-07-29, MAE is:2.22 & sMAPE is:6.24% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :3.94 & 15.29% & 0.85\n",
      "for 2020-07-30, MAE is:2.55 & sMAPE is:6.23% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :3.93 & 15.25% & 0.85\n",
      "for 2020-07-31, MAE is:1.81 & sMAPE is:4.38% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :3.92 & 15.20% & 0.85\n",
      "for 2020-08-01, MAE is:5.32 & sMAPE is:14.90% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :3.93 & 15.20% & 0.85\n",
      "for 2020-08-02, MAE is:3.17 & sMAPE is:10.73% & rMAE is:2.10 ||| daily mean of MAE & sMAPE & rMAE till now are :3.93 & 15.18% & 0.86\n",
      "for 2020-08-03, MAE is:3.22 & sMAPE is:9.00% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :3.92 & 15.15% & 0.86\n",
      "for 2020-08-04, MAE is:2.65 & sMAPE is:7.43% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :3.92 & 15.11% & 0.86\n",
      "for 2020-08-05, MAE is:2.51 & sMAPE is:6.75% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :3.91 & 15.07% & 0.86\n",
      "for 2020-08-06, MAE is:2.69 & sMAPE is:6.92% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :3.90 & 15.04% & 0.86\n",
      "for 2020-08-07, MAE is:2.37 & sMAPE is:6.14% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :3.90 & 15.00% & 0.86\n",
      "for 2020-08-08, MAE is:3.91 & sMAPE is:10.73% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :3.90 & 14.98% & 0.86\n",
      "for 2020-08-09, MAE is:3.61 & sMAPE is:10.53% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :3.90 & 14.96% & 0.86\n",
      "for 2020-08-10, MAE is:2.62 & sMAPE is:7.17% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :3.89 & 14.92% & 0.86\n",
      "for 2020-08-11, MAE is:1.73 & sMAPE is:4.58% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :3.88 & 14.88% & 0.86\n",
      "for 2020-08-12, MAE is:1.51 & sMAPE is:4.00% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :3.87 & 14.83% & 0.86\n",
      "for 2020-08-13, MAE is:2.26 & sMAPE is:5.78% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :3.86 & 14.79% & 0.86\n",
      "for 2020-08-14, MAE is:2.32 & sMAPE is:6.25% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :3.86 & 14.75% & 0.86\n",
      "for 2020-08-15, MAE is:3.56 & sMAPE is:10.90% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :3.86 & 14.73% & 0.86\n",
      "for 2020-08-16, MAE is:2.81 & sMAPE is:8.97% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :3.85 & 14.71% & 0.86\n",
      "for 2020-08-17, MAE is:3.08 & sMAPE is:8.95% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :3.85 & 14.68% & 0.86\n",
      "for 2020-08-18, MAE is:2.44 & sMAPE is:6.51% & rMAE is:2.05 ||| daily mean of MAE & sMAPE & rMAE till now are :3.84 & 14.65% & 0.86\n",
      "for 2020-08-19, MAE is:4.77 & sMAPE is:13.55% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :3.85 & 14.64% & 0.86\n",
      "for 2020-08-20, MAE is:3.24 & sMAPE is:9.48% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :3.84 & 14.62% & 0.86\n",
      "for 2020-08-21, MAE is:4.62 & sMAPE is:13.48% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :3.85 & 14.62% & 0.86\n",
      "for 2020-08-22, MAE is:2.90 & sMAPE is:9.17% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :3.84 & 14.59% & 0.86\n",
      "for 2020-08-23, MAE is:3.94 & sMAPE is:12.98% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :3.84 & 14.59% & 0.87\n",
      "for 2020-08-24, MAE is:6.19 & sMAPE is:17.39% & rMAE is:2.25 ||| daily mean of MAE & sMAPE & rMAE till now are :3.85 & 14.60% & 0.87\n",
      "for 2020-08-25, MAE is:3.32 & sMAPE is:8.32% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :3.85 & 14.57% & 0.87\n",
      "for 2020-08-26, MAE is:2.95 & sMAPE is:7.66% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :3.85 & 14.54% & 0.87\n",
      "for 2020-08-27, MAE is:5.62 & sMAPE is:13.37% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :3.85 & 14.54% & 0.87\n",
      "for 2020-08-28, MAE is:3.73 & sMAPE is:9.47% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :3.85 & 14.52% & 0.87\n",
      "for 2020-08-29, MAE is:4.34 & sMAPE is:14.24% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :3.86 & 14.52% & 0.87\n",
      "for 2020-08-30, MAE is:3.14 & sMAPE is:9.63% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :3.85 & 14.50% & 0.87\n",
      "for 2020-08-31, MAE is:5.56 & sMAPE is:13.78% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :3.86 & 14.49% & 0.87\n",
      "for 2020-09-01, MAE is:3.42 & sMAPE is:7.65% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :3.86 & 14.46% & 0.87\n",
      "for 2020-09-02, MAE is:2.99 & sMAPE is:6.84% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :3.85 & 14.43% & 0.87\n",
      "for 2020-09-03, MAE is:3.40 & sMAPE is:7.47% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :3.85 & 14.41% & 0.87\n",
      "for 2020-09-04, MAE is:4.32 & sMAPE is:10.04% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :3.85 & 14.39% & 0.87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-09-05, MAE is:5.12 & sMAPE is:13.90% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :3.86 & 14.39% & 0.87\n",
      "for 2020-09-06, MAE is:3.27 & sMAPE is:10.16% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :3.86 & 14.37% & 0.87\n",
      "for 2020-09-07, MAE is:3.98 & sMAPE is:10.17% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :3.86 & 14.35% & 0.87\n",
      "for 2020-09-08, MAE is:3.82 & sMAPE is:9.48% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :3.86 & 14.33% & 0.87\n",
      "for 2020-09-09, MAE is:2.61 & sMAPE is:5.99% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :3.85 & 14.30% & 0.87\n",
      "for 2020-09-10, MAE is:2.65 & sMAPE is:6.07% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :3.85 & 14.27% & 0.87\n",
      "for 2020-09-11, MAE is:2.11 & sMAPE is:4.66% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :3.84 & 14.23% & 0.87\n",
      "for 2020-09-12, MAE is:5.25 & sMAPE is:12.39% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :3.85 & 14.22% & 0.87\n",
      "for 2020-09-13, MAE is:6.94 & sMAPE is:18.77% & rMAE is:2.00 ||| daily mean of MAE & sMAPE & rMAE till now are :3.86 & 14.24% & 0.88\n",
      "for 2020-09-14, MAE is:3.65 & sMAPE is:8.61% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :3.86 & 14.22% & 0.88\n",
      "for 2020-09-15, MAE is:3.10 & sMAPE is:6.53% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :3.85 & 14.19% & 0.87\n",
      "for 2020-09-16, MAE is:2.43 & sMAPE is:4.88% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :3.85 & 14.15% & 0.87\n",
      "for 2020-09-17, MAE is:3.92 & sMAPE is:8.77% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :3.85 & 14.13% & 0.88\n",
      "for 2020-09-18, MAE is:4.40 & sMAPE is:10.09% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :3.85 & 14.12% & 0.88\n",
      "for 2020-09-19, MAE is:3.46 & sMAPE is:8.43% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :3.85 & 14.10% & 0.88\n",
      "for 2020-09-20, MAE is:4.01 & sMAPE is:9.90% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :3.85 & 14.08% & 0.88\n",
      "for 2020-09-21, MAE is:4.07 & sMAPE is:8.60% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :3.85 & 14.06% & 0.88\n",
      "for 2020-09-22, MAE is:2.60 & sMAPE is:5.23% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :3.85 & 14.03% & 0.88\n",
      "for 2020-09-23, MAE is:4.30 & sMAPE is:9.44% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :3.85 & 14.01% & 0.88\n",
      "for 2020-09-24, MAE is:7.30 & sMAPE is:17.80% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :3.86 & 14.02% & 0.88\n",
      "for 2020-09-25, MAE is:11.86 & sMAPE is:38.89% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :3.89 & 14.12% & 0.88\n",
      "for 2020-09-26, MAE is:5.42 & sMAPE is:18.24% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :3.90 & 14.13% & 0.88\n",
      "for 2020-09-27, MAE is:5.46 & sMAPE is:22.21% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :3.90 & 14.16% & 0.87\n",
      "for 2020-09-28, MAE is:6.94 & sMAPE is:17.89% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :3.91 & 14.17% & 0.87\n",
      "for 2020-09-29, MAE is:6.01 & sMAPE is:12.88% & rMAE is:1.83 ||| daily mean of MAE & sMAPE & rMAE till now are :3.92 & 14.17% & 0.88\n",
      "for 2020-09-30, MAE is:5.02 & sMAPE is:10.57% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :3.93 & 14.16% & 0.88\n",
      "for 2020-10-01, MAE is:5.17 & sMAPE is:12.68% & rMAE is:1.75 ||| daily mean of MAE & sMAPE & rMAE till now are :3.93 & 14.15% & 0.88\n",
      "for 2020-10-02, MAE is:7.45 & sMAPE is:27.35% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :3.94 & 14.20% & 0.88\n",
      "for 2020-10-03, MAE is:6.36 & sMAPE is:32.32% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :3.95 & 14.26% & 0.88\n",
      "for 2020-10-04, MAE is:11.58 & sMAPE is:68.99% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :3.98 & 14.46% & 0.88\n",
      "for 2020-10-05, MAE is:13.27 & sMAPE is:45.72% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.01 & 14.57% & 0.89\n",
      "for 2020-10-06, MAE is:4.39 & sMAPE is:11.22% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :4.01 & 14.56% & 0.89\n",
      "for 2020-10-07, MAE is:3.79 & sMAPE is:9.04% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.01 & 14.54% & 0.88\n",
      "for 2020-10-08, MAE is:4.36 & sMAPE is:10.03% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :4.01 & 14.53% & 0.88\n",
      "for 2020-10-09, MAE is:4.18 & sMAPE is:9.82% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :4.01 & 14.51% & 0.88\n",
      "for 2020-10-10, MAE is:3.31 & sMAPE is:9.89% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :4.01 & 14.49% & 0.88\n",
      "for 2020-10-11, MAE is:3.85 & sMAPE is:13.81% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :4.01 & 14.49% & 0.88\n",
      "for 2020-10-12, MAE is:5.55 & sMAPE is:15.69% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :4.02 & 14.49% & 0.88\n",
      "for 2020-10-13, MAE is:5.41 & sMAPE is:13.28% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :4.02 & 14.49% & 0.88\n",
      "for 2020-10-14, MAE is:6.34 & sMAPE is:17.09% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :4.03 & 14.50% & 0.88\n",
      "for 2020-10-15, MAE is:3.43 & sMAPE is:8.72% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :4.03 & 14.48% & 0.88\n",
      "for 2020-10-16, MAE is:3.99 & sMAPE is:9.45% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :4.03 & 14.46% & 0.88\n",
      "for 2020-10-17, MAE is:4.03 & sMAPE is:9.87% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.03 & 14.45% & 0.88\n",
      "for 2020-10-18, MAE is:3.54 & sMAPE is:9.07% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :4.03 & 14.43% & 0.88\n",
      "for 2020-10-19, MAE is:7.85 & sMAPE is:21.83% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 14.45% & 0.88\n",
      "for 2020-10-20, MAE is:4.35 & sMAPE is:12.18% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 14.44% & 0.88\n",
      "for 2020-10-21, MAE is:8.03 & sMAPE is:24.04% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :4.05 & 14.48% & 0.88\n",
      "for 2020-10-22, MAE is:3.63 & sMAPE is:8.41% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :4.05 & 14.46% & 0.88\n",
      "for 2020-10-23, MAE is:3.68 & sMAPE is:8.20% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :4.05 & 14.44% & 0.88\n",
      "for 2020-10-24, MAE is:8.09 & sMAPE is:22.97% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :4.06 & 14.46% & 0.88\n",
      "for 2020-10-25, MAE is:11.17 & sMAPE is:73.32% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :4.09 & 14.66% & 0.88\n",
      "for 2020-10-26, MAE is:7.62 & sMAPE is:26.74% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :4.10 & 14.70% & 0.88\n",
      "for 2020-10-27, MAE is:4.74 & sMAPE is:12.13% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :4.10 & 14.69% & 0.88\n",
      "for 2020-10-28, MAE is:7.17 & sMAPE is:17.74% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :4.11 & 14.70% & 0.88\n",
      "for 2020-10-29, MAE is:3.19 & sMAPE is:7.08% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :4.11 & 14.68% & 0.88\n",
      "for 2020-10-30, MAE is:4.76 & sMAPE is:11.27% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :4.11 & 14.67% & 0.88\n",
      "for 2020-10-31, MAE is:6.04 & sMAPE is:15.82% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :4.12 & 14.67% & 0.88\n",
      "for 2020-11-01, MAE is:2.78 & sMAPE is:8.53% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :4.11 & 14.65% & 0.88\n",
      "for 2020-11-02, MAE is:4.11 & sMAPE is:10.44% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.11 & 14.64% & 0.87\n",
      "for 2020-11-03, MAE is:3.55 & sMAPE is:8.88% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :4.11 & 14.62% & 0.88\n",
      "for 2020-11-04, MAE is:5.48 & sMAPE is:14.76% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :4.12 & 14.62% & 0.88\n",
      "for 2020-11-05, MAE is:3.39 & sMAPE is:10.94% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.11 & 14.61% & 0.87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-11-06, MAE is:5.01 & sMAPE is:13.90% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :4.12 & 14.60% & 0.87\n",
      "for 2020-11-07, MAE is:4.60 & sMAPE is:15.45% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.12 & 14.61% & 0.88\n",
      "for 2020-11-08, MAE is:3.88 & sMAPE is:12.51% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :4.12 & 14.60% & 0.88\n",
      "for 2020-11-09, MAE is:6.87 & sMAPE is:15.94% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :4.13 & 14.60% & 0.88\n",
      "for 2020-11-10, MAE is:4.78 & sMAPE is:9.97% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.13 & 14.59% & 0.88\n",
      "for 2020-11-11, MAE is:5.56 & sMAPE is:12.02% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :4.13 & 14.58% & 0.88\n",
      "for 2020-11-12, MAE is:2.98 & sMAPE is:6.53% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :4.13 & 14.56% & 0.88\n",
      "for 2020-11-13, MAE is:3.09 & sMAPE is:6.97% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :4.13 & 14.53% & 0.87\n",
      "for 2020-11-14, MAE is:3.10 & sMAPE is:7.72% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :4.12 & 14.51% & 0.87\n",
      "for 2020-11-15, MAE is:9.99 & sMAPE is:42.50% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :4.14 & 14.60% & 0.87\n",
      "for 2020-11-16, MAE is:2.88 & sMAPE is:7.31% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :4.14 & 14.58% & 0.87\n",
      "for 2020-11-17, MAE is:3.41 & sMAPE is:7.96% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :4.13 & 14.56% & 0.87\n",
      "for 2020-11-18, MAE is:3.86 & sMAPE is:9.37% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :4.13 & 14.54% & 0.87\n",
      "for 2020-11-19, MAE is:7.07 & sMAPE is:16.80% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :4.14 & 14.55% & 0.87\n",
      "for 2020-11-20, MAE is:3.29 & sMAPE is:8.42% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :4.14 & 14.53% & 0.87\n",
      "for 2020-11-21, MAE is:3.67 & sMAPE is:8.95% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :4.14 & 14.51% & 0.87\n",
      "for 2020-11-22, MAE is:3.54 & sMAPE is:8.37% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :4.14 & 14.49% & 0.87\n",
      "for 2020-11-23, MAE is:4.17 & sMAPE is:8.72% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :4.14 & 14.47% & 0.87\n",
      "for 2020-11-24, MAE is:4.18 & sMAPE is:8.97% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :4.14 & 14.46% & 0.87\n",
      "for 2020-11-25, MAE is:7.35 & sMAPE is:16.07% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :4.15 & 14.46% & 0.87\n",
      "for 2020-11-26, MAE is:4.60 & sMAPE is:9.82% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :4.15 & 14.45% & 0.87\n",
      "for 2020-11-27, MAE is:5.63 & sMAPE is:11.13% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.15 & 14.44% & 0.87\n",
      "for 2020-11-28, MAE is:2.67 & sMAPE is:5.63% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :4.15 & 14.41% & 0.87\n",
      "for 2020-11-29, MAE is:3.30 & sMAPE is:7.05% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :4.15 & 14.39% & 0.87\n",
      "for 2020-11-30, MAE is:4.77 & sMAPE is:9.51% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :4.15 & 14.38% & 0.87\n",
      "for 2020-12-01, MAE is:5.77 & sMAPE is:11.68% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :4.15 & 14.37% & 0.87\n",
      "for 2020-12-02, MAE is:6.04 & sMAPE is:11.86% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :4.16 & 14.36% & 0.87\n",
      "for 2020-12-03, MAE is:6.08 & sMAPE is:12.27% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :4.16 & 14.35% & 0.87\n",
      "for 2020-12-04, MAE is:7.69 & sMAPE is:18.45% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :4.17 & 14.37% & 0.87\n",
      "for 2020-12-05, MAE is:2.75 & sMAPE is:6.05% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :4.17 & 14.34% & 0.87\n",
      "for 2020-12-06, MAE is:6.07 & sMAPE is:14.97% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :4.18 & 14.34% & 0.87\n",
      "for 2020-12-07, MAE is:7.74 & sMAPE is:18.60% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 14.36% & 0.87\n",
      "for 2020-12-08, MAE is:12.52 & sMAPE is:60.60% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :4.21 & 14.49% & 0.87\n",
      "for 2020-12-09, MAE is:5.49 & sMAPE is:11.06% & rMAE is:1.77 ||| daily mean of MAE & sMAPE & rMAE till now are :4.21 & 14.48% & 0.87\n",
      "for 2020-12-10, MAE is:3.12 & sMAPE is:7.58% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :4.21 & 14.46% & 0.87\n",
      "for 2020-12-11, MAE is:8.67 & sMAPE is:22.05% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :4.22 & 14.48% & 0.87\n",
      "for 2020-12-12, MAE is:5.59 & sMAPE is:17.27% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :4.23 & 14.49% & 0.87\n",
      "for 2020-12-13, MAE is:2.34 & sMAPE is:5.36% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.22 & 14.46% & 0.87\n",
      "for 2020-12-14, MAE is:4.04 & sMAPE is:9.35% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.22 & 14.45% & 0.87\n",
      "for 2020-12-15, MAE is:4.81 & sMAPE is:10.53% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :4.22 & 14.44% & 0.87\n",
      "for 2020-12-16, MAE is:4.97 & sMAPE is:10.26% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :4.23 & 14.43% & 0.87\n",
      "for 2020-12-17, MAE is:4.65 & sMAPE is:8.34% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :4.23 & 14.41% & 0.87\n",
      "for 2020-12-18, MAE is:5.91 & sMAPE is:12.14% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :4.23 & 14.40% & 0.87\n",
      "for 2020-12-19, MAE is:6.46 & sMAPE is:15.24% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :4.24 & 14.40% & 0.87\n",
      "for 2020-12-20, MAE is:3.70 & sMAPE is:8.32% & rMAE is:1.95 ||| daily mean of MAE & sMAPE & rMAE till now are :4.24 & 14.39% & 0.87\n",
      "for 2020-12-21, MAE is:3.86 & sMAPE is:8.66% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :4.24 & 14.37% & 0.87\n",
      "for 2020-12-22, MAE is:2.98 & sMAPE is:6.48% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :4.23 & 14.35% & 0.87\n",
      "for 2020-12-23, MAE is:3.03 & sMAPE is:6.72% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :4.23 & 14.33% & 0.87\n",
      "for 2020-12-24, MAE is:5.20 & sMAPE is:12.71% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.23 & 14.32% & 0.87\n",
      "for 2020-12-25, MAE is:15.89 & sMAPE is:77.73% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :4.26 & 14.50% & 0.87\n",
      "for 2020-12-26, MAE is:11.56 & sMAPE is:43.22% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :4.28 & 14.58% & 0.87\n",
      "for 2020-12-27, MAE is:13.79 & sMAPE is:39.80% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :4.31 & 14.65% & 0.87\n",
      "for 2020-12-28, MAE is:10.18 & sMAPE is:62.78% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 14.78% & 0.87\n",
      "for 2020-12-29, MAE is:5.80 & sMAPE is:15.63% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 14.78% & 0.87\n",
      "for 2020-12-30, MAE is:6.16 & sMAPE is:12.92% & rMAE is:2.16 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 14.78% & 0.87\n",
      "for 2020-12-31, MAE is:6.90 & sMAPE is:14.88% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 14.78% & 0.87\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\1 - Consolidated Data\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 03:52:52,028]\u001b[0m A new study created in RDB with name: PT_2021\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:53:09,348]\u001b[0m Trial 2 finished with value: 8.73987225588318 and parameters: {'n_hidden': 4, 'learning_rate': 0.0033450996337420105, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19509508375107762, 'dropout_rate_Layer_2': 0.15694067119098737, 'dropout_rate_Layer_3': 0.10090338231456492, 'dropout_rate_Layer_4': 0.20831937146950175, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.009356515833378135, 'l1_Layer_2': 0.0008467017320802642, 'l1_Layer_3': 4.504524597584865e-05, 'l1_Layer_4': 0.011491000491968037, 'n_units_Layer_1': 65, 'n_units_Layer_2': 140, 'n_units_Layer_3': 265, 'n_units_Layer_4': 190}. Best is trial 2 with value: 8.73987225588318.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.74 | sMAPE for Validation Set is: 27.94% | rMAE for Validation Set is: 1.31\n",
      "MAE for Test Set is: 69.42 | sMAPE for Test Set is: 72.28% | rMAE for Test Set is: 2.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 03:53:14,284]\u001b[0m Trial 1 finished with value: 12.861798256136467 and parameters: {'n_hidden': 3, 'learning_rate': 0.08875507895868619, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2558464389144141, 'dropout_rate_Layer_2': 0.24915274004609805, 'dropout_rate_Layer_3': 0.22257257954350648, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.039443362680674054, 'l1_Layer_2': 0.0007828495614770806, 'l1_Layer_3': 0.028278625861834106, 'n_units_Layer_1': 175, 'n_units_Layer_2': 165, 'n_units_Layer_3': 110}. Best is trial 2 with value: 8.73987225588318.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.86 | sMAPE for Validation Set is: 36.83% | rMAE for Validation Set is: 1.93\n",
      "MAE for Test Set is: 66.20 | sMAPE for Test Set is: 68.37% | rMAE for Test Set is: 2.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 03:53:19,942]\u001b[0m Trial 3 finished with value: 4.098079034841327 and parameters: {'n_hidden': 3, 'learning_rate': 0.005054954807766037, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25938997046654244, 'dropout_rate_Layer_2': 0.2957722729444567, 'dropout_rate_Layer_3': 0.3880031949132216, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.916807120767241e-05, 'l1_Layer_2': 0.0010249309349882362, 'l1_Layer_3': 0.00034485131323302255, 'n_units_Layer_1': 300, 'n_units_Layer_2': 215, 'n_units_Layer_3': 115}. Best is trial 3 with value: 4.098079034841327.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.10 | sMAPE for Validation Set is: 14.61% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 55.94 | sMAPE for Test Set is: 52.43% | rMAE for Test Set is: 2.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 03:53:24,552]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:53:24,927]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:53:34,101]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:53:41,903]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:53:45,410]\u001b[0m Trial 5 finished with value: 9.199076026679196 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005709553973370053, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38452032289060173, 'dropout_rate_Layer_2': 0.23421589585068592, 'dropout_rate_Layer_3': 0.07113195083235349, 'dropout_rate_Layer_4': 0.12423738238275997, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0001411331020715222, 'l1_Layer_2': 0.001330204027921659, 'l1_Layer_3': 0.0017370437325212869, 'l1_Layer_4': 0.006592540755889618, 'n_units_Layer_1': 240, 'n_units_Layer_2': 300, 'n_units_Layer_3': 290, 'n_units_Layer_4': 65}. Best is trial 3 with value: 4.098079034841327.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.20 | sMAPE for Validation Set is: 29.17% | rMAE for Validation Set is: 1.38\n",
      "MAE for Test Set is: 81.44 | sMAPE for Test Set is: 94.01% | rMAE for Test Set is: 3.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 03:53:45,840]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:53:49,763]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:53:51,268]\u001b[0m Trial 0 finished with value: 4.598074000156246 and parameters: {'n_hidden': 3, 'learning_rate': 0.0038958600508291956, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11697253124397906, 'dropout_rate_Layer_2': 0.2677950414597476, 'dropout_rate_Layer_3': 0.27569403592003866, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0528332645925693, 'l1_Layer_2': 0.010239103962352837, 'l1_Layer_3': 1.8161148663486968e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 60, 'n_units_Layer_3': 110}. Best is trial 3 with value: 4.098079034841327.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.60 | sMAPE for Validation Set is: 15.88% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 50.80 | sMAPE for Test Set is: 46.58% | rMAE for Test Set is: 2.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 03:53:52,314]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:53:54,998]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:53:59,105]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:54:01,448]\u001b[0m Trial 7 finished with value: 4.971815679978747 and parameters: {'n_hidden': 4, 'learning_rate': 0.011720379212292447, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3651685941352993, 'dropout_rate_Layer_2': 0.013439761355401814, 'dropout_rate_Layer_3': 0.095741612893994, 'dropout_rate_Layer_4': 0.361448214456072, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.020359730405106174, 'l1_Layer_2': 0.008570489073878104, 'l1_Layer_3': 0.0073968065132922044, 'l1_Layer_4': 3.790157745366426e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 205, 'n_units_Layer_3': 215, 'n_units_Layer_4': 125}. Best is trial 3 with value: 4.098079034841327.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.97 | sMAPE for Validation Set is: 16.91% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 54.98 | sMAPE for Test Set is: 51.60% | rMAE for Test Set is: 2.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 03:54:03,932]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:54:09,868]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:54:12,321]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:54:16,523]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:54:20,971]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:54:24,221]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:54:28,452]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:54:32,968]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:54:33,536]\u001b[0m Trial 13 finished with value: 4.1192791068874905 and parameters: {'n_hidden': 3, 'learning_rate': 0.002624993811371163, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15847962297798848, 'dropout_rate_Layer_2': 0.2500290626408006, 'dropout_rate_Layer_3': 0.2202710928042972, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.011744157546299226, 'l1_Layer_2': 1.5114246803229164e-05, 'l1_Layer_3': 2.6599018834658348e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 260, 'n_units_Layer_3': 135}. Best is trial 3 with value: 4.098079034841327.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.12 | sMAPE for Validation Set is: 14.45% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 51.78 | sMAPE for Test Set is: 47.70% | rMAE for Test Set is: 2.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 03:54:39,106]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:54:39,372]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:54:45,773]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:54:46,080]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:54:52,205]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:54:53,111]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:54:54,616]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:54:58,445]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:55:02,589]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:55:03,114]\u001b[0m Trial 20 finished with value: 4.171875184416882 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008431651489050878, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39096965754792906, 'dropout_rate_Layer_2': 0.19603195400984422, 'dropout_rate_Layer_3': 0.03966452655689601, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003481477312875389, 'l1_Layer_2': 0.07457301987151321, 'l1_Layer_3': 1.6623692851374353e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 105, 'n_units_Layer_3': 285}. Best is trial 3 with value: 4.098079034841327.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.17 | sMAPE for Validation Set is: 14.50% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 14.77 | sMAPE for Test Set is: 19.47% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 03:55:03,255]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:55:03,704]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:55:12,514]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:55:17,585]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:55:20,857]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:55:21,901]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:55:28,396]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:55:33,471]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:55:35,470]\u001b[0m Trial 42 finished with value: 4.794644423576007 and parameters: {'n_hidden': 3, 'learning_rate': 0.012726980106617354, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08025534221352332, 'dropout_rate_Layer_2': 0.1765487984263884, 'dropout_rate_Layer_3': 0.010866016508278743, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.024259777086033753, 'l1_Layer_2': 0.0003014692184520055, 'l1_Layer_3': 0.00011860052914262212, 'n_units_Layer_1': 95, 'n_units_Layer_2': 190, 'n_units_Layer_3': 295}. Best is trial 3 with value: 4.098079034841327.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.79 | sMAPE for Validation Set is: 16.57% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 45.95 | sMAPE for Test Set is: 41.86% | rMAE for Test Set is: 1.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 03:55:39,564]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:55:41,948]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:55:44,974]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:55:45,020]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:55:45,340]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:55:50,499]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:55:52,478]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:55:53,220]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:55:53,760]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:55:57,452]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:56:01,760]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:56:03,954]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:56:04,649]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:56:07,224]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:56:11,490]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:56:11,689]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:56:17,672]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:56:25,721]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:56:29,512]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:56:40,407]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:56:43,780]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:56:43,925]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:56:44,569]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:56:50,638]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:56:50,722]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:56:52,077]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:56:52,494]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:56:57,737]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:56:59,063]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:57:05,666]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:57:05,941]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:57:08,181]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:57:14,825]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:57:15,154]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:57:17,926]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:57:20,681]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:57:23,340]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:57:27,213]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:57:28,029]\u001b[0m Trial 75 finished with value: 5.428748463326952 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028357358536361694, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3472601013015176, 'dropout_rate_Layer_2': 0.13061485286436442, 'dropout_rate_Layer_3': 0.22539364830153563, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0067710493343877435, 'l1_Layer_2': 0.010274986487481465, 'l1_Layer_3': 0.0017068834088676435, 'n_units_Layer_1': 210, 'n_units_Layer_2': 60, 'n_units_Layer_3': 300}. Best is trial 3 with value: 4.098079034841327.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.43 | sMAPE for Validation Set is: 18.74% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 56.21 | sMAPE for Test Set is: 53.31% | rMAE for Test Set is: 2.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 03:57:28,557]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:57:35,147]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:57:35,361]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:57:36,248]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:57:45,892]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:57:48,072]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:57:48,454]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:57:52,934]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:57:56,619]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:57:59,575]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:57:59,777]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:58:03,664]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:58:09,608]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:58:12,928]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:58:27,581]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:58:32,923]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:58:46,234]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:58:46,612]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:58:48,102]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:58:52,578]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:58:55,364]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:58:55,665]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:58:55,701]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:58:57,059]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:59:02,442]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:59:05,101]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:59:05,332]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:59:07,988]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:59:09,001]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:59:12,527]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:59:14,050]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:59:18,750]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:59:22,040]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:59:26,207]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:59:29,003]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:59:31,874]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:59:33,654]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:59:34,995]\u001b[0m Trial 117 finished with value: 5.60635855414409 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036660945533118243, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1257296597019899, 'dropout_rate_Layer_2': 0.38612479544122563, 'dropout_rate_Layer_3': 0.1100734302040243, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.005136731393901292, 'l1_Layer_2': 0.0036889625596343645, 'l1_Layer_3': 0.00013847373400644185, 'n_units_Layer_1': 230, 'n_units_Layer_2': 215, 'n_units_Layer_3': 295}. Best is trial 3 with value: 4.098079034841327.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.61 | sMAPE for Validation Set is: 19.47% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 56.50 | sMAPE for Test Set is: 53.58% | rMAE for Test Set is: 2.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 03:59:36,736]\u001b[0m Trial 113 finished with value: 5.283561962042678 and parameters: {'n_hidden': 3, 'learning_rate': 0.003093279861539227, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2793235579364293, 'dropout_rate_Layer_2': 0.16303398648109746, 'dropout_rate_Layer_3': 0.20338723289443877, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000668284108460918, 'l1_Layer_2': 0.0070959022795762695, 'l1_Layer_3': 0.002016689256340035, 'n_units_Layer_1': 190, 'n_units_Layer_2': 125, 'n_units_Layer_3': 255}. Best is trial 3 with value: 4.098079034841327.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.28 | sMAPE for Validation Set is: 18.58% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 58.75 | sMAPE for Test Set is: 56.45% | rMAE for Test Set is: 2.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 03:59:38,760]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:59:44,662]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:59:44,869]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:59:45,643]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:59:52,738]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:59:54,569]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 03:59:56,747]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:00:00,428]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:00:02,430]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:00:04,703]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:00:11,554]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:00:15,927]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:00:17,826]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.80 | sMAPE for Validation Set is: 16.23% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 59.19 | sMAPE for Test Set is: 56.84% | rMAE for Test Set is: 2.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:00:19,154]\u001b[0m Trial 123 finished with value: 4.7972249007424255 and parameters: {'n_hidden': 3, 'learning_rate': 0.006286247836664349, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3361972491210026, 'dropout_rate_Layer_2': 0.13223352733489993, 'dropout_rate_Layer_3': 0.24014845409751812, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00032773662006380913, 'l1_Layer_2': 0.0017188405716913738, 'l1_Layer_3': 0.0020549444571395787, 'n_units_Layer_1': 200, 'n_units_Layer_2': 180, 'n_units_Layer_3': 240}. Best is trial 3 with value: 4.098079034841327.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:00:23,211]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:00:25,923]\u001b[0m Trial 136 finished with value: 9.294314209159706 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030806647038471337, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3919674364335143, 'dropout_rate_Layer_2': 0.3153980934832211, 'dropout_rate_Layer_3': 0.39521262673553953, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.004475530758133013, 'l1_Layer_2': 1.3079235225237068e-05, 'l1_Layer_3': 0.000263952012350105, 'n_units_Layer_1': 230, 'n_units_Layer_2': 300, 'n_units_Layer_3': 210}. Best is trial 3 with value: 4.098079034841327.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.29 | sMAPE for Validation Set is: 29.64% | rMAE for Validation Set is: 1.40\n",
      "MAE for Test Set is: 83.55 | sMAPE for Test Set is: 98.52% | rMAE for Test Set is: 3.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:00:29,647]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:00:33,709]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:00:41,644]\u001b[0m Trial 138 finished with value: 4.279398996325256 and parameters: {'n_hidden': 3, 'learning_rate': 0.003017411328146276, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10577289220528535, 'dropout_rate_Layer_2': 0.31390633655058753, 'dropout_rate_Layer_3': 0.39916667808808526, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.004421110650524345, 'l1_Layer_2': 1.6264823061011685e-05, 'l1_Layer_3': 0.00018633911603724708, 'n_units_Layer_1': 230, 'n_units_Layer_2': 285, 'n_units_Layer_3': 300}. Best is trial 3 with value: 4.098079034841327.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.28 | sMAPE for Validation Set is: 14.65% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 55.31 | sMAPE for Test Set is: 51.86% | rMAE for Test Set is: 2.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:00:45,486]\u001b[0m Trial 133 finished with value: 4.10726901032245 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015885959869699243, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01608274653237189, 'dropout_rate_Layer_2': 0.1604471353410296, 'dropout_rate_Layer_3': 0.025421703261562414, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0071772011183226705, 'l1_Layer_2': 0.00048398506666409453, 'l1_Layer_3': 3.289450351805431e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 240, 'n_units_Layer_3': 300}. Best is trial 3 with value: 4.098079034841327.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.11 | sMAPE for Validation Set is: 14.71% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 48.08 | sMAPE for Test Set is: 43.85% | rMAE for Test Set is: 1.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:00:49,201]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:00:51,653]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:00:55,421]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:01:01,171]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:01:08,121]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:01:10,803]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:01:14,166]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:01:14,518]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:01:20,879]\u001b[0m Trial 139 finished with value: 3.9521373206548582 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017344335515029651, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0014639826678128855, 'dropout_rate_Layer_2': 0.1395335368909728, 'dropout_rate_Layer_3': 0.020427722474841814, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008366884318798076, 'l1_Layer_2': 0.0005070888399515074, 'l1_Layer_3': 2.4922308322595854e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 240, 'n_units_Layer_3': 300}. Best is trial 139 with value: 3.9521373206548582.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.95 | sMAPE for Validation Set is: 14.12% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 45.71 | sMAPE for Test Set is: 41.08% | rMAE for Test Set is: 1.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:01:21,045]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:01:25,477]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:01:28,926]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:01:29,135]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:01:34,808]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:01:38,089]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:01:38,140]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:01:42,958]\u001b[0m Trial 158 finished with value: 8.227493759498843 and parameters: {'n_hidden': 3, 'learning_rate': 0.0705718033715454, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09170003980082922, 'dropout_rate_Layer_2': 0.27893955476646615, 'dropout_rate_Layer_3': 0.3330864023124641, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 9.28891154681063e-05, 'l1_Layer_2': 1.2928820633049503e-05, 'l1_Layer_3': 0.0017021075565319267, 'n_units_Layer_1': 225, 'n_units_Layer_2': 300, 'n_units_Layer_3': 55}. Best is trial 139 with value: 3.9521373206548582.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.23 | sMAPE for Validation Set is: 25.50% | rMAE for Validation Set is: 1.24\n",
      "MAE for Test Set is: 66.52 | sMAPE for Test Set is: 67.48% | rMAE for Test Set is: 2.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:01:43,643]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:01:43,692]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:01:46,303]\u001b[0m Trial 150 finished with value: 4.3445662444370585 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018348495769263645, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3660976187012616, 'dropout_rate_Layer_2': 0.11376043885538949, 'dropout_rate_Layer_3': 0.22593083781563106, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00019221437416654517, 'l1_Layer_2': 0.010919825152309477, 'l1_Layer_3': 0.002286138114183845, 'n_units_Layer_1': 155, 'n_units_Layer_2': 110, 'n_units_Layer_3': 250}. Best is trial 139 with value: 3.9521373206548582.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.34 | sMAPE for Validation Set is: 15.44% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 15.91 | sMAPE for Test Set is: 20.07% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:01:52,578]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:01:58,303]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:02:00,289]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:02:04,166]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:02:05,911]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:02:09,585]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:02:16,251]\u001b[0m Trial 166 finished with value: 4.473319925128472 and parameters: {'n_hidden': 3, 'learning_rate': 0.001799014475496707, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07891879388706491, 'dropout_rate_Layer_2': 0.16279760394192208, 'dropout_rate_Layer_3': 0.2664729252042314, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0006842194775748283, 'l1_Layer_2': 4.37011724370751e-05, 'l1_Layer_3': 8.443756856118726e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 255, 'n_units_Layer_3': 300}. Best is trial 139 with value: 3.9521373206548582.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.47 | sMAPE for Validation Set is: 15.76% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 55.24 | sMAPE for Test Set is: 51.63% | rMAE for Test Set is: 2.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:02:16,678]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:02:18,796]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:02:23,496]\u001b[0m Trial 164 finished with value: 4.990108015216271 and parameters: {'n_hidden': 3, 'learning_rate': 0.001568616931467351, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3434505279609666, 'dropout_rate_Layer_2': 0.14888563498833138, 'dropout_rate_Layer_3': 0.2103335891322111, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.011911788448102579, 'l1_Layer_2': 0.004699041266803242, 'l1_Layer_3': 0.00216550086908534, 'n_units_Layer_1': 145, 'n_units_Layer_2': 115, 'n_units_Layer_3': 245}. Best is trial 139 with value: 3.9521373206548582.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.99 | sMAPE for Validation Set is: 17.52% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 19.02 | sMAPE for Test Set is: 22.78% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:02:27,944]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:02:28,035]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:02:34,223]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:02:34,724]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:02:35,572]\u001b[0m Trial 171 finished with value: 4.408699189523025 and parameters: {'n_hidden': 3, 'learning_rate': 0.005700680034302424, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16357171701160625, 'dropout_rate_Layer_2': 0.33223961806548513, 'dropout_rate_Layer_3': 0.34910920075826374, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0013817656113533975, 'l1_Layer_2': 0.0018190786385264667, 'l1_Layer_3': 0.0006647739774346757, 'n_units_Layer_1': 255, 'n_units_Layer_2': 220, 'n_units_Layer_3': 135}. Best is trial 139 with value: 3.9521373206548582.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.41 | sMAPE for Validation Set is: 15.58% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 57.35 | sMAPE for Test Set is: 54.34% | rMAE for Test Set is: 2.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:02:43,682]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:02:47,856]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:02:50,519]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:02:50,974]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:02:55,825]\u001b[0m Trial 173 finished with value: 4.090945543255536 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023124263623718836, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1415364594555256, 'dropout_rate_Layer_2': 0.30151299057973935, 'dropout_rate_Layer_3': 0.013286530159502024, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0077191923435017025, 'l1_Layer_2': 0.03527316378296661, 'l1_Layer_3': 1.9274872029190078e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 85, 'n_units_Layer_3': 275}. Best is trial 139 with value: 3.9521373206548582.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.09 | sMAPE for Validation Set is: 14.21% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 53.91 | sMAPE for Test Set is: 50.32% | rMAE for Test Set is: 2.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:02:57,179]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:03:01,043]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:03:03,822]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:03:05,716]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:03:06,940]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:03:11,175]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:03:13,226]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:03:15,087]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:03:17,493]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:03:20,205]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:03:21,361]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:03:26,832]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:03:27,327]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:03:46,026]\u001b[0m Trial 193 finished with value: 4.315064482434326 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015300659291121264, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25541146381441937, 'dropout_rate_Layer_2': 0.2667786503465943, 'dropout_rate_Layer_3': 0.3961245431337802, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.01163928312219653, 'l1_Layer_2': 4.1230992251898624e-05, 'l1_Layer_3': 0.00010170655470628827, 'n_units_Layer_1': 200, 'n_units_Layer_2': 275, 'n_units_Layer_3': 260}. Best is trial 139 with value: 3.9521373206548582.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.32 | sMAPE for Validation Set is: 15.36% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 59.03 | sMAPE for Test Set is: 56.58% | rMAE for Test Set is: 2.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:03:49,374]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:03:49,795]\u001b[0m Trial 197 finished with value: 4.408246771556532 and parameters: {'n_hidden': 3, 'learning_rate': 0.003209611263385033, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3483558941820716, 'dropout_rate_Layer_2': 0.10634616568607952, 'dropout_rate_Layer_3': 0.039632505972357526, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.005183725252365207, 'l1_Layer_2': 0.024572695994974865, 'l1_Layer_3': 4.5922871998564723e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 120, 'n_units_Layer_3': 200}. Best is trial 139 with value: 3.9521373206548582.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.41 | sMAPE for Validation Set is: 15.66% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 54.45 | sMAPE for Test Set is: 50.94% | rMAE for Test Set is: 2.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:03:54,298]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:03:54,685]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:03:56,742]\u001b[0m Trial 182 finished with value: 4.472624805941002 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010829214594499142, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1268436719093441, 'dropout_rate_Layer_2': 0.3103819794727877, 'dropout_rate_Layer_3': 0.1302459826211588, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.003968498082872809, 'l1_Layer_2': 0.03525444445067027, 'l1_Layer_3': 0.0002859916759031791, 'n_units_Layer_1': 220, 'n_units_Layer_2': 90, 'n_units_Layer_3': 225}. Best is trial 139 with value: 3.9521373206548582.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.47 | sMAPE for Validation Set is: 15.93% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 53.93 | sMAPE for Test Set is: 50.33% | rMAE for Test Set is: 2.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:03:59,560]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:04:02,658]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:04:06,993]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:04:07,601]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:04:08,050]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:04:12,127]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:04:16,815]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:04:18,667]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:04:19,739]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:04:21,697]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:04:26,132]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:04:30,577]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:04:31,281]\u001b[0m Trial 201 finished with value: 4.316132462671097 and parameters: {'n_hidden': 3, 'learning_rate': 0.006343525662740179, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12670074755116206, 'dropout_rate_Layer_2': 0.29221195960540236, 'dropout_rate_Layer_3': 0.3202864000700325, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.5457977662155546e-05, 'l1_Layer_2': 0.001573906809325986, 'l1_Layer_3': 0.0012000247747488584, 'n_units_Layer_1': 245, 'n_units_Layer_2': 215, 'n_units_Layer_3': 185}. Best is trial 139 with value: 3.9521373206548582.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.32 | sMAPE for Validation Set is: 15.50% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 60.78 | sMAPE for Test Set is: 58.81% | rMAE for Test Set is: 2.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:04:34,560]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:04:38,295]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:04:38,658]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:04:40,359]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:04:47,095]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:04:48,414]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:04:51,006]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:04:54,031]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:04:55,600]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:04:59,122]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:05:01,369]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:05:05,986]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:05:06,349]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:05:11,540]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:05:16,070]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:05:19,262]\u001b[0m Trial 225 finished with value: 5.060940684271611 and parameters: {'n_hidden': 3, 'learning_rate': 0.007473656112557765, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09819511460052988, 'dropout_rate_Layer_2': 0.16947215827775122, 'dropout_rate_Layer_3': 0.2789214730932983, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000642401674492379, 'l1_Layer_2': 0.009349142721094949, 'l1_Layer_3': 4.102354636121994e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 170, 'n_units_Layer_3': 255}. Best is trial 139 with value: 3.9521373206548582.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.06 | sMAPE for Validation Set is: 17.68% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 51.53 | sMAPE for Test Set is: 47.47% | rMAE for Test Set is: 2.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:05:23,795]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:05:27,204]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:05:27,504]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:05:27,662]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:05:28,820]\u001b[0m Trial 218 finished with value: 4.003364817460819 and parameters: {'n_hidden': 3, 'learning_rate': 0.001533570973880225, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.012403696715285241, 'dropout_rate_Layer_2': 0.156880367113727, 'dropout_rate_Layer_3': 0.03372585138523156, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008509724348049209, 'l1_Layer_2': 0.000483037537407832, 'l1_Layer_3': 2.8918939268616538e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 235, 'n_units_Layer_3': 300}. Best is trial 139 with value: 3.9521373206548582.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.00 | sMAPE for Validation Set is: 14.32% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 44.92 | sMAPE for Test Set is: 40.27% | rMAE for Test Set is: 1.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:05:35,412]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:05:35,612]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:05:36,306]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:05:41,741]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:05:43,716]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:05:45,373]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:05:47,174]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:05:49,868]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:05:54,202]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:05:55,808]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:05:59,631]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:05:59,696]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:06:00,072]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:06:01,555]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:06:07,615]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:06:09,661]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:06:09,833]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:06:15,992]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:06:21,164]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:06:21,360]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:06:26,889]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:06:27,755]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:06:30,552]\u001b[0m Trial 249 finished with value: 4.339540429774987 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013294587113989859, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24565545867144137, 'dropout_rate_Layer_2': 0.24076550408129532, 'dropout_rate_Layer_3': 0.3730554993942368, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.011342014894844208, 'l1_Layer_2': 3.158519534819367e-05, 'l1_Layer_3': 6.578427938508044e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 280, 'n_units_Layer_3': 275}. Best is trial 139 with value: 3.9521373206548582.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.34 | sMAPE for Validation Set is: 15.60% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 57.42 | sMAPE for Test Set is: 54.57% | rMAE for Test Set is: 2.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:06:34,184]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:06:37,469]\u001b[0m Trial 253 finished with value: 4.120407479108209 and parameters: {'n_hidden': 3, 'learning_rate': 0.002033185892773575, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02836249922078747, 'dropout_rate_Layer_2': 0.1136897452823873, 'dropout_rate_Layer_3': 0.009249902527842736, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008620775837214663, 'l1_Layer_2': 0.0004006071713022607, 'l1_Layer_3': 2.6622023424425658e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 235, 'n_units_Layer_3': 290}. Best is trial 139 with value: 3.9521373206548582.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.12 | sMAPE for Validation Set is: 14.57% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 42.87 | sMAPE for Test Set is: 38.30% | rMAE for Test Set is: 1.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:06:39,059]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:06:41,512]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:06:45,618]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:06:47,645]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:06:48,580]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:06:49,083]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:06:55,604]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:06:56,160]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:06:56,826]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:07:03,187]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:07:07,099]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:07:11,626]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:07:11,959]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:07:18,907]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:07:20,962]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:07:23,091]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:07:23,492]\u001b[0m Trial 265 finished with value: 4.715306068073297 and parameters: {'n_hidden': 3, 'learning_rate': 0.005417669013720151, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.363515830494835, 'dropout_rate_Layer_2': 0.11081495664438785, 'dropout_rate_Layer_3': 0.08402952942833901, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0004110439183750006, 'l1_Layer_2': 0.04897319751015657, 'l1_Layer_3': 5.440033843743327e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 75, 'n_units_Layer_3': 205}. Best is trial 139 with value: 3.9521373206548582.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.72 | sMAPE for Validation Set is: 16.73% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 54.08 | sMAPE for Test Set is: 50.49% | rMAE for Test Set is: 2.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:07:25,777]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:07:32,873]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:07:33,174]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:07:40,682]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:07:40,923]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:07:47,986]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:07:52,082]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:07:56,387]\u001b[0m Trial 278 finished with value: 4.272216884799875 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012631277964502273, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12686292227437282, 'dropout_rate_Layer_2': 0.30695200036184533, 'dropout_rate_Layer_3': 0.13610848398291725, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.004956961391356914, 'l1_Layer_2': 0.02640038102297504, 'l1_Layer_3': 0.00016882799468852214, 'n_units_Layer_1': 225, 'n_units_Layer_2': 90, 'n_units_Layer_3': 235}. Best is trial 139 with value: 3.9521373206548582.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.27 | sMAPE for Validation Set is: 14.97% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 56.03 | sMAPE for Test Set is: 52.93% | rMAE for Test Set is: 2.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:07:58,867]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:07:59,596]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:08:02,062]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:08:06,136]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:08:07,487]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:08:09,229]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:08:12,484]\u001b[0m Trial 271 finished with value: 4.0738836954917295 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013580035433955863, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19368059993000544, 'dropout_rate_Layer_2': 0.22467028344708312, 'dropout_rate_Layer_3': 0.13890818000041527, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0514438899518242e-05, 'l1_Layer_2': 0.057235495407165514, 'l1_Layer_3': 2.0590571948449838e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 120, 'n_units_Layer_3': 105}. Best is trial 139 with value: 3.9521373206548582.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.07 | sMAPE for Validation Set is: 14.42% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 15.19 | sMAPE for Test Set is: 19.64% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:08:15,318]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:08:19,457]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:08:23,634]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:08:27,694]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:08:28,126]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.25 | sMAPE for Validation Set is: 14.93% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 59.07 | sMAPE for Test Set is: 56.73% | rMAE for Test Set is: 2.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:08:33,211]\u001b[0m Trial 292 finished with value: 4.252395178989447 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011540432939269039, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19270651954369197, 'dropout_rate_Layer_2': 0.30740663626718634, 'dropout_rate_Layer_3': 0.3044632295176005, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.002110464387219814, 'l1_Layer_2': 2.848658051640759e-05, 'l1_Layer_3': 0.00013866113754426154, 'n_units_Layer_1': 175, 'n_units_Layer_2': 245, 'n_units_Layer_3': 280}. Best is trial 139 with value: 3.9521373206548582.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:08:35,970]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:08:39,731]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:08:39,872]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:08:49,007]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:08:49,228]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:08:55,590]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:08:59,691]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:09:02,842]\u001b[0m Trial 300 finished with value: 4.975740595908771 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021919716547442, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25874481610180955, 'dropout_rate_Layer_2': 0.2676905025133011, 'dropout_rate_Layer_3': 0.19069442722999616, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007045081159702742, 'l1_Layer_2': 0.011204697524123714, 'l1_Layer_3': 0.004178793719400058, 'n_units_Layer_1': 195, 'n_units_Layer_2': 100, 'n_units_Layer_3': 275}. Best is trial 139 with value: 3.9521373206548582.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.98 | sMAPE for Validation Set is: 17.55% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 58.67 | sMAPE for Test Set is: 56.39% | rMAE for Test Set is: 2.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:09:05,306]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:09:08,684]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:09:09,185]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:09:13,476]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:09:14,061]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:09:14,461]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:09:21,597]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:09:24,307]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:09:28,001]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:09:29,710]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:09:32,598]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:09:32,965]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:09:37,174]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:09:39,431]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:09:39,656]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:09:39,881]\u001b[0m Trial 306 finished with value: 4.086357048361413 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015327951639266927, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13407334314872185, 'dropout_rate_Layer_2': 0.17277045315631426, 'dropout_rate_Layer_3': 0.04161742334698361, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00402777054077542, 'l1_Layer_2': 0.0007724063104054748, 'l1_Layer_3': 3.384940139649732e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 255, 'n_units_Layer_3': 295}. Best is trial 139 with value: 3.9521373206548582.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.09 | sMAPE for Validation Set is: 14.67% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 43.70 | sMAPE for Test Set is: 39.06% | rMAE for Test Set is: 1.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:09:40,821]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:09:49,512]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:09:49,662]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:09:50,761]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:09:52,943]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:09:59,815]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:10:03,621]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:10:03,785]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:10:06,672]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:10:10,184]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:10:11,724]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:10:14,452]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:10:19,127]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:10:19,637]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:10:24,894]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:10:25,004]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:10:25,825]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:10:31,714]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:10:31,856]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:10:37,851]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:10:38,723]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:10:43,458]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:10:47,687]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:10:48,125]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:10:49,715]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:10:54,547]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:10:55,803]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:10:57,723]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:10:58,223]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:11:03,388]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:11:07,048]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:11:08,261]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:11:17,010]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:11:21,758]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:11:25,051]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:11:28,029]\u001b[0m Trial 354 finished with value: 4.502746626180747 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017698774779485863, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37940144067148035, 'dropout_rate_Layer_2': 0.11444182902301352, 'dropout_rate_Layer_3': 0.21020008519616734, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008672000945885565, 'l1_Layer_2': 3.68857037256533e-05, 'l1_Layer_3': 4.811161558989086e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 110, 'n_units_Layer_3': 240}. Best is trial 139 with value: 3.9521373206548582.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.50 | sMAPE for Validation Set is: 15.65% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 52.55 | sMAPE for Test Set is: 48.48% | rMAE for Test Set is: 2.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:11:31,020]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:11:34,489]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:11:36,665]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:11:39,782]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:11:41,484]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:11:42,085]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:11:47,675]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:11:48,153]\u001b[0m Trial 355 finished with value: 4.646363808942705 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022720481248437873, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09772489778501098, 'dropout_rate_Layer_2': 0.38399162985283797, 'dropout_rate_Layer_3': 0.1201747089928244, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01618943494376308, 'l1_Layer_2': 0.05016513436158787, 'l1_Layer_3': 0.00012112896935387951, 'n_units_Layer_1': 300, 'n_units_Layer_2': 195, 'n_units_Layer_3': 285}. Best is trial 139 with value: 3.9521373206548582.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.65 | sMAPE for Validation Set is: 16.56% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 15.21 | sMAPE for Test Set is: 19.66% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:11:48,723]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:11:49,029]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:11:57,385]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:12:01,826]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:12:04,776]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:12:07,604]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:12:09,095]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:12:13,743]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:12:14,210]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:12:19,045]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:12:22,958]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:12:23,407]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:12:30,094]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:12:31,274]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:12:36,052]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:12:36,799]\u001b[0m Trial 367 finished with value: 4.542042769656179 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020726759422874867, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38908415919068845, 'dropout_rate_Layer_2': 0.12697194336318093, 'dropout_rate_Layer_3': 0.22711533774424303, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.013470742206903159, 'l1_Layer_2': 1.2273971748632224e-05, 'l1_Layer_3': 2.7550018526442447e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 95, 'n_units_Layer_3': 245}. Best is trial 139 with value: 3.9521373206548582.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.54 | sMAPE for Validation Set is: 16.95% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 55.53 | sMAPE for Test Set is: 52.15% | rMAE for Test Set is: 2.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:12:39,385]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:12:43,479]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:12:46,923]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:12:47,515]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:12:54,067]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:12:54,106]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:12:54,647]\u001b[0m Trial 374 finished with value: 4.331229619240474 and parameters: {'n_hidden': 3, 'learning_rate': 0.002622045180477247, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12454585190576883, 'dropout_rate_Layer_2': 0.11566787309715182, 'dropout_rate_Layer_3': 0.20736870207977692, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00916267849332587, 'l1_Layer_2': 1.1524420923104476e-05, 'l1_Layer_3': 0.0020529687390637512, 'n_units_Layer_1': 65, 'n_units_Layer_2': 115, 'n_units_Layer_3': 265}. Best is trial 139 with value: 3.9521373206548582.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.33 | sMAPE for Validation Set is: 15.16% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 55.45 | sMAPE for Test Set is: 52.12% | rMAE for Test Set is: 2.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:13:02,695]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:13:04,145]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:13:04,205]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:13:10,060]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:13:12,451]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:13:13,090]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:13:16,111]\u001b[0m Trial 392 finished with value: 4.959918281507359 and parameters: {'n_hidden': 3, 'learning_rate': 0.00865355886398195, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19236094020459418, 'dropout_rate_Layer_2': 0.30308370073542185, 'dropout_rate_Layer_3': 0.30086468648918197, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0017729878863693984, 'l1_Layer_2': 2.4711618443517742e-05, 'l1_Layer_3': 0.000648214254090756, 'n_units_Layer_1': 170, 'n_units_Layer_2': 195, 'n_units_Layer_3': 285}. Best is trial 139 with value: 3.9521373206548582.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.96 | sMAPE for Validation Set is: 16.97% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 70.77 | sMAPE for Test Set is: 72.71% | rMAE for Test Set is: 2.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:13:18,781]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:13:22,064]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:13:24,491]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:13:24,908]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:13:28,762]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:13:33,076]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:13:34,634]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:13:38,060]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:13:38,542]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:13:45,636]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:13:49,552]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:13:50,095]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:13:52,834]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:13:57,697]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:13:58,149]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:14:03,988]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:14:09,585]\u001b[0m Trial 401 finished with value: 3.9020368072769647 and parameters: {'n_hidden': 3, 'learning_rate': 0.001483492123709209, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15026074131509704, 'dropout_rate_Layer_2': 0.0524850180398492, 'dropout_rate_Layer_3': 0.02467596569469644, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002990052249615148, 'l1_Layer_2': 0.02221083277975925, 'l1_Layer_3': 1.6444591937063907e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 65, 'n_units_Layer_3': 265}. Best is trial 401 with value: 3.9020368072769647.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.90 | sMAPE for Validation Set is: 13.60% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 15.56 | sMAPE for Test Set is: 19.79% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:14:11,504]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:14:12,359]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:14:17,224]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:14:17,388]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:14:17,644]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:14:25,844]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:14:28,847]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:14:31,785]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:14:36,111]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:14:37,898]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:14:41,619]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:14:41,875]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:14:41,996]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:14:46,801]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:14:48,659]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:14:54,674]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:14:54,916]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:14:55,313]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:15:03,437]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:15:05,008]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:15:08,791]\u001b[0m Trial 431 finished with value: 9.731974854163807 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019573612736221006, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.242244155216149, 'dropout_rate_Layer_2': 0.26830521963182125, 'dropout_rate_Layer_3': 0.39786968615057183, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00945035112643515, 'l1_Layer_2': 5.180801501119797e-05, 'l1_Layer_3': 1.2296774682678609e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 260, 'n_units_Layer_3': 260}. Best is trial 401 with value: 3.9020368072769647.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.73 | sMAPE for Validation Set is: 30.26% | rMAE for Validation Set is: 1.46\n",
      "MAE for Test Set is: 78.51 | sMAPE for Test Set is: 88.02% | rMAE for Test Set is: 3.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:15:09,149]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:15:16,310]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:15:19,412]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:15:19,848]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:15:24,237]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:15:27,398]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:15:27,650]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:15:33,948]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:15:34,088]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:15:40,667]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:15:42,966]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:15:43,213]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:15:43,797]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:15:50,176]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:15:54,024]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:15:54,297]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:16:00,101]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:16:02,952]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:16:05,604]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:16:08,040]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:16:13,143]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:16:15,060]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:16:18,562]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:16:20,259]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:16:20,674]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:16:25,442]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:16:27,172]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:16:30,750]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:16:31,282]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:16:31,658]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:16:36,709]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:16:41,103]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:16:43,615]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:16:47,662]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:16:48,330]\u001b[0m Trial 466 finished with value: 9.533642541961532 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009843680688769831, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2294936211785893, 'dropout_rate_Layer_2': 0.32022393198459237, 'dropout_rate_Layer_3': 0.3712685326281599, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.010206994342826561, 'l1_Layer_2': 0.0001258776151049581, 'l1_Layer_3': 6.44111910300279e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 285, 'n_units_Layer_3': 275}. Best is trial 401 with value: 3.9020368072769647.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.53 | sMAPE for Validation Set is: 29.80% | rMAE for Validation Set is: 1.43\n",
      "MAE for Test Set is: 79.05 | sMAPE for Test Set is: 89.14% | rMAE for Test Set is: 3.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:16:50,766]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:16:55,743]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:16:55,929]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:17:02,211]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:17:02,786]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.59 | sMAPE for Validation Set is: 16.06% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 56.42 | sMAPE for Test Set is: 53.62% | rMAE for Test Set is: 2.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:17:08,055]\u001b[0m Trial 465 finished with value: 4.590151299504958 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027539578244478915, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13244422475053724, 'dropout_rate_Layer_2': 0.28570077607351513, 'dropout_rate_Layer_3': 0.10977714225007723, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0015205060541933634, 'l1_Layer_2': 0.0066466208282019625, 'l1_Layer_3': 0.0006953983628771898, 'n_units_Layer_1': 205, 'n_units_Layer_2': 165, 'n_units_Layer_3': 250}. Best is trial 401 with value: 3.9020368072769647.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:17:08,526]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:17:08,741]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:17:09,325]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:17:15,956]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:17:16,414]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:17:20,451]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:17:22,275]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:17:25,747]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:17:26,687]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:17:33,086]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:17:56,636]\u001b[0m Trial 485 finished with value: 4.686089310340562 and parameters: {'n_hidden': 3, 'learning_rate': 0.001589940788514449, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11060196046378883, 'dropout_rate_Layer_2': 0.27000205496136037, 'dropout_rate_Layer_3': 0.123027070987738, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000989604178853729, 'l1_Layer_2': 0.006122863097548836, 'l1_Layer_3': 0.0015086329937686568, 'n_units_Layer_1': 210, 'n_units_Layer_2': 165, 'n_units_Layer_3': 250}. Best is trial 401 with value: 3.9020368072769647.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.69 | sMAPE for Validation Set is: 16.50% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 54.33 | sMAPE for Test Set is: 50.95% | rMAE for Test Set is: 2.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:17:57,629]\u001b[0m Trial 486 finished with value: 5.103614181777117 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016104734568283333, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35882340858669876, 'dropout_rate_Layer_2': 0.26805235562789625, 'dropout_rate_Layer_3': 0.10119944316672963, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002089469884372041, 'l1_Layer_2': 0.006399423047337735, 'l1_Layer_3': 0.0012071004345052744, 'n_units_Layer_1': 210, 'n_units_Layer_2': 165, 'n_units_Layer_3': 250}. Best is trial 401 with value: 3.9020368072769647.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.10 | sMAPE for Validation Set is: 18.02% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 49.72 | sMAPE for Test Set is: 45.56% | rMAE for Test Set is: 2.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:18:07,452]\u001b[0m Trial 487 finished with value: 5.366274556467238 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016542655039559272, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1434765332843725, 'dropout_rate_Layer_2': 0.29339387492973973, 'dropout_rate_Layer_3': 0.24315091939142705, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.892995287433236e-05, 'l1_Layer_2': 0.008927807844786211, 'l1_Layer_3': 0.0006923741544930925, 'n_units_Layer_1': 210, 'n_units_Layer_2': 175, 'n_units_Layer_3': 250}. Best is trial 401 with value: 3.9020368072769647.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.37 | sMAPE for Validation Set is: 18.63% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 57.41 | sMAPE for Test Set is: 54.84% | rMAE for Test Set is: 2.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:18:10,856]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:18:15,337]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:18:19,778]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:18:28,023]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:18:28,909]\u001b[0m Trial 480 finished with value: 4.124782296980047 and parameters: {'n_hidden': 3, 'learning_rate': 0.002624594912260117, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11826750786050681, 'dropout_rate_Layer_2': 0.2820588838931532, 'dropout_rate_Layer_3': 0.10158416237549664, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0014060329524732483, 'l1_Layer_2': 0.008588635222938863, 'l1_Layer_3': 0.0009397519879773249, 'n_units_Layer_1': 215, 'n_units_Layer_2': 165, 'n_units_Layer_3': 245}. Best is trial 401 with value: 3.9020368072769647.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.12 | sMAPE for Validation Set is: 14.38% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 22.79 | sMAPE for Test Set is: 24.79% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:18:34,238]\u001b[0m Trial 489 finished with value: 4.507682362054383 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015176833584254466, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11401146354099059, 'dropout_rate_Layer_2': 0.2785202098209516, 'dropout_rate_Layer_3': 0.12455124043224172, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002196339478108527, 'l1_Layer_2': 0.004446310629815949, 'l1_Layer_3': 0.0012545242145252694, 'n_units_Layer_1': 210, 'n_units_Layer_2': 165, 'n_units_Layer_3': 190}. Best is trial 401 with value: 3.9020368072769647.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.51 | sMAPE for Validation Set is: 15.76% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 51.10 | sMAPE for Test Set is: 47.16% | rMAE for Test Set is: 2.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:18:42,970]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:18:46,746]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:18:49,459]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:18:51,416]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:18:57,047]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:19:03,557]\u001b[0m Trial 493 finished with value: 5.03231879115658 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017264478597127852, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09966603984370219, 'dropout_rate_Layer_2': 0.2949968418497347, 'dropout_rate_Layer_3': 0.1269827094177519, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0020744211083611967, 'l1_Layer_2': 0.0051902379117907405, 'l1_Layer_3': 0.0011646866833380793, 'n_units_Layer_1': 220, 'n_units_Layer_2': 165, 'n_units_Layer_3': 190}. Best is trial 401 with value: 3.9020368072769647.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.03 | sMAPE for Validation Set is: 17.70% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 55.19 | sMAPE for Test Set is: 51.98% | rMAE for Test Set is: 2.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:19:05,583]\u001b[0m Trial 495 finished with value: 4.587415098200933 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017244228612218896, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11580514874149475, 'dropout_rate_Layer_2': 0.29456061267265293, 'dropout_rate_Layer_3': 0.13274638595938973, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002095817245531634, 'l1_Layer_2': 0.005680169450121837, 'l1_Layer_3': 0.0011354870457600623, 'n_units_Layer_1': 215, 'n_units_Layer_2': 165, 'n_units_Layer_3': 195}. Best is trial 401 with value: 3.9020368072769647.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.59 | sMAPE for Validation Set is: 16.21% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 52.73 | sMAPE for Test Set is: 49.03% | rMAE for Test Set is: 2.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:19:09,129]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:19:12,281]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:19:36,369]\u001b[0m Trial 504 finished with value: 4.426583219353756 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014391627787006425, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10616928471448275, 'dropout_rate_Layer_2': 0.3120373308890422, 'dropout_rate_Layer_3': 0.12831173879816254, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002375402281930632, 'l1_Layer_2': 0.004624495755409311, 'l1_Layer_3': 0.0012335237543128425, 'n_units_Layer_1': 220, 'n_units_Layer_2': 170, 'n_units_Layer_3': 210}. Best is trial 401 with value: 3.9020368072769647.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.43 | sMAPE for Validation Set is: 15.64% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 49.33 | sMAPE for Test Set is: 45.12% | rMAE for Test Set is: 1.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:19:39,503]\u001b[0m Trial 500 finished with value: 4.234421380808095 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013890266546649787, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12010775827943675, 'dropout_rate_Layer_2': 0.29290139597829834, 'dropout_rate_Layer_3': 0.12674680523386078, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.820475610557771e-05, 'l1_Layer_2': 0.005926464283329084, 'l1_Layer_3': 0.001188186383580062, 'n_units_Layer_1': 220, 'n_units_Layer_2': 165, 'n_units_Layer_3': 190}. Best is trial 401 with value: 3.9020368072769647.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.23 | sMAPE for Validation Set is: 15.18% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 57.38 | sMAPE for Test Set is: 54.63% | rMAE for Test Set is: 2.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:19:41,929]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:19:45,950]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:19:50,754]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:19:52,902]\u001b[0m Trial 505 finished with value: 4.703452152068015 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014720594569690487, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11396857601523128, 'dropout_rate_Layer_2': 0.30395390233902075, 'dropout_rate_Layer_3': 0.12917191252935317, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0025980066846323013, 'l1_Layer_2': 0.0042161550712101195, 'l1_Layer_3': 0.0011806514620416038, 'n_units_Layer_1': 215, 'n_units_Layer_2': 170, 'n_units_Layer_3': 195}. Best is trial 401 with value: 3.9020368072769647.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.70 | sMAPE for Validation Set is: 16.74% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 50.78 | sMAPE for Test Set is: 46.67% | rMAE for Test Set is: 2.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:19:57,740]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:19:59,591]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:20:01,372]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:20:04,948]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:20:07,828]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:20:11,064]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:20:16,114]\u001b[0m Trial 506 finished with value: 4.331413271132728 and parameters: {'n_hidden': 3, 'learning_rate': 0.001333413457157107, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10472396171288459, 'dropout_rate_Layer_2': 0.2985062291811819, 'dropout_rate_Layer_3': 0.13914779680116768, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0021192045172033092, 'l1_Layer_2': 0.004372756346136408, 'l1_Layer_3': 0.001241444100476047, 'n_units_Layer_1': 220, 'n_units_Layer_2': 165, 'n_units_Layer_3': 205}. Best is trial 401 with value: 3.9020368072769647.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.33 | sMAPE for Validation Set is: 15.26% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 51.77 | sMAPE for Test Set is: 48.02% | rMAE for Test Set is: 2.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:20:16,768]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:20:21,514]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:20:25,486]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:20:28,378]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:20:31,641]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:20:34,668]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:20:36,862]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:20:40,215]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:20:40,418]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:20:43,845]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:20:47,882]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:20:52,105]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:20:55,735]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:20:59,045]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:21:03,293]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:21:07,602]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:21:11,854]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:21:27,547]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:21:31,115]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:21:43,640]\u001b[0m Trial 535 finished with value: 4.348390824792556 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011419889537891148, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11054248081054424, 'dropout_rate_Layer_2': 0.28598643691241965, 'dropout_rate_Layer_3': 0.14217902749117112, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001932538538726947, 'l1_Layer_2': 0.004835907531618513, 'l1_Layer_3': 0.0010806770116700058, 'n_units_Layer_1': 230, 'n_units_Layer_2': 180, 'n_units_Layer_3': 180}. Best is trial 401 with value: 3.9020368072769647.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.35 | sMAPE for Validation Set is: 15.35% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 49.08 | sMAPE for Test Set is: 44.90% | rMAE for Test Set is: 1.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:21:49,652]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:21:55,661]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:22:01,232]\u001b[0m Trial 532 finished with value: 4.322882461654111 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010477637420007516, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12050195912714427, 'dropout_rate_Layer_2': 0.21245155059390317, 'dropout_rate_Layer_3': 0.09704528252686526, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.004223555436602656, 'l1_Layer_2': 0.042765665892804304, 'l1_Layer_3': 0.0003086197251546701, 'n_units_Layer_1': 230, 'n_units_Layer_2': 95, 'n_units_Layer_3': 230}. Best is trial 401 with value: 3.9020368072769647.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.32 | sMAPE for Validation Set is: 15.27% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 54.91 | sMAPE for Test Set is: 51.58% | rMAE for Test Set is: 2.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:22:06,191]\u001b[0m Trial 537 finished with value: 4.510398244149395 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011059076163127991, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11229110970820498, 'dropout_rate_Layer_2': 0.2871136423635074, 'dropout_rate_Layer_3': 0.14461081647053228, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0015921427933010496, 'l1_Layer_2': 0.005922373305296107, 'l1_Layer_3': 0.000877613181756919, 'n_units_Layer_1': 210, 'n_units_Layer_2': 180, 'n_units_Layer_3': 180}. Best is trial 401 with value: 3.9020368072769647.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.51 | sMAPE for Validation Set is: 16.02% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 52.54 | sMAPE for Test Set is: 48.81% | rMAE for Test Set is: 2.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:22:06,492]\u001b[0m Trial 536 finished with value: 4.628612761723299 and parameters: {'n_hidden': 3, 'learning_rate': 0.001164663953086734, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11322461724284884, 'dropout_rate_Layer_2': 0.2886388573182661, 'dropout_rate_Layer_3': 0.14372936528708327, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0020748172688872706, 'l1_Layer_2': 0.006242045295848696, 'l1_Layer_3': 0.001173812629453999, 'n_units_Layer_1': 230, 'n_units_Layer_2': 180, 'n_units_Layer_3': 210}. Best is trial 401 with value: 3.9020368072769647.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.63 | sMAPE for Validation Set is: 16.41% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 49.03 | sMAPE for Test Set is: 44.74% | rMAE for Test Set is: 1.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:22:08,900]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:22:20,334]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:22:27,990]\u001b[0m Trial 540 finished with value: 4.505514962586852 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013282448040075414, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10962182876833787, 'dropout_rate_Layer_2': 0.28420632953321734, 'dropout_rate_Layer_3': 0.14998867094989388, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0016712593508725955, 'l1_Layer_2': 0.006043232185026302, 'l1_Layer_3': 0.0008751211650180591, 'n_units_Layer_1': 235, 'n_units_Layer_2': 190, 'n_units_Layer_3': 180}. Best is trial 401 with value: 3.9020368072769647.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.51 | sMAPE for Validation Set is: 15.81% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 51.80 | sMAPE for Test Set is: 48.01% | rMAE for Test Set is: 2.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:22:42,405]\u001b[0m Trial 542 finished with value: 4.415017619044446 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010156247620223614, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11055475404556889, 'dropout_rate_Layer_2': 0.2867136542741828, 'dropout_rate_Layer_3': 0.1425188409640943, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018224607909134711, 'l1_Layer_2': 0.00632204424052225, 'l1_Layer_3': 0.0011337731890015941, 'n_units_Layer_1': 235, 'n_units_Layer_2': 185, 'n_units_Layer_3': 175}. Best is trial 401 with value: 3.9020368072769647.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.42 | sMAPE for Validation Set is: 15.54% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 52.00 | sMAPE for Test Set is: 48.23% | rMAE for Test Set is: 2.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:22:48,350]\u001b[0m Trial 543 finished with value: 4.59379324008938 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009671276227130793, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10897168145468578, 'dropout_rate_Layer_2': 0.28762229876521883, 'dropout_rate_Layer_3': 0.14695057307235468, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0019461141138507377, 'l1_Layer_2': 0.006180566156711913, 'l1_Layer_3': 0.0008437490472483891, 'n_units_Layer_1': 235, 'n_units_Layer_2': 190, 'n_units_Layer_3': 205}. Best is trial 401 with value: 3.9020368072769647.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.59 | sMAPE for Validation Set is: 16.27% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 51.01 | sMAPE for Test Set is: 47.04% | rMAE for Test Set is: 2.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:22:51,028]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.40 | sMAPE for Validation Set is: 15.39% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 48.00 | sMAPE for Test Set is: 43.70% | rMAE for Test Set is: 1.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:22:52,751]\u001b[0m Trial 545 finished with value: 4.397431495196307 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010167984572851529, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09688895976936575, 'dropout_rate_Layer_2': 0.29387188288951693, 'dropout_rate_Layer_3': 0.1528103194444375, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002045748971181793, 'l1_Layer_2': 0.004683811279766099, 'l1_Layer_3': 0.000933508844439575, 'n_units_Layer_1': 240, 'n_units_Layer_2': 185, 'n_units_Layer_3': 180}. Best is trial 401 with value: 3.9020368072769647.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:22:56,343]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:22:58,164]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:23:10,861]\u001b[0m Trial 546 finished with value: 4.371800428242626 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009143609364143724, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10016550303918671, 'dropout_rate_Layer_2': 0.27946956144121543, 'dropout_rate_Layer_3': 0.15547940921251666, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0015369117391154322, 'l1_Layer_2': 0.004778415847783967, 'l1_Layer_3': 0.0008659359783001571, 'n_units_Layer_1': 220, 'n_units_Layer_2': 195, 'n_units_Layer_3': 180}. Best is trial 401 with value: 3.9020368072769647.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.37 | sMAPE for Validation Set is: 15.36% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 50.79 | sMAPE for Test Set is: 46.81% | rMAE for Test Set is: 2.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:23:26,800]\u001b[0m Trial 548 finished with value: 4.362122110762636 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009493010205058227, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10031740099801063, 'dropout_rate_Layer_2': 0.2820299642417632, 'dropout_rate_Layer_3': 0.15475046783551658, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0016174356395174097, 'l1_Layer_2': 0.004798770411668736, 'l1_Layer_3': 0.0008553631546671418, 'n_units_Layer_1': 245, 'n_units_Layer_2': 190, 'n_units_Layer_3': 175}. Best is trial 401 with value: 3.9020368072769647.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.36 | sMAPE for Validation Set is: 15.36% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 51.19 | sMAPE for Test Set is: 47.37% | rMAE for Test Set is: 2.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:23:41,582]\u001b[0m Trial 551 finished with value: 4.397770920176138 and parameters: {'n_hidden': 3, 'learning_rate': 0.000872675486357837, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09745145784939975, 'dropout_rate_Layer_2': 0.2997925973779421, 'dropout_rate_Layer_3': 0.14955173719493214, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001735735284889551, 'l1_Layer_2': 0.0038520038905348357, 'l1_Layer_3': 0.0008296860945402405, 'n_units_Layer_1': 240, 'n_units_Layer_2': 185, 'n_units_Layer_3': 180}. Best is trial 401 with value: 3.9020368072769647.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.40 | sMAPE for Validation Set is: 15.59% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 50.18 | sMAPE for Test Set is: 46.12% | rMAE for Test Set is: 2.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:23:42,210]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:23:44,790]\u001b[0m Trial 552 finished with value: 4.5566810306046115 and parameters: {'n_hidden': 3, 'learning_rate': 0.000934364584637143, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0847728194889987, 'dropout_rate_Layer_2': 0.30118381624163115, 'dropout_rate_Layer_3': 0.1453322639743139, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0017429363680434027, 'l1_Layer_2': 0.004180053024550384, 'l1_Layer_3': 0.0008615006586197935, 'n_units_Layer_1': 240, 'n_units_Layer_2': 190, 'n_units_Layer_3': 180}. Best is trial 401 with value: 3.9020368072769647.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.56 | sMAPE for Validation Set is: 16.16% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 50.18 | sMAPE for Test Set is: 46.09% | rMAE for Test Set is: 2.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:23:49,811]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:23:55,602]\u001b[0m Trial 553 finished with value: 4.317039916876188 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009309112806628975, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11370192891268864, 'dropout_rate_Layer_2': 0.28418142876207264, 'dropout_rate_Layer_3': 0.14624309792511397, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015407574068324902, 'l1_Layer_2': 0.0037451829148118995, 'l1_Layer_3': 0.0008221312037322209, 'n_units_Layer_1': 240, 'n_units_Layer_2': 190, 'n_units_Layer_3': 180}. Best is trial 401 with value: 3.9020368072769647.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.32 | sMAPE for Validation Set is: 15.17% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 49.61 | sMAPE for Test Set is: 45.50% | rMAE for Test Set is: 2.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:24:00,377]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:24:34,427]\u001b[0m Trial 558 finished with value: 4.308503904595017 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007353165663213746, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0814818363442139, 'dropout_rate_Layer_2': 0.3085934996529489, 'dropout_rate_Layer_3': 0.1624021116283786, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0016014453735450917, 'l1_Layer_2': 0.004014570778253056, 'l1_Layer_3': 0.0008627648709068499, 'n_units_Layer_1': 245, 'n_units_Layer_2': 205, 'n_units_Layer_3': 180}. Best is trial 401 with value: 3.9020368072769647.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.31 | sMAPE for Validation Set is: 15.25% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 48.81 | sMAPE for Test Set is: 44.62% | rMAE for Test Set is: 1.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:24:46,574]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:24:49,764]\u001b[0m Trial 557 finished with value: 4.466609500807087 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006900858869062136, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08337291937933874, 'dropout_rate_Layer_2': 0.2977175987230425, 'dropout_rate_Layer_3': 0.16060623117213596, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0014398356738002367, 'l1_Layer_2': 0.00413294172184144, 'l1_Layer_3': 0.0008222138739902381, 'n_units_Layer_1': 250, 'n_units_Layer_2': 200, 'n_units_Layer_3': 180}. Best is trial 401 with value: 3.9020368072769647.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.47 | sMAPE for Validation Set is: 15.78% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 48.88 | sMAPE for Test Set is: 44.66% | rMAE for Test Set is: 1.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:24:50,131]\u001b[0m Trial 559 finished with value: 4.350145600495122 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007124256711122748, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07767686376527398, 'dropout_rate_Layer_2': 0.28988987876545425, 'dropout_rate_Layer_3': 0.16314633525950056, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001624722939416406, 'l1_Layer_2': 0.0033406537139025385, 'l1_Layer_3': 0.0008250193235655963, 'n_units_Layer_1': 245, 'n_units_Layer_2': 200, 'n_units_Layer_3': 180}. Best is trial 401 with value: 3.9020368072769647.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.35 | sMAPE for Validation Set is: 15.31% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 47.84 | sMAPE for Test Set is: 43.51% | rMAE for Test Set is: 1.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:24:56,310]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:24:58,063]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:25:02,382]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:25:03,003]\u001b[0m Trial 560 finished with value: 4.472920596743471 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007384690449720163, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07522729272580739, 'dropout_rate_Layer_2': 0.2882314659649706, 'dropout_rate_Layer_3': 0.1565732251260536, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015618380911368366, 'l1_Layer_2': 0.0038196216727011552, 'l1_Layer_3': 0.0008288305753599384, 'n_units_Layer_1': 245, 'n_units_Layer_2': 205, 'n_units_Layer_3': 180}. Best is trial 401 with value: 3.9020368072769647.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.47 | sMAPE for Validation Set is: 15.84% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 50.35 | sMAPE for Test Set is: 46.27% | rMAE for Test Set is: 2.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:25:12,044]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:25:16,182]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:25:18,846]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:25:19,010]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:25:22,635]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:25:29,869]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:25:31,674]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:25:32,259]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:25:43,463]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:25:47,045]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:25:59,308]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:26:31,595]\u001b[0m Trial 574 finished with value: 4.202234793435454 and parameters: {'n_hidden': 3, 'learning_rate': 0.000711424564479387, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0802641553148393, 'dropout_rate_Layer_2': 0.3235091529499656, 'dropout_rate_Layer_3': 0.15364389862584307, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013427109779457153, 'l1_Layer_2': 0.002304215983985496, 'l1_Layer_3': 0.0006696644537156318, 'n_units_Layer_1': 255, 'n_units_Layer_2': 215, 'n_units_Layer_3': 170}. Best is trial 401 with value: 3.9020368072769647.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.20 | sMAPE for Validation Set is: 14.87% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 48.22 | sMAPE for Test Set is: 43.93% | rMAE for Test Set is: 1.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:26:34,138]\u001b[0m Trial 578 finished with value: 4.36589880111379 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007808033865410168, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08323495740141724, 'dropout_rate_Layer_2': 0.32234953734550154, 'dropout_rate_Layer_3': 0.15650119422500577, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001359968058079207, 'l1_Layer_2': 0.003898909792680614, 'l1_Layer_3': 0.0009224901552341105, 'n_units_Layer_1': 245, 'n_units_Layer_2': 210, 'n_units_Layer_3': 170}. Best is trial 401 with value: 3.9020368072769647.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.37 | sMAPE for Validation Set is: 15.29% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 50.99 | sMAPE for Test Set is: 47.08% | rMAE for Test Set is: 2.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:26:46,805]\u001b[0m Trial 575 finished with value: 4.34525362337975 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006715908181098197, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07644646904313311, 'dropout_rate_Layer_2': 0.3208691216998409, 'dropout_rate_Layer_3': 0.16718269384012446, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013714801355896513, 'l1_Layer_2': 0.0024009776179093655, 'l1_Layer_3': 0.0006581375225184742, 'n_units_Layer_1': 255, 'n_units_Layer_2': 210, 'n_units_Layer_3': 170}. Best is trial 401 with value: 3.9020368072769647.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.35 | sMAPE for Validation Set is: 15.27% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 48.14 | sMAPE for Test Set is: 43.80% | rMAE for Test Set is: 1.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:26:56,547]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:27:05,719]\u001b[0m Trial 579 finished with value: 4.5545067934250545 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007820933929807579, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.054541792854874885, 'dropout_rate_Layer_2': 0.32205883574113653, 'dropout_rate_Layer_3': 0.15214243799330943, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014882855291698427, 'l1_Layer_2': 0.00382395542101935, 'l1_Layer_3': 0.0009341514557367962, 'n_units_Layer_1': 245, 'n_units_Layer_2': 200, 'n_units_Layer_3': 170}. Best is trial 401 with value: 3.9020368072769647.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.55 | sMAPE for Validation Set is: 16.12% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 50.92 | sMAPE for Test Set is: 46.83% | rMAE for Test Set is: 2.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:27:13,144]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:27:34,877]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:27:38,295]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:28:01,957]\u001b[0m Trial 582 finished with value: 4.396656174093015 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006490689475841719, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06512933321971798, 'dropout_rate_Layer_2': 0.32840627011707413, 'dropout_rate_Layer_3': 0.1711495312137048, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00130528070956659, 'l1_Layer_2': 0.0025781377437445853, 'l1_Layer_3': 0.0009378432206704044, 'n_units_Layer_1': 255, 'n_units_Layer_2': 210, 'n_units_Layer_3': 170}. Best is trial 401 with value: 3.9020368072769647.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.40 | sMAPE for Validation Set is: 15.60% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 48.58 | sMAPE for Test Set is: 44.32% | rMAE for Test Set is: 1.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:28:09,375]\u001b[0m Trial 580 finished with value: 4.580671842799988 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008009383157236292, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.057673421751629234, 'dropout_rate_Layer_2': 0.3189207920066568, 'dropout_rate_Layer_3': 0.1625902114582958, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001408056008802338, 'l1_Layer_2': 0.003738758009394824, 'l1_Layer_3': 0.0009288428331387811, 'n_units_Layer_1': 260, 'n_units_Layer_2': 210, 'n_units_Layer_3': 170}. Best is trial 401 with value: 3.9020368072769647.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.58 | sMAPE for Validation Set is: 16.22% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 51.26 | sMAPE for Test Set is: 47.22% | rMAE for Test Set is: 2.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:28:14,168]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:28:25,880]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:28:31,917]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:28:43,360]\u001b[0m Trial 587 finished with value: 4.469451658449022 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007475547844385032, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07650273348057084, 'dropout_rate_Layer_2': 0.36983333023389797, 'dropout_rate_Layer_3': 0.16239616764961648, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016933303560622574, 'l1_Layer_2': 0.0032529301532079604, 'l1_Layer_3': 0.0009823336409665857, 'n_units_Layer_1': 255, 'n_units_Layer_2': 210, 'n_units_Layer_3': 175}. Best is trial 401 with value: 3.9020368072769647.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.47 | sMAPE for Validation Set is: 15.79% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 51.39 | sMAPE for Test Set is: 47.51% | rMAE for Test Set is: 2.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:28:48,080]\u001b[0m Trial 591 finished with value: 4.236966812196659 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016647485881978762, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13093380318658515, 'dropout_rate_Layer_2': 0.3029212849082169, 'dropout_rate_Layer_3': 0.38049530865634945, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.7597182175147672e-05, 'l1_Layer_2': 0.005354208608259736, 'l1_Layer_3': 0.00018664022576554904, 'n_units_Layer_1': 245, 'n_units_Layer_2': 265, 'n_units_Layer_3': 150}. Best is trial 401 with value: 3.9020368072769647.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.24 | sMAPE for Validation Set is: 15.09% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 56.01 | sMAPE for Test Set is: 52.69% | rMAE for Test Set is: 2.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:28:51,203]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:28:53,329]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:28:55,187]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:29:04,241]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:29:21,609]\u001b[0m Trial 592 finished with value: 4.382630388371459 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008395979526389995, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0940014326218445, 'dropout_rate_Layer_2': 0.35380204644920493, 'dropout_rate_Layer_3': 0.17130982482123003, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012147067389883155, 'l1_Layer_2': 0.004563503197856953, 'l1_Layer_3': 0.0007805689719391456, 'n_units_Layer_1': 270, 'n_units_Layer_2': 225, 'n_units_Layer_3': 180}. Best is trial 401 with value: 3.9020368072769647.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.38 | sMAPE for Validation Set is: 15.37% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 53.39 | sMAPE for Test Set is: 49.88% | rMAE for Test Set is: 2.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:29:25,549]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:29:30,531]\u001b[0m Trial 590 finished with value: 4.0435044850700965 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006387367056707948, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07353291527003236, 'dropout_rate_Layer_2': 0.3330939384965206, 'dropout_rate_Layer_3': 0.15364819598411264, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001153479448263466, 'l1_Layer_2': 0.002037092981207591, 'l1_Layer_3': 0.000575708883399506, 'n_units_Layer_1': 245, 'n_units_Layer_2': 220, 'n_units_Layer_3': 160}. Best is trial 401 with value: 3.9020368072769647.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.04 | sMAPE for Validation Set is: 14.38% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 47.37 | sMAPE for Test Set is: 42.90% | rMAE for Test Set is: 1.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:29:31,041]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:29:36,788]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:29:37,467]\u001b[0m Trial 596 finished with value: 4.2209330296582825 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015649569060096373, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0067960210992932335, 'dropout_rate_Layer_2': 0.2677843204485625, 'dropout_rate_Layer_3': 0.17134108758509148, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.014054552437750818, 'l1_Layer_2': 0.0004884600850468717, 'l1_Layer_3': 0.001721480974719189, 'n_units_Layer_1': 90, 'n_units_Layer_2': 245, 'n_units_Layer_3': 95}. Best is trial 401 with value: 3.9020368072769647.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.22 | sMAPE for Validation Set is: 14.85% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 52.20 | sMAPE for Test Set is: 48.32% | rMAE for Test Set is: 2.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:29:48,868]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:29:49,143]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:29:55,462]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:30:00,575]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:30:15,379]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:30:22,243]\u001b[0m Trial 603 finished with value: 3.87883733635604 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017547666218352162, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0054474424650740655, 'dropout_rate_Layer_2': 0.25551720959518653, 'dropout_rate_Layer_3': 0.1770886637041512, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011261928662209524, 'l1_Layer_2': 0.0009743137349650155, 'l1_Layer_3': 2.2414769710005764e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 255, 'n_units_Layer_3': 70}. Best is trial 603 with value: 3.87883733635604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.88 | sMAPE for Validation Set is: 13.69% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 48.69 | sMAPE for Test Set is: 44.23% | rMAE for Test Set is: 1.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:30:30,825]\u001b[0m Trial 609 finished with value: 4.424401238920961 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017294640274493557, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06828297137549608, 'dropout_rate_Layer_2': 0.2597185139431642, 'dropout_rate_Layer_3': 0.3868552801040132, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.140459928557837e-05, 'l1_Layer_2': 0.007919884741203522, 'l1_Layer_3': 0.00017683917502159065, 'n_units_Layer_1': 245, 'n_units_Layer_2': 270, 'n_units_Layer_3': 150}. Best is trial 603 with value: 3.87883733635604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.42 | sMAPE for Validation Set is: 15.73% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 53.18 | sMAPE for Test Set is: 49.40% | rMAE for Test Set is: 2.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:30:47,114]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:30:53,421]\u001b[0m Trial 605 finished with value: 4.080522096996076 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008303151572137354, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08262840150852069, 'dropout_rate_Layer_2': 0.3576188896848305, 'dropout_rate_Layer_3': 0.15498769403882973, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013433704348392995, 'l1_Layer_2': 0.0015987037480015176, 'l1_Layer_3': 0.0005165022705783878, 'n_units_Layer_1': 250, 'n_units_Layer_2': 220, 'n_units_Layer_3': 155}. Best is trial 603 with value: 3.87883733635604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.08 | sMAPE for Validation Set is: 14.60% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 48.57 | sMAPE for Test Set is: 44.19% | rMAE for Test Set is: 1.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:30:54,024]\u001b[0m Trial 604 finished with value: 4.280533269405807 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005608767406478318, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06984426793932343, 'dropout_rate_Layer_2': 0.34657523052502665, 'dropout_rate_Layer_3': 0.17756613111558525, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011415455885627282, 'l1_Layer_2': 0.002142517294775745, 'l1_Layer_3': 0.0007516940821682285, 'n_units_Layer_1': 265, 'n_units_Layer_2': 230, 'n_units_Layer_3': 160}. Best is trial 603 with value: 3.87883733635604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.28 | sMAPE for Validation Set is: 15.16% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 50.08 | sMAPE for Test Set is: 46.00% | rMAE for Test Set is: 2.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:31:06,228]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:31:07,855]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:31:13,960]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:31:25,672]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:31:31,818]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:31:40,773]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:31:49,202]\u001b[0m Trial 615 finished with value: 3.956454393837113 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016334861061494698, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02425670353123574, 'dropout_rate_Layer_2': 0.2628072829729594, 'dropout_rate_Layer_3': 0.17774481181582447, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009960380068321007, 'l1_Layer_2': 0.0006702994073353696, 'l1_Layer_3': 4.3007203550255044e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 260, 'n_units_Layer_3': 85}. Best is trial 603 with value: 3.87883733635604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.96 | sMAPE for Validation Set is: 14.04% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 46.25 | sMAPE for Test Set is: 41.65% | rMAE for Test Set is: 1.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:31:49,389]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:31:55,601]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:32:00,176]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:32:05,296]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:32:21,381]\u001b[0m Trial 619 finished with value: 4.221417608752556 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018549805790178335, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008389822656314076, 'dropout_rate_Layer_2': 0.2942571041500368, 'dropout_rate_Layer_3': 0.1514667136863388, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011981469737098991, 'l1_Layer_2': 0.002186914091945419, 'l1_Layer_3': 0.00022843525139388274, 'n_units_Layer_1': 90, 'n_units_Layer_2': 265, 'n_units_Layer_3': 50}. Best is trial 603 with value: 3.87883733635604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.22 | sMAPE for Validation Set is: 14.90% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 51.25 | sMAPE for Test Set is: 47.28% | rMAE for Test Set is: 2.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:32:29,126]\u001b[0m Trial 617 finished with value: 4.159487138409911 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005864907590191186, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09074367021763921, 'dropout_rate_Layer_2': 0.35043547180215523, 'dropout_rate_Layer_3': 0.16785515935657133, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010439557320466727, 'l1_Layer_2': 0.002148732328705972, 'l1_Layer_3': 0.0005657202180653173, 'n_units_Layer_1': 265, 'n_units_Layer_2': 235, 'n_units_Layer_3': 150}. Best is trial 603 with value: 3.87883733635604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.16 | sMAPE for Validation Set is: 14.87% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 49.01 | sMAPE for Test Set is: 44.68% | rMAE for Test Set is: 1.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:33:18,793]\u001b[0m Trial 627 finished with value: 4.375540270229789 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005447339421308708, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1483211968984714, 'dropout_rate_Layer_2': 0.26894863503481375, 'dropout_rate_Layer_3': 0.008133610224424725, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.006410981069614007, 'l1_Layer_2': 0.028960625556259344, 'l1_Layer_3': 0.0007707333077250718, 'n_units_Layer_1': 210, 'n_units_Layer_2': 80, 'n_units_Layer_3': 190}. Best is trial 603 with value: 3.87883733635604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.38 | sMAPE for Validation Set is: 15.35% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 57.09 | sMAPE for Test Set is: 54.38% | rMAE for Test Set is: 2.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:33:19,609]\u001b[0m Trial 625 finished with value: 4.036651688051532 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005313871549189656, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03902312409369804, 'dropout_rate_Layer_2': 0.38082192582986, 'dropout_rate_Layer_3': 0.1389614323279143, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001095163767077779, 'l1_Layer_2': 0.0019726494279966277, 'l1_Layer_3': 0.0005412288362712663, 'n_units_Layer_1': 260, 'n_units_Layer_2': 225, 'n_units_Layer_3': 155}. Best is trial 603 with value: 3.87883733635604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.04 | sMAPE for Validation Set is: 14.39% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 48.59 | sMAPE for Test Set is: 44.21% | rMAE for Test Set is: 1.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:33:22,275]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:33:25,917]\u001b[0m Trial 623 finished with value: 4.11556511616419 and parameters: {'n_hidden': 3, 'learning_rate': 0.000593414347360334, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03958727768346942, 'dropout_rate_Layer_2': 0.32855289171213203, 'dropout_rate_Layer_3': 0.16713484346735422, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011755636815065267, 'l1_Layer_2': 0.0017598389005171278, 'l1_Layer_3': 0.0005350703095540966, 'n_units_Layer_1': 265, 'n_units_Layer_2': 230, 'n_units_Layer_3': 160}. Best is trial 603 with value: 3.87883733635604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.12 | sMAPE for Validation Set is: 14.84% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 48.85 | sMAPE for Test Set is: 44.44% | rMAE for Test Set is: 1.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:33:31,200]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:33:42,392]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:33:44,001]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:33:49,961]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:33:53,664]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:34:15,220]\u001b[0m Trial 630 finished with value: 4.085971658028377 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013849896460665877, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.019030641987172404, 'dropout_rate_Layer_2': 0.3262620838155099, 'dropout_rate_Layer_3': 0.13151408931713016, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013881234861525598, 'l1_Layer_2': 0.0017316513499631145, 'l1_Layer_3': 0.00022848584715244946, 'n_units_Layer_1': 95, 'n_units_Layer_2': 270, 'n_units_Layer_3': 80}. Best is trial 603 with value: 3.87883733635604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.09 | sMAPE for Validation Set is: 14.45% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 49.27 | sMAPE for Test Set is: 45.01% | rMAE for Test Set is: 1.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:34:30,781]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:34:32,506]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:34:39,890]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:34:50,264]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:34:50,934]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:35:02,355]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:35:29,917]\u001b[0m Trial 643 finished with value: 4.243010301160503 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007409179032320243, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17335999016451537, 'dropout_rate_Layer_2': 0.3111766594363614, 'dropout_rate_Layer_3': 0.3590201545427339, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006488976321805333, 'l1_Layer_2': 0.007089734651647758, 'l1_Layer_3': 0.0002153671037746832, 'n_units_Layer_1': 185, 'n_units_Layer_2': 265, 'n_units_Layer_3': 100}. Best is trial 603 with value: 3.87883733635604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.24 | sMAPE for Validation Set is: 14.83% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 48.10 | sMAPE for Test Set is: 43.84% | rMAE for Test Set is: 1.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:35:38,628]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:35:46,156]\u001b[0m Trial 632 finished with value: 4.062263722313479 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005327666064320201, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0388481202740153, 'dropout_rate_Layer_2': 0.3489364803325411, 'dropout_rate_Layer_3': 0.17139237732770735, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010749359615367013, 'l1_Layer_2': 0.0019639200619997734, 'l1_Layer_3': 0.00044417060688595325, 'n_units_Layer_1': 265, 'n_units_Layer_2': 230, 'n_units_Layer_3': 145}. Best is trial 603 with value: 3.87883733635604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.06 | sMAPE for Validation Set is: 14.44% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 49.72 | sMAPE for Test Set is: 45.47% | rMAE for Test Set is: 2.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:35:48,274]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:35:55,744]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:36:18,515]\u001b[0m Trial 635 finished with value: 4.098778211094211 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005322251482882552, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03600577878806126, 'dropout_rate_Layer_2': 0.34285327883361183, 'dropout_rate_Layer_3': 0.17080783129610413, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010908205489241795, 'l1_Layer_2': 0.0018559479325588961, 'l1_Layer_3': 0.0004310831866160529, 'n_units_Layer_1': 265, 'n_units_Layer_2': 230, 'n_units_Layer_3': 155}. Best is trial 603 with value: 3.87883733635604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.10 | sMAPE for Validation Set is: 14.69% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 50.35 | sMAPE for Test Set is: 46.15% | rMAE for Test Set is: 2.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:36:25,818]\u001b[0m Trial 641 finished with value: 4.1073416976122905 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005615078860900567, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03804059794717148, 'dropout_rate_Layer_2': 0.38967332351141154, 'dropout_rate_Layer_3': 0.14077487888028103, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001108883834342028, 'l1_Layer_2': 0.0017457987834066894, 'l1_Layer_3': 0.0005580084285967836, 'n_units_Layer_1': 270, 'n_units_Layer_2': 245, 'n_units_Layer_3': 160}. Best is trial 603 with value: 3.87883733635604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.11 | sMAPE for Validation Set is: 14.76% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 47.31 | sMAPE for Test Set is: 42.80% | rMAE for Test Set is: 1.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:36:29,466]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:36:39,630]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:37:01,046]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:37:08,451]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:37:16,714]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:37:23,983]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:37:24,194]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:37:34,544]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:37:43,526]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:37:50,649]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:37:55,522]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:37:59,729]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:38:08,834]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:38:08,945]\u001b[0m Trial 651 finished with value: 4.037223460229325 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005029003149622231, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03634298725763338, 'dropout_rate_Layer_2': 0.3578017696722922, 'dropout_rate_Layer_3': 0.18278699651177438, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012204161727390897, 'l1_Layer_2': 0.0013812586593281752, 'l1_Layer_3': 0.0004475849006624656, 'n_units_Layer_1': 270, 'n_units_Layer_2': 255, 'n_units_Layer_3': 160}. Best is trial 603 with value: 3.87883733635604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.04 | sMAPE for Validation Set is: 14.48% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 49.70 | sMAPE for Test Set is: 45.56% | rMAE for Test Set is: 2.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:38:18,362]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:38:28,325]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:38:34,334]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:38:38,955]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:38:52,410]\u001b[0m Trial 649 finished with value: 4.010208177327445 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005491185251002421, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.019170098931307833, 'dropout_rate_Layer_2': 0.360453312878892, 'dropout_rate_Layer_3': 0.1844829630559886, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009858257158573388, 'l1_Layer_2': 0.0014535500173505644, 'l1_Layer_3': 0.000402400340537936, 'n_units_Layer_1': 280, 'n_units_Layer_2': 235, 'n_units_Layer_3': 145}. Best is trial 603 with value: 3.87883733635604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.01 | sMAPE for Validation Set is: 14.46% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 50.68 | sMAPE for Test Set is: 46.48% | rMAE for Test Set is: 2.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:38:58,083]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:39:05,516]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:39:09,561]\u001b[0m Trial 667 finished with value: 3.9968324165357516 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009879050810707845, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14481399070310458, 'dropout_rate_Layer_2': 0.11124621120458195, 'dropout_rate_Layer_3': 0.30592930323814316, 'dropout_rate_Layer_4': 0.16781682358516137, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0011827895843295891, 'l1_Layer_2': 0.0032296375449782267, 'l1_Layer_3': 0.0002444112765565648, 'l1_Layer_4': 0.003210299803441385, 'n_units_Layer_1': 300, 'n_units_Layer_2': 180, 'n_units_Layer_3': 105, 'n_units_Layer_4': 295}. Best is trial 603 with value: 3.87883733635604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.00 | sMAPE for Validation Set is: 13.96% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 52.26 | sMAPE for Test Set is: 48.31% | rMAE for Test Set is: 2.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:39:13,984]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:39:51,072]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:40:00,042]\u001b[0m Trial 663 finished with value: 4.062594920718902 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005311143586078416, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.009243293826681695, 'dropout_rate_Layer_2': 0.3909162943364032, 'dropout_rate_Layer_3': 0.1394952262800016, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001086413746368551, 'l1_Layer_2': 0.0015259295524131685, 'l1_Layer_3': 0.0004313449220417586, 'n_units_Layer_1': 285, 'n_units_Layer_2': 255, 'n_units_Layer_3': 135}. Best is trial 603 with value: 3.87883733635604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.06 | sMAPE for Validation Set is: 14.58% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 49.22 | sMAPE for Test Set is: 45.01% | rMAE for Test Set is: 1.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:40:15,413]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:40:30,182]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:40:37,424]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:40:40,982]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:40:54,406]\u001b[0m Trial 669 finished with value: 4.13239667951784 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005743678387772679, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03138160319709627, 'dropout_rate_Layer_2': 0.3709172994307246, 'dropout_rate_Layer_3': 0.18199794138702172, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008327146073549689, 'l1_Layer_2': 0.0015301975409853753, 'l1_Layer_3': 0.00042607196268630755, 'n_units_Layer_1': 285, 'n_units_Layer_2': 260, 'n_units_Layer_3': 140}. Best is trial 603 with value: 3.87883733635604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.13 | sMAPE for Validation Set is: 14.82% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 49.11 | sMAPE for Test Set is: 44.70% | rMAE for Test Set is: 1.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:41:01,809]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:41:16,879]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:41:24,555]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:41:36,745]\u001b[0m Trial 673 finished with value: 4.216543260643409 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005004400105565976, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015321688607746683, 'dropout_rate_Layer_2': 0.3373534759857725, 'dropout_rate_Layer_3': 0.1553585212761824, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014667914900012215, 'l1_Layer_2': 0.0019314710620840039, 'l1_Layer_3': 0.0003825023007912767, 'n_units_Layer_1': 285, 'n_units_Layer_2': 260, 'n_units_Layer_3': 135}. Best is trial 603 with value: 3.87883733635604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.22 | sMAPE for Validation Set is: 15.03% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 50.33 | sMAPE for Test Set is: 46.14% | rMAE for Test Set is: 2.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:41:45,052]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:41:50,100]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:42:00,870]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:42:15,309]\u001b[0m Trial 683 finished with value: 4.2354947700739585 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015958206104764367, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015888992305166945, 'dropout_rate_Layer_2': 0.2425724341203298, 'dropout_rate_Layer_3': 0.1868997382070876, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008093140728102216, 'l1_Layer_2': 0.001966300858901567, 'l1_Layer_3': 0.0001648622174697096, 'n_units_Layer_1': 90, 'n_units_Layer_2': 255, 'n_units_Layer_3': 55}. Best is trial 603 with value: 3.87883733635604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.24 | sMAPE for Validation Set is: 14.90% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 48.82 | sMAPE for Test Set is: 44.51% | rMAE for Test Set is: 1.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:42:17,011]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:42:22,124]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:42:28,734]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:42:34,427]\u001b[0m Trial 679 finished with value: 4.097079083297467 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006427627058589696, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0021094037064118554, 'dropout_rate_Layer_2': 0.35201470661901263, 'dropout_rate_Layer_3': 0.162897653515198, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013739277624777479, 'l1_Layer_2': 0.0018581196065773152, 'l1_Layer_3': 0.0005510062694450002, 'n_units_Layer_1': 260, 'n_units_Layer_2': 230, 'n_units_Layer_3': 160}. Best is trial 603 with value: 3.87883733635604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.10 | sMAPE for Validation Set is: 14.71% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 51.06 | sMAPE for Test Set is: 46.96% | rMAE for Test Set is: 2.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:42:46,522]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:42:51,204]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:42:55,484]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:43:00,316]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:43:33,577]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:43:41,828]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:43:42,103]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:43:52,313]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:44:07,794]\u001b[0m Trial 688 finished with value: 4.2681094792072924 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006312231943678962, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01664719843362631, 'dropout_rate_Layer_2': 0.34786818344007825, 'dropout_rate_Layer_3': 0.16478600395448245, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.401312533898193e-05, 'l1_Layer_2': 0.0019445158531197133, 'l1_Layer_3': 0.00037729760105979717, 'n_units_Layer_1': 270, 'n_units_Layer_2': 265, 'n_units_Layer_3': 130}. Best is trial 603 with value: 3.87883733635604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.27 | sMAPE for Validation Set is: 15.20% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 54.88 | sMAPE for Test Set is: 51.65% | rMAE for Test Set is: 2.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:44:17,936]\u001b[0m Trial 685 finished with value: 4.06029138478728 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005116499973710514, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0005535896419711517, 'dropout_rate_Layer_2': 0.34797577783486844, 'dropout_rate_Layer_3': 0.13799740217173365, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011567592112524617, 'l1_Layer_2': 0.0020854808967173087, 'l1_Layer_3': 0.00038933687166311674, 'n_units_Layer_1': 285, 'n_units_Layer_2': 270, 'n_units_Layer_3': 130}. Best is trial 603 with value: 3.87883733635604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.06 | sMAPE for Validation Set is: 14.57% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 50.88 | sMAPE for Test Set is: 46.65% | rMAE for Test Set is: 2.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:44:30,163]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:44:44,918]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:44:48,346]\u001b[0m Trial 700 finished with value: 4.155263019225724 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009788375171207227, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15939176540747466, 'dropout_rate_Layer_2': 0.34234680273049745, 'dropout_rate_Layer_3': 0.001146295076994569, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0072778480812898715, 'l1_Layer_2': 0.022278980564549335, 'l1_Layer_3': 1.2661773805038291e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 90, 'n_units_Layer_3': 295}. Best is trial 603 with value: 3.87883733635604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.16 | sMAPE for Validation Set is: 14.48% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 54.13 | sMAPE for Test Set is: 50.48% | rMAE for Test Set is: 2.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:44:56,115]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:45:01,533]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:45:09,327]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:46:06,800]\u001b[0m Trial 699 finished with value: 4.067636381435305 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005199105245203198, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02907702560108196, 'dropout_rate_Layer_2': 0.3387871182023282, 'dropout_rate_Layer_3': 0.13576427350267986, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009831409337481823, 'l1_Layer_2': 0.001327054730921409, 'l1_Layer_3': 0.000551462347962914, 'n_units_Layer_1': 295, 'n_units_Layer_2': 235, 'n_units_Layer_3': 145}. Best is trial 603 with value: 3.87883733635604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.07 | sMAPE for Validation Set is: 14.66% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 50.36 | sMAPE for Test Set is: 46.22% | rMAE for Test Set is: 2.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:46:11,204]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:46:12,054]\u001b[0m Trial 706 finished with value: 4.072944686158231 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005119238686240312, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.001678366643482428, 'dropout_rate_Layer_2': 0.34605275292706295, 'dropout_rate_Layer_3': 0.13713310724786298, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.224957174242454e-05, 'l1_Layer_2': 0.0011987536537983279, 'l1_Layer_3': 0.00034114589193335584, 'n_units_Layer_1': 270, 'n_units_Layer_2': 275, 'n_units_Layer_3': 130}. Best is trial 603 with value: 3.87883733635604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.07 | sMAPE for Validation Set is: 14.45% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 49.11 | sMAPE for Test Set is: 44.70% | rMAE for Test Set is: 1.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:46:20,519]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:46:23,739]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:46:31,168]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:46:35,361]\u001b[0m Trial 708 finished with value: 4.371472818942234 and parameters: {'n_hidden': 3, 'learning_rate': 0.000584491328355026, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02864631955225289, 'dropout_rate_Layer_2': 0.3577785768603712, 'dropout_rate_Layer_3': 0.13392566437562586, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.758614126810932e-05, 'l1_Layer_2': 0.0019405260700488599, 'l1_Layer_3': 0.0004627877591506323, 'n_units_Layer_1': 270, 'n_units_Layer_2': 260, 'n_units_Layer_3': 135}. Best is trial 603 with value: 3.87883733635604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.37 | sMAPE for Validation Set is: 15.55% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 50.07 | sMAPE for Test Set is: 45.81% | rMAE for Test Set is: 2.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:46:47,946]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:46:56,282]\u001b[0m Trial 710 finished with value: 4.245771981914949 and parameters: {'n_hidden': 3, 'learning_rate': 0.001894486794246962, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.025769411137984838, 'dropout_rate_Layer_2': 0.2650759043579345, 'dropout_rate_Layer_3': 0.1765790443684937, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011341106991344387, 'l1_Layer_2': 0.001656445200003755, 'l1_Layer_3': 0.00014757850177713914, 'n_units_Layer_1': 105, 'n_units_Layer_2': 255, 'n_units_Layer_3': 65}. Best is trial 603 with value: 3.87883733635604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.25 | sMAPE for Validation Set is: 14.96% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 49.19 | sMAPE for Test Set is: 44.93% | rMAE for Test Set is: 1.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:46:59,630]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:47:06,998]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:47:09,719]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:47:14,142]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:47:20,353]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:47:22,523]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:47:28,132]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:47:39,810]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:47:48,955]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:47:52,032]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:47:55,720]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:47:59,538]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:48:07,073]\u001b[0m Trial 712 finished with value: 4.344723376231605 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005064835172496877, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015594657855147666, 'dropout_rate_Layer_2': 0.35412091066976026, 'dropout_rate_Layer_3': 0.14974520951937942, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.02324492885841e-05, 'l1_Layer_2': 0.0015510896811242083, 'l1_Layer_3': 0.0005148245148480654, 'n_units_Layer_1': 300, 'n_units_Layer_2': 270, 'n_units_Layer_3': 125}. Best is trial 603 with value: 3.87883733635604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.34 | sMAPE for Validation Set is: 15.38% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 51.54 | sMAPE for Test Set is: 47.49% | rMAE for Test Set is: 2.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:48:09,258]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:48:21,377]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:48:31,369]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:49:02,904]\u001b[0m Trial 726 finished with value: 4.0156204424993565 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006361111960073463, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.009320568964992122, 'dropout_rate_Layer_2': 0.33958690535100894, 'dropout_rate_Layer_3': 0.15266349707574225, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001225444432487396, 'l1_Layer_2': 0.0018213141682849167, 'l1_Layer_3': 0.00027153180111563616, 'n_units_Layer_1': 295, 'n_units_Layer_2': 220, 'n_units_Layer_3': 160}. Best is trial 603 with value: 3.87883733635604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.02 | sMAPE for Validation Set is: 14.31% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 48.29 | sMAPE for Test Set is: 43.79% | rMAE for Test Set is: 1.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:49:09,111]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:49:39,533]\u001b[0m Trial 729 finished with value: 4.027346911363947 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005638716960847294, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02363250065510686, 'dropout_rate_Layer_2': 0.34054661047506674, 'dropout_rate_Layer_3': 0.1533033438855115, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011716546227489699, 'l1_Layer_2': 0.0017258277989140225, 'l1_Layer_3': 0.00045287096381863804, 'n_units_Layer_1': 295, 'n_units_Layer_2': 220, 'n_units_Layer_3': 160}. Best is trial 603 with value: 3.87883733635604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.03 | sMAPE for Validation Set is: 14.56% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 48.93 | sMAPE for Test Set is: 44.58% | rMAE for Test Set is: 1.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:49:48,468]\u001b[0m Trial 735 finished with value: 4.441905919958732 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008832663708033482, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14568380160618255, 'dropout_rate_Layer_2': 0.021185831298217328, 'dropout_rate_Layer_3': 0.026487709745976355, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0026929708530471536, 'l1_Layer_2': 0.028486572796269205, 'l1_Layer_3': 3.174377308940644e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 115, 'n_units_Layer_3': 265}. Best is trial 603 with value: 3.87883733635604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.44 | sMAPE for Validation Set is: 15.64% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 50.94 | sMAPE for Test Set is: 46.77% | rMAE for Test Set is: 2.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:49:49,445]\u001b[0m Trial 733 finished with value: 3.8906032846011596 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005655051923370355, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00619963654813188, 'dropout_rate_Layer_2': 0.05226286435708748, 'dropout_rate_Layer_3': 0.140908188249765, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012445713009047118, 'l1_Layer_2': 0.002704730584354988, 'l1_Layer_3': 0.00042470875261170217, 'n_units_Layer_1': 280, 'n_units_Layer_2': 220, 'n_units_Layer_3': 155}. Best is trial 603 with value: 3.87883733635604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.89 | sMAPE for Validation Set is: 13.97% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 48.89 | sMAPE for Test Set is: 44.53% | rMAE for Test Set is: 1.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:49:56,359]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:50:01,549]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:50:05,684]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:50:09,903]\u001b[0m Trial 734 finished with value: 4.06238617058916 and parameters: {'n_hidden': 3, 'learning_rate': 0.002072189612708986, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0013710221261312551, 'dropout_rate_Layer_2': 0.2676891869431134, 'dropout_rate_Layer_3': 0.14417719475707685, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011624845151889046, 'l1_Layer_2': 0.0012937185625270155, 'l1_Layer_3': 0.0003572542837489075, 'n_units_Layer_1': 95, 'n_units_Layer_2': 270, 'n_units_Layer_3': 85}. Best is trial 603 with value: 3.87883733635604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.06 | sMAPE for Validation Set is: 14.42% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 50.40 | sMAPE for Test Set is: 46.30% | rMAE for Test Set is: 2.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:50:10,571]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:50:29,226]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:50:48,427]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:50:50,404]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:51:00,832]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:51:04,581]\u001b[0m Trial 736 finished with value: 3.9326584766170103 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005704209471173293, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.020706114832896822, 'dropout_rate_Layer_2': 0.3381576112766144, 'dropout_rate_Layer_3': 0.162725699686454, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009314940119042192, 'l1_Layer_2': 0.0012648861690549907, 'l1_Layer_3': 0.0003105820680784331, 'n_units_Layer_1': 295, 'n_units_Layer_2': 220, 'n_units_Layer_3': 160}. Best is trial 603 with value: 3.87883733635604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.93 | sMAPE for Validation Set is: 14.07% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 47.14 | sMAPE for Test Set is: 42.59% | rMAE for Test Set is: 1.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:51:42,414]\u001b[0m Trial 743 finished with value: 3.956605699199599 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005369976628761342, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2049020954363016, 'dropout_rate_Layer_2': 0.09181085652403964, 'dropout_rate_Layer_3': 0.04045352491925791, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007837152158425258, 'l1_Layer_2': 0.0429907502215503, 'l1_Layer_3': 2.035655881872503e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 70, 'n_units_Layer_3': 260}. Best is trial 603 with value: 3.87883733635604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.96 | sMAPE for Validation Set is: 14.06% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 16.13 | sMAPE for Test Set is: 20.01% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:51:47,727]\u001b[0m Trial 745 finished with value: 3.891100820335062 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006461470324122253, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02159778399729497, 'dropout_rate_Layer_2': 0.05962563903967106, 'dropout_rate_Layer_3': 0.11556521848268653, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010686075854888155, 'l1_Layer_2': 0.001767661018185233, 'l1_Layer_3': 0.0003411639523897378, 'n_units_Layer_1': 300, 'n_units_Layer_2': 235, 'n_units_Layer_3': 150}. Best is trial 603 with value: 3.87883733635604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.89 | sMAPE for Validation Set is: 13.99% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 47.83 | sMAPE for Test Set is: 43.37% | rMAE for Test Set is: 1.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:51:52,773]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:51:57,776]\u001b[0m Trial 747 finished with value: 4.1287557421377 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029795643453312086, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0012758131859485421, 'dropout_rate_Layer_2': 0.284239165072017, 'dropout_rate_Layer_3': 0.17265037251678095, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010926336646019965, 'l1_Layer_2': 0.0014901727509423295, 'l1_Layer_3': 0.00024919473771692704, 'n_units_Layer_1': 80, 'n_units_Layer_2': 260, 'n_units_Layer_3': 75}. Best is trial 603 with value: 3.87883733635604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.13 | sMAPE for Validation Set is: 14.70% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 51.17 | sMAPE for Test Set is: 47.09% | rMAE for Test Set is: 2.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:52:06,769]\u001b[0m Trial 748 finished with value: 3.9338937673905208 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015293605477734757, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0030896071823799183, 'dropout_rate_Layer_2': 0.28925817220392197, 'dropout_rate_Layer_3': 0.021182846735190726, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010987574466304805, 'l1_Layer_2': 0.0012017546036797305, 'l1_Layer_3': 0.00014657918171809146, 'n_units_Layer_1': 105, 'n_units_Layer_2': 270, 'n_units_Layer_3': 85}. Best is trial 603 with value: 3.87883733635604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.93 | sMAPE for Validation Set is: 13.93% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 48.76 | sMAPE for Test Set is: 44.23% | rMAE for Test Set is: 1.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:52:15,691]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:52:24,334]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:52:33,819]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:53:08,296]\u001b[0m Trial 751 finished with value: 3.720768816012857 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005064333025774007, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.026198862744372095, 'dropout_rate_Layer_2': 0.05515092878854914, 'dropout_rate_Layer_3': 0.11857406172040161, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009813504098989782, 'l1_Layer_2': 0.0013294223329211629, 'l1_Layer_3': 0.00022595065380485595, 'n_units_Layer_1': 300, 'n_units_Layer_2': 235, 'n_units_Layer_3': 140}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.72 | sMAPE for Validation Set is: 13.38% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 45.67 | sMAPE for Test Set is: 41.01% | rMAE for Test Set is: 1.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:53:16,633]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:53:25,139]\u001b[0m Trial 752 finished with value: 3.8537618751357634 and parameters: {'n_hidden': 3, 'learning_rate': 0.000501793967669644, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.027105840494719667, 'dropout_rate_Layer_2': 0.05975243184237136, 'dropout_rate_Layer_3': 0.11610764072186461, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010213751923133715, 'l1_Layer_2': 0.0013495729291622982, 'l1_Layer_3': 0.0003408084176581039, 'n_units_Layer_1': 300, 'n_units_Layer_2': 235, 'n_units_Layer_3': 140}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.85 | sMAPE for Validation Set is: 13.76% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 45.57 | sMAPE for Test Set is: 40.93% | rMAE for Test Set is: 1.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:53:30,834]\u001b[0m Trial 754 finished with value: 3.850986649394588 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005011652804732252, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.027803698504949646, 'dropout_rate_Layer_2': 0.05727996215024299, 'dropout_rate_Layer_3': 0.11714515498657212, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008184918280638613, 'l1_Layer_2': 0.0015154762487989883, 'l1_Layer_3': 0.00033519474779446185, 'n_units_Layer_1': 295, 'n_units_Layer_2': 235, 'n_units_Layer_3': 140}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.85 | sMAPE for Validation Set is: 13.75% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 46.61 | sMAPE for Test Set is: 41.96% | rMAE for Test Set is: 1.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:53:34,446]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:53:52,795]\u001b[0m Trial 756 finished with value: 3.8638988984107083 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005062107475974308, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02374201446103793, 'dropout_rate_Layer_2': 0.046436235555896196, 'dropout_rate_Layer_3': 0.11988135974706249, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008545712279670155, 'l1_Layer_2': 0.0016006950806009852, 'l1_Layer_3': 0.00034523490185429587, 'n_units_Layer_1': 290, 'n_units_Layer_2': 235, 'n_units_Layer_3': 165}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.86 | sMAPE for Validation Set is: 13.81% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 47.38 | sMAPE for Test Set is: 42.81% | rMAE for Test Set is: 1.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:54:33,263]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:54:38,677]\u001b[0m Trial 760 finished with value: 3.7706904157135583 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005054224843220335, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.028044273528152534, 'dropout_rate_Layer_2': 0.06341230809556475, 'dropout_rate_Layer_3': 0.10537316568859431, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007628810303748757, 'l1_Layer_2': 0.0009764699701394228, 'l1_Layer_3': 0.00022280505588281792, 'n_units_Layer_1': 300, 'n_units_Layer_2': 235, 'n_units_Layer_3': 140}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.77 | sMAPE for Validation Set is: 13.55% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 46.56 | sMAPE for Test Set is: 42.00% | rMAE for Test Set is: 1.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:54:46,708]\u001b[0m Trial 762 finished with value: 4.055557943085552 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007654021937358021, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14453744237773722, 'dropout_rate_Layer_2': 0.12792904498331406, 'dropout_rate_Layer_3': 0.35487246526012933, 'dropout_rate_Layer_4': 0.21802901402292876, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.001783577219761166, 'l1_Layer_2': 0.010992242159108741, 'l1_Layer_3': 0.0004025611904784756, 'l1_Layer_4': 0.0004500407813492788, 'n_units_Layer_1': 275, 'n_units_Layer_2': 230, 'n_units_Layer_3': 110, 'n_units_Layer_4': 240}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.06 | sMAPE for Validation Set is: 14.33% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 49.43 | sMAPE for Test Set is: 45.11% | rMAE for Test Set is: 1.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:54:51,816]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:54:52,535]\u001b[0m Trial 758 finished with value: 3.868807808797228 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005499129306798658, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0216081539053749, 'dropout_rate_Layer_2': 0.05840667755865628, 'dropout_rate_Layer_3': 0.11345828127627786, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008717405967741289, 'l1_Layer_2': 0.0007626462448622726, 'l1_Layer_3': 0.00019383012305543477, 'n_units_Layer_1': 290, 'n_units_Layer_2': 235, 'n_units_Layer_3': 140}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.87 | sMAPE for Validation Set is: 13.85% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 47.42 | sMAPE for Test Set is: 42.81% | rMAE for Test Set is: 1.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:54:56,281]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:55:43,353]\u001b[0m Trial 766 finished with value: 3.745584576393347 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005019319517275639, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.038975685572251055, 'dropout_rate_Layer_2': 0.058985598861036964, 'dropout_rate_Layer_3': 0.11465012276344165, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007432344471497946, 'l1_Layer_2': 0.0009611656096893515, 'l1_Layer_3': 0.0001741581447800342, 'n_units_Layer_1': 295, 'n_units_Layer_2': 235, 'n_units_Layer_3': 140}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 13.46% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 46.42 | sMAPE for Test Set is: 41.92% | rMAE for Test Set is: 1.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:55:52,798]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:55:52,910]\u001b[0m Trial 764 finished with value: 3.967006764110859 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009789625908145578, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12288066453501074, 'dropout_rate_Layer_2': 0.12085833427710913, 'dropout_rate_Layer_3': 0.04135468761765636, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006125793365829358, 'l1_Layer_2': 0.030680484170502863, 'l1_Layer_3': 2.1643429342461044e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 80, 'n_units_Layer_3': 270}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.97 | sMAPE for Validation Set is: 14.23% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 14.64 | sMAPE for Test Set is: 18.71% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:56:00,202]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:56:04,439]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:56:09,854]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:56:15,374]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:56:29,214]\u001b[0m Trial 767 finished with value: 3.8657875804538064 and parameters: {'n_hidden': 3, 'learning_rate': 0.000502059780696653, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.037108104679458534, 'dropout_rate_Layer_2': 0.05718827389745598, 'dropout_rate_Layer_3': 0.11730529378940396, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006391994313226244, 'l1_Layer_2': 0.0007268417750021451, 'l1_Layer_3': 0.0001977410257062105, 'n_units_Layer_1': 295, 'n_units_Layer_2': 235, 'n_units_Layer_3': 140}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.87 | sMAPE for Validation Set is: 13.91% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 47.34 | sMAPE for Test Set is: 42.74% | rMAE for Test Set is: 1.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:56:32,702]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:56:32,909]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:56:55,020]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:57:02,025]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:57:10,818]\u001b[0m Trial 775 finished with value: 4.071322132356761 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015463505665832392, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0025053673390073687, 'dropout_rate_Layer_2': 0.29944177998527965, 'dropout_rate_Layer_3': 0.16664407705120465, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0017884316205082646, 'l1_Layer_2': 0.0015542552664662764, 'l1_Layer_3': 0.00027959635199564895, 'n_units_Layer_1': 100, 'n_units_Layer_2': 280, 'n_units_Layer_3': 95}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.07 | sMAPE for Validation Set is: 14.45% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 52.01 | sMAPE for Test Set is: 48.03% | rMAE for Test Set is: 2.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:57:13,695]\u001b[0m Trial 774 finished with value: 4.153098799929977 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016347339316855221, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0022521224858584954, 'dropout_rate_Layer_2': 0.296613387026428, 'dropout_rate_Layer_3': 0.09665890333511844, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015601143722969307, 'l1_Layer_2': 0.0016505024434454632, 'l1_Layer_3': 0.00029305652415189597, 'n_units_Layer_1': 100, 'n_units_Layer_2': 280, 'n_units_Layer_3': 90}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.15 | sMAPE for Validation Set is: 14.72% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 52.38 | sMAPE for Test Set is: 48.32% | rMAE for Test Set is: 2.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:57:21,736]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:57:33,357]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:57:35,785]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:58:20,081]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:58:31,219]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:58:37,171]\u001b[0m Trial 781 finished with value: 3.9054290433315177 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005570654618116579, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.021256944444725465, 'dropout_rate_Layer_2': 0.07394687960257601, 'dropout_rate_Layer_3': 0.10313895722547181, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006129494129352574, 'l1_Layer_2': 0.0007959641955791558, 'l1_Layer_3': 0.00021935800722519392, 'n_units_Layer_1': 300, 'n_units_Layer_2': 230, 'n_units_Layer_3': 150}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.91 | sMAPE for Validation Set is: 14.05% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 47.16 | sMAPE for Test Set is: 42.55% | rMAE for Test Set is: 1.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:58:47,844]\u001b[0m Trial 785 finished with value: 3.793162787564949 and parameters: {'n_hidden': 3, 'learning_rate': 0.000556450870352091, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02979602264997891, 'dropout_rate_Layer_2': 0.06808053380895047, 'dropout_rate_Layer_3': 0.1171674435282247, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006220555829088008, 'l1_Layer_2': 0.0008329324990073133, 'l1_Layer_3': 0.00013297028775603853, 'n_units_Layer_1': 290, 'n_units_Layer_2': 225, 'n_units_Layer_3': 150}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.79 | sMAPE for Validation Set is: 13.57% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 48.11 | sMAPE for Test Set is: 43.54% | rMAE for Test Set is: 1.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:58:51,722]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:58:58,908]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:59:11,967]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:59:15,407]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:59:21,276]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:59:37,787]\u001b[0m Trial 786 finished with value: 3.801360547053337 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005699914275498677, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00933839262408069, 'dropout_rate_Layer_2': 0.06897161915361687, 'dropout_rate_Layer_3': 0.11776647588699451, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006695127170992417, 'l1_Layer_2': 0.0005801357464972029, 'l1_Layer_3': 0.00013909503329083065, 'n_units_Layer_1': 290, 'n_units_Layer_2': 235, 'n_units_Layer_3': 150}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.80 | sMAPE for Validation Set is: 13.50% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 45.80 | sMAPE for Test Set is: 40.99% | rMAE for Test Set is: 1.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 04:59:44,637]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 04:59:53,931]\u001b[0m Trial 794 finished with value: 4.804210544699525 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006070694481394937, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1125584120600242, 'dropout_rate_Layer_2': 0.2837240550621579, 'dropout_rate_Layer_3': 0.079342967356298, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0030646537841151965, 'l1_Layer_2': 0.014586667617902003, 'l1_Layer_3': 0.007461412757583774, 'n_units_Layer_1': 195, 'n_units_Layer_2': 60, 'n_units_Layer_3': 250}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.80 | sMAPE for Validation Set is: 17.00% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 55.53 | sMAPE for Test Set is: 52.35% | rMAE for Test Set is: 2.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:00:11,000]\u001b[0m Trial 790 finished with value: 3.816078330210877 and parameters: {'n_hidden': 3, 'learning_rate': 0.000565999608379415, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04555256231930176, 'dropout_rate_Layer_2': 0.06650271785590138, 'dropout_rate_Layer_3': 0.1025329995964064, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005534238284729123, 'l1_Layer_2': 0.000590236081596511, 'l1_Layer_3': 0.0001482769900072056, 'n_units_Layer_1': 290, 'n_units_Layer_2': 220, 'n_units_Layer_3': 145}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.82 | sMAPE for Validation Set is: 13.72% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 45.84 | sMAPE for Test Set is: 41.06% | rMAE for Test Set is: 1.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:00:15,193]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:00:42,432]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:00:48,254]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:00:54,109]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:01:08,987]\u001b[0m Trial 792 finished with value: 3.874185497377797 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005578126208021623, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.029269837794606145, 'dropout_rate_Layer_2': 0.06719294513324678, 'dropout_rate_Layer_3': 0.09125523079515482, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005783183107992961, 'l1_Layer_2': 0.0009000091447340824, 'l1_Layer_3': 0.00013264108100118332, 'n_units_Layer_1': 290, 'n_units_Layer_2': 220, 'n_units_Layer_3': 145}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.87 | sMAPE for Validation Set is: 13.86% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 47.12 | sMAPE for Test Set is: 42.34% | rMAE for Test Set is: 1.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:01:15,522]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:01:30,001]\u001b[0m Trial 801 finished with value: 4.401605307863282 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008178850691778482, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1774516643377219, 'dropout_rate_Layer_2': 0.11201466263254387, 'dropout_rate_Layer_3': 0.3558158502614917, 'dropout_rate_Layer_4': 0.23555246630862028, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002067780036547426, 'l1_Layer_2': 0.03128340228153061, 'l1_Layer_3': 0.0021476800711497084, 'l1_Layer_4': 0.005683492332124416, 'n_units_Layer_1': 270, 'n_units_Layer_2': 230, 'n_units_Layer_3': 125, 'n_units_Layer_4': 250}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.40 | sMAPE for Validation Set is: 15.48% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 54.19 | sMAPE for Test Set is: 50.70% | rMAE for Test Set is: 2.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:01:30,347]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:01:37,321]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:01:39,419]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:01:44,328]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:01:57,672]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:02:15,856]\u001b[0m Trial 803 finished with value: 3.8038087365664914 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006487088020095104, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01942361365991152, 'dropout_rate_Layer_2': 0.06186191267068109, 'dropout_rate_Layer_3': 0.09535808618569017, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006031210937242008, 'l1_Layer_2': 0.0006936704694809903, 'l1_Layer_3': 0.00018036681406561437, 'n_units_Layer_1': 290, 'n_units_Layer_2': 225, 'n_units_Layer_3': 140}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.80 | sMAPE for Validation Set is: 13.66% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 47.10 | sMAPE for Test Set is: 42.50% | rMAE for Test Set is: 1.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:02:32,066]\u001b[0m Trial 809 finished with value: 3.7824594201505897 and parameters: {'n_hidden': 3, 'learning_rate': 0.000641614033122793, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.020696791672608298, 'dropout_rate_Layer_2': 0.06141347129437005, 'dropout_rate_Layer_3': 0.10111643048824756, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006203056503156223, 'l1_Layer_2': 0.0003774494464575547, 'l1_Layer_3': 0.00015310634050201623, 'n_units_Layer_1': 290, 'n_units_Layer_2': 225, 'n_units_Layer_3': 140}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.78 | sMAPE for Validation Set is: 13.42% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 44.58 | sMAPE for Test Set is: 39.69% | rMAE for Test Set is: 1.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:02:37,030]\u001b[0m Trial 807 finished with value: 3.725077811332355 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006603327988476421, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.019736153081500427, 'dropout_rate_Layer_2': 0.06357999332672044, 'dropout_rate_Layer_3': 0.09333386147491818, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006599103641263285, 'l1_Layer_2': 0.0007009861594873183, 'l1_Layer_3': 0.00018630038412709797, 'n_units_Layer_1': 290, 'n_units_Layer_2': 225, 'n_units_Layer_3': 140}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.73 | sMAPE for Validation Set is: 13.27% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 44.41 | sMAPE for Test Set is: 39.61% | rMAE for Test Set is: 1.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:02:38,775]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:02:43,510]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:02:45,538]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:02:51,270]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:03:03,312]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:03:10,491]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:03:16,264]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:03:20,063]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:03:24,724]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:03:33,906]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:03:38,750]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:03:42,764]\u001b[0m Trial 815 finished with value: 3.835337904002119 and parameters: {'n_hidden': 3, 'learning_rate': 0.000660206273447237, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.019132741048890105, 'dropout_rate_Layer_2': 0.0705580476818662, 'dropout_rate_Layer_3': 0.09519410198745269, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004223568177791965, 'l1_Layer_2': 0.0004036935027720607, 'l1_Layer_3': 0.0001715750859676859, 'n_units_Layer_1': 290, 'n_units_Layer_2': 215, 'n_units_Layer_3': 140}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.84 | sMAPE for Validation Set is: 13.75% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 46.64 | sMAPE for Test Set is: 41.94% | rMAE for Test Set is: 1.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:04:03,432]\u001b[0m Trial 817 finished with value: 3.998491653481787 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018397692215497558, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007452014830904928, 'dropout_rate_Layer_2': 0.30630250992937125, 'dropout_rate_Layer_3': 0.17870789114081906, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010693557019268614, 'l1_Layer_2': 0.0011246921611728048, 'l1_Layer_3': 0.00024260936448931576, 'n_units_Layer_1': 90, 'n_units_Layer_2': 275, 'n_units_Layer_3': 65}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.00 | sMAPE for Validation Set is: 13.94% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 54.69 | sMAPE for Test Set is: 51.20% | rMAE for Test Set is: 2.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:04:20,285]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:04:40,375]\u001b[0m Trial 824 finished with value: 3.897724236430342 and parameters: {'n_hidden': 3, 'learning_rate': 0.000595246331975434, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02655691967033267, 'dropout_rate_Layer_2': 0.07171963630560602, 'dropout_rate_Layer_3': 0.10175937046175193, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00038671339116517014, 'l1_Layer_2': 0.0003151799748224475, 'l1_Layer_3': 0.0002121394142336916, 'n_units_Layer_1': 295, 'n_units_Layer_2': 235, 'n_units_Layer_3': 150}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.90 | sMAPE for Validation Set is: 14.02% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 46.53 | sMAPE for Test Set is: 41.83% | rMAE for Test Set is: 1.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:04:44,956]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:04:49,729]\u001b[0m Trial 825 finished with value: 3.970985439817664 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005910072757125699, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.025410880095726267, 'dropout_rate_Layer_2': 0.0730975621336111, 'dropout_rate_Layer_3': 0.0785855541471506, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003911610116442228, 'l1_Layer_2': 0.00024378353223879844, 'l1_Layer_3': 0.00020683575443947448, 'n_units_Layer_1': 300, 'n_units_Layer_2': 225, 'n_units_Layer_3': 140}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.97 | sMAPE for Validation Set is: 14.29% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 47.10 | sMAPE for Test Set is: 42.38% | rMAE for Test Set is: 1.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:04:52,743]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:05:03,268]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:05:06,732]\u001b[0m Trial 826 finished with value: 3.833726076769851 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005838040152889381, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.025113184992041942, 'dropout_rate_Layer_2': 0.0722156018912284, 'dropout_rate_Layer_3': 0.09809558059452912, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004150272190717456, 'l1_Layer_2': 0.00026230263864766, 'l1_Layer_3': 0.00019958057732463058, 'n_units_Layer_1': 300, 'n_units_Layer_2': 225, 'n_units_Layer_3': 140}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.83 | sMAPE for Validation Set is: 13.65% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 45.11 | sMAPE for Test Set is: 40.40% | rMAE for Test Set is: 1.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:05:24,790]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:05:27,343]\u001b[0m Trial 830 finished with value: 3.9281236195896323 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006885735323090272, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02609082809302111, 'dropout_rate_Layer_2': 0.07185218526099191, 'dropout_rate_Layer_3': 0.06089396981086843, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00039591989757195405, 'l1_Layer_2': 0.00021918613105352246, 'l1_Layer_3': 0.00011818772276543885, 'n_units_Layer_1': 295, 'n_units_Layer_2': 235, 'n_units_Layer_3': 135}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.93 | sMAPE for Validation Set is: 14.07% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 47.38 | sMAPE for Test Set is: 42.80% | rMAE for Test Set is: 1.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:05:33,897]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:05:51,757]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:05:55,139]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:06:00,475]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:06:02,740]\u001b[0m Trial 833 finished with value: 4.038801713361713 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006581352931326088, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01400043575907954, 'dropout_rate_Layer_2': 0.07864941467317622, 'dropout_rate_Layer_3': 0.07571946440665671, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003130385369236804, 'l1_Layer_2': 0.00027577623549560884, 'l1_Layer_3': 0.00021678968495183942, 'n_units_Layer_1': 300, 'n_units_Layer_2': 235, 'n_units_Layer_3': 135}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.04 | sMAPE for Validation Set is: 14.36% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 48.51 | sMAPE for Test Set is: 44.09% | rMAE for Test Set is: 1.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:06:11,343]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:06:13,467]\u001b[0m Trial 835 finished with value: 3.9661669219635987 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007733316448774682, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02736643368074619, 'dropout_rate_Layer_2': 0.06867743454082646, 'dropout_rate_Layer_3': 0.05890532805082534, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003667466641235761, 'l1_Layer_2': 0.00018108109397348403, 'l1_Layer_3': 0.0001374775432250607, 'n_units_Layer_1': 300, 'n_units_Layer_2': 235, 'n_units_Layer_3': 135}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.97 | sMAPE for Validation Set is: 14.32% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 47.36 | sMAPE for Test Set is: 42.74% | rMAE for Test Set is: 1.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:06:17,865]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:06:35,575]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:06:50,843]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:07:00,826]\u001b[0m Trial 843 finished with value: 3.9525327853439243 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007759300308849154, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.045150259934347764, 'dropout_rate_Layer_2': 0.06629483093626029, 'dropout_rate_Layer_3': 0.055122665570696325, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00027759527810003877, 'l1_Layer_2': 0.0003367806374647137, 'l1_Layer_3': 0.00013842332676066555, 'n_units_Layer_1': 300, 'n_units_Layer_2': 245, 'n_units_Layer_3': 130}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.95 | sMAPE for Validation Set is: 14.24% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 47.29 | sMAPE for Test Set is: 42.70% | rMAE for Test Set is: 1.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:07:03,330]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:07:09,966]\u001b[0m Trial 842 finished with value: 3.9861079665301786 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007431780799641052, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.035833448275458785, 'dropout_rate_Layer_2': 0.03970137535271249, 'dropout_rate_Layer_3': 0.05139789832565088, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00042092705045424677, 'l1_Layer_2': 0.00018271690308624007, 'l1_Layer_3': 0.00018165663668484597, 'n_units_Layer_1': 300, 'n_units_Layer_2': 245, 'n_units_Layer_3': 140}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.99 | sMAPE for Validation Set is: 14.19% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 46.98 | sMAPE for Test Set is: 42.23% | rMAE for Test Set is: 1.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:07:13,027]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:07:45,075]\u001b[0m Trial 845 finished with value: 4.009305316190976 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007984462335531441, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04508626882668171, 'dropout_rate_Layer_2': 0.06413260438405498, 'dropout_rate_Layer_3': 0.048419866192026456, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004841902758291253, 'l1_Layer_2': 0.00032171512555955817, 'l1_Layer_3': 0.0001885106716486774, 'n_units_Layer_1': 300, 'n_units_Layer_2': 245, 'n_units_Layer_3': 130}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.01 | sMAPE for Validation Set is: 14.13% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 45.90 | sMAPE for Test Set is: 41.11% | rMAE for Test Set is: 1.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:07:54,115]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:07:59,181]\u001b[0m Trial 849 finished with value: 3.8702448864301933 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007621189120403611, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04809576472048983, 'dropout_rate_Layer_2': 0.06473086222174915, 'dropout_rate_Layer_3': 0.05616087470986983, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005404166770001606, 'l1_Layer_2': 0.00033643483726858306, 'l1_Layer_3': 0.0001088509572929218, 'n_units_Layer_1': 290, 'n_units_Layer_2': 240, 'n_units_Layer_3': 125}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.87 | sMAPE for Validation Set is: 13.89% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 46.39 | sMAPE for Test Set is: 41.74% | rMAE for Test Set is: 1.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:07:59,727]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:08:04,923]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:08:08,074]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:08:08,378]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:08:11,340]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:08:19,464]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:08:28,223]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:08:38,744]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:08:40,925]\u001b[0m Trial 852 finished with value: 4.408272745210812 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012697896551746404, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13149349146179493, 'dropout_rate_Layer_2': 0.17004689284976224, 'dropout_rate_Layer_3': 0.06781489761940702, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0012576103836657423, 'l1_Layer_2': 0.031121896883093338, 'l1_Layer_3': 4.0856184685970066e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 105, 'n_units_Layer_3': 245}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.41 | sMAPE for Validation Set is: 15.36% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 55.02 | sMAPE for Test Set is: 51.63% | rMAE for Test Set is: 2.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:08:49,612]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:08:56,794]\u001b[0m Trial 858 finished with value: 4.1412756220842795 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011780506208937628, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.227670440192294, 'dropout_rate_Layer_2': 0.04582663427410141, 'dropout_rate_Layer_3': 0.3809613690904122, 'dropout_rate_Layer_4': 0.2599220878492437, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.909267103088432e-05, 'l1_Layer_2': 0.002957052836552079, 'l1_Layer_3': 0.00028095027280635387, 'l1_Layer_4': 6.559624277506187e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 250, 'n_units_Layer_3': 80, 'n_units_Layer_4': 215}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.14 | sMAPE for Validation Set is: 14.47% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 58.25 | sMAPE for Test Set is: 55.76% | rMAE for Test Set is: 2.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:09:00,398]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:09:00,888]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:09:04,923]\u001b[0m Trial 856 finished with value: 3.9355693417693463 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017753070176518638, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008696227301835705, 'dropout_rate_Layer_2': 0.3039231734555364, 'dropout_rate_Layer_3': 0.16217995054119863, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001104119688393209, 'l1_Layer_2': 0.0007098927002848145, 'l1_Layer_3': 0.0002775229850707228, 'n_units_Layer_1': 100, 'n_units_Layer_2': 295, 'n_units_Layer_3': 65}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.94 | sMAPE for Validation Set is: 13.91% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 49.76 | sMAPE for Test Set is: 45.40% | rMAE for Test Set is: 2.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:09:11,634]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:09:12,553]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:09:13,657]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:09:25,812]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:09:46,475]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:09:56,482]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:10:01,038]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:10:19,353]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:10:24,502]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:10:29,631]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:10:39,350]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:10:42,930]\u001b[0m Trial 869 finished with value: 3.8355521208197287 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005854178443880319, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01868623886306252, 'dropout_rate_Layer_2': 0.04753524254240871, 'dropout_rate_Layer_3': 0.11208758857958685, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006195317931507445, 'l1_Layer_2': 0.000854914458367689, 'l1_Layer_3': 0.00010076210216192717, 'n_units_Layer_1': 295, 'n_units_Layer_2': 230, 'n_units_Layer_3': 150}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.84 | sMAPE for Validation Set is: 13.78% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 45.76 | sMAPE for Test Set is: 40.97% | rMAE for Test Set is: 1.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:10:45,140]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:10:47,837]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:10:52,589]\u001b[0m Trial 867 finished with value: 4.097227055820581 and parameters: {'n_hidden': 3, 'learning_rate': 0.000582593518554295, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03950107494611948, 'dropout_rate_Layer_2': 0.056649312875197484, 'dropout_rate_Layer_3': 0.11390263241495337, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002462820629958337, 'l1_Layer_2': 0.0008477230830943672, 'l1_Layer_3': 0.0001671405666408047, 'n_units_Layer_1': 295, 'n_units_Layer_2': 230, 'n_units_Layer_3': 150}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.10 | sMAPE for Validation Set is: 14.78% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 49.71 | sMAPE for Test Set is: 45.25% | rMAE for Test Set is: 2.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:10:56,896]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:10:59,346]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:11:08,376]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:11:19,138]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:11:20,032]\u001b[0m Trial 879 finished with value: 4.128875565909631 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012552749946544415, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11659459268759631, 'dropout_rate_Layer_2': 0.16849938980011345, 'dropout_rate_Layer_3': 0.04871155070220315, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0025454277241846453, 'l1_Layer_2': 0.030713228603867736, 'l1_Layer_3': 2.0329387193952107e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 105, 'n_units_Layer_3': 245}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.13 | sMAPE for Validation Set is: 14.31% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 54.50 | sMAPE for Test Set is: 50.97% | rMAE for Test Set is: 2.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:11:25,724]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:11:30,228]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:11:34,961]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:11:50,758]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:11:56,359]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:12:01,757]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:12:19,468]\u001b[0m Trial 883 finished with value: 3.829988628407817 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005021136839432221, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008395446942419775, 'dropout_rate_Layer_2': 0.08641840566953557, 'dropout_rate_Layer_3': 0.09889538960527891, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006962598996157867, 'l1_Layer_2': 0.0009438904692719756, 'l1_Layer_3': 0.00011036837063738268, 'n_units_Layer_1': 290, 'n_units_Layer_2': 225, 'n_units_Layer_3': 145}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.83 | sMAPE for Validation Set is: 13.77% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 46.50 | sMAPE for Test Set is: 41.82% | rMAE for Test Set is: 1.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:12:24,885]\u001b[0m Trial 884 finished with value: 3.7890419644145026 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005019700320776849, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.009273115339453446, 'dropout_rate_Layer_2': 0.01966310626972836, 'dropout_rate_Layer_3': 0.09876163050965404, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006663635683474187, 'l1_Layer_2': 0.0009445457297266063, 'l1_Layer_3': 0.00021813509942318694, 'n_units_Layer_1': 290, 'n_units_Layer_2': 225, 'n_units_Layer_3': 145}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.79 | sMAPE for Validation Set is: 13.55% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 46.44 | sMAPE for Test Set is: 41.76% | rMAE for Test Set is: 1.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:12:48,067]\u001b[0m Trial 889 finished with value: 3.737113910409844 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005592549829165408, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.020126846897024403, 'dropout_rate_Layer_2': 0.0589071973154415, 'dropout_rate_Layer_3': 0.12265932814981989, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007196891832275081, 'l1_Layer_2': 0.0007592692894728609, 'l1_Layer_3': 0.00011527662512016233, 'n_units_Layer_1': 295, 'n_units_Layer_2': 235, 'n_units_Layer_3': 135}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.74 | sMAPE for Validation Set is: 13.24% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 45.20 | sMAPE for Test Set is: 40.34% | rMAE for Test Set is: 1.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:12:56,917]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:13:00,452]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:13:04,670]\u001b[0m Trial 894 finished with value: 3.931120225619473 and parameters: {'n_hidden': 3, 'learning_rate': 0.002321487838193567, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007275368851207952, 'dropout_rate_Layer_2': 0.26431882153771463, 'dropout_rate_Layer_3': 0.18781537843204565, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009308925735648154, 'l1_Layer_2': 0.0005892716018348218, 'l1_Layer_3': 0.0003873846917344383, 'n_units_Layer_1': 100, 'n_units_Layer_2': 290, 'n_units_Layer_3': 60}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.93 | sMAPE for Validation Set is: 13.80% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 50.97 | sMAPE for Test Set is: 46.84% | rMAE for Test Set is: 2.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:13:09,233]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:13:13,188]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:13:15,100]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:13:17,244]\u001b[0m Trial 893 finished with value: 3.755185884884805 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005529936754145976, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01379797504537409, 'dropout_rate_Layer_2': 0.08333420915836702, 'dropout_rate_Layer_3': 0.10441599169292835, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006181244704144389, 'l1_Layer_2': 0.0004265691447995083, 'l1_Layer_3': 0.00011003619356478891, 'n_units_Layer_1': 280, 'n_units_Layer_2': 235, 'n_units_Layer_3': 150}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.76 | sMAPE for Validation Set is: 13.42% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 45.05 | sMAPE for Test Set is: 40.43% | rMAE for Test Set is: 1.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:13:21,607]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:13:25,643]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:13:28,048]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:13:32,626]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:13:58,803]\u001b[0m Trial 904 finished with value: 4.266992234428835 and parameters: {'n_hidden': 3, 'learning_rate': 0.001515150430303745, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10460645998653449, 'dropout_rate_Layer_2': 0.20274768796287926, 'dropout_rate_Layer_3': 0.026218858245224914, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.002400871155358341, 'l1_Layer_2': 0.037172508264889464, 'l1_Layer_3': 1.9636886722572288e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 90, 'n_units_Layer_3': 265}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.27 | sMAPE for Validation Set is: 14.71% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 54.07 | sMAPE for Test Set is: 50.44% | rMAE for Test Set is: 2.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:14:06,572]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:14:14,073]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:14:14,773]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:14:31,488]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:14:34,028]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:14:38,420]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:14:40,275]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:14:44,312]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:14:46,288]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:14:51,863]\u001b[0m Trial 910 finished with value: 4.271263194544622 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015061511273500188, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10019472736461708, 'dropout_rate_Layer_2': 0.184696441831097, 'dropout_rate_Layer_3': 0.028714788646936405, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0022262964438525107, 'l1_Layer_2': 0.03789943157769366, 'l1_Layer_3': 1.1860608119852143e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 90, 'n_units_Layer_3': 255}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.27 | sMAPE for Validation Set is: 14.73% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 54.62 | sMAPE for Test Set is: 51.05% | rMAE for Test Set is: 2.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:15:04,055]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:15:21,451]\u001b[0m Trial 918 finished with value: 4.828299963197558 and parameters: {'n_hidden': 4, 'learning_rate': 0.001037494626008595, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15525802060318294, 'dropout_rate_Layer_2': 0.15587847762524754, 'dropout_rate_Layer_3': 0.3354578985793942, 'dropout_rate_Layer_4': 0.15707881849240135, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00012340406685679625, 'l1_Layer_2': 0.011499660760415593, 'l1_Layer_3': 0.04873338642252612, 'l1_Layer_4': 1.5674643228004107e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 225, 'n_units_Layer_3': 110, 'n_units_Layer_4': 280}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.83 | sMAPE for Validation Set is: 17.00% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 56.60 | sMAPE for Test Set is: 53.74% | rMAE for Test Set is: 2.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:15:27,278]\u001b[0m Trial 917 finished with value: 4.395933584723078 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015601728675590668, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09977177232120044, 'dropout_rate_Layer_2': 0.20510270058587804, 'dropout_rate_Layer_3': 0.02921002378132806, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0016764016659423036, 'l1_Layer_2': 0.03863306856555215, 'l1_Layer_3': 1.1371044957857605e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 90, 'n_units_Layer_3': 255}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.40 | sMAPE for Validation Set is: 15.73% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 54.07 | sMAPE for Test Set is: 50.43% | rMAE for Test Set is: 2.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:15:44,721]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:15:57,944]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:16:08,672]\u001b[0m Trial 909 finished with value: 4.04601818591882 and parameters: {'n_hidden': 3, 'learning_rate': 0.000502290807589119, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0018844079974178925, 'dropout_rate_Layer_2': 0.04590346233708041, 'dropout_rate_Layer_3': 0.11150324483931831, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005095607787394882, 'l1_Layer_2': 0.0007997768924715662, 'l1_Layer_3': 7.357427551106504e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 215, 'n_units_Layer_3': 135}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.05 | sMAPE for Validation Set is: 14.45% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 47.85 | sMAPE for Test Set is: 43.27% | rMAE for Test Set is: 1.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:16:27,701]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:16:27,857]\u001b[0m Trial 919 finished with value: 3.7772319469478455 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006253268031573318, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015798166604314046, 'dropout_rate_Layer_2': 0.09362574412953338, 'dropout_rate_Layer_3': 0.08055851390997294, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000816070558838309, 'l1_Layer_2': 0.0006505635940422416, 'l1_Layer_3': 0.00016543122344769395, 'n_units_Layer_1': 295, 'n_units_Layer_2': 240, 'n_units_Layer_3': 130}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.78 | sMAPE for Validation Set is: 13.47% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 44.90 | sMAPE for Test Set is: 40.11% | rMAE for Test Set is: 1.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:16:34,711]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:16:37,501]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:16:43,345]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:16:57,886]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:17:03,347]\u001b[0m Trial 922 finished with value: 3.838829695799889 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006270569122660186, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01635271841651245, 'dropout_rate_Layer_2': 0.00145923194764137, 'dropout_rate_Layer_3': 0.02123501330583097, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008370399944490813, 'l1_Layer_2': 0.0006768434682773986, 'l1_Layer_3': 0.00017330279925837654, 'n_units_Layer_1': 285, 'n_units_Layer_2': 240, 'n_units_Layer_3': 130}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.84 | sMAPE for Validation Set is: 13.72% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 44.09 | sMAPE for Test Set is: 39.20% | rMAE for Test Set is: 1.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:17:07,821]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:17:15,223]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:17:23,842]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:17:31,612]\u001b[0m Trial 930 finished with value: 4.559910404323535 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017714382565287227, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07589225307195592, 'dropout_rate_Layer_2': 0.18338799441663126, 'dropout_rate_Layer_3': 0.059705753214743015, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0010253760393809897, 'l1_Layer_2': 0.05450803202794433, 'l1_Layer_3': 2.3860781973057967e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 100, 'n_units_Layer_3': 270}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.56 | sMAPE for Validation Set is: 15.91% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 54.15 | sMAPE for Test Set is: 50.56% | rMAE for Test Set is: 2.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:17:36,138]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:17:51,637]\u001b[0m Trial 929 finished with value: 3.9224514753749884 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020719140026751823, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007289823009396612, 'dropout_rate_Layer_2': 0.2808125245785607, 'dropout_rate_Layer_3': 0.1776245205258338, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010627585592790402, 'l1_Layer_2': 0.00044640408298574335, 'l1_Layer_3': 2.885830383280096e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 250, 'n_units_Layer_3': 50}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.92 | sMAPE for Validation Set is: 13.81% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 50.92 | sMAPE for Test Set is: 46.70% | rMAE for Test Set is: 2.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:17:55,419]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:18:12,567]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:18:17,587]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:18:21,458]\u001b[0m Trial 933 finished with value: 3.9106707069402282 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020657136517081803, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00914545195059987, 'dropout_rate_Layer_2': 0.2906861384844861, 'dropout_rate_Layer_3': 0.17730023533861908, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010670061893989853, 'l1_Layer_2': 0.000434907047489491, 'l1_Layer_3': 2.8867328066513293e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 250, 'n_units_Layer_3': 50}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.91 | sMAPE for Validation Set is: 13.79% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 48.91 | sMAPE for Test Set is: 44.51% | rMAE for Test Set is: 1.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:18:33,958]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:18:37,629]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:18:41,220]\u001b[0m Trial 935 finished with value: 3.8907658390967845 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006902047270185054, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.025249597448752364, 'dropout_rate_Layer_2': 0.06854767862251855, 'dropout_rate_Layer_3': 0.020942900889649063, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004648209179459417, 'l1_Layer_2': 0.0008636163470675168, 'l1_Layer_3': 0.0001443532344887508, 'n_units_Layer_1': 295, 'n_units_Layer_2': 245, 'n_units_Layer_3': 120}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:18:41,286]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.89 | sMAPE for Validation Set is: 13.99% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 46.16 | sMAPE for Test Set is: 41.43% | rMAE for Test Set is: 1.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:18:42,647]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:18:45,438]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:18:48,923]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:18:51,417]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:18:51,653]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:18:51,815]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:18:52,833]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:18:58,737]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:18:59,023]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:19:05,887]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:19:10,881]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:19:16,763]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:19:18,603]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:19:40,410]\u001b[0m Trial 952 finished with value: 4.198732439835203 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010656720423672021, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12010616170055775, 'dropout_rate_Layer_2': 0.21971066664450584, 'dropout_rate_Layer_3': 0.011660157912434728, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.003036241425336457, 'l1_Layer_2': 0.02176415405218748, 'l1_Layer_3': 2.945301682507023e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 80, 'n_units_Layer_3': 245}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.20 | sMAPE for Validation Set is: 14.55% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 54.02 | sMAPE for Test Set is: 50.33% | rMAE for Test Set is: 2.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:19:59,616]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:20:16,691]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.73 | sMAPE for Validation Set is: 13.32% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 45.71 | sMAPE for Test Set is: 40.97% | rMAE for Test Set is: 1.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:20:23,914]\u001b[0m Trial 957 finished with value: 3.7283613005476965 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006199187154153592, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01796896389930905, 'dropout_rate_Layer_2': 0.019567407067223198, 'dropout_rate_Layer_3': 0.07040124908131987, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006629319090942955, 'l1_Layer_2': 0.0007032306747226355, 'l1_Layer_3': 0.00015734010194516637, 'n_units_Layer_1': 285, 'n_units_Layer_2': 235, 'n_units_Layer_3': 140}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:20:31,225]\u001b[0m Trial 955 finished with value: 3.7945381190672776 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006251300135043527, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03102606610663793, 'dropout_rate_Layer_2': 0.023414558366102435, 'dropout_rate_Layer_3': 0.10657706234176408, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006844791158844403, 'l1_Layer_2': 0.0006742008013632152, 'l1_Layer_3': 8.703108485580527e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 235, 'n_units_Layer_3': 140}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.79 | sMAPE for Validation Set is: 13.51% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 47.31 | sMAPE for Test Set is: 42.68% | rMAE for Test Set is: 1.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:20:49,679]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:20:53,439]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:21:01,429]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:21:06,353]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:21:09,979]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.73 | sMAPE for Validation Set is: 13.28% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 45.62 | sMAPE for Test Set is: 40.85% | rMAE for Test Set is: 1.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:21:12,192]\u001b[0m Trial 959 finished with value: 3.730357802151083 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006143305252709016, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0159591797601755, 'dropout_rate_Layer_2': 0.023887454422302973, 'dropout_rate_Layer_3': 0.06958702351913158, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007044436553389832, 'l1_Layer_2': 0.0006984533899910418, 'l1_Layer_3': 0.0002557746648894594, 'n_units_Layer_1': 285, 'n_units_Layer_2': 235, 'n_units_Layer_3': 140}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:21:16,338]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:21:20,978]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:21:24,930]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:21:31,550]\u001b[0m Trial 961 finished with value: 3.7312908675699403 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006667198280999013, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007272913947439234, 'dropout_rate_Layer_2': 0.0255601493037885, 'dropout_rate_Layer_3': 0.11831891866658241, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000837649620741122, 'l1_Layer_2': 0.0006780371813767372, 'l1_Layer_3': 0.00016426850701533623, 'n_units_Layer_1': 280, 'n_units_Layer_2': 240, 'n_units_Layer_3': 130}. Best is trial 751 with value: 3.720768816012857.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.73 | sMAPE for Validation Set is: 13.37% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 45.87 | sMAPE for Test Set is: 41.20% | rMAE for Test Set is: 1.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:21:32,298]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:21:32,371]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:21:37,284]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:21:39,740]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:21:43,637]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:21:48,451]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:21:48,964]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:21:51,092]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:22:19,234]\u001b[0m Trial 967 finished with value: 3.707936331705573 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005544850072976517, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01966129754656297, 'dropout_rate_Layer_2': 0.005594844745589156, 'dropout_rate_Layer_3': 0.125322737282302, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006872078596240259, 'l1_Layer_2': 0.0005690668511391545, 'l1_Layer_3': 8.9066647720919e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 235, 'n_units_Layer_3': 135}. Best is trial 967 with value: 3.707936331705573.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.71 | sMAPE for Validation Set is: 13.16% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 45.57 | sMAPE for Test Set is: 40.80% | rMAE for Test Set is: 1.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:22:24,492]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:22:29,942]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:22:38,413]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:22:43,813]\u001b[0m Trial 980 finished with value: 3.69498041656356 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007316886045744596, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.017486176836487927, 'dropout_rate_Layer_2': 0.014313983367455742, 'dropout_rate_Layer_3': 0.08214902352153838, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007771324098739114, 'l1_Layer_2': 0.0010152646323845827, 'l1_Layer_3': 6.394427666098187e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 230, 'n_units_Layer_3': 135}. Best is trial 980 with value: 3.69498041656356.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.69 | sMAPE for Validation Set is: 13.15% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 45.36 | sMAPE for Test Set is: 40.54% | rMAE for Test Set is: 1.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:22:46,553]\u001b[0m Trial 979 finished with value: 3.7398989907347056 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007275327716076769, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015783391625306478, 'dropout_rate_Layer_2': 0.025987171667082212, 'dropout_rate_Layer_3': 0.09731542537980908, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008588609231270231, 'l1_Layer_2': 0.0011276610801123875, 'l1_Layer_3': 6.657304548518032e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 230, 'n_units_Layer_3': 135}. Best is trial 980 with value: 3.69498041656356.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.74 | sMAPE for Validation Set is: 13.37% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 45.16 | sMAPE for Test Set is: 40.40% | rMAE for Test Set is: 1.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:22:49,221]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:23:00,263]\u001b[0m Trial 978 finished with value: 3.8840388969281476 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007259828389165323, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00035552653502323936, 'dropout_rate_Layer_2': 0.02453868490466685, 'dropout_rate_Layer_3': 0.09594306357778089, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007690578710400986, 'l1_Layer_2': 0.0010027298020192034, 'l1_Layer_3': 0.00022843927598365516, 'n_units_Layer_1': 285, 'n_units_Layer_2': 230, 'n_units_Layer_3': 135}. Best is trial 980 with value: 3.69498041656356.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.88 | sMAPE for Validation Set is: 14.03% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 48.93 | sMAPE for Test Set is: 44.54% | rMAE for Test Set is: 1.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:23:05,818]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:23:09,193]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:23:12,826]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:23:13,624]\u001b[0m Trial 984 finished with value: 3.9390112871280287 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012902934936151811, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22798603203468684, 'dropout_rate_Layer_2': 0.3071652508316617, 'dropout_rate_Layer_3': 0.3410841026679058, 'dropout_rate_Layer_4': 0.3056880633193694, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.71678246891245e-05, 'l1_Layer_2': 0.0006810798584657508, 'l1_Layer_3': 8.040003230902941e-05, 'l1_Layer_4': 0.00024028091016272676, 'n_units_Layer_1': 300, 'n_units_Layer_2': 265, 'n_units_Layer_3': 130, 'n_units_Layer_4': 205}. Best is trial 980 with value: 3.69498041656356.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.94 | sMAPE for Validation Set is: 13.90% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 59.82 | sMAPE for Test Set is: 57.69% | rMAE for Test Set is: 2.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:23:15,489]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:23:15,645]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:23:19,921]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:23:25,206]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:23:27,642]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:23:30,716]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:23:30,908]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:23:31,659]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:23:38,346]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:23:39,944]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:23:41,907]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:23:45,483]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:23:45,958]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:23:47,576]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:23:52,865]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:23:57,344]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:24:03,290]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:24:07,318]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:24:13,472]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:24:17,193]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:24:25,240]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:24:31,238]\u001b[0m Trial 993 finished with value: 3.833647459144379 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007321280882160797, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.018252312355827836, 'dropout_rate_Layer_2': 0.03140161590948861, 'dropout_rate_Layer_3': 0.09454437969658215, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004707838430859093, 'l1_Layer_2': 0.0008348885842831976, 'l1_Layer_3': 6.325056281744564e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 230, 'n_units_Layer_3': 130}. Best is trial 980 with value: 3.69498041656356.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.83 | sMAPE for Validation Set is: 13.66% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 45.33 | sMAPE for Test Set is: 40.49% | rMAE for Test Set is: 1.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:24:36,031]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:24:36,845]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:24:41,242]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:24:44,882]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:24:54,148]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:25:04,867]\u001b[0m Trial 1016 finished with value: 4.007202767081829 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009126270542511431, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2790398936558204, 'dropout_rate_Layer_2': 0.16975687700185688, 'dropout_rate_Layer_3': 0.34322663728615405, 'dropout_rate_Layer_4': 0.30207813800208383, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00015991545584753827, 'l1_Layer_2': 0.0007819816671230783, 'l1_Layer_3': 9.658416193707818e-05, 'l1_Layer_4': 7.996956045244873e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 275, 'n_units_Layer_3': 155, 'n_units_Layer_4': 225}. Best is trial 980 with value: 3.69498041656356.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.01 | sMAPE for Validation Set is: 14.49% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 55.49 | sMAPE for Test Set is: 52.13% | rMAE for Test Set is: 2.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:25:14,856]\u001b[0m Trial 1007 finished with value: 3.96499171359736 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007072432028335689, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.019800939651945657, 'dropout_rate_Layer_2': 0.03331729827236497, 'dropout_rate_Layer_3': 0.09903936320815732, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00036015704541360875, 'l1_Layer_2': 0.0010812997584053769, 'l1_Layer_3': 0.00012584955499806924, 'n_units_Layer_1': 285, 'n_units_Layer_2': 230, 'n_units_Layer_3': 140}. Best is trial 980 with value: 3.69498041656356.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.96 | sMAPE for Validation Set is: 14.29% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 49.14 | sMAPE for Test Set is: 44.66% | rMAE for Test Set is: 1.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:25:19,376]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:25:21,760]\u001b[0m Trial 1019 finished with value: 4.038708191547221 and parameters: {'n_hidden': 4, 'learning_rate': 0.002095786596213487, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25768874262557806, 'dropout_rate_Layer_2': 0.07671060866267096, 'dropout_rate_Layer_3': 0.3405885655937706, 'dropout_rate_Layer_4': 0.3015430849701861, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.3714221065931235e-05, 'l1_Layer_2': 0.0006759041311223479, 'l1_Layer_3': 7.899397964187856e-05, 'l1_Layer_4': 7.712490460867605e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 280, 'n_units_Layer_3': 150, 'n_units_Layer_4': 230}. Best is trial 980 with value: 3.69498041656356.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.04 | sMAPE for Validation Set is: 14.37% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 58.39 | sMAPE for Test Set is: 55.57% | rMAE for Test Set is: 2.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:25:22,614]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:25:29,427]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:25:30,528]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:25:38,545]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:25:42,584]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:25:48,049]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:26:10,086]\u001b[0m Trial 1026 finished with value: 3.7207215887036935 and parameters: {'n_hidden': 3, 'learning_rate': 0.002369401368422342, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.024889123942076485, 'dropout_rate_Layer_2': 0.3238384260233551, 'dropout_rate_Layer_3': 0.1838396338516132, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008649324445848273, 'l1_Layer_2': 0.0023149835011371076, 'l1_Layer_3': 0.0005629905925324934, 'n_units_Layer_1': 110, 'n_units_Layer_2': 270, 'n_units_Layer_3': 85}. Best is trial 980 with value: 3.69498041656356.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.72 | sMAPE for Validation Set is: 12.74% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 14.82 | sMAPE for Test Set is: 18.93% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:26:14,304]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:26:16,776]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:26:21,095]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:26:26,301]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:26:28,362]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:26:31,932]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:26:34,317]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:26:37,297]\u001b[0m Trial 1029 finished with value: 3.691607636617307 and parameters: {'n_hidden': 3, 'learning_rate': 0.000637413460392866, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.013725612050362244, 'dropout_rate_Layer_2': 0.08878919648177586, 'dropout_rate_Layer_3': 0.06883602598461071, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000581123260187576, 'l1_Layer_2': 0.0004650586948142009, 'l1_Layer_3': 7.163282972999231e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 235, 'n_units_Layer_3': 135}. Best is trial 1029 with value: 3.691607636617307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.69 | sMAPE for Validation Set is: 13.23% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 46.49 | sMAPE for Test Set is: 41.88% | rMAE for Test Set is: 1.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:26:47,094]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:26:55,523]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:27:00,041]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:27:06,424]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:27:16,045]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:27:18,009]\u001b[0m Trial 1038 finished with value: 4.274253949977339 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008149538305051309, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1378988101390899, 'dropout_rate_Layer_2': 0.22068039267855577, 'dropout_rate_Layer_3': 0.009041712030821866, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0038816561914252097, 'l1_Layer_2': 0.03795744168142402, 'l1_Layer_3': 0.00037007538319865557, 'n_units_Layer_1': 205, 'n_units_Layer_2': 90, 'n_units_Layer_3': 275}. Best is trial 1029 with value: 3.691607636617307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.27 | sMAPE for Validation Set is: 15.10% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 54.75 | sMAPE for Test Set is: 51.40% | rMAE for Test Set is: 2.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:27:21,120]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:27:24,903]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:27:30,564]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:27:33,864]\u001b[0m Trial 1035 finished with value: 3.81958431958488 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007371780981137931, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.030509022109990312, 'dropout_rate_Layer_2': 0.04235378497505585, 'dropout_rate_Layer_3': 0.10620755319378662, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008966382659101017, 'l1_Layer_2': 0.00048797128110211204, 'l1_Layer_3': 0.0001512533233529238, 'n_units_Layer_1': 280, 'n_units_Layer_2': 235, 'n_units_Layer_3': 135}. Best is trial 1029 with value: 3.691607636617307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.82 | sMAPE for Validation Set is: 13.79% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 44.54 | sMAPE for Test Set is: 39.82% | rMAE for Test Set is: 1.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:27:38,151]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:27:41,744]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:27:44,459]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:27:44,764]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:27:53,579]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:27:55,678]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:28:02,173]\u001b[0m Trial 1037 finished with value: 3.855636337823965 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007193093694003286, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03157720035742892, 'dropout_rate_Layer_2': 0.041722531746001906, 'dropout_rate_Layer_3': 0.1028655072152825, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007557436870830016, 'l1_Layer_2': 0.0009400726594420584, 'l1_Layer_3': 0.00014635760136082532, 'n_units_Layer_1': 280, 'n_units_Layer_2': 235, 'n_units_Layer_3': 135}. Best is trial 1029 with value: 3.691607636617307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.86 | sMAPE for Validation Set is: 13.81% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 46.20 | sMAPE for Test Set is: 41.39% | rMAE for Test Set is: 1.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:28:04,392]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:28:08,339]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:28:08,647]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:28:18,564]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:28:20,890]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:28:24,540]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:28:24,815]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:28:31,348]\u001b[0m Trial 1044 finished with value: 3.7362538612564067 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006587290384452289, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0070827953365034885, 'dropout_rate_Layer_2': 0.08778037473006559, 'dropout_rate_Layer_3': 0.09502355622230779, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000883721139617092, 'l1_Layer_2': 0.00038884012776853403, 'l1_Layer_3': 0.0001389854401834209, 'n_units_Layer_1': 290, 'n_units_Layer_2': 240, 'n_units_Layer_3': 120}. Best is trial 1029 with value: 3.691607636617307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.74 | sMAPE for Validation Set is: 13.30% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 45.74 | sMAPE for Test Set is: 41.05% | rMAE for Test Set is: 1.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:28:34,954]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:28:35,367]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:28:41,451]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:28:42,350]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:28:46,270]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:29:06,658]\u001b[0m Trial 1061 finished with value: 4.290242346017141 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007771900788167842, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1649341355968104, 'dropout_rate_Layer_2': 0.21990596487837868, 'dropout_rate_Layer_3': 0.020237105722764506, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0027682005984959865, 'l1_Layer_2': 0.03483732467575341, 'l1_Layer_3': 0.00024250986989960243, 'n_units_Layer_1': 190, 'n_units_Layer_2': 90, 'n_units_Layer_3': 275}. Best is trial 1029 with value: 3.691607636617307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.29 | sMAPE for Validation Set is: 15.02% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 54.78 | sMAPE for Test Set is: 51.37% | rMAE for Test Set is: 2.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:29:11,904]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:29:17,887]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:29:20,451]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:29:23,386]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:29:27,492]\u001b[0m Trial 1068 finished with value: 4.271018172629808 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018216508449083724, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.034226063671691884, 'dropout_rate_Layer_2': 0.2859147190756015, 'dropout_rate_Layer_3': 0.17021108982363237, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016189941005569789, 'l1_Layer_2': 0.0016508976745147994, 'l1_Layer_3': 0.00029199962615814766, 'n_units_Layer_1': 90, 'n_units_Layer_2': 240, 'n_units_Layer_3': 70}. Best is trial 1029 with value: 3.691607636617307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.27 | sMAPE for Validation Set is: 15.13% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 49.46 | sMAPE for Test Set is: 45.25% | rMAE for Test Set is: 1.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:29:29,705]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:29:32,388]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:29:34,199]\u001b[0m Trial 1067 finished with value: 3.9444158098057343 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008944127357396744, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3119794232600496, 'dropout_rate_Layer_2': 0.1343705588418247, 'dropout_rate_Layer_3': 0.3449630210896181, 'dropout_rate_Layer_4': 0.27861054567906485, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 7.70499697229287e-05, 'l1_Layer_2': 0.0008052844734559883, 'l1_Layer_3': 0.00012240826878091756, 'l1_Layer_4': 9.079843951384546e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 290, 'n_units_Layer_3': 150, 'n_units_Layer_4': 235}. Best is trial 1029 with value: 3.691607636617307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.94 | sMAPE for Validation Set is: 13.88% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 56.86 | sMAPE for Test Set is: 53.82% | rMAE for Test Set is: 2.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:29:38,484]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:29:41,396]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:29:45,723]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:29:49,762]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:29:49,796]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:29:50,100]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:29:50,788]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:30:00,812]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:30:01,034]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:30:01,742]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:30:09,554]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:30:10,190]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:30:13,800]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:30:20,490]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:30:24,590]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:30:34,598]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:30:52,951]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:30:57,503]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:31:02,579]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:31:04,940]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:31:09,987]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:31:13,345]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:31:14,726]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:31:20,630]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:31:22,116]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:31:22,897]\u001b[0m Trial 1090 finished with value: 3.753330696162628 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007283934568236307, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.018207335994276888, 'dropout_rate_Layer_2': 0.05225570590743891, 'dropout_rate_Layer_3': 0.08220355480342686, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009282446967632202, 'l1_Layer_2': 0.00092034852295043, 'l1_Layer_3': 0.00018677986348808933, 'n_units_Layer_1': 295, 'n_units_Layer_2': 245, 'n_units_Layer_3': 135}. Best is trial 1029 with value: 3.691607636617307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 13.51% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 46.83 | sMAPE for Test Set is: 42.28% | rMAE for Test Set is: 1.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:31:27,555]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:31:29,912]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:31:30,804]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:31:33,273]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:31:33,457]\u001b[0m Trial 1091 finished with value: 3.8161674407420603 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007120490816833926, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0170988811815078, 'dropout_rate_Layer_2': 0.05198369684160311, 'dropout_rate_Layer_3': 0.10667514133602105, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006303105502544347, 'l1_Layer_2': 0.0008725654509803455, 'l1_Layer_3': 0.00018685806901529292, 'n_units_Layer_1': 295, 'n_units_Layer_2': 245, 'n_units_Layer_3': 135}. Best is trial 1029 with value: 3.691607636617307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.82 | sMAPE for Validation Set is: 13.75% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 47.18 | sMAPE for Test Set is: 42.59% | rMAE for Test Set is: 1.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:31:36,457]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:31:38,190]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:31:43,537]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:31:43,597]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:31:50,706]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:31:56,721]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:32:00,932]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:32:06,029]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:32:09,815]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:32:16,299]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:32:16,496]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:32:22,006]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:32:38,351]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:32:41,512]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.97 | sMAPE for Validation Set is: 14.13% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 48.83 | sMAPE for Test Set is: 44.47% | rMAE for Test Set is: 1.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:32:44,525]\u001b[0m Trial 1110 finished with value: 3.9719226128942124 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014824836362156506, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02193395372437502, 'dropout_rate_Layer_2': 0.25742402205797577, 'dropout_rate_Layer_3': 0.17565464168115957, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006674068421852338, 'l1_Layer_2': 0.0006094281542620508, 'l1_Layer_3': 2.1779776383377895e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 265, 'n_units_Layer_3': 50}. Best is trial 1029 with value: 3.691607636617307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.81 | sMAPE for Validation Set is: 13.70% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 46.05 | sMAPE for Test Set is: 41.39% | rMAE for Test Set is: 1.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:32:46,687]\u001b[0m Trial 1109 finished with value: 3.812282414870231 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007555048782232205, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.028398772282336372, 'dropout_rate_Layer_2': 0.06027728853320727, 'dropout_rate_Layer_3': 0.10423961035447858, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008002544959239346, 'l1_Layer_2': 0.0005706917439706946, 'l1_Layer_3': 0.000164326053276552, 'n_units_Layer_1': 300, 'n_units_Layer_2': 250, 'n_units_Layer_3': 135}. Best is trial 1029 with value: 3.691607636617307.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:32:52,661]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:32:57,137]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:33:01,451]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:33:07,105]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:33:09,140]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:33:12,087]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:33:16,253]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:33:19,004]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:33:24,784]\u001b[0m Trial 1122 finished with value: 4.155328542995807 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013822764098227924, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09627838215917595, 'dropout_rate_Layer_2': 0.22358174089817404, 'dropout_rate_Layer_3': 0.01938422104753631, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.008132747163089937, 'l1_Layer_2': 0.031165127787513448, 'l1_Layer_3': 1.6431051392503967e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 80, 'n_units_Layer_3': 270}. Best is trial 1029 with value: 3.691607636617307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.16 | sMAPE for Validation Set is: 14.27% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 53.74 | sMAPE for Test Set is: 50.04% | rMAE for Test Set is: 2.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:33:39,758]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:33:47,476]\u001b[0m Trial 1121 finished with value: 3.8608224405485267 and parameters: {'n_hidden': 3, 'learning_rate': 0.00092820126440936, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.026407201378723558, 'dropout_rate_Layer_2': 0.05472483526154686, 'dropout_rate_Layer_3': 0.08230007390962525, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006247605651890323, 'l1_Layer_2': 0.0005981821406118822, 'l1_Layer_3': 0.0001484592752192404, 'n_units_Layer_1': 285, 'n_units_Layer_2': 240, 'n_units_Layer_3': 135}. Best is trial 1029 with value: 3.691607636617307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.86 | sMAPE for Validation Set is: 13.67% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 46.83 | sMAPE for Test Set is: 42.12% | rMAE for Test Set is: 1.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:33:47,701]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:33:52,629]\u001b[0m Trial 1132 finished with value: 4.066196838546485 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013867594593122623, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28343148088328524, 'dropout_rate_Layer_2': 0.11890864746685792, 'dropout_rate_Layer_3': 0.3442822230020315, 'dropout_rate_Layer_4': 0.32741387489812135, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.562958910924573e-05, 'l1_Layer_2': 0.0007799643459959397, 'l1_Layer_3': 3.1492306093506874e-05, 'l1_Layer_4': 3.821660117108258e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 275, 'n_units_Layer_3': 170, 'n_units_Layer_4': 255}. Best is trial 1029 with value: 3.691607636617307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.07 | sMAPE for Validation Set is: 14.34% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 57.85 | sMAPE for Test Set is: 55.17% | rMAE for Test Set is: 2.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:33:56,130]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:33:56,747]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:34:02,155]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:34:02,339]\u001b[0m Trial 1133 finished with value: 4.1446064783980034 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013218824424081359, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09445224452906097, 'dropout_rate_Layer_2': 0.22704262817153817, 'dropout_rate_Layer_3': 0.18110305910914276, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.009099970965581886, 'l1_Layer_2': 0.030898895648046577, 'l1_Layer_3': 1.4910105313635321e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 65, 'n_units_Layer_3': 280}. Best is trial 1029 with value: 3.691607636617307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.14 | sMAPE for Validation Set is: 14.50% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 54.09 | sMAPE for Test Set is: 50.45% | rMAE for Test Set is: 2.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:34:13,574]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:34:17,825]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:34:21,570]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:34:21,916]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:34:27,757]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:34:28,168]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:34:32,839]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:34:33,442]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:34:35,962]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:34:37,290]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:34:43,966]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:34:44,860]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:34:50,157]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:34:51,658]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:34:54,229]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:34:57,011]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:34:57,534]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:34:58,173]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:34:58,349]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:35:07,113]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:35:09,857]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:35:10,746]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:35:13,657]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:35:23,611]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:35:25,797]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:35:28,726]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:35:32,732]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:35:39,194]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:35:39,540]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:35:44,337]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:35:58,702]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:36:11,852]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:36:15,141]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:36:19,414]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:36:22,905]\u001b[0m Trial 1173 finished with value: 9.193166857261627 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018009810632973085, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26392845515094604, 'dropout_rate_Layer_2': 0.10026007927922612, 'dropout_rate_Layer_3': 0.3120476202237741, 'dropout_rate_Layer_4': 0.29372925675108563, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00014009014030602488, 'l1_Layer_2': 0.0016515109988692572, 'l1_Layer_3': 2.8108844721016852e-05, 'l1_Layer_4': 0.00010513349489798973, 'n_units_Layer_1': 290, 'n_units_Layer_2': 130, 'n_units_Layer_3': 145, 'n_units_Layer_4': 285}. Best is trial 1029 with value: 3.691607636617307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.19 | sMAPE for Validation Set is: 29.26% | rMAE for Validation Set is: 1.38\n",
      "MAE for Test Set is: 82.56 | sMAPE for Test Set is: 96.38% | rMAE for Test Set is: 3.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:36:23,324]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:36:29,946]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:36:33,004]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:36:33,360]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:36:40,069]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:36:40,363]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:36:45,212]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:36:47,894]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:36:51,868]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:36:51,958]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:36:52,130]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:36:55,757]\u001b[0m Trial 1169 finished with value: 3.8288086957099154 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006044169692865602, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02769513855374698, 'dropout_rate_Layer_2': 0.06093155757467934, 'dropout_rate_Layer_3': 0.08586971732237925, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010011037816985, 'l1_Layer_2': 0.0005395395686070666, 'l1_Layer_3': 0.0002168336152933987, 'n_units_Layer_1': 295, 'n_units_Layer_2': 235, 'n_units_Layer_3': 75}. Best is trial 1029 with value: 3.691607636617307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.83 | sMAPE for Validation Set is: 13.84% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 46.88 | sMAPE for Test Set is: 42.40% | rMAE for Test Set is: 1.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:37:01,867]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:37:01,995]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:37:02,402]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:37:02,765]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:37:13,058]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:37:13,087]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:37:13,165]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:37:13,699]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:37:22,289]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:37:26,175]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:37:28,818]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:37:32,572]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:37:35,867]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:37:39,131]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:37:42,429]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:37:44,695]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:37:53,225]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:37:57,407]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:38:00,636]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:38:08,138]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:38:13,465]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:38:22,122]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:38:31,518]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:38:35,643]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:38:38,367]\u001b[0m Trial 1195 finished with value: 3.712295308285769 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005003218366491293, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.031571967432103436, 'dropout_rate_Layer_2': 0.0721085163825318, 'dropout_rate_Layer_3': 0.1066793179939022, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000801437188387855, 'l1_Layer_2': 0.0009363121261938732, 'l1_Layer_3': 7.466021291655005e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 225, 'n_units_Layer_3': 145}. Best is trial 1029 with value: 3.691607636617307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.71 | sMAPE for Validation Set is: 13.32% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 46.56 | sMAPE for Test Set is: 42.04% | rMAE for Test Set is: 1.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:38:40,905]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:38:46,366]\u001b[0m Trial 1203 finished with value: 3.627662358345981 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014991256284861863, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02708555772849162, 'dropout_rate_Layer_2': 0.3200015822976324, 'dropout_rate_Layer_3': 0.18436584641721743, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00805425827551028, 'l1_Layer_2': 0.000984257795946203, 'l1_Layer_3': 2.0091144537873218e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 265, 'n_units_Layer_3': 210}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.63 | sMAPE for Validation Set is: 12.64% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 14.76 | sMAPE for Test Set is: 18.94% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:38:48,693]\u001b[0m Trial 1204 finished with value: 3.7161901026250255 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007521096558338679, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02622488169578472, 'dropout_rate_Layer_2': 0.053879970923320884, 'dropout_rate_Layer_3': 0.11040802775945002, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008522989064334755, 'l1_Layer_2': 0.0008017299856416299, 'l1_Layer_3': 0.0001283520786720714, 'n_units_Layer_1': 285, 'n_units_Layer_2': 235, 'n_units_Layer_3': 150}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.72 | sMAPE for Validation Set is: 13.26% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 44.65 | sMAPE for Test Set is: 39.87% | rMAE for Test Set is: 1.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:38:52,641]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:38:55,004]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:39:02,730]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:39:03,604]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:39:07,577]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:39:10,122]\u001b[0m Trial 1213 finished with value: 4.03361052468848 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008128990825137878, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27486226442602857, 'dropout_rate_Layer_2': 0.13617003402045139, 'dropout_rate_Layer_3': 0.3907629844655899, 'dropout_rate_Layer_4': 0.28699433126236346, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.55729966592621e-05, 'l1_Layer_2': 0.00047182761339962907, 'l1_Layer_3': 0.00013406855258910608, 'l1_Layer_4': 6.352422372549581e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 250, 'n_units_Layer_3': 120, 'n_units_Layer_4': 205}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.03 | sMAPE for Validation Set is: 13.84% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 58.71 | sMAPE for Test Set is: 56.01% | rMAE for Test Set is: 2.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:39:12,061]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:39:16,357]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:40:09,740]\u001b[0m Trial 1217 finished with value: 3.679549014485314 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012609428101760009, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01898252101767923, 'dropout_rate_Layer_2': 0.322754795085537, 'dropout_rate_Layer_3': 0.2056815707674547, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006065565983201923, 'l1_Layer_2': 0.005706711806287289, 'l1_Layer_3': 1.9849132872324806e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 265, 'n_units_Layer_3': 255}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.68 | sMAPE for Validation Set is: 12.76% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 14.17 | sMAPE for Test Set is: 18.62% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:40:10,486]\u001b[0m Trial 1220 finished with value: 3.6825927715735403 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012501758639334136, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00010010858688029242, 'dropout_rate_Layer_2': 0.32823589341982556, 'dropout_rate_Layer_3': 0.20408917031088822, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00949942401624331, 'l1_Layer_2': 0.0008904897776607596, 'l1_Layer_3': 2.1372681425058217e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 265, 'n_units_Layer_3': 235}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.68 | sMAPE for Validation Set is: 12.79% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 14.07 | sMAPE for Test Set is: 18.41% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:40:15,215]\u001b[0m Trial 1224 finished with value: 3.8092193233955762 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007653720647478042, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.022931524413367814, 'dropout_rate_Layer_2': 0.033078741864755075, 'dropout_rate_Layer_3': 0.0678640509332208, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008077452852946602, 'l1_Layer_2': 0.001257419575947999, 'l1_Layer_3': 8.5609686142169e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 225, 'n_units_Layer_3': 150}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.81 | sMAPE for Validation Set is: 13.57% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 46.82 | sMAPE for Test Set is: 42.22% | rMAE for Test Set is: 1.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:40:18,274]\u001b[0m Trial 1222 finished with value: 3.630494515378938 and parameters: {'n_hidden': 3, 'learning_rate': 0.001244226959936154, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0004543612006994756, 'dropout_rate_Layer_2': 0.3094261727186029, 'dropout_rate_Layer_3': 0.1874520164016542, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006022593145770897, 'l1_Layer_2': 0.0008715136391080143, 'l1_Layer_3': 1.985053637067988e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 265, 'n_units_Layer_3': 225}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.63 | sMAPE for Validation Set is: 12.58% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 13.62 | sMAPE for Test Set is: 18.14% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:40:18,450]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:40:19,597]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:40:33,515]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:40:40,845]\u001b[0m Trial 1230 finished with value: 4.012793305595383 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008409873929277267, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2803114491798094, 'dropout_rate_Layer_2': 0.14486497154177994, 'dropout_rate_Layer_3': 0.39191526609840976, 'dropout_rate_Layer_4': 0.2838440147897478, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.0787377712995424e-05, 'l1_Layer_2': 0.00042607750905058854, 'l1_Layer_3': 1.0529840129436065e-05, 'l1_Layer_4': 2.1437012208533397e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 260, 'n_units_Layer_3': 155, 'n_units_Layer_4': 200}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.01 | sMAPE for Validation Set is: 13.99% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 57.95 | sMAPE for Test Set is: 55.20% | rMAE for Test Set is: 2.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:40:46,389]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:40:47,202]\u001b[0m Trial 1225 finished with value: 4.3066192882683065 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006526458488896696, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1519330612115844, 'dropout_rate_Layer_2': 0.26138886658022553, 'dropout_rate_Layer_3': 0.0010864216366729962, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.009088548557345172, 'l1_Layer_2': 0.0021702551695877382, 'l1_Layer_3': 2.4489432740584542e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 65, 'n_units_Layer_3': 280}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.31 | sMAPE for Validation Set is: 15.24% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 44.87 | sMAPE for Test Set is: 40.55% | rMAE for Test Set is: 1.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:41:05,170]\u001b[0m Trial 1231 finished with value: 4.168312240532402 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010934526816274584, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0786826567361152, 'dropout_rate_Layer_2': 0.235908324755549, 'dropout_rate_Layer_3': 0.001359290260746676, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00547697077208344, 'l1_Layer_2': 0.04838483945037506, 'l1_Layer_3': 1.7572292166111746e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 65, 'n_units_Layer_3': 265}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.17 | sMAPE for Validation Set is: 14.69% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 54.83 | sMAPE for Test Set is: 51.40% | rMAE for Test Set is: 2.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:41:19,342]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:41:23,123]\u001b[0m Trial 1229 finished with value: 3.717205866788865 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010563254267528777, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0004925367015249198, 'dropout_rate_Layer_2': 0.32183215046224417, 'dropout_rate_Layer_3': 0.21491057793872398, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004517379596375658, 'l1_Layer_2': 0.0010242586659371822, 'l1_Layer_3': 1.5131967370491257e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 265, 'n_units_Layer_3': 225}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.72 | sMAPE for Validation Set is: 12.89% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 13.96 | sMAPE for Test Set is: 18.49% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:41:27,695]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:41:39,987]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:41:43,979]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:41:47,587]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:41:51,603]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:41:55,583]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:41:59,743]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:42:05,754]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:42:10,974]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:42:14,864]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:42:20,023]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:42:31,032]\u001b[0m Trial 1234 finished with value: 3.8694043702645335 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006110716613356215, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.011890867226678162, 'dropout_rate_Layer_2': 0.0353564054473844, 'dropout_rate_Layer_3': 0.06526959972636577, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008539294911476213, 'l1_Layer_2': 0.0010527094382712272, 'l1_Layer_3': 8.141461769143178e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 215, 'n_units_Layer_3': 150}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.87 | sMAPE for Validation Set is: 13.85% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 46.46 | sMAPE for Test Set is: 41.68% | rMAE for Test Set is: 1.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:42:33,287]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:42:36,437]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:42:39,125]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:42:41,926]\u001b[0m Trial 1236 finished with value: 3.789661562613236 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006049134838662315, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.012799653740892716, 'dropout_rate_Layer_2': 0.03266919821245055, 'dropout_rate_Layer_3': 0.0535345782692323, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008780750097495021, 'l1_Layer_2': 0.001009689175138969, 'l1_Layer_3': 7.37929433536635e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 210, 'n_units_Layer_3': 100}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.79 | sMAPE for Validation Set is: 13.65% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 45.87 | sMAPE for Test Set is: 41.21% | rMAE for Test Set is: 1.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:42:42,316]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:42:43,284]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:42:49,743]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:42:51,311]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:42:52,492]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:42:54,166]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:43:01,186]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:43:04,834]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:43:05,504]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:43:11,613]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:43:17,237]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:43:22,096]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:43:22,699]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:43:28,514]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:43:53,270]\u001b[0m Trial 1252 finished with value: 3.8141629930060543 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005591234235052301, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.001165182137460163, 'dropout_rate_Layer_2': 0.0008110461389948011, 'dropout_rate_Layer_3': 0.12059786542812888, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007245454329763043, 'l1_Layer_2': 0.0013609851027371594, 'l1_Layer_3': 0.00011360593668037642, 'n_units_Layer_1': 280, 'n_units_Layer_2': 210, 'n_units_Layer_3': 140}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.81 | sMAPE for Validation Set is: 13.72% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 47.29 | sMAPE for Test Set is: 42.65% | rMAE for Test Set is: 1.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:43:55,384]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:44:01,619]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:44:08,909]\u001b[0m Trial 1257 finished with value: 3.8078214638368215 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010232581462805105, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 4.177256955089758e-05, 'dropout_rate_Layer_2': 0.31932430201830914, 'dropout_rate_Layer_3': 0.21466980400620372, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004975408212752653, 'l1_Layer_2': 0.0009201918724767728, 'l1_Layer_3': 1.319415340446557e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 260, 'n_units_Layer_3': 230}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.81 | sMAPE for Validation Set is: 13.12% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 14.54 | sMAPE for Test Set is: 18.86% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:44:14,312]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:44:17,897]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:44:21,748]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:44:22,383]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:44:27,813]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:44:28,655]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:44:33,118]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:44:36,348]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:44:40,376]\u001b[0m Trial 1275 finished with value: 4.147866483878797 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005927182047564324, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2829525916054203, 'dropout_rate_Layer_2': 0.143559583940072, 'dropout_rate_Layer_3': 0.39011672169959977, 'dropout_rate_Layer_4': 0.2882058606757758, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.8689556476106184e-05, 'l1_Layer_2': 0.000452160928552936, 'l1_Layer_3': 1.3631789282685581e-05, 'l1_Layer_4': 2.1565348680096797e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 270, 'n_units_Layer_3': 155, 'n_units_Layer_4': 205}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.15 | sMAPE for Validation Set is: 14.59% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 56.64 | sMAPE for Test Set is: 53.72% | rMAE for Test Set is: 2.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:44:45,642]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:44:49,427]\u001b[0m Trial 1265 finished with value: 3.8645738194092836 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005020231915108704, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007268091914741001, 'dropout_rate_Layer_2': 0.05501440686403097, 'dropout_rate_Layer_3': 0.09128212731579527, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006850687624133582, 'l1_Layer_2': 0.001024629509386584, 'l1_Layer_3': 7.295998167835918e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 230, 'n_units_Layer_3': 105}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.86 | sMAPE for Validation Set is: 13.83% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 46.40 | sMAPE for Test Set is: 41.68% | rMAE for Test Set is: 1.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:44:52,131]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:44:57,973]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:44:58,262]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:45:04,495]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:45:04,567]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:45:05,825]\u001b[0m Trial 1278 finished with value: 4.039295001893323 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012086093626271564, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12558986267859468, 'dropout_rate_Layer_2': 0.029096018106371385, 'dropout_rate_Layer_3': 0.0005310175464789714, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.005370803898052178, 'l1_Layer_2': 0.020272450230310702, 'l1_Layer_3': 3.0798833760704384e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 80, 'n_units_Layer_3': 260}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.04 | sMAPE for Validation Set is: 13.97% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 54.29 | sMAPE for Test Set is: 50.71% | rMAE for Test Set is: 2.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:45:15,532]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:45:15,667]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:45:15,857]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:45:25,364]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:45:29,255]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:45:33,003]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:45:36,145]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:45:40,330]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:45:42,160]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:45:46,683]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:45:50,635]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:46:05,729]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:46:11,104]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:46:19,413]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:46:23,038]\u001b[0m Trial 1279 finished with value: 3.8917723097221213 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006632611962877831, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05276576587561453, 'dropout_rate_Layer_2': 0.042713619553235264, 'dropout_rate_Layer_3': 0.053458555020109634, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007273312513443683, 'l1_Layer_2': 0.0011058553023748571, 'l1_Layer_3': 0.00010093501840874261, 'n_units_Layer_1': 295, 'n_units_Layer_2': 240, 'n_units_Layer_3': 140}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.89 | sMAPE for Validation Set is: 13.90% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 47.20 | sMAPE for Test Set is: 42.51% | rMAE for Test Set is: 1.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:46:28,150]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:46:31,560]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:46:35,753]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:46:43,458]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:46:47,385]\u001b[0m Trial 1296 finished with value: 3.832073522399948 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013369370420909527, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.024284933690333157, 'dropout_rate_Layer_2': 0.3221628593602737, 'dropout_rate_Layer_3': 0.20218329544698793, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004619176745984543, 'l1_Layer_2': 0.00822915440692617, 'l1_Layer_3': 2.386545861677695e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 265, 'n_units_Layer_3': 220}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.83 | sMAPE for Validation Set is: 13.27% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 14.27 | sMAPE for Test Set is: 18.63% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:46:50,246]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:46:55,722]\u001b[0m Trial 1302 finished with value: 4.027580500029809 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015074278945991855, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06668129291660019, 'dropout_rate_Layer_2': 0.02217451778479169, 'dropout_rate_Layer_3': 0.039314818779857166, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.01203703742758265, 'l1_Layer_2': 0.02782536340158609, 'l1_Layer_3': 2.1047683920332175e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 80, 'n_units_Layer_3': 250}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.03 | sMAPE for Validation Set is: 13.87% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 53.47 | sMAPE for Test Set is: 49.66% | rMAE for Test Set is: 2.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:46:56,244]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:47:03,005]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:47:03,838]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:47:09,262]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:47:16,205]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:47:23,708]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:47:42,823]\u001b[0m Trial 1306 finished with value: 4.025774567583256 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011866249737986574, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12233472148532692, 'dropout_rate_Layer_2': 0.008137999982129579, 'dropout_rate_Layer_3': 9.421264960633117e-05, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.011608207594915494, 'l1_Layer_2': 0.027922429949701063, 'l1_Layer_3': 2.0660443500287678e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 80, 'n_units_Layer_3': 265}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.03 | sMAPE for Validation Set is: 13.72% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 51.61 | sMAPE for Test Set is: 47.51% | rMAE for Test Set is: 2.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:47:45,461]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:47:50,644]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:47:51,604]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:47:58,141]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:48:00,232]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:48:02,786]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:48:03,582]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:48:04,462]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:48:10,568]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:48:11,911]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:48:11,955]\u001b[0m Trial 1314 finished with value: 3.693065441626581 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007055692987995298, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03308003782850816, 'dropout_rate_Layer_2': 0.023883767878422703, 'dropout_rate_Layer_3': 0.1249508831622255, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006465759936644706, 'l1_Layer_2': 0.00039316144951321446, 'l1_Layer_3': 0.00012266808892962707, 'n_units_Layer_1': 285, 'n_units_Layer_2': 225, 'n_units_Layer_3': 145}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.69 | sMAPE for Validation Set is: 13.05% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 45.19 | sMAPE for Test Set is: 40.40% | rMAE for Test Set is: 1.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:48:12,227]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:48:22,779]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:48:24,694]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:48:24,830]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:48:29,659]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:48:33,842]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:48:34,241]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:48:35,497]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:48:41,798]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:48:44,749]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:48:45,528]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:48:50,221]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:48:57,231]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:49:04,928]\u001b[0m Trial 1336 finished with value: 4.065829379715738 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014159918093613235, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12248914331335936, 'dropout_rate_Layer_2': 0.014816935418770053, 'dropout_rate_Layer_3': 0.024522120088411103, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.010131391365744683, 'l1_Layer_2': 0.022169802559525716, 'l1_Layer_3': 2.1119334545066477e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 75, 'n_units_Layer_3': 260}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.07 | sMAPE for Validation Set is: 14.02% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 55.15 | sMAPE for Test Set is: 51.77% | rMAE for Test Set is: 2.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:49:13,247]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:49:13,905]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:49:18,398]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:49:20,314]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:49:29,440]\u001b[0m Trial 1326 finished with value: 3.7155710291751802 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005579039646324047, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04666760983559719, 'dropout_rate_Layer_2': 0.023859959848485213, 'dropout_rate_Layer_3': 0.12401409131289606, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008558212823261424, 'l1_Layer_2': 0.00029536216590928866, 'l1_Layer_3': 0.00012956777966219478, 'n_units_Layer_1': 270, 'n_units_Layer_2': 215, 'n_units_Layer_3': 150}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.72 | sMAPE for Validation Set is: 13.19% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 44.31 | sMAPE for Test Set is: 39.51% | rMAE for Test Set is: 1.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:49:29,924]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:49:43,591]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:49:47,277]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:49:53,443]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:49:57,147]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:50:06,128]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:50:15,180]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:50:33,175]\u001b[0m Trial 1350 finished with value: 3.695354096285701 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014345202743748355, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02014607980995954, 'dropout_rate_Layer_2': 0.328959191929789, 'dropout_rate_Layer_3': 0.20542396510460356, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006229569867638686, 'l1_Layer_2': 0.0061671656162556225, 'l1_Layer_3': 2.1602844476261798e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 265, 'n_units_Layer_3': 235}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.70 | sMAPE for Validation Set is: 12.78% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 14.33 | sMAPE for Test Set is: 18.66% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:50:37,830]\u001b[0m Trial 1347 finished with value: 3.704293239010409 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005020804334606609, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05169267925312397, 'dropout_rate_Layer_2': 0.015118072673243242, 'dropout_rate_Layer_3': 0.04768683818551611, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009841266009319454, 'l1_Layer_2': 0.0002909640497681493, 'l1_Layer_3': 7.3424935378714e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 205, 'n_units_Layer_3': 130}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.70 | sMAPE for Validation Set is: 13.13% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 43.85 | sMAPE for Test Set is: 39.00% | rMAE for Test Set is: 1.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:50:38,278]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:50:44,182]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:50:44,493]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:50:45,745]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:50:52,457]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:50:55,251]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:51:00,630]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:51:04,985]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:51:11,147]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:51:12,141]\u001b[0m Trial 1352 finished with value: 3.733395552552178 and parameters: {'n_hidden': 3, 'learning_rate': 0.00123890873683653, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13510737384415936, 'dropout_rate_Layer_2': 0.3261688407733618, 'dropout_rate_Layer_3': 0.20115467915075363, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005824064705379191, 'l1_Layer_2': 3.097597880340134e-05, 'l1_Layer_3': 2.0746922588260655e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 250, 'n_units_Layer_3': 255}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.73 | sMAPE for Validation Set is: 12.98% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 14.28 | sMAPE for Test Set is: 18.86% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:51:49,481]\u001b[0m Trial 1361 finished with value: 3.7597195911828067 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005015852244540197, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0574568117875332, 'dropout_rate_Layer_2': 0.0005408518863863005, 'dropout_rate_Layer_3': 0.03401835226533169, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010090025463843908, 'l1_Layer_2': 0.000258579393764078, 'l1_Layer_3': 7.968670413547552e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 205, 'n_units_Layer_3': 125}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.76 | sMAPE for Validation Set is: 13.39% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 44.63 | sMAPE for Test Set is: 39.90% | rMAE for Test Set is: 1.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:51:59,834]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:52:09,779]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:52:19,294]\u001b[0m Trial 1359 finished with value: 3.697063641693156 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012461372278989033, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04063290953390632, 'dropout_rate_Layer_2': 0.3264819701915653, 'dropout_rate_Layer_3': 0.20103499370702146, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005449271764379936, 'l1_Layer_2': 0.005631264167752414, 'l1_Layer_3': 1.5154589901766928e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 265, 'n_units_Layer_3': 255}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.70 | sMAPE for Validation Set is: 12.83% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 14.56 | sMAPE for Test Set is: 18.90% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:52:20,327]\u001b[0m Trial 1365 finished with value: 3.6371024396271197 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005060563715260187, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.050932756598296464, 'dropout_rate_Layer_2': 0.01208868303010674, 'dropout_rate_Layer_3': 0.036329115959942065, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010936279054086797, 'l1_Layer_2': 0.00014274628286784454, 'l1_Layer_3': 7.539432031812003e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 210, 'n_units_Layer_3': 125}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.64 | sMAPE for Validation Set is: 12.89% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 45.31 | sMAPE for Test Set is: 40.49% | rMAE for Test Set is: 1.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:52:25,516]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:52:32,872]\u001b[0m Trial 1367 finished with value: 4.027171178512698 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012322846684814216, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11466828888449537, 'dropout_rate_Layer_2': 0.03375522881737095, 'dropout_rate_Layer_3': 0.014044608285468836, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.011432977223229047, 'l1_Layer_2': 0.02958327180833796, 'l1_Layer_3': 2.7488443456967072e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 75, 'n_units_Layer_3': 255}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.03 | sMAPE for Validation Set is: 13.87% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 52.84 | sMAPE for Test Set is: 48.88% | rMAE for Test Set is: 2.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:52:36,905]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:52:41,441]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:52:59,580]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:53:20,182]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:53:21,154]\u001b[0m Trial 1369 finished with value: 3.659759610352299 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010502905791402823, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.006624369447584254, 'dropout_rate_Layer_2': 0.35754100099146174, 'dropout_rate_Layer_3': 0.1987100870303894, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004849999351002269, 'l1_Layer_2': 0.009273642813589302, 'l1_Layer_3': 1.518365544070282e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 250, 'n_units_Layer_3': 235}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.66 | sMAPE for Validation Set is: 12.71% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 14.11 | sMAPE for Test Set is: 18.60% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:53:27,660]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:53:28,300]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:53:33,926]\u001b[0m Trial 1372 finished with value: 3.7962951794175375 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005033815318276388, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06337577630578381, 'dropout_rate_Layer_2': 0.001117706783686558, 'dropout_rate_Layer_3': 0.012786087705820293, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014440721587692517, 'l1_Layer_2': 0.00012066299589477502, 'l1_Layer_3': 5.716157677505303e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 200, 'n_units_Layer_3': 120}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.80 | sMAPE for Validation Set is: 13.56% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 44.81 | sMAPE for Test Set is: 40.18% | rMAE for Test Set is: 1.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:53:41,648]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:54:03,970]\u001b[0m Trial 1376 finished with value: 3.737599122529795 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011532444897362514, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.021473523643604747, 'dropout_rate_Layer_2': 0.35497670072240645, 'dropout_rate_Layer_3': 0.21334554962967345, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007168647262960435, 'l1_Layer_2': 0.007462117912288748, 'l1_Layer_3': 1.4056838912334481e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 260, 'n_units_Layer_3': 250}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.74 | sMAPE for Validation Set is: 13.01% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 14.94 | sMAPE for Test Set is: 19.01% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:54:13,291]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:54:29,446]\u001b[0m Trial 1380 finished with value: 3.704969178377309 and parameters: {'n_hidden': 3, 'learning_rate': 0.000936064489346189, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0060539446212944355, 'dropout_rate_Layer_2': 0.3179664483815956, 'dropout_rate_Layer_3': 0.2038306530590363, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0054769216632653845, 'l1_Layer_2': 0.007205203368783006, 'l1_Layer_3': 1.4795221315749503e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 250, 'n_units_Layer_3': 235}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.70 | sMAPE for Validation Set is: 12.85% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 14.04 | sMAPE for Test Set is: 18.52% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:54:48,753]\u001b[0m Trial 1381 finished with value: 3.717950921786971 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008883907743057589, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007269880911982402, 'dropout_rate_Layer_2': 0.36438507911701834, 'dropout_rate_Layer_3': 0.30222773183765517, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004766294465709957, 'l1_Layer_2': 0.008110351968035771, 'l1_Layer_3': 1.485234380576866e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 250, 'n_units_Layer_3': 235}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.72 | sMAPE for Validation Set is: 12.90% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 14.75 | sMAPE for Test Set is: 18.90% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:54:52,380]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:55:01,306]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:55:04,961]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:55:15,453]\u001b[0m Trial 1383 finished with value: 3.712954031378445 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005550687244855814, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06323249755050292, 'dropout_rate_Layer_2': 0.012861764799967335, 'dropout_rate_Layer_3': 0.03957044191961384, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011178302564847247, 'l1_Layer_2': 0.0002272597363662429, 'l1_Layer_3': 8.904162549679687e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 200, 'n_units_Layer_3': 125}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.71 | sMAPE for Validation Set is: 13.24% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 46.10 | sMAPE for Test Set is: 41.51% | rMAE for Test Set is: 1.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:55:19,330]\u001b[0m Trial 1384 finished with value: 3.684368158670742 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005022981143494964, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05885661551235443, 'dropout_rate_Layer_2': 0.013219234385442596, 'dropout_rate_Layer_3': 0.04792897547066, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010999752057052159, 'l1_Layer_2': 0.00016683591806723624, 'l1_Layer_3': 8.26270573720757e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 205, 'n_units_Layer_3': 125}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.68 | sMAPE for Validation Set is: 13.10% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 43.82 | sMAPE for Test Set is: 38.99% | rMAE for Test Set is: 1.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:55:22,026]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:55:26,798]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:55:32,938]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:55:36,687]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:55:43,040]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:55:47,470]\u001b[0m Trial 1385 finished with value: 3.686164763873666 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005040425055528734, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05161006841598148, 'dropout_rate_Layer_2': 0.013475982329676615, 'dropout_rate_Layer_3': 0.051515059228190815, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011326986825255737, 'l1_Layer_2': 0.00014951809071145884, 'l1_Layer_3': 9.030515180030419e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 215, 'n_units_Layer_3': 125}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.69 | sMAPE for Validation Set is: 13.00% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 43.21 | sMAPE for Test Set is: 38.31% | rMAE for Test Set is: 1.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:55:47,684]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:55:53,199]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:55:54,159]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:55:58,475]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:56:02,437]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:56:06,235]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:56:13,636]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:56:16,818]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:56:22,780]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:56:28,300]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:56:49,272]\u001b[0m Trial 1397 finished with value: 3.742513449807463 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005058999323385789, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06549971079466888, 'dropout_rate_Layer_2': 0.008874838133720107, 'dropout_rate_Layer_3': 0.03338806901987625, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001395267041425643, 'l1_Layer_2': 0.0001655467156779603, 'l1_Layer_3': 8.822454398228847e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 200, 'n_units_Layer_3': 120}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.74 | sMAPE for Validation Set is: 13.36% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 42.88 | sMAPE for Test Set is: 38.12% | rMAE for Test Set is: 1.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:56:53,248]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:57:07,385]\u001b[0m Trial 1401 finished with value: 3.7127459266834375 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010215904149199824, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02176566355721928, 'dropout_rate_Layer_2': 0.35296048701453286, 'dropout_rate_Layer_3': 0.2849424703938634, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004772956626196144, 'l1_Layer_2': 0.007757480026461484, 'l1_Layer_3': 1.6295607175722426e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 250, 'n_units_Layer_3': 250}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.71 | sMAPE for Validation Set is: 12.99% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 14.80 | sMAPE for Test Set is: 18.95% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:57:27,869]\u001b[0m Trial 1403 finished with value: 3.7151152187945553 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010072570526944477, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02120537022090055, 'dropout_rate_Layer_2': 0.3533565287767538, 'dropout_rate_Layer_3': 0.27274853308198155, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004907237918932649, 'l1_Layer_2': 0.007552765452411484, 'l1_Layer_3': 1.6286640893583527e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 250, 'n_units_Layer_3': 245}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.72 | sMAPE for Validation Set is: 12.88% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 14.45 | sMAPE for Test Set is: 18.89% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:57:34,179]\u001b[0m Trial 1409 finished with value: 4.086038640561542 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014524775622573505, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0988942861973756, 'dropout_rate_Layer_2': 0.019025893045542162, 'dropout_rate_Layer_3': 0.03357533988913222, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00661490314448908, 'l1_Layer_2': 0.02673098190131216, 'l1_Layer_3': 1.8104088440398513e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 75, 'n_units_Layer_3': 250}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.09 | sMAPE for Validation Set is: 14.02% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 52.53 | sMAPE for Test Set is: 48.47% | rMAE for Test Set is: 2.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:57:40,839]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:57:47,366]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:57:51,057]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:57:51,478]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:57:58,219]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:58:03,362]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:58:04,185]\u001b[0m Trial 1407 finished with value: 3.6855592278008564 and parameters: {'n_hidden': 3, 'learning_rate': 0.001022341082864519, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00874159758043387, 'dropout_rate_Layer_2': 0.3386288507566221, 'dropout_rate_Layer_3': 0.28545971784771185, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00485891542318491, 'l1_Layer_2': 0.005315916565607196, 'l1_Layer_3': 1.778973749784143e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 250, 'n_units_Layer_3': 235}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.69 | sMAPE for Validation Set is: 12.79% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 14.59 | sMAPE for Test Set is: 18.92% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:58:12,104]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:58:16,429]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:58:23,608]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:58:27,728]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:58:47,978]\u001b[0m Trial 1419 finished with value: 4.040234035520279 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013484046998422305, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12364704495703162, 'dropout_rate_Layer_2': 0.018734724249135873, 'dropout_rate_Layer_3': 0.037480893688548025, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.006548588642808653, 'l1_Layer_2': 0.024153765187273874, 'l1_Layer_3': 1.8351685808390435e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 75, 'n_units_Layer_3': 255}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.04 | sMAPE for Validation Set is: 13.74% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 52.90 | sMAPE for Test Set is: 49.04% | rMAE for Test Set is: 2.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:59:13,257]\u001b[0m Trial 1418 finished with value: 3.649635071247511 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005010898736443034, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05268949133973523, 'dropout_rate_Layer_2': 0.009699122106928401, 'dropout_rate_Layer_3': 0.039968807021801035, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015310887250821119, 'l1_Layer_2': 0.000105667673709325, 'l1_Layer_3': 9.212319139118042e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 195, 'n_units_Layer_3': 120}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.65 | sMAPE for Validation Set is: 12.90% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 43.34 | sMAPE for Test Set is: 38.48% | rMAE for Test Set is: 1.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:59:18,039]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:59:19,346]\u001b[0m Trial 1416 finished with value: 3.7181477272300225 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010991719217365848, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015668047936120456, 'dropout_rate_Layer_2': 0.37207979202590546, 'dropout_rate_Layer_3': 0.2790214871492006, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005387335830914247, 'l1_Layer_2': 0.011411337128759092, 'l1_Layer_3': 1.8915554138302713e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 250, 'n_units_Layer_3': 235}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.72 | sMAPE for Validation Set is: 12.91% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 14.67 | sMAPE for Test Set is: 18.86% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:59:22,452]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:59:24,143]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:59:30,635]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:59:35,092]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:59:38,047]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:59:41,983]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:59:50,462]\u001b[0m Trial 1423 finished with value: 3.712767489147938 and parameters: {'n_hidden': 3, 'learning_rate': 0.001082337829970961, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.012469948208760191, 'dropout_rate_Layer_2': 0.36537252808977594, 'dropout_rate_Layer_3': 0.27424347589716896, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005251221508262635, 'l1_Layer_2': 0.007319268392423995, 'l1_Layer_3': 1.1854395794090773e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 250, 'n_units_Layer_3': 260}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.71 | sMAPE for Validation Set is: 12.86% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 14.47 | sMAPE for Test Set is: 18.78% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 05:59:54,768]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 05:59:57,294]\u001b[0m Trial 1428 finished with value: 4.04225294237128 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013612718600272444, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12332920444561239, 'dropout_rate_Layer_2': 0.02266475419121008, 'dropout_rate_Layer_3': 0.05501189522072838, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.01096989902613188, 'l1_Layer_2': 0.0187323576000625, 'l1_Layer_3': 2.2185303600489274e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 70, 'n_units_Layer_3': 250}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.04 | sMAPE for Validation Set is: 13.99% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 54.18 | sMAPE for Test Set is: 50.57% | rMAE for Test Set is: 2.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 06:00:01,194]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:00:01,343]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:00:08,925]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:00:11,626]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:00:15,487]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:00:18,935]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:00:19,729]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:00:24,578]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:00:24,847]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:00:34,016]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:00:38,649]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:00:44,729]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:00:45,162]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:00:50,321]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:00:53,586]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:00:56,830]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:01:03,758]\u001b[0m Trial 1433 finished with value: 3.8249022217381294 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006087576817512509, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0647796615510001, 'dropout_rate_Layer_2': 0.023650437854690516, 'dropout_rate_Layer_3': 0.0303528808911689, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013690919286560588, 'l1_Layer_2': 0.00015760273302978375, 'l1_Layer_3': 9.236138371161697e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 195, 'n_units_Layer_3': 125}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.82 | sMAPE for Validation Set is: 13.58% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 45.79 | sMAPE for Test Set is: 41.04% | rMAE for Test Set is: 1.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 06:01:06,709]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:01:08,125]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:01:13,071]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:01:13,882]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:01:13,973]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:01:20,382]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:01:24,354]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:01:24,932]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:01:28,429]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:01:34,665]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:01:35,920]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:01:41,026]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:01:41,277]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:01:46,244]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:01:50,138]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:01:50,776]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:01:51,036]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:01:59,911]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:02:02,148]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:02:05,824]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:02:06,593]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:02:15,886]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:02:16,055]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:02:39,766]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:02:45,626]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:02:54,850]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:02:58,674]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:03:02,871]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:03:08,309]\u001b[0m Trial 1475 finished with value: 4.27995689017527 and parameters: {'n_hidden': 3, 'learning_rate': 0.001426804067982182, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07003959321066193, 'dropout_rate_Layer_2': 0.02436817875423931, 'dropout_rate_Layer_3': 0.0640107109994392, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.012841355612899626, 'l1_Layer_2': 0.0504013866300327, 'l1_Layer_3': 1.7840297799476538e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 60, 'n_units_Layer_3': 150}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.28 | sMAPE for Validation Set is: 14.87% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 15.73 | sMAPE for Test Set is: 20.12% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 06:03:13,595]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:03:17,940]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:03:26,272]\u001b[0m Trial 1474 finished with value: 3.6785798105832703 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010771647950283722, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.024404807017746326, 'dropout_rate_Layer_2': 0.33616902342888194, 'dropout_rate_Layer_3': 0.28460242681685183, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0062705130780075355, 'l1_Layer_2': 0.004038742008746667, 'l1_Layer_3': 1.234651340374146e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 250, 'n_units_Layer_3': 225}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.68 | sMAPE for Validation Set is: 12.77% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 14.10 | sMAPE for Test Set is: 18.64% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 06:03:30,682]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:03:35,308]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:03:53,652]\u001b[0m Trial 1482 finished with value: 4.03077648407016 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010927111802794965, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1317355308130991, 'dropout_rate_Layer_2': 0.0037014187523432343, 'dropout_rate_Layer_3': 0.014165550305225812, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.007457051070592477, 'l1_Layer_2': 0.02228612084398174, 'l1_Layer_3': 2.6216270868295344e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 80, 'n_units_Layer_3': 245}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.03 | sMAPE for Validation Set is: 13.73% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 52.63 | sMAPE for Test Set is: 48.70% | rMAE for Test Set is: 2.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 06:03:59,071]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:03:59,078]\u001b[0m Trial 1486 finished with value: 3.9966817400050356 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009952206636690375, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11858986142517575, 'dropout_rate_Layer_2': 0.005654572643746109, 'dropout_rate_Layer_3': 0.01429608812155743, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.025893522744780146, 'l1_Layer_2': 0.021371911437007632, 'l1_Layer_3': 3.088128677550398e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 80, 'n_units_Layer_3': 245}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.00 | sMAPE for Validation Set is: 13.80% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 54.90 | sMAPE for Test Set is: 51.43% | rMAE for Test Set is: 2.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 06:04:05,577]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:04:07,058]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:04:09,361]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:04:13,582]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:04:15,436]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:04:16,377]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:04:21,869]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:04:25,710]\u001b[0m Trial 1487 finished with value: 4.079710958015066 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011128087897855506, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1326856554705519, 'dropout_rate_Layer_2': 0.005860020896454326, 'dropout_rate_Layer_3': 0.01278545699209406, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.005558454194295851, 'l1_Layer_2': 0.021567210427144705, 'l1_Layer_3': 2.8770800452528527e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 80, 'n_units_Layer_3': 245}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.08 | sMAPE for Validation Set is: 14.11% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 52.86 | sMAPE for Test Set is: 49.04% | rMAE for Test Set is: 2.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 06:04:29,190]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:04:29,933]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 06:04:40,193]\u001b[0m Trial 1497 finished with value: 4.056837348326998 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010647181265953918, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27207357973054164, 'dropout_rate_Layer_2': 0.10834204745375633, 'dropout_rate_Layer_3': 0.3523468634506454, 'dropout_rate_Layer_4': 0.31752626227570635, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 7.626459302882891e-05, 'l1_Layer_2': 0.00011903732147884759, 'l1_Layer_3': 9.102386164737414e-05, 'l1_Layer_4': 7.120868979826484e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 235, 'n_units_Layer_3': 150, 'n_units_Layer_4': 165}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.06 | sMAPE for Validation Set is: 14.23% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 59.52 | sMAPE for Test Set is: 57.19% | rMAE for Test Set is: 2.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 06:04:41,897]\u001b[0m Trial 1496 finished with value: 4.092890269904637 and parameters: {'n_hidden': 3, 'learning_rate': 0.000951972582639485, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1416330635099651, 'dropout_rate_Layer_2': 0.0018964470734799807, 'dropout_rate_Layer_3': 0.01903660125047275, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.03677523257952267, 'l1_Layer_2': 0.02630195886381631, 'l1_Layer_3': 3.715975469575503e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 70, 'n_units_Layer_3': 255}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.09 | sMAPE for Validation Set is: 14.09% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 55.06 | sMAPE for Test Set is: 51.68% | rMAE for Test Set is: 2.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 06:04:49,857]\u001b[0m Trial 1499 finished with value: 4.081816646439562 and parameters: {'n_hidden': 3, 'learning_rate': 0.000968259027427709, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13143777343055482, 'dropout_rate_Layer_2': 0.004408815949048805, 'dropout_rate_Layer_3': 0.022592616898661676, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0295442683752056, 'l1_Layer_2': 0.016710712598711673, 'l1_Layer_3': 3.4838862614505346e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 75, 'n_units_Layer_3': 230}. Best is trial 1203 with value: 3.627662358345981.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.08 | sMAPE for Validation Set is: 14.19% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 53.04 | sMAPE for Test Set is: 49.16% | rMAE for Test Set is: 2.13\n",
      "for 2021-01-01, MAE is:6.11 & sMAPE is:14.26% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.11 & 14.26% & 0.23\n",
      "for 2021-01-02, MAE is:1.99 & sMAPE is:3.93% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :4.05 & 9.10% & 0.18\n",
      "for 2021-01-03, MAE is:4.00 & sMAPE is:8.29% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 8.83% & 0.19\n",
      "for 2021-01-04, MAE is:7.22 & sMAPE is:12.31% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :4.83 & 9.70% & 0.19\n",
      "for 2021-01-05, MAE is:6.81 & sMAPE is:10.12% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :5.23 & 9.78% & 0.20\n",
      "for 2021-01-06, MAE is:5.50 & sMAPE is:7.85% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :5.27 & 9.46% & 0.21\n",
      "for 2021-01-07, MAE is:19.02 & sMAPE is:22.26% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :7.24 & 11.29% & 0.24\n",
      "for 2021-01-08, MAE is:14.11 & sMAPE is:15.57% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :8.09 & 11.82% & 0.25\n",
      "for 2021-01-09, MAE is:13.16 & sMAPE is:15.29% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :8.66 & 12.21% & 0.26\n",
      "for 2021-01-10, MAE is:27.06 & sMAPE is:34.71% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :10.50 & 14.46% & 0.35\n",
      "for 2021-01-11, MAE is:12.18 & sMAPE is:15.15% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :10.65 & 14.52% & 0.37\n",
      "for 2021-01-12, MAE is:9.33 & sMAPE is:11.89% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :10.54 & 14.30% & 0.38\n",
      "for 2021-01-13, MAE is:4.97 & sMAPE is:6.15% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :10.11 & 13.68% & 0.37\n",
      "for 2021-01-14, MAE is:10.59 & sMAPE is:12.36% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :10.15 & 13.58% & 0.48\n",
      "for 2021-01-15, MAE is:15.33 & sMAPE is:18.30% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :10.49 & 13.90% & 0.51\n",
      "for 2021-01-16, MAE is:7.97 & sMAPE is:11.36% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :10.33 & 13.74% & 0.51\n",
      "for 2021-01-17, MAE is:8.06 & sMAPE is:11.20% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :10.20 & 13.59% & 0.56\n",
      "for 2021-01-18, MAE is:9.10 & sMAPE is:11.89% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :10.14 & 13.49% & 0.57\n",
      "for 2021-01-19, MAE is:6.78 & sMAPE is:8.55% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :9.96 & 13.23% & 0.57\n",
      "for 2021-01-20, MAE is:11.09 & sMAPE is:18.75% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :10.02 & 13.51% & 0.55\n",
      "for 2021-01-21, MAE is:5.96 & sMAPE is:16.42% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :9.83 & 13.65% & 0.53\n",
      "for 2021-01-22, MAE is:4.00 & sMAPE is:9.65% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :9.56 & 13.47% & 0.51\n",
      "for 2021-01-23, MAE is:17.19 & sMAPE is:53.07% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :9.89 & 15.19% & 0.51\n",
      "for 2021-01-24, MAE is:7.87 & sMAPE is:42.30% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :9.81 & 16.32% & 0.50\n",
      "for 2021-01-25, MAE is:12.05 & sMAPE is:22.85% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :9.90 & 16.58% & 0.50\n",
      "for 2021-01-26, MAE is:8.41 & sMAPE is:14.08% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :9.84 & 16.48% & 0.51\n",
      "for 2021-01-27, MAE is:3.54 & sMAPE is:6.46% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :9.61 & 16.11% & 0.51\n",
      "for 2021-01-28, MAE is:5.29 & sMAPE is:9.85% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :9.45 & 15.89% & 0.50\n",
      "for 2021-01-29, MAE is:4.99 & sMAPE is:11.17% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :9.30 & 15.73% & 0.51\n",
      "for 2021-01-30, MAE is:33.94 & sMAPE is:163.54% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :10.12 & 20.65% & 0.54\n",
      "for 2021-01-31, MAE is:5.56 & sMAPE is:130.24% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :9.97 & 24.19% & 0.53\n",
      "for 2021-02-01, MAE is:6.92 & sMAPE is:91.32% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :9.88 & 26.29% & 0.52\n",
      "for 2021-02-02, MAE is:8.60 & sMAPE is:57.36% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :9.84 & 27.23% & 0.51\n",
      "for 2021-02-03, MAE is:11.74 & sMAPE is:38.11% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :9.90 & 27.55% & 0.51\n",
      "for 2021-02-04, MAE is:11.70 & sMAPE is:24.98% & rMAE is:2.37 ||| daily mean of MAE & sMAPE & rMAE till now are :9.95 & 27.47% & 0.56\n",
      "for 2021-02-05, MAE is:3.68 & sMAPE is:7.19% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :9.77 & 26.91% & 0.57\n",
      "for 2021-02-06, MAE is:6.86 & sMAPE is:17.82% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :9.69 & 26.67% & 0.56\n",
      "for 2021-02-07, MAE is:15.49 & sMAPE is:91.51% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :9.85 & 28.37% & 0.58\n",
      "for 2021-02-08, MAE is:8.43 & sMAPE is:84.88% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :9.81 & 29.82% & 0.61\n",
      "for 2021-02-09, MAE is:6.11 & sMAPE is:90.76% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :9.72 & 31.34% & 0.60\n",
      "for 2021-02-10, MAE is:16.09 & sMAPE is:125.09% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :9.87 & 33.63% & 0.61\n",
      "for 2021-02-11, MAE is:17.53 & sMAPE is:45.28% & rMAE is:2.19 ||| daily mean of MAE & sMAPE & rMAE till now are :10.06 & 33.91% & 0.65\n",
      "for 2021-02-12, MAE is:16.96 & sMAPE is:47.21% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :10.22 & 34.22% & 0.66\n",
      "for 2021-02-13, MAE is:10.83 & sMAPE is:34.51% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :10.23 & 34.22% & 0.66\n",
      "for 2021-02-14, MAE is:32.03 & sMAPE is:114.62% & rMAE is:3.84 ||| daily mean of MAE & sMAPE & rMAE till now are :10.72 & 36.01% & 0.73\n",
      "for 2021-02-15, MAE is:7.44 & sMAPE is:86.25% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :10.64 & 37.10% & 0.74\n",
      "for 2021-02-16, MAE is:13.67 & sMAPE is:77.21% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :10.71 & 37.96% & 0.74\n",
      "for 2021-02-17, MAE is:9.70 & sMAPE is:24.33% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :10.69 & 37.67% & 0.74\n",
      "for 2021-02-18, MAE is:8.84 & sMAPE is:35.63% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :10.65 & 37.63% & 0.74\n",
      "for 2021-02-19, MAE is:20.21 & sMAPE is:68.07% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :10.84 & 38.24% & 0.75\n",
      "for 2021-02-20, MAE is:17.28 & sMAPE is:172.35% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :10.97 & 40.87% & 0.74\n",
      "for 2021-02-21, MAE is:3.09 & sMAPE is:75.88% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :10.82 & 41.54% & 0.74\n",
      "for 2021-02-22, MAE is:29.16 & sMAPE is:126.80% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :11.16 & 43.15% & 0.74\n",
      "for 2021-02-23, MAE is:6.19 & sMAPE is:14.10% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :11.07 & 42.61% & 0.73\n",
      "for 2021-02-24, MAE is:15.83 & sMAPE is:62.01% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :11.16 & 42.97% & 0.74\n",
      "for 2021-02-25, MAE is:11.13 & sMAPE is:28.07% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :11.16 & 42.70% & 0.74\n",
      "for 2021-02-26, MAE is:5.60 & sMAPE is:12.19% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :11.06 & 42.16% & 0.73\n",
      "for 2021-02-27, MAE is:12.90 & sMAPE is:37.42% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :11.09 & 42.08% & 0.73\n",
      "for 2021-02-28, MAE is:8.49 & sMAPE is:41.64% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :11.05 & 42.08% & 0.73\n",
      "for 2021-03-01, MAE is:15.82 & sMAPE is:47.13% & rMAE is:2.71 ||| daily mean of MAE & sMAPE & rMAE till now are :11.13 & 42.16% & 0.76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-03-02, MAE is:9.87 & sMAPE is:20.28% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :11.10 & 41.80% & 0.76\n",
      "for 2021-03-03, MAE is:6.53 & sMAPE is:12.18% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :11.03 & 41.32% & 0.76\n",
      "for 2021-03-04, MAE is:4.82 & sMAPE is:8.77% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :10.93 & 40.81% & 0.75\n",
      "for 2021-03-05, MAE is:5.38 & sMAPE is:10.21% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :10.85 & 40.33% & 0.75\n",
      "for 2021-03-06, MAE is:4.23 & sMAPE is:9.16% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :10.74 & 39.85% & 0.75\n",
      "for 2021-03-07, MAE is:6.14 & sMAPE is:13.64% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :10.67 & 39.45% & 0.74\n",
      "for 2021-03-08, MAE is:7.91 & sMAPE is:15.41% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :10.63 & 39.09% & 0.74\n",
      "for 2021-03-09, MAE is:4.43 & sMAPE is:7.81% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :10.54 & 38.63% & 0.74\n",
      "for 2021-03-10, MAE is:4.81 & sMAPE is:8.77% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :10.46 & 38.20% & 0.75\n",
      "for 2021-03-11, MAE is:8.68 & sMAPE is:20.65% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :10.43 & 37.95% & 0.74\n",
      "for 2021-03-12, MAE is:7.90 & sMAPE is:20.36% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :10.40 & 37.70% & 0.74\n",
      "for 2021-03-13, MAE is:15.60 & sMAPE is:49.49% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :10.47 & 37.86% & 0.75\n",
      "for 2021-03-14, MAE is:9.93 & sMAPE is:41.00% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :10.46 & 37.91% & 0.74\n",
      "for 2021-03-15, MAE is:7.40 & sMAPE is:17.15% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :10.42 & 37.63% & 0.74\n",
      "for 2021-03-16, MAE is:12.51 & sMAPE is:32.24% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :10.45 & 37.56% & 0.74\n",
      "for 2021-03-17, MAE is:15.00 & sMAPE is:59.99% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :10.51 & 37.85% & 0.74\n",
      "for 2021-03-18, MAE is:19.04 & sMAPE is:88.69% & rMAE is:2.18 ||| daily mean of MAE & sMAPE & rMAE till now are :10.62 & 38.51% & 0.76\n",
      "for 2021-03-19, MAE is:5.73 & sMAPE is:18.62% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :10.56 & 38.26% & 0.75\n",
      "for 2021-03-20, MAE is:5.96 & sMAPE is:25.93% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :10.50 & 38.10% & 0.75\n",
      "for 2021-03-21, MAE is:8.55 & sMAPE is:27.69% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :10.47 & 37.97% & 0.76\n",
      "for 2021-03-22, MAE is:10.28 & sMAPE is:20.17% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :10.47 & 37.75% & 0.77\n",
      "for 2021-03-23, MAE is:9.65 & sMAPE is:15.77% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :10.46 & 37.48% & 0.76\n",
      "for 2021-03-24, MAE is:5.17 & sMAPE is:7.94% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :10.40 & 37.13% & 0.75\n",
      "for 2021-03-25, MAE is:7.52 & sMAPE is:11.87% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :10.36 & 36.83% & 0.75\n",
      "for 2021-03-26, MAE is:4.65 & sMAPE is:7.79% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :10.30 & 36.48% & 0.74\n",
      "for 2021-03-27, MAE is:12.99 & sMAPE is:30.01% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :10.33 & 36.41% & 0.74\n",
      "for 2021-03-28, MAE is:8.76 & sMAPE is:22.41% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :10.31 & 36.25% & 0.74\n",
      "for 2021-03-29, MAE is:9.79 & sMAPE is:22.77% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :10.30 & 36.09% & 0.74\n",
      "for 2021-03-30, MAE is:7.70 & sMAPE is:15.33% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :10.27 & 35.86% & 0.74\n",
      "for 2021-03-31, MAE is:6.83 & sMAPE is:12.62% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :10.24 & 35.60% & 0.74\n",
      "for 2021-04-01, MAE is:5.77 & sMAPE is:11.12% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :10.19 & 35.33% & 0.74\n",
      "for 2021-04-02, MAE is:8.12 & sMAPE is:16.11% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :10.16 & 35.12% & 0.74\n",
      "for 2021-04-03, MAE is:8.78 & sMAPE is:26.63% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :10.15 & 35.03% & 0.74\n",
      "for 2021-04-04, MAE is:10.14 & sMAPE is:44.85% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :10.15 & 35.14% & 0.74\n",
      "for 2021-04-05, MAE is:11.60 & sMAPE is:29.82% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :10.16 & 35.08% & 0.75\n",
      "for 2021-04-06, MAE is:7.24 & sMAPE is:13.42% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :10.13 & 34.86% & 0.76\n",
      "for 2021-04-07, MAE is:10.65 & sMAPE is:17.39% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :10.14 & 34.68% & 0.76\n",
      "for 2021-04-08, MAE is:5.49 & sMAPE is:8.05% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :10.09 & 34.40% & 0.75\n",
      "for 2021-04-09, MAE is:6.98 & sMAPE is:10.20% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :10.06 & 34.16% & 0.75\n",
      "for 2021-04-10, MAE is:3.76 & sMAPE is:5.81% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :10.00 & 33.88% & 0.74\n",
      "for 2021-04-11, MAE is:5.44 & sMAPE is:10.94% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :9.95 & 33.65% & 0.74\n",
      "for 2021-04-12, MAE is:9.87 & sMAPE is:16.37% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :9.95 & 33.48% & 0.74\n",
      "for 2021-04-13, MAE is:9.06 & sMAPE is:12.60% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :9.94 & 33.28% & 0.73\n",
      "for 2021-04-14, MAE is:5.35 & sMAPE is:7.53% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :9.90 & 33.03% & 0.73\n",
      "for 2021-04-15, MAE is:3.65 & sMAPE is:5.48% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :9.84 & 32.77% & 0.74\n",
      "for 2021-04-16, MAE is:7.74 & sMAPE is:11.75% & rMAE is:2.89 ||| daily mean of MAE & sMAPE & rMAE till now are :9.82 & 32.57% & 0.76\n",
      "for 2021-04-17, MAE is:6.02 & sMAPE is:9.50% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :9.78 & 32.35% & 0.76\n",
      "for 2021-04-18, MAE is:6.95 & sMAPE is:10.68% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :9.76 & 32.15% & 0.76\n",
      "for 2021-04-19, MAE is:8.42 & sMAPE is:11.14% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :9.75 & 31.96% & 0.76\n",
      "for 2021-04-20, MAE is:6.57 & sMAPE is:8.49% & rMAE is:1.83 ||| daily mean of MAE & sMAPE & rMAE till now are :9.72 & 31.75% & 0.77\n",
      "for 2021-04-21, MAE is:8.61 & sMAPE is:11.38% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :9.71 & 31.56% & 0.77\n",
      "for 2021-04-22, MAE is:6.27 & sMAPE is:8.50% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :9.68 & 31.36% & 0.78\n",
      "for 2021-04-23, MAE is:9.89 & sMAPE is:14.50% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :9.68 & 31.21% & 0.79\n",
      "for 2021-04-24, MAE is:7.52 & sMAPE is:13.55% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :9.66 & 31.05% & 0.79\n",
      "for 2021-04-25, MAE is:7.70 & sMAPE is:12.47% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :9.64 & 30.89% & 0.80\n",
      "for 2021-04-26, MAE is:5.35 & sMAPE is:7.30% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :9.61 & 30.69% & 0.80\n",
      "for 2021-04-27, MAE is:8.23 & sMAPE is:11.33% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :9.59 & 30.52% & 0.81\n",
      "for 2021-04-28, MAE is:6.41 & sMAPE is:9.10% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :9.57 & 30.34% & 0.81\n",
      "for 2021-04-29, MAE is:6.56 & sMAPE is:9.14% & rMAE is:2.87 ||| daily mean of MAE & sMAPE & rMAE till now are :9.54 & 30.16% & 0.83\n",
      "for 2021-04-30, MAE is:8.86 & sMAPE is:11.74% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :9.54 & 30.01% & 0.83\n",
      "for 2021-05-01, MAE is:6.79 & sMAPE is:11.32% & rMAE is:2.08 ||| daily mean of MAE & sMAPE & rMAE till now are :9.51 & 29.86% & 0.84\n",
      "for 2021-05-02, MAE is:5.67 & sMAPE is:9.01% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :9.48 & 29.68% & 0.84\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-05-03, MAE is:8.82 & sMAPE is:12.37% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :9.48 & 29.54% & 0.85\n",
      "for 2021-05-04, MAE is:6.44 & sMAPE is:8.22% & rMAE is:1.79 ||| daily mean of MAE & sMAPE & rMAE till now are :9.45 & 29.37% & 0.86\n",
      "for 2021-05-05, MAE is:5.63 & sMAPE is:7.48% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :9.42 & 29.20% & 0.86\n",
      "for 2021-05-06, MAE is:5.66 & sMAPE is:7.82% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :9.39 & 29.03% & 0.87\n",
      "for 2021-05-07, MAE is:7.85 & sMAPE is:10.83% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :9.38 & 28.88% & 0.87\n",
      "for 2021-05-08, MAE is:25.35 & sMAPE is:56.86% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :9.50 & 29.10% & 0.87\n",
      "for 2021-05-09, MAE is:31.56 & sMAPE is:150.46% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :9.67 & 30.04% & 0.87\n",
      "for 2021-05-10, MAE is:18.40 & sMAPE is:36.31% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :9.74 & 30.09% & 0.87\n",
      "for 2021-05-11, MAE is:15.68 & sMAPE is:29.03% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :9.79 & 30.08% & 0.87\n",
      "for 2021-05-12, MAE is:14.17 & sMAPE is:27.98% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :9.82 & 30.07% & 0.87\n",
      "for 2021-05-13, MAE is:10.53 & sMAPE is:19.22% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :9.83 & 29.99% & 0.87\n",
      "for 2021-05-14, MAE is:8.79 & sMAPE is:12.75% & rMAE is:2.41 ||| daily mean of MAE & sMAPE & rMAE till now are :9.82 & 29.86% & 0.88\n",
      "for 2021-05-15, MAE is:25.55 & sMAPE is:61.68% & rMAE is:3.43 ||| daily mean of MAE & sMAPE & rMAE till now are :9.93 & 30.09% & 0.90\n",
      "for 2021-05-16, MAE is:23.26 & sMAPE is:80.95% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :10.03 & 30.47% & 0.90\n",
      "for 2021-05-17, MAE is:20.74 & sMAPE is:31.01% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :10.11 & 30.47% & 0.90\n",
      "for 2021-05-18, MAE is:7.57 & sMAPE is:9.97% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :10.09 & 30.32% & 0.90\n",
      "for 2021-05-19, MAE is:9.22 & sMAPE is:12.14% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :10.09 & 30.19% & 0.90\n",
      "for 2021-05-20, MAE is:7.12 & sMAPE is:9.15% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :10.06 & 30.04% & 0.89\n",
      "for 2021-05-21, MAE is:13.74 & sMAPE is:20.71% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :10.09 & 29.97% & 0.90\n",
      "for 2021-05-22, MAE is:11.16 & sMAPE is:17.49% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :10.10 & 29.89% & 0.89\n",
      "for 2021-05-23, MAE is:8.22 & sMAPE is:12.26% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :10.09 & 29.76% & 0.89\n",
      "for 2021-05-24, MAE is:7.69 & sMAPE is:11.23% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :10.07 & 29.63% & 0.89\n",
      "for 2021-05-25, MAE is:6.17 & sMAPE is:8.34% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :10.04 & 29.49% & 0.89\n",
      "for 2021-05-26, MAE is:7.66 & sMAPE is:10.09% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :10.03 & 29.35% & 0.89\n",
      "for 2021-05-27, MAE is:7.68 & sMAPE is:9.44% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :10.01 & 29.22% & 0.89\n",
      "for 2021-05-28, MAE is:6.79 & sMAPE is:7.90% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :9.99 & 29.08% & 0.89\n",
      "for 2021-05-29, MAE is:8.22 & sMAPE is:10.44% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :9.98 & 28.95% & 0.89\n",
      "for 2021-05-30, MAE is:7.53 & sMAPE is:10.22% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :9.96 & 28.83% & 0.89\n",
      "for 2021-05-31, MAE is:5.84 & sMAPE is:6.88% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :9.93 & 28.68% & 0.88\n",
      "for 2021-06-01, MAE is:6.00 & sMAPE is:7.09% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :9.91 & 28.54% & 0.88\n",
      "for 2021-06-02, MAE is:4.93 & sMAPE is:5.87% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :9.87 & 28.39% & 0.88\n",
      "for 2021-06-03, MAE is:5.37 & sMAPE is:6.92% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :9.84 & 28.25% & 0.88\n",
      "for 2021-06-04, MAE is:4.91 & sMAPE is:6.23% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :9.81 & 28.11% & 0.88\n",
      "for 2021-06-05, MAE is:5.90 & sMAPE is:7.81% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :9.79 & 27.98% & 0.88\n",
      "for 2021-06-06, MAE is:9.00 & sMAPE is:13.42% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :9.78 & 27.89% & 0.88\n",
      "for 2021-06-07, MAE is:4.63 & sMAPE is:5.97% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :9.75 & 27.75% & 0.88\n",
      "for 2021-06-08, MAE is:5.41 & sMAPE is:6.79% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :9.72 & 27.62% & 0.88\n",
      "for 2021-06-09, MAE is:4.78 & sMAPE is:6.14% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :9.69 & 27.48% & 0.88\n",
      "for 2021-06-10, MAE is:9.76 & sMAPE is:12.40% & rMAE is:2.15 ||| daily mean of MAE & sMAPE & rMAE till now are :9.69 & 27.39% & 0.89\n",
      "for 2021-06-11, MAE is:3.43 & sMAPE is:4.21% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :9.65 & 27.24% & 0.89\n",
      "for 2021-06-12, MAE is:5.79 & sMAPE is:7.43% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :9.63 & 27.12% & 0.89\n",
      "for 2021-06-13, MAE is:6.07 & sMAPE is:7.69% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :9.61 & 27.00% & 0.89\n",
      "for 2021-06-14, MAE is:4.77 & sMAPE is:5.57% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :9.58 & 26.87% & 0.89\n",
      "for 2021-06-15, MAE is:5.24 & sMAPE is:5.93% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :9.55 & 26.75% & 0.88\n",
      "for 2021-06-16, MAE is:7.18 & sMAPE is:7.84% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :9.54 & 26.63% & 0.88\n",
      "for 2021-06-17, MAE is:5.98 & sMAPE is:6.64% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :9.52 & 26.52% & 0.88\n",
      "for 2021-06-18, MAE is:4.42 & sMAPE is:5.00% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :9.49 & 26.39% & 0.88\n",
      "for 2021-06-19, MAE is:6.67 & sMAPE is:7.98% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :9.47 & 26.28% & 0.88\n",
      "for 2021-06-20, MAE is:27.39 & sMAPE is:49.90% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :9.58 & 26.42% & 0.88\n",
      "for 2021-06-21, MAE is:12.69 & sMAPE is:16.34% & rMAE is:1.77 ||| daily mean of MAE & sMAPE & rMAE till now are :9.59 & 26.36% & 0.88\n",
      "for 2021-06-22, MAE is:3.98 & sMAPE is:4.57% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :9.56 & 26.23% & 0.88\n",
      "for 2021-06-23, MAE is:8.94 & sMAPE is:10.70% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :9.56 & 26.14% & 0.89\n",
      "for 2021-06-24, MAE is:3.54 & sMAPE is:4.19% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :9.52 & 26.02% & 0.89\n",
      "for 2021-06-25, MAE is:5.36 & sMAPE is:6.20% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :9.50 & 25.91% & 0.89\n",
      "for 2021-06-26, MAE is:9.14 & sMAPE is:11.25% & rMAE is:2.27 ||| daily mean of MAE & sMAPE & rMAE till now are :9.50 & 25.82% & 0.89\n",
      "for 2021-06-27, MAE is:18.50 & sMAPE is:33.81% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :9.55 & 25.87% & 0.90\n",
      "for 2021-06-28, MAE is:10.10 & sMAPE is:12.18% & rMAE is:2.18 ||| daily mean of MAE & sMAPE & rMAE till now are :9.55 & 25.79% & 0.90\n",
      "for 2021-06-29, MAE is:4.09 & sMAPE is:4.46% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :9.52 & 25.67% & 0.90\n",
      "for 2021-06-30, MAE is:6.07 & sMAPE is:6.68% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :9.50 & 25.57% & 0.91\n",
      "for 2021-07-01, MAE is:4.37 & sMAPE is:4.86% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :9.47 & 25.45% & 0.90\n",
      "for 2021-07-02, MAE is:11.27 & sMAPE is:11.94% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :9.48 & 25.38% & 0.90\n",
      "for 2021-07-03, MAE is:6.01 & sMAPE is:6.57% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :9.46 & 25.28% & 0.90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-07-04, MAE is:12.96 & sMAPE is:15.87% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :9.48 & 25.23% & 0.90\n",
      "for 2021-07-05, MAE is:7.20 & sMAPE is:7.94% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :9.47 & 25.13% & 0.90\n",
      "for 2021-07-06, MAE is:6.28 & sMAPE is:6.89% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :9.45 & 25.04% & 0.90\n",
      "for 2021-07-07, MAE is:4.01 & sMAPE is:4.11% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :9.42 & 24.93% & 0.90\n",
      "for 2021-07-08, MAE is:5.62 & sMAPE is:6.08% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :9.40 & 24.83% & 0.90\n",
      "for 2021-07-09, MAE is:5.00 & sMAPE is:5.31% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :9.38 & 24.72% & 0.90\n",
      "for 2021-07-10, MAE is:7.72 & sMAPE is:8.81% & rMAE is:1.94 ||| daily mean of MAE & sMAPE & rMAE till now are :9.37 & 24.64% & 0.91\n",
      "for 2021-07-11, MAE is:9.68 & sMAPE is:11.03% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :9.37 & 24.57% & 0.91\n",
      "for 2021-07-12, MAE is:10.86 & sMAPE is:12.50% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :9.38 & 24.51% & 0.91\n",
      "for 2021-07-13, MAE is:6.98 & sMAPE is:7.60% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :9.37 & 24.42% & 0.91\n",
      "for 2021-07-14, MAE is:9.84 & sMAPE is:11.29% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :9.37 & 24.35% & 0.91\n",
      "for 2021-07-15, MAE is:10.66 & sMAPE is:12.65% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :9.38 & 24.29% & 0.91\n",
      "for 2021-07-16, MAE is:5.19 & sMAPE is:6.05% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :9.36 & 24.20% & 0.91\n",
      "for 2021-07-17, MAE is:11.92 & sMAPE is:14.11% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :9.37 & 24.15% & 0.92\n",
      "for 2021-07-18, MAE is:10.60 & sMAPE is:12.98% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :9.38 & 24.09% & 0.92\n",
      "for 2021-07-19, MAE is:7.15 & sMAPE is:7.46% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :9.37 & 24.01% & 0.92\n",
      "for 2021-07-20, MAE is:3.93 & sMAPE is:4.00% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :9.34 & 23.91% & 0.91\n",
      "for 2021-07-21, MAE is:9.02 & sMAPE is:8.88% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :9.34 & 23.84% & 0.91\n",
      "for 2021-07-22, MAE is:3.99 & sMAPE is:3.93% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :9.31 & 23.74% & 0.91\n",
      "for 2021-07-23, MAE is:10.16 & sMAPE is:10.64% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :9.31 & 23.67% & 0.91\n",
      "for 2021-07-24, MAE is:6.63 & sMAPE is:7.29% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :9.30 & 23.59% & 0.91\n",
      "for 2021-07-25, MAE is:7.03 & sMAPE is:7.63% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :9.29 & 23.52% & 0.91\n",
      "for 2021-07-26, MAE is:3.77 & sMAPE is:3.83% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :9.26 & 23.42% & 0.91\n",
      "for 2021-07-27, MAE is:4.63 & sMAPE is:4.71% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :9.24 & 23.33% & 0.91\n",
      "for 2021-07-28, MAE is:7.27 & sMAPE is:7.93% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :9.23 & 23.26% & 0.91\n",
      "for 2021-07-29, MAE is:7.53 & sMAPE is:7.93% & rMAE is:2.54 ||| daily mean of MAE & sMAPE & rMAE till now are :9.22 & 23.18% & 0.92\n",
      "for 2021-07-30, MAE is:7.63 & sMAPE is:8.43% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :9.22 & 23.11% & 0.92\n",
      "for 2021-07-31, MAE is:24.76 & sMAPE is:39.99% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :9.29 & 23.19% & 0.92\n",
      "for 2021-08-01, MAE is:12.83 & sMAPE is:17.28% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :9.31 & 23.17% & 0.92\n",
      "for 2021-08-02, MAE is:3.89 & sMAPE is:3.98% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :9.28 & 23.08% & 0.92\n",
      "for 2021-08-03, MAE is:8.35 & sMAPE is:8.20% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :9.28 & 23.01% & 0.92\n",
      "for 2021-08-04, MAE is:6.08 & sMAPE is:5.85% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :9.26 & 22.93% & 0.91\n",
      "for 2021-08-05, MAE is:9.70 & sMAPE is:9.86% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :9.26 & 22.87% & 0.92\n",
      "for 2021-08-06, MAE is:7.43 & sMAPE is:8.12% & rMAE is:2.19 ||| daily mean of MAE & sMAPE & rMAE till now are :9.26 & 22.80% & 0.92\n",
      "for 2021-08-07, MAE is:25.10 & sMAPE is:46.93% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :9.33 & 22.91% & 0.93\n",
      "for 2021-08-08, MAE is:14.59 & sMAPE is:17.84% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :9.35 & 22.89% & 0.93\n",
      "for 2021-08-09, MAE is:7.94 & sMAPE is:7.71% & rMAE is:1.78 ||| daily mean of MAE & sMAPE & rMAE till now are :9.35 & 22.82% & 0.93\n",
      "for 2021-08-10, MAE is:5.50 & sMAPE is:5.03% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :9.33 & 22.74% & 0.93\n",
      "for 2021-08-11, MAE is:5.09 & sMAPE is:4.48% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :9.31 & 22.66% & 0.93\n",
      "for 2021-08-12, MAE is:5.84 & sMAPE is:5.03% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :9.29 & 22.58% & 0.93\n",
      "for 2021-08-13, MAE is:5.67 & sMAPE is:4.90% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :9.28 & 22.50% & 0.93\n",
      "for 2021-08-14, MAE is:10.93 & sMAPE is:9.84% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :9.28 & 22.44% & 0.92\n",
      "for 2021-08-15, MAE is:11.19 & sMAPE is:10.47% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :9.29 & 22.39% & 0.92\n",
      "for 2021-08-16, MAE is:24.20 & sMAPE is:24.07% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :9.36 & 22.40% & 0.92\n",
      "for 2021-08-17, MAE is:6.67 & sMAPE is:7.17% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :9.35 & 22.33% & 0.92\n",
      "for 2021-08-18, MAE is:11.84 & sMAPE is:11.20% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :9.36 & 22.28% & 0.92\n",
      "for 2021-08-19, MAE is:7.92 & sMAPE is:7.32% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :9.35 & 22.22% & 0.92\n",
      "for 2021-08-20, MAE is:6.37 & sMAPE is:5.46% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :9.34 & 22.15% & 0.92\n",
      "for 2021-08-21, MAE is:6.75 & sMAPE is:6.25% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :9.33 & 22.08% & 0.92\n",
      "for 2021-08-22, MAE is:6.96 & sMAPE is:6.98% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :9.32 & 22.01% & 0.92\n",
      "for 2021-08-23, MAE is:9.28 & sMAPE is:9.26% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :9.32 & 21.96% & 0.92\n",
      "for 2021-08-24, MAE is:9.44 & sMAPE is:9.15% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :9.32 & 21.90% & 0.92\n",
      "for 2021-08-25, MAE is:4.87 & sMAPE is:4.25% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :9.30 & 21.83% & 0.92\n",
      "for 2021-08-26, MAE is:7.23 & sMAPE is:6.13% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :9.29 & 21.76% & 0.92\n",
      "for 2021-08-27, MAE is:5.33 & sMAPE is:4.55% & rMAE is:1.67 ||| daily mean of MAE & sMAPE & rMAE till now are :9.27 & 21.69% & 0.92\n",
      "for 2021-08-28, MAE is:13.39 & sMAPE is:12.37% & rMAE is:1.77 ||| daily mean of MAE & sMAPE & rMAE till now are :9.29 & 21.65% & 0.93\n",
      "for 2021-08-29, MAE is:11.45 & sMAPE is:10.88% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :9.30 & 21.61% & 0.93\n",
      "for 2021-08-30, MAE is:7.26 & sMAPE is:5.99% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :9.29 & 21.54% & 0.92\n",
      "for 2021-08-31, MAE is:9.13 & sMAPE is:7.30% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :9.29 & 21.49% & 0.92\n",
      "for 2021-09-01, MAE is:7.97 & sMAPE is:6.14% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :9.29 & 21.42% & 0.92\n",
      "for 2021-09-02, MAE is:9.02 & sMAPE is:6.71% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :9.28 & 21.36% & 0.92\n",
      "for 2021-09-03, MAE is:7.08 & sMAPE is:5.21% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :9.28 & 21.30% & 0.92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-09-04, MAE is:16.47 & sMAPE is:12.53% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :9.30 & 21.26% & 0.91\n",
      "for 2021-09-05, MAE is:14.79 & sMAPE is:11.70% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :9.33 & 21.22% & 0.91\n",
      "for 2021-09-06, MAE is:14.20 & sMAPE is:10.60% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :9.35 & 21.18% & 0.91\n",
      "for 2021-09-07, MAE is:13.40 & sMAPE is:10.55% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :9.36 & 21.14% & 0.91\n",
      "for 2021-09-08, MAE is:8.95 & sMAPE is:6.66% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :9.36 & 21.08% & 0.92\n",
      "for 2021-09-09, MAE is:5.89 & sMAPE is:4.17% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :9.35 & 21.01% & 0.91\n",
      "for 2021-09-10, MAE is:9.41 & sMAPE is:6.40% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :9.35 & 20.96% & 0.91\n",
      "for 2021-09-11, MAE is:10.91 & sMAPE is:7.47% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :9.35 & 20.90% & 0.91\n",
      "for 2021-09-12, MAE is:18.49 & sMAPE is:13.20% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :9.39 & 20.87% & 0.91\n",
      "for 2021-09-13, MAE is:7.15 & sMAPE is:4.71% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :9.38 & 20.81% & 0.91\n",
      "for 2021-09-14, MAE is:13.84 & sMAPE is:9.42% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :9.40 & 20.76% & 0.91\n",
      "for 2021-09-15, MAE is:12.85 & sMAPE is:7.73% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :9.41 & 20.71% & 0.91\n",
      "for 2021-09-16, MAE is:24.87 & sMAPE is:14.15% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :9.47 & 20.69% & 0.91\n",
      "for 2021-09-17, MAE is:23.84 & sMAPE is:13.69% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :9.53 & 20.66% & 0.91\n",
      "for 2021-09-18, MAE is:18.94 & sMAPE is:12.15% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :9.56 & 20.63% & 0.91\n",
      "for 2021-09-19, MAE is:15.00 & sMAPE is:9.64% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :9.58 & 20.59% & 0.91\n",
      "for 2021-09-20, MAE is:20.08 & sMAPE is:12.50% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :9.62 & 20.56% & 0.92\n",
      "for 2021-09-21, MAE is:16.34 & sMAPE is:10.71% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :9.65 & 20.52% & 0.92\n",
      "for 2021-09-22, MAE is:24.77 & sMAPE is:15.03% & rMAE is:2.36 ||| daily mean of MAE & sMAPE & rMAE till now are :9.71 & 20.50% & 0.92\n",
      "for 2021-09-23, MAE is:21.48 & sMAPE is:12.90% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :9.75 & 20.47% & 0.92\n",
      "for 2021-09-24, MAE is:6.40 & sMAPE is:3.78% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :9.74 & 20.41% & 0.92\n",
      "for 2021-09-25, MAE is:15.19 & sMAPE is:9.37% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :9.76 & 20.37% & 0.92\n",
      "for 2021-09-26, MAE is:17.50 & sMAPE is:10.89% & rMAE is:1.82 ||| daily mean of MAE & sMAPE & rMAE till now are :9.79 & 20.33% & 0.93\n",
      "for 2021-09-27, MAE is:11.11 & sMAPE is:6.61% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :9.79 & 20.28% & 0.92\n",
      "for 2021-09-28, MAE is:11.90 & sMAPE is:6.72% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :9.80 & 20.23% & 0.92\n",
      "for 2021-09-29, MAE is:18.50 & sMAPE is:10.24% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :9.83 & 20.19% & 0.92\n",
      "for 2021-09-30, MAE is:18.17 & sMAPE is:9.86% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :9.86 & 20.16% & 0.92\n",
      "for 2021-10-01, MAE is:16.14 & sMAPE is:7.73% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :9.88 & 20.11% & 0.92\n",
      "for 2021-10-02, MAE is:45.62 & sMAPE is:28.27% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :10.01 & 20.14% & 0.92\n",
      "for 2021-10-03, MAE is:36.82 & sMAPE is:37.22% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :10.11 & 20.20% & 0.92\n",
      "for 2021-10-04, MAE is:37.08 & sMAPE is:21.84% & rMAE is:1.79 ||| daily mean of MAE & sMAPE & rMAE till now are :10.21 & 20.21% & 0.92\n",
      "for 2021-10-05, MAE is:27.23 & sMAPE is:13.28% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :10.27 & 20.18% & 0.92\n",
      "for 2021-10-06, MAE is:19.41 & sMAPE is:8.65% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :10.30 & 20.14% & 0.92\n",
      "for 2021-10-07, MAE is:55.30 & sMAPE is:21.01% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :10.46 & 20.14% & 0.92\n",
      "for 2021-10-08, MAE is:62.20 & sMAPE is:24.67% & rMAE is:2.79 ||| daily mean of MAE & sMAPE & rMAE till now are :10.65 & 20.16% & 0.93\n",
      "for 2021-10-09, MAE is:18.46 & sMAPE is:8.33% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :10.68 & 20.12% & 0.93\n",
      "for 2021-10-10, MAE is:36.11 & sMAPE is:19.65% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :10.77 & 20.12% & 0.92\n",
      "for 2021-10-11, MAE is:32.67 & sMAPE is:17.90% & rMAE is:3.00 ||| daily mean of MAE & sMAPE & rMAE till now are :10.84 & 20.11% & 0.93\n",
      "for 2021-10-12, MAE is:15.20 & sMAPE is:8.24% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :10.86 & 20.07% & 0.93\n",
      "for 2021-10-13, MAE is:24.82 & sMAPE is:13.43% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :10.91 & 20.04% & 0.93\n",
      "for 2021-10-14, MAE is:21.25 & sMAPE is:10.13% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :10.94 & 20.01% & 0.93\n",
      "for 2021-10-15, MAE is:15.85 & sMAPE is:6.87% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :10.96 & 19.96% & 0.93\n",
      "for 2021-10-16, MAE is:15.40 & sMAPE is:6.82% & rMAE is:2.40 ||| daily mean of MAE & sMAPE & rMAE till now are :10.97 & 19.92% & 0.93\n",
      "for 2021-10-17, MAE is:18.72 & sMAPE is:8.59% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :11.00 & 19.88% & 0.93\n",
      "for 2021-10-18, MAE is:20.92 & sMAPE is:9.09% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :11.04 & 19.84% & 0.93\n",
      "for 2021-10-19, MAE is:26.76 & sMAPE is:12.66% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :11.09 & 19.82% & 0.93\n",
      "for 2021-10-20, MAE is:28.65 & sMAPE is:14.26% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :11.15 & 19.80% & 0.93\n",
      "for 2021-10-21, MAE is:18.93 & sMAPE is:9.21% & rMAE is:2.10 ||| daily mean of MAE & sMAPE & rMAE till now are :11.18 & 19.76% & 0.94\n",
      "for 2021-10-22, MAE is:21.32 & sMAPE is:10.37% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :11.21 & 19.73% & 0.94\n",
      "for 2021-10-23, MAE is:18.99 & sMAPE is:8.97% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :11.24 & 19.69% & 0.94\n",
      "for 2021-10-24, MAE is:20.51 & sMAPE is:9.54% & rMAE is:2.00 ||| daily mean of MAE & sMAPE & rMAE till now are :11.27 & 19.66% & 0.94\n",
      "for 2021-10-25, MAE is:14.96 & sMAPE is:6.59% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :11.28 & 19.62% & 0.94\n",
      "for 2021-10-26, MAE is:24.02 & sMAPE is:11.08% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :11.32 & 19.59% & 0.94\n",
      "for 2021-10-27, MAE is:21.84 & sMAPE is:9.95% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :11.36 & 19.56% & 0.94\n",
      "for 2021-10-28, MAE is:22.06 & sMAPE is:10.67% & rMAE is:2.51 ||| daily mean of MAE & sMAPE & rMAE till now are :11.39 & 19.53% & 0.95\n",
      "for 2021-10-29, MAE is:18.99 & sMAPE is:11.02% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :11.42 & 19.50% & 0.95\n",
      "for 2021-10-30, MAE is:41.26 & sMAPE is:32.97% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :11.52 & 19.54% & 0.95\n",
      "for 2021-10-31, MAE is:59.88 & sMAPE is:58.68% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :11.68 & 19.67% & 0.94\n",
      "for 2021-11-01, MAE is:37.70 & sMAPE is:43.83% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :11.76 & 19.75% & 0.94\n",
      "for 2021-11-02, MAE is:26.10 & sMAPE is:18.25% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :11.81 & 19.75% & 0.94\n",
      "for 2021-11-03, MAE is:27.89 & sMAPE is:17.60% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :11.86 & 19.74% & 0.94\n",
      "for 2021-11-04, MAE is:20.27 & sMAPE is:12.43% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :11.89 & 19.72% & 0.94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-11-05, MAE is:18.43 & sMAPE is:10.80% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :11.91 & 19.69% & 0.94\n",
      "for 2021-11-06, MAE is:21.44 & sMAPE is:13.35% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :11.94 & 19.67% & 0.94\n",
      "for 2021-11-07, MAE is:33.77 & sMAPE is:26.06% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :12.01 & 19.69% & 0.94\n",
      "for 2021-11-08, MAE is:18.55 & sMAPE is:11.12% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :12.03 & 19.66% & 0.93\n",
      "for 2021-11-09, MAE is:17.00 & sMAPE is:9.51% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :12.05 & 19.63% & 0.93\n",
      "for 2021-11-10, MAE is:14.48 & sMAPE is:7.26% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :12.05 & 19.59% & 0.93\n",
      "for 2021-11-11, MAE is:20.30 & sMAPE is:10.80% & rMAE is:1.62 ||| daily mean of MAE & sMAPE & rMAE till now are :12.08 & 19.56% & 0.93\n",
      "for 2021-11-12, MAE is:10.12 & sMAPE is:5.44% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :12.07 & 19.51% & 0.93\n",
      "for 2021-11-13, MAE is:15.97 & sMAPE is:8.84% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :12.09 & 19.48% & 0.93\n",
      "for 2021-11-14, MAE is:12.11 & sMAPE is:6.91% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :12.09 & 19.44% & 0.93\n",
      "for 2021-11-15, MAE is:24.42 & sMAPE is:13.54% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :12.13 & 19.42% & 0.93\n",
      "for 2021-11-16, MAE is:17.98 & sMAPE is:9.13% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :12.14 & 19.39% & 0.93\n",
      "for 2021-11-17, MAE is:21.41 & sMAPE is:10.86% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :12.17 & 19.36% & 0.93\n",
      "for 2021-11-18, MAE is:25.71 & sMAPE is:11.66% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :12.21 & 19.34% & 0.93\n",
      "for 2021-11-19, MAE is:15.62 & sMAPE is:6.75% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :12.23 & 19.30% & 0.93\n",
      "for 2021-11-20, MAE is:18.22 & sMAPE is:8.28% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :12.24 & 19.27% & 0.93\n",
      "for 2021-11-21, MAE is:17.35 & sMAPE is:7.56% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :12.26 & 19.23% & 0.93\n",
      "for 2021-11-22, MAE is:25.57 & sMAPE is:11.19% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :12.30 & 19.21% & 0.93\n",
      "for 2021-11-23, MAE is:16.15 & sMAPE is:6.97% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :12.31 & 19.17% & 0.92\n",
      "for 2021-11-24, MAE is:17.80 & sMAPE is:7.82% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :12.33 & 19.13% & 0.92\n",
      "for 2021-11-25, MAE is:22.48 & sMAPE is:10.30% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :12.36 & 19.11% & 0.93\n",
      "for 2021-11-26, MAE is:14.78 & sMAPE is:6.70% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :12.37 & 19.07% & 0.93\n",
      "for 2021-11-27, MAE is:24.40 & sMAPE is:11.78% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :12.40 & 19.05% & 0.93\n",
      "for 2021-11-28, MAE is:16.43 & sMAPE is:7.97% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :12.42 & 19.01% & 0.93\n",
      "for 2021-11-29, MAE is:32.82 & sMAPE is:17.00% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :12.48 & 19.01% & 0.93\n",
      "for 2021-11-30, MAE is:38.12 & sMAPE is:14.61% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :12.55 & 19.00% & 0.93\n",
      "for 2021-12-01, MAE is:22.12 & sMAPE is:8.92% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :12.58 & 18.97% & 0.93\n",
      "for 2021-12-02, MAE is:25.57 & sMAPE is:11.50% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :12.62 & 18.94% & 0.93\n",
      "for 2021-12-03, MAE is:27.07 & sMAPE is:11.77% & rMAE is:2.22 ||| daily mean of MAE & sMAPE & rMAE till now are :12.66 & 18.92% & 0.93\n",
      "for 2021-12-04, MAE is:9.82 & sMAPE is:4.47% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :12.66 & 18.88% & 0.93\n",
      "for 2021-12-05, MAE is:118.81 & sMAPE is:97.73% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :12.97 & 19.11% & 0.93\n",
      "for 2021-12-06, MAE is:19.76 & sMAPE is:9.29% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :12.99 & 19.08% & 0.93\n",
      "for 2021-12-07, MAE is:23.02 & sMAPE is:10.49% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :13.02 & 19.06% & 0.93\n",
      "for 2021-12-08, MAE is:92.91 & sMAPE is:78.30% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :13.25 & 19.23% & 0.93\n",
      "for 2021-12-09, MAE is:27.10 & sMAPE is:13.09% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :13.29 & 19.21% & 0.93\n",
      "for 2021-12-10, MAE is:34.19 & sMAPE is:18.12% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :13.35 & 19.21% & 0.93\n",
      "for 2021-12-11, MAE is:26.71 & sMAPE is:11.11% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :13.39 & 19.19% & 0.93\n",
      "for 2021-12-12, MAE is:17.66 & sMAPE is:6.83% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :13.40 & 19.15% & 0.93\n",
      "for 2021-12-13, MAE is:22.05 & sMAPE is:8.27% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :13.43 & 19.12% & 0.93\n",
      "for 2021-12-14, MAE is:23.15 & sMAPE is:8.26% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :13.46 & 19.09% & 0.92\n",
      "for 2021-12-15, MAE is:29.64 & sMAPE is:10.67% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :13.50 & 19.06% & 0.92\n",
      "for 2021-12-16, MAE is:29.82 & sMAPE is:10.10% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :13.55 & 19.04% & 0.92\n",
      "for 2021-12-17, MAE is:28.49 & sMAPE is:9.43% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :13.59 & 19.01% & 0.92\n",
      "for 2021-12-18, MAE is:20.50 & sMAPE is:6.83% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :13.61 & 18.98% & 0.92\n",
      "for 2021-12-19, MAE is:23.20 & sMAPE is:7.49% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :13.64 & 18.94% & 0.92\n",
      "for 2021-12-20, MAE is:33.17 & sMAPE is:10.03% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :13.69 & 18.92% & 0.91\n",
      "for 2021-12-21, MAE is:17.92 & sMAPE is:5.52% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :13.71 & 18.88% & 0.91\n",
      "for 2021-12-22, MAE is:38.92 & sMAPE is:11.44% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :13.78 & 18.86% & 0.91\n",
      "for 2021-12-23, MAE is:46.40 & sMAPE is:12.74% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :13.87 & 18.84% & 0.91\n",
      "for 2021-12-24, MAE is:60.55 & sMAPE is:18.04% & rMAE is:3.50 ||| daily mean of MAE & sMAPE & rMAE till now are :14.00 & 18.84% & 0.92\n",
      "for 2021-12-25, MAE is:50.34 & sMAPE is:22.39% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :14.10 & 18.85% & 0.92\n",
      "for 2021-12-26, MAE is:71.98 & sMAPE is:32.90% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :14.26 & 18.89% & 0.92\n",
      "for 2021-12-27, MAE is:91.88 & sMAPE is:83.36% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :14.48 & 19.07% & 0.92\n",
      "for 2021-12-28, MAE is:29.03 & sMAPE is:39.31% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :14.52 & 19.12% & 0.91\n",
      "for 2021-12-29, MAE is:48.97 & sMAPE is:29.19% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :14.61 & 19.15% & 0.91\n",
      "for 2021-12-30, MAE is:19.16 & sMAPE is:9.24% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :14.62 & 19.12% & 0.91\n",
      "for 2021-12-31, MAE is:63.25 & sMAPE is:37.71% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :14.76 & 19.18% & 0.91\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\1 - Consolidated Data\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:02:32,584]\u001b[0m A new study created in RDB with name: PT_2022\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:02:48,082]\u001b[0m Trial 1 finished with value: 58.02427654075779 and parameters: {'n_hidden': 3, 'learning_rate': 0.004534535065380906, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.028301357872422318, 'dropout_rate_Layer_2': 0.1940504590444535, 'dropout_rate_Layer_3': 0.07807617946487261, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010785436660569857, 'l1_Layer_2': 0.00014942945310652183, 'l1_Layer_3': 0.00366805366637282, 'n_units_Layer_1': 85, 'n_units_Layer_2': 240, 'n_units_Layer_3': 300}. Best is trial 1 with value: 58.02427654075779.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 58.02 | sMAPE for Validation Set is: 55.28% | rMAE for Validation Set is: 2.33\n",
      "MAE for Test Set is: 104.80 | sMAPE for Test Set is: 83.64% | rMAE for Test Set is: 2.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:02:50,767]\u001b[0m Trial 0 finished with value: 55.06026444298373 and parameters: {'n_hidden': 3, 'learning_rate': 0.05855838980562904, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06538497953201454, 'dropout_rate_Layer_2': 0.0032747455728136202, 'dropout_rate_Layer_3': 0.20654101276129022, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.221535734068891e-05, 'l1_Layer_2': 0.016217111166318805, 'l1_Layer_3': 7.167791585322746e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 170, 'n_units_Layer_3': 185}. Best is trial 0 with value: 55.06026444298373.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.06 | sMAPE for Validation Set is: 51.59% | rMAE for Validation Set is: 2.21\n",
      "MAE for Test Set is: 100.74 | sMAPE for Test Set is: 78.96% | rMAE for Test Set is: 2.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:02:53,691]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:02:56,270]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:03:01,273]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:03:05,878]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:03:06,284]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:03:12,728]\u001b[0m Trial 3 finished with value: 65.8560926106167 and parameters: {'n_hidden': 3, 'learning_rate': 0.052919661971384056, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2451944629032398, 'dropout_rate_Layer_2': 0.06797901660010273, 'dropout_rate_Layer_3': 0.11858344491484903, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0001854716927121598, 'l1_Layer_2': 0.017006348196330928, 'l1_Layer_3': 0.0005738671223055996, 'n_units_Layer_1': 125, 'n_units_Layer_2': 60, 'n_units_Layer_3': 225}. Best is trial 0 with value: 55.06026444298373.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 65.86 | sMAPE for Validation Set is: 66.41% | rMAE for Validation Set is: 2.65\n",
      "MAE for Test Set is: 115.38 | sMAPE for Test Set is: 97.31% | rMAE for Test Set is: 2.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:03:13,274]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:03:16,802]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.75 | sMAPE for Validation Set is: 55.18% | rMAE for Validation Set is: 2.32\n",
      "MAE for Test Set is: 103.88 | sMAPE for Test Set is: 82.64% | rMAE for Test Set is: 2.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:03:19,076]\u001b[0m Trial 2 finished with value: 57.75350646381715 and parameters: {'n_hidden': 3, 'learning_rate': 0.026197403919275372, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3738053003939905, 'dropout_rate_Layer_2': 0.2351684474232295, 'dropout_rate_Layer_3': 0.29023643799875815, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.024998898008058358, 'l1_Layer_2': 0.0006533375561465756, 'l1_Layer_3': 0.011472734010695984, 'n_units_Layer_1': 60, 'n_units_Layer_2': 235, 'n_units_Layer_3': 185}. Best is trial 0 with value: 55.06026444298373.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:03:20,456]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:03:21,921]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:03:22,819]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:03:25,129]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:03:26,037]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:03:30,518]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:03:33,970]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:03:38,487]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:03:41,315]\u001b[0m Trial 19 finished with value: 64.25964860926793 and parameters: {'n_hidden': 3, 'learning_rate': 0.09291479691784472, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2528449187299481, 'dropout_rate_Layer_2': 0.3691185281680751, 'dropout_rate_Layer_3': 0.2984577033851945, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 2.7386279282680622e-05, 'l1_Layer_2': 0.003612480722063384, 'l1_Layer_3': 0.0001733732591412715, 'n_units_Layer_1': 215, 'n_units_Layer_2': 160, 'n_units_Layer_3': 105}. Best is trial 0 with value: 55.06026444298373.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 64.26 | sMAPE for Validation Set is: 63.89% | rMAE for Validation Set is: 2.58\n",
      "MAE for Test Set is: 111.26 | sMAPE for Test Set is: 91.52% | rMAE for Test Set is: 2.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:03:46,122]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:03:49,166]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:03:49,987]\u001b[0m Trial 20 finished with value: 14.35814209182835 and parameters: {'n_hidden': 3, 'learning_rate': 0.02548766313465437, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39578272210237925, 'dropout_rate_Layer_2': 0.16609328142794746, 'dropout_rate_Layer_3': 0.38723390143226977, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2432511957547623e-05, 'l1_Layer_2': 0.07170687860840683, 'l1_Layer_3': 1.0134520820526717e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 300, 'n_units_Layer_3': 80}. Best is trial 20 with value: 14.35814209182835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.36 | sMAPE for Validation Set is: 19.12% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 28.08 | sMAPE for Test Set is: 20.07% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:03:55,238]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:03:55,615]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:04:01,934]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:04:07,134]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:04:10,499]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:04:13,923]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:04:17,088]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:04:18,872]\u001b[0m Trial 18 finished with value: 60.833878245054 and parameters: {'n_hidden': 3, 'learning_rate': 0.015704863586316713, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24774033448458446, 'dropout_rate_Layer_2': 0.18826557833411017, 'dropout_rate_Layer_3': 0.02476558141565932, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.002260953232623735, 'l1_Layer_2': 2.9878659419706682e-05, 'l1_Layer_3': 1.135649668658007e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 55, 'n_units_Layer_3': 210}. Best is trial 20 with value: 14.35814209182835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 60.83 | sMAPE for Validation Set is: 58.88% | rMAE for Validation Set is: 2.45\n",
      "MAE for Test Set is: 106.87 | sMAPE for Test Set is: 85.83% | rMAE for Test Set is: 2.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:04:21,148]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:04:24,452]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:04:33,478]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:04:34,596]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:04:40,671]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:04:43,743]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:04:46,446]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:04:49,862]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:04:51,277]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:04:56,066]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:05:08,448]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:05:11,821]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:05:14,371]\u001b[0m Trial 44 finished with value: 14.609941884183792 and parameters: {'n_hidden': 3, 'learning_rate': 0.0176105688195834, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3815305644010526, 'dropout_rate_Layer_2': 0.21578132246391155, 'dropout_rate_Layer_3': 0.3516350025471205, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.776967866953252e-05, 'l1_Layer_2': 0.08993516150228546, 'l1_Layer_3': 2.1232097309981544e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 160, 'n_units_Layer_3': 105}. Best is trial 20 with value: 14.35814209182835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.61 | sMAPE for Validation Set is: 19.12% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 27.30 | sMAPE for Test Set is: 19.76% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:05:14,861]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:05:19,067]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:05:22,005]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:05:22,502]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:05:25,370]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:05:26,735]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:05:27,665]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:05:34,537]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:05:38,904]\u001b[0m Trial 23 finished with value: 56.17522711705008 and parameters: {'n_hidden': 3, 'learning_rate': 0.010865199525925668, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05963884920216933, 'dropout_rate_Layer_2': 0.1594204230952424, 'dropout_rate_Layer_3': 0.31229947069793673, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00014772800077526442, 'l1_Layer_2': 2.6148030420797118e-05, 'l1_Layer_3': 0.0014969227072957677, 'n_units_Layer_1': 100, 'n_units_Layer_2': 240, 'n_units_Layer_3': 150}. Best is trial 20 with value: 14.35814209182835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.18 | sMAPE for Validation Set is: 53.13% | rMAE for Validation Set is: 2.26\n",
      "MAE for Test Set is: 102.00 | sMAPE for Test Set is: 80.32% | rMAE for Test Set is: 2.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:05:43,395]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:05:45,268]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:05:51,864]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:05:55,017]\u001b[0m Trial 58 finished with value: 71.5782126226372 and parameters: {'n_hidden': 4, 'learning_rate': 0.036637541319947495, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15434561409061295, 'dropout_rate_Layer_2': 0.2599989612594581, 'dropout_rate_Layer_3': 0.027500785089924484, 'dropout_rate_Layer_4': 0.36998448495713937, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 1.553081174212958e-05, 'l1_Layer_2': 1.0736691982110325e-05, 'l1_Layer_3': 0.014276959754683922, 'l1_Layer_4': 0.0006751257332223702, 'n_units_Layer_1': 50, 'n_units_Layer_2': 170, 'n_units_Layer_3': 60, 'n_units_Layer_4': 65}. Best is trial 20 with value: 14.35814209182835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 71.58 | sMAPE for Validation Set is: 75.61% | rMAE for Validation Set is: 2.88\n",
      "MAE for Test Set is: 121.97 | sMAPE for Test Set is: 106.65% | rMAE for Test Set is: 3.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:05:56,805]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:05:57,701]\u001b[0m Trial 52 finished with value: 53.61499638393826 and parameters: {'n_hidden': 3, 'learning_rate': 0.06937195318703403, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.056189430155432256, 'dropout_rate_Layer_2': 0.17255281803748282, 'dropout_rate_Layer_3': 0.12545103775613403, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.0165901841169777e-05, 'l1_Layer_2': 0.008974068571252554, 'l1_Layer_3': 0.0854101940027945, 'n_units_Layer_1': 205, 'n_units_Layer_2': 135, 'n_units_Layer_3': 205}. Best is trial 20 with value: 14.35814209182835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.61 | sMAPE for Validation Set is: 50.12% | rMAE for Validation Set is: 2.16\n",
      "MAE for Test Set is: 98.37 | sMAPE for Test Set is: 76.15% | rMAE for Test Set is: 2.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:05:57,816]\u001b[0m Trial 53 finished with value: 62.025760094333634 and parameters: {'n_hidden': 4, 'learning_rate': 0.06844201554305009, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28725120623412503, 'dropout_rate_Layer_2': 0.14307896444760315, 'dropout_rate_Layer_3': 0.1386649279005542, 'dropout_rate_Layer_4': 0.3826917679759204, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0037039876322649203, 'l1_Layer_2': 0.006813106118844085, 'l1_Layer_3': 0.0058618317752951645, 'l1_Layer_4': 0.00030794280489376136, 'n_units_Layer_1': 70, 'n_units_Layer_2': 125, 'n_units_Layer_3': 200, 'n_units_Layer_4': 250}. Best is trial 20 with value: 14.35814209182835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 62.03 | sMAPE for Validation Set is: 60.78% | rMAE for Validation Set is: 2.49\n",
      "MAE for Test Set is: 110.61 | sMAPE for Test Set is: 90.89% | rMAE for Test Set is: 2.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:06:00,130]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:06:07,090]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:06:07,543]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:06:09,408]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:06:16,226]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:06:17,455]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:06:19,490]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:06:20,445]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:06:22,062]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:06:28,331]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:06:32,476]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:06:37,834]\u001b[0m Trial 70 finished with value: 59.09468454799617 and parameters: {'n_hidden': 3, 'learning_rate': 0.09962922228920423, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.011059132577620173, 'dropout_rate_Layer_2': 0.004539017477567214, 'dropout_rate_Layer_3': 0.31947859729982214, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.010297337449657912, 'l1_Layer_2': 0.0003507579633688471, 'l1_Layer_3': 0.00013463242629118088, 'n_units_Layer_1': 140, 'n_units_Layer_2': 215, 'n_units_Layer_3': 160}. Best is trial 20 with value: 14.35814209182835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 59.09 | sMAPE for Validation Set is: 57.12% | rMAE for Validation Set is: 2.38\n",
      "MAE for Test Set is: 105.97 | sMAPE for Test Set is: 85.22% | rMAE for Test Set is: 2.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:06:38,081]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:06:38,668]\u001b[0m Trial 62 finished with value: 57.817059797665706 and parameters: {'n_hidden': 3, 'learning_rate': 0.09601706366284238, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01656672440531958, 'dropout_rate_Layer_2': 0.2542563146477913, 'dropout_rate_Layer_3': 0.23048857143672663, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.319331903729891e-05, 'l1_Layer_2': 0.09768905177436193, 'l1_Layer_3': 0.06641720057031737, 'n_units_Layer_1': 300, 'n_units_Layer_2': 130, 'n_units_Layer_3': 190}. Best is trial 20 with value: 14.35814209182835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.82 | sMAPE for Validation Set is: 55.97% | rMAE for Validation Set is: 2.33\n",
      "MAE for Test Set is: 103.99 | sMAPE for Test Set is: 82.62% | rMAE for Test Set is: 2.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:06:42,758]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:06:47,331]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:06:47,856]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:06:49,657]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:06:51,777]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:06:53,348]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:06:58,436]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:06:58,863]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:06:59,266]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:07:03,161]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:07:05,156]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:07:09,312]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:07:10,977]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:07:12,354]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:07:15,190]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:07:19,494]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:07:27,801]\u001b[0m Trial 91 finished with value: 16.481709403506372 and parameters: {'n_hidden': 3, 'learning_rate': 0.02867757495650504, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.000958103299460257, 'dropout_rate_Layer_2': 0.003449747670942027, 'dropout_rate_Layer_3': 0.3993176280565658, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1366334037872657e-05, 'l1_Layer_2': 0.0001608713451353605, 'l1_Layer_3': 0.02448547166994945, 'n_units_Layer_1': 275, 'n_units_Layer_2': 215, 'n_units_Layer_3': 165}. Best is trial 20 with value: 14.35814209182835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.48 | sMAPE for Validation Set is: 20.51% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 30.77 | sMAPE for Test Set is: 21.61% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:07:32,290]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:07:34,962]\u001b[0m Trial 93 finished with value: 17.224914688429127 and parameters: {'n_hidden': 3, 'learning_rate': 0.04004611883679354, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.005697102486183901, 'dropout_rate_Layer_2': 0.00196872334885298, 'dropout_rate_Layer_3': 0.38174725063964343, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0562476564440486e-05, 'l1_Layer_2': 0.00019451362763477802, 'l1_Layer_3': 0.011361756113844929, 'n_units_Layer_1': 260, 'n_units_Layer_2': 215, 'n_units_Layer_3': 155}. Best is trial 20 with value: 14.35814209182835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.22 | sMAPE for Validation Set is: 21.00% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 29.98 | sMAPE for Test Set is: 21.31% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:07:37,464]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:07:39,882]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:07:41,090]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:07:42,542]\u001b[0m Trial 89 finished with value: 14.300176523773752 and parameters: {'n_hidden': 3, 'learning_rate': 0.006034114385284754, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11719449604057726, 'dropout_rate_Layer_2': 0.18296306218817251, 'dropout_rate_Layer_3': 0.3130758706382244, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.584557265759737e-05, 'l1_Layer_2': 0.0103517370303634, 'l1_Layer_3': 1.0245478829628379e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 140, 'n_units_Layer_3': 275}. Best is trial 89 with value: 14.300176523773752.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.30 | sMAPE for Validation Set is: 18.48% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 30.32 | sMAPE for Test Set is: 20.98% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:07:44,974]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:07:46,950]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:07:49,580]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:07:52,133]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:07:55,217]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.10 | sMAPE for Validation Set is: 46.73% | rMAE for Validation Set is: 1.89\n",
      "MAE for Test Set is: 64.47 | sMAPE for Test Set is: 43.29% | rMAE for Test Set is: 1.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:07:56,665]\u001b[0m Trial 99 finished with value: 47.10492387718148 and parameters: {'n_hidden': 3, 'learning_rate': 0.018857076476529958, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09042130046065897, 'dropout_rate_Layer_2': 0.1117631983871886, 'dropout_rate_Layer_3': 0.031482373038559885, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003770923460827504, 'l1_Layer_2': 7.91146000545279e-05, 'l1_Layer_3': 0.0043100887724394875, 'n_units_Layer_1': 150, 'n_units_Layer_2': 195, 'n_units_Layer_3': 295}. Best is trial 89 with value: 14.300176523773752.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:07:57,755]\u001b[0m Trial 102 finished with value: 16.991428385242624 and parameters: {'n_hidden': 3, 'learning_rate': 0.0047206848590196256, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0326488990481092, 'dropout_rate_Layer_2': 0.11329483414709235, 'dropout_rate_Layer_3': 0.35359495587204054, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.37064645816395e-05, 'l1_Layer_2': 2.1001007158319105e-05, 'l1_Layer_3': 1.3324897223591814e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 80, 'n_units_Layer_3': 155}. Best is trial 89 with value: 14.300176523773752.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.99 | sMAPE for Validation Set is: 20.93% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 32.44 | sMAPE for Test Set is: 21.98% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:07:58,522]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:08:05,469]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:08:05,532]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:08:10,088]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:08:10,257]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:08:14,428]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:08:14,683]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:08:15,240]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:08:19,838]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:08:25,578]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:08:28,125]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:08:30,705]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:08:35,582]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:08:37,462]\u001b[0m Trial 115 finished with value: 14.599311079113178 and parameters: {'n_hidden': 3, 'learning_rate': 0.006683603230942278, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04015172215978444, 'dropout_rate_Layer_2': 0.13937826694355493, 'dropout_rate_Layer_3': 0.3404448858065766, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00016998912105997007, 'l1_Layer_2': 0.06973132392132372, 'l1_Layer_3': 0.0006236243917303317, 'n_units_Layer_1': 215, 'n_units_Layer_2': 85, 'n_units_Layer_3': 160}. Best is trial 89 with value: 14.300176523773752.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.60 | sMAPE for Validation Set is: 19.03% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 27.97 | sMAPE for Test Set is: 20.16% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:08:40,025]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:08:42,701]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:08:45,720]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:08:45,954]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:08:50,618]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:09:24,910]\u001b[0m Trial 124 finished with value: 49.77157181500945 and parameters: {'n_hidden': 4, 'learning_rate': 0.004023573648580339, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2680553944588463, 'dropout_rate_Layer_2': 0.22864396735203107, 'dropout_rate_Layer_3': 0.07777035712308554, 'dropout_rate_Layer_4': 0.38432146011272517, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.002401771032416482, 'l1_Layer_2': 0.0005727190106108584, 'l1_Layer_3': 0.058785936976318974, 'l1_Layer_4': 4.5550772592108056e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 70, 'n_units_Layer_3': 170, 'n_units_Layer_4': 300}. Best is trial 89 with value: 14.300176523773752.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.77 | sMAPE for Validation Set is: 45.80% | rMAE for Validation Set is: 2.00\n",
      "MAE for Test Set is: 90.60 | sMAPE for Test Set is: 67.85% | rMAE for Test Set is: 2.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:09:30,692]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:09:33,955]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:09:38,251]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:09:40,964]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:09:42,963]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:09:46,460]\u001b[0m Trial 118 finished with value: 47.589228761825474 and parameters: {'n_hidden': 3, 'learning_rate': 0.02640519732737972, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12992429316997064, 'dropout_rate_Layer_2': 0.00616326945013963, 'dropout_rate_Layer_3': 0.3024416361271199, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.02083266266354922, 'l1_Layer_2': 4.799490225096359e-05, 'l1_Layer_3': 0.0013074771088093702, 'n_units_Layer_1': 295, 'n_units_Layer_2': 55, 'n_units_Layer_3': 150}. Best is trial 89 with value: 14.300176523773752.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.59 | sMAPE for Validation Set is: 43.12% | rMAE for Validation Set is: 1.91\n",
      "MAE for Test Set is: 87.43 | sMAPE for Test Set is: 64.15% | rMAE for Test Set is: 2.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:09:48,780]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:09:51,405]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:09:53,020]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:09:53,391]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:09:57,568]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:09:59,892]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:10:00,450]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:10:07,161]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:10:09,574]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:10:12,347]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:10:13,031]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:10:16,996]\u001b[0m Trial 135 finished with value: 14.411641279803085 and parameters: {'n_hidden': 3, 'learning_rate': 0.011403571059867836, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12947704878153748, 'dropout_rate_Layer_2': 0.026670047136026803, 'dropout_rate_Layer_3': 0.3178493293137565, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002979424947064618, 'l1_Layer_2': 0.015326921631844303, 'l1_Layer_3': 4.731524770047611e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 285, 'n_units_Layer_3': 160}. Best is trial 89 with value: 14.300176523773752.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.41 | sMAPE for Validation Set is: 18.75% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 28.72 | sMAPE for Test Set is: 20.42% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:10:20,362]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:10:20,693]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:10:21,054]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:10:26,746]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:10:26,965]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:10:27,868]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:10:33,210]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:10:35,314]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:10:37,893]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:10:38,169]\u001b[0m Trial 139 finished with value: 15.907019326400212 and parameters: {'n_hidden': 3, 'learning_rate': 0.004974148578180234, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006662042144534489, 'dropout_rate_Layer_2': 0.05275490024095577, 'dropout_rate_Layer_3': 0.3540100722559998, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.09999103874371228, 'l1_Layer_2': 0.000838993611099931, 'l1_Layer_3': 1.266995277519697e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 110, 'n_units_Layer_3': 145}. Best is trial 89 with value: 14.300176523773752.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.91 | sMAPE for Validation Set is: 20.01% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 31.88 | sMAPE for Test Set is: 21.83% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:10:42,026]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:10:42,696]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:10:45,897]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:10:46,734]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:10:52,362]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:10:52,563]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:10:56,871]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:10:57,183]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:10:57,296]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:11:03,781]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:11:05,650]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:11:09,207]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:11:09,498]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:11:14,776]\u001b[0m Trial 152 finished with value: 54.404704385145635 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015359316756816078, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36058144841259043, 'dropout_rate_Layer_2': 0.07650096579159867, 'dropout_rate_Layer_3': 0.13075313743650105, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0005740880450377214, 'l1_Layer_2': 7.284799349086896e-05, 'l1_Layer_3': 0.0001300077877809062, 'n_units_Layer_1': 230, 'n_units_Layer_2': 95, 'n_units_Layer_3': 125}. Best is trial 89 with value: 14.300176523773752.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.40 | sMAPE for Validation Set is: 50.86% | rMAE for Validation Set is: 2.19\n",
      "MAE for Test Set is: 99.59 | sMAPE for Test Set is: 77.52% | rMAE for Test Set is: 2.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:11:19,234]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:11:31,989]\u001b[0m Trial 167 finished with value: 14.224461736845848 and parameters: {'n_hidden': 3, 'learning_rate': 0.005231840718900674, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22410725953294627, 'dropout_rate_Layer_2': 0.0004046946649753358, 'dropout_rate_Layer_3': 0.35759671619756916, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014787178854851869, 'l1_Layer_2': 1.726462348051291e-05, 'l1_Layer_3': 4.488113732106296e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 150, 'n_units_Layer_3': 205}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.22 | sMAPE for Validation Set is: 18.15% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 29.38 | sMAPE for Test Set is: 20.51% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:11:35,515]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:11:35,962]\u001b[0m Trial 170 finished with value: 14.436834226136321 and parameters: {'n_hidden': 3, 'learning_rate': 0.005578188654125341, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14938349247083205, 'dropout_rate_Layer_2': 0.16192978746258865, 'dropout_rate_Layer_3': 0.26404711325834435, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.2352514917144095e-05, 'l1_Layer_2': 0.044709183665986446, 'l1_Layer_3': 2.1657126365830864e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 160, 'n_units_Layer_3': 255}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.44 | sMAPE for Validation Set is: 18.92% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 27.11 | sMAPE for Test Set is: 19.63% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:11:36,539]\u001b[0m Trial 164 finished with value: 54.358680131170125 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018461055924878693, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1982583195268959, 'dropout_rate_Layer_2': 0.07992072884192403, 'dropout_rate_Layer_3': 0.10779133462944804, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0005188264313972128, 'l1_Layer_2': 0.00010084681395281707, 'l1_Layer_3': 0.00018313695217661322, 'n_units_Layer_1': 215, 'n_units_Layer_2': 95, 'n_units_Layer_3': 125}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.36 | sMAPE for Validation Set is: 50.89% | rMAE for Validation Set is: 2.19\n",
      "MAE for Test Set is: 98.91 | sMAPE for Test Set is: 76.80% | rMAE for Test Set is: 2.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:11:42,362]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:11:42,451]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:11:44,882]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:11:49,807]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:11:51,244]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:11:56,971]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:12:02,114]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:12:02,322]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:12:10,997]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:12:13,733]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:12:14,124]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:12:18,322]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:12:22,051]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:12:23,211]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:12:26,980]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:12:29,095]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:12:30,932]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:12:35,497]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:12:38,714]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:12:39,131]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:12:43,618]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:12:45,430]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:12:58,410]\u001b[0m Trial 189 finished with value: 65.2497985849789 and parameters: {'n_hidden': 3, 'learning_rate': 0.09685115543142614, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2078936704539895, 'dropout_rate_Layer_2': 0.3256507625846369, 'dropout_rate_Layer_3': 0.33156200555417237, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.014965424421247556, 'l1_Layer_2': 0.00041896779339710546, 'l1_Layer_3': 0.00013075965429614492, 'n_units_Layer_1': 220, 'n_units_Layer_2': 180, 'n_units_Layer_3': 140}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 65.25 | sMAPE for Validation Set is: 65.86% | rMAE for Validation Set is: 2.62\n",
      "MAE for Test Set is: 113.31 | sMAPE for Test Set is: 94.62% | rMAE for Test Set is: 2.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:13:02,884]\u001b[0m Trial 195 finished with value: 16.252106971332257 and parameters: {'n_hidden': 3, 'learning_rate': 0.048100596644506693, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0352002334418717, 'dropout_rate_Layer_2': 0.09178764983816229, 'dropout_rate_Layer_3': 0.395603308386894, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00041638123152383055, 'l1_Layer_2': 0.0019636731739267814, 'l1_Layer_3': 0.007097502668817178, 'n_units_Layer_1': 280, 'n_units_Layer_2': 230, 'n_units_Layer_3': 175}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.25 | sMAPE for Validation Set is: 20.42% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 29.05 | sMAPE for Test Set is: 20.70% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:13:05,326]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:13:19,021]\u001b[0m Trial 194 finished with value: 16.395291798047623 and parameters: {'n_hidden': 4, 'learning_rate': 0.008700806169615218, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18810691919008182, 'dropout_rate_Layer_2': 0.27814449981690126, 'dropout_rate_Layer_3': 0.20571710106071606, 'dropout_rate_Layer_4': 0.1790841588680614, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.03885040406643437, 'l1_Layer_2': 0.00062511464184118, 'l1_Layer_3': 0.00015341813006376908, 'l1_Layer_4': 0.05818564160305578, 'n_units_Layer_1': 200, 'n_units_Layer_2': 160, 'n_units_Layer_3': 235, 'n_units_Layer_4': 180}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.40 | sMAPE for Validation Set is: 21.77% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 28.45 | sMAPE for Test Set is: 20.30% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:13:19,314]\u001b[0m Trial 197 finished with value: 15.579392084939963 and parameters: {'n_hidden': 3, 'learning_rate': 0.05205137736179755, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.035966885744448555, 'dropout_rate_Layer_2': 0.09788858655908941, 'dropout_rate_Layer_3': 0.3992953654384812, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00037139852363996656, 'l1_Layer_2': 0.002186671036919305, 'l1_Layer_3': 0.0072490827740891725, 'n_units_Layer_1': 275, 'n_units_Layer_2': 235, 'n_units_Layer_3': 175}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.58 | sMAPE for Validation Set is: 19.54% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 29.70 | sMAPE for Test Set is: 20.88% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:13:24,386]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:13:24,468]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:13:29,845]\u001b[0m Trial 196 finished with value: 23.454905193069575 and parameters: {'n_hidden': 4, 'learning_rate': 0.006772859598255596, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19853675799968584, 'dropout_rate_Layer_2': 0.28244284061526326, 'dropout_rate_Layer_3': 0.21759596827697938, 'dropout_rate_Layer_4': 0.17112084904605726, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.08757833545466226, 'l1_Layer_2': 0.0006411721508432238, 'l1_Layer_3': 5.536922994606853e-05, 'l1_Layer_4': 0.09636188228866988, 'n_units_Layer_1': 205, 'n_units_Layer_2': 175, 'n_units_Layer_3': 235, 'n_units_Layer_4': 180}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.45 | sMAPE for Validation Set is: 25.35% | rMAE for Validation Set is: 0.94\n",
      "MAE for Test Set is: 36.71 | sMAPE for Test Set is: 25.33% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:13:32,879]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:13:33,297]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:13:37,874]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:13:41,836]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:13:43,818]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:13:46,583]\u001b[0m Trial 199 finished with value: 17.220332883484037 and parameters: {'n_hidden': 4, 'learning_rate': 0.008714235195828608, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19672702519390128, 'dropout_rate_Layer_2': 0.29192127159626813, 'dropout_rate_Layer_3': 0.21286909723237146, 'dropout_rate_Layer_4': 0.1602639867013532, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0657750871472385, 'l1_Layer_2': 0.0005392433697780705, 'l1_Layer_3': 0.00013850368883931474, 'l1_Layer_4': 0.02280502167323438, 'n_units_Layer_1': 200, 'n_units_Layer_2': 180, 'n_units_Layer_3': 225, 'n_units_Layer_4': 180}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.22 | sMAPE for Validation Set is: 21.82% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 31.63 | sMAPE for Test Set is: 21.89% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:13:47,179]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:13:52,195]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:13:55,548]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:13:55,980]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:14:01,274]\u001b[0m Trial 209 finished with value: 14.718074698541068 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034809526506975694, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2398798743085691, 'dropout_rate_Layer_2': 0.2510766661074607, 'dropout_rate_Layer_3': 0.2484539921575394, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.7012392513760167e-05, 'l1_Layer_2': 0.00028544030758027617, 'l1_Layer_3': 3.092955147148615e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 180, 'n_units_Layer_3': 195}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.72 | sMAPE for Validation Set is: 18.96% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 28.80 | sMAPE for Test Set is: 20.45% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:14:04,965]\u001b[0m Trial 207 finished with value: 16.449160451329618 and parameters: {'n_hidden': 4, 'learning_rate': 0.008567714413090427, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21986009035265164, 'dropout_rate_Layer_2': 0.29398556454244446, 'dropout_rate_Layer_3': 0.20484429373836366, 'dropout_rate_Layer_4': 0.14020118000762732, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.09958508756625248, 'l1_Layer_2': 0.015100272004695601, 'l1_Layer_3': 5.33227233960913e-05, 'l1_Layer_4': 0.09813493353859593, 'n_units_Layer_1': 195, 'n_units_Layer_2': 215, 'n_units_Layer_3': 240, 'n_units_Layer_4': 180}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.45 | sMAPE for Validation Set is: 20.57% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 27.82 | sMAPE for Test Set is: 20.03% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:14:07,577]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:14:10,733]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:14:12,222]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:14:17,376]\u001b[0m Trial 214 finished with value: 51.99802896805871 and parameters: {'n_hidden': 3, 'learning_rate': 0.019163741980682044, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14200786091100798, 'dropout_rate_Layer_2': 0.14216257838434204, 'dropout_rate_Layer_3': 0.3595534370105004, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011756859439832925, 'l1_Layer_2': 0.0016065942912030285, 'l1_Layer_3': 0.0018355535307104129, 'n_units_Layer_1': 230, 'n_units_Layer_2': 300, 'n_units_Layer_3': 220}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.00 | sMAPE for Validation Set is: 49.79% | rMAE for Validation Set is: 2.09\n",
      "MAE for Test Set is: 93.98 | sMAPE for Test Set is: 71.55% | rMAE for Test Set is: 2.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:14:26,548]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:14:29,297]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:14:30,597]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:14:34,024]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:14:35,672]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.87 | sMAPE for Validation Set is: 22.39% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 30.06 | sMAPE for Test Set is: 21.09% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:14:38,648]\u001b[0m Trial 218 finished with value: 15.867082123753079 and parameters: {'n_hidden': 4, 'learning_rate': 0.014859878283240965, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08447037250847317, 'dropout_rate_Layer_2': 0.39363708416786913, 'dropout_rate_Layer_3': 0.17611346124632077, 'dropout_rate_Layer_4': 0.0715428356961856, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.009617531799002543, 'l1_Layer_2': 0.018894436205277518, 'l1_Layer_3': 4.2820400935910746e-05, 'l1_Layer_4': 0.006208942697095274, 'n_units_Layer_1': 140, 'n_units_Layer_2': 240, 'n_units_Layer_3': 280, 'n_units_Layer_4': 140}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:14:42,980]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:14:46,498]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:14:48,351]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:14:53,096]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:14:55,872]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:14:59,031]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:15:01,529]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:15:02,172]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:15:04,676]\u001b[0m Trial 230 finished with value: 58.11322383413767 and parameters: {'n_hidden': 3, 'learning_rate': 0.05823716887702051, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26040504436861617, 'dropout_rate_Layer_2': 0.07013714774865967, 'dropout_rate_Layer_3': 0.16594102144788367, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00025346328693486947, 'l1_Layer_2': 0.000549584129273981, 'l1_Layer_3': 0.0002992871166736491, 'n_units_Layer_1': 265, 'n_units_Layer_2': 195, 'n_units_Layer_3': 175}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 58.11 | sMAPE for Validation Set is: 56.18% | rMAE for Validation Set is: 2.34\n",
      "MAE for Test Set is: 103.87 | sMAPE for Test Set is: 82.79% | rMAE for Test Set is: 2.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:15:06,285]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:15:07,897]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:15:10,755]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:15:11,276]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:15:15,576]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:15:18,312]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:15:20,605]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:15:23,084]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:15:28,554]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:15:31,757]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:15:32,460]\u001b[0m Trial 240 finished with value: 46.86711486484253 and parameters: {'n_hidden': 3, 'learning_rate': 0.09845247304818942, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09398038701527835, 'dropout_rate_Layer_2': 0.3516678707084184, 'dropout_rate_Layer_3': 0.11274582467548494, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.015058035339668258, 'l1_Layer_2': 0.00027366540832573615, 'l1_Layer_3': 8.322600186547618e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 210, 'n_units_Layer_3': 190}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.87 | sMAPE for Validation Set is: 48.23% | rMAE for Validation Set is: 1.88\n",
      "MAE for Test Set is: 80.78 | sMAPE for Test Set is: 57.82% | rMAE for Test Set is: 2.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:15:46,485]\u001b[0m Trial 244 finished with value: 49.38828203994857 and parameters: {'n_hidden': 3, 'learning_rate': 0.09818376987946241, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2654082632734979, 'dropout_rate_Layer_2': 0.26845878266846657, 'dropout_rate_Layer_3': 0.31816244119630793, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01331390255719796, 'l1_Layer_2': 0.0003330227986713263, 'l1_Layer_3': 8.362547914276138e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 210, 'n_units_Layer_3': 220}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.39 | sMAPE for Validation Set is: 45.90% | rMAE for Validation Set is: 1.99\n",
      "MAE for Test Set is: 90.98 | sMAPE for Test Set is: 67.86% | rMAE for Test Set is: 2.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:15:46,817]\u001b[0m Trial 245 finished with value: 44.48083403829562 and parameters: {'n_hidden': 3, 'learning_rate': 0.03329241546786093, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12339203163349594, 'dropout_rate_Layer_2': 0.3575637057807929, 'dropout_rate_Layer_3': 0.06533286017924264, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.02586152179821038, 'l1_Layer_2': 0.00058554373012389, 'l1_Layer_3': 1.6078613880763687e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 175, 'n_units_Layer_3': 220}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.48 | sMAPE for Validation Set is: 41.85% | rMAE for Validation Set is: 1.79\n",
      "MAE for Test Set is: 74.58 | sMAPE for Test Set is: 52.03% | rMAE for Test Set is: 1.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:15:51,851]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:15:59,825]\u001b[0m Trial 246 finished with value: 49.75418333932785 and parameters: {'n_hidden': 3, 'learning_rate': 0.064276663028992, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1388082773995841, 'dropout_rate_Layer_2': 0.3556709962691367, 'dropout_rate_Layer_3': 0.002658073354621475, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.027147827132752277, 'l1_Layer_2': 0.0005046980911022508, 'l1_Layer_3': 1.156046402080499e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 285, 'n_units_Layer_3': 220}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.75 | sMAPE for Validation Set is: 45.26% | rMAE for Validation Set is: 2.00\n",
      "MAE for Test Set is: 91.43 | sMAPE for Test Set is: 68.58% | rMAE for Test Set is: 2.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:16:05,717]\u001b[0m Trial 249 finished with value: 41.03060078527716 and parameters: {'n_hidden': 3, 'learning_rate': 0.012098479148474133, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13201015661247167, 'dropout_rate_Layer_2': 0.36009320228545044, 'dropout_rate_Layer_3': 0.05205297531059228, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.026595555696133737, 'l1_Layer_2': 0.0005760951028903237, 'l1_Layer_3': 1.8612139106077478e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 240, 'n_units_Layer_3': 220}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.03 | sMAPE for Validation Set is: 39.19% | rMAE for Validation Set is: 1.65\n",
      "MAE for Test Set is: 67.01 | sMAPE for Test Set is: 45.90% | rMAE for Test Set is: 1.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:16:07,373]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:16:08,586]\u001b[0m Trial 247 finished with value: 15.876392614952456 and parameters: {'n_hidden': 4, 'learning_rate': 0.01783200671098443, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11717514988301367, 'dropout_rate_Layer_2': 0.39886284983783626, 'dropout_rate_Layer_3': 0.18008788172344084, 'dropout_rate_Layer_4': 0.07522108268879997, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.029739367793618212, 'l1_Layer_2': 0.019141906140791982, 'l1_Layer_3': 2.9452252639236593e-05, 'l1_Layer_4': 0.00842680687484827, 'n_units_Layer_1': 135, 'n_units_Layer_2': 240, 'n_units_Layer_3': 275, 'n_units_Layer_4': 135}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.88 | sMAPE for Validation Set is: 20.39% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 28.15 | sMAPE for Test Set is: 20.26% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:16:12,309]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:16:16,393]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:16:25,904]\u001b[0m Trial 254 finished with value: 34.53706145305152 and parameters: {'n_hidden': 3, 'learning_rate': 0.012824725948547215, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12905117452192041, 'dropout_rate_Layer_2': 0.3561356218826173, 'dropout_rate_Layer_3': 0.05394249789896427, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.084502535144602, 'l1_Layer_2': 0.0005748257572211746, 'l1_Layer_3': 1.5058622923801241e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 280, 'n_units_Layer_3': 220}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 34.54 | sMAPE for Validation Set is: 32.13% | rMAE for Validation Set is: 1.39\n",
      "MAE for Test Set is: 56.90 | sMAPE for Test Set is: 37.49% | rMAE for Test Set is: 1.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:16:28,649]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:16:33,133]\u001b[0m Trial 253 finished with value: 16.695798059291235 and parameters: {'n_hidden': 4, 'learning_rate': 0.018560285104183366, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08176029026565618, 'dropout_rate_Layer_2': 0.3999938715699439, 'dropout_rate_Layer_3': 0.17905655653669203, 'dropout_rate_Layer_4': 0.058154843184034674, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.009050585448194244, 'l1_Layer_2': 0.017500858184498008, 'l1_Layer_3': 3.318269390194618e-05, 'l1_Layer_4': 0.005216092550989001, 'n_units_Layer_1': 125, 'n_units_Layer_2': 275, 'n_units_Layer_3': 275, 'n_units_Layer_4': 125}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.70 | sMAPE for Validation Set is: 21.11% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 31.35 | sMAPE for Test Set is: 21.80% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:16:34,006]\u001b[0m Trial 255 finished with value: 15.152558873871852 and parameters: {'n_hidden': 4, 'learning_rate': 0.015415882618331732, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08715910284492277, 'dropout_rate_Layer_2': 0.397018868262608, 'dropout_rate_Layer_3': 0.16418872456469671, 'dropout_rate_Layer_4': 0.06429065872729575, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.010997641631675398, 'l1_Layer_2': 0.016720051425332828, 'l1_Layer_3': 3.441029596934232e-05, 'l1_Layer_4': 0.005266956613508456, 'n_units_Layer_1': 135, 'n_units_Layer_2': 275, 'n_units_Layer_3': 280, 'n_units_Layer_4': 125}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.15 | sMAPE for Validation Set is: 19.91% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 28.69 | sMAPE for Test Set is: 20.49% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:16:40,610]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:16:43,460]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:16:46,371]\u001b[0m Trial 257 finished with value: 40.90051575165845 and parameters: {'n_hidden': 3, 'learning_rate': 0.012581750690792202, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13040762681706894, 'dropout_rate_Layer_2': 0.3557474437329355, 'dropout_rate_Layer_3': 0.003346224141216464, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.07332668974600114, 'l1_Layer_2': 0.0006515563624581491, 'l1_Layer_3': 1.4575437363855695e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 285, 'n_units_Layer_3': 220}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 40.90 | sMAPE for Validation Set is: 38.80% | rMAE for Validation Set is: 1.65\n",
      "MAE for Test Set is: 71.69 | sMAPE for Test Set is: 49.51% | rMAE for Test Set is: 1.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:16:49,852]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:16:54,546]\u001b[0m Trial 259 finished with value: 15.000885622754444 and parameters: {'n_hidden': 4, 'learning_rate': 0.021427415912925313, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07881887232525635, 'dropout_rate_Layer_2': 0.3857302833744337, 'dropout_rate_Layer_3': 0.15987986958185926, 'dropout_rate_Layer_4': 0.09131781914737945, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.01268164483471595, 'l1_Layer_2': 0.08053139512609546, 'l1_Layer_3': 2.2957256688531986e-05, 'l1_Layer_4': 0.003387008323376791, 'n_units_Layer_1': 165, 'n_units_Layer_2': 255, 'n_units_Layer_3': 270, 'n_units_Layer_4': 125}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.00 | sMAPE for Validation Set is: 19.55% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 29.35 | sMAPE for Test Set is: 20.73% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:16:59,764]\u001b[0m Trial 261 finished with value: 38.82478034568954 and parameters: {'n_hidden': 3, 'learning_rate': 0.012498174728957022, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13129748091815624, 'dropout_rate_Layer_2': 0.3499342748093132, 'dropout_rate_Layer_3': 0.06077189814555503, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.09907556477810142, 'l1_Layer_2': 0.00017542557714196518, 'l1_Layer_3': 1.3800847871130007e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 285, 'n_units_Layer_3': 220}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 38.82 | sMAPE for Validation Set is: 36.08% | rMAE for Validation Set is: 1.56\n",
      "MAE for Test Set is: 66.46 | sMAPE for Test Set is: 45.02% | rMAE for Test Set is: 1.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:17:03,605]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:17:08,320]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:17:16,185]\u001b[0m Trial 265 finished with value: 36.49303311180788 and parameters: {'n_hidden': 3, 'learning_rate': 0.011431308150362127, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1242354584099413, 'dropout_rate_Layer_2': 0.38081262741584015, 'dropout_rate_Layer_3': 0.05263137332359789, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.08953297315296642, 'l1_Layer_2': 0.00022408840748648466, 'l1_Layer_3': 1.7578212687974553e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 285, 'n_units_Layer_3': 240}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.49 | sMAPE for Validation Set is: 36.14% | rMAE for Validation Set is: 1.47\n",
      "MAE for Test Set is: 54.70 | sMAPE for Test Set is: 35.90% | rMAE for Test Set is: 1.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:17:19,736]\u001b[0m Trial 266 finished with value: 39.55236597476003 and parameters: {'n_hidden': 3, 'learning_rate': 0.011901566582033717, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12498795856877773, 'dropout_rate_Layer_2': 0.38303667130800056, 'dropout_rate_Layer_3': 0.04796752547916881, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.08715431827271186, 'l1_Layer_2': 0.00016773902072652792, 'l1_Layer_3': 1.456501422222804e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 285, 'n_units_Layer_3': 245}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 39.55 | sMAPE for Validation Set is: 36.13% | rMAE for Validation Set is: 1.59\n",
      "MAE for Test Set is: 67.15 | sMAPE for Test Set is: 45.54% | rMAE for Test Set is: 1.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:17:22,469]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:17:23,228]\u001b[0m Trial 267 finished with value: 39.85009697204875 and parameters: {'n_hidden': 3, 'learning_rate': 0.012562247385492236, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12090063160102182, 'dropout_rate_Layer_2': 0.3827252196567007, 'dropout_rate_Layer_3': 0.046890305007869476, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.06743676987480803, 'l1_Layer_2': 0.0009583080548161644, 'l1_Layer_3': 1.6884950279351275e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 285, 'n_units_Layer_3': 240}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 39.85 | sMAPE for Validation Set is: 40.83% | rMAE for Validation Set is: 1.60\n",
      "MAE for Test Set is: 63.81 | sMAPE for Test Set is: 42.64% | rMAE for Test Set is: 1.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:17:25,560]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:17:26,739]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:17:31,398]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:17:39,714]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:17:43,085]\u001b[0m Trial 271 finished with value: 41.52558345102065 and parameters: {'n_hidden': 3, 'learning_rate': 0.01268837340301253, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12841989783959384, 'dropout_rate_Layer_2': 0.38445260647655777, 'dropout_rate_Layer_3': 0.05607423066347107, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0967072552753791, 'l1_Layer_2': 0.00017191373573247645, 'l1_Layer_3': 1.8081140699655298e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 290, 'n_units_Layer_3': 245}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.53 | sMAPE for Validation Set is: 38.07% | rMAE for Validation Set is: 1.67\n",
      "MAE for Test Set is: 71.78 | sMAPE for Test Set is: 49.50% | rMAE for Test Set is: 1.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:17:45,858]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:17:47,780]\u001b[0m Trial 273 finished with value: 14.532780537303376 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034175934161489504, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11018789937741323, 'dropout_rate_Layer_2': 0.11730341564451723, 'dropout_rate_Layer_3': 0.3740431683916597, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.5985588441276514e-05, 'l1_Layer_2': 0.07641703593472278, 'l1_Layer_3': 1.0103174262200434e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 80, 'n_units_Layer_3': 155}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.53 | sMAPE for Validation Set is: 18.94% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 28.48 | sMAPE for Test Set is: 20.43% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:17:48,427]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:17:54,753]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:17:59,808]\u001b[0m Trial 213 finished with value: 16.129857620038578 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011722181075734498, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09727347132934283, 'dropout_rate_Layer_2': 0.26839825560788344, 'dropout_rate_Layer_3': 0.33856350215017283, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.040228217562387425, 'l1_Layer_2': 0.003952999205510248, 'l1_Layer_3': 0.013212543398286807, 'n_units_Layer_1': 180, 'n_units_Layer_2': 180, 'n_units_Layer_3': 145}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.13 | sMAPE for Validation Set is: 20.04% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 28.73 | sMAPE for Test Set is: 20.46% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:18:06,795]\u001b[0m Trial 278 finished with value: 40.454091498520874 and parameters: {'n_hidden': 3, 'learning_rate': 0.007953098259348921, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16027947243588755, 'dropout_rate_Layer_2': 0.3693425071127582, 'dropout_rate_Layer_3': 0.026700251538830017, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.06620241649021423, 'l1_Layer_2': 0.0010427504044141257, 'l1_Layer_3': 1.2936236258823994e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 295, 'n_units_Layer_3': 255}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 40.45 | sMAPE for Validation Set is: 36.17% | rMAE for Validation Set is: 1.63\n",
      "MAE for Test Set is: 73.05 | sMAPE for Test Set is: 50.59% | rMAE for Test Set is: 1.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:18:07,613]\u001b[0m Trial 279 finished with value: 42.77698394064894 and parameters: {'n_hidden': 3, 'learning_rate': 0.007219203536421806, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16200851187650966, 'dropout_rate_Layer_2': 0.3686564314627111, 'dropout_rate_Layer_3': 0.028484767256739423, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.06975166250103366, 'l1_Layer_2': 0.0010242593433693787, 'l1_Layer_3': 1.2336841899651641e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 280, 'n_units_Layer_3': 210}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.78 | sMAPE for Validation Set is: 38.40% | rMAE for Validation Set is: 1.72\n",
      "MAE for Test Set is: 77.63 | sMAPE for Test Set is: 54.80% | rMAE for Test Set is: 1.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:18:10,053]\u001b[0m Trial 280 finished with value: 35.80317128025481 and parameters: {'n_hidden': 3, 'learning_rate': 0.008068669833197881, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16183426687281244, 'dropout_rate_Layer_2': 0.36690679551524497, 'dropout_rate_Layer_3': 0.02892439022942237, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.07086510008842711, 'l1_Layer_2': 0.0008494735316517191, 'l1_Layer_3': 1.3563936348979042e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 280, 'n_units_Layer_3': 260}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 35.80 | sMAPE for Validation Set is: 37.24% | rMAE for Validation Set is: 1.44\n",
      "MAE for Test Set is: 49.83 | sMAPE for Test Set is: 32.33% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:18:12,407]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:18:15,629]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:18:19,614]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:18:19,933]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:18:20,014]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.91 | sMAPE for Validation Set is: 21.06% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 30.03 | sMAPE for Test Set is: 21.18% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:18:25,480]\u001b[0m Trial 281 finished with value: 17.90594448500727 and parameters: {'n_hidden': 3, 'learning_rate': 0.007700399645125171, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15447076847112806, 'dropout_rate_Layer_2': 0.3852985652875243, 'dropout_rate_Layer_3': 0.02877154101170211, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0702661422117436, 'l1_Layer_2': 0.0010566412321395282, 'l1_Layer_3': 1.212595503290083e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 280, 'n_units_Layer_3': 260}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:18:28,165]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:18:31,348]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:18:37,109]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:18:41,151]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:18:43,753]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:18:44,614]\u001b[0m Trial 290 finished with value: 15.36053317888711 and parameters: {'n_hidden': 4, 'learning_rate': 0.021868994886911686, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007672191870994716, 'dropout_rate_Layer_2': 0.3406397894957838, 'dropout_rate_Layer_3': 0.25183087941512994, 'dropout_rate_Layer_4': 0.028356257899121856, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0007577263143856088, 'l1_Layer_2': 0.08363027686140352, 'l1_Layer_3': 0.0003265166511548147, 'l1_Layer_4': 0.00204785445511817, 'n_units_Layer_1': 175, 'n_units_Layer_2': 300, 'n_units_Layer_3': 285, 'n_units_Layer_4': 95}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.36 | sMAPE for Validation Set is: 19.79% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 29.91 | sMAPE for Test Set is: 21.13% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:18:44,908]\u001b[0m Trial 288 finished with value: 15.42055542963177 and parameters: {'n_hidden': 4, 'learning_rate': 0.01237121794289603, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.010794849015770797, 'dropout_rate_Layer_2': 0.3427837361219262, 'dropout_rate_Layer_3': 0.25295757112733736, 'dropout_rate_Layer_4': 0.0006770765099794185, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0008777746593010767, 'l1_Layer_2': 0.09934058769055412, 'l1_Layer_3': 0.00039523613428064827, 'l1_Layer_4': 0.0013201837140109252, 'n_units_Layer_1': 180, 'n_units_Layer_2': 300, 'n_units_Layer_3': 300, 'n_units_Layer_4': 105}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.42 | sMAPE for Validation Set is: 19.91% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 29.65 | sMAPE for Test Set is: 20.91% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:18:51,405]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:18:54,957]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:18:58,323]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:19:02,091]\u001b[0m Trial 287 finished with value: 17.381123997230414 and parameters: {'n_hidden': 3, 'learning_rate': 0.008051210593452745, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10989815612471635, 'dropout_rate_Layer_2': 0.3879301819401349, 'dropout_rate_Layer_3': 0.07360044095935303, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.04477791078508304, 'l1_Layer_2': 0.0002363249103309144, 'l1_Layer_3': 2.9434747566863827e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 300, 'n_units_Layer_3': 260}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.38 | sMAPE for Validation Set is: 20.59% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 31.18 | sMAPE for Test Set is: 21.66% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:19:08,455]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:19:11,390]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:19:17,110]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:19:25,446]\u001b[0m Trial 297 finished with value: 16.222000181526223 and parameters: {'n_hidden': 3, 'learning_rate': 0.005052496292151513, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11008272996916901, 'dropout_rate_Layer_2': 0.39369697166449713, 'dropout_rate_Layer_3': 0.0763882102952066, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.04526307122904085, 'l1_Layer_2': 0.0017756111775214668, 'l1_Layer_3': 2.7736759222935378e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 265, 'n_units_Layer_3': 260}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.22 | sMAPE for Validation Set is: 20.07% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 28.24 | sMAPE for Test Set is: 20.15% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:19:25,655]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:19:30,923]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:19:39,373]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:19:43,525]\u001b[0m Trial 300 finished with value: 15.680536673487454 and parameters: {'n_hidden': 3, 'learning_rate': 0.005209962668878715, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10777999407794023, 'dropout_rate_Layer_2': 0.38930163216673247, 'dropout_rate_Layer_3': 0.07429864497925959, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.046536598720098785, 'l1_Layer_2': 0.0020371773305134662, 'l1_Layer_3': 3.3877498905874825e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 265, 'n_units_Layer_3': 260}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.68 | sMAPE for Validation Set is: 19.77% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 29.95 | sMAPE for Test Set is: 20.93% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:19:46,561]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:19:49,042]\u001b[0m Trial 306 finished with value: 16.70805888223748 and parameters: {'n_hidden': 3, 'learning_rate': 0.04122200512173627, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01059447780578001, 'dropout_rate_Layer_2': 0.021737093125217752, 'dropout_rate_Layer_3': 0.37717244633884994, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.715839466558893e-05, 'l1_Layer_2': 0.00014309192282477818, 'l1_Layer_3': 0.011869995246639913, 'n_units_Layer_1': 255, 'n_units_Layer_2': 215, 'n_units_Layer_3': 155}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.71 | sMAPE for Validation Set is: 20.42% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 32.33 | sMAPE for Test Set is: 22.22% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:19:52,571]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:19:55,852]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:19:56,884]\u001b[0m Trial 308 finished with value: 14.71996169084943 and parameters: {'n_hidden': 3, 'learning_rate': 0.004178126217303219, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10888199214605432, 'dropout_rate_Layer_2': 0.34283855505832195, 'dropout_rate_Layer_3': 0.07915152380286579, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.046101557335780696, 'l1_Layer_2': 0.0018203461038074575, 'l1_Layer_3': 2.3552122182300692e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 275, 'n_units_Layer_3': 275}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.72 | sMAPE for Validation Set is: 19.22% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 26.92 | sMAPE for Test Set is: 19.49% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:19:59,957]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:20:00,810]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:20:05,776]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:20:06,286]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:20:11,993]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:20:12,971]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:20:14,722]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:20:20,792]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:20:24,020]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:20:24,533]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.08 | sMAPE for Validation Set is: 19.13% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 30.27 | sMAPE for Test Set is: 21.35% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:20:28,234]\u001b[0m Trial 305 finished with value: 15.084863293277484 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009641670661517074, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.003637053948636257, 'dropout_rate_Layer_2': 0.023664454546010932, 'dropout_rate_Layer_3': 0.3805500213642908, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.6024949414030433e-05, 'l1_Layer_2': 0.00023530965196450363, 'l1_Layer_3': 0.013226780186909395, 'n_units_Layer_1': 260, 'n_units_Layer_2': 215, 'n_units_Layer_3': 150}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:20:29,783]\u001b[0m Trial 320 finished with value: 14.926084186928675 and parameters: {'n_hidden': 3, 'learning_rate': 0.008447633068599246, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18444514615019555, 'dropout_rate_Layer_2': 0.38932658034005396, 'dropout_rate_Layer_3': 0.10336610138857322, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.034023780846280154, 'l1_Layer_2': 0.0020441770870382853, 'l1_Layer_3': 2.2961097440370252e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 275, 'n_units_Layer_3': 260}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.93 | sMAPE for Validation Set is: 19.87% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 28.58 | sMAPE for Test Set is: 20.53% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:20:30,133]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:20:35,713]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:20:35,833]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:20:36,174]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:20:44,857]\u001b[0m Trial 324 finished with value: 14.969204000467693 and parameters: {'n_hidden': 3, 'learning_rate': 0.007850083771178263, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09642361290813539, 'dropout_rate_Layer_2': 0.3741757201514478, 'dropout_rate_Layer_3': 0.0983069468956819, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.05304938006790924, 'l1_Layer_2': 0.0019017447428444317, 'l1_Layer_3': 1.0068975749135206e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 275, 'n_units_Layer_3': 260}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.97 | sMAPE for Validation Set is: 19.53% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 30.00 | sMAPE for Test Set is: 21.11% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:20:45,160]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:20:50,234]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:20:50,922]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:20:56,266]\u001b[0m Trial 329 finished with value: 14.9500234391747 and parameters: {'n_hidden': 3, 'learning_rate': 0.008266262695466165, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09890239029560935, 'dropout_rate_Layer_2': 0.39211400496031207, 'dropout_rate_Layer_3': 0.09738286345137333, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.032660209588301584, 'l1_Layer_2': 0.002085839053330761, 'l1_Layer_3': 2.277500478680814e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 275, 'n_units_Layer_3': 265}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.95 | sMAPE for Validation Set is: 19.70% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 26.72 | sMAPE for Test Set is: 19.42% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:20:59,382]\u001b[0m Trial 328 finished with value: 15.686037441159092 and parameters: {'n_hidden': 3, 'learning_rate': 0.008314939084269701, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1876791967343426, 'dropout_rate_Layer_2': 0.3903965430741159, 'dropout_rate_Layer_3': 0.0953240998140795, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.031862722545721624, 'l1_Layer_2': 0.0019214417548807177, 'l1_Layer_3': 2.369408034791808e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 265, 'n_units_Layer_3': 265}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.69 | sMAPE for Validation Set is: 19.41% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 27.60 | sMAPE for Test Set is: 19.79% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:21:04,488]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:21:08,352]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:21:11,833]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:21:12,428]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:21:17,678]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:21:19,242]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.66 | sMAPE for Validation Set is: 19.19% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 27.54 | sMAPE for Test Set is: 19.81% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:21:22,189]\u001b[0m Trial 337 finished with value: 14.655199848397926 and parameters: {'n_hidden': 3, 'learning_rate': 0.006266908026269869, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09802330377254993, 'dropout_rate_Layer_2': 0.39151335329033693, 'dropout_rate_Layer_3': 0.10251536880954416, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.032918326873825676, 'l1_Layer_2': 0.0019570710636660858, 'l1_Layer_3': 2.455370813597703e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 265, 'n_units_Layer_3': 270}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:21:22,673]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:21:23,128]\u001b[0m Trial 336 finished with value: 15.321824703762651 and parameters: {'n_hidden': 3, 'learning_rate': 0.006181885634009011, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09758058148392189, 'dropout_rate_Layer_2': 0.3936531072164346, 'dropout_rate_Layer_3': 0.13224922799475478, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.03397089851113056, 'l1_Layer_2': 0.0019030863572459082, 'l1_Layer_3': 5.8787201798607045e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 265, 'n_units_Layer_3': 300}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.32 | sMAPE for Validation Set is: 19.61% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 29.55 | sMAPE for Test Set is: 20.90% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:21:31,323]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:21:33,076]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:21:35,145]\u001b[0m Trial 342 finished with value: 15.132319067292594 and parameters: {'n_hidden': 3, 'learning_rate': 0.008857489225316779, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09669010404770613, 'dropout_rate_Layer_2': 0.39085924112898646, 'dropout_rate_Layer_3': 0.1371947876746823, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.03180185259341762, 'l1_Layer_2': 0.0019946093281850755, 'l1_Layer_3': 5.2974666747798165e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 265, 'n_units_Layer_3': 285}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.13 | sMAPE for Validation Set is: 19.39% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 27.39 | sMAPE for Test Set is: 19.84% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:21:37,572]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:21:40,709]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:21:42,809]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:21:53,730]\u001b[0m Trial 350 finished with value: 15.083648375894326 and parameters: {'n_hidden': 4, 'learning_rate': 0.012664393201048941, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01856125255858911, 'dropout_rate_Layer_2': 0.3378415728892882, 'dropout_rate_Layer_3': 0.24643492105094558, 'dropout_rate_Layer_4': 0.008432363767851236, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0008076992552364827, 'l1_Layer_2': 0.08496496011914799, 'l1_Layer_3': 0.00029682208375657814, 'l1_Layer_4': 0.0009559310791921688, 'n_units_Layer_1': 180, 'n_units_Layer_2': 295, 'n_units_Layer_3': 295, 'n_units_Layer_4': 95}. Best is trial 167 with value: 14.224461736845848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.08 | sMAPE for Validation Set is: 19.79% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 28.50 | sMAPE for Test Set is: 20.41% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:21:56,918]\u001b[0m Trial 351 finished with value: 14.176042686112543 and parameters: {'n_hidden': 3, 'learning_rate': 0.006258691389803434, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.060117652633162655, 'dropout_rate_Layer_2': 0.37321169296446505, 'dropout_rate_Layer_3': 0.13150594601615992, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.018593438365619483, 'l1_Layer_2': 0.00538839914534643, 'l1_Layer_3': 6.048226662247044e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 255, 'n_units_Layer_3': 300}. Best is trial 351 with value: 14.176042686112543.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.18 | sMAPE for Validation Set is: 18.35% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 28.55 | sMAPE for Test Set is: 20.35% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:21:58,152]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:22:00,412]\u001b[0m Trial 344 finished with value: 14.125512540904282 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030002289524778615, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02021180335387289, 'dropout_rate_Layer_2': 0.010406033812630309, 'dropout_rate_Layer_3': 0.3999543607253272, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011458493228083865, 'l1_Layer_2': 0.016899503795466713, 'l1_Layer_3': 5.906278055756115e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 295, 'n_units_Layer_3': 130}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.13 | sMAPE for Validation Set is: 18.64% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 27.53 | sMAPE for Test Set is: 19.77% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:22:06,406]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:22:09,240]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:22:13,779]\u001b[0m Trial 353 finished with value: 15.340311958683268 and parameters: {'n_hidden': 3, 'learning_rate': 0.006365398937983214, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07924061266626244, 'dropout_rate_Layer_2': 0.3738137093923322, 'dropout_rate_Layer_3': 0.14225759311769343, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.023640737744742065, 'l1_Layer_2': 0.006010494571326925, 'l1_Layer_3': 4.6228889928610565e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 250, 'n_units_Layer_3': 300}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.34 | sMAPE for Validation Set is: 19.59% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 28.94 | sMAPE for Test Set is: 20.56% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:22:20,927]\u001b[0m Trial 354 finished with value: 15.427168890477697 and parameters: {'n_hidden': 4, 'learning_rate': 0.01161077640685375, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0007920146591164521, 'dropout_rate_Layer_2': 0.31364705025284756, 'dropout_rate_Layer_3': 0.2353576019196433, 'dropout_rate_Layer_4': 0.03938994295940121, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00023339904874897412, 'l1_Layer_2': 0.029509783475010223, 'l1_Layer_3': 0.00032165605307705965, 'l1_Layer_4': 0.0006755563184135248, 'n_units_Layer_1': 165, 'n_units_Layer_2': 265, 'n_units_Layer_3': 260, 'n_units_Layer_4': 85}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.43 | sMAPE for Validation Set is: 20.07% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 29.74 | sMAPE for Test Set is: 21.01% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:22:25,933]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:22:29,457]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:22:41,815]\u001b[0m Trial 358 finished with value: 14.22475096364039 and parameters: {'n_hidden': 3, 'learning_rate': 0.003314564271917311, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.004803316764083854, 'dropout_rate_Layer_2': 0.02396672341413529, 'dropout_rate_Layer_3': 0.3652899149311408, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010951454907540253, 'l1_Layer_2': 0.036358416228143745, 'l1_Layer_3': 1.675277948279167e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 275, 'n_units_Layer_3': 115}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.22 | sMAPE for Validation Set is: 18.73% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 27.97 | sMAPE for Test Set is: 20.07% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:22:42,721]\u001b[0m Trial 347 finished with value: 14.89726871321321 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012006612958083715, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.022932244401912473, 'dropout_rate_Layer_2': 0.09632752094231604, 'dropout_rate_Layer_3': 0.3353461863919146, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.74495903702977e-05, 'l1_Layer_2': 0.00029604453928575275, 'l1_Layer_3': 0.06694159838615969, 'n_units_Layer_1': 290, 'n_units_Layer_2': 155, 'n_units_Layer_3': 195}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.90 | sMAPE for Validation Set is: 19.09% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 29.34 | sMAPE for Test Set is: 20.81% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:22:44,543]\u001b[0m Trial 360 finished with value: 15.102057544661191 and parameters: {'n_hidden': 3, 'learning_rate': 0.006394600944782768, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05264780731277145, 'dropout_rate_Layer_2': 0.3709896270386703, 'dropout_rate_Layer_3': 0.13779609351270153, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.023127897299116074, 'l1_Layer_2': 0.007312964501923234, 'l1_Layer_3': 5.973414484781936e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 250, 'n_units_Layer_3': 300}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.10 | sMAPE for Validation Set is: 19.33% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 29.83 | sMAPE for Test Set is: 20.94% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:22:46,234]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:22:52,801]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:23:01,040]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.90 | sMAPE for Validation Set is: 19.20% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 28.58 | sMAPE for Test Set is: 20.49% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:23:02,721]\u001b[0m Trial 365 finished with value: 14.904212106996852 and parameters: {'n_hidden': 3, 'learning_rate': 0.006547671278498771, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05207414005835005, 'dropout_rate_Layer_2': 0.37449653915008424, 'dropout_rate_Layer_3': 0.13561628741335546, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.019140616779440883, 'l1_Layer_2': 0.009366312008278742, 'l1_Layer_3': 5.58184082745762e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 255, 'n_units_Layer_3': 300}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:23:04,859]\u001b[0m Trial 364 finished with value: 15.15904097604574 and parameters: {'n_hidden': 3, 'learning_rate': 0.006193116706413156, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.056808514313741516, 'dropout_rate_Layer_2': 0.372647525823028, 'dropout_rate_Layer_3': 0.14281059643131697, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02071834722921535, 'l1_Layer_2': 0.0088118144807426, 'l1_Layer_3': 5.588646780705124e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 250, 'n_units_Layer_3': 295}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.16 | sMAPE for Validation Set is: 19.37% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 28.32 | sMAPE for Test Set is: 20.25% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:23:17,457]\u001b[0m Trial 367 finished with value: 15.006960746926746 and parameters: {'n_hidden': 3, 'learning_rate': 0.0038258292948298517, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07945618843687546, 'dropout_rate_Layer_2': 0.3996052738053114, 'dropout_rate_Layer_3': 0.1596981624128433, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.017446949328616266, 'l1_Layer_2': 0.005759942005762781, 'l1_Layer_3': 4.9677604867662405e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 250, 'n_units_Layer_3': 290}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.01 | sMAPE for Validation Set is: 19.08% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 30.13 | sMAPE for Test Set is: 21.17% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:23:21,591]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:23:24,716]\u001b[0m Trial 369 finished with value: 14.637910433916629 and parameters: {'n_hidden': 3, 'learning_rate': 0.004332331341330077, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02704202578057746, 'dropout_rate_Layer_2': 0.3444966528771406, 'dropout_rate_Layer_3': 0.16242891611573074, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008181699092180705, 'l1_Layer_2': 0.009650850977583758, 'l1_Layer_3': 4.364574260960485e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 255, 'n_units_Layer_3': 290}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.64 | sMAPE for Validation Set is: 18.72% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 27.57 | sMAPE for Test Set is: 19.80% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:23:31,373]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:23:36,895]\u001b[0m Trial 363 finished with value: 14.608670050945667 and parameters: {'n_hidden': 3, 'learning_rate': 0.001023623166356702, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02567987966306655, 'dropout_rate_Layer_2': 0.1804911485369149, 'dropout_rate_Layer_3': 0.30906223599641003, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.9159044949465524e-05, 'l1_Layer_2': 0.00028549427486420444, 'l1_Layer_3': 0.08341089728204405, 'n_units_Layer_1': 290, 'n_units_Layer_2': 155, 'n_units_Layer_3': 200}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.61 | sMAPE for Validation Set is: 19.10% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 28.03 | sMAPE for Test Set is: 20.16% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:23:37,598]\u001b[0m Trial 372 finished with value: 14.647034120462015 and parameters: {'n_hidden': 3, 'learning_rate': 0.004296365134998326, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01971944375601859, 'dropout_rate_Layer_2': 0.34551603757786903, 'dropout_rate_Layer_3': 0.1704752362853926, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01692137069482593, 'l1_Layer_2': 0.005400133490628338, 'l1_Layer_3': 4.2243970384076535e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 255, 'n_units_Layer_3': 285}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.65 | sMAPE for Validation Set is: 18.86% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 28.04 | sMAPE for Test Set is: 20.05% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:23:42,647]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:23:57,151]\u001b[0m Trial 375 finished with value: 15.006028080306239 and parameters: {'n_hidden': 3, 'learning_rate': 0.004394246554363045, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.034803252110847595, 'dropout_rate_Layer_2': 0.3454369979151477, 'dropout_rate_Layer_3': 0.1687405253101889, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007738812364494814, 'l1_Layer_2': 0.018243685648571047, 'l1_Layer_3': 3.9989609308237856e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 235, 'n_units_Layer_3': 285}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.01 | sMAPE for Validation Set is: 19.24% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 29.06 | sMAPE for Test Set is: 20.67% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:24:00,883]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:24:09,787]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:24:15,811]\u001b[0m Trial 376 finished with value: 14.556589064993227 and parameters: {'n_hidden': 3, 'learning_rate': 0.004120940529189269, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.024859407043941788, 'dropout_rate_Layer_2': 0.04582687456818947, 'dropout_rate_Layer_3': 0.334241793221789, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.023437079753436455, 'l1_Layer_2': 0.0056051542786454195, 'l1_Layer_3': 5.002572950961977e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 200, 'n_units_Layer_3': 110}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.56 | sMAPE for Validation Set is: 19.28% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 28.17 | sMAPE for Test Set is: 20.02% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:24:25,248]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:24:25,971]\u001b[0m Trial 373 finished with value: 15.68183246297543 and parameters: {'n_hidden': 3, 'learning_rate': 0.001311439555647583, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02708239870752002, 'dropout_rate_Layer_2': 0.16195048656851113, 'dropout_rate_Layer_3': 0.3436377100395811, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.713695399732154e-05, 'l1_Layer_2': 0.03227556431919514, 'l1_Layer_3': 0.05042848381370714, 'n_units_Layer_1': 290, 'n_units_Layer_2': 120, 'n_units_Layer_3': 220}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.68 | sMAPE for Validation Set is: 19.96% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 29.31 | sMAPE for Test Set is: 20.92% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:24:29,951]\u001b[0m Trial 379 finished with value: 14.965968202705492 and parameters: {'n_hidden': 3, 'learning_rate': 0.004377211963505688, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.039831828636575216, 'dropout_rate_Layer_2': 0.3155225986038627, 'dropout_rate_Layer_3': 0.10420236572110295, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.017077001373008625, 'l1_Layer_2': 0.03189601386666251, 'l1_Layer_3': 3.9838454283103255e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 240, 'n_units_Layer_3': 275}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.97 | sMAPE for Validation Set is: 19.01% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 30.10 | sMAPE for Test Set is: 21.15% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:24:31,971]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:24:35,115]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:24:35,229]\u001b[0m Trial 380 finished with value: 15.125950845636467 and parameters: {'n_hidden': 4, 'learning_rate': 0.005315914195856395, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03679857862388193, 'dropout_rate_Layer_2': 0.3741865274461053, 'dropout_rate_Layer_3': 0.2803211236393042, 'dropout_rate_Layer_4': 0.10779917839684874, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.004314933314006691, 'l1_Layer_2': 0.062138746944848555, 'l1_Layer_3': 1.815777696151346e-05, 'l1_Layer_4': 0.0001910761557281181, 'n_units_Layer_1': 175, 'n_units_Layer_2': 285, 'n_units_Layer_3': 215, 'n_units_Layer_4': 50}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.13 | sMAPE for Validation Set is: 19.59% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 29.31 | sMAPE for Test Set is: 20.67% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:24:35,437]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:24:42,346]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:24:42,450]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:24:42,706]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:24:45,172]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:24:50,303]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:24:52,255]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:25:05,774]\u001b[0m Trial 391 finished with value: 15.08452644056892 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034787644155755567, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.043267439938143054, 'dropout_rate_Layer_2': 0.2942598563331524, 'dropout_rate_Layer_3': 0.12250673134705567, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.009571252998502089, 'l1_Layer_2': 0.026935869335556632, 'l1_Layer_3': 7.056166320540313e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 275, 'n_units_Layer_3': 275}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.08 | sMAPE for Validation Set is: 19.13% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 28.34 | sMAPE for Test Set is: 20.23% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:25:14,985]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:25:15,262]\u001b[0m Trial 392 finished with value: 14.486475235744338 and parameters: {'n_hidden': 3, 'learning_rate': 0.002803470943661936, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.018879495552029085, 'dropout_rate_Layer_2': 0.05087737632832978, 'dropout_rate_Layer_3': 0.31945354748051324, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005252295673984626, 'l1_Layer_2': 0.007935593363065981, 'l1_Layer_3': 5.1184425298294795e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 260, 'n_units_Layer_3': 125}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.49 | sMAPE for Validation Set is: 18.73% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 28.26 | sMAPE for Test Set is: 20.10% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:25:27,584]\u001b[0m Trial 388 finished with value: 14.554719626548348 and parameters: {'n_hidden': 3, 'learning_rate': 0.0037272972758842083, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04241897315777414, 'dropout_rate_Layer_2': 0.032957954730492484, 'dropout_rate_Layer_3': 0.343012288742707, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.015056149950378267, 'l1_Layer_2': 0.007901948195495315, 'l1_Layer_3': 3.707676014682905e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 275, 'n_units_Layer_3': 115}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.55 | sMAPE for Validation Set is: 19.18% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 28.78 | sMAPE for Test Set is: 20.35% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:25:31,503]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:25:40,703]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:25:45,908]\u001b[0m Trial 395 finished with value: 14.285148622081712 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025443162665893964, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.018826585730164245, 'dropout_rate_Layer_2': 0.04819033728359889, 'dropout_rate_Layer_3': 0.3115738259158842, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004812623094211527, 'l1_Layer_2': 0.00522510576918592, 'l1_Layer_3': 5.140418703203898e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 265, 'n_units_Layer_3': 125}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.29 | sMAPE for Validation Set is: 18.67% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 27.72 | sMAPE for Test Set is: 19.84% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:25:46,189]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:25:46,581]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.69 | sMAPE for Validation Set is: 20.27% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 29.23 | sMAPE for Test Set is: 20.89% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:25:49,393]\u001b[0m Trial 393 finished with value: 15.693577932210383 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008551490578375364, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06485433592871037, 'dropout_rate_Layer_2': 0.2753473335168967, 'dropout_rate_Layer_3': 0.26412808756117995, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013727647701907678, 'l1_Layer_2': 0.026411374839126787, 'l1_Layer_3': 0.06036711207447439, 'n_units_Layer_1': 270, 'n_units_Layer_2': 180, 'n_units_Layer_3': 240}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:26:01,578]\u001b[0m Trial 400 finished with value: 14.95718692702288 and parameters: {'n_hidden': 3, 'learning_rate': 0.004491678418170953, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03322759232601703, 'dropout_rate_Layer_2': 0.3628054102450026, 'dropout_rate_Layer_3': 0.10670401951026914, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00863727613063879, 'l1_Layer_2': 0.043995908949126306, 'l1_Layer_3': 2.2183986404599292e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 240, 'n_units_Layer_3': 290}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.96 | sMAPE for Validation Set is: 19.31% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 28.44 | sMAPE for Test Set is: 20.35% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:26:05,079]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.85 | sMAPE for Validation Set is: 19.03% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 28.92 | sMAPE for Test Set is: 20.53% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:26:12,980]\u001b[0m Trial 403 finished with value: 14.849128815874707 and parameters: {'n_hidden': 3, 'learning_rate': 0.004552649679680094, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06651853807753436, 'dropout_rate_Layer_2': 0.36234756913271493, 'dropout_rate_Layer_3': 0.12032429908723227, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007154116105371321, 'l1_Layer_2': 0.010739873469661144, 'l1_Layer_3': 4.3017858130375046e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 240, 'n_units_Layer_3': 290}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:26:32,359]\u001b[0m Trial 401 finished with value: 15.790056243626543 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010069349941586427, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05870936822593632, 'dropout_rate_Layer_2': 0.26199028804632707, 'dropout_rate_Layer_3': 0.2564234186907831, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011522772249632195, 'l1_Layer_2': 0.04946844954060331, 'l1_Layer_3': 0.09194839643490958, 'n_units_Layer_1': 295, 'n_units_Layer_2': 145, 'n_units_Layer_3': 255}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.79 | sMAPE for Validation Set is: 20.31% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 29.91 | sMAPE for Test Set is: 21.26% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:26:38,972]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:26:38,998]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.29 | sMAPE for Validation Set is: 18.80% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 28.22 | sMAPE for Test Set is: 20.13% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:26:43,004]\u001b[0m Trial 406 finished with value: 14.291407544359814 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022199012852633, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.029429838007346668, 'dropout_rate_Layer_2': 0.047679094823715865, 'dropout_rate_Layer_3': 0.3150513702660057, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005770689977354651, 'l1_Layer_2': 0.005232641154857763, 'l1_Layer_3': 5.711077620302251e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 255, 'n_units_Layer_3': 130}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:26:46,327]\u001b[0m Trial 402 finished with value: 15.91327187884273 and parameters: {'n_hidden': 3, 'learning_rate': 0.000947696262817594, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06941508350923888, 'dropout_rate_Layer_2': 0.27101531309837856, 'dropout_rate_Layer_3': 0.2593672234916215, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.995563028170468e-05, 'l1_Layer_2': 0.04645366725427768, 'l1_Layer_3': 0.09547917742969426, 'n_units_Layer_1': 120, 'n_units_Layer_2': 135, 'n_units_Layer_3': 255}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.91 | sMAPE for Validation Set is: 20.22% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 30.35 | sMAPE for Test Set is: 21.40% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:26:48,552]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:26:49,327]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:26:56,515]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:26:59,057]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:27:00,619]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:27:07,761]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:27:07,865]\u001b[0m Trial 414 finished with value: 51.56003680254938 and parameters: {'n_hidden': 4, 'learning_rate': 0.0035972628444233355, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.034247890569942374, 'dropout_rate_Layer_2': 0.37468892908799867, 'dropout_rate_Layer_3': 0.2875644047284013, 'dropout_rate_Layer_4': 0.1085007391270936, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0040846218113049625, 'l1_Layer_2': 0.010273207539325731, 'l1_Layer_3': 1.7955490174472657e-05, 'l1_Layer_4': 0.0001527899554408393, 'n_units_Layer_1': 100, 'n_units_Layer_2': 280, 'n_units_Layer_3': 215, 'n_units_Layer_4': 65}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.56 | sMAPE for Validation Set is: 48.61% | rMAE for Validation Set is: 2.07\n",
      "MAE for Test Set is: 90.83 | sMAPE for Test Set is: 68.40% | rMAE for Test Set is: 2.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:27:08,708]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.78 | sMAPE for Validation Set is: 19.05% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 28.79 | sMAPE for Test Set is: 20.49% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:27:13,318]\u001b[0m Trial 413 finished with value: 14.783940163262509 and parameters: {'n_hidden': 3, 'learning_rate': 0.002915308390605052, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04435424443834279, 'dropout_rate_Layer_2': 0.36153183861580757, 'dropout_rate_Layer_3': 0.1088725970675222, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006572779204498981, 'l1_Layer_2': 0.03781752310968097, 'l1_Layer_3': 4.355121492264727e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 245, 'n_units_Layer_3': 280}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:27:15,428]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:27:25,157]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:27:25,761]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:27:31,071]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:27:38,826]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:27:42,376]\u001b[0m Trial 418 finished with value: 14.45481873775716 and parameters: {'n_hidden': 3, 'learning_rate': 0.002793693055037136, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02653558433312891, 'dropout_rate_Layer_2': 0.2913297243587437, 'dropout_rate_Layer_3': 0.303471619351813, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002295683035583523, 'l1_Layer_2': 0.005163099723263024, 'l1_Layer_3': 5.450966878600891e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 275, 'n_units_Layer_3': 135}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.45 | sMAPE for Validation Set is: 18.67% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 27.20 | sMAPE for Test Set is: 19.57% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:27:42,837]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:27:42,869]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:27:50,456]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:27:55,860]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:27:59,090]\u001b[0m Trial 419 finished with value: 15.632905437000636 and parameters: {'n_hidden': 3, 'learning_rate': 0.001410611264801888, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.028367600122399823, 'dropout_rate_Layer_2': 0.3262935677601987, 'dropout_rate_Layer_3': 0.31434380570260295, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.4355108485105994e-05, 'l1_Layer_2': 0.03171625632701701, 'l1_Layer_3': 0.05542495580779017, 'n_units_Layer_1': 265, 'n_units_Layer_2': 180, 'n_units_Layer_3': 240}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.63 | sMAPE for Validation Set is: 20.14% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 30.20 | sMAPE for Test Set is: 21.39% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:28:01,518]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:28:02,068]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:28:09,339]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:28:09,839]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:28:14,464]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:28:18,160]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:28:19,507]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:28:20,832]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:28:23,333]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:28:28,831]\u001b[0m Trial 433 finished with value: 14.98957123623214 and parameters: {'n_hidden': 3, 'learning_rate': 0.004605016821676468, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006706561308344709, 'dropout_rate_Layer_2': 0.3160436240572038, 'dropout_rate_Layer_3': 0.12862691170854307, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.012454393794159547, 'l1_Layer_2': 0.03532315538096407, 'l1_Layer_3': 6.989401701533167e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 245, 'n_units_Layer_3': 275}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.99 | sMAPE for Validation Set is: 19.06% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 29.88 | sMAPE for Test Set is: 21.03% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:28:29,248]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:28:39,268]\u001b[0m Trial 438 finished with value: 14.458910299555106 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027578133127457625, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0025044353455352247, 'dropout_rate_Layer_2': 0.3782003660620967, 'dropout_rate_Layer_3': 0.11889210141453037, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.011923151346636603, 'l1_Layer_2': 0.024994845697637907, 'l1_Layer_3': 6.933522648898715e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 245, 'n_units_Layer_3': 280}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.46 | sMAPE for Validation Set is: 18.89% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 28.04 | sMAPE for Test Set is: 20.07% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:28:42,939]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:28:45,110]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:28:53,883]\u001b[0m Trial 442 finished with value: 14.909382415776811 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027017343058101575, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03069651141833115, 'dropout_rate_Layer_2': 0.33069151355612647, 'dropout_rate_Layer_3': 0.11711436520570379, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.027722860237287133, 'l1_Layer_2': 0.05931158856196395, 'l1_Layer_3': 3.2983124395811325e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 245, 'n_units_Layer_3': 285}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.91 | sMAPE for Validation Set is: 19.07% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 29.24 | sMAPE for Test Set is: 20.66% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:28:56,744]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:28:57,218]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:29:03,096]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:29:03,516]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:29:09,224]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:29:12,707]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:29:14,703]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:29:18,370]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:29:19,228]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:29:23,265]\u001b[0m Trial 446 finished with value: 14.965179535210467 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026885996029301306, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.019958686073014334, 'dropout_rate_Layer_2': 0.37983726110555316, 'dropout_rate_Layer_3': 0.116926899980144, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002646216296915081, 'l1_Layer_2': 0.06559062772071383, 'l1_Layer_3': 4.481255894832856e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 255, 'n_units_Layer_3': 285}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.97 | sMAPE for Validation Set is: 19.16% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 28.39 | sMAPE for Test Set is: 20.28% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:29:23,698]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:29:28,707]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:29:37,534]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:29:41,081]\u001b[0m Trial 439 finished with value: 16.257024216066966 and parameters: {'n_hidden': 3, 'learning_rate': 0.001927083597018924, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.023029877235276802, 'dropout_rate_Layer_2': 0.38591457262294526, 'dropout_rate_Layer_3': 0.3351379341062889, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.553963124958055e-05, 'l1_Layer_2': 0.092875589182309, 'l1_Layer_3': 0.01949965094778137, 'n_units_Layer_1': 285, 'n_units_Layer_2': 160, 'n_units_Layer_3': 210}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.26 | sMAPE for Validation Set is: 20.52% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 29.28 | sMAPE for Test Set is: 20.93% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:29:45,080]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:29:52,559]\u001b[0m Trial 459 finished with value: 14.585335516667676 and parameters: {'n_hidden': 3, 'learning_rate': 0.00959756472959959, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.011155303294062308, 'dropout_rate_Layer_2': 0.3523905459665452, 'dropout_rate_Layer_3': 0.08486207843221427, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.014584722666702066, 'l1_Layer_2': 0.009511651955605823, 'l1_Layer_3': 2.8255421218434782e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 270, 'n_units_Layer_3': 280}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.59 | sMAPE for Validation Set is: 19.04% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 28.25 | sMAPE for Test Set is: 20.18% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:29:57,686]\u001b[0m Trial 455 finished with value: 14.57417873620099 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035608246458981568, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02658872432992967, 'dropout_rate_Layer_2': 0.04935620914069626, 'dropout_rate_Layer_3': 0.333219129281571, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.024629102774039045, 'l1_Layer_2': 0.009416684071782902, 'l1_Layer_3': 4.6391190177474236e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 270, 'n_units_Layer_3': 120}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.57 | sMAPE for Validation Set is: 19.30% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 28.47 | sMAPE for Test Set is: 20.25% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:30:01,360]\u001b[0m Trial 461 finished with value: 14.544589586542081 and parameters: {'n_hidden': 3, 'learning_rate': 0.003343376319842252, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00983256547679684, 'dropout_rate_Layer_2': 0.34928605029310145, 'dropout_rate_Layer_3': 0.08810573469564247, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.027212532903750246, 'l1_Layer_2': 0.008737271479291101, 'l1_Layer_3': 9.695001561339598e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 270, 'n_units_Layer_3': 280}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.54 | sMAPE for Validation Set is: 18.82% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 28.59 | sMAPE for Test Set is: 20.34% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:30:07,592]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:30:11,126]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:30:14,593]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:30:15,816]\u001b[0m Trial 463 finished with value: 14.45052023060051 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033653815485669325, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.025642319364338043, 'dropout_rate_Layer_2': 0.35153512583157454, 'dropout_rate_Layer_3': 0.08327186133474211, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.012804628706584003, 'l1_Layer_2': 0.010890397689116758, 'l1_Layer_3': 9.54198358501699e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 270, 'n_units_Layer_3': 280}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.45 | sMAPE for Validation Set is: 18.84% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 27.86 | sMAPE for Test Set is: 20.01% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:30:17,244]\u001b[0m Trial 462 finished with value: 14.38251027223118 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034291635349829276, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.029072872848960794, 'dropout_rate_Layer_2': 0.2929612273340998, 'dropout_rate_Layer_3': 0.15646907669305402, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.013711704736548402, 'l1_Layer_2': 0.009570549189205831, 'l1_Layer_3': 2.7698497395323508e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 270, 'n_units_Layer_3': 280}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.38 | sMAPE for Validation Set is: 18.58% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 28.95 | sMAPE for Test Set is: 20.51% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:30:21,786]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:30:24,366]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:30:27,012]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:30:27,673]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:30:34,335]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:30:36,892]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:30:39,845]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:30:47,365]\u001b[0m Trial 472 finished with value: 14.262121269938222 and parameters: {'n_hidden': 3, 'learning_rate': 0.003074494222827625, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014594034546401395, 'dropout_rate_Layer_2': 0.3490353137817742, 'dropout_rate_Layer_3': 0.087098315514748, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01453174166565747, 'l1_Layer_2': 0.009564021799647484, 'l1_Layer_3': 9.799212854015189e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 255, 'n_units_Layer_3': 280}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.26 | sMAPE for Validation Set is: 18.52% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 27.92 | sMAPE for Test Set is: 20.01% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:30:51,441]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:30:52,607]\u001b[0m Trial 475 finished with value: 14.358553892895719 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034280589697312457, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0080709493321157, 'dropout_rate_Layer_2': 0.34756427330396483, 'dropout_rate_Layer_3': 0.08805391080974824, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.013991984615830101, 'l1_Layer_2': 0.011780392006412524, 'l1_Layer_3': 9.705958864488989e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 270, 'n_units_Layer_3': 280}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.36 | sMAPE for Validation Set is: 18.62% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 28.64 | sMAPE for Test Set is: 20.35% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:30:54,703]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:31:00,134]\u001b[0m Trial 464 finished with value: 14.849811707595206 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006832606380007101, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2666200540796896, 'dropout_rate_Layer_2': 0.1956886585158599, 'dropout_rate_Layer_3': 0.31188147275864386, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.622074033836458e-05, 'l1_Layer_2': 0.01222548281256173, 'l1_Layer_3': 0.029518579204238088, 'n_units_Layer_1': 260, 'n_units_Layer_2': 145, 'n_units_Layer_3': 190}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.85 | sMAPE for Validation Set is: 19.40% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 28.77 | sMAPE for Test Set is: 20.55% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:31:03,665]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:31:04,040]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:31:04,626]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:31:08,506]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:31:14,464]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:31:15,457]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:31:18,745]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:31:20,097]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:31:22,467]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:31:24,539]\u001b[0m Trial 482 finished with value: 15.210721575503463 and parameters: {'n_hidden': 4, 'learning_rate': 0.01515194966028286, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02249315993644898, 'dropout_rate_Layer_2': 0.3419351029187308, 'dropout_rate_Layer_3': 0.23816435911683542, 'dropout_rate_Layer_4': 0.029579860294973417, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0011714240745374631, 'l1_Layer_2': 0.07776602758728345, 'l1_Layer_3': 0.0023444999531242964, 'l1_Layer_4': 0.002954594026272015, 'n_units_Layer_1': 170, 'n_units_Layer_2': 300, 'n_units_Layer_3': 290, 'n_units_Layer_4': 110}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.21 | sMAPE for Validation Set is: 20.15% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 28.58 | sMAPE for Test Set is: 20.42% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:31:25,338]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:31:28,060]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:31:29,993]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:31:31,324]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:31:32,371]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:31:35,700]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:31:41,441]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:31:42,264]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:31:45,135]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:31:49,912]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:31:50,369]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:31:55,429]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:31:59,020]\u001b[0m Trial 494 finished with value: 14.616390711089087 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034065129068900205, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3975625104714537, 'dropout_rate_Layer_2': 0.02700567060224672, 'dropout_rate_Layer_3': 0.03418610199632602, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008013079542241203, 'l1_Layer_2': 0.012905684229408191, 'l1_Layer_3': 0.0020714560061647082, 'n_units_Layer_1': 105, 'n_units_Layer_2': 295, 'n_units_Layer_3': 120}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.62 | sMAPE for Validation Set is: 19.29% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 28.64 | sMAPE for Test Set is: 20.36% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:32:01,305]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:32:04,811]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:32:05,294]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:32:10,140]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:32:13,394]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.51 | sMAPE for Validation Set is: 20.09% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 29.22 | sMAPE for Test Set is: 20.86% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:32:16,586]\u001b[0m Trial 500 finished with value: 15.511471404096932 and parameters: {'n_hidden': 3, 'learning_rate': 0.002462246558941297, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20320643217460638, 'dropout_rate_Layer_2': 0.15093153922157498, 'dropout_rate_Layer_3': 0.27423364780220966, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.50650957656844e-05, 'l1_Layer_2': 0.03570982280407596, 'l1_Layer_3': 0.06722350933000214, 'n_units_Layer_1': 220, 'n_units_Layer_2': 115, 'n_units_Layer_3': 195}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:32:19,517]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:32:20,145]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:32:20,778]\u001b[0m Trial 503 finished with value: 15.181734879589612 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026757444034310666, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34980948923404864, 'dropout_rate_Layer_2': 0.15965478493643304, 'dropout_rate_Layer_3': 0.3248691428078795, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.6315463774910836e-05, 'l1_Layer_2': 0.03217327116493257, 'l1_Layer_3': 0.04209639325821291, 'n_units_Layer_1': 265, 'n_units_Layer_2': 110, 'n_units_Layer_3': 215}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.18 | sMAPE for Validation Set is: 19.87% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 28.42 | sMAPE for Test Set is: 20.44% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:32:25,465]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:32:26,283]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:32:31,105]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:32:31,973]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:32:34,008]\u001b[0m Trial 509 finished with value: 14.66865443485409 and parameters: {'n_hidden': 3, 'learning_rate': 0.005297493990072932, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008713607368042758, 'dropout_rate_Layer_2': 0.3361608620725088, 'dropout_rate_Layer_3': 0.11050144530933387, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.012658886787399274, 'l1_Layer_2': 0.018528853083369084, 'l1_Layer_3': 4.979078542578342e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 260, 'n_units_Layer_3': 275}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.67 | sMAPE for Validation Set is: 19.07% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 28.36 | sMAPE for Test Set is: 20.19% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:32:36,356]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:32:40,736]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:32:46,578]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:32:48,680]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:32:53,178]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:32:53,873]\u001b[0m Trial 518 finished with value: 14.718949044385658 and parameters: {'n_hidden': 3, 'learning_rate': 0.003035958168609266, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0005147787296098556, 'dropout_rate_Layer_2': 0.34256565409323314, 'dropout_rate_Layer_3': 0.0957970389725881, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.014315956701342666, 'l1_Layer_2': 0.025870741527315187, 'l1_Layer_3': 2.9253182917023507e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 265, 'n_units_Layer_3': 270}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:32:53,904]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.72 | sMAPE for Validation Set is: 18.93% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 28.51 | sMAPE for Test Set is: 20.35% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:32:59,557]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:32:59,581]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:32:59,857]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:33:09,021]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:33:12,100]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:33:17,654]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:33:21,626]\u001b[0m Trial 525 finished with value: 14.843043135650996 and parameters: {'n_hidden': 3, 'learning_rate': 0.002521839116544699, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3514515279333852, 'dropout_rate_Layer_2': 0.14801306346279536, 'dropout_rate_Layer_3': 0.2811771450048806, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.6325159074456945e-05, 'l1_Layer_2': 0.006361108800468038, 'l1_Layer_3': 0.07725451749024194, 'n_units_Layer_1': 220, 'n_units_Layer_2': 110, 'n_units_Layer_3': 200}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.84 | sMAPE for Validation Set is: 19.47% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 28.70 | sMAPE for Test Set is: 20.51% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:33:22,204]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:33:27,453]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:33:27,596]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:33:32,555]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:33:33,062]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:33:41,436]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:33:43,893]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:33:50,734]\u001b[0m Trial 537 finished with value: 14.30329383139282 and parameters: {'n_hidden': 3, 'learning_rate': 0.002901424434125568, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03231308023404033, 'dropout_rate_Layer_2': 0.3498507592948545, 'dropout_rate_Layer_3': 0.09023112138257883, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00999168964623392, 'l1_Layer_2': 0.003216737255740918, 'l1_Layer_3': 2.8456249820974034e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 265, 'n_units_Layer_3': 280}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.30 | sMAPE for Validation Set is: 18.30% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 28.71 | sMAPE for Test Set is: 20.44% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:33:51,455]\u001b[0m Trial 530 finished with value: 14.575033418566155 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005687229525281364, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1948261249325458, 'dropout_rate_Layer_2': 0.18352865495892634, 'dropout_rate_Layer_3': 0.27578854426185073, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010090622855734453, 'l1_Layer_2': 0.006490315461225905, 'l1_Layer_3': 0.025287134256912844, 'n_units_Layer_1': 205, 'n_units_Layer_2': 110, 'n_units_Layer_3': 205}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.58 | sMAPE for Validation Set is: 19.09% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 28.21 | sMAPE for Test Set is: 20.17% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:33:54,158]\u001b[0m Trial 536 finished with value: 14.94427163822913 and parameters: {'n_hidden': 3, 'learning_rate': 0.002967283974366741, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.034556966359012425, 'dropout_rate_Layer_2': 0.3515705883992846, 'dropout_rate_Layer_3': 0.09345517084051715, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01028298143054918, 'l1_Layer_2': 0.018167002506086036, 'l1_Layer_3': 2.7659427388492985e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 255, 'n_units_Layer_3': 280}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.94 | sMAPE for Validation Set is: 19.05% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 28.82 | sMAPE for Test Set is: 20.49% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:33:55,419]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:34:01,634]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:34:04,695]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:34:08,433]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:34:11,767]\u001b[0m Trial 542 finished with value: 14.819111287052182 and parameters: {'n_hidden': 4, 'learning_rate': 0.009305376284773667, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.021649975972220126, 'dropout_rate_Layer_2': 0.3512920605052405, 'dropout_rate_Layer_3': 0.2792212469588706, 'dropout_rate_Layer_4': 0.0021452650004356935, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.0936697049871616e-05, 'l1_Layer_2': 0.039734713914342634, 'l1_Layer_3': 0.005910802148404164, 'l1_Layer_4': 0.0004513615676772811, 'n_units_Layer_1': 120, 'n_units_Layer_2': 240, 'n_units_Layer_3': 260, 'n_units_Layer_4': 160}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.82 | sMAPE for Validation Set is: 19.49% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 28.33 | sMAPE for Test Set is: 20.32% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:34:14,670]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:34:18,260]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:34:22,170]\u001b[0m Trial 540 finished with value: 15.345595623510066 and parameters: {'n_hidden': 4, 'learning_rate': 0.010410469454464584, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.025969145994130277, 'dropout_rate_Layer_2': 0.34838157783117335, 'dropout_rate_Layer_3': 0.28045802901768246, 'dropout_rate_Layer_4': 0.06905254744720009, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.013041888550037375, 'l1_Layer_2': 0.03665088232902796, 'l1_Layer_3': 0.006400849911553796, 'l1_Layer_4': 0.0003681299037239154, 'n_units_Layer_1': 120, 'n_units_Layer_2': 235, 'n_units_Layer_3': 270, 'n_units_Layer_4': 115}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.35 | sMAPE for Validation Set is: 19.67% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 30.22 | sMAPE for Test Set is: 21.20% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:34:22,834]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:34:27,912]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:34:28,500]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:34:32,724]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:34:35,550]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:34:38,535]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:34:41,816]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:34:46,386]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:34:46,625]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:34:51,944]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:34:55,200]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:34:57,488]\u001b[0m Trial 541 finished with value: 14.966270886155703 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006265699386641303, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3964339629631853, 'dropout_rate_Layer_2': 0.17998881992475732, 'dropout_rate_Layer_3': 0.28762076695917227, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.2529977397117164e-05, 'l1_Layer_2': 0.006653204036233642, 'l1_Layer_3': 0.03865608923519512, 'n_units_Layer_1': 200, 'n_units_Layer_2': 105, 'n_units_Layer_3': 205}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.97 | sMAPE for Validation Set is: 19.41% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 29.06 | sMAPE for Test Set is: 20.68% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:35:00,620]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:35:00,879]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:35:04,270]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:35:06,373]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:35:10,059]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:35:10,486]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:35:11,028]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:35:16,030]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:35:16,684]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:35:22,392]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:35:23,631]\u001b[0m Trial 563 finished with value: 14.563172916722252 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024025556567934922, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015568077546583747, 'dropout_rate_Layer_2': 0.013931554449929445, 'dropout_rate_Layer_3': 0.1504640881630573, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.060815026595678e-05, 'l1_Layer_2': 0.00671849786244437, 'l1_Layer_3': 0.030175337625718744, 'n_units_Layer_1': 120, 'n_units_Layer_2': 255, 'n_units_Layer_3': 255}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.56 | sMAPE for Validation Set is: 19.02% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 27.68 | sMAPE for Test Set is: 19.96% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:35:24,563]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:35:25,774]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:35:31,146]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:35:34,932]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:35:35,326]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:35:40,587]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:35:40,686]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:35:41,201]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:35:46,700]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:35:49,412]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:35:49,515]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:35:50,564]\u001b[0m Trial 569 finished with value: 14.943365961271068 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011796153708316514, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3678060956819067, 'dropout_rate_Layer_2': 0.13502743858838342, 'dropout_rate_Layer_3': 0.2888864691780621, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.040694597746571e-05, 'l1_Layer_2': 0.021109828712692236, 'l1_Layer_3': 0.022629178317310785, 'n_units_Layer_1': 210, 'n_units_Layer_2': 110, 'n_units_Layer_3': 215}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.94 | sMAPE for Validation Set is: 19.59% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 28.29 | sMAPE for Test Set is: 20.35% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:35:50,735]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:35:55,529]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:36:00,174]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:36:01,341]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:36:05,725]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:36:06,197]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:36:06,199]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:36:06,433]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:36:14,134]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:36:15,227]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:36:17,675]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:36:22,837]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:36:29,139]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:36:31,950]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:36:35,279]\u001b[0m Trial 594 finished with value: 14.589798346107457 and parameters: {'n_hidden': 3, 'learning_rate': 0.003478171236791004, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04473112068161281, 'dropout_rate_Layer_2': 0.32971723150788756, 'dropout_rate_Layer_3': 0.12676057235611488, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03796792608377124, 'l1_Layer_2': 0.006488018450320041, 'l1_Layer_3': 5.6028171002909986e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 260, 'n_units_Layer_3': 270}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.59 | sMAPE for Validation Set is: 18.84% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 29.37 | sMAPE for Test Set is: 20.78% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:36:37,983]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:36:38,648]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.63 | sMAPE for Validation Set is: 18.62% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 29.58 | sMAPE for Test Set is: 20.87% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:36:41,398]\u001b[0m Trial 597 finished with value: 14.631820190827497 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036124652935447883, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04103615030343377, 'dropout_rate_Layer_2': 0.3296643277554749, 'dropout_rate_Layer_3': 0.11386989633801889, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.011449604470621348, 'l1_Layer_2': 0.006512347817201284, 'l1_Layer_3': 5.4157421014124676e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 260, 'n_units_Layer_3': 270}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:36:45,734]\u001b[0m Trial 591 finished with value: 14.784030911309758 and parameters: {'n_hidden': 3, 'learning_rate': 0.001156888314808942, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3659017581413811, 'dropout_rate_Layer_2': 0.13195684352814718, 'dropout_rate_Layer_3': 0.28964634651397614, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.009530768565433e-05, 'l1_Layer_2': 0.0097747240965617, 'l1_Layer_3': 0.021457737528319296, 'n_units_Layer_1': 220, 'n_units_Layer_2': 80, 'n_units_Layer_3': 230}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.78 | sMAPE for Validation Set is: 19.28% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 27.86 | sMAPE for Test Set is: 20.05% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:36:48,623]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:36:48,770]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:36:50,428]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:36:57,729]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:36:57,839]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:37:03,156]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:37:07,288]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:37:07,696]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:37:07,884]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:37:10,082]\u001b[0m Trial 603 finished with value: 14.577049202483904 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011993750559296003, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36446115619867175, 'dropout_rate_Layer_2': 0.13333084447198973, 'dropout_rate_Layer_3': 0.28923131347102216, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3961616538215056e-05, 'l1_Layer_2': 0.00902613592747441, 'l1_Layer_3': 0.021782038103877514, 'n_units_Layer_1': 165, 'n_units_Layer_2': 85, 'n_units_Layer_3': 230}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.58 | sMAPE for Validation Set is: 19.17% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 27.98 | sMAPE for Test Set is: 20.10% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:37:13,620]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:37:15,943]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:37:16,452]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:37:24,963]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:37:29,430]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:37:29,878]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:37:33,885]\u001b[0m Trial 613 finished with value: 14.424180514799149 and parameters: {'n_hidden': 4, 'learning_rate': 0.007802300746015817, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10345549273149736, 'dropout_rate_Layer_2': 0.16786299661891751, 'dropout_rate_Layer_3': 0.11454261870049291, 'dropout_rate_Layer_4': 0.2922941280640835, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.024729351569509554, 'l1_Layer_2': 0.025095146497571087, 'l1_Layer_3': 0.0009650819216033932, 'l1_Layer_4': 0.0006089164162764037, 'n_units_Layer_1': 105, 'n_units_Layer_2': 205, 'n_units_Layer_3': 245, 'n_units_Layer_4': 150}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.42 | sMAPE for Validation Set is: 19.32% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 28.35 | sMAPE for Test Set is: 20.19% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:37:36,441]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:37:36,869]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:37:40,496]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:37:42,742]\u001b[0m Trial 615 finished with value: 14.679085380382823 and parameters: {'n_hidden': 4, 'learning_rate': 0.008182412630599963, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16239629049275064, 'dropout_rate_Layer_2': 0.17627019836833072, 'dropout_rate_Layer_3': 0.0057632911139325615, 'dropout_rate_Layer_4': 0.3337748972729403, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.026251127080748077, 'l1_Layer_2': 0.0255840181219981, 'l1_Layer_3': 0.0007984933923803931, 'l1_Layer_4': 0.0006131773825728191, 'n_units_Layer_1': 105, 'n_units_Layer_2': 265, 'n_units_Layer_3': 240, 'n_units_Layer_4': 150}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.68 | sMAPE for Validation Set is: 19.44% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 28.98 | sMAPE for Test Set is: 20.44% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:37:43,940]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:37:45,948]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:37:52,812]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:37:53,754]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:37:57,328]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:37:58,367]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:38:02,266]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:38:04,587]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:38:08,480]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:38:08,672]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:38:13,661]\u001b[0m Trial 627 finished with value: 14.301654053236076 and parameters: {'n_hidden': 3, 'learning_rate': 0.003520736583922098, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.037915316474851295, 'dropout_rate_Layer_2': 0.3676010115188796, 'dropout_rate_Layer_3': 0.08212600377627631, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008896258665271925, 'l1_Layer_2': 0.013180796034174979, 'l1_Layer_3': 4.7817823874892516e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 275, 'n_units_Layer_3': 290}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.30 | sMAPE for Validation Set is: 18.63% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 28.14 | sMAPE for Test Set is: 20.13% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:38:14,023]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:38:19,729]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:38:25,293]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:38:29,276]\u001b[0m Trial 632 finished with value: 14.467274001248498 and parameters: {'n_hidden': 4, 'learning_rate': 0.008291839727010728, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17092460652054575, 'dropout_rate_Layer_2': 0.16912905230348918, 'dropout_rate_Layer_3': 0.04482295455337255, 'dropout_rate_Layer_4': 0.3169494567723784, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.04606763561228823, 'l1_Layer_2': 0.025582747505984316, 'l1_Layer_3': 0.001006226494300619, 'l1_Layer_4': 0.0005633331237507053, 'n_units_Layer_1': 110, 'n_units_Layer_2': 200, 'n_units_Layer_3': 240, 'n_units_Layer_4': 155}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.47 | sMAPE for Validation Set is: 19.22% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 27.73 | sMAPE for Test Set is: 19.82% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:38:29,881]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:38:30,027]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:38:36,970]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:38:38,092]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:38:39,061]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:38:43,949]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:38:47,157]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:38:47,346]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:38:48,579]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:38:51,898]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:38:55,038]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:38:58,372]\u001b[0m Trial 634 finished with value: 15.253558875963895 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010718886192814703, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30141420838506394, 'dropout_rate_Layer_2': 0.13444362121798062, 'dropout_rate_Layer_3': 0.27707324943254574, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5085046694805612e-05, 'l1_Layer_2': 0.02110014386965215, 'l1_Layer_3': 0.02661674042283366, 'n_units_Layer_1': 155, 'n_units_Layer_2': 75, 'n_units_Layer_3': 225}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.25 | sMAPE for Validation Set is: 19.72% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 29.60 | sMAPE for Test Set is: 20.99% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:38:58,520]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:39:03,304]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:39:03,469]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:39:09,229]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:39:12,574]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:39:16,713]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:39:16,866]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:39:21,262]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:39:24,304]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:39:24,501]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:39:24,731]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:39:32,230]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:39:32,639]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:39:32,875]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:39:38,700]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:39:41,010]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:39:43,096]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:39:46,263]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:39:46,522]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:39:46,934]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:39:49,128]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:39:50,934]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:39:55,063]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:39:56,203]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:39:57,079]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:39:58,294]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:40:05,081]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:40:08,203]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:40:10,536]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:40:13,393]\u001b[0m Trial 673 finished with value: 14.970602820243693 and parameters: {'n_hidden': 4, 'learning_rate': 0.008272998638783433, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15685705148062332, 'dropout_rate_Layer_2': 0.15511606823753682, 'dropout_rate_Layer_3': 0.05064852938493941, 'dropout_rate_Layer_4': 0.32194149626795354, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.04704657827433364, 'l1_Layer_2': 0.02415251439841833, 'l1_Layer_3': 0.0008541822597183152, 'l1_Layer_4': 0.0005806973259980373, 'n_units_Layer_1': 105, 'n_units_Layer_2': 205, 'n_units_Layer_3': 240, 'n_units_Layer_4': 200}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.97 | sMAPE for Validation Set is: 19.48% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 27.40 | sMAPE for Test Set is: 19.67% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:40:15,806]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:40:19,283]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:40:22,599]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:40:23,687]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:40:24,905]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:40:29,815]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:40:30,071]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:40:37,148]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:40:39,532]\u001b[0m Trial 681 finished with value: 14.3618018645814 and parameters: {'n_hidden': 4, 'learning_rate': 0.00832521481118325, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17309249526671067, 'dropout_rate_Layer_2': 0.16855506282669772, 'dropout_rate_Layer_3': 0.004744527806305909, 'dropout_rate_Layer_4': 0.3163934348042872, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.048280598490302314, 'l1_Layer_2': 0.023746752860938202, 'l1_Layer_3': 0.0008186724081322221, 'l1_Layer_4': 0.000557565504478172, 'n_units_Layer_1': 100, 'n_units_Layer_2': 205, 'n_units_Layer_3': 245, 'n_units_Layer_4': 160}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.36 | sMAPE for Validation Set is: 19.26% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 28.25 | sMAPE for Test Set is: 20.11% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:40:42,022]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:40:45,934]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:40:49,419]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:40:49,639]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:40:56,733]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:40:56,899]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:40:57,646]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:41:02,736]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:41:05,374]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:41:05,535]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:41:06,581]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:41:06,676]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:41:15,216]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:41:15,356]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:41:16,062]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:41:22,051]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:41:22,405]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:41:27,333]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:41:27,646]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:41:27,714]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:41:34,863]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:41:35,428]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:41:35,541]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:41:42,879]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:41:43,071]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:41:43,349]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:41:53,011]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:41:53,552]\u001b[0m Trial 711 finished with value: 14.456896003509145 and parameters: {'n_hidden': 3, 'learning_rate': 0.004203083355354229, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.040700622408649384, 'dropout_rate_Layer_2': 0.35929908937873856, 'dropout_rate_Layer_3': 0.1204846832431584, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.012387965585999501, 'l1_Layer_2': 0.008256045988932106, 'l1_Layer_3': 0.0015456163753103133, 'n_units_Layer_1': 80, 'n_units_Layer_2': 265, 'n_units_Layer_3': 295}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.46 | sMAPE for Validation Set is: 18.99% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 27.79 | sMAPE for Test Set is: 19.99% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:41:54,346]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:41:59,542]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:42:01,687]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:42:06,634]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:42:07,597]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:42:10,545]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:42:13,793]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:42:16,148]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:42:21,178]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:42:21,926]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:42:22,644]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:42:24,800]\u001b[0m Trial 718 finished with value: 14.718670176918058 and parameters: {'n_hidden': 3, 'learning_rate': 0.0041102584086940746, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02447543111164243, 'dropout_rate_Layer_2': 0.3290552016870699, 'dropout_rate_Layer_3': 0.12400537322228734, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.018486214513570357, 'l1_Layer_2': 0.010209832148393265, 'l1_Layer_3': 0.0018552189731930867, 'n_units_Layer_1': 95, 'n_units_Layer_2': 275, 'n_units_Layer_3': 285}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.72 | sMAPE for Validation Set is: 19.36% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 29.19 | sMAPE for Test Set is: 20.71% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:42:32,609]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:42:32,807]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:42:33,998]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:42:41,195]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:42:41,889]\u001b[0m Trial 728 finished with value: 14.286212886902652 and parameters: {'n_hidden': 3, 'learning_rate': 0.0037914337760279124, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.051841357200352406, 'dropout_rate_Layer_2': 0.35894764705769616, 'dropout_rate_Layer_3': 0.11345638663887983, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00955296679817044, 'l1_Layer_2': 0.007132078620341377, 'l1_Layer_3': 0.0022214386743186583, 'n_units_Layer_1': 80, 'n_units_Layer_2': 265, 'n_units_Layer_3': 280}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.29 | sMAPE for Validation Set is: 18.86% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 27.40 | sMAPE for Test Set is: 19.77% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:42:42,575]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:42:46,819]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:42:49,850]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:42:54,657]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:42:55,680]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:42:56,322]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:42:57,247]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:43:03,619]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:43:03,824]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:43:04,472]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:43:09,821]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:43:12,183]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:43:14,300]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:43:25,082]\u001b[0m Trial 746 finished with value: 14.831109061392103 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036102645150758996, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14946902641181994, 'dropout_rate_Layer_2': 0.17650498555752347, 'dropout_rate_Layer_3': 0.04458183937289498, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.04568938702942273, 'l1_Layer_2': 0.02515768839364717, 'l1_Layer_3': 0.0005395893943801167, 'n_units_Layer_1': 95, 'n_units_Layer_2': 195, 'n_units_Layer_3': 200}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.83 | sMAPE for Validation Set is: 19.37% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 29.45 | sMAPE for Test Set is: 20.67% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:43:30,439]\u001b[0m Trial 748 finished with value: 14.854812922242411 and parameters: {'n_hidden': 3, 'learning_rate': 0.004205884196790436, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1463659959370646, 'dropout_rate_Layer_2': 0.17562553120344884, 'dropout_rate_Layer_3': 0.04706691938660895, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.047129381666245154, 'l1_Layer_2': 0.0018909769382924847, 'l1_Layer_3': 0.0005251702951798097, 'n_units_Layer_1': 75, 'n_units_Layer_2': 165, 'n_units_Layer_3': 200}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.85 | sMAPE for Validation Set is: 19.11% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 28.46 | sMAPE for Test Set is: 20.16% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:43:31,657]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:43:35,084]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:43:37,192]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:43:39,412]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:43:42,897]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:43:43,238]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:43:43,829]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:43:51,014]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:43:51,373]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:43:57,134]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:43:57,304]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:44:02,198]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:44:02,371]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:44:03,313]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:44:09,714]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:44:12,739]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:44:13,471]\u001b[0m Trial 759 finished with value: 14.730455028717742 and parameters: {'n_hidden': 3, 'learning_rate': 0.006061130988302689, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.013623276436140577, 'dropout_rate_Layer_2': 0.32677228512343226, 'dropout_rate_Layer_3': 0.13758457127670398, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.010425778588092042, 'l1_Layer_2': 0.017476070957719296, 'l1_Layer_3': 0.002865915239905941, 'n_units_Layer_1': 85, 'n_units_Layer_2': 260, 'n_units_Layer_3': 265}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.73 | sMAPE for Validation Set is: 19.17% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 28.32 | sMAPE for Test Set is: 20.30% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:44:13,882]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:44:19,261]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:44:20,040]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:44:20,272]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:44:28,430]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:44:31,913]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:44:33,822]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:44:37,308]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:44:37,646]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:44:45,178]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:44:45,429]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:44:45,656]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.54 | sMAPE for Validation Set is: 19.28% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 28.40 | sMAPE for Test Set is: 20.27% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:44:52,232]\u001b[0m Trial 773 finished with value: 14.542443836632165 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033248514935683426, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.030260583685123674, 'dropout_rate_Layer_2': 0.3558258711014414, 'dropout_rate_Layer_3': 0.07763798702102032, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.029242605028858146, 'l1_Layer_2': 0.010105498702591887, 'l1_Layer_3': 0.0024510996459920194, 'n_units_Layer_1': 95, 'n_units_Layer_2': 275, 'n_units_Layer_3': 280}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:44:54,140]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:44:56,485]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:44:57,276]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:44:59,097]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:45:02,433]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:45:03,758]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:45:08,697]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:45:10,819]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:45:13,601]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:45:19,334]\u001b[0m Trial 785 finished with value: 14.491904728485887 and parameters: {'n_hidden': 3, 'learning_rate': 0.00451750939667059, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14005024612400577, 'dropout_rate_Layer_2': 0.18578410399965808, 'dropout_rate_Layer_3': 0.05944422075093987, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03528193448627963, 'l1_Layer_2': 0.0014693422482670764, 'l1_Layer_3': 0.0005522234129822384, 'n_units_Layer_1': 75, 'n_units_Layer_2': 165, 'n_units_Layer_3': 200}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.49 | sMAPE for Validation Set is: 18.87% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 29.50 | sMAPE for Test Set is: 20.69% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:45:21,702]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:45:27,773]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:45:27,995]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:45:29,466]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:45:32,717]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:45:33,144]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:45:33,263]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:45:35,029]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:45:40,888]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:45:41,292]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:45:43,021]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:45:46,323]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:45:52,142]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:45:53,777]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:45:55,677]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:46:00,768]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:46:04,556]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:46:04,789]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:46:09,505]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:46:09,692]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:46:15,379]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:46:15,718]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:46:17,188]\u001b[0m Trial 805 finished with value: 15.036490988829058 and parameters: {'n_hidden': 3, 'learning_rate': 0.003391219500711363, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01954966421911198, 'dropout_rate_Layer_2': 0.3447234195236165, 'dropout_rate_Layer_3': 0.1265639787381165, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.039215479096647465, 'l1_Layer_2': 0.016447406027912847, 'l1_Layer_3': 0.004531381717259585, 'n_units_Layer_1': 100, 'n_units_Layer_2': 115, 'n_units_Layer_3': 265}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.04 | sMAPE for Validation Set is: 19.52% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 29.03 | sMAPE for Test Set is: 20.65% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:46:24,807]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:46:24,916]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:46:26,384]\u001b[0m Trial 804 finished with value: 14.587769674828598 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013846457988519068, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39961563417551654, 'dropout_rate_Layer_2': 0.08437561639075239, 'dropout_rate_Layer_3': 0.3457368858973698, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.691412195643094e-05, 'l1_Layer_2': 0.006668759672605883, 'l1_Layer_3': 0.049424936088056245, 'n_units_Layer_1': 280, 'n_units_Layer_2': 100, 'n_units_Layer_3': 220}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.59 | sMAPE for Validation Set is: 19.35% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 28.10 | sMAPE for Test Set is: 20.19% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:46:33,444]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:46:33,603]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:46:33,771]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:46:40,773]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:46:40,986]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:46:41,794]\u001b[0m Trial 812 finished with value: 14.275562758752088 and parameters: {'n_hidden': 3, 'learning_rate': 0.00509825829037497, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3904035625322588, 'dropout_rate_Layer_2': 2.720065642384823e-05, 'dropout_rate_Layer_3': 0.30095669226349836, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008169315502645915, 'l1_Layer_2': 0.005056629027572104, 'l1_Layer_3': 1.9044152307025173e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 250, 'n_units_Layer_3': 110}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.28 | sMAPE for Validation Set is: 18.57% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 28.01 | sMAPE for Test Set is: 20.08% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:46:47,316]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:46:48,789]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:46:49,385]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:46:55,429]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:46:59,592]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:46:59,665]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:47:00,945]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:47:08,226]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:47:08,855]\u001b[0m Trial 818 finished with value: 14.577533510343988 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013621622888369937, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39734480718753956, 'dropout_rate_Layer_2': 0.07736282725026734, 'dropout_rate_Layer_3': 0.3402539072140863, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2203047157802157e-05, 'l1_Layer_2': 0.005853272107347345, 'l1_Layer_3': 0.04808653743257244, 'n_units_Layer_1': 280, 'n_units_Layer_2': 105, 'n_units_Layer_3': 220}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.58 | sMAPE for Validation Set is: 19.05% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 28.54 | sMAPE for Test Set is: 20.33% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:47:09,802]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:47:15,826]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:47:17,789]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:47:19,561]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:47:21,617]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:47:24,660]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:47:26,673]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:47:26,996]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:47:30,946]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:47:35,885]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:47:38,498]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:47:42,727]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:47:47,026]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:47:50,487]\u001b[0m Trial 839 finished with value: 15.045976249558967 and parameters: {'n_hidden': 3, 'learning_rate': 0.005870554283045955, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11827111946062042, 'dropout_rate_Layer_2': 0.224568782977326, 'dropout_rate_Layer_3': 0.022256557903525136, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02985602756715074, 'l1_Layer_2': 0.012481938869639352, 'l1_Layer_3': 0.00021371026910406944, 'n_units_Layer_1': 65, 'n_units_Layer_2': 180, 'n_units_Layer_3': 195}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.05 | sMAPE for Validation Set is: 19.59% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 29.66 | sMAPE for Test Set is: 20.85% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:47:53,844]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:47:54,641]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:47:56,115]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:47:56,760]\u001b[0m Trial 842 finished with value: 14.685294763464723 and parameters: {'n_hidden': 3, 'learning_rate': 0.00579055720763, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.015617350948160679, 'dropout_rate_Layer_2': 0.3218357294907424, 'dropout_rate_Layer_3': 0.141054341321833, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.009818539820457243, 'l1_Layer_2': 0.02101170020663927, 'l1_Layer_3': 0.0024152161644739483, 'n_units_Layer_1': 95, 'n_units_Layer_2': 260, 'n_units_Layer_3': 265}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.69 | sMAPE for Validation Set is: 19.03% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 28.01 | sMAPE for Test Set is: 20.11% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:48:04,184]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:48:04,418]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:48:09,482]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:48:11,985]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:48:13,816]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:48:17,740]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:48:20,256]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:48:20,910]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:48:22,137]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:48:28,954]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:48:29,605]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:48:29,655]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:48:33,253]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:48:36,727]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:48:40,361]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:48:40,758]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:48:45,877]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:48:48,391]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:48:50,099]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:48:50,293]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:48:56,314]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:48:56,947]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:49:01,164]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:49:03,165]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:49:06,841]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:49:07,381]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:49:09,924]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:49:14,552]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:49:16,692]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:49:17,655]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:49:22,587]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:49:23,031]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:49:23,603]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.18 | sMAPE for Validation Set is: 19.64% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 29.20 | sMAPE for Test Set is: 20.66% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:49:28,151]\u001b[0m Trial 872 finished with value: 15.184208830912462 and parameters: {'n_hidden': 3, 'learning_rate': 0.006077789932773422, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14141035031486174, 'dropout_rate_Layer_2': 0.1436123669502089, 'dropout_rate_Layer_3': 0.0933236361530207, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.036119242523946896, 'l1_Layer_2': 0.015569297972323808, 'l1_Layer_3': 0.001234528003162008, 'n_units_Layer_1': 115, 'n_units_Layer_2': 130, 'n_units_Layer_3': 210}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:49:30,812]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:49:33,382]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:49:33,778]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:49:34,729]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:49:35,331]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:49:44,295]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:49:44,581]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:49:44,950]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:49:46,405]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:49:51,525]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:49:52,158]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:49:58,034]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:49:58,744]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:49:59,275]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:50:06,168]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:50:06,836]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:50:07,319]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:50:07,751]\u001b[0m Trial 890 finished with value: 15.711702448606935 and parameters: {'n_hidden': 3, 'learning_rate': 0.009685224325126598, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1669018278224592, 'dropout_rate_Layer_2': 0.09668846630436481, 'dropout_rate_Layer_3': 0.0008101129539054286, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.021237208453824857, 'l1_Layer_2': 0.021972098957692848, 'l1_Layer_3': 0.03763323849125726, 'n_units_Layer_1': 50, 'n_units_Layer_2': 155, 'n_units_Layer_3': 250}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.71 | sMAPE for Validation Set is: 19.80% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 31.18 | sMAPE for Test Set is: 21.69% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:50:11,615]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:50:16,627]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:50:18,702]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:50:21,778]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:50:25,940]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:50:28,917]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:50:31,924]\u001b[0m Trial 900 finished with value: 14.89908221225277 and parameters: {'n_hidden': 3, 'learning_rate': 0.009518073388061562, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12107131257839446, 'dropout_rate_Layer_2': 0.1755755324247561, 'dropout_rate_Layer_3': 0.12074541237184128, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.015799554588407518, 'l1_Layer_2': 0.043166994779651656, 'l1_Layer_3': 0.0006323300027999019, 'n_units_Layer_1': 110, 'n_units_Layer_2': 175, 'n_units_Layer_3': 145}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.90 | sMAPE for Validation Set is: 19.36% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 29.27 | sMAPE for Test Set is: 20.66% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:50:32,241]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:50:35,757]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:50:39,071]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:50:39,233]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:50:40,101]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:50:45,507]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:50:46,462]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:50:51,871]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:50:52,229]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:50:56,218]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:50:57,188]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:50:58,883]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:50:59,973]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:51:01,798]\u001b[0m Trial 913 finished with value: 14.51707803734188 and parameters: {'n_hidden': 4, 'learning_rate': 0.005062121614438582, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10334530443220166, 'dropout_rate_Layer_2': 0.23027426546433902, 'dropout_rate_Layer_3': 0.0361555765543022, 'dropout_rate_Layer_4': 0.29485908308344166, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.1146824848674001e-05, 'l1_Layer_2': 0.03597520681881856, 'l1_Layer_3': 0.0002119864993138171, 'l1_Layer_4': 0.00034121756917846754, 'n_units_Layer_1': 60, 'n_units_Layer_2': 245, 'n_units_Layer_3': 100, 'n_units_Layer_4': 165}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.52 | sMAPE for Validation Set is: 19.29% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 28.35 | sMAPE for Test Set is: 20.13% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:51:05,152]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:51:18,675]\u001b[0m Trial 920 finished with value: 14.561990178433598 and parameters: {'n_hidden': 4, 'learning_rate': 0.0047873054000226725, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.256464002026078, 'dropout_rate_Layer_2': 0.1884810139028908, 'dropout_rate_Layer_3': 0.0400467804104494, 'dropout_rate_Layer_4': 0.2966746002466829, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.006879500076533444, 'l1_Layer_2': 0.0003192488834067823, 'l1_Layer_3': 0.0002206290586609819, 'l1_Layer_4': 0.000281398741107917, 'n_units_Layer_1': 65, 'n_units_Layer_2': 245, 'n_units_Layer_3': 170, 'n_units_Layer_4': 165}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.56 | sMAPE for Validation Set is: 18.83% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 27.90 | sMAPE for Test Set is: 19.73% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:51:21,061]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:51:23,610]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:51:25,185]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.33 | sMAPE for Validation Set is: 19.04% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 28.09 | sMAPE for Test Set is: 19.91% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:51:29,499]\u001b[0m Trial 924 finished with value: 14.330536690424273 and parameters: {'n_hidden': 4, 'learning_rate': 0.004881626112320426, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24580594323747942, 'dropout_rate_Layer_2': 0.11221183056814268, 'dropout_rate_Layer_3': 0.030205843814083592, 'dropout_rate_Layer_4': 0.28405544449367026, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.0862691851471934e-05, 'l1_Layer_2': 0.0363536737890641, 'l1_Layer_3': 0.00021570476161391272, 'l1_Layer_4': 0.00025590920146827855, 'n_units_Layer_1': 60, 'n_units_Layer_2': 225, 'n_units_Layer_3': 50, 'n_units_Layer_4': 165}. Best is trial 344 with value: 14.125512540904282.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:51:33,140]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:51:36,976]\u001b[0m Trial 922 finished with value: 13.943217146445475 and parameters: {'n_hidden': 4, 'learning_rate': 0.00218908802294561, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10109936968509674, 'dropout_rate_Layer_2': 0.11436298589570522, 'dropout_rate_Layer_3': 0.03844596643292153, 'dropout_rate_Layer_4': 0.28970790273803765, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.4923314928163521e-05, 'l1_Layer_2': 0.0350773717410827, 'l1_Layer_3': 0.00023370199953033264, 'l1_Layer_4': 0.0002481216891206705, 'n_units_Layer_1': 60, 'n_units_Layer_2': 225, 'n_units_Layer_3': 90, 'n_units_Layer_4': 165}. Best is trial 922 with value: 13.943217146445475.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.94 | sMAPE for Validation Set is: 18.43% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 27.56 | sMAPE for Test Set is: 19.75% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:51:37,596]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:51:38,020]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:51:43,613]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:51:47,088]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:51:47,804]\u001b[0m Trial 927 finished with value: 14.569995580665227 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034590373489451058, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.024626845167354548, 'dropout_rate_Layer_2': 0.3350643949607697, 'dropout_rate_Layer_3': 0.07762821118166632, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.009241932519281027, 'l1_Layer_2': 0.014185407747334011, 'l1_Layer_3': 2.7990152658093467e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 250, 'n_units_Layer_3': 280}. Best is trial 922 with value: 13.943217146445475.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.57 | sMAPE for Validation Set is: 18.83% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 28.45 | sMAPE for Test Set is: 20.28% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:51:48,049]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:51:54,995]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:51:55,855]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:51:56,019]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:52:02,221]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:52:05,211]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:52:06,207]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:52:08,204]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:52:10,054]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.74 | sMAPE for Validation Set is: 18.83% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 29.57 | sMAPE for Test Set is: 20.61% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:52:13,162]\u001b[0m Trial 933 finished with value: 14.736766587367882 and parameters: {'n_hidden': 4, 'learning_rate': 0.0020670864087982284, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26863391130248643, 'dropout_rate_Layer_2': 0.10872122308375927, 'dropout_rate_Layer_3': 0.03449018048939211, 'dropout_rate_Layer_4': 0.28587458758597567, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.1918439359586854e-05, 'l1_Layer_2': 7.158470140054035e-05, 'l1_Layer_3': 0.00022395974341738215, 'l1_Layer_4': 0.00022277116726906752, 'n_units_Layer_1': 60, 'n_units_Layer_2': 220, 'n_units_Layer_3': 50, 'n_units_Layer_4': 170}. Best is trial 922 with value: 13.943217146445475.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:52:17,425]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:52:21,067]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:52:21,477]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:52:27,888]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:52:28,206]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:52:28,316]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.78 | sMAPE for Validation Set is: 19.28% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 28.68 | sMAPE for Test Set is: 20.41% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:52:34,287]\u001b[0m Trial 943 finished with value: 14.77635877934248 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036289575530447297, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02819332338608707, 'dropout_rate_Layer_2': 0.3229360203707635, 'dropout_rate_Layer_3': 0.06809921962302035, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.011716500022297016, 'l1_Layer_2': 0.013326298359111829, 'l1_Layer_3': 0.00296757415311938, 'n_units_Layer_1': 85, 'n_units_Layer_2': 255, 'n_units_Layer_3': 270}. Best is trial 922 with value: 13.943217146445475.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:52:36,164]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:52:37,129]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:52:38,131]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:52:42,924]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:52:48,020]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:52:49,478]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:52:50,469]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:52:52,597]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:52:59,859]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:53:03,454]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:53:03,616]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:53:03,692]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:53:04,728]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:53:15,022]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:53:19,716]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:53:23,093]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:53:26,579]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:53:29,304]\u001b[0m Trial 963 finished with value: 14.309816777251063 and parameters: {'n_hidden': 3, 'learning_rate': 0.003015984190009077, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.019883088254129065, 'dropout_rate_Layer_2': 0.3000176383692057, 'dropout_rate_Layer_3': 0.15797116107596093, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.02523017307328704, 'l1_Layer_2': 0.005295947925789114, 'l1_Layer_3': 4.4600506813132904e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 260, 'n_units_Layer_3': 290}. Best is trial 922 with value: 13.943217146445475.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.31 | sMAPE for Validation Set is: 18.50% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 28.32 | sMAPE for Test Set is: 20.17% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:53:31,991]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:53:32,747]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:53:32,906]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:53:37,160]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:53:39,053]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:53:40,707]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:53:46,592]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:53:49,775]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:53:50,378]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:53:52,932]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:54:00,137]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:54:03,550]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:54:06,136]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:54:08,155]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:54:10,731]\u001b[0m Trial 980 finished with value: 14.540959970868945 and parameters: {'n_hidden': 3, 'learning_rate': 0.002964296430699704, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.024803506519261387, 'dropout_rate_Layer_2': 0.2972688846699358, 'dropout_rate_Layer_3': 0.1731216861447162, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.026460020200977586, 'l1_Layer_2': 0.0037050177392508083, 'l1_Layer_3': 3.9654454037996914e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 250, 'n_units_Layer_3': 295}. Best is trial 922 with value: 13.943217146445475.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.54 | sMAPE for Validation Set is: 18.81% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 29.07 | sMAPE for Test Set is: 20.64% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:54:12,378]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:54:14,780]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:54:18,011]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:54:19,024]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:54:22,625]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:54:24,427]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:54:27,958]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:54:28,600]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:54:28,884]\u001b[0m Trial 979 finished with value: 15.36457430418116 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005885128027022274, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29390262898218883, 'dropout_rate_Layer_2': 0.06802883214038627, 'dropout_rate_Layer_3': 0.014663124326599431, 'dropout_rate_Layer_4': 0.3708453238548505, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.3974603743133765e-05, 'l1_Layer_2': 0.0012776541015012597, 'l1_Layer_3': 0.00018161469399999522, 'l1_Layer_4': 2.894642707258013e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 215, 'n_units_Layer_3': 70, 'n_units_Layer_4': 190}. Best is trial 922 with value: 13.943217146445475.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.36 | sMAPE for Validation Set is: 19.84% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 28.39 | sMAPE for Test Set is: 20.00% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:54:35,178]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:54:38,366]\u001b[0m Trial 988 finished with value: 15.218156732595636 and parameters: {'n_hidden': 4, 'learning_rate': 0.002469707146048964, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2934601605474285, 'dropout_rate_Layer_2': 0.0641726334309564, 'dropout_rate_Layer_3': 0.014884242697756993, 'dropout_rate_Layer_4': 0.36109639932069476, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.4612217229469403e-05, 'l1_Layer_2': 0.0003532238748877744, 'l1_Layer_3': 0.00017971926548884234, 'l1_Layer_4': 2.3404222718190822e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 210, 'n_units_Layer_3': 75, 'n_units_Layer_4': 190}. Best is trial 922 with value: 13.943217146445475.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.22 | sMAPE for Validation Set is: 19.68% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 28.95 | sMAPE for Test Set is: 20.34% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:54:40,573]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:54:43,417]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:54:47,148]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:54:47,213]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:54:47,793]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:54:56,037]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:54:56,715]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:55:00,299]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:55:01,698]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:55:02,733]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:55:07,762]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:55:08,207]\u001b[0m Trial 1000 finished with value: 59.68788873585464 and parameters: {'n_hidden': 4, 'learning_rate': 0.006683503228942204, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24393057445731495, 'dropout_rate_Layer_2': 0.22026597149484745, 'dropout_rate_Layer_3': 0.06934433056147883, 'dropout_rate_Layer_4': 0.30437909406633423, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.8366450875911307e-05, 'l1_Layer_2': 0.0007347941104766466, 'l1_Layer_3': 0.00039423822982245066, 'l1_Layer_4': 0.00011791747264543195, 'n_units_Layer_1': 75, 'n_units_Layer_2': 230, 'n_units_Layer_3': 130, 'n_units_Layer_4': 155}. Best is trial 922 with value: 13.943217146445475.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 59.69 | sMAPE for Validation Set is: 57.44% | rMAE for Validation Set is: 2.40\n",
      "MAE for Test Set is: 108.70 | sMAPE for Test Set is: 88.31% | rMAE for Test Set is: 2.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:55:08,812]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:55:11,460]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:55:19,283]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:55:20,227]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:55:21,238]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:55:23,198]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:55:31,119]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:55:34,878]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:55:37,836]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:55:38,384]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:55:39,563]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:55:45,397]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:55:50,701]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:55:50,804]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:55:58,336]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:55:58,855]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:56:03,898]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:56:06,567]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:56:11,028]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:56:11,204]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:56:11,511]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:56:18,632]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:56:18,927]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:56:25,900]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:56:30,402]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:56:32,922]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:56:36,357]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:56:39,298]\u001b[0m Trial 1029 finished with value: 14.337066933029854 and parameters: {'n_hidden': 4, 'learning_rate': 0.00401160460439907, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12797346207905705, 'dropout_rate_Layer_2': 0.2519778761529435, 'dropout_rate_Layer_3': 0.03297007989699939, 'dropout_rate_Layer_4': 0.3372274118727943, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.2784135998625965e-05, 'l1_Layer_2': 0.03339360262016938, 'l1_Layer_3': 0.00013207430405506166, 'l1_Layer_4': 0.0007830369783031898, 'n_units_Layer_1': 70, 'n_units_Layer_2': 245, 'n_units_Layer_3': 155, 'n_units_Layer_4': 170}. Best is trial 922 with value: 13.943217146445475.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.34 | sMAPE for Validation Set is: 19.05% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 27.76 | sMAPE for Test Set is: 19.87% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:56:39,687]\u001b[0m Trial 1025 finished with value: 14.452872517766844 and parameters: {'n_hidden': 3, 'learning_rate': 0.001230654879117062, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33070710766842076, 'dropout_rate_Layer_2': 0.2343507474934135, 'dropout_rate_Layer_3': 0.29074134274922964, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2028476155138466e-05, 'l1_Layer_2': 0.004353501221473505, 'l1_Layer_3': 0.03914063206412003, 'n_units_Layer_1': 280, 'n_units_Layer_2': 130, 'n_units_Layer_3': 195}. Best is trial 922 with value: 13.943217146445475.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:56:39,797]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.45 | sMAPE for Validation Set is: 19.34% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 27.01 | sMAPE for Test Set is: 19.59% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:56:47,726]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:56:47,894]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:56:48,579]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:56:58,426]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:57:01,365]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:57:01,587]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:57:02,074]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:57:02,756]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:57:13,533]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:57:17,706]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:57:17,980]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:57:26,493]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:57:27,112]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:57:31,569]\u001b[0m Trial 1046 finished with value: 13.936954577168938 and parameters: {'n_hidden': 4, 'learning_rate': 0.004151683725029321, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12820397769126082, 'dropout_rate_Layer_2': 0.2600886317258595, 'dropout_rate_Layer_3': 0.03608215971798316, 'dropout_rate_Layer_4': 0.3472749279009032, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.0341662488454413e-05, 'l1_Layer_2': 0.013640630813126081, 'l1_Layer_3': 0.00012663685399248934, 'l1_Layer_4': 0.0008517065026700972, 'n_units_Layer_1': 70, 'n_units_Layer_2': 250, 'n_units_Layer_3': 160, 'n_units_Layer_4': 170}. Best is trial 1046 with value: 13.936954577168938.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.94 | sMAPE for Validation Set is: 18.71% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 27.05 | sMAPE for Test Set is: 19.39% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:57:33,393]\u001b[0m Trial 1047 finished with value: 14.427422831440325 and parameters: {'n_hidden': 4, 'learning_rate': 0.005532451906399008, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12566470483403752, 'dropout_rate_Layer_2': 0.2494557347411917, 'dropout_rate_Layer_3': 0.03650235231380742, 'dropout_rate_Layer_4': 0.29921509975096205, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.0044442923970578e-05, 'l1_Layer_2': 0.03374874254959249, 'l1_Layer_3': 0.00011489799543371397, 'l1_Layer_4': 0.0007559201184625693, 'n_units_Layer_1': 70, 'n_units_Layer_2': 245, 'n_units_Layer_3': 85, 'n_units_Layer_4': 170}. Best is trial 1046 with value: 13.936954577168938.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.43 | sMAPE for Validation Set is: 19.05% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 27.74 | sMAPE for Test Set is: 19.83% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:57:33,716]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:57:44,360]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:57:48,197]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:57:48,951]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:57:54,019]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:57:55,314]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:57:56,979]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:58:02,808]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:58:07,309]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:58:11,779]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:58:12,286]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:58:18,852]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:58:25,813]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:58:26,303]\u001b[0m Trial 1060 finished with value: 14.414730772377169 and parameters: {'n_hidden': 4, 'learning_rate': 0.003944638368646098, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12928839712764925, 'dropout_rate_Layer_2': 0.2552639747867104, 'dropout_rate_Layer_3': 0.05691970846894698, 'dropout_rate_Layer_4': 0.39481529050837205, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.701510774335958e-05, 'l1_Layer_2': 0.018619740517511234, 'l1_Layer_3': 0.00010938171499523773, 'l1_Layer_4': 0.001314877027612321, 'n_units_Layer_1': 85, 'n_units_Layer_2': 180, 'n_units_Layer_3': 90, 'n_units_Layer_4': 180}. Best is trial 1046 with value: 13.936954577168938.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.41 | sMAPE for Validation Set is: 19.20% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 28.08 | sMAPE for Test Set is: 20.03% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:58:32,501]\u001b[0m Trial 1054 finished with value: 14.518934212255965 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012053407243243198, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3781988420419641, 'dropout_rate_Layer_2': 0.22741752984605382, 'dropout_rate_Layer_3': 0.30147815100216646, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1841036215707762e-05, 'l1_Layer_2': 0.0046307034833387994, 'l1_Layer_3': 0.039101395849142566, 'n_units_Layer_1': 290, 'n_units_Layer_2': 140, 'n_units_Layer_3': 205}. Best is trial 1046 with value: 13.936954577168938.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.52 | sMAPE for Validation Set is: 19.23% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 27.64 | sMAPE for Test Set is: 19.98% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:58:32,879]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:58:38,035]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:58:39,394]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:58:43,807]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:58:44,672]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:58:50,172]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:58:50,221]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:58:57,323]\u001b[0m Trial 1067 finished with value: 14.165772678541293 and parameters: {'n_hidden': 4, 'learning_rate': 0.004112255605967487, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1299683097443124, 'dropout_rate_Layer_2': 0.2620538914364315, 'dropout_rate_Layer_3': 0.02975677668063452, 'dropout_rate_Layer_4': 0.3888355947999679, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.2131247171539576e-05, 'l1_Layer_2': 0.014997294781694523, 'l1_Layer_3': 0.00010337798944515916, 'l1_Layer_4': 0.0008761705387860223, 'n_units_Layer_1': 85, 'n_units_Layer_2': 235, 'n_units_Layer_3': 85, 'n_units_Layer_4': 180}. Best is trial 1046 with value: 13.936954577168938.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.17 | sMAPE for Validation Set is: 19.03% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 28.15 | sMAPE for Test Set is: 20.08% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 08:58:57,962]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:58:59,024]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:59:05,772]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:59:08,499]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:59:09,854]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:59:09,900]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:59:10,774]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:59:19,432]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:59:23,997]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:59:24,744]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:59:25,498]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:59:25,662]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:59:33,635]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:59:36,768]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:59:37,017]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:59:40,712]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:59:41,197]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:59:51,256]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:59:52,100]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:59:55,807]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 08:59:58,482]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:00:04,808]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:00:08,326]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:00:08,509]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:00:09,249]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:00:19,184]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:00:19,478]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:00:21,167]\u001b[0m Trial 1095 finished with value: 14.17869123965169 and parameters: {'n_hidden': 3, 'learning_rate': 0.003525675323322599, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03870437565157936, 'dropout_rate_Layer_2': 0.34661325914464197, 'dropout_rate_Layer_3': 0.07255913440858171, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012650649495415083, 'l1_Layer_2': 0.012803325025434104, 'l1_Layer_3': 5.399022965693487e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 265, 'n_units_Layer_3': 285}. Best is trial 1046 with value: 13.936954577168938.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.18 | sMAPE for Validation Set is: 18.30% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 27.79 | sMAPE for Test Set is: 19.93% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 09:00:28,300]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:00:29,527]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:00:36,009]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:00:38,886]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:00:39,712]\u001b[0m Trial 1102 finished with value: 14.916555383551719 and parameters: {'n_hidden': 3, 'learning_rate': 0.00303834403046592, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0318865948789569, 'dropout_rate_Layer_2': 0.34689315753179295, 'dropout_rate_Layer_3': 0.08626986440649517, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00974216969426066, 'l1_Layer_2': 0.014221960266805358, 'l1_Layer_3': 2.1387300733693608e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 285, 'n_units_Layer_3': 115}. Best is trial 1046 with value: 13.936954577168938.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.92 | sMAPE for Validation Set is: 19.10% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 29.30 | sMAPE for Test Set is: 20.75% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 09:00:40,626]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:00:49,068]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:00:50,040]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:00:51,192]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:00:53,345]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:00:53,721]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:00:59,202]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:01:02,727]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:01:05,289]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:01:09,100]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:01:14,319]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:01:18,130]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:01:20,450]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:01:21,130]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:01:29,385]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:01:33,232]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:01:34,663]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:01:41,586]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:01:47,316]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:01:51,729]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:01:56,651]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:02:00,551]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:02:05,092]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:02:09,121]\u001b[0m Trial 1126 finished with value: 13.88962519620162 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024269118914915207, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04131103179711157, 'dropout_rate_Layer_2': 0.36271840431603236, 'dropout_rate_Layer_3': 0.33663800485162576, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.010735693502747593, 'l1_Layer_2': 0.003763033829517811, 'l1_Layer_3': 1.1366312423060554e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 270, 'n_units_Layer_3': 130}. Best is trial 1126 with value: 13.88962519620162.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.89 | sMAPE for Validation Set is: 18.30% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 27.77 | sMAPE for Test Set is: 19.84% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 09:02:09,728]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:02:12,849]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:02:15,863]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:02:21,486]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:02:22,164]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:02:28,353]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:02:30,962]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:02:31,104]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:02:33,259]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:02:38,676]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:02:39,607]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:02:40,248]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:02:45,907]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:02:51,177]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:02:54,080]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:02:55,046]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:02:55,518]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:03:02,217]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:03:02,777]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:03:09,320]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:03:12,731]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:03:15,109]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.11 | sMAPE for Validation Set is: 19.21% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 29.29 | sMAPE for Test Set is: 20.75% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 09:03:17,427]\u001b[0m Trial 1128 finished with value: 15.105037697808925 and parameters: {'n_hidden': 3, 'learning_rate': 0.000955876220236203, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3553073822840044, 'dropout_rate_Layer_2': 0.1899768903476574, 'dropout_rate_Layer_3': 0.34414496684834583, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.739870487498987e-05, 'l1_Layer_2': 0.007316599282922643, 'l1_Layer_3': 0.018482418767531334, 'n_units_Layer_1': 230, 'n_units_Layer_2': 150, 'n_units_Layer_3': 215}. Best is trial 1126 with value: 13.88962519620162.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:03:18,327]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:03:25,740]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:03:25,901]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:03:27,432]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:03:34,491]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:03:35,082]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:03:36,125]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:03:39,471]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:03:39,506]\u001b[0m Trial 1151 finished with value: 14.20370818750069 and parameters: {'n_hidden': 4, 'learning_rate': 0.003012696213298523, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07121969992235189, 'dropout_rate_Layer_2': 0.25858282606994076, 'dropout_rate_Layer_3': 0.11694681458556694, 'dropout_rate_Layer_4': 0.38739473546328085, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 6.630103604669882e-05, 'l1_Layer_2': 0.01440098362077361, 'l1_Layer_3': 6.679494252329506e-05, 'l1_Layer_4': 0.0007633966057335254, 'n_units_Layer_1': 55, 'n_units_Layer_2': 220, 'n_units_Layer_3': 65, 'n_units_Layer_4': 175}. Best is trial 1126 with value: 13.88962519620162.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.20 | sMAPE for Validation Set is: 18.44% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 27.27 | sMAPE for Test Set is: 19.45% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 09:03:41,535]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:03:50,110]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:03:51,208]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:03:51,630]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:03:51,816]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:03:58,460]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:03:59,099]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:04:07,017]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:04:07,170]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:04:08,689]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:04:14,507]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:04:16,275]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:04:18,867]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:04:22,805]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:04:24,381]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:04:29,580]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:04:29,849]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:04:36,645]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:04:39,635]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:04:42,387]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:04:43,157]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:04:43,615]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:04:52,939]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:04:55,864]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:04:59,309]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:04:59,907]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:05:05,847]\u001b[0m Trial 1181 finished with value: 14.146457541810287 and parameters: {'n_hidden': 4, 'learning_rate': 0.002110918641559176, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11065681968260199, 'dropout_rate_Layer_2': 0.28895678925662094, 'dropout_rate_Layer_3': 0.01095444060666836, 'dropout_rate_Layer_4': 0.376483022222361, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 7.25530973010642e-05, 'l1_Layer_2': 0.014654073299328555, 'l1_Layer_3': 5.0971736788294096e-05, 'l1_Layer_4': 0.0007344214835129818, 'n_units_Layer_1': 55, 'n_units_Layer_2': 250, 'n_units_Layer_3': 65, 'n_units_Layer_4': 175}. Best is trial 1126 with value: 13.88962519620162.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.15 | sMAPE for Validation Set is: 19.03% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 27.25 | sMAPE for Test Set is: 19.57% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 09:05:06,541]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:05:07,879]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:05:12,828]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:05:15,602]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:05:20,561]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:05:20,720]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:05:22,658]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:05:27,242]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:05:29,054]\u001b[0m Trial 1189 finished with value: 14.36769503334159 and parameters: {'n_hidden': 4, 'learning_rate': 0.0023185560206484108, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07301426667795723, 'dropout_rate_Layer_2': 0.2654976496793956, 'dropout_rate_Layer_3': 0.010801454218468107, 'dropout_rate_Layer_4': 0.37433517419687146, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.858609252044343e-05, 'l1_Layer_2': 0.050490623288491986, 'l1_Layer_3': 0.00010720873924915186, 'l1_Layer_4': 0.0007578428854485215, 'n_units_Layer_1': 85, 'n_units_Layer_2': 235, 'n_units_Layer_3': 70, 'n_units_Layer_4': 175}. Best is trial 1126 with value: 13.88962519620162.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.37 | sMAPE for Validation Set is: 19.24% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 28.05 | sMAPE for Test Set is: 19.99% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 09:05:30,327]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:05:34,387]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:05:38,922]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:05:39,423]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:05:45,307]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:05:46,347]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:05:51,890]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:05:54,301]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:06:02,980]\u001b[0m Trial 1202 finished with value: 14.367495847059137 and parameters: {'n_hidden': 4, 'learning_rate': 0.002194622377111352, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06140783313811535, 'dropout_rate_Layer_2': 0.26630925754165913, 'dropout_rate_Layer_3': 0.012117533272480187, 'dropout_rate_Layer_4': 0.37500538545908296, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 6.964288043948532e-05, 'l1_Layer_2': 0.0511299328827343, 'l1_Layer_3': 6.58206081841303e-05, 'l1_Layer_4': 0.0015015732268414427, 'n_units_Layer_1': 85, 'n_units_Layer_2': 250, 'n_units_Layer_3': 65, 'n_units_Layer_4': 175}. Best is trial 1126 with value: 13.88962519620162.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.37 | sMAPE for Validation Set is: 19.25% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 27.87 | sMAPE for Test Set is: 19.91% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 09:06:07,921]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:06:08,182]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:06:15,658]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:06:16,571]\u001b[0m Trial 1203 finished with value: 14.1185007187849 and parameters: {'n_hidden': 3, 'learning_rate': 0.00131122186936334, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3388722771615216, 'dropout_rate_Layer_2': 0.14508085532795942, 'dropout_rate_Layer_3': 0.18649998475502677, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5554161601244627e-05, 'l1_Layer_2': 0.0032335279940295006, 'l1_Layer_3': 0.029351510148068978, 'n_units_Layer_1': 220, 'n_units_Layer_2': 135, 'n_units_Layer_3': 200}. Best is trial 1126 with value: 13.88962519620162.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.12 | sMAPE for Validation Set is: 18.34% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 27.36 | sMAPE for Test Set is: 19.76% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 09:06:16,933]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:06:23,984]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:06:26,585]\u001b[0m Trial 1209 finished with value: 14.385933450262861 and parameters: {'n_hidden': 4, 'learning_rate': 0.002265624006832161, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07277810799664104, 'dropout_rate_Layer_2': 0.26701023724443396, 'dropout_rate_Layer_3': 0.009045844132559145, 'dropout_rate_Layer_4': 0.37151813770640957, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 7.512809196800968e-05, 'l1_Layer_2': 0.05101144036681881, 'l1_Layer_3': 6.670666864036854e-05, 'l1_Layer_4': 0.0016615262182193221, 'n_units_Layer_1': 85, 'n_units_Layer_2': 235, 'n_units_Layer_3': 70, 'n_units_Layer_4': 175}. Best is trial 1126 with value: 13.88962519620162.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.39 | sMAPE for Validation Set is: 19.06% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 28.12 | sMAPE for Test Set is: 20.05% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 09:06:28,096]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:06:31,942]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:06:34,228]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:06:39,888]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:06:40,951]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:06:46,726]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:06:49,992]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:06:50,584]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:06:50,762]\u001b[0m Trial 1216 finished with value: 14.752661894952785 and parameters: {'n_hidden': 3, 'learning_rate': 0.003434857146933249, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014683548559325563, 'dropout_rate_Layer_2': 0.3517771081681312, 'dropout_rate_Layer_3': 0.1724346945680928, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.016772438989933622, 'l1_Layer_2': 0.018783292873035148, 'l1_Layer_3': 4.057717885264036e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 265, 'n_units_Layer_3': 290}. Best is trial 1126 with value: 13.88962519620162.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.75 | sMAPE for Validation Set is: 18.95% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 29.40 | sMAPE for Test Set is: 20.78% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 09:06:58,005]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:06:58,863]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:07:04,025]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:07:07,912]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:07:08,095]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:07:08,308]\u001b[0m Trial 1215 finished with value: 14.432526972999783 and parameters: {'n_hidden': 3, 'learning_rate': 0.001094209631115184, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33713468476625913, 'dropout_rate_Layer_2': 0.15146182713967174, 'dropout_rate_Layer_3': 0.17942517582762127, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.0477647952650086e-05, 'l1_Layer_2': 0.003307460615059396, 'l1_Layer_3': 0.042159518260409, 'n_units_Layer_1': 205, 'n_units_Layer_2': 145, 'n_units_Layer_3': 190}. Best is trial 1126 with value: 13.88962519620162.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.43 | sMAPE for Validation Set is: 18.96% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 27.17 | sMAPE for Test Set is: 19.68% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 09:07:08,699]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:07:16,966]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:07:23,634]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:07:23,818]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:07:30,878]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:07:34,455]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:07:40,434]\u001b[0m Trial 1234 finished with value: 14.258794174962423 and parameters: {'n_hidden': 3, 'learning_rate': 0.002557896044087513, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02303139674472994, 'dropout_rate_Layer_2': 0.3381439669999002, 'dropout_rate_Layer_3': 0.2455026528465145, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.009188955378679189, 'l1_Layer_2': 0.0055537611397760474, 'l1_Layer_3': 2.473836453802829e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 250, 'n_units_Layer_3': 275}. Best is trial 1126 with value: 13.88962519620162.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.26 | sMAPE for Validation Set is: 18.77% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 27.61 | sMAPE for Test Set is: 19.91% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 09:07:41,342]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:07:45,790]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:07:49,636]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:07:53,220]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:07:55,951]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:07:57,309]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:07:58,271]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:07:59,487]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:08:02,052]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:08:07,989]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:08:10,440]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:08:12,914]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:08:14,579]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:08:17,544]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:08:22,235]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:08:23,729]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:08:25,424]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:08:35,263]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:08:35,715]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:08:35,897]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:08:36,929]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:08:44,943]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:08:46,475]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:08:47,417]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:08:47,564]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:08:56,748]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:08:57,078]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:08:58,477]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:08:59,247]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:09:04,340]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:09:04,891]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:09:09,697]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:09:09,981]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:09:15,426]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:09:18,244]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:09:18,815]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:09:24,500]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:09:30,045]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:09:31,541]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:09:35,402]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:09:35,478]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:09:41,139]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:09:41,655]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:09:49,116]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:09:52,932]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:09:56,057]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:10:00,061]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:10:03,374]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:10:05,736]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:10:09,568]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:10:10,496]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:10:15,928]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:10:16,537]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:10:17,250]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:10:17,627]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:10:26,932]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:10:29,597]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:10:30,863]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:10:32,195]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:10:32,804]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:10:40,288]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:10:40,984]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:10:42,515]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:10:50,388]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:10:53,097]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:10:56,247]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:11:00,811]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:11:01,084]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:11:08,304]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:11:08,669]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.53 | sMAPE for Validation Set is: 18.79% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 28.71 | sMAPE for Test Set is: 20.43% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 09:11:12,851]\u001b[0m Trial 1299 finished with value: 14.532170792986783 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010664895330384592, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3009197389310516, 'dropout_rate_Layer_2': 0.13653457744076158, 'dropout_rate_Layer_3': 0.18669855290135728, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5497535358279257e-05, 'l1_Layer_2': 0.002353382872882678, 'l1_Layer_3': 0.028913773128550323, 'n_units_Layer_1': 205, 'n_units_Layer_2': 145, 'n_units_Layer_3': 210}. Best is trial 1126 with value: 13.88962519620162.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:11:14,886]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:11:16,745]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:11:17,764]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:11:24,201]\u001b[0m Trial 1305 finished with value: 14.447217861243024 and parameters: {'n_hidden': 4, 'learning_rate': 0.002110582983407422, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09234176906784082, 'dropout_rate_Layer_2': 0.24026779802323064, 'dropout_rate_Layer_3': 0.012595502551234317, 'dropout_rate_Layer_4': 0.3675499881554211, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.6079767497730574e-05, 'l1_Layer_2': 0.06124741106636078, 'l1_Layer_3': 4.320199719695105e-05, 'l1_Layer_4': 0.0017298509388862877, 'n_units_Layer_1': 90, 'n_units_Layer_2': 235, 'n_units_Layer_3': 65, 'n_units_Layer_4': 160}. Best is trial 1126 with value: 13.88962519620162.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.45 | sMAPE for Validation Set is: 19.23% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 27.42 | sMAPE for Test Set is: 19.71% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 09:11:25,159]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:11:30,015]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:11:33,942]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:11:38,418]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:11:43,155]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:11:50,949]\u001b[0m Trial 1313 finished with value: 14.232082503987423 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010839921158522813, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29568659897307753, 'dropout_rate_Layer_2': 0.1294547158059553, 'dropout_rate_Layer_3': 0.1870635469691685, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.6079115574336573e-05, 'l1_Layer_2': 0.0022444581224727264, 'l1_Layer_3': 0.029014008731762655, 'n_units_Layer_1': 210, 'n_units_Layer_2': 155, 'n_units_Layer_3': 210}. Best is trial 1126 with value: 13.88962519620162.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.23 | sMAPE for Validation Set is: 18.76% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 27.66 | sMAPE for Test Set is: 19.94% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 09:11:54,519]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:12:04,010]\u001b[0m Trial 1312 finished with value: 14.342327012144432 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010841517428244747, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.299621946656708, 'dropout_rate_Layer_2': 0.13589071021921248, 'dropout_rate_Layer_3': 0.19476046198044059, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.786596411777537e-05, 'l1_Layer_2': 0.002280376685321431, 'l1_Layer_3': 0.029672599605002105, 'n_units_Layer_1': 210, 'n_units_Layer_2': 135, 'n_units_Layer_3': 210}. Best is trial 1126 with value: 13.88962519620162.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.34 | sMAPE for Validation Set is: 18.69% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 28.43 | sMAPE for Test Set is: 20.26% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 09:12:06,972]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:12:08,860]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:12:12,254]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:12:13,439]\u001b[0m Trial 1320 finished with value: 14.354377618877137 and parameters: {'n_hidden': 3, 'learning_rate': 0.00131309543310316, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3005027518285525, 'dropout_rate_Layer_2': 0.13730728955791197, 'dropout_rate_Layer_3': 0.19043216983588862, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5452019424182607e-05, 'l1_Layer_2': 0.0023913865310402583, 'l1_Layer_3': 0.025900093084387798, 'n_units_Layer_1': 210, 'n_units_Layer_2': 155, 'n_units_Layer_3': 210}. Best is trial 1126 with value: 13.88962519620162.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.35 | sMAPE for Validation Set is: 18.79% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 27.71 | sMAPE for Test Set is: 19.90% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 09:12:13,643]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:12:21,479]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:12:25,255]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:12:25,610]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:12:25,611]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:12:29,810]\u001b[0m Trial 1324 finished with value: 14.230829983729889 and parameters: {'n_hidden': 4, 'learning_rate': 0.002702043259523177, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05667039680937568, 'dropout_rate_Layer_2': 0.32459596179029054, 'dropout_rate_Layer_3': 0.01802275189099552, 'dropout_rate_Layer_4': 0.32920719528144426, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.630737960259723e-05, 'l1_Layer_2': 0.020647430191432354, 'l1_Layer_3': 0.00016051447977123503, 'l1_Layer_4': 0.0015531085774138857, 'n_units_Layer_1': 70, 'n_units_Layer_2': 235, 'n_units_Layer_3': 55, 'n_units_Layer_4': 185}. Best is trial 1126 with value: 13.88962519620162.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.23 | sMAPE for Validation Set is: 19.04% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 27.92 | sMAPE for Test Set is: 19.90% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 09:12:35,917]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:12:36,603]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:12:37,866]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:12:38,150]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:12:42,278]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:12:48,568]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:12:50,060]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:12:50,345]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:12:56,917]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:12:57,245]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:12:57,902]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:13:06,634]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:13:09,550]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:13:09,551]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:13:10,812]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:13:17,934]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:13:20,312]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:13:23,861]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:13:29,127]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:13:32,711]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:13:36,512]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:13:36,763]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:13:42,485]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:13:47,017]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:13:50,943]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:13:53,731]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:13:54,794]\u001b[0m Trial 1346 finished with value: 14.260389406359172 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013963947838941636, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2949414425465494, 'dropout_rate_Layer_2': 0.12026183398238514, 'dropout_rate_Layer_3': 0.18939803033340835, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5110584046569397e-05, 'l1_Layer_2': 0.002579477079184095, 'l1_Layer_3': 0.03749660816626544, 'n_units_Layer_1': 215, 'n_units_Layer_2': 135, 'n_units_Layer_3': 205}. Best is trial 1126 with value: 13.88962519620162.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.26 | sMAPE for Validation Set is: 18.58% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 26.81 | sMAPE for Test Set is: 19.49% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 09:14:00,240]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:14:00,615]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:14:06,472]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:14:10,382]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:14:11,447]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:14:13,908]\u001b[0m Trial 1353 finished with value: 14.042425124631913 and parameters: {'n_hidden': 4, 'learning_rate': 0.0027463334072645534, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06111949704872165, 'dropout_rate_Layer_2': 0.3241722495775843, 'dropout_rate_Layer_3': 0.02718665260381814, 'dropout_rate_Layer_4': 0.33133520141595796, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.7072357634685777e-05, 'l1_Layer_2': 0.020868883528768537, 'l1_Layer_3': 0.0001368567022259733, 'l1_Layer_4': 0.000455959449275207, 'n_units_Layer_1': 70, 'n_units_Layer_2': 225, 'n_units_Layer_3': 55, 'n_units_Layer_4': 185}. Best is trial 1126 with value: 13.88962519620162.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.04 | sMAPE for Validation Set is: 18.53% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 27.09 | sMAPE for Test Set is: 19.40% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 09:14:15,937]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:14:17,807]\u001b[0m Trial 1360 finished with value: 14.31596159973624 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029567451593342955, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.034257078199443805, 'dropout_rate_Layer_2': 0.2611392954370839, 'dropout_rate_Layer_3': 0.19836206548148044, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01937788018672986, 'l1_Layer_2': 0.0055684725985444515, 'l1_Layer_3': 2.4366059833505043e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 260, 'n_units_Layer_3': 290}. Best is trial 1126 with value: 13.88962519620162.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.32 | sMAPE for Validation Set is: 18.71% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 28.45 | sMAPE for Test Set is: 20.27% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 09:14:24,843]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:14:27,279]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:14:27,646]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:14:32,906]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:14:33,836]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:14:34,943]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:14:35,657]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:14:44,042]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:14:45,407]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:14:49,497]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:14:50,713]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:14:56,147]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:14:58,164]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:15:02,054]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:15:03,606]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:15:08,004]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:15:11,032]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:15:13,197]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:15:15,842]\u001b[0m Trial 1377 finished with value: 14.452201718265115 and parameters: {'n_hidden': 3, 'learning_rate': 0.003403800299890391, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04136963596084253, 'dropout_rate_Layer_2': 0.37193407879499957, 'dropout_rate_Layer_3': 0.1986851437551012, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.022802423124145915, 'l1_Layer_2': 0.004775001480083623, 'l1_Layer_3': 2.0198790906925163e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 125, 'n_units_Layer_3': 285}. Best is trial 1126 with value: 13.88962519620162.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.45 | sMAPE for Validation Set is: 18.71% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 28.90 | sMAPE for Test Set is: 20.55% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 09:15:18,205]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:15:19,669]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:15:20,431]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:15:22,382]\u001b[0m Trial 1373 finished with value: 14.591165991863946 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012642278082770503, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3026084556425836, 'dropout_rate_Layer_2': 0.10470318097899253, 'dropout_rate_Layer_3': 0.15677633575954084, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3902964970118644e-05, 'l1_Layer_2': 0.0030061671676516284, 'l1_Layer_3': 0.039940876474073954, 'n_units_Layer_1': 235, 'n_units_Layer_2': 175, 'n_units_Layer_3': 200}. Best is trial 1126 with value: 13.88962519620162.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.59 | sMAPE for Validation Set is: 18.95% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 28.42 | sMAPE for Test Set is: 20.33% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 09:15:27,878]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:15:31,760]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:15:32,183]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:15:33,517]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:15:40,298]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:15:40,787]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:15:42,596]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:15:52,346]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:15:53,039]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:16:01,159]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:16:05,225]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:16:09,536]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:16:13,438]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:16:15,336]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:16:19,163]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:16:19,475]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:16:22,039]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:16:28,590]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:16:29,831]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:16:29,938]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:16:36,022]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:16:36,740]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:16:38,686]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:16:41,017]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:16:48,111]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:16:49,362]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:16:49,624]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:16:54,440]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:16:55,699]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:16:56,597]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:16:59,856]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:17:07,812]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:17:08,783]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:17:09,370]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:17:14,638]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:17:17,601]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:17:19,616]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:17:21,208]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:17:26,281]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:17:27,562]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:17:32,779]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:17:39,232]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:17:42,403]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:17:42,854]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:17:43,137]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:17:51,468]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:17:52,266]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:17:52,614]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:17:52,675]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:17:59,033]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:17:59,670]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:18:05,078]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:18:05,514]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:18:10,350]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:18:11,205]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:18:19,171]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:18:19,911]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:18:20,719]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:18:21,738]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:18:28,693]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:18:31,246]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:18:34,503]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:18:38,472]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:18:38,679]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:18:39,154]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:18:51,244]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:18:56,473]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:19:00,144]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:19:00,842]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:19:00,981]\u001b[0m Trial 1451 finished with value: 14.271404050601925 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015226288335135568, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3363606963212966, 'dropout_rate_Layer_2': 0.13433383103105895, 'dropout_rate_Layer_3': 0.21024728261591002, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4515877776838336e-05, 'l1_Layer_2': 0.003811522256984332, 'l1_Layer_3': 0.02448653778822988, 'n_units_Layer_1': 215, 'n_units_Layer_2': 135, 'n_units_Layer_3': 205}. Best is trial 1126 with value: 13.88962519620162.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.27 | sMAPE for Validation Set is: 18.74% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 27.25 | sMAPE for Test Set is: 19.70% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 09:19:03,358]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:19:13,095]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:19:13,208]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:19:13,368]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:19:13,913]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:19:25,640]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:19:26,052]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:19:26,165]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:19:30,177]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:19:36,005]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:19:36,339]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:19:38,572]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:19:40,548]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:19:47,156]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:19:47,849]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:19:54,103]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:19:56,638]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:20:00,374]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:20:12,111]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:20:15,094]\u001b[0m Trial 1476 finished with value: 14.393855657015877 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015597855786943318, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33763517636908935, 'dropout_rate_Layer_2': 0.0977913923135504, 'dropout_rate_Layer_3': 0.1951461332014285, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1635008366749225e-05, 'l1_Layer_2': 0.0037939328397270686, 'l1_Layer_3': 0.023884451342924353, 'n_units_Layer_1': 215, 'n_units_Layer_2': 135, 'n_units_Layer_3': 205}. Best is trial 1126 with value: 13.88962519620162.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.39 | sMAPE for Validation Set is: 18.80% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 27.31 | sMAPE for Test Set is: 19.71% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 09:20:16,212]\u001b[0m Trial 1473 finished with value: 14.501499543918134 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013612395378930517, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3377211168770795, 'dropout_rate_Layer_2': 0.09965872526694375, 'dropout_rate_Layer_3': 0.1712416319567287, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2129148609847544e-05, 'l1_Layer_2': 0.003934837002274258, 'l1_Layer_3': 0.031142581628320426, 'n_units_Layer_1': 220, 'n_units_Layer_2': 135, 'n_units_Layer_3': 205}. Best is trial 1126 with value: 13.88962519620162.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.50 | sMAPE for Validation Set is: 18.81% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 27.89 | sMAPE for Test Set is: 19.97% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 09:20:16,531]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:20:23,090]\u001b[0m Trial 1477 finished with value: 14.231782622255205 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015091406802977348, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3262871069905568, 'dropout_rate_Layer_2': 0.09638634812113363, 'dropout_rate_Layer_3': 0.1684552285294612, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.150897715315387e-05, 'l1_Layer_2': 0.0038147976292407363, 'l1_Layer_3': 0.02480885309942622, 'n_units_Layer_1': 215, 'n_units_Layer_2': 135, 'n_units_Layer_3': 205}. Best is trial 1126 with value: 13.88962519620162.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.23 | sMAPE for Validation Set is: 18.50% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 27.39 | sMAPE for Test Set is: 19.75% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 09:20:25,100]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:20:28,507]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:20:33,632]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:20:33,759]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:20:34,209]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:20:40,809]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:20:42,984]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:20:43,558]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:20:43,784]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:20:48,960]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:20:54,654]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:20:56,527]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:20:56,721]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:20:57,377]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:21:04,969]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:21:08,016]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:21:10,345]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:21:10,873]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 09:21:16,742]\u001b[0m Trial 1497 finished with value: 14.769001760853513 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017113472622739881, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32574484174810997, 'dropout_rate_Layer_2': 0.09951726602668814, 'dropout_rate_Layer_3': 0.20257413157199888, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.8069109613926194e-05, 'l1_Layer_2': 0.004928769470466507, 'l1_Layer_3': 0.016202113558110524, 'n_units_Layer_1': 195, 'n_units_Layer_2': 130, 'n_units_Layer_3': 205}. Best is trial 1126 with value: 13.88962519620162.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.77 | sMAPE for Validation Set is: 18.98% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 29.34 | sMAPE for Test Set is: 20.80% | rMAE for Test Set is: 0.74\n",
      "for 2022-01-01, MAE is:39.78 & sMAPE is:31.42% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :39.78 & 31.42% & 0.38\n",
      "for 2022-01-02, MAE is:35.27 & sMAPE is:24.61% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :37.52 & 28.01% & 0.52\n",
      "for 2022-01-03, MAE is:22.89 & sMAPE is:14.91% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :32.64 & 23.65% & 0.47\n",
      "for 2022-01-04, MAE is:32.42 & sMAPE is:22.18% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :32.59 & 23.28% & 0.51\n",
      "for 2022-01-05, MAE is:58.58 & sMAPE is:36.27% & rMAE is:5.18 ||| daily mean of MAE & sMAPE & rMAE till now are :37.79 & 25.88% & 1.44\n",
      "for 2022-01-06, MAE is:17.33 & sMAPE is:8.02% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :34.38 & 22.90% & 1.40\n",
      "for 2022-01-07, MAE is:20.41 & sMAPE is:9.74% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :32.38 & 21.02% & 1.24\n",
      "for 2022-01-08, MAE is:19.74 & sMAPE is:9.72% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :30.80 & 19.61% & 1.11\n",
      "for 2022-01-09, MAE is:73.08 & sMAPE is:58.25% & rMAE is:2.16 ||| daily mean of MAE & sMAPE & rMAE till now are :35.50 & 23.90% & 1.23\n",
      "for 2022-01-10, MAE is:36.83 & sMAPE is:17.37% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :35.63 & 23.25% & 1.16\n",
      "for 2022-01-11, MAE is:17.69 & sMAPE is:7.88% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :34.00 & 21.85% & 1.08\n",
      "for 2022-01-12, MAE is:21.09 & sMAPE is:9.82% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :32.93 & 20.85% & 1.05\n",
      "for 2022-01-13, MAE is:17.27 & sMAPE is:8.04% & rMAE is:1.85 ||| daily mean of MAE & sMAPE & rMAE till now are :31.72 & 19.86% & 1.11\n",
      "for 2022-01-14, MAE is:19.30 & sMAPE is:9.19% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :30.83 & 19.10% & 1.09\n",
      "for 2022-01-15, MAE is:23.38 & sMAPE is:11.12% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :30.34 & 18.57% & 1.08\n",
      "for 2022-01-16, MAE is:15.40 & sMAPE is:7.04% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :29.40 & 17.85% & 1.02\n",
      "for 2022-01-17, MAE is:21.29 & sMAPE is:8.98% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :28.93 & 17.33% & 1.00\n",
      "for 2022-01-18, MAE is:22.11 & sMAPE is:9.60% & rMAE is:3.49 ||| daily mean of MAE & sMAPE & rMAE till now are :28.55 & 16.90% & 1.14\n",
      "for 2022-01-19, MAE is:20.14 & sMAPE is:9.24% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :28.10 & 16.50% & 1.15\n",
      "for 2022-01-20, MAE is:20.31 & sMAPE is:10.44% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :27.72 & 16.19% & 1.13\n",
      "for 2022-01-21, MAE is:14.76 & sMAPE is:8.18% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :27.10 & 15.81% & 1.11\n",
      "for 2022-01-22, MAE is:13.97 & sMAPE is:7.17% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :26.50 & 15.42% & 1.08\n",
      "for 2022-01-23, MAE is:13.65 & sMAPE is:6.56% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :25.94 & 15.03% & 1.08\n",
      "for 2022-01-24, MAE is:29.79 & sMAPE is:13.45% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :26.10 & 14.97% & 1.10\n",
      "for 2022-01-25, MAE is:14.30 & sMAPE is:6.33% & rMAE is:2.80 ||| daily mean of MAE & sMAPE & rMAE till now are :25.63 & 14.62% & 1.17\n",
      "for 2022-01-26, MAE is:20.91 & sMAPE is:9.37% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :25.45 & 14.42% & 1.16\n",
      "for 2022-01-27, MAE is:13.68 & sMAPE is:6.04% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :25.01 & 14.11% & 1.13\n",
      "for 2022-01-28, MAE is:18.21 & sMAPE is:8.26% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :24.77 & 13.90% & 1.10\n",
      "for 2022-01-29, MAE is:19.60 & sMAPE is:8.90% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :24.59 & 13.73% & 1.08\n",
      "for 2022-01-30, MAE is:13.64 & sMAPE is:5.88% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :24.23 & 13.47% & 1.06\n",
      "for 2022-01-31, MAE is:18.85 & sMAPE is:8.47% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :24.05 & 13.31% & 1.06\n",
      "for 2022-02-01, MAE is:21.34 & sMAPE is:10.11% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :23.97 & 13.21% & 1.06\n",
      "for 2022-02-02, MAE is:23.42 & sMAPE is:10.94% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :23.95 & 13.14% & 1.05\n",
      "for 2022-02-03, MAE is:23.00 & sMAPE is:10.82% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :23.92 & 13.07% & 1.05\n",
      "for 2022-02-04, MAE is:18.18 & sMAPE is:9.11% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :23.76 & 12.96% & 1.04\n",
      "for 2022-02-05, MAE is:13.77 & sMAPE is:6.97% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :23.48 & 12.79% & 1.02\n",
      "for 2022-02-06, MAE is:18.62 & sMAPE is:9.39% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :23.35 & 12.70% & 1.01\n",
      "for 2022-02-07, MAE is:19.52 & sMAPE is:9.39% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :23.25 & 12.61% & 1.01\n",
      "for 2022-02-08, MAE is:18.82 & sMAPE is:9.10% & rMAE is:2.35 ||| daily mean of MAE & sMAPE & rMAE till now are :23.14 & 12.52% & 1.04\n",
      "for 2022-02-09, MAE is:18.50 & sMAPE is:8.66% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :23.02 & 12.42% & 1.05\n",
      "for 2022-02-10, MAE is:18.31 & sMAPE is:8.78% & rMAE is:2.62 ||| daily mean of MAE & sMAPE & rMAE till now are :22.91 & 12.34% & 1.09\n",
      "for 2022-02-11, MAE is:17.86 & sMAPE is:9.06% & rMAE is:2.98 ||| daily mean of MAE & sMAPE & rMAE till now are :22.79 & 12.26% & 1.14\n",
      "for 2022-02-12, MAE is:17.54 & sMAPE is:9.05% & rMAE is:1.97 ||| daily mean of MAE & sMAPE & rMAE till now are :22.66 & 12.18% & 1.16\n",
      "for 2022-02-13, MAE is:33.40 & sMAPE is:21.03% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :22.91 & 12.38% & 1.15\n",
      "for 2022-02-14, MAE is:29.55 & sMAPE is:16.55% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :23.06 & 12.48% & 1.15\n",
      "for 2022-02-15, MAE is:22.12 & sMAPE is:11.00% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :23.04 & 12.44% & 1.17\n",
      "for 2022-02-16, MAE is:30.18 & sMAPE is:16.67% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :23.19 & 12.53% & 1.16\n",
      "for 2022-02-17, MAE is:35.40 & sMAPE is:21.03% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :23.44 & 12.71% & 1.15\n",
      "for 2022-02-18, MAE is:16.48 & sMAPE is:8.99% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :23.30 & 12.64% & 1.15\n",
      "for 2022-02-19, MAE is:35.17 & sMAPE is:25.31% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :23.54 & 12.89% & 1.14\n",
      "for 2022-02-20, MAE is:27.20 & sMAPE is:16.35% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :23.61 & 12.96% & 1.13\n",
      "for 2022-02-21, MAE is:23.75 & sMAPE is:12.77% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :23.61 & 12.95% & 1.14\n",
      "for 2022-02-22, MAE is:22.53 & sMAPE is:12.28% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :23.59 & 12.94% & 1.14\n",
      "for 2022-02-23, MAE is:19.34 & sMAPE is:9.83% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :23.51 & 12.88% & 1.14\n",
      "for 2022-02-24, MAE is:15.65 & sMAPE is:7.86% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :23.37 & 12.79% & 1.12\n",
      "for 2022-02-25, MAE is:65.92 & sMAPE is:30.24% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :24.13 & 13.10% & 1.12\n",
      "for 2022-02-26, MAE is:23.93 & sMAPE is:9.42% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :24.13 & 13.04% & 1.11\n",
      "for 2022-02-27, MAE is:21.51 & sMAPE is:8.07% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :24.08 & 12.95% & 1.09\n",
      "for 2022-02-28, MAE is:32.37 & sMAPE is:11.96% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :24.22 & 12.94% & 1.08\n",
      "for 2022-03-01, MAE is:29.20 & sMAPE is:11.21% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :24.30 & 12.91% & 1.07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-03-02, MAE is:22.13 & sMAPE is:8.72% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :24.27 & 12.84% & 1.05\n",
      "for 2022-03-03, MAE is:94.11 & sMAPE is:31.75% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :25.40 & 13.14% & 1.05\n",
      "for 2022-03-04, MAE is:49.82 & sMAPE is:15.00% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :25.78 & 13.17% & 1.04\n",
      "for 2022-03-05, MAE is:24.58 & sMAPE is:6.92% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :25.76 & 13.08% & 1.03\n",
      "for 2022-03-06, MAE is:40.66 & sMAPE is:10.75% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :25.99 & 13.04% & 1.02\n",
      "for 2022-03-07, MAE is:45.29 & sMAPE is:10.55% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :26.29 & 13.00% & 1.01\n",
      "for 2022-03-08, MAE is:136.28 & sMAPE is:27.51% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :27.93 & 13.22% & 1.00\n",
      "for 2022-03-09, MAE is:82.14 & sMAPE is:16.96% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :28.72 & 13.27% & 0.99\n",
      "for 2022-03-10, MAE is:118.98 & sMAPE is:28.29% & rMAE is:3.79 ||| daily mean of MAE & sMAPE & rMAE till now are :30.03 & 13.49% & 1.03\n",
      "for 2022-03-11, MAE is:79.18 & sMAPE is:26.38% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :30.73 & 13.68% & 1.03\n",
      "for 2022-03-12, MAE is:68.78 & sMAPE is:25.18% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :31.27 & 13.84% & 1.03\n",
      "for 2022-03-13, MAE is:47.82 & sMAPE is:18.60% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :31.50 & 13.90% & 1.02\n",
      "for 2022-03-14, MAE is:62.40 & sMAPE is:22.61% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :31.92 & 14.02% & 1.01\n",
      "for 2022-03-15, MAE is:22.00 & sMAPE is:8.80% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :31.79 & 13.95% & 1.00\n",
      "for 2022-03-16, MAE is:24.88 & sMAPE is:9.26% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :31.70 & 13.89% & 0.98\n",
      "for 2022-03-17, MAE is:36.43 & sMAPE is:16.00% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :31.76 & 13.92% & 0.97\n",
      "for 2022-03-18, MAE is:22.72 & sMAPE is:9.70% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :31.64 & 13.86% & 0.97\n",
      "for 2022-03-19, MAE is:21.20 & sMAPE is:9.52% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :31.51 & 13.81% & 0.97\n",
      "for 2022-03-20, MAE is:24.60 & sMAPE is:11.40% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :31.42 & 13.78% & 0.96\n",
      "for 2022-03-21, MAE is:19.91 & sMAPE is:8.64% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :31.28 & 13.71% & 0.96\n",
      "for 2022-03-22, MAE is:20.48 & sMAPE is:8.99% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :31.14 & 13.65% & 0.95\n",
      "for 2022-03-23, MAE is:26.45 & sMAPE is:12.09% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :31.09 & 13.63% & 0.95\n",
      "for 2022-03-24, MAE is:15.55 & sMAPE is:6.99% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :30.90 & 13.55% & 0.95\n",
      "for 2022-03-25, MAE is:41.16 & sMAPE is:16.83% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :31.02 & 13.59% & 0.95\n",
      "for 2022-03-26, MAE is:24.82 & sMAPE is:10.38% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :30.95 & 13.56% & 0.96\n",
      "for 2022-03-27, MAE is:33.00 & sMAPE is:14.65% & rMAE is:1.88 ||| daily mean of MAE & sMAPE & rMAE till now are :30.97 & 13.57% & 0.97\n",
      "for 2022-03-28, MAE is:16.32 & sMAPE is:7.03% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :30.80 & 13.49% & 0.98\n",
      "for 2022-03-29, MAE is:19.61 & sMAPE is:8.04% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :30.68 & 13.43% & 0.97\n",
      "for 2022-03-30, MAE is:25.91 & sMAPE is:10.66% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :30.62 & 13.40% & 0.97\n",
      "for 2022-03-31, MAE is:27.96 & sMAPE is:12.10% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :30.59 & 13.39% & 0.97\n",
      "for 2022-04-01, MAE is:35.46 & sMAPE is:15.55% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :30.65 & 13.41% & 0.97\n",
      "for 2022-04-02, MAE is:48.99 & sMAPE is:23.74% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :30.85 & 13.52% & 0.97\n",
      "for 2022-04-03, MAE is:44.40 & sMAPE is:20.27% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :30.99 & 13.59% & 0.97\n",
      "for 2022-04-04, MAE is:43.77 & sMAPE is:18.36% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :31.13 & 13.65% & 0.98\n",
      "for 2022-04-05, MAE is:22.93 & sMAPE is:8.93% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :31.04 & 13.60% & 0.98\n",
      "for 2022-04-06, MAE is:24.92 & sMAPE is:9.96% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :30.98 & 13.56% & 0.98\n",
      "for 2022-04-07, MAE is:30.81 & sMAPE is:14.49% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :30.98 & 13.57% & 0.98\n",
      "for 2022-04-08, MAE is:73.05 & sMAPE is:51.92% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :31.41 & 13.96% & 0.98\n",
      "for 2022-04-09, MAE is:58.11 & sMAPE is:26.80% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :31.68 & 14.09% & 0.98\n",
      "for 2022-04-10, MAE is:96.02 & sMAPE is:71.45% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :32.32 & 14.66% & 0.99\n",
      "for 2022-04-11, MAE is:59.03 & sMAPE is:38.17% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :32.58 & 14.89% & 0.99\n",
      "for 2022-04-12, MAE is:34.38 & sMAPE is:15.10% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :32.60 & 14.90% & 0.99\n",
      "for 2022-04-13, MAE is:13.85 & sMAPE is:6.12% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :32.42 & 14.81% & 0.98\n",
      "for 2022-04-14, MAE is:17.20 & sMAPE is:7.77% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :32.27 & 14.74% & 0.98\n",
      "for 2022-04-15, MAE is:20.17 & sMAPE is:10.35% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :32.16 & 14.70% & 0.98\n",
      "for 2022-04-16, MAE is:40.17 & sMAPE is:24.32% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :32.23 & 14.79% & 0.97\n",
      "for 2022-04-17, MAE is:47.75 & sMAPE is:41.86% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :32.38 & 15.05% & 0.97\n",
      "for 2022-04-18, MAE is:56.34 & sMAPE is:47.95% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :32.60 & 15.35% & 0.97\n",
      "for 2022-04-19, MAE is:39.63 & sMAPE is:34.08% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :32.66 & 15.52% & 0.96\n",
      "for 2022-04-20, MAE is:46.54 & sMAPE is:55.24% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :32.79 & 15.88% & 0.96\n",
      "for 2022-04-21, MAE is:58.17 & sMAPE is:41.54% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :33.02 & 16.11% & 0.96\n",
      "for 2022-04-22, MAE is:31.67 & sMAPE is:16.34% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :33.01 & 16.12% & 0.96\n",
      "for 2022-04-23, MAE is:106.94 & sMAPE is:96.98% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :33.66 & 16.83% & 0.96\n",
      "for 2022-04-24, MAE is:33.86 & sMAPE is:21.17% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :33.66 & 16.87% & 0.96\n",
      "for 2022-04-25, MAE is:33.00 & sMAPE is:15.14% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :33.66 & 16.86% & 0.96\n",
      "for 2022-04-26, MAE is:15.72 & sMAPE is:6.83% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :33.50 & 16.77% & 0.95\n",
      "for 2022-04-27, MAE is:17.28 & sMAPE is:7.77% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :33.36 & 16.69% & 0.94\n",
      "for 2022-04-28, MAE is:17.73 & sMAPE is:7.89% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :33.23 & 16.62% & 0.94\n",
      "for 2022-04-29, MAE is:14.59 & sMAPE is:6.75% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :33.07 & 16.53% & 0.94\n",
      "for 2022-04-30, MAE is:18.68 & sMAPE is:10.05% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :32.95 & 16.48% & 0.93\n",
      "for 2022-05-01, MAE is:24.97 & sMAPE is:15.02% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :32.89 & 16.47% & 0.93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-05-02, MAE is:13.08 & sMAPE is:7.02% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :32.73 & 16.39% & 0.92\n",
      "for 2022-05-03, MAE is:13.38 & sMAPE is:7.17% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :32.57 & 16.32% & 0.92\n",
      "for 2022-05-04, MAE is:9.79 & sMAPE is:4.90% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :32.39 & 16.22% & 0.91\n",
      "for 2022-05-05, MAE is:14.10 & sMAPE is:7.52% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :32.24 & 16.15% & 0.91\n",
      "for 2022-05-06, MAE is:18.52 & sMAPE is:9.79% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :32.13 & 16.10% & 0.91\n",
      "for 2022-05-07, MAE is:23.32 & sMAPE is:12.95% & rMAE is:1.94 ||| daily mean of MAE & sMAPE & rMAE till now are :32.06 & 16.08% & 0.92\n",
      "for 2022-05-08, MAE is:27.47 & sMAPE is:16.64% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :32.03 & 16.08% & 0.92\n",
      "for 2022-05-09, MAE is:11.39 & sMAPE is:5.50% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :31.87 & 16.00% & 0.92\n",
      "for 2022-05-10, MAE is:12.15 & sMAPE is:5.88% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :31.71 & 15.92% & 0.92\n",
      "for 2022-05-11, MAE is:25.66 & sMAPE is:13.34% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :31.67 & 15.90% & 0.92\n",
      "for 2022-05-12, MAE is:15.04 & sMAPE is:7.93% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :31.54 & 15.84% & 0.92\n",
      "for 2022-05-13, MAE is:17.42 & sMAPE is:8.64% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :31.44 & 15.79% & 0.92\n",
      "for 2022-05-14, MAE is:26.79 & sMAPE is:14.37% & rMAE is:2.13 ||| daily mean of MAE & sMAPE & rMAE till now are :31.40 & 15.78% & 0.93\n",
      "for 2022-05-15, MAE is:72.06 & sMAPE is:62.89% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :31.70 & 16.13% & 0.94\n",
      "for 2022-05-16, MAE is:26.81 & sMAPE is:13.71% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :31.67 & 16.11% & 0.94\n",
      "for 2022-05-17, MAE is:22.79 & sMAPE is:11.49% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :31.60 & 16.08% & 0.94\n",
      "for 2022-05-18, MAE is:24.03 & sMAPE is:12.15% & rMAE is:2.38 ||| daily mean of MAE & sMAPE & rMAE till now are :31.55 & 16.05% & 0.96\n",
      "for 2022-05-19, MAE is:15.51 & sMAPE is:8.10% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :31.43 & 15.99% & 0.96\n",
      "for 2022-05-20, MAE is:13.98 & sMAPE is:6.89% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :31.31 & 15.93% & 0.96\n",
      "for 2022-05-21, MAE is:17.16 & sMAPE is:9.31% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :31.21 & 15.88% & 0.96\n",
      "for 2022-05-22, MAE is:21.32 & sMAPE is:12.98% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :31.14 & 15.86% & 0.96\n",
      "for 2022-05-23, MAE is:10.36 & sMAPE is:5.27% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :30.99 & 15.78% & 0.96\n",
      "for 2022-05-24, MAE is:12.33 & sMAPE is:6.75% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :30.86 & 15.72% & 0.95\n",
      "for 2022-05-25, MAE is:12.05 & sMAPE is:6.41% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :30.73 & 15.66% & 0.95\n",
      "for 2022-05-26, MAE is:16.84 & sMAPE is:9.64% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :30.64 & 15.62% & 0.95\n",
      "for 2022-05-27, MAE is:24.75 & sMAPE is:14.16% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :30.60 & 15.61% & 0.95\n",
      "for 2022-05-28, MAE is:21.85 & sMAPE is:13.21% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :30.54 & 15.59% & 0.95\n",
      "for 2022-05-29, MAE is:24.76 & sMAPE is:15.08% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :30.50 & 15.59% & 0.96\n",
      "for 2022-05-30, MAE is:11.54 & sMAPE is:5.51% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :30.37 & 15.52% & 0.96\n",
      "for 2022-05-31, MAE is:10.91 & sMAPE is:5.12% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :30.24 & 15.45% & 0.95\n",
      "for 2022-06-01, MAE is:14.65 & sMAPE is:7.04% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :30.14 & 15.40% & 0.95\n",
      "for 2022-06-02, MAE is:22.94 & sMAPE is:10.97% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :30.09 & 15.37% & 0.95\n",
      "for 2022-06-03, MAE is:15.37 & sMAPE is:7.41% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :30.00 & 15.31% & 0.94\n",
      "for 2022-06-04, MAE is:18.18 & sMAPE is:9.02% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :29.92 & 15.27% & 0.94\n",
      "for 2022-06-05, MAE is:22.95 & sMAPE is:11.94% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :29.88 & 15.25% & 0.94\n",
      "for 2022-06-06, MAE is:18.81 & sMAPE is:9.53% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :29.81 & 15.22% & 0.94\n",
      "for 2022-06-07, MAE is:12.98 & sMAPE is:6.74% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :29.70 & 15.16% & 0.94\n",
      "for 2022-06-08, MAE is:18.08 & sMAPE is:9.48% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :29.63 & 15.13% & 0.94\n",
      "for 2022-06-09, MAE is:9.87 & sMAPE is:5.46% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :29.50 & 15.07% & 0.93\n",
      "for 2022-06-10, MAE is:15.87 & sMAPE is:8.37% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :29.42 & 15.02% & 0.93\n",
      "for 2022-06-11, MAE is:15.12 & sMAPE is:8.04% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :29.33 & 14.98% & 0.93\n",
      "for 2022-06-12, MAE is:20.82 & sMAPE is:12.10% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :29.28 & 14.96% & 0.93\n",
      "for 2022-06-13, MAE is:16.81 & sMAPE is:8.58% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :29.20 & 14.93% & 0.93\n",
      "for 2022-06-14, MAE is:7.14 & sMAPE is:3.40% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :29.07 & 14.86% & 0.93\n",
      "for 2022-06-15, MAE is:44.45 & sMAPE is:23.74% & rMAE is:2.05 ||| daily mean of MAE & sMAPE & rMAE till now are :29.16 & 14.91% & 0.94\n",
      "for 2022-06-16, MAE is:17.87 & sMAPE is:10.59% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :29.09 & 14.88% & 0.94\n",
      "for 2022-06-17, MAE is:11.24 & sMAPE is:6.14% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :28.99 & 14.83% & 0.94\n",
      "for 2022-06-18, MAE is:36.53 & sMAPE is:24.44% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :29.03 & 14.89% & 0.93\n",
      "for 2022-06-19, MAE is:44.49 & sMAPE is:36.03% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :29.12 & 15.01% & 0.93\n",
      "for 2022-06-20, MAE is:24.09 & sMAPE is:15.41% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :29.09 & 15.01% & 0.93\n",
      "for 2022-06-21, MAE is:15.80 & sMAPE is:10.46% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :29.02 & 14.99% & 0.93\n",
      "for 2022-06-22, MAE is:8.74 & sMAPE is:5.53% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :28.90 & 14.93% & 0.92\n",
      "for 2022-06-23, MAE is:16.96 & sMAPE is:11.09% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :28.83 & 14.91% & 0.92\n",
      "for 2022-06-24, MAE is:15.78 & sMAPE is:11.28% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :28.76 & 14.89% & 0.92\n",
      "for 2022-06-25, MAE is:32.94 & sMAPE is:26.25% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :28.78 & 14.95% & 0.93\n",
      "for 2022-06-26, MAE is:18.51 & sMAPE is:16.42% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :28.72 & 14.96% & 0.92\n",
      "for 2022-06-27, MAE is:15.32 & sMAPE is:11.05% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :28.65 & 14.94% & 0.92\n",
      "for 2022-06-28, MAE is:11.40 & sMAPE is:7.69% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :28.55 & 14.90% & 0.93\n",
      "for 2022-06-29, MAE is:21.89 & sMAPE is:15.99% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :28.51 & 14.91% & 0.93\n",
      "for 2022-06-30, MAE is:13.11 & sMAPE is:10.20% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :28.43 & 14.88% & 0.93\n",
      "for 2022-07-01, MAE is:11.19 & sMAPE is:8.18% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :28.33 & 14.84% & 0.92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-07-02, MAE is:16.27 & sMAPE is:11.56% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :28.27 & 14.83% & 0.92\n",
      "for 2022-07-03, MAE is:18.39 & sMAPE is:13.29% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :28.21 & 14.82% & 0.92\n",
      "for 2022-07-04, MAE is:9.92 & sMAPE is:6.24% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :28.11 & 14.77% & 0.92\n",
      "for 2022-07-05, MAE is:15.68 & sMAPE is:10.90% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :28.05 & 14.75% & 0.92\n",
      "for 2022-07-06, MAE is:12.69 & sMAPE is:8.89% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :27.97 & 14.72% & 0.92\n",
      "for 2022-07-07, MAE is:22.77 & sMAPE is:17.28% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :27.94 & 14.73% & 0.92\n",
      "for 2022-07-08, MAE is:11.53 & sMAPE is:7.96% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :27.85 & 14.70% & 0.92\n",
      "for 2022-07-09, MAE is:10.36 & sMAPE is:6.95% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :27.76 & 14.66% & 0.93\n",
      "for 2022-07-10, MAE is:15.68 & sMAPE is:11.34% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :27.70 & 14.64% & 0.93\n",
      "for 2022-07-11, MAE is:7.35 & sMAPE is:4.72% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :27.59 & 14.59% & 0.93\n",
      "for 2022-07-12, MAE is:12.61 & sMAPE is:7.98% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :27.51 & 14.55% & 0.92\n",
      "for 2022-07-13, MAE is:11.71 & sMAPE is:7.07% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :27.43 & 14.51% & 0.92\n",
      "for 2022-07-14, MAE is:16.14 & sMAPE is:9.95% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :27.37 & 14.49% & 0.92\n",
      "for 2022-07-15, MAE is:16.97 & sMAPE is:10.93% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :27.32 & 14.47% & 0.92\n",
      "for 2022-07-16, MAE is:16.19 & sMAPE is:11.57% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :27.26 & 14.46% & 0.93\n",
      "for 2022-07-17, MAE is:39.69 & sMAPE is:33.27% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :27.33 & 14.55% & 0.93\n",
      "for 2022-07-18, MAE is:26.44 & sMAPE is:21.10% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :27.32 & 14.59% & 0.93\n",
      "for 2022-07-19, MAE is:34.51 & sMAPE is:27.12% & rMAE is:2.28 ||| daily mean of MAE & sMAPE & rMAE till now are :27.36 & 14.65% & 0.93\n",
      "for 2022-07-20, MAE is:12.15 & sMAPE is:7.90% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :27.28 & 14.62% & 0.93\n",
      "for 2022-07-21, MAE is:10.80 & sMAPE is:7.64% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :27.20 & 14.58% & 0.93\n",
      "for 2022-07-22, MAE is:12.15 & sMAPE is:8.96% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :27.13 & 14.55% & 0.93\n",
      "for 2022-07-23, MAE is:42.60 & sMAPE is:30.95% & rMAE is:2.01 ||| daily mean of MAE & sMAPE & rMAE till now are :27.20 & 14.63% & 0.93\n",
      "for 2022-07-24, MAE is:27.59 & sMAPE is:18.82% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :27.20 & 14.65% & 0.93\n",
      "for 2022-07-25, MAE is:13.82 & sMAPE is:8.99% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :27.14 & 14.63% & 0.93\n",
      "for 2022-07-26, MAE is:10.26 & sMAPE is:7.05% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :27.06 & 14.59% & 0.93\n",
      "for 2022-07-27, MAE is:9.58 & sMAPE is:6.66% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :26.97 & 14.55% & 0.93\n",
      "for 2022-07-28, MAE is:24.73 & sMAPE is:15.91% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :26.96 & 14.56% & 0.93\n",
      "for 2022-07-29, MAE is:16.80 & sMAPE is:11.17% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :26.91 & 14.54% & 0.93\n",
      "for 2022-07-30, MAE is:12.06 & sMAPE is:9.16% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :26.84 & 14.52% & 0.93\n",
      "for 2022-07-31, MAE is:24.04 & sMAPE is:20.05% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :26.83 & 14.54% & 0.93\n",
      "for 2022-08-01, MAE is:10.19 & sMAPE is:7.17% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :26.75 & 14.51% & 0.93\n",
      "for 2022-08-02, MAE is:10.43 & sMAPE is:7.10% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :26.68 & 14.47% & 0.93\n",
      "for 2022-08-03, MAE is:13.98 & sMAPE is:9.38% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :26.62 & 14.45% & 0.93\n",
      "for 2022-08-04, MAE is:9.46 & sMAPE is:6.40% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :26.54 & 14.41% & 0.93\n",
      "for 2022-08-05, MAE is:10.62 & sMAPE is:7.81% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :26.46 & 14.38% & 0.92\n",
      "for 2022-08-06, MAE is:14.74 & sMAPE is:10.31% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :26.41 & 14.36% & 0.93\n",
      "for 2022-08-07, MAE is:15.53 & sMAPE is:11.32% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :26.36 & 14.35% & 0.92\n",
      "for 2022-08-08, MAE is:6.94 & sMAPE is:4.77% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :26.27 & 14.31% & 0.92\n",
      "for 2022-08-09, MAE is:6.60 & sMAPE is:4.61% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :26.18 & 14.26% & 0.92\n",
      "for 2022-08-10, MAE is:7.30 & sMAPE is:5.27% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :26.10 & 14.22% & 0.92\n",
      "for 2022-08-11, MAE is:8.21 & sMAPE is:5.60% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :26.02 & 14.18% & 0.92\n",
      "for 2022-08-12, MAE is:8.38 & sMAPE is:5.45% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :25.94 & 14.14% & 0.92\n",
      "for 2022-08-13, MAE is:13.09 & sMAPE is:9.07% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :25.88 & 14.12% & 0.92\n",
      "for 2022-08-14, MAE is:36.11 & sMAPE is:25.15% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :25.93 & 14.17% & 0.92\n",
      "for 2022-08-15, MAE is:17.58 & sMAPE is:11.79% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :25.89 & 14.16% & 0.93\n",
      "for 2022-08-16, MAE is:26.26 & sMAPE is:18.13% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :25.89 & 14.18% & 0.93\n",
      "for 2022-08-17, MAE is:22.83 & sMAPE is:16.79% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :25.88 & 14.19% & 0.93\n",
      "for 2022-08-18, MAE is:20.29 & sMAPE is:15.35% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :25.85 & 14.19% & 0.93\n",
      "for 2022-08-19, MAE is:28.55 & sMAPE is:21.17% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :25.87 & 14.22% & 0.93\n",
      "for 2022-08-20, MAE is:19.89 & sMAPE is:12.01% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :25.84 & 14.21% & 0.93\n",
      "for 2022-08-21, MAE is:40.13 & sMAPE is:31.17% & rMAE is:2.73 ||| daily mean of MAE & sMAPE & rMAE till now are :25.90 & 14.29% & 0.94\n",
      "for 2022-08-22, MAE is:31.40 & sMAPE is:18.06% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :25.93 & 14.30% & 0.94\n",
      "for 2022-08-23, MAE is:18.07 & sMAPE is:9.76% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :25.89 & 14.28% & 0.94\n",
      "for 2022-08-24, MAE is:24.51 & sMAPE is:13.62% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :25.89 & 14.28% & 0.94\n",
      "for 2022-08-25, MAE is:34.06 & sMAPE is:19.74% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :25.92 & 14.30% & 0.94\n",
      "for 2022-08-26, MAE is:33.08 & sMAPE is:19.32% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :25.95 & 14.32% & 0.94\n",
      "for 2022-08-27, MAE is:36.73 & sMAPE is:22.01% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :26.00 & 14.36% & 0.94\n",
      "for 2022-08-28, MAE is:26.53 & sMAPE is:16.51% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :26.00 & 14.37% & 0.94\n",
      "for 2022-08-29, MAE is:24.54 & sMAPE is:13.18% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :25.99 & 14.36% & 0.94\n",
      "for 2022-08-30, MAE is:20.33 & sMAPE is:10.23% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :25.97 & 14.34% & 0.94\n",
      "for 2022-08-31, MAE is:17.79 & sMAPE is:9.51% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :25.94 & 14.32% & 0.94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-09-01, MAE is:16.94 & sMAPE is:8.71% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :25.90 & 14.30% & 0.94\n",
      "for 2022-09-02, MAE is:41.93 & sMAPE is:25.04% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :25.96 & 14.34% & 0.94\n",
      "for 2022-09-03, MAE is:35.41 & sMAPE is:33.46% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :26.00 & 14.42% & 0.94\n",
      "for 2022-09-04, MAE is:60.56 & sMAPE is:48.82% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :26.14 & 14.56% & 0.94\n",
      "for 2022-09-05, MAE is:27.84 & sMAPE is:15.57% & rMAE is:2.38 ||| daily mean of MAE & sMAPE & rMAE till now are :26.15 & 14.57% & 0.95\n",
      "for 2022-09-06, MAE is:40.40 & sMAPE is:23.46% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :26.21 & 14.60% & 0.95\n",
      "for 2022-09-07, MAE is:95.54 & sMAPE is:66.22% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :26.48 & 14.81% & 0.95\n",
      "for 2022-09-08, MAE is:32.19 & sMAPE is:21.87% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :26.51 & 14.84% & 0.95\n",
      "for 2022-09-09, MAE is:28.94 & sMAPE is:18.07% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :26.52 & 14.85% & 0.95\n",
      "for 2022-09-10, MAE is:25.06 & sMAPE is:13.72% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :26.51 & 14.84% & 0.95\n",
      "for 2022-09-11, MAE is:42.82 & sMAPE is:26.53% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :26.57 & 14.89% & 0.95\n",
      "for 2022-09-12, MAE is:18.83 & sMAPE is:10.79% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :26.54 & 14.87% & 0.95\n",
      "for 2022-09-13, MAE is:50.08 & sMAPE is:34.74% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :26.64 & 14.95% & 0.95\n",
      "for 2022-09-14, MAE is:34.54 & sMAPE is:24.96% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :26.67 & 14.99% & 0.95\n",
      "for 2022-09-15, MAE is:14.44 & sMAPE is:8.43% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :26.62 & 14.97% & 0.95\n",
      "for 2022-09-16, MAE is:13.44 & sMAPE is:7.89% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :26.57 & 14.94% & 0.95\n",
      "for 2022-09-17, MAE is:85.36 & sMAPE is:87.46% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :26.79 & 15.22% & 0.95\n",
      "for 2022-09-18, MAE is:41.80 & sMAPE is:34.16% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :26.85 & 15.29% & 0.95\n",
      "for 2022-09-19, MAE is:34.15 & sMAPE is:18.90% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :26.88 & 15.30% & 0.95\n",
      "for 2022-09-20, MAE is:35.06 & sMAPE is:21.77% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :26.91 & 15.33% & 0.95\n",
      "for 2022-09-21, MAE is:14.62 & sMAPE is:10.66% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :26.86 & 15.31% & 0.95\n",
      "for 2022-09-22, MAE is:34.47 & sMAPE is:20.94% & rMAE is:2.62 ||| daily mean of MAE & sMAPE & rMAE till now are :26.89 & 15.33% & 0.96\n",
      "for 2022-09-23, MAE is:50.58 & sMAPE is:34.77% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :26.98 & 15.40% & 0.96\n",
      "for 2022-09-24, MAE is:25.07 & sMAPE is:25.04% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :26.97 & 15.44% & 0.96\n",
      "for 2022-09-25, MAE is:39.45 & sMAPE is:59.42% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :27.02 & 15.61% & 0.96\n",
      "for 2022-09-26, MAE is:21.44 & sMAPE is:17.17% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :27.00 & 15.61% & 0.95\n",
      "for 2022-09-27, MAE is:38.95 & sMAPE is:42.37% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :27.04 & 15.71% & 0.95\n",
      "for 2022-09-28, MAE is:24.99 & sMAPE is:25.85% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :27.04 & 15.75% & 0.95\n",
      "for 2022-09-29, MAE is:22.15 & sMAPE is:18.71% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :27.02 & 15.76% & 0.95\n",
      "for 2022-09-30, MAE is:32.11 & sMAPE is:26.65% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :27.04 & 15.80% & 0.95\n",
      "for 2022-10-01, MAE is:36.34 & sMAPE is:30.54% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :27.07 & 15.85% & 0.95\n",
      "for 2022-10-02, MAE is:33.63 & sMAPE is:23.85% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :27.10 & 15.88% & 0.95\n",
      "for 2022-10-03, MAE is:28.70 & sMAPE is:15.00% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :27.10 & 15.88% & 0.95\n",
      "for 2022-10-04, MAE is:33.87 & sMAPE is:18.08% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :27.13 & 15.89% & 0.95\n",
      "for 2022-10-05, MAE is:41.42 & sMAPE is:23.85% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :27.18 & 15.91% & 0.95\n",
      "for 2022-10-06, MAE is:51.55 & sMAPE is:41.10% & rMAE is:2.59 ||| daily mean of MAE & sMAPE & rMAE till now are :27.26 & 16.00% & 0.95\n",
      "for 2022-10-07, MAE is:24.53 & sMAPE is:15.38% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :27.26 & 16.00% & 0.95\n",
      "for 2022-10-08, MAE is:27.69 & sMAPE is:22.85% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :27.26 & 16.03% & 0.95\n",
      "for 2022-10-09, MAE is:31.70 & sMAPE is:26.54% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :27.27 & 16.06% & 0.95\n",
      "for 2022-10-10, MAE is:29.73 & sMAPE is:18.49% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :27.28 & 16.07% & 0.95\n",
      "for 2022-10-11, MAE is:17.93 & sMAPE is:10.47% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :27.25 & 16.05% & 0.95\n",
      "for 2022-10-12, MAE is:27.49 & sMAPE is:19.55% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :27.25 & 16.07% & 0.95\n",
      "for 2022-10-13, MAE is:21.42 & sMAPE is:14.03% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :27.23 & 16.06% & 0.95\n",
      "for 2022-10-14, MAE is:25.48 & sMAPE is:19.43% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :27.22 & 16.07% & 0.95\n",
      "for 2022-10-15, MAE is:22.16 & sMAPE is:21.04% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :27.20 & 16.09% & 0.95\n",
      "for 2022-10-16, MAE is:16.54 & sMAPE is:17.00% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :27.17 & 16.09% & 0.95\n",
      "for 2022-10-17, MAE is:27.28 & sMAPE is:19.14% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :27.17 & 16.10% & 0.95\n",
      "for 2022-10-18, MAE is:35.23 & sMAPE is:33.42% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :27.20 & 16.16% & 0.95\n",
      "for 2022-10-19, MAE is:28.66 & sMAPE is:34.59% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :27.20 & 16.22% & 0.95\n",
      "for 2022-10-20, MAE is:12.07 & sMAPE is:14.03% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :27.15 & 16.22% & 0.95\n",
      "for 2022-10-21, MAE is:23.35 & sMAPE is:22.89% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :27.14 & 16.24% & 0.95\n",
      "for 2022-10-22, MAE is:19.55 & sMAPE is:19.91% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :27.11 & 16.25% & 0.95\n",
      "for 2022-10-23, MAE is:27.62 & sMAPE is:42.46% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :27.11 & 16.34% & 0.95\n",
      "for 2022-10-24, MAE is:17.15 & sMAPE is:15.15% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :27.08 & 16.34% & 0.94\n",
      "for 2022-10-25, MAE is:14.93 & sMAPE is:14.13% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :27.04 & 16.33% & 0.94\n",
      "for 2022-10-26, MAE is:14.77 & sMAPE is:13.18% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :27.00 & 16.32% & 0.94\n",
      "for 2022-10-27, MAE is:17.49 & sMAPE is:15.01% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :26.97 & 16.31% & 0.94\n",
      "for 2022-10-28, MAE is:12.63 & sMAPE is:11.35% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :26.92 & 16.30% & 0.94\n",
      "for 2022-10-29, MAE is:10.79 & sMAPE is:10.30% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :26.86 & 16.28% & 0.94\n",
      "for 2022-10-30, MAE is:40.24 & sMAPE is:31.59% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :26.91 & 16.33% & 0.94\n",
      "for 2022-10-31, MAE is:22.99 & sMAPE is:13.86% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :26.90 & 16.32% & 0.94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-11-01, MAE is:66.09 & sMAPE is:48.12% & rMAE is:3.52 ||| daily mean of MAE & sMAPE & rMAE till now are :27.02 & 16.42% & 0.95\n",
      "for 2022-11-02, MAE is:19.57 & sMAPE is:14.90% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :27.00 & 16.42% & 0.95\n",
      "for 2022-11-03, MAE is:16.07 & sMAPE is:13.02% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :26.96 & 16.41% & 0.95\n",
      "for 2022-11-04, MAE is:33.70 & sMAPE is:23.85% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :26.99 & 16.43% & 0.95\n",
      "for 2022-11-05, MAE is:29.97 & sMAPE is:22.18% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :27.00 & 16.45% & 0.95\n",
      "for 2022-11-06, MAE is:18.04 & sMAPE is:15.72% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :26.97 & 16.45% & 0.95\n",
      "for 2022-11-07, MAE is:19.52 & sMAPE is:15.76% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :26.94 & 16.45% & 0.94\n",
      "for 2022-11-08, MAE is:16.02 & sMAPE is:13.92% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :26.91 & 16.44% & 0.94\n",
      "for 2022-11-09, MAE is:20.50 & sMAPE is:15.60% & rMAE is:1.86 ||| daily mean of MAE & sMAPE & rMAE till now are :26.89 & 16.44% & 0.95\n",
      "for 2022-11-10, MAE is:18.21 & sMAPE is:13.11% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :26.86 & 16.42% & 0.95\n",
      "for 2022-11-11, MAE is:16.62 & sMAPE is:13.28% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :26.83 & 16.41% & 0.95\n",
      "for 2022-11-12, MAE is:21.23 & sMAPE is:18.85% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :26.81 & 16.42% & 0.94\n",
      "for 2022-11-13, MAE is:22.83 & sMAPE is:18.20% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :26.80 & 16.43% & 0.95\n",
      "for 2022-11-14, MAE is:16.35 & sMAPE is:11.81% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :26.76 & 16.41% & 0.95\n",
      "for 2022-11-15, MAE is:15.08 & sMAPE is:13.46% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :26.73 & 16.40% & 0.95\n",
      "for 2022-11-16, MAE is:12.06 & sMAPE is:11.56% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :26.68 & 16.39% & 0.95\n",
      "for 2022-11-17, MAE is:33.03 & sMAPE is:47.42% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :26.70 & 16.49% & 0.94\n",
      "for 2022-11-18, MAE is:15.85 & sMAPE is:15.22% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :26.67 & 16.48% & 0.94\n",
      "for 2022-11-19, MAE is:31.57 & sMAPE is:45.74% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :26.68 & 16.57% & 0.94\n",
      "for 2022-11-20, MAE is:18.59 & sMAPE is:19.01% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :26.66 & 16.58% & 0.94\n",
      "for 2022-11-21, MAE is:22.65 & sMAPE is:26.80% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :26.65 & 16.61% & 0.94\n",
      "for 2022-11-22, MAE is:15.29 & sMAPE is:20.79% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :26.61 & 16.62% & 0.94\n",
      "for 2022-11-23, MAE is:44.55 & sMAPE is:66.89% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :26.67 & 16.78% & 0.94\n",
      "for 2022-11-24, MAE is:30.05 & sMAPE is:23.30% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :26.68 & 16.80% & 0.94\n",
      "for 2022-11-25, MAE is:12.69 & sMAPE is:9.35% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :26.63 & 16.78% & 0.94\n",
      "for 2022-11-26, MAE is:19.27 & sMAPE is:14.88% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :26.61 & 16.77% & 0.94\n",
      "for 2022-11-27, MAE is:17.47 & sMAPE is:14.72% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :26.58 & 16.76% & 0.93\n",
      "for 2022-11-28, MAE is:20.37 & sMAPE is:19.57% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :26.56 & 16.77% & 0.93\n",
      "for 2022-11-29, MAE is:20.92 & sMAPE is:16.62% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :26.55 & 16.77% & 0.93\n",
      "for 2022-11-30, MAE is:26.09 & sMAPE is:18.52% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :26.55 & 16.78% & 0.93\n",
      "for 2022-12-01, MAE is:15.11 & sMAPE is:10.52% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :26.51 & 16.76% & 0.93\n",
      "for 2022-12-02, MAE is:16.72 & sMAPE is:13.12% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :26.48 & 16.75% & 0.93\n",
      "for 2022-12-03, MAE is:9.58 & sMAPE is:7.95% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :26.43 & 16.72% & 0.93\n",
      "for 2022-12-04, MAE is:84.78 & sMAPE is:57.04% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :26.61 & 16.84% & 0.93\n",
      "for 2022-12-05, MAE is:29.41 & sMAPE is:14.57% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :26.61 & 16.83% & 0.93\n",
      "for 2022-12-06, MAE is:53.14 & sMAPE is:29.47% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :26.69 & 16.87% & 0.93\n",
      "for 2022-12-07, MAE is:9.62 & sMAPE is:6.85% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :26.64 & 16.84% & 0.93\n",
      "for 2022-12-08, MAE is:11.14 & sMAPE is:8.78% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :26.60 & 16.82% & 0.93\n",
      "for 2022-12-09, MAE is:19.39 & sMAPE is:14.00% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :26.58 & 16.81% & 0.93\n",
      "for 2022-12-10, MAE is:18.21 & sMAPE is:13.96% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :26.55 & 16.80% & 0.93\n",
      "for 2022-12-11, MAE is:17.02 & sMAPE is:11.75% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :26.52 & 16.79% & 0.93\n",
      "for 2022-12-12, MAE is:27.55 & sMAPE is:22.27% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :26.53 & 16.80% & 0.93\n",
      "for 2022-12-13, MAE is:43.87 & sMAPE is:64.19% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :26.58 & 16.94% & 0.93\n",
      "for 2022-12-14, MAE is:42.63 & sMAPE is:70.41% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :26.62 & 17.09% & 0.93\n",
      "for 2022-12-15, MAE is:33.21 & sMAPE is:27.69% & rMAE is:2.12 ||| daily mean of MAE & sMAPE & rMAE till now are :26.64 & 17.12% & 0.93\n",
      "for 2022-12-16, MAE is:7.49 & sMAPE is:5.77% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :26.59 & 17.09% & 0.93\n",
      "for 2022-12-17, MAE is:29.52 & sMAPE is:24.58% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :26.60 & 17.11% & 0.93\n",
      "for 2022-12-18, MAE is:14.82 & sMAPE is:14.33% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :26.56 & 17.10% & 0.93\n",
      "for 2022-12-19, MAE is:17.04 & sMAPE is:21.96% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :26.53 & 17.12% & 0.93\n",
      "for 2022-12-20, MAE is:25.78 & sMAPE is:54.65% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :26.53 & 17.22% & 0.92\n",
      "for 2022-12-21, MAE is:10.24 & sMAPE is:16.27% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :26.49 & 17.22% & 0.92\n",
      "for 2022-12-22, MAE is:11.67 & sMAPE is:23.17% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :26.45 & 17.24% & 0.92\n",
      "for 2022-12-23, MAE is:30.58 & sMAPE is:101.38% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :26.46 & 17.47% & 0.92\n",
      "for 2022-12-24, MAE is:11.92 & sMAPE is:37.51% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :26.42 & 17.53% & 0.92\n",
      "for 2022-12-25, MAE is:17.27 & sMAPE is:115.68% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :26.39 & 17.80% & 0.91\n",
      "for 2022-12-26, MAE is:40.56 & sMAPE is:51.66% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :26.43 & 17.90% & 0.92\n",
      "for 2022-12-27, MAE is:23.05 & sMAPE is:20.93% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :26.42 & 17.91% & 0.91\n",
      "for 2022-12-28, MAE is:54.29 & sMAPE is:85.12% & rMAE is:2.39 ||| daily mean of MAE & sMAPE & rMAE till now are :26.50 & 18.09% & 0.92\n",
      "for 2022-12-29, MAE is:28.77 & sMAPE is:110.36% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :26.50 & 18.34% & 0.92\n",
      "for 2022-12-30, MAE is:24.16 & sMAPE is:141.92% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :26.50 & 18.68% & 0.92\n",
      "for 2022-12-31, MAE is:14.05 & sMAPE is:173.94% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :26.46 & 19.11% & 0.92\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\1 - Consolidated Data\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 10:43:45,640]\u001b[0m A new study created in RDB with name: PT_2023\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:44:01,672]\u001b[0m Trial 2 finished with value: 38.786813832323865 and parameters: {'n_hidden': 4, 'learning_rate': 0.013781472631549158, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16578425090968893, 'dropout_rate_Layer_2': 0.10948958501570374, 'dropout_rate_Layer_3': 0.2704526272669817, 'dropout_rate_Layer_4': 0.1291234459730509, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.6268307887233524e-05, 'l1_Layer_2': 1.2425407167036372e-05, 'l1_Layer_3': 0.013186970349823099, 'l1_Layer_4': 1.2233572929673648e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 140, 'n_units_Layer_3': 255, 'n_units_Layer_4': 180}. Best is trial 2 with value: 38.786813832323865.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 38.79 | sMAPE for Validation Set is: 26.68% | rMAE for Validation Set is: 0.98\n",
      "MAE for Test Set is: 25.46 | sMAPE for Test Set is: 37.35% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 10:44:04,374]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:44:07,413]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:44:14,205]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:44:17,194]\u001b[0m Trial 1 finished with value: 123.60036040586688 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020062754758359094, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19124714932706166, 'dropout_rate_Layer_2': 0.2544397148883644, 'dropout_rate_Layer_3': 0.20605960319451802, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.01034440919952491, 'l1_Layer_2': 0.007542371338510238, 'l1_Layer_3': 0.00014489871089701201, 'n_units_Layer_1': 280, 'n_units_Layer_2': 95, 'n_units_Layer_3': 100}. Best is trial 2 with value: 38.786813832323865.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 123.60 | sMAPE for Validation Set is: 109.19% | rMAE for Validation Set is: 3.12\n",
      "MAE for Test Set is: 52.38 | sMAPE for Test Set is: 75.26% | rMAE for Test Set is: 1.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 10:44:19,818]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:44:23,111]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:44:29,557]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:44:38,022]\u001b[0m Trial 11 finished with value: 40.91286501316162 and parameters: {'n_hidden': 3, 'learning_rate': 0.052507592040450926, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.040251548651227556, 'dropout_rate_Layer_2': 0.06698360802081993, 'dropout_rate_Layer_3': 0.19541768460295683, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00024331213909699323, 'l1_Layer_2': 0.005919534118390365, 'l1_Layer_3': 0.0027634333811300464, 'n_units_Layer_1': 140, 'n_units_Layer_2': 120, 'n_units_Layer_3': 140}. Best is trial 2 with value: 38.786813832323865.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 40.91 | sMAPE for Validation Set is: 26.59% | rMAE for Validation Set is: 1.03\n",
      "MAE for Test Set is: 40.85 | sMAPE for Test Set is: 45.74% | rMAE for Test Set is: 1.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 10:44:42,213]\u001b[0m Trial 3 finished with value: 26.111315237374725 and parameters: {'n_hidden': 4, 'learning_rate': 0.004843348529050892, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18779786231438647, 'dropout_rate_Layer_2': 0.33047418121168415, 'dropout_rate_Layer_3': 0.21740171997086832, 'dropout_rate_Layer_4': 0.29415182580546023, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.02015568562641017, 'l1_Layer_2': 0.013100740881812456, 'l1_Layer_3': 0.00022567465096196723, 'l1_Layer_4': 0.0027800735119895025, 'n_units_Layer_1': 220, 'n_units_Layer_2': 205, 'n_units_Layer_3': 240, 'n_units_Layer_4': 70}. Best is trial 3 with value: 26.111315237374725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.11 | sMAPE for Validation Set is: 18.83% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 20.96 | sMAPE for Test Set is: 33.11% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 10:44:42,768]\u001b[0m Trial 8 finished with value: 25.19135972432362 and parameters: {'n_hidden': 3, 'learning_rate': 0.007866553061858014, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1914891290372297, 'dropout_rate_Layer_2': 0.03448802212269344, 'dropout_rate_Layer_3': 0.02456308280247419, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0038752050440887787, 'l1_Layer_2': 0.02374666567937523, 'l1_Layer_3': 6.977990223307548e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 180, 'n_units_Layer_3': 240}. Best is trial 8 with value: 25.19135972432362.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.19 | sMAPE for Validation Set is: 18.49% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 20.07 | sMAPE for Test Set is: 32.18% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 10:44:49,486]\u001b[0m Trial 0 finished with value: 28.433935044286855 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007782477728938759, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22821815549698968, 'dropout_rate_Layer_2': 0.32255051897314746, 'dropout_rate_Layer_3': 0.39908450000122814, 'dropout_rate_Layer_4': 0.18208147521087575, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.049384381859809985, 'l1_Layer_2': 0.010265944137397887, 'l1_Layer_3': 0.03798504136447745, 'l1_Layer_4': 0.00014305679773702666, 'n_units_Layer_1': 225, 'n_units_Layer_2': 300, 'n_units_Layer_3': 225, 'n_units_Layer_4': 150}. Best is trial 8 with value: 25.19135972432362.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.43 | sMAPE for Validation Set is: 20.22% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 23.01 | sMAPE for Test Set is: 34.52% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 10:44:52,281]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:44:54,036]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:44:56,127]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:44:56,139]\u001b[0m Trial 12 finished with value: 29.14503251563237 and parameters: {'n_hidden': 3, 'learning_rate': 0.020814663945360815, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2746468389940258, 'dropout_rate_Layer_2': 0.21686206479725922, 'dropout_rate_Layer_3': 0.29727174870875933, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00036557582069443676, 'l1_Layer_2': 0.002538657276963714, 'l1_Layer_3': 0.00010919287661584419, 'n_units_Layer_1': 245, 'n_units_Layer_2': 285, 'n_units_Layer_3': 90}. Best is trial 8 with value: 25.19135972432362.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.15 | sMAPE for Validation Set is: 20.55% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 23.69 | sMAPE for Test Set is: 35.21% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 10:44:57,956]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:45:03,917]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:45:06,457]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:45:06,885]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:45:10,486]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:45:14,717]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:45:18,830]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:45:20,440]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:45:24,885]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:45:30,064]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:45:32,746]\u001b[0m Trial 20 finished with value: 31.37298113482846 and parameters: {'n_hidden': 3, 'learning_rate': 0.010627316136302172, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07149242963192459, 'dropout_rate_Layer_2': 0.13085903626163345, 'dropout_rate_Layer_3': 0.12910282531050707, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.025538341627773426, 'l1_Layer_2': 0.038474102817412044, 'l1_Layer_3': 1.399750252235846e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 230, 'n_units_Layer_3': 200}. Best is trial 8 with value: 25.19135972432362.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 31.37 | sMAPE for Validation Set is: 21.63% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 24.51 | sMAPE for Test Set is: 35.38% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 10:45:33,732]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:45:36,441]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:45:39,174]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:45:40,511]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:45:44,325]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:45:46,476]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:45:52,253]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:45:53,852]\u001b[0m Trial 26 finished with value: 28.744031138983956 and parameters: {'n_hidden': 4, 'learning_rate': 0.004337464100280602, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04273433817987393, 'dropout_rate_Layer_2': 0.13782954285489396, 'dropout_rate_Layer_3': 0.10506522702051152, 'dropout_rate_Layer_4': 0.3449381954339264, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003089512233325784, 'l1_Layer_2': 0.006466134651581552, 'l1_Layer_3': 9.190481703167507e-05, 'l1_Layer_4': 0.00020932103534197305, 'n_units_Layer_1': 205, 'n_units_Layer_2': 220, 'n_units_Layer_3': 250, 'n_units_Layer_4': 115}. Best is trial 8 with value: 25.19135972432362.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.74 | sMAPE for Validation Set is: 20.16% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 22.11 | sMAPE for Test Set is: 34.06% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 10:45:54,061]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:45:56,704]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:45:59,046]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:46:02,692]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:46:05,556]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:46:08,601]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:46:08,958]\u001b[0m Trial 40 finished with value: 32.731488219026744 and parameters: {'n_hidden': 3, 'learning_rate': 0.047276419447987154, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16777974430642018, 'dropout_rate_Layer_2': 0.047939760178345836, 'dropout_rate_Layer_3': 0.16548669788422515, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015433163398019664, 'l1_Layer_2': 0.0026925291597767694, 'l1_Layer_3': 0.0005332063491637544, 'n_units_Layer_1': 170, 'n_units_Layer_2': 130, 'n_units_Layer_3': 155}. Best is trial 8 with value: 25.19135972432362.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.73 | sMAPE for Validation Set is: 22.41% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 26.66 | sMAPE for Test Set is: 38.62% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 10:46:10,870]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:46:12,129]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:46:16,448]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:46:18,015]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:46:18,342]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:46:18,725]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:46:26,057]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:46:26,306]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:46:26,407]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:46:27,175]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:46:32,490]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:46:32,755]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:46:38,051]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:46:38,124]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:46:40,469]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:46:44,188]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:46:47,124]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:46:47,396]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:46:47,595]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:46:47,884]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:46:54,550]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:46:58,049]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:46:59,716]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:47:03,828]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:47:04,400]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:47:04,517]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:47:10,447]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:47:10,628]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:47:19,434]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:47:21,935]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:47:22,456]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:47:26,679]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:47:27,111]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:47:27,775]\u001b[0m Trial 67 finished with value: 26.96380634237268 and parameters: {'n_hidden': 3, 'learning_rate': 0.008586457736156182, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24462168373398713, 'dropout_rate_Layer_2': 0.13333161068132443, 'dropout_rate_Layer_3': 0.09952511871570434, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020293197733164706, 'l1_Layer_2': 0.007630230617995738, 'l1_Layer_3': 6.439106994720524e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 300, 'n_units_Layer_3': 135}. Best is trial 8 with value: 25.19135972432362.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.96 | sMAPE for Validation Set is: 19.45% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 21.11 | sMAPE for Test Set is: 32.73% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 10:47:29,868]\u001b[0m Trial 72 finished with value: 26.813800377654847 and parameters: {'n_hidden': 3, 'learning_rate': 0.009013387042415574, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1267966294397908, 'dropout_rate_Layer_2': 0.15428917824505503, 'dropout_rate_Layer_3': 0.3346961845237656, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.8925242501373673e-05, 'l1_Layer_2': 0.001008105509036285, 'l1_Layer_3': 0.08533743712782926, 'n_units_Layer_1': 165, 'n_units_Layer_2': 195, 'n_units_Layer_3': 190}. Best is trial 8 with value: 25.19135972432362.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.81 | sMAPE for Validation Set is: 19.63% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 21.93 | sMAPE for Test Set is: 34.48% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 10:47:31,875]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:47:33,085]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:47:35,867]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:47:36,543]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:47:38,035]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:47:40,499]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:47:43,639]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:47:44,515]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:47:47,254]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:47:47,748]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:47:49,516]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:47:51,883]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:47:54,085]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:47:56,592]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:48:00,484]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:48:02,408]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:48:06,314]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:48:07,327]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:48:10,458]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:48:13,435]\u001b[0m Trial 92 finished with value: 28.970532038851157 and parameters: {'n_hidden': 3, 'learning_rate': 0.006260382217939276, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16333270074663273, 'dropout_rate_Layer_2': 0.22349236625982893, 'dropout_rate_Layer_3': 0.2507910317887025, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.918050061047007e-05, 'l1_Layer_2': 0.002938112147575139, 'l1_Layer_3': 0.0017062337241860587, 'n_units_Layer_1': 185, 'n_units_Layer_2': 205, 'n_units_Layer_3': 110}. Best is trial 8 with value: 25.19135972432362.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.97 | sMAPE for Validation Set is: 20.94% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 22.10 | sMAPE for Test Set is: 33.66% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 10:48:17,509]\u001b[0m Trial 91 finished with value: 25.31139483858531 and parameters: {'n_hidden': 4, 'learning_rate': 0.004065077757677618, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3978312717353709, 'dropout_rate_Layer_2': 0.08065429386605205, 'dropout_rate_Layer_3': 0.07190893451512521, 'dropout_rate_Layer_4': 0.30623656189150766, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 8.639767602539148e-05, 'l1_Layer_2': 0.012173682252682571, 'l1_Layer_3': 0.0012269113924832963, 'l1_Layer_4': 1.2903871621646785e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 195, 'n_units_Layer_3': 235, 'n_units_Layer_4': 125}. Best is trial 8 with value: 25.19135972432362.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.31 | sMAPE for Validation Set is: 18.64% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.79 | sMAPE for Test Set is: 33.58% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 10:48:19,676]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:48:23,257]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:48:23,947]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:48:25,403]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:48:31,808]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:48:37,011]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:48:41,222]\u001b[0m Trial 103 finished with value: 26.645790870482696 and parameters: {'n_hidden': 3, 'learning_rate': 0.004180484133237395, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.182086293936559, 'dropout_rate_Layer_2': 0.19529779653502377, 'dropout_rate_Layer_3': 0.1751730657132992, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002862114740350403, 'l1_Layer_2': 3.218558912083938e-05, 'l1_Layer_3': 0.0002457092049325786, 'n_units_Layer_1': 240, 'n_units_Layer_2': 215, 'n_units_Layer_3': 120}. Best is trial 8 with value: 25.19135972432362.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.65 | sMAPE for Validation Set is: 19.39% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 20.39 | sMAPE for Test Set is: 32.28% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 10:48:41,405]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:48:47,533]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:48:50,023]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.14 | sMAPE for Validation Set is: 17.90% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 21.68 | sMAPE for Test Set is: 33.57% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 10:48:51,454]\u001b[0m Trial 106 finished with value: 24.135116367757433 and parameters: {'n_hidden': 3, 'learning_rate': 0.0044155496621106185, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16987387983576085, 'dropout_rate_Layer_2': 0.24201912258215394, 'dropout_rate_Layer_3': 0.15461683162429463, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.4355298527106372e-05, 'l1_Layer_2': 2.195772198262678e-05, 'l1_Layer_3': 0.0010903182671697259, 'n_units_Layer_1': 240, 'n_units_Layer_2': 205, 'n_units_Layer_3': 125}. Best is trial 106 with value: 24.135116367757433.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:48:53,680]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:48:56,414]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:48:58,455]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:49:07,260]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:49:11,543]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:49:14,865]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:49:19,663]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:49:20,699]\u001b[0m Trial 99 finished with value: 24.35442377420333 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009290468537952278, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18051044844481834, 'dropout_rate_Layer_2': 0.09188638540472858, 'dropout_rate_Layer_3': 0.11270391649117292, 'dropout_rate_Layer_4': 0.09159832843584996, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 8.782655886863679e-05, 'l1_Layer_2': 0.002738273831937105, 'l1_Layer_3': 0.00031352300398427603, 'l1_Layer_4': 0.015747295603693538, 'n_units_Layer_1': 195, 'n_units_Layer_2': 270, 'n_units_Layer_3': 190, 'n_units_Layer_4': 185}. Best is trial 106 with value: 24.135116367757433.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.35 | sMAPE for Validation Set is: 17.97% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 20.40 | sMAPE for Test Set is: 32.43% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 10:49:26,069]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:49:29,110]\u001b[0m Trial 116 finished with value: 25.448321033505312 and parameters: {'n_hidden': 3, 'learning_rate': 0.006299854116243593, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3076531148590194, 'dropout_rate_Layer_2': 0.0914650115701978, 'dropout_rate_Layer_3': 0.05656716621917889, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1411057132639262e-05, 'l1_Layer_2': 0.0810782404750227, 'l1_Layer_3': 3.0954668397863216e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 170, 'n_units_Layer_3': 170}. Best is trial 106 with value: 24.135116367757433.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.45 | sMAPE for Validation Set is: 18.74% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 20.92 | sMAPE for Test Set is: 33.12% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 10:49:32,467]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:49:35,352]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:49:37,649]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:49:37,919]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:49:40,951]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:49:44,274]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:49:46,913]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:49:47,389]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:49:54,032]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:49:55,713]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:50:00,765]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:50:02,066]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:50:05,386]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:50:07,259]\u001b[0m Trial 125 finished with value: 24.643155281011513 and parameters: {'n_hidden': 3, 'learning_rate': 0.006390472700904158, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3162764250905812, 'dropout_rate_Layer_2': 0.17334031483436194, 'dropout_rate_Layer_3': 0.14863507733505624, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.416730577209743e-05, 'l1_Layer_2': 0.0032842345886014, 'l1_Layer_3': 2.5915709075648703e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 165, 'n_units_Layer_3': 165}. Best is trial 106 with value: 24.135116367757433.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.64 | sMAPE for Validation Set is: 17.98% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 19.75 | sMAPE for Test Set is: 31.27% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 10:50:10,788]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:50:11,221]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:50:11,924]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:50:17,093]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:50:19,100]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:50:20,218]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:50:20,684]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:50:20,958]\u001b[0m Trial 131 finished with value: 24.66621995463718 and parameters: {'n_hidden': 3, 'learning_rate': 0.008214520148608212, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22284775583151928, 'dropout_rate_Layer_2': 0.3011551899353344, 'dropout_rate_Layer_3': 0.12303028421271432, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.2612022890682744e-05, 'l1_Layer_2': 0.001781087519182099, 'l1_Layer_3': 0.0003350326139111044, 'n_units_Layer_1': 190, 'n_units_Layer_2': 185, 'n_units_Layer_3': 190}. Best is trial 106 with value: 24.135116367757433.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.67 | sMAPE for Validation Set is: 18.37% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 21.07 | sMAPE for Test Set is: 32.99% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 10:50:22,104]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:50:28,235]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:50:30,776]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:50:33,745]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:50:35,102]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:50:37,108]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:50:38,643]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:50:40,651]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:50:41,523]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:50:45,677]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:50:48,847]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:50:49,025]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:50:50,057]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:50:56,557]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:50:57,167]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:51:01,531]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:51:02,073]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:51:07,871]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:51:07,936]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:51:12,651]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:51:13,164]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:51:17,075]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:51:19,899]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:51:23,882]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:51:26,748]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.56 | sMAPE for Validation Set is: 18.01% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 19.40 | sMAPE for Test Set is: 31.11% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 10:51:29,139]\u001b[0m Trial 158 finished with value: 24.55976950617337 and parameters: {'n_hidden': 3, 'learning_rate': 0.0038683663233263625, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33857900155022225, 'dropout_rate_Layer_2': 0.17527865480751692, 'dropout_rate_Layer_3': 0.24132458163090129, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4532832648195971e-05, 'l1_Layer_2': 0.0034454745703052475, 'l1_Layer_3': 0.00017304143892199686, 'n_units_Layer_1': 160, 'n_units_Layer_2': 185, 'n_units_Layer_3': 200}. Best is trial 106 with value: 24.135116367757433.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:51:29,827]\u001b[0m Trial 157 finished with value: 24.04598439500513 and parameters: {'n_hidden': 3, 'learning_rate': 0.0038244765292308916, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34499849565253404, 'dropout_rate_Layer_2': 0.18360571992567462, 'dropout_rate_Layer_3': 0.2323942838842221, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1377490945612258e-05, 'l1_Layer_2': 0.0024333726546260557, 'l1_Layer_3': 0.00019661532773640513, 'n_units_Layer_1': 165, 'n_units_Layer_2': 190, 'n_units_Layer_3': 205}. Best is trial 157 with value: 24.04598439500513.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.05 | sMAPE for Validation Set is: 17.76% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.11 | sMAPE for Test Set is: 30.69% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 10:51:34,225]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:51:36,043]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:51:39,298]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:51:42,622]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:51:47,911]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:51:51,102]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:51:53,109]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:51:55,786]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:51:56,531]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:52:00,081]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:52:01,058]\u001b[0m Trial 170 finished with value: 24.392462643360517 and parameters: {'n_hidden': 3, 'learning_rate': 0.00682547711803883, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.004199669679372244, 'dropout_rate_Layer_2': 0.15057652400819566, 'dropout_rate_Layer_3': 0.3554993652092129, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017654615238862665, 'l1_Layer_2': 0.004194208229528147, 'l1_Layer_3': 0.0015931587091968264, 'n_units_Layer_1': 185, 'n_units_Layer_2': 70, 'n_units_Layer_3': 220}. Best is trial 157 with value: 24.04598439500513.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.39 | sMAPE for Validation Set is: 17.97% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 19.58 | sMAPE for Test Set is: 30.96% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 10:52:02,654]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:52:06,265]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:52:06,403]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:52:06,875]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:52:07,065]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:52:13,473]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:52:15,876]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:52:15,933]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:52:16,605]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:52:17,258]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:52:24,251]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:52:24,810]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:52:24,828]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:52:25,161]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:52:29,615]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:52:33,205]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:52:34,252]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:52:38,229]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:52:38,272]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:52:42,275]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:52:42,608]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:52:43,523]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:52:49,000]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:52:51,813]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:52:54,858]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:52:57,397]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:52:59,447]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:53:01,039]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:53:03,482]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:53:04,189]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:53:06,015]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:53:09,024]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:53:12,172]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:53:12,867]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:53:22,085]\u001b[0m Trial 206 finished with value: 24.08165413857367 and parameters: {'n_hidden': 3, 'learning_rate': 0.006313361796050696, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1635929815351233, 'dropout_rate_Layer_2': 0.10063142246034802, 'dropout_rate_Layer_3': 0.20624345482285011, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.285131092721392e-05, 'l1_Layer_2': 0.0036302385736994465, 'l1_Layer_3': 0.00012967478021134795, 'n_units_Layer_1': 200, 'n_units_Layer_2': 235, 'n_units_Layer_3': 115}. Best is trial 157 with value: 24.04598439500513.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.08 | sMAPE for Validation Set is: 17.84% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.73 | sMAPE for Test Set is: 31.45% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 10:53:24,414]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:53:24,654]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:53:31,235]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:53:35,601]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:53:38,225]\u001b[0m Trial 214 finished with value: 24.84433955547641 and parameters: {'n_hidden': 3, 'learning_rate': 0.004764757202005008, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37721494863328114, 'dropout_rate_Layer_2': 0.16569527926138214, 'dropout_rate_Layer_3': 0.23121576810282718, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010271237340217061, 'l1_Layer_2': 0.001539036766088246, 'l1_Layer_3': 0.00036405268338119274, 'n_units_Layer_1': 145, 'n_units_Layer_2': 185, 'n_units_Layer_3': 185}. Best is trial 157 with value: 24.04598439500513.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.84 | sMAPE for Validation Set is: 18.37% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 20.07 | sMAPE for Test Set is: 32.11% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 10:53:44,343]\u001b[0m Trial 216 finished with value: 24.248342889409713 and parameters: {'n_hidden': 3, 'learning_rate': 0.008832792888163923, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02535826492710827, 'dropout_rate_Layer_2': 0.1294439859360761, 'dropout_rate_Layer_3': 0.31386794245457234, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00021232801456393, 'l1_Layer_2': 0.0047679048836174074, 'l1_Layer_3': 0.000931075776102991, 'n_units_Layer_1': 185, 'n_units_Layer_2': 65, 'n_units_Layer_3': 220}. Best is trial 157 with value: 24.04598439500513.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.25 | sMAPE for Validation Set is: 17.92% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.57 | sMAPE for Test Set is: 31.34% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 10:53:49,080]\u001b[0m Trial 218 finished with value: 24.38554530883607 and parameters: {'n_hidden': 3, 'learning_rate': 0.004488055510708279, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34269869153686594, 'dropout_rate_Layer_2': 0.15903767852412054, 'dropout_rate_Layer_3': 0.17423939502616845, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001277994674036956, 'l1_Layer_2': 0.0007781718062870903, 'l1_Layer_3': 0.0003745973456839296, 'n_units_Layer_1': 140, 'n_units_Layer_2': 245, 'n_units_Layer_3': 185}. Best is trial 157 with value: 24.04598439500513.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.39 | sMAPE for Validation Set is: 17.94% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 20.03 | sMAPE for Test Set is: 31.81% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 10:53:52,063]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:53:52,246]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:53:57,001]\u001b[0m Trial 222 finished with value: 24.58643521258036 and parameters: {'n_hidden': 3, 'learning_rate': 0.008420910628267952, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17009971693592998, 'dropout_rate_Layer_2': 0.10325375411170262, 'dropout_rate_Layer_3': 0.17715576757641738, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001494318119265137, 'l1_Layer_2': 0.004260525819669689, 'l1_Layer_3': 0.00036298124077563675, 'n_units_Layer_1': 210, 'n_units_Layer_2': 180, 'n_units_Layer_3': 220}. Best is trial 157 with value: 24.04598439500513.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.59 | sMAPE for Validation Set is: 18.15% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 19.68 | sMAPE for Test Set is: 31.62% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 10:53:58,789]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:53:58,952]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.50 | sMAPE for Validation Set is: 18.06% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 19.86 | sMAPE for Test Set is: 31.76% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 10:54:01,644]\u001b[0m Trial 221 finished with value: 24.500211804279402 and parameters: {'n_hidden': 3, 'learning_rate': 0.009820511499095725, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.030783367543529616, 'dropout_rate_Layer_2': 0.3091024751296991, 'dropout_rate_Layer_3': 0.3484835130263015, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00019776588223992651, 'l1_Layer_2': 0.00491882702069672, 'l1_Layer_3': 0.0007317902882325568, 'n_units_Layer_1': 185, 'n_units_Layer_2': 85, 'n_units_Layer_3': 220}. Best is trial 157 with value: 24.04598439500513.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:54:04,947]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:54:06,232]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:54:10,158]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:54:10,866]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:54:13,008]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:54:17,533]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:54:20,474]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:54:25,475]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:54:25,626]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:54:27,361]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:54:30,018]\u001b[0m Trial 233 finished with value: 25.24065294632379 and parameters: {'n_hidden': 3, 'learning_rate': 0.008654638719213743, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1520268559483667, 'dropout_rate_Layer_2': 0.10617376086815816, 'dropout_rate_Layer_3': 0.14501325349082692, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001916450959455751, 'l1_Layer_2': 4.850073098971491e-05, 'l1_Layer_3': 0.05331602883852509, 'n_units_Layer_1': 190, 'n_units_Layer_2': 180, 'n_units_Layer_3': 240}. Best is trial 157 with value: 24.04598439500513.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:54:30,104]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.24 | sMAPE for Validation Set is: 18.48% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 20.37 | sMAPE for Test Set is: 32.38% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 10:54:35,721]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:54:37,339]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:54:37,896]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:54:41,154]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:54:42,859]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:54:46,790]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:54:46,968]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:54:47,355]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:54:48,258]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:54:54,751]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:54:58,739]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:54:58,885]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:54:59,603]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:55:07,436]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:55:08,995]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:55:11,988]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:55:12,822]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:55:16,450]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:55:18,145]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:55:18,948]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:55:21,900]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:55:26,204]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:55:26,703]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:55:27,508]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:55:31,397]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:55:36,696]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:55:39,329]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:55:44,606]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:55:46,705]\u001b[0m Trial 262 finished with value: 24.310609020149716 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031771727045320232, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32801982349487513, 'dropout_rate_Layer_2': 0.11224914701690636, 'dropout_rate_Layer_3': 0.17823428872751945, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00047533122542329375, 'l1_Layer_2': 0.0018282548468264747, 'l1_Layer_3': 0.00033705577710332554, 'n_units_Layer_1': 140, 'n_units_Layer_2': 150, 'n_units_Layer_3': 150}. Best is trial 157 with value: 24.04598439500513.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.31 | sMAPE for Validation Set is: 17.87% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.75 | sMAPE for Test Set is: 31.46% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 10:55:49,221]\u001b[0m Trial 265 finished with value: 25.108914837437638 and parameters: {'n_hidden': 3, 'learning_rate': 0.0064242068977236905, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2059457241211296, 'dropout_rate_Layer_2': 0.3958322192610877, 'dropout_rate_Layer_3': 0.11316594269902923, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003302424145706952, 'l1_Layer_2': 8.767075481873599e-05, 'l1_Layer_3': 0.00016606604137184272, 'n_units_Layer_1': 185, 'n_units_Layer_2': 200, 'n_units_Layer_3': 220}. Best is trial 157 with value: 24.04598439500513.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.11 | sMAPE for Validation Set is: 18.47% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 22.91 | sMAPE for Test Set is: 34.70% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 10:55:49,750]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:55:50,228]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:55:55,814]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:55:57,072]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:55:59,454]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:56:00,331]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:56:04,730]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:56:04,967]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:56:06,339]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:56:07,902]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:56:10,345]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:56:11,773]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:56:17,264]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:56:17,643]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:56:21,969]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:56:22,118]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:56:22,648]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:56:27,532]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:56:28,705]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:56:29,790]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:56:31,601]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:56:35,506]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:56:36,031]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:56:36,345]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:56:41,651]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:56:44,842]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:56:45,497]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:56:45,775]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:56:51,639]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:56:51,748]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:56:52,837]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:56:58,264]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:56:59,153]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:57:00,502]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:57:01,002]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:57:02,219]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:57:03,093]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:57:08,488]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:57:11,722]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:57:12,960]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:57:14,486]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:57:19,767]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:57:21,110]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:57:21,818]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:57:26,495]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:57:29,638]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:57:30,290]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:57:34,596]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:57:35,081]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:57:39,072]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:57:42,734]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:57:45,099]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:57:45,738]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:57:55,341]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:58:00,754]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:58:03,418]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:58:04,044]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:58:07,951]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:58:10,788]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:58:13,497]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:58:15,405]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:58:18,137]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:58:18,723]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:58:22,572]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:58:22,840]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:58:22,934]\u001b[0m Trial 326 finished with value: 24.453169599063347 and parameters: {'n_hidden': 3, 'learning_rate': 0.004062803933495014, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23163814681830316, 'dropout_rate_Layer_2': 0.37160721808944547, 'dropout_rate_Layer_3': 0.20015118211773691, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0014094242363470923, 'l1_Layer_2': 0.0010101997992797767, 'l1_Layer_3': 0.000393377194662502, 'n_units_Layer_1': 210, 'n_units_Layer_2': 220, 'n_units_Layer_3': 115}. Best is trial 157 with value: 24.04598439500513.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.45 | sMAPE for Validation Set is: 18.08% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 20.03 | sMAPE for Test Set is: 32.06% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 10:58:29,875]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:58:30,238]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:58:30,885]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:58:37,558]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:58:38,291]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:58:44,166]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:58:49,794]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:58:52,844]\u001b[0m Trial 341 finished with value: 25.67583115507992 and parameters: {'n_hidden': 3, 'learning_rate': 0.008658968612003087, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1471526151709031, 'dropout_rate_Layer_2': 0.38665708449231684, 'dropout_rate_Layer_3': 0.15328735772579793, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0078747697078437, 'l1_Layer_2': 0.0011704539800123325, 'l1_Layer_3': 0.00461035707176358, 'n_units_Layer_1': 210, 'n_units_Layer_2': 175, 'n_units_Layer_3': 190}. Best is trial 157 with value: 24.04598439500513.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.68 | sMAPE for Validation Set is: 18.88% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 20.59 | sMAPE for Test Set is: 32.66% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 10:58:55,458]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:58:58,095]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:59:03,464]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:59:05,256]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:59:09,131]\u001b[0m Trial 338 finished with value: 24.430680911177337 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021370163765975655, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37395727652479954, 'dropout_rate_Layer_2': 0.1318811140875683, 'dropout_rate_Layer_3': 0.2420652454180587, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003135047380860091, 'l1_Layer_2': 0.0024299343032473833, 'l1_Layer_3': 0.00037304938998994314, 'n_units_Layer_1': 155, 'n_units_Layer_2': 200, 'n_units_Layer_3': 175}. Best is trial 157 with value: 24.04598439500513.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.43 | sMAPE for Validation Set is: 17.90% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 20.01 | sMAPE for Test Set is: 31.58% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 10:59:09,660]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:59:10,320]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:59:16,331]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:59:18,591]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:59:19,379]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:59:23,003]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:59:23,245]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:59:23,702]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:59:30,042]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:59:30,594]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:59:34,349]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:59:34,551]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:59:34,707]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:59:40,744]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:59:45,010]\u001b[0m Trial 356 finished with value: 25.5993878231446 and parameters: {'n_hidden': 3, 'learning_rate': 0.003918374069536336, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3133719641729513, 'dropout_rate_Layer_2': 0.10198877274343998, 'dropout_rate_Layer_3': 0.1297898727300983, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007391621911030301, 'l1_Layer_2': 0.0037993788906927613, 'l1_Layer_3': 0.09186672652676846, 'n_units_Layer_1': 160, 'n_units_Layer_2': 235, 'n_units_Layer_3': 140}. Best is trial 157 with value: 24.04598439500513.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.60 | sMAPE for Validation Set is: 18.72% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 20.76 | sMAPE for Test Set is: 32.75% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 10:59:46,799]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:59:49,191]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:59:51,056]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:59:52,440]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:59:54,101]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 10:59:55,555]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:00:01,262]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:00:02,279]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:00:05,412]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:00:07,325]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:00:09,487]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:00:10,072]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:00:14,791]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:00:17,888]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:00:19,661]\u001b[0m Trial 365 finished with value: 24.2699110418307 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007311596669117138, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35764751887500346, 'dropout_rate_Layer_2': 0.14863188334599156, 'dropout_rate_Layer_3': 0.08560206256989861, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.5168806220827016e-05, 'l1_Layer_2': 0.0021841162895812963, 'l1_Layer_3': 4.612816148674949e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 195, 'n_units_Layer_3': 225}. Best is trial 157 with value: 24.04598439500513.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.27 | sMAPE for Validation Set is: 17.92% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 20.39 | sMAPE for Test Set is: 32.08% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:00:19,900]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:00:25,349]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:00:25,742]\u001b[0m Trial 372 finished with value: 24.95404096251441 and parameters: {'n_hidden': 3, 'learning_rate': 0.0041315514919462145, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10668905202847206, 'dropout_rate_Layer_2': 0.384588361251451, 'dropout_rate_Layer_3': 0.13623218702371248, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001660433736511268, 'l1_Layer_2': 0.0031535275281811435, 'l1_Layer_3': 0.007860434911490173, 'n_units_Layer_1': 200, 'n_units_Layer_2': 225, 'n_units_Layer_3': 200}. Best is trial 157 with value: 24.04598439500513.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.95 | sMAPE for Validation Set is: 18.18% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 20.26 | sMAPE for Test Set is: 31.69% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:00:26,425]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:00:28,670]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:00:31,029]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:00:36,823]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:00:38,462]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:00:40,889]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:00:42,906]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:00:45,775]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:00:45,938]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:00:49,295]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:00:52,698]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:00:53,369]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:00:53,577]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:01:00,341]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:01:00,474]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:01:01,436]\u001b[0m Trial 384 finished with value: 24.981438689542383 and parameters: {'n_hidden': 3, 'learning_rate': 0.0048790007240732845, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11558233047576871, 'dropout_rate_Layer_2': 0.3799951769366667, 'dropout_rate_Layer_3': 0.13109675168571977, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001171309355250943, 'l1_Layer_2': 0.004224061990331344, 'l1_Layer_3': 0.007180983770357563, 'n_units_Layer_1': 210, 'n_units_Layer_2': 225, 'n_units_Layer_3': 200}. Best is trial 157 with value: 24.04598439500513.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.98 | sMAPE for Validation Set is: 18.33% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 20.07 | sMAPE for Test Set is: 31.81% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:01:07,424]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:01:09,253]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:01:10,000]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:01:14,139]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:01:16,827]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:01:17,077]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:01:22,480]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:01:24,979]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:01:28,505]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:01:29,078]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:01:30,659]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:01:38,051]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:01:42,401]\u001b[0m Trial 397 finished with value: 24.757306109059954 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007166518690947661, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39924343563100756, 'dropout_rate_Layer_2': 0.14658445710195847, 'dropout_rate_Layer_3': 0.18354935684158868, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.418546089773933e-05, 'l1_Layer_2': 0.011438040420019814, 'l1_Layer_3': 2.1223833564475226e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 160, 'n_units_Layer_3': 195}. Best is trial 157 with value: 24.04598439500513.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.76 | sMAPE for Validation Set is: 18.16% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 20.50 | sMAPE for Test Set is: 32.24% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:01:45,371]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:01:48,330]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:01:49,847]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:01:56,089]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:01:56,754]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:01:57,054]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:02:03,618]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:02:06,738]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:02:09,771]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:02:10,557]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:02:12,960]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:02:15,062]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:02:17,015]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:02:20,167]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:02:25,465]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:02:29,843]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:02:30,454]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:02:34,901]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:02:35,130]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:02:41,593]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:02:42,508]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:02:45,577]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:02:48,311]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:02:49,286]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:02:50,652]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:02:53,997]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:02:55,822]\u001b[0m Trial 429 finished with value: 25.723055060975383 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015965120628527781, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.030514538156064214, 'dropout_rate_Layer_2': 0.05142813952365703, 'dropout_rate_Layer_3': 0.33148232212502576, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002612625857278627, 'l1_Layer_2': 0.003277312563601458, 'l1_Layer_3': 0.00039358926055858677, 'n_units_Layer_1': 200, 'n_units_Layer_2': 60, 'n_units_Layer_3': 240}. Best is trial 157 with value: 24.04598439500513.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.72 | sMAPE for Validation Set is: 18.89% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 20.38 | sMAPE for Test Set is: 31.94% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:02:58,421]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:03:00,535]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:03:00,950]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:03:02,318]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:03:06,938]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:03:07,168]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:03:07,534]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:03:15,843]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:03:16,407]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:03:20,593]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:03:23,582]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:03:26,751]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:03:29,928]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:03:30,796]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:03:35,200]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:03:41,563]\u001b[0m Trial 450 finished with value: 24.8293733792709 and parameters: {'n_hidden': 3, 'learning_rate': 0.008198285581142724, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04581561985063768, 'dropout_rate_Layer_2': 0.029758617649155, 'dropout_rate_Layer_3': 0.3209823996654809, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022026665700436538, 'l1_Layer_2': 0.010815217206691388, 'l1_Layer_3': 0.0008760124569745335, 'n_units_Layer_1': 165, 'n_units_Layer_2': 65, 'n_units_Layer_3': 210}. Best is trial 157 with value: 24.04598439500513.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.83 | sMAPE for Validation Set is: 18.34% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 20.39 | sMAPE for Test Set is: 32.04% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:03:47,256]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:03:51,286]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:03:52,274]\u001b[0m Trial 454 finished with value: 24.84865811560296 and parameters: {'n_hidden': 3, 'learning_rate': 0.007242321253693407, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21847319378468344, 'dropout_rate_Layer_2': 0.1575086439615199, 'dropout_rate_Layer_3': 0.23162736108275778, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013449618187874197, 'l1_Layer_2': 1.5420821776374947e-05, 'l1_Layer_3': 0.0002540778660939201, 'n_units_Layer_1': 220, 'n_units_Layer_2': 225, 'n_units_Layer_3': 110}. Best is trial 157 with value: 24.04598439500513.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.85 | sMAPE for Validation Set is: 18.41% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 19.81 | sMAPE for Test Set is: 31.99% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:03:52,445]\u001b[0m Trial 455 finished with value: 24.995999123836473 and parameters: {'n_hidden': 3, 'learning_rate': 0.0040734283929867235, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18946781962656717, 'dropout_rate_Layer_2': 0.2877026943285127, 'dropout_rate_Layer_3': 0.14792465033458982, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0012375439208585812, 'l1_Layer_2': 0.0014369646952831611, 'l1_Layer_3': 0.0046127404741027, 'n_units_Layer_1': 225, 'n_units_Layer_2': 190, 'n_units_Layer_3': 195}. Best is trial 157 with value: 24.04598439500513.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.00 | sMAPE for Validation Set is: 18.35% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 20.25 | sMAPE for Test Set is: 32.34% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:03:58,248]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:03:59,676]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:04:02,310]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:04:03,782]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:04:06,412]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:04:06,688]\u001b[0m Trial 446 finished with value: 24.166793974051306 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009475278088997527, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33907890074876346, 'dropout_rate_Layer_2': 0.12334756641021884, 'dropout_rate_Layer_3': 0.11083057215006208, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00029252517499552916, 'l1_Layer_2': 0.002875327980223878, 'l1_Layer_3': 7.056500694315243e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 180, 'n_units_Layer_3': 215}. Best is trial 157 with value: 24.04598439500513.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.17 | sMAPE for Validation Set is: 17.74% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.54 | sMAPE for Test Set is: 31.04% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:04:07,883]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:04:13,217]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:04:14,810]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:04:18,908]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:04:19,887]\u001b[0m Trial 460 finished with value: 24.377337315189106 and parameters: {'n_hidden': 3, 'learning_rate': 0.0038903248356935835, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2040243726220782, 'dropout_rate_Layer_2': 0.29054200897843907, 'dropout_rate_Layer_3': 0.23748898289338044, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011382093987565016, 'l1_Layer_2': 1.6708404278001202e-05, 'l1_Layer_3': 0.003812609636762897, 'n_units_Layer_1': 220, 'n_units_Layer_2': 235, 'n_units_Layer_3': 115}. Best is trial 157 with value: 24.04598439500513.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.38 | sMAPE for Validation Set is: 18.06% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 19.52 | sMAPE for Test Set is: 31.49% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:04:22,746]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:04:23,225]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:04:23,995]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:04:27,364]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:04:31,185]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:04:38,081]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:04:38,609]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:04:42,198]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:04:42,368]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:04:43,114]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:04:45,009]\u001b[0m Trial 469 finished with value: 24.028839594361063 and parameters: {'n_hidden': 3, 'learning_rate': 0.014497463559555836, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.011735490478552324, 'dropout_rate_Layer_2': 0.029623193718077565, 'dropout_rate_Layer_3': 0.3435596526670863, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001790467533509795, 'l1_Layer_2': 0.019797605788426972, 'l1_Layer_3': 0.00038392639220836413, 'n_units_Layer_1': 180, 'n_units_Layer_2': 95, 'n_units_Layer_3': 195}. Best is trial 469 with value: 24.028839594361063.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.03 | sMAPE for Validation Set is: 17.87% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.54 | sMAPE for Test Set is: 31.11% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:04:46,729]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:04:49,346]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:04:50,482]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:04:51,313]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:04:52,933]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:04:55,370]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:04:57,407]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:04:59,617]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:05:01,834]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:05:05,119]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:05:05,788]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:05:05,831]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:05:10,207]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:05:12,301]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:05:12,656]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:05:13,397]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:05:17,437]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:05:18,643]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:05:22,311]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:05:23,344]\u001b[0m Trial 486 finished with value: 24.193043904160316 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009709720776583979, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3710312385858763, 'dropout_rate_Layer_2': 0.1379289822277446, 'dropout_rate_Layer_3': 0.09647750674974416, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.036673159963941e-05, 'l1_Layer_2': 1.090607371406143e-05, 'l1_Layer_3': 5.0619928155437874e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 180, 'n_units_Layer_3': 215}. Best is trial 469 with value: 24.028839594361063.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.19 | sMAPE for Validation Set is: 17.86% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.59 | sMAPE for Test Set is: 31.39% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:05:23,684]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:05:27,862]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:05:29,644]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:05:32,849]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:05:33,942]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:05:35,066]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:05:40,319]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:05:40,597]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:05:41,600]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:05:47,493]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:05:48,096]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:05:54,475]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:05:54,833]\u001b[0m Trial 500 finished with value: 24.298012629137475 and parameters: {'n_hidden': 3, 'learning_rate': 0.001419574869277758, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3330888691226648, 'dropout_rate_Layer_2': 0.21007470413327742, 'dropout_rate_Layer_3': 0.13921084681594656, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010333447035082296, 'l1_Layer_2': 0.0004319053354205422, 'l1_Layer_3': 0.0003131392192762279, 'n_units_Layer_1': 145, 'n_units_Layer_2': 180, 'n_units_Layer_3': 215}. Best is trial 469 with value: 24.028839594361063.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.30 | sMAPE for Validation Set is: 17.88% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.64 | sMAPE for Test Set is: 31.35% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:05:55,639]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:05:57,493]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:05:59,835]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:06:01,494]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:06:03,155]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:06:04,716]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:06:05,799]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:06:11,936]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:06:12,781]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:06:19,010]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:06:24,872]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:06:28,035]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:06:28,332]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:06:32,810]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:06:36,717]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:06:39,673]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:06:42,558]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:06:48,238]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:06:48,793]\u001b[0m Trial 524 finished with value: 24.391507466627036 and parameters: {'n_hidden': 3, 'learning_rate': 0.001084371872301488, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3288182636383835, 'dropout_rate_Layer_2': 0.2050439294387566, 'dropout_rate_Layer_3': 0.08966611360972745, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00031964161891363487, 'l1_Layer_2': 0.00045903153579244247, 'l1_Layer_3': 0.0001045242473838371, 'n_units_Layer_1': 145, 'n_units_Layer_2': 180, 'n_units_Layer_3': 215}. Best is trial 469 with value: 24.028839594361063.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.39 | sMAPE for Validation Set is: 18.04% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 20.14 | sMAPE for Test Set is: 32.06% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:06:53,713]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:06:54,409]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:06:58,468]\u001b[0m Trial 525 finished with value: 23.7570262281279 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014714795224010225, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09459790552013324, 'dropout_rate_Layer_2': 0.20967666042515884, 'dropout_rate_Layer_3': 0.09244028758008263, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003279718700206072, 'l1_Layer_2': 2.3884437529993454e-05, 'l1_Layer_3': 0.00011381447020122427, 'n_units_Layer_1': 145, 'n_units_Layer_2': 180, 'n_units_Layer_3': 215}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.76 | sMAPE for Validation Set is: 17.51% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 18.96 | sMAPE for Test Set is: 30.36% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:07:01,717]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:07:05,074]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:07:07,105]\u001b[0m Trial 529 finished with value: 24.4524463102449 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010565185937559468, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3736327496435467, 'dropout_rate_Layer_2': 0.1886438740439221, 'dropout_rate_Layer_3': 0.07742316593140464, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0325656831075846e-05, 'l1_Layer_2': 0.00016828655672645773, 'l1_Layer_3': 0.0002219755237889436, 'n_units_Layer_1': 145, 'n_units_Layer_2': 190, 'n_units_Layer_3': 220}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.45 | sMAPE for Validation Set is: 17.97% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 20.93 | sMAPE for Test Set is: 32.57% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:07:09,418]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:07:09,499]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:07:15,202]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:07:15,698]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:07:23,383]\u001b[0m Trial 536 finished with value: 25.105415296816517 and parameters: {'n_hidden': 3, 'learning_rate': 0.003656028015002697, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0066574767374690345, 'dropout_rate_Layer_2': 0.07984929079506504, 'dropout_rate_Layer_3': 0.35217235909954003, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.204230991123323e-05, 'l1_Layer_2': 0.006341575843886257, 'l1_Layer_3': 0.003974201089023987, 'n_units_Layer_1': 180, 'n_units_Layer_2': 85, 'n_units_Layer_3': 185}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.11 | sMAPE for Validation Set is: 18.56% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 19.61 | sMAPE for Test Set is: 31.53% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:07:23,809]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:07:24,844]\u001b[0m Trial 540 finished with value: 24.550551617443006 and parameters: {'n_hidden': 3, 'learning_rate': 0.004522339078467738, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13740316612142434, 'dropout_rate_Layer_2': 0.22300016949768073, 'dropout_rate_Layer_3': 0.34831107698990904, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01853766910309379, 'l1_Layer_2': 2.194247785124022e-05, 'l1_Layer_3': 1.4500717145104575e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 205, 'n_units_Layer_3': 120}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.55 | sMAPE for Validation Set is: 18.15% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 21.93 | sMAPE for Test Set is: 33.80% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:07:26,724]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:07:29,429]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:07:31,869]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:07:33,665]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:07:42,980]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:07:46,093]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:07:46,592]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:07:48,867]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:07:53,132]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:07:57,887]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:08:03,663]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:08:04,554]\u001b[0m Trial 553 finished with value: 25.54649074033874 and parameters: {'n_hidden': 3, 'learning_rate': 0.004484513554992915, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14810322880292703, 'dropout_rate_Layer_2': 0.31924974304480186, 'dropout_rate_Layer_3': 0.3369591535178408, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.069552693536225e-05, 'l1_Layer_2': 0.0033510611938435755, 'l1_Layer_3': 0.0007492085157113191, 'n_units_Layer_1': 190, 'n_units_Layer_2': 205, 'n_units_Layer_3': 100}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.55 | sMAPE for Validation Set is: 18.76% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 22.68 | sMAPE for Test Set is: 34.57% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:08:09,373]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:08:12,691]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:08:12,905]\u001b[0m Trial 556 finished with value: 25.20694719683969 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034238276686442983, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03224033501247762, 'dropout_rate_Layer_2': 0.09895168175796229, 'dropout_rate_Layer_3': 0.3677559674155751, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.108668988290918e-05, 'l1_Layer_2': 0.002547934973934422, 'l1_Layer_3': 0.0026435382661402097, 'n_units_Layer_1': 190, 'n_units_Layer_2': 75, 'n_units_Layer_3': 180}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.21 | sMAPE for Validation Set is: 18.51% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 20.61 | sMAPE for Test Set is: 32.25% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:08:16,977]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:08:21,184]\u001b[0m Trial 551 finished with value: 23.85367513492676 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012770068642967108, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1047099151453286, 'dropout_rate_Layer_2': 0.20210709904110802, 'dropout_rate_Layer_3': 0.09112608336924853, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00048640217964884597, 'l1_Layer_2': 1.0907830597448248e-05, 'l1_Layer_3': 0.0001390875609914489, 'n_units_Layer_1': 155, 'n_units_Layer_2': 205, 'n_units_Layer_3': 210}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.85 | sMAPE for Validation Set is: 17.76% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 19.31 | sMAPE for Test Set is: 31.15% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:08:23,791]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:08:27,508]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:08:30,624]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:08:33,698]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:08:34,796]\u001b[0m Trial 561 finished with value: 24.571204484499148 and parameters: {'n_hidden': 3, 'learning_rate': 0.001245481841106125, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.035848071168524516, 'dropout_rate_Layer_2': 0.24376004332648654, 'dropout_rate_Layer_3': 0.0472110480913941, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001020994231599839, 'l1_Layer_2': 1.3566323842821386e-05, 'l1_Layer_3': 5.5049236467824205e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 170, 'n_units_Layer_3': 210}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.57 | sMAPE for Validation Set is: 18.22% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 22.60 | sMAPE for Test Set is: 34.22% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:08:35,031]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:08:38,722]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:08:44,217]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:08:44,762]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:08:47,575]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:08:51,254]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:08:51,461]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:08:51,953]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:08:57,548]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:08:58,387]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:08:59,928]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:09:04,713]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:09:08,292]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:09:09,250]\u001b[0m Trial 569 finished with value: 24.302673153810662 and parameters: {'n_hidden': 3, 'learning_rate': 0.004682032918919968, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.052412840052439916, 'dropout_rate_Layer_2': 0.04017472147215718, 'dropout_rate_Layer_3': 0.38504102764376574, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.015078120089982787, 'l1_Layer_2': 0.005345218430432835, 'l1_Layer_3': 0.00020817936670001794, 'n_units_Layer_1': 155, 'n_units_Layer_2': 85, 'n_units_Layer_3': 165}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.30 | sMAPE for Validation Set is: 17.99% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.47 | sMAPE for Test Set is: 31.26% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:09:11,815]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:09:12,810]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:09:17,576]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:09:17,924]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:09:22,589]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:09:23,722]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:09:27,105]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:09:27,963]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:09:28,448]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:09:31,585]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:09:37,242]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:09:38,153]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:09:38,247]\u001b[0m Trial 584 finished with value: 24.619073551990777 and parameters: {'n_hidden': 3, 'learning_rate': 0.0040392140082075, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11154282635175791, 'dropout_rate_Layer_2': 0.24380550986252145, 'dropout_rate_Layer_3': 0.36277667479319464, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.116797418205982e-05, 'l1_Layer_2': 0.0022104222035682435, 'l1_Layer_3': 0.00026848718941126866, 'n_units_Layer_1': 230, 'n_units_Layer_2': 215, 'n_units_Layer_3': 200}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.62 | sMAPE for Validation Set is: 18.17% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 21.72 | sMAPE for Test Set is: 33.13% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:09:39,805]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:09:42,709]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:09:47,276]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:09:50,815]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:09:52,326]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:09:53,512]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:09:59,398]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:10:03,086]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:10:04,491]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:10:09,425]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:10:09,881]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:10:10,522]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:10:16,545]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:10:18,678]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:10:21,523]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:10:23,702]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:10:25,905]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:10:28,194]\u001b[0m Trial 606 finished with value: 24.44904684981599 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019612995527605107, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11800503772046952, 'dropout_rate_Layer_2': 0.16937815736521028, 'dropout_rate_Layer_3': 0.10511235221880884, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022970272384856735, 'l1_Layer_2': 2.6985031368546503e-05, 'l1_Layer_3': 0.00033414947272892664, 'n_units_Layer_1': 155, 'n_units_Layer_2': 210, 'n_units_Layer_3': 200}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.45 | sMAPE for Validation Set is: 18.15% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 20.61 | sMAPE for Test Set is: 32.65% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:10:31,732]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:10:33,312]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:10:37,516]\u001b[0m Trial 596 finished with value: 23.926191863665423 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012230854487505572, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1316045287392376, 'dropout_rate_Layer_2': 0.16410799942138216, 'dropout_rate_Layer_3': 0.09676503769798828, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008925817041234606, 'l1_Layer_2': 1.3398381803607703e-05, 'l1_Layer_3': 0.0003057953272524873, 'n_units_Layer_1': 175, 'n_units_Layer_2': 210, 'n_units_Layer_3': 210}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.93 | sMAPE for Validation Set is: 17.61% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 19.25 | sMAPE for Test Set is: 30.73% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:10:38,006]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:10:46,351]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:10:50,130]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:10:50,935]\u001b[0m Trial 617 finished with value: 25.572136318279604 and parameters: {'n_hidden': 3, 'learning_rate': 0.007327045357147871, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.029939927419000888, 'dropout_rate_Layer_2': 0.021454579550340334, 'dropout_rate_Layer_3': 0.32792401087218986, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015180011136814943, 'l1_Layer_2': 0.005851848020931354, 'l1_Layer_3': 0.0007780250664384133, 'n_units_Layer_1': 175, 'n_units_Layer_2': 65, 'n_units_Layer_3': 210}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.57 | sMAPE for Validation Set is: 18.94% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 20.43 | sMAPE for Test Set is: 32.24% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:10:55,348]\u001b[0m Trial 618 finished with value: 24.640739226869584 and parameters: {'n_hidden': 3, 'learning_rate': 0.005679255820073848, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11336282486945884, 'dropout_rate_Layer_2': 0.18218634253398308, 'dropout_rate_Layer_3': 0.15764043757354776, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.009602439307746732, 'l1_Layer_2': 3.9856426773484715e-05, 'l1_Layer_3': 0.00030540864463646933, 'n_units_Layer_1': 215, 'n_units_Layer_2': 50, 'n_units_Layer_3': 195}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.64 | sMAPE for Validation Set is: 18.26% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 19.79 | sMAPE for Test Set is: 31.83% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:10:55,543]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:10:55,678]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:11:00,954]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:11:04,503]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:11:07,797]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:11:11,118]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:11:17,524]\u001b[0m Trial 623 finished with value: 24.5064184550172 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010153001438270052, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08873619616593534, 'dropout_rate_Layer_2': 0.2434806943607701, 'dropout_rate_Layer_3': 0.079165388248804, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017276496687840693, 'l1_Layer_2': 0.0006406429305087112, 'l1_Layer_3': 0.00013887166771129068, 'n_units_Layer_1': 185, 'n_units_Layer_2': 90, 'n_units_Layer_3': 235}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.51 | sMAPE for Validation Set is: 18.01% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 20.10 | sMAPE for Test Set is: 31.98% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:11:17,926]\u001b[0m Trial 624 finished with value: 24.605999047179022 and parameters: {'n_hidden': 3, 'learning_rate': 0.008717516861505016, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.030407613976316424, 'dropout_rate_Layer_2': 0.017796298281734596, 'dropout_rate_Layer_3': 0.31729376623086814, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.542092315825545e-05, 'l1_Layer_2': 0.010696679600928996, 'l1_Layer_3': 0.000802526222791907, 'n_units_Layer_1': 175, 'n_units_Layer_2': 65, 'n_units_Layer_3': 130}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.61 | sMAPE for Validation Set is: 18.19% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 19.33 | sMAPE for Test Set is: 31.06% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:11:18,210]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:11:22,893]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:11:25,086]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:11:25,678]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:11:27,148]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.88 | sMAPE for Validation Set is: 18.36% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 20.25 | sMAPE for Test Set is: 32.14% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:11:30,430]\u001b[0m Trial 627 finished with value: 24.88242734939692 and parameters: {'n_hidden': 3, 'learning_rate': 0.010146691014447142, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05887701101027001, 'dropout_rate_Layer_2': 0.009470187939408195, 'dropout_rate_Layer_3': 0.32710943586006275, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.042552204231985594, 'l1_Layer_2': 0.005876041936473006, 'l1_Layer_3': 0.0006678312897454877, 'n_units_Layer_1': 155, 'n_units_Layer_2': 80, 'n_units_Layer_3': 105}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:11:34,225]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:11:38,124]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:11:40,227]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:11:42,950]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:11:45,035]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:11:47,772]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:11:51,002]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:11:52,894]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:11:55,013]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:11:57,037]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:11:57,481]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:11:59,328]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:12:01,304]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:12:04,254]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:12:05,863]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:12:09,839]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:12:11,601]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:12:14,930]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:12:15,181]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:12:15,897]\u001b[0m Trial 646 finished with value: 25.551207494504848 and parameters: {'n_hidden': 3, 'learning_rate': 0.008450156567958781, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04830257380858907, 'dropout_rate_Layer_2': 0.00035901811796601804, 'dropout_rate_Layer_3': 0.3132281725937166, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.045766310524649766, 'l1_Layer_2': 0.005429391425509153, 'l1_Layer_3': 0.0008839917833465516, 'n_units_Layer_1': 140, 'n_units_Layer_2': 90, 'n_units_Layer_3': 110}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.55 | sMAPE for Validation Set is: 18.75% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.23 | sMAPE for Test Set is: 32.95% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:12:24,297]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:12:24,766]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:12:26,816]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:12:30,024]\u001b[0m Trial 651 finished with value: 25.84121344499748 and parameters: {'n_hidden': 3, 'learning_rate': 0.008702629035602795, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05238388760586276, 'dropout_rate_Layer_2': 0.02961851129221764, 'dropout_rate_Layer_3': 0.3129469199363611, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.04832941365522768, 'l1_Layer_2': 0.0053026450240834175, 'l1_Layer_3': 0.0009300626345531272, 'n_units_Layer_1': 155, 'n_units_Layer_2': 75, 'n_units_Layer_3': 115}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.84 | sMAPE for Validation Set is: 18.91% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 21.31 | sMAPE for Test Set is: 33.14% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:12:34,370]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:12:35,087]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:12:36,333]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:12:39,670]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:12:43,997]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:12:47,191]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:12:48,029]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:12:48,332]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:12:54,661]\u001b[0m Trial 661 finished with value: 25.45154598474947 and parameters: {'n_hidden': 3, 'learning_rate': 0.007702902093516234, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0511257663844553, 'dropout_rate_Layer_2': 0.024559743101907734, 'dropout_rate_Layer_3': 0.3109903484970122, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.05319558062229151, 'l1_Layer_2': 0.005397272473341129, 'l1_Layer_3': 0.0009519601285096405, 'n_units_Layer_1': 140, 'n_units_Layer_2': 75, 'n_units_Layer_3': 105}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.45 | sMAPE for Validation Set is: 18.75% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.06 | sMAPE for Test Set is: 33.05% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:12:55,015]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:12:55,988]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:12:59,506]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:13:01,365]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:13:03,800]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:13:05,273]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:13:07,916]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:13:08,658]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:13:13,452]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:13:16,625]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:13:16,934]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:13:22,448]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:13:22,666]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:13:22,899]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:13:23,654]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:13:32,393]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:13:32,547]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:13:32,746]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:13:35,539]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:13:37,419]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:13:39,824]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:13:42,292]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:13:48,250]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:13:48,725]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:13:51,996]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:13:54,630]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:13:55,244]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:13:55,932]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:14:01,899]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:14:03,962]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:14:07,789]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:14:08,666]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:14:11,837]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:14:13,802]\u001b[0m Trial 694 finished with value: 25.4219894487254 and parameters: {'n_hidden': 3, 'learning_rate': 0.003419077723008146, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.243377982319534, 'dropout_rate_Layer_2': 0.3996037587722941, 'dropout_rate_Layer_3': 0.3369147383461218, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.236803225026446e-05, 'l1_Layer_2': 1.6152449240260162e-05, 'l1_Layer_3': 0.004648258590782878, 'n_units_Layer_1': 160, 'n_units_Layer_2': 215, 'n_units_Layer_3': 195}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.42 | sMAPE for Validation Set is: 18.84% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 20.81 | sMAPE for Test Set is: 32.84% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:14:16,502]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:14:18,034]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:14:19,514]\u001b[0m Trial 695 finished with value: 25.028960908875565 and parameters: {'n_hidden': 3, 'learning_rate': 0.011452459748001369, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.024431891734057458, 'dropout_rate_Layer_2': 0.036282904718761014, 'dropout_rate_Layer_3': 0.33308071961720875, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0848155027047982, 'l1_Layer_2': 0.004391189081503613, 'l1_Layer_3': 0.0006701208100674149, 'n_units_Layer_1': 150, 'n_units_Layer_2': 95, 'n_units_Layer_3': 95}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.03 | sMAPE for Validation Set is: 18.44% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 20.46 | sMAPE for Test Set is: 32.41% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:14:20,428]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:14:26,141]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:14:26,202]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:14:26,831]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:14:27,713]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:14:33,814]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:14:35,042]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:14:35,221]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:14:41,517]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:14:44,452]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:14:46,507]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:14:47,458]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:14:47,705]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:14:47,846]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:14:55,652]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:14:58,164]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:14:59,840]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:14:59,945]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:15:01,369]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:15:07,734]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:15:15,934]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:15:19,347]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:15:27,888]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:15:28,300]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:15:33,106]\u001b[0m Trial 726 finished with value: 24.03763902154257 and parameters: {'n_hidden': 3, 'learning_rate': 0.001032872094746766, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11251876668365793, 'dropout_rate_Layer_2': 0.16976554432390897, 'dropout_rate_Layer_3': 0.08922737589534291, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002646309138091113, 'l1_Layer_2': 3.516841881494809e-05, 'l1_Layer_3': 0.00038683853352422884, 'n_units_Layer_1': 155, 'n_units_Layer_2': 210, 'n_units_Layer_3': 195}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.04 | sMAPE for Validation Set is: 17.66% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.23 | sMAPE for Test Set is: 30.93% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:15:33,846]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:15:37,970]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:15:38,035]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:15:38,779]\u001b[0m Trial 724 finished with value: 24.055732313378588 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018555586354171438, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11830187288676522, 'dropout_rate_Layer_2': 0.1661549484999416, 'dropout_rate_Layer_3': 0.10989716647729696, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003353083508782807, 'l1_Layer_2': 3.013539731783465e-05, 'l1_Layer_3': 0.00040580665824405067, 'n_units_Layer_1': 160, 'n_units_Layer_2': 210, 'n_units_Layer_3': 195}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:15:38,891]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.06 | sMAPE for Validation Set is: 17.65% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.03 | sMAPE for Test Set is: 30.59% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:15:47,367]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:15:48,045]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:15:48,860]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:15:49,363]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:15:55,652]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:15:55,909]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:15:57,593]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:15:57,609]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:16:02,399]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:16:04,173]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:16:08,917]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:16:09,325]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:16:10,118]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:16:14,692]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:16:15,842]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:16:16,413]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:16:21,859]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:16:22,604]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:16:24,707]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:16:27,578]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:16:30,922]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:16:31,700]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:16:36,895]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:16:37,210]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:16:39,697]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:16:42,592]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:16:46,799]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:16:47,167]\u001b[0m Trial 756 finished with value: 24.74385085750781 and parameters: {'n_hidden': 3, 'learning_rate': 0.005575038814530436, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10983838387954276, 'dropout_rate_Layer_2': 0.1626617292647726, 'dropout_rate_Layer_3': 0.12996333825801143, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003150035896831542, 'l1_Layer_2': 2.5098705430428318e-05, 'l1_Layer_3': 5.117079517499835e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 175, 'n_units_Layer_3': 210}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.74 | sMAPE for Validation Set is: 18.21% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 20.47 | sMAPE for Test Set is: 32.34% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:16:47,360]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:16:47,792]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:16:53,334]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:16:56,314]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:16:57,184]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:16:57,449]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:17:01,140]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:17:04,257]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:17:05,484]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:17:10,913]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:17:13,177]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:17:15,279]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:17:20,034]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:17:20,515]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:17:26,142]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:17:26,335]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:17:29,792]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:17:30,926]\u001b[0m Trial 770 finished with value: 24.456763611456708 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010679174053103428, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3425980069349142, 'dropout_rate_Layer_2': 0.08943638797777176, 'dropout_rate_Layer_3': 0.08583795322909339, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00039375148257818566, 'l1_Layer_2': 3.758326177702507e-05, 'l1_Layer_3': 0.0006021050319100827, 'n_units_Layer_1': 160, 'n_units_Layer_2': 195, 'n_units_Layer_3': 170}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.46 | sMAPE for Validation Set is: 17.99% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 19.76 | sMAPE for Test Set is: 31.65% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:17:31,041]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:17:36,932]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:17:40,298]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:17:43,510]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:17:44,597]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:17:47,574]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:17:48,311]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.12 | sMAPE for Validation Set is: 18.52% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 19.44 | sMAPE for Test Set is: 31.31% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:17:52,406]\u001b[0m Trial 780 finished with value: 25.121760407692893 and parameters: {'n_hidden': 3, 'learning_rate': 0.005907700973055919, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.026965630957636495, 'dropout_rate_Layer_2': 0.15267593211296399, 'dropout_rate_Layer_3': 0.3335133885067325, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.300272297161246e-05, 'l1_Layer_2': 0.005186522869924045, 'l1_Layer_3': 0.0006547245563550355, 'n_units_Layer_1': 165, 'n_units_Layer_2': 65, 'n_units_Layer_3': 220}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:17:53,428]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:17:55,414]\u001b[0m Trial 784 finished with value: 24.407240201454595 and parameters: {'n_hidden': 3, 'learning_rate': 0.004754358527231655, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10493120382816322, 'dropout_rate_Layer_2': 0.3916681437463121, 'dropout_rate_Layer_3': 0.021440453071921106, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.04660231098323984, 'l1_Layer_2': 2.922418254270217e-05, 'l1_Layer_3': 0.00017163197156069967, 'n_units_Layer_1': 205, 'n_units_Layer_2': 205, 'n_units_Layer_3': 185}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.41 | sMAPE for Validation Set is: 18.03% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 19.98 | sMAPE for Test Set is: 31.97% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:18:00,449]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:18:00,969]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:18:05,205]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:18:07,797]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:18:11,442]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:18:12,103]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:18:19,057]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:18:25,104]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:18:25,297]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:18:30,005]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:18:33,069]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:18:38,133]\u001b[0m Trial 795 finished with value: 24.04509157283499 and parameters: {'n_hidden': 3, 'learning_rate': 0.00450072389827858, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08955553541168, 'dropout_rate_Layer_2': 0.392205276987332, 'dropout_rate_Layer_3': 0.004888903900851196, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006564434911419363, 'l1_Layer_2': 2.486018086602986e-05, 'l1_Layer_3': 0.00016458081543883088, 'n_units_Layer_1': 200, 'n_units_Layer_2': 175, 'n_units_Layer_3': 180}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.05 | sMAPE for Validation Set is: 17.78% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.78 | sMAPE for Test Set is: 31.71% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:18:39,901]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:18:40,410]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:18:44,412]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:18:50,662]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:18:50,852]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:18:58,450]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:19:01,154]\u001b[0m Trial 806 finished with value: 24.205661226757968 and parameters: {'n_hidden': 3, 'learning_rate': 0.004086246586567898, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09015162017860401, 'dropout_rate_Layer_2': 0.3725766291848267, 'dropout_rate_Layer_3': 0.008989650900855555, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008118836649202996, 'l1_Layer_2': 2.49637579584359e-05, 'l1_Layer_3': 0.00016529895230222007, 'n_units_Layer_1': 200, 'n_units_Layer_2': 300, 'n_units_Layer_3': 185}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.21 | sMAPE for Validation Set is: 17.86% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.46 | sMAPE for Test Set is: 31.15% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:19:04,710]\u001b[0m Trial 807 finished with value: 24.49084530621684 and parameters: {'n_hidden': 3, 'learning_rate': 0.003875892056317375, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09579886514959862, 'dropout_rate_Layer_2': 0.3929023173714513, 'dropout_rate_Layer_3': 0.19987732014544546, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007539101047481677, 'l1_Layer_2': 3.9044597865805766e-05, 'l1_Layer_3': 0.00015614244818752782, 'n_units_Layer_1': 200, 'n_units_Layer_2': 205, 'n_units_Layer_3': 180}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.49 | sMAPE for Validation Set is: 18.15% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 19.77 | sMAPE for Test Set is: 31.80% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:19:05,353]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:19:13,956]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:19:17,320]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.08 | sMAPE for Validation Set is: 17.90% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.25 | sMAPE for Test Set is: 31.39% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:19:17,538]\u001b[0m Trial 809 finished with value: 24.080996969103666 and parameters: {'n_hidden': 3, 'learning_rate': 0.003985469230803495, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10014491235216809, 'dropout_rate_Layer_2': 0.38163264927727436, 'dropout_rate_Layer_3': 0.013175150173286382, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005773940322825722, 'l1_Layer_2': 2.6702623194346126e-05, 'l1_Layer_3': 8.623356399917602e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 175, 'n_units_Layer_3': 180}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:19:24,576]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:19:27,106]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:19:31,279]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:19:31,740]\u001b[0m Trial 812 finished with value: 24.43235502875051 and parameters: {'n_hidden': 3, 'learning_rate': 0.0038291424767557, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07954308477342924, 'dropout_rate_Layer_2': 0.368862312672422, 'dropout_rate_Layer_3': 0.018359104787826867, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007463425489787148, 'l1_Layer_2': 2.6457668020424036e-05, 'l1_Layer_3': 9.465364684043452e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 295, 'n_units_Layer_3': 170}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.43 | sMAPE for Validation Set is: 17.91% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 19.24 | sMAPE for Test Set is: 30.98% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:19:33,398]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:19:39,375]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:19:39,792]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:19:45,188]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:19:50,582]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:19:55,715]\u001b[0m Trial 818 finished with value: 24.31404256574713 and parameters: {'n_hidden': 3, 'learning_rate': 0.009852389030701798, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.009287189920077744, 'dropout_rate_Layer_2': 0.04163358039052523, 'dropout_rate_Layer_3': 0.34800101405669553, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003125829151805462, 'l1_Layer_2': 0.012103532227863515, 'l1_Layer_3': 0.0007606921706270992, 'n_units_Layer_1': 175, 'n_units_Layer_2': 65, 'n_units_Layer_3': 230}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.31 | sMAPE for Validation Set is: 17.99% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.46 | sMAPE for Test Set is: 31.29% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:19:59,099]\u001b[0m Trial 820 finished with value: 24.321730524622865 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035886859920248753, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08360702953682363, 'dropout_rate_Layer_2': 0.37524826606395584, 'dropout_rate_Layer_3': 0.024885315184322524, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008854459460705136, 'l1_Layer_2': 2.8491931655356434e-05, 'l1_Layer_3': 8.427635174819274e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 300, 'n_units_Layer_3': 170}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.32 | sMAPE for Validation Set is: 17.93% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.31 | sMAPE for Test Set is: 30.90% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:20:02,675]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:20:03,226]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:20:07,593]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:20:09,096]\u001b[0m Trial 824 finished with value: 24.522194138118234 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033095059185958915, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07261854784860655, 'dropout_rate_Layer_2': 0.3718374765560986, 'dropout_rate_Layer_3': 0.02179648342247496, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008635336746950889, 'l1_Layer_2': 2.9698948650403474e-05, 'l1_Layer_3': 6.846034298648213e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 300, 'n_units_Layer_3': 175}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.52 | sMAPE for Validation Set is: 18.36% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 19.59 | sMAPE for Test Set is: 31.43% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:20:11,724]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:20:13,169]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:20:18,120]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:20:18,307]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:20:19,017]\u001b[0m Trial 826 finished with value: 24.008836445868422 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032034850379728196, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08273941414225675, 'dropout_rate_Layer_2': 0.3738279804621866, 'dropout_rate_Layer_3': 0.016961794791068685, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007845898783597927, 'l1_Layer_2': 2.8447238149400283e-05, 'l1_Layer_3': 9.094629452302947e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 165, 'n_units_Layer_3': 165}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.01 | sMAPE for Validation Set is: 17.73% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.39 | sMAPE for Test Set is: 31.26% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:20:26,760]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:20:29,779]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:20:33,076]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:20:33,899]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:20:34,617]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:20:34,910]\u001b[0m Trial 835 finished with value: 24.647388813566675 and parameters: {'n_hidden': 3, 'learning_rate': 0.003461181764125709, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2236551207359496, 'dropout_rate_Layer_2': 0.18529700459148846, 'dropout_rate_Layer_3': 0.06542538229008413, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.4992985774715183e-05, 'l1_Layer_2': 2.6154798318504978e-05, 'l1_Layer_3': 0.0001809363151162478, 'n_units_Layer_1': 150, 'n_units_Layer_2': 195, 'n_units_Layer_3': 205}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.65 | sMAPE for Validation Set is: 18.24% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 20.25 | sMAPE for Test Set is: 32.30% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:20:40,372]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:20:44,372]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:20:45,445]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:20:47,003]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:20:51,529]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:20:52,276]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:20:56,177]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:20:59,558]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:21:04,517]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:21:08,064]\u001b[0m Trial 843 finished with value: 24.744260869472388 and parameters: {'n_hidden': 3, 'learning_rate': 0.009642477750296169, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.034244143820355746, 'dropout_rate_Layer_2': 0.33358676765042683, 'dropout_rate_Layer_3': 0.35317845647676727, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003132354656475988, 'l1_Layer_2': 0.006581847155257667, 'l1_Layer_3': 0.0007285829814696956, 'n_units_Layer_1': 165, 'n_units_Layer_2': 75, 'n_units_Layer_3': 240}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.74 | sMAPE for Validation Set is: 18.26% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 19.69 | sMAPE for Test Set is: 31.52% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:21:09,221]\u001b[0m Trial 844 finished with value: 24.94960560040101 and parameters: {'n_hidden': 3, 'learning_rate': 0.010200662959268712, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03639115171890043, 'dropout_rate_Layer_2': 0.03932174875921539, 'dropout_rate_Layer_3': 0.35266721144636143, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00034600292719497925, 'l1_Layer_2': 0.007219593432966231, 'l1_Layer_3': 0.0007071640977583596, 'n_units_Layer_1': 180, 'n_units_Layer_2': 225, 'n_units_Layer_3': 225}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.95 | sMAPE for Validation Set is: 18.32% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 19.93 | sMAPE for Test Set is: 31.48% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:21:10,048]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:21:16,210]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:21:21,023]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:21:23,050]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:21:24,742]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:21:32,850]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:21:33,246]\u001b[0m Trial 854 finished with value: 24.490714228482886 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027396130219921352, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08983287192711291, 'dropout_rate_Layer_2': 0.3819447394653464, 'dropout_rate_Layer_3': 0.042268415204284954, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.009707058006298504, 'l1_Layer_2': 2.3030957044689996e-05, 'l1_Layer_3': 0.00013221397150494206, 'n_units_Layer_1': 200, 'n_units_Layer_2': 285, 'n_units_Layer_3': 180}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.49 | sMAPE for Validation Set is: 18.10% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 20.00 | sMAPE for Test Set is: 31.88% | rMAE for Test Set is: 0.63\n",
      "MAE for Validation Set is: 24.92 | sMAPE for Validation Set is: 18.43% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 19.43 | sMAPE for Test Set is: 31.15% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:21:38,034]\u001b[0m Trial 857 finished with value: 24.920690122413237 and parameters: {'n_hidden': 3, 'learning_rate': 0.010020248319942021, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03617611920203539, 'dropout_rate_Layer_2': 0.03600849306110149, 'dropout_rate_Layer_3': 0.36442594876676915, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004048855197579591, 'l1_Layer_2': 0.0034872617806077, 'l1_Layer_3': 0.0004232530016760635, 'n_units_Layer_1': 195, 'n_units_Layer_2': 285, 'n_units_Layer_3': 235}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:21:45,372]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:21:49,453]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:21:53,275]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:22:00,247]\u001b[0m Trial 850 finished with value: 24.193395989772835 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012435717008625316, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39188494421497966, 'dropout_rate_Layer_2': 0.23707064645402734, 'dropout_rate_Layer_3': 0.13223785098686391, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00019111139711609353, 'l1_Layer_2': 0.0026343083515064773, 'l1_Layer_3': 0.0007304918475194281, 'n_units_Layer_1': 170, 'n_units_Layer_2': 160, 'n_units_Layer_3': 190}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.19 | sMAPE for Validation Set is: 17.76% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.22 | sMAPE for Test Set is: 30.78% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:22:04,302]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:22:05,137]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:22:13,780]\u001b[0m Trial 861 finished with value: 24.360800200534825 and parameters: {'n_hidden': 3, 'learning_rate': 0.000908441434350194, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.298576854548265, 'dropout_rate_Layer_2': 0.11989250046304228, 'dropout_rate_Layer_3': 0.08022681019186578, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00018956798310344435, 'l1_Layer_2': 0.000409115363531539, 'l1_Layer_3': 0.00010560187763451746, 'n_units_Layer_1': 60, 'n_units_Layer_2': 180, 'n_units_Layer_3': 190}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.36 | sMAPE for Validation Set is: 17.93% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.84 | sMAPE for Test Set is: 31.55% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:22:17,615]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:22:19,937]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:22:23,534]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:22:24,012]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:22:24,277]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:22:31,796]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:22:34,414]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:22:35,233]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:22:39,842]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:22:45,062]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:22:48,695]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:22:49,967]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:22:55,011]\u001b[0m Trial 871 finished with value: 24.477241936968692 and parameters: {'n_hidden': 3, 'learning_rate': 0.003357145402270457, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0927676951640537, 'dropout_rate_Layer_2': 0.3700544005371603, 'dropout_rate_Layer_3': 0.028987610304286242, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007093106758063339, 'l1_Layer_2': 3.245331600012708e-05, 'l1_Layer_3': 8.666348068023129e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 300, 'n_units_Layer_3': 185}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.48 | sMAPE for Validation Set is: 18.08% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 19.37 | sMAPE for Test Set is: 31.38% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:22:55,179]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:22:55,784]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:23:03,925]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:23:07,392]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:23:10,033]\u001b[0m Trial 859 finished with value: 23.766665323725046 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009128769080476666, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13448636730169503, 'dropout_rate_Layer_2': 0.23357437198964126, 'dropout_rate_Layer_3': 0.13489845028584835, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011812729261642851, 'l1_Layer_2': 0.002541157298141683, 'l1_Layer_3': 0.00010332272103972398, 'n_units_Layer_1': 60, 'n_units_Layer_2': 245, 'n_units_Layer_3': 190}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.77 | sMAPE for Validation Set is: 17.54% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 19.04 | sMAPE for Test Set is: 30.56% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:23:12,255]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:23:16,017]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:23:16,064]\u001b[0m Trial 881 finished with value: 25.163024447927707 and parameters: {'n_hidden': 3, 'learning_rate': 0.009378407520060972, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.026163719867180926, 'dropout_rate_Layer_2': 0.024578860594435065, 'dropout_rate_Layer_3': 0.35294087493078163, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.05394730869552335, 'l1_Layer_2': 0.0068926313984974796, 'l1_Layer_3': 0.0007319510972731973, 'n_units_Layer_1': 200, 'n_units_Layer_2': 95, 'n_units_Layer_3': 225}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.16 | sMAPE for Validation Set is: 18.57% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 20.35 | sMAPE for Test Set is: 32.41% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:23:16,200]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:23:23,175]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:23:24,361]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:23:27,726]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:23:35,996]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:23:40,804]\u001b[0m Trial 888 finished with value: 25.322236275442048 and parameters: {'n_hidden': 3, 'learning_rate': 0.010333738358494169, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.032708593285718686, 'dropout_rate_Layer_2': 0.02783357247567833, 'dropout_rate_Layer_3': 0.39928309254181166, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.07992953605821727, 'l1_Layer_2': 0.007782435322308327, 'l1_Layer_3': 0.0006203077144957358, 'n_units_Layer_1': 145, 'n_units_Layer_2': 95, 'n_units_Layer_3': 225}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.32 | sMAPE for Validation Set is: 18.58% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 20.61 | sMAPE for Test Set is: 32.44% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:23:41,620]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:23:46,530]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:23:48,464]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:23:50,620]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:23:54,470]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:23:56,982]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:23:59,742]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:24:02,468]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:24:05,802]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:24:05,917]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:24:06,987]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:24:16,666]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:24:17,344]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:24:24,258]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:24:29,366]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:24:30,200]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:24:34,267]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:24:35,696]\u001b[0m Trial 905 finished with value: 24.789296200992453 and parameters: {'n_hidden': 3, 'learning_rate': 0.002943686475755364, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09202344843012393, 'dropout_rate_Layer_2': 0.3710066572493475, 'dropout_rate_Layer_3': 0.033361696223184925, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008035776175828215, 'l1_Layer_2': 2.4835433258118823e-05, 'l1_Layer_3': 0.0001420039575396675, 'n_units_Layer_1': 195, 'n_units_Layer_2': 295, 'n_units_Layer_3': 180}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.79 | sMAPE for Validation Set is: 18.26% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 19.60 | sMAPE for Test Set is: 31.59% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:24:36,281]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:24:36,527]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:24:39,629]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:24:44,455]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:24:46,773]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:24:50,876]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:24:52,844]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:24:54,285]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:24:58,345]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:24:58,469]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:24:59,271]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:24:59,572]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:25:07,261]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:25:08,639]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:25:11,957]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:25:16,330]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:25:16,424]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:25:23,666]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:25:24,604]\u001b[0m Trial 926 finished with value: 25.70535718595072 and parameters: {'n_hidden': 3, 'learning_rate': 0.009665048758721637, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04039682465084297, 'dropout_rate_Layer_2': 0.11114182879647738, 'dropout_rate_Layer_3': 0.38979884737563164, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.024944149108207286, 'l1_Layer_2': 0.03424954833987958, 'l1_Layer_3': 0.0007258149239683511, 'n_units_Layer_1': 145, 'n_units_Layer_2': 220, 'n_units_Layer_3': 225}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.71 | sMAPE for Validation Set is: 18.88% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 21.11 | sMAPE for Test Set is: 32.99% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:25:26,539]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:25:27,028]\u001b[0m Trial 925 finished with value: 24.57565337924318 and parameters: {'n_hidden': 3, 'learning_rate': 0.009486048573099159, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04034291175387465, 'dropout_rate_Layer_2': 0.10931595962914184, 'dropout_rate_Layer_3': 0.3457494148117611, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03411386961946004, 'l1_Layer_2': 0.005255646311522069, 'l1_Layer_3': 0.0009308249169047442, 'n_units_Layer_1': 225, 'n_units_Layer_2': 100, 'n_units_Layer_3': 240}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.58 | sMAPE for Validation Set is: 18.18% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 20.07 | sMAPE for Test Set is: 32.02% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:25:35,705]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:25:51,521]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:25:55,238]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:25:56,090]\u001b[0m Trial 932 finished with value: 24.669615504751658 and parameters: {'n_hidden': 3, 'learning_rate': 0.003784598325658685, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07944792006345525, 'dropout_rate_Layer_2': 0.36976796138342805, 'dropout_rate_Layer_3': 0.008110060346387699, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.012509035712473532, 'l1_Layer_2': 3.619635673808672e-05, 'l1_Layer_3': 2.2431761155657372e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 250, 'n_units_Layer_3': 165}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.67 | sMAPE for Validation Set is: 18.19% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 19.65 | sMAPE for Test Set is: 31.87% | rMAE for Test Set is: 0.62\n",
      "MAE for Validation Set is: 24.60 | sMAPE for Validation Set is: 18.05% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 19.79 | sMAPE for Test Set is: 31.65% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:25:56,221]\u001b[0m Trial 931 finished with value: 24.597897484025037 and parameters: {'n_hidden': 3, 'learning_rate': 0.003746891728598979, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1157792933505418, 'dropout_rate_Layer_2': 0.3797141666090066, 'dropout_rate_Layer_3': 0.0066489750740165166, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0063205114838345315, 'l1_Layer_2': 3.523891988102567e-05, 'l1_Layer_3': 0.00021295469414064092, 'n_units_Layer_1': 195, 'n_units_Layer_2': 290, 'n_units_Layer_3': 155}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:26:02,777]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:26:03,237]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:26:09,129]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:26:09,419]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:26:10,798]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:26:13,213]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:26:13,870]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:26:16,415]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:26:23,043]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:26:25,747]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:26:26,697]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:26:32,373]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:26:36,243]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:26:43,048]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:26:44,195]\u001b[0m Trial 944 finished with value: 24.38637965446966 and parameters: {'n_hidden': 3, 'learning_rate': 0.002945572066658314, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08005606828975824, 'dropout_rate_Layer_2': 0.3737935202568766, 'dropout_rate_Layer_3': 0.028305850989368102, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.011375386672401169, 'l1_Layer_2': 3.9657123466690597e-05, 'l1_Layer_3': 1.043778547417819e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 290, 'n_units_Layer_3': 160}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.39 | sMAPE for Validation Set is: 18.18% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 20.12 | sMAPE for Test Set is: 32.22% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:26:48,927]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:26:53,614]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:26:58,247]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:27:01,321]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:27:02,518]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:27:10,453]\u001b[0m Trial 948 finished with value: 24.185525111786927 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012594360192988915, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10361002187293446, 'dropout_rate_Layer_2': 0.1988803501276377, 'dropout_rate_Layer_3': 0.07110336106328763, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005554765852061948, 'l1_Layer_2': 0.001776440266750328, 'l1_Layer_3': 8.540462953579499e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 190, 'n_units_Layer_3': 175}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.19 | sMAPE for Validation Set is: 17.72% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.65 | sMAPE for Test Set is: 31.13% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:27:10,969]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:27:13,259]\u001b[0m Trial 954 finished with value: 24.45627179726542 and parameters: {'n_hidden': 3, 'learning_rate': 0.008062714175186683, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0028983837404738598, 'dropout_rate_Layer_2': 0.013136933001280616, 'dropout_rate_Layer_3': 0.355327392934212, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.030678579408070616, 'l1_Layer_2': 0.004110391127470408, 'l1_Layer_3': 0.0011769300322628186, 'n_units_Layer_1': 225, 'n_units_Layer_2': 85, 'n_units_Layer_3': 240}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.46 | sMAPE for Validation Set is: 18.16% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 19.91 | sMAPE for Test Set is: 31.90% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:27:15,806]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:27:15,866]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:27:21,104]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:27:25,353]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:27:25,772]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:27:26,290]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:27:33,685]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:27:34,789]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:27:42,002]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:27:46,130]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:27:51,330]\u001b[0m Trial 970 finished with value: 24.28294887852847 and parameters: {'n_hidden': 3, 'learning_rate': 0.003760075268019072, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07767144025551677, 'dropout_rate_Layer_2': 0.38631589001802935, 'dropout_rate_Layer_3': 0.01237964169428544, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005203054254025704, 'l1_Layer_2': 3.44029388955119e-05, 'l1_Layer_3': 1.2854674784559934e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 290, 'n_units_Layer_3': 170}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.28 | sMAPE for Validation Set is: 18.08% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.58 | sMAPE for Test Set is: 31.51% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:27:51,930]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:27:57,027]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:27:58,009]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:28:02,458]\u001b[0m Trial 965 finished with value: 24.42365070059313 and parameters: {'n_hidden': 3, 'learning_rate': 0.003965200748172358, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.013710332659771507, 'dropout_rate_Layer_2': 0.015855133661367236, 'dropout_rate_Layer_3': 0.3601774540825039, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.024711428162168522, 'l1_Layer_2': 0.004666593244770585, 'l1_Layer_3': 0.001487228747048328, 'n_units_Layer_1': 225, 'n_units_Layer_2': 200, 'n_units_Layer_3': 215}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.42 | sMAPE for Validation Set is: 18.07% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 19.68 | sMAPE for Test Set is: 31.63% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:28:03,161]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:28:09,029]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:28:09,877]\u001b[0m Trial 969 finished with value: 24.255924038445816 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013005216852740034, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014929952978379707, 'dropout_rate_Layer_2': 0.2002805908696403, 'dropout_rate_Layer_3': 0.08265714530439273, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005711828825461429, 'l1_Layer_2': 0.0009984723168948188, 'l1_Layer_3': 6.260279744744256e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 180, 'n_units_Layer_3': 60}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.26 | sMAPE for Validation Set is: 17.81% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.39 | sMAPE for Test Set is: 30.93% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:28:12,017]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:28:17,277]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:28:17,451]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:28:18,298]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:28:25,050]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:28:27,973]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:28:28,280]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:28:33,905]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:28:37,776]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:28:46,570]\u001b[0m Trial 985 finished with value: 24.45581799555355 and parameters: {'n_hidden': 3, 'learning_rate': 0.001302267796275804, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0008537344010219484, 'dropout_rate_Layer_2': 0.20079175357356355, 'dropout_rate_Layer_3': 0.08262435138550951, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005345312350412628, 'l1_Layer_2': 0.0010333099220386712, 'l1_Layer_3': 5.9034969325510426e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 60, 'n_units_Layer_3': 195}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.46 | sMAPE for Validation Set is: 17.98% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 19.94 | sMAPE for Test Set is: 31.73% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:28:50,945]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:28:53,971]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:28:57,561]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:28:59,074]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:29:03,351]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:29:04,628]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:29:05,412]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:29:07,528]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:29:10,776]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:29:13,953]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:29:14,372]\u001b[0m Trial 987 finished with value: 23.94130687396384 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012935791204694612, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0143545730855856, 'dropout_rate_Layer_2': 0.20135529125058912, 'dropout_rate_Layer_3': 0.08499862844873239, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005534074914883335, 'l1_Layer_2': 0.0007054776747714277, 'l1_Layer_3': 7.285375585101259e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 165, 'n_units_Layer_3': 60}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.94 | sMAPE for Validation Set is: 17.75% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 19.53 | sMAPE for Test Set is: 31.30% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:29:28,404]\u001b[0m Trial 998 finished with value: 24.889913728849848 and parameters: {'n_hidden': 3, 'learning_rate': 0.004202759062284469, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02043101538289488, 'dropout_rate_Layer_2': 0.01973647810365726, 'dropout_rate_Layer_3': 0.11987476331813365, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00952303288716927, 'l1_Layer_2': 0.0067814231122501675, 'l1_Layer_3': 0.0017295805400476053, 'n_units_Layer_1': 235, 'n_units_Layer_2': 80, 'n_units_Layer_3': 220}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.89 | sMAPE for Validation Set is: 18.46% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 20.04 | sMAPE for Test Set is: 31.99% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:29:32,320]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:29:36,220]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:29:36,800]\u001b[0m Trial 999 finished with value: 25.31175786340259 and parameters: {'n_hidden': 3, 'learning_rate': 0.00494582180802163, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02085852723488083, 'dropout_rate_Layer_2': 0.01283558391326233, 'dropout_rate_Layer_3': 0.3722582930640637, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03213905202267913, 'l1_Layer_2': 0.0025727566977435698, 'l1_Layer_3': 0.0016547758997094036, 'n_units_Layer_1': 225, 'n_units_Layer_2': 170, 'n_units_Layer_3': 185}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.31 | sMAPE for Validation Set is: 18.62% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 20.65 | sMAPE for Test Set is: 32.65% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:29:37,367]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:29:45,299]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:29:45,718]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:29:52,320]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:29:56,077]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:29:56,243]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:30:01,115]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:30:08,895]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:30:12,621]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:30:17,210]\u001b[0m Trial 1004 finished with value: 24.063338878329574 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009670465047246246, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01070079231688566, 'dropout_rate_Layer_2': 0.22040522258946577, 'dropout_rate_Layer_3': 0.07542586658139562, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004142356196131373, 'l1_Layer_2': 0.0007549487833476786, 'l1_Layer_3': 3.3255450694983625e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 150, 'n_units_Layer_3': 60}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.06 | sMAPE for Validation Set is: 17.73% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 20.52 | sMAPE for Test Set is: 31.86% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:30:20,689]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:30:25,776]\u001b[0m Trial 1007 finished with value: 24.36236883796738 and parameters: {'n_hidden': 3, 'learning_rate': 0.000976831617537786, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.023634590222680968, 'dropout_rate_Layer_2': 0.21854838776328006, 'dropout_rate_Layer_3': 0.07594777513826688, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001009756911287499, 'l1_Layer_2': 0.0019197920334254148, 'l1_Layer_3': 3.685743673561396e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 145, 'n_units_Layer_3': 55}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.36 | sMAPE for Validation Set is: 17.91% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 20.25 | sMAPE for Test Set is: 31.88% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:30:26,177]\u001b[0m Trial 1010 finished with value: 24.88874039968299 and parameters: {'n_hidden': 3, 'learning_rate': 0.004219438722659499, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015183363132464715, 'dropout_rate_Layer_2': 0.026590685616244433, 'dropout_rate_Layer_3': 0.3671269208984017, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03196147839148971, 'l1_Layer_2': 0.0032451399770125895, 'l1_Layer_3': 0.001979093958803777, 'n_units_Layer_1': 230, 'n_units_Layer_2': 110, 'n_units_Layer_3': 185}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.89 | sMAPE for Validation Set is: 18.36% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 20.37 | sMAPE for Test Set is: 32.15% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:30:26,516]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:30:32,069]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:30:34,369]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:30:35,104]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:30:41,271]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:30:46,072]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:30:49,367]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:30:49,872]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:30:50,993]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:30:56,034]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:30:58,223]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:30:58,979]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:31:06,550]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:31:06,934]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:31:07,718]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:31:15,350]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:31:19,251]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:31:21,493]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:31:21,687]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:31:22,587]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:31:28,242]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:31:32,579]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:31:33,242]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:31:38,129]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:31:41,736]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:31:42,924]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:31:47,684]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:31:48,468]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:31:49,161]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:31:50,840]\u001b[0m Trial 1014 finished with value: 24.032411991615593 and parameters: {'n_hidden': 3, 'learning_rate': 0.000976441569958907, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.024209413151946142, 'dropout_rate_Layer_2': 0.19369135911127983, 'dropout_rate_Layer_3': 0.0964672352074824, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010481120947583736, 'l1_Layer_2': 0.0013481202957869257, 'l1_Layer_3': 8.614011882277048e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 175, 'n_units_Layer_3': 60}. Best is trial 525 with value: 23.7570262281279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.03 | sMAPE for Validation Set is: 17.67% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.39 | sMAPE for Test Set is: 30.72% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:31:57,768]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:31:58,430]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:31:58,824]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:32:04,762]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:32:08,492]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:32:12,645]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:32:12,990]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:32:18,729]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:32:19,011]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:32:24,496]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:32:26,748]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:32:33,067]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:32:33,960]\u001b[0m Trial 1045 finished with value: 23.543212556754213 and parameters: {'n_hidden': 3, 'learning_rate': 0.0052342503469283, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03146433223704291, 'dropout_rate_Layer_2': 0.010211764237325898, 'dropout_rate_Layer_3': 0.14743633444404494, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.015399738757998131, 'l1_Layer_2': 0.004220332912545622, 'l1_Layer_3': 3.580587333769362e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 180, 'n_units_Layer_3': 235}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.54 | sMAPE for Validation Set is: 17.38% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 19.36 | sMAPE for Test Set is: 31.24% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:32:39,369]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:32:39,537]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:32:47,285]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:32:51,079]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:32:52,111]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:32:57,259]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:33:00,011]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:33:00,922]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:33:08,332]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:33:12,859]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:33:22,908]\u001b[0m Trial 1051 finished with value: 24.06843304523751 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009885706164284662, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.004616247890513642, 'dropout_rate_Layer_2': 0.19311568065636842, 'dropout_rate_Layer_3': 0.10389830683441659, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001561540728558296, 'l1_Layer_2': 0.001469882037369932, 'l1_Layer_3': 7.260426784982564e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 170, 'n_units_Layer_3': 75}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.07 | sMAPE for Validation Set is: 17.70% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.04 | sMAPE for Test Set is: 30.47% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:33:28,303]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:33:31,567]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:33:33,293]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:33:38,803]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:33:39,234]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:33:39,552]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:33:45,913]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:33:55,402]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:33:57,829]\u001b[0m Trial 1071 finished with value: 24.109759994608805 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011477308210776549, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.030750347372579596, 'dropout_rate_Layer_2': 0.3618219484728095, 'dropout_rate_Layer_3': 0.10476387533815643, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001538536074021226, 'l1_Layer_2': 1.203429085897507e-05, 'l1_Layer_3': 4.7425650585419055e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 185, 'n_units_Layer_3': 70}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.11 | sMAPE for Validation Set is: 17.89% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.56 | sMAPE for Test Set is: 31.27% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:34:01,636]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:34:03,272]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:34:04,853]\u001b[0m Trial 1077 finished with value: 23.914733092496295 and parameters: {'n_hidden': 3, 'learning_rate': 0.005410410340044463, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06925072820991947, 'dropout_rate_Layer_2': 0.22998750527209147, 'dropout_rate_Layer_3': 0.05961597814509109, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007788412487885797, 'l1_Layer_2': 3.256077717828e-05, 'l1_Layer_3': 4.2566738610994387e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 250, 'n_units_Layer_3': 190}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.91 | sMAPE for Validation Set is: 17.72% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 19.63 | sMAPE for Test Set is: 31.57% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:34:08,437]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:34:09,311]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:34:15,125]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:34:15,588]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:34:22,716]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:34:25,522]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:34:29,511]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:34:29,929]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:34:34,338]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:34:38,074]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:34:46,158]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:34:49,116]\u001b[0m Trial 1092 finished with value: 24.870569819993374 and parameters: {'n_hidden': 3, 'learning_rate': 0.004251791929667373, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0392606264847773, 'dropout_rate_Layer_2': 0.09543671258512142, 'dropout_rate_Layer_3': 0.2680294522811125, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.026119278481922824, 'l1_Layer_2': 0.0035496288991983477, 'l1_Layer_3': 0.00010818590687734245, 'n_units_Layer_1': 210, 'n_units_Layer_2': 150, 'n_units_Layer_3': 250}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.87 | sMAPE for Validation Set is: 18.40% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 20.37 | sMAPE for Test Set is: 32.16% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:34:51,998]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:34:54,268]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:34:59,356]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:34:59,876]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:35:04,300]\u001b[0m Trial 1089 finished with value: 24.13199064090973 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011549142797372275, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.036308976885261635, 'dropout_rate_Layer_2': 0.18164070405275348, 'dropout_rate_Layer_3': 0.10711405196821633, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001951145196246888, 'l1_Layer_2': 1.1775645855246459e-05, 'l1_Layer_3': 5.026828511785034e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 190, 'n_units_Layer_3': 65}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.13 | sMAPE for Validation Set is: 17.77% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.49 | sMAPE for Test Set is: 31.03% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:35:05,707]\u001b[0m Trial 1085 finished with value: 23.890751153684846 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011473521342617282, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.015450136340992076, 'dropout_rate_Layer_2': 0.3844669411515227, 'dropout_rate_Layer_3': 0.10758943892518973, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001831842065625116, 'l1_Layer_2': 1.30616568056097e-05, 'l1_Layer_3': 5.393431871542254e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 185, 'n_units_Layer_3': 65}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.89 | sMAPE for Validation Set is: 17.63% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 19.50 | sMAPE for Test Set is: 31.12% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:35:08,975]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:35:13,013]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:35:15,528]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:35:20,710]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:35:21,334]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.35 | sMAPE for Validation Set is: 18.70% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 19.85 | sMAPE for Test Set is: 31.69% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:35:24,254]\u001b[0m Trial 1100 finished with value: 25.353360172951913 and parameters: {'n_hidden': 3, 'learning_rate': 0.0042436473082027365, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03148985822947663, 'dropout_rate_Layer_2': 0.08534832263037148, 'dropout_rate_Layer_3': 0.33763743533759655, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.426229080058985e-05, 'l1_Layer_2': 0.0037270484889628907, 'l1_Layer_3': 0.00012462307935671597, 'n_units_Layer_1': 205, 'n_units_Layer_2': 120, 'n_units_Layer_3': 255}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:35:25,916]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:35:29,225]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:35:35,618]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:35:39,670]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:35:39,963]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:35:40,584]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:35:46,683]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:35:47,367]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:35:51,953]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:35:52,263]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:35:53,163]\u001b[0m Trial 1104 finished with value: 24.365476496227405 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010385643841863944, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.017060607364490107, 'dropout_rate_Layer_2': 0.3931690173322299, 'dropout_rate_Layer_3': 0.11226643465594083, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00440312844595416, 'l1_Layer_2': 1.2210031682661247e-05, 'l1_Layer_3': 4.449193956609431e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 190, 'n_units_Layer_3': 65}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.37 | sMAPE for Validation Set is: 17.94% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.77 | sMAPE for Test Set is: 31.56% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:36:00,924]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:36:11,257]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:36:15,201]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:36:19,907]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:36:24,810]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:36:28,774]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:36:32,581]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:36:35,716]\u001b[0m Trial 1120 finished with value: 24.356871507806876 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012485609081327794, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04806296400886673, 'dropout_rate_Layer_2': 0.3623638984862987, 'dropout_rate_Layer_3': 0.12078974434950952, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0020688593896662608, 'l1_Layer_2': 1.782430141337681e-05, 'l1_Layer_3': 3.778643540621571e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 195, 'n_units_Layer_3': 75}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.36 | sMAPE for Validation Set is: 17.95% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 20.50 | sMAPE for Test Set is: 32.09% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:36:38,528]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:36:42,246]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:36:46,182]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:36:48,383]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:36:58,229]\u001b[0m Trial 1117 finished with value: 24.008857196482865 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010255584722227804, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04885661864742037, 'dropout_rate_Layer_2': 0.3744211062389894, 'dropout_rate_Layer_3': 0.11386793159270715, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0019506170895184974, 'l1_Layer_2': 1.4562849585614796e-05, 'l1_Layer_3': 3.07473961864966e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 195, 'n_units_Layer_3': 80}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.01 | sMAPE for Validation Set is: 17.80% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.44 | sMAPE for Test Set is: 31.00% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:37:02,963]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:37:03,117]\u001b[0m Trial 1112 finished with value: 24.054046144710174 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009986063009867275, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.017419973870667183, 'dropout_rate_Layer_2': 0.38085875433140043, 'dropout_rate_Layer_3': 0.11380276292603159, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0021409687138702754, 'l1_Layer_2': 1.4339320329097015e-05, 'l1_Layer_3': 3.531208508301462e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 190, 'n_units_Layer_3': 75}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.05 | sMAPE for Validation Set is: 17.82% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 20.87 | sMAPE for Test Set is: 32.47% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:37:09,394]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:37:09,670]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:37:15,974]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:37:19,269]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:37:20,028]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:37:24,786]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:37:26,248]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:37:29,704]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:37:32,605]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:37:33,789]\u001b[0m Trial 1134 finished with value: 24.18623823824611 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027314343107217526, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23349568418859595, 'dropout_rate_Layer_2': 0.3874694278882947, 'dropout_rate_Layer_3': 0.0006692626145080307, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007478149990452139, 'l1_Layer_2': 3.3607191826684195e-05, 'l1_Layer_3': 0.0003008219958062772, 'n_units_Layer_1': 190, 'n_units_Layer_2': 235, 'n_units_Layer_3': 185}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.19 | sMAPE for Validation Set is: 17.81% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.55 | sMAPE for Test Set is: 31.37% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:37:34,477]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:37:41,949]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:37:42,649]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:37:49,258]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:37:53,207]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:37:56,392]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:37:59,808]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:38:00,831]\u001b[0m Trial 1130 finished with value: 23.97669780752568 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008535031343350587, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01804099829064295, 'dropout_rate_Layer_2': 0.35471440662743564, 'dropout_rate_Layer_3': 0.09546370429546094, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014454870689221712, 'l1_Layer_2': 1.3776479415784268e-05, 'l1_Layer_3': 6.537628176170603e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 185, 'n_units_Layer_3': 60}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.98 | sMAPE for Validation Set is: 17.58% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 19.36 | sMAPE for Test Set is: 30.89% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:38:06,184]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:38:07,379]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:38:14,650]\u001b[0m Trial 1146 finished with value: 24.946906043970387 and parameters: {'n_hidden': 3, 'learning_rate': 0.008601959931422244, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33044997768081485, 'dropout_rate_Layer_2': 0.13027963343937335, 'dropout_rate_Layer_3': 0.10524565756481499, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003427245584992694, 'l1_Layer_2': 0.026432356481747694, 'l1_Layer_3': 0.0012816580175215302, 'n_units_Layer_1': 190, 'n_units_Layer_2': 70, 'n_units_Layer_3': 230}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.95 | sMAPE for Validation Set is: 18.40% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 20.08 | sMAPE for Test Set is: 31.92% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:38:15,889]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:38:18,657]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:38:19,943]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:38:25,336]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:38:25,894]\u001b[0m Trial 1153 finished with value: 25.2037190050697 and parameters: {'n_hidden': 3, 'learning_rate': 0.009719497691347953, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04276275461487279, 'dropout_rate_Layer_2': 0.024140583754962187, 'dropout_rate_Layer_3': 0.33388520451781606, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.027203114787997296, 'l1_Layer_2': 0.012276165444110015, 'l1_Layer_3': 1.1662341654618917e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 100, 'n_units_Layer_3': 215}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.20 | sMAPE for Validation Set is: 18.61% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 20.26 | sMAPE for Test Set is: 32.33% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:38:26,184]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:38:32,972]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:38:35,489]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:38:38,899]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:38:41,722]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:38:45,698]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:38:55,179]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:39:00,022]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:39:06,484]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:39:17,249]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:39:23,951]\u001b[0m Trial 1156 finished with value: 24.128108119420727 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008794628490875385, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05187356627760201, 'dropout_rate_Layer_2': 0.3837354014194671, 'dropout_rate_Layer_3': 0.10246597827683453, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016515134916165377, 'l1_Layer_2': 1.3994615873206635e-05, 'l1_Layer_3': 2.564986078149245e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 200, 'n_units_Layer_3': 80}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.13 | sMAPE for Validation Set is: 17.83% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 21.17 | sMAPE for Test Set is: 32.62% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:39:26,892]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:39:27,583]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:39:27,744]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:39:37,147]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:39:50,156]\u001b[0m Trial 1167 finished with value: 24.172329571421642 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010641505795045286, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0307672043939377, 'dropout_rate_Layer_2': 0.3660462780532564, 'dropout_rate_Layer_3': 0.10103224959587563, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0017065395546988463, 'l1_Layer_2': 2.029347529518495e-05, 'l1_Layer_3': 8.767116486125667e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 190, 'n_units_Layer_3': 75}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.17 | sMAPE for Validation Set is: 17.77% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 20.79 | sMAPE for Test Set is: 32.38% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:39:51,545]\u001b[0m Trial 1173 finished with value: 24.78148657350567 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029296100572120632, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11462846041339349, 'dropout_rate_Layer_2': 0.3675080410404137, 'dropout_rate_Layer_3': 0.01730215917591344, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005219345128522577, 'l1_Layer_2': 0.0001476572542083751, 'l1_Layer_3': 9.156914657831884e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 240, 'n_units_Layer_3': 175}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.78 | sMAPE for Validation Set is: 18.22% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 19.76 | sMAPE for Test Set is: 31.63% | rMAE for Test Set is: 0.62\n",
      "MAE for Validation Set is: 24.34 | sMAPE for Validation Set is: 17.98% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 20.18 | sMAPE for Test Set is: 31.97% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:39:51,586]\u001b[0m Trial 1172 finished with value: 24.341517534638086 and parameters: {'n_hidden': 3, 'learning_rate': 0.003755731661223701, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.108141627711474, 'dropout_rate_Layer_2': 0.10215907810862643, 'dropout_rate_Layer_3': 0.017656952308548225, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.009711721036080385, 'l1_Layer_2': 1.728658276850379e-05, 'l1_Layer_3': 8.87809892343397e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 285, 'n_units_Layer_3': 175}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:39:56,456]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:40:00,949]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:40:01,191]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:40:12,844]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:40:14,436]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:40:20,835]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:40:21,032]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:40:21,211]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:40:28,937]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:40:32,585]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:40:32,804]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:40:33,680]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:40:40,496]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:40:40,528]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:40:42,298]\u001b[0m Trial 1175 finished with value: 23.948756958552025 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008174109253863246, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04942243588496735, 'dropout_rate_Layer_2': 0.36474050505757843, 'dropout_rate_Layer_3': 0.11904545528622178, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0018412278840605634, 'l1_Layer_2': 1.2429880769631527e-05, 'l1_Layer_3': 3.8196808966920414e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 205, 'n_units_Layer_3': 90}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.95 | sMAPE for Validation Set is: 17.69% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 19.38 | sMAPE for Test Set is: 30.98% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:40:43,650]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:40:48,297]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:40:49,420]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:40:51,961]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:40:55,548]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:40:55,872]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:40:59,957]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:41:07,260]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:41:09,163]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:41:09,689]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:41:16,503]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:41:17,146]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:41:22,399]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:41:22,931]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:41:26,019]\u001b[0m Trial 1197 finished with value: 24.581242353334556 and parameters: {'n_hidden': 3, 'learning_rate': 0.009351168258351117, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008482263785675683, 'dropout_rate_Layer_2': 0.13571124040856428, 'dropout_rate_Layer_3': 0.12826302114017532, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.04035386960597697, 'l1_Layer_2': 0.004660646430215648, 'l1_Layer_3': 0.0007492772960980429, 'n_units_Layer_1': 220, 'n_units_Layer_2': 90, 'n_units_Layer_3': 50}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.58 | sMAPE for Validation Set is: 18.20% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 20.05 | sMAPE for Test Set is: 31.97% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:41:29,789]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:41:39,700]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:41:45,368]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:41:49,814]\u001b[0m Trial 1209 finished with value: 24.424199127962112 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036189029529475687, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0941071424370314, 'dropout_rate_Layer_2': 0.3998969450942786, 'dropout_rate_Layer_3': 8.872844301593963e-06, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008159091049487546, 'l1_Layer_2': 2.404635022896514e-05, 'l1_Layer_3': 0.00018845262631049726, 'n_units_Layer_1': 215, 'n_units_Layer_2': 295, 'n_units_Layer_3': 160}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.42 | sMAPE for Validation Set is: 18.03% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 19.49 | sMAPE for Test Set is: 31.29% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:41:59,664]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:42:03,918]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:42:04,116]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:42:06,594]\u001b[0m Trial 1202 finished with value: 24.025092820506575 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007086420452650494, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.034712627420823663, 'dropout_rate_Layer_2': 0.3496786133020362, 'dropout_rate_Layer_3': 0.10752447267909941, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0023179554159192374, 'l1_Layer_2': 1.2190251680497366e-05, 'l1_Layer_3': 1.8733637948359037e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 200, 'n_units_Layer_3': 75}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.03 | sMAPE for Validation Set is: 17.69% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.61 | sMAPE for Test Set is: 31.22% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:42:11,178]\u001b[0m Trial 1212 finished with value: 23.960852328610486 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034106152589008557, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09259485915977035, 'dropout_rate_Layer_2': 0.39627270479280857, 'dropout_rate_Layer_3': 0.011184948298781684, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008180520806185093, 'l1_Layer_2': 2.091312767052347e-05, 'l1_Layer_3': 0.0001797639615008736, 'n_units_Layer_1': 205, 'n_units_Layer_2': 295, 'n_units_Layer_3': 155}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.96 | sMAPE for Validation Set is: 17.78% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 19.24 | sMAPE for Test Set is: 31.07% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:42:11,505]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:42:11,643]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:42:19,629]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:42:20,592]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:42:23,951]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:42:26,534]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:42:29,723]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:42:30,061]\u001b[0m Trial 1216 finished with value: 25.78564832282022 and parameters: {'n_hidden': 3, 'learning_rate': 0.010435538491695278, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0001941419777235793, 'dropout_rate_Layer_2': 0.14123250690557823, 'dropout_rate_Layer_3': 0.1254692016175194, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.04210424338163311, 'l1_Layer_2': 0.004225887597941838, 'l1_Layer_3': 0.0007830282097940325, 'n_units_Layer_1': 220, 'n_units_Layer_2': 95, 'n_units_Layer_3': 55}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.79 | sMAPE for Validation Set is: 19.01% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 20.65 | sMAPE for Test Set is: 32.60% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:42:31,275]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:42:34,616]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:42:38,078]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:42:45,507]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:42:49,162]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:42:51,208]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:42:56,042]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:43:00,169]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:43:04,481]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.22 | sMAPE for Validation Set is: 17.87% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.74 | sMAPE for Test Set is: 31.38% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:43:06,316]\u001b[0m Trial 1227 finished with value: 24.221480949725787 and parameters: {'n_hidden': 3, 'learning_rate': 0.00284681107913317, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06592323345386435, 'dropout_rate_Layer_2': 0.3902070393845329, 'dropout_rate_Layer_3': 0.00021098091915472406, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.013312906974500615, 'l1_Layer_2': 2.2806871561818123e-05, 'l1_Layer_3': 8.11901002846018e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 295, 'n_units_Layer_3': 165}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:43:11,121]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:43:14,439]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:43:14,668]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:43:20,638]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:43:28,002]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:43:30,294]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:43:32,012]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:43:33,374]\u001b[0m Trial 1233 finished with value: 23.753470876020703 and parameters: {'n_hidden': 3, 'learning_rate': 0.004545376455465168, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07450153217828093, 'dropout_rate_Layer_2': 0.38304589851768034, 'dropout_rate_Layer_3': 0.022648581927512935, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.012048882623258567, 'l1_Layer_2': 2.2579287692498993e-05, 'l1_Layer_3': 0.00018172890781839837, 'n_units_Layer_1': 215, 'n_units_Layer_2': 300, 'n_units_Layer_3': 170}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.75 | sMAPE for Validation Set is: 17.52% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 18.59 | sMAPE for Test Set is: 30.61% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:43:34,699]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:43:40,698]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:43:41,009]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:43:46,604]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:43:50,200]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:43:51,350]\u001b[0m Trial 1228 finished with value: 24.072220923570114 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010968162137814485, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04216774695903829, 'dropout_rate_Layer_2': 0.3738845886168275, 'dropout_rate_Layer_3': 0.1031029722842971, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001177365892609525, 'l1_Layer_2': 1.5726289957196798e-05, 'l1_Layer_3': 2.417615229453615e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 210, 'n_units_Layer_3': 60}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.07 | sMAPE for Validation Set is: 17.62% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.59 | sMAPE for Test Set is: 31.11% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:43:53,444]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:43:58,967]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:44:02,386]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:44:06,554]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:44:07,306]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:44:12,532]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:44:12,810]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:44:19,912]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:44:20,511]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:44:23,262]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:44:27,194]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:44:33,758]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:44:34,540]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:44:40,668]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:44:44,159]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:44:44,980]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:44:49,818]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:44:50,733]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:44:55,662]\u001b[0m Trial 1258 finished with value: 24.279184078617195 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031529449555838304, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05874066102068866, 'dropout_rate_Layer_2': 0.3843715476925715, 'dropout_rate_Layer_3': 0.0002833249446297804, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.012217562536918445, 'l1_Layer_2': 2.7888515917568464e-05, 'l1_Layer_3': 0.00012344757862948208, 'n_units_Layer_1': 210, 'n_units_Layer_2': 300, 'n_units_Layer_3': 175}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:44:55,755]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.28 | sMAPE for Validation Set is: 17.89% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.84 | sMAPE for Test Set is: 31.59% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:45:00,257]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:45:00,947]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:45:01,823]\u001b[0m Trial 1262 finished with value: 24.346019432270552 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028004527741016124, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06082283195831868, 'dropout_rate_Layer_2': 0.3904921572331393, 'dropout_rate_Layer_3': 0.0213248741021795, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01576316193720475, 'l1_Layer_2': 2.4618558218386995e-05, 'l1_Layer_3': 0.00019058783990328598, 'n_units_Layer_1': 210, 'n_units_Layer_2': 300, 'n_units_Layer_3': 175}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.35 | sMAPE for Validation Set is: 17.99% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.92 | sMAPE for Test Set is: 31.92% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:45:01,922]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:45:08,748]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:45:11,339]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:45:15,818]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:45:16,732]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:45:17,209]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:45:25,241]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:45:25,522]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:45:31,732]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:45:34,942]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:45:35,291]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:45:40,078]\u001b[0m Trial 1275 finished with value: 24.23729517225003 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023781255552363942, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.059493440454092245, 'dropout_rate_Layer_2': 0.3838036627413948, 'dropout_rate_Layer_3': 0.007684244367249748, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01260896724796988, 'l1_Layer_2': 2.1887494308819678e-05, 'l1_Layer_3': 0.00012569994045061466, 'n_units_Layer_1': 215, 'n_units_Layer_2': 295, 'n_units_Layer_3': 170}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.24 | sMAPE for Validation Set is: 17.95% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.55 | sMAPE for Test Set is: 31.52% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:45:43,966]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:45:44,025]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:45:49,792]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:45:53,483]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:46:05,172]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:46:06,505]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:46:12,445]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:46:15,432]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:46:15,991]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:46:26,803]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:46:29,818]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:46:34,000]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:46:34,505]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:46:36,150]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:46:44,062]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:46:45,197]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:46:46,374]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:46:46,717]\u001b[0m Trial 1285 finished with value: 24.013007564885157 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011681622663913213, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04799772417582318, 'dropout_rate_Layer_2': 0.3715853742266481, 'dropout_rate_Layer_3': 0.1036740913132597, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015281720194182564, 'l1_Layer_2': 1.425580385214967e-05, 'l1_Layer_3': 4.244458091905197e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 200, 'n_units_Layer_3': 75}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.01 | sMAPE for Validation Set is: 17.68% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.52 | sMAPE for Test Set is: 31.33% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:46:49,311]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:46:54,966]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:46:56,078]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:46:57,247]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:46:59,530]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:47:04,884]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:47:05,277]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:47:10,064]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:47:11,563]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:47:13,888]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:47:18,899]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:47:19,825]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:47:23,896]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:47:24,305]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:47:24,895]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:47:25,565]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:47:35,690]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:47:36,627]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:47:37,363]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:47:44,158]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:47:46,033]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:47:49,149]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:47:49,677]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:47:50,824]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:47:57,808]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:47:58,520]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:48:00,750]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:48:04,325]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:48:07,081]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:48:07,665]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:48:11,683]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:48:15,354]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:48:15,751]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:48:21,409]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:48:22,136]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:48:28,089]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:48:31,523]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:48:46,521]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:48:49,183]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:48:51,464]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:48:55,608]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:48:56,714]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:49:01,269]\u001b[0m Trial 1336 finished with value: 24.005495984665703 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010960465183084845, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.028670648209509077, 'dropout_rate_Layer_2': 0.3658032498700592, 'dropout_rate_Layer_3': 0.08743244876649989, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0027551669537750384, 'l1_Layer_2': 1.3142456338443615e-05, 'l1_Layer_3': 6.931701958052215e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 210, 'n_units_Layer_3': 70}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.01 | sMAPE for Validation Set is: 17.67% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.57 | sMAPE for Test Set is: 31.04% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:49:01,555]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.11 | sMAPE for Validation Set is: 17.63% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.46 | sMAPE for Test Set is: 31.31% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:49:05,706]\u001b[0m Trial 1339 finished with value: 24.114124609285643 and parameters: {'n_hidden': 3, 'learning_rate': 0.003484267517683971, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08098078244206375, 'dropout_rate_Layer_2': 0.3838138010866849, 'dropout_rate_Layer_3': 0.008574448181408758, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.014489891345603793, 'l1_Layer_2': 1.72757181810489e-05, 'l1_Layer_3': 3.0466540020517404e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 265, 'n_units_Layer_3': 175}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:49:07,794]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:49:09,393]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:49:12,627]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:49:14,860]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:49:19,917]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:49:20,946]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:49:27,290]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:49:31,051]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:49:34,155]\u001b[0m Trial 1344 finished with value: 23.97559008067658 and parameters: {'n_hidden': 3, 'learning_rate': 0.0037311367224109504, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08177068936832986, 'dropout_rate_Layer_2': 0.37158469803177874, 'dropout_rate_Layer_3': 0.03302467664304122, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00650426414665034, 'l1_Layer_2': 3.132732826543644e-05, 'l1_Layer_3': 0.00018749110837809027, 'n_units_Layer_1': 205, 'n_units_Layer_2': 290, 'n_units_Layer_3': 140}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.98 | sMAPE for Validation Set is: 17.82% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 19.34 | sMAPE for Test Set is: 31.27% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:49:34,704]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:49:35,192]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:49:36,790]\u001b[0m Trial 1349 finished with value: 24.7846883180288 and parameters: {'n_hidden': 3, 'learning_rate': 0.007610144488369559, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.014404955891024022, 'dropout_rate_Layer_2': 0.03838227215752224, 'dropout_rate_Layer_3': 0.3539271869339367, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.027622011408433185, 'l1_Layer_2': 0.0034111648164414574, 'l1_Layer_3': 0.0006881560265793949, 'n_units_Layer_1': 205, 'n_units_Layer_2': 100, 'n_units_Layer_3': 280}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.78 | sMAPE for Validation Set is: 18.33% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 20.08 | sMAPE for Test Set is: 32.06% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:49:42,148]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:49:46,805]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:49:47,339]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:49:47,532]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:49:55,432]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:49:56,482]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:50:01,911]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:50:03,687]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:50:04,563]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:50:04,815]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:50:05,394]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:50:14,111]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:50:14,739]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:50:16,235]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:50:22,604]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:50:26,051]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:50:28,071]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:50:32,056]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:50:32,181]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:50:38,518]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:50:39,050]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:50:45,329]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:50:45,807]\u001b[0m Trial 1371 finished with value: 24.621658223938454 and parameters: {'n_hidden': 3, 'learning_rate': 0.00369228282314355, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28421337918053774, 'dropout_rate_Layer_2': 0.3998800095557458, 'dropout_rate_Layer_3': 0.03121684988794551, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005678702085805528, 'l1_Layer_2': 1.9639935233917893e-05, 'l1_Layer_3': 0.00013109330612181237, 'n_units_Layer_1': 225, 'n_units_Layer_2': 280, 'n_units_Layer_3': 175}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.62 | sMAPE for Validation Set is: 18.24% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 19.89 | sMAPE for Test Set is: 31.87% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:50:46,376]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:50:51,818]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:50:55,409]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:50:56,682]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:50:57,457]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:50:57,610]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:51:04,588]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:51:05,577]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:51:09,332]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:51:09,396]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:51:16,652]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:51:16,858]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:51:17,241]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:51:21,093]\u001b[0m Trial 1385 finished with value: 24.82086627686157 and parameters: {'n_hidden': 3, 'learning_rate': 0.004160127696853374, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0848513502017662, 'dropout_rate_Layer_2': 0.37283579407486117, 'dropout_rate_Layer_3': 0.03827287427171004, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.009310274516370377, 'l1_Layer_2': 2.9527021030575004e-05, 'l1_Layer_3': 0.00020255199433240185, 'n_units_Layer_1': 195, 'n_units_Layer_2': 285, 'n_units_Layer_3': 180}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.82 | sMAPE for Validation Set is: 18.16% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 19.82 | sMAPE for Test Set is: 31.68% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:51:28,304]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:51:29,110]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:51:33,713]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:51:33,790]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:51:34,425]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:51:38,949]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:51:44,256]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:51:46,788]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:51:51,287]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:51:51,490]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:51:53,443]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:52:00,605]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:52:02,860]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:52:07,599]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:52:10,892]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:52:11,651]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:52:12,258]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:52:20,357]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:52:23,530]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:52:39,503]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:52:43,711]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:52:48,826]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:52:54,897]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:52:58,601]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:53:02,313]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:53:09,962]\u001b[0m Trial 1415 finished with value: 23.6219602099 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009508308974031838, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.002592500476434202, 'dropout_rate_Layer_2': 0.04653487830807698, 'dropout_rate_Layer_3': 0.07706276615783547, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0026904721646712113, 'l1_Layer_2': 1.414175888186908e-05, 'l1_Layer_3': 4.794153960580028e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 195, 'n_units_Layer_3': 65}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.62 | sMAPE for Validation Set is: 17.44% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 19.17 | sMAPE for Test Set is: 30.43% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:53:14,693]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:53:17,097]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:53:18,885]\u001b[0m Trial 1412 finished with value: 24.167248260484428 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009738260848526879, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00021566195850870364, 'dropout_rate_Layer_2': 0.3433825243745424, 'dropout_rate_Layer_3': 0.07865425887439342, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002359998600232283, 'l1_Layer_2': 1.4259332604030498e-05, 'l1_Layer_3': 0.00011475187652495025, 'n_units_Layer_1': 110, 'n_units_Layer_2': 185, 'n_units_Layer_3': 65}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.17 | sMAPE for Validation Set is: 17.75% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.50 | sMAPE for Test Set is: 30.88% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:53:19,531]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:53:29,710]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:53:30,031]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:53:32,891]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:53:36,427]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:53:37,608]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:53:39,499]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:53:40,076]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:53:45,671]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:53:45,830]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:53:48,477]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:53:50,396]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:53:56,550]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:53:57,270]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:53:58,228]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:54:06,040]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:54:07,784]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:54:11,261]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:54:12,341]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:54:17,561]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:54:17,892]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:54:19,140]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:54:24,158]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:54:25,125]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:54:26,282]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:54:34,033]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:54:34,246]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:54:34,546]\u001b[0m Trial 1438 finished with value: 24.3376565962563 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027519834197764935, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07528443803220901, 'dropout_rate_Layer_2': 0.3919242371302933, 'dropout_rate_Layer_3': 0.017909147777396, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006389464544455779, 'l1_Layer_2': 3.866981229319921e-05, 'l1_Layer_3': 0.00015372189553529886, 'n_units_Layer_1': 210, 'n_units_Layer_2': 280, 'n_units_Layer_3': 180}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.34 | sMAPE for Validation Set is: 17.86% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.47 | sMAPE for Test Set is: 31.24% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:54:35,078]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:54:45,029]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:54:45,335]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:54:47,013]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:54:53,328]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:54:57,231]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:54:59,505]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:55:01,693]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:55:04,269]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:55:04,936]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:55:06,472]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:55:13,909]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:55:14,302]\u001b[0m Trial 1454 finished with value: 23.98842574838896 and parameters: {'n_hidden': 3, 'learning_rate': 0.00249759842130189, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.062111337997773255, 'dropout_rate_Layer_2': 0.3937389091584585, 'dropout_rate_Layer_3': 0.02638782992272087, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004237384116030944, 'l1_Layer_2': 4.292341402728168e-05, 'l1_Layer_3': 0.00016816029698576507, 'n_units_Layer_1': 220, 'n_units_Layer_2': 270, 'n_units_Layer_3': 190}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.99 | sMAPE for Validation Set is: 17.72% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.24 | sMAPE for Test Set is: 30.97% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:55:14,577]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:55:16,068]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:55:25,618]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:55:25,826]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:55:27,064]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:55:32,738]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:55:33,908]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:55:34,508]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:55:40,228]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:55:44,882]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:55:48,584]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:55:49,391]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:55:52,002]\u001b[0m Trial 1465 finished with value: 23.885003467862607 and parameters: {'n_hidden': 3, 'learning_rate': 0.003110899969600165, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04409801875167725, 'dropout_rate_Layer_2': 0.38383607108590784, 'dropout_rate_Layer_3': 0.034687426596330756, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005136564709301751, 'l1_Layer_2': 4.5699177786639466e-05, 'l1_Layer_3': 0.00015679543951938987, 'n_units_Layer_1': 230, 'n_units_Layer_2': 270, 'n_units_Layer_3': 190}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.89 | sMAPE for Validation Set is: 17.76% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 19.58 | sMAPE for Test Set is: 31.59% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:55:52,703]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:55:58,703]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:55:59,443]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:56:04,008]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:56:04,302]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:56:04,616]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:56:12,973]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:56:14,898]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:56:16,277]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:56:21,181]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:56:21,682]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:56:21,863]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:56:29,152]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:56:29,378]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:56:29,633]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:56:37,290]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:56:38,050]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:56:38,808]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.01 | sMAPE for Validation Set is: 17.69% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.78 | sMAPE for Test Set is: 31.27% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:56:45,696]\u001b[0m Trial 1477 finished with value: 24.006153248115 and parameters: {'n_hidden': 3, 'learning_rate': 0.001047436274126308, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0615681274805406, 'dropout_rate_Layer_2': 0.32864145913608556, 'dropout_rate_Layer_3': 0.09554173952084719, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0019190987006144622, 'l1_Layer_2': 1.4448674533783235e-05, 'l1_Layer_3': 4.295809490995144e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 210, 'n_units_Layer_3': 70}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:56:49,512]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:56:51,499]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:56:54,978]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-12 11:56:59,920]\u001b[0m Trial 1495 finished with value: 24.29611679319119 and parameters: {'n_hidden': 3, 'learning_rate': 0.002983197661689012, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05879524481394233, 'dropout_rate_Layer_2': 0.3783855192480959, 'dropout_rate_Layer_3': 0.030410101461871918, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.015660413367314274, 'l1_Layer_2': 6.508825307966207e-05, 'l1_Layer_3': 4.192111285886353e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 275, 'n_units_Layer_3': 195}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.30 | sMAPE for Validation Set is: 17.97% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.63 | sMAPE for Test Set is: 31.62% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-12 11:57:04,588]\u001b[0m Trial 1496 finished with value: 24.039227381191626 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009079720059946939, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13863316876586299, 'dropout_rate_Layer_2': 0.3071015200332531, 'dropout_rate_Layer_3': 0.0910259226887319, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011852243520296666, 'l1_Layer_2': 1.176913086763321e-05, 'l1_Layer_3': 3.232603469772227e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 215, 'n_units_Layer_3': 65}. Best is trial 1045 with value: 23.543212556754213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.04 | sMAPE for Validation Set is: 17.71% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.58 | sMAPE for Test Set is: 31.13% | rMAE for Test Set is: 0.62\n",
      "for 2023-01-01, MAE is:9.44 & sMAPE is:151.77% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :9.44 & 151.77% & 1.10\n",
      "for 2023-01-02, MAE is:75.29 & sMAPE is:97.09% & rMAE is:2.03 ||| daily mean of MAE & sMAPE & rMAE till now are :42.36 & 124.43% & 1.57\n",
      "for 2023-01-03, MAE is:17.48 & sMAPE is:13.35% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :34.07 & 87.40% & 1.25\n",
      "for 2023-01-04, MAE is:14.72 & sMAPE is:12.75% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :29.23 & 68.74% & 0.99\n",
      "for 2023-01-05, MAE is:20.38 & sMAPE is:19.07% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :27.46 & 58.80% & 0.84\n",
      "for 2023-01-06, MAE is:12.67 & sMAPE is:12.60% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :25.00 & 51.10% & 0.72\n",
      "for 2023-01-07, MAE is:59.39 & sMAPE is:116.57% & rMAE is:2.67 ||| daily mean of MAE & sMAPE & rMAE till now are :29.91 & 60.46% & 1.00\n",
      "for 2023-01-08, MAE is:20.21 & sMAPE is:115.53% & rMAE is:3.94 ||| daily mean of MAE & sMAPE & rMAE till now are :28.70 & 67.34% & 1.37\n",
      "for 2023-01-09, MAE is:61.80 & sMAPE is:105.36% & rMAE is:2.42 ||| daily mean of MAE & sMAPE & rMAE till now are :32.38 & 71.56% & 1.48\n",
      "for 2023-01-10, MAE is:16.97 & sMAPE is:15.88% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :30.83 & 66.00% & 1.40\n",
      "for 2023-01-11, MAE is:33.62 & sMAPE is:57.71% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :31.09 & 65.24% & 1.36\n",
      "for 2023-01-12, MAE is:18.92 & sMAPE is:20.80% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :30.07 & 61.54% & 1.34\n",
      "for 2023-01-13, MAE is:22.16 & sMAPE is:26.58% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :29.47 & 58.85% & 1.31\n",
      "for 2023-01-14, MAE is:37.65 & sMAPE is:53.76% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :30.05 & 58.49% & 1.31\n",
      "for 2023-01-15, MAE is:14.31 & sMAPE is:63.20% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :29.00 & 58.80% & 1.30\n",
      "for 2023-01-16, MAE is:19.28 & sMAPE is:97.30% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :28.39 & 61.21% & 1.24\n",
      "for 2023-01-17, MAE is:16.43 & sMAPE is:126.67% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :27.69 & 65.06% & 1.17\n",
      "for 2023-01-18, MAE is:16.88 & sMAPE is:109.67% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :27.09 & 67.54% & 1.12\n",
      "for 2023-01-19, MAE is:15.24 & sMAPE is:41.50% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :26.46 & 66.17% & 1.08\n",
      "for 2023-01-20, MAE is:52.17 & sMAPE is:70.46% & rMAE is:3.64 ||| daily mean of MAE & sMAPE & rMAE till now are :27.75 & 66.38% & 1.21\n",
      "for 2023-01-21, MAE is:33.70 & sMAPE is:47.09% & rMAE is:3.13 ||| daily mean of MAE & sMAPE & rMAE till now are :28.03 & 65.46% & 1.30\n",
      "for 2023-01-22, MAE is:30.34 & sMAPE is:75.18% & rMAE is:1.67 ||| daily mean of MAE & sMAPE & rMAE till now are :28.14 & 65.90% & 1.32\n",
      "for 2023-01-23, MAE is:20.11 & sMAPE is:25.38% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :27.79 & 64.14% & 1.27\n",
      "for 2023-01-24, MAE is:25.75 & sMAPE is:24.99% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :27.70 & 62.51% & 1.23\n",
      "for 2023-01-25, MAE is:21.25 & sMAPE is:21.18% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :27.45 & 60.86% & 1.20\n",
      "for 2023-01-26, MAE is:12.56 & sMAPE is:18.07% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :26.87 & 59.21% & 1.16\n",
      "for 2023-01-27, MAE is:17.65 & sMAPE is:37.02% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :26.53 & 58.39% & 1.14\n",
      "for 2023-01-28, MAE is:14.15 & sMAPE is:34.05% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :26.09 & 57.52% & 1.12\n",
      "for 2023-01-29, MAE is:28.98 & sMAPE is:35.71% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :26.19 & 56.77% & 1.12\n",
      "for 2023-01-30, MAE is:25.40 & sMAPE is:19.62% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :26.16 & 55.53% & 1.09\n",
      "for 2023-01-31, MAE is:17.27 & sMAPE is:13.63% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :25.88 & 54.18% & 1.07\n",
      "for 2023-02-01, MAE is:20.93 & sMAPE is:17.06% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :25.72 & 53.02% & 1.05\n",
      "for 2023-02-02, MAE is:23.78 & sMAPE is:19.05% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :25.66 & 51.99% & 1.03\n",
      "for 2023-02-03, MAE is:17.13 & sMAPE is:12.84% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :25.41 & 50.84% & 1.01\n",
      "for 2023-02-04, MAE is:18.02 & sMAPE is:15.36% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :25.20 & 49.82% & 0.98\n",
      "for 2023-02-05, MAE is:39.20 & sMAPE is:52.68% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :25.59 & 49.90% & 0.99\n",
      "for 2023-02-06, MAE is:31.63 & sMAPE is:24.88% & rMAE is:1.81 ||| daily mean of MAE & sMAPE & rMAE till now are :25.75 & 49.23% & 1.01\n",
      "for 2023-02-07, MAE is:10.83 & sMAPE is:8.22% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :25.36 & 48.15% & 1.01\n",
      "for 2023-02-08, MAE is:21.61 & sMAPE is:16.87% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :25.26 & 47.35% & 1.02\n",
      "for 2023-02-09, MAE is:13.19 & sMAPE is:9.98% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :24.96 & 46.41% & 1.02\n",
      "for 2023-02-10, MAE is:12.52 & sMAPE is:9.52% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :24.66 & 45.51% & 1.03\n",
      "for 2023-02-11, MAE is:15.09 & sMAPE is:11.90% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :24.43 & 44.71% & 1.04\n",
      "for 2023-02-12, MAE is:12.32 & sMAPE is:9.09% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :24.15 & 43.88% & 1.02\n",
      "for 2023-02-13, MAE is:12.19 & sMAPE is:8.68% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :23.88 & 43.08% & 1.01\n",
      "for 2023-02-14, MAE is:8.05 & sMAPE is:5.83% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :23.53 & 42.25% & 1.02\n",
      "for 2023-02-15, MAE is:12.79 & sMAPE is:9.14% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :23.29 & 41.54% & 1.02\n",
      "for 2023-02-16, MAE is:16.07 & sMAPE is:11.82% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :23.14 & 40.90% & 1.03\n",
      "for 2023-02-17, MAE is:11.52 & sMAPE is:8.68% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :22.90 & 40.23% & 1.03\n",
      "for 2023-02-18, MAE is:9.09 & sMAPE is:7.03% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :22.61 & 39.55% & 1.04\n",
      "for 2023-02-19, MAE is:11.92 & sMAPE is:9.32% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :22.40 & 38.95% & 1.03\n",
      "for 2023-02-20, MAE is:10.18 & sMAPE is:7.73% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :22.16 & 38.34% & 1.03\n",
      "for 2023-02-21, MAE is:21.08 & sMAPE is:15.35% & rMAE is:2.41 ||| daily mean of MAE & sMAPE & rMAE till now are :22.14 & 37.90% & 1.06\n",
      "for 2023-02-22, MAE is:8.79 & sMAPE is:6.28% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :21.89 & 37.30% & 1.06\n",
      "for 2023-02-23, MAE is:12.26 & sMAPE is:9.14% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :21.71 & 36.78% & 1.07\n",
      "for 2023-02-24, MAE is:23.89 & sMAPE is:17.48% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :21.75 & 36.43% & 1.08\n",
      "for 2023-02-25, MAE is:10.89 & sMAPE is:8.01% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :21.56 & 35.92% & 1.07\n",
      "for 2023-02-26, MAE is:32.62 & sMAPE is:27.14% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :21.75 & 35.76% & 1.08\n",
      "for 2023-02-27, MAE is:18.34 & sMAPE is:15.01% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :21.69 & 35.41% & 1.08\n",
      "for 2023-02-28, MAE is:15.08 & sMAPE is:11.59% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :21.58 & 35.00% & 1.07\n",
      "for 2023-03-01, MAE is:12.07 & sMAPE is:8.60% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :21.42 & 34.56% & 1.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2023-03-02, MAE is:15.78 & sMAPE is:11.64% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :21.33 & 34.19% & 1.09\n",
      "for 2023-03-03, MAE is:17.68 & sMAPE is:13.12% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :21.27 & 33.85% & 1.10\n",
      "for 2023-03-04, MAE is:13.46 & sMAPE is:10.25% & rMAE is:1.77 ||| daily mean of MAE & sMAPE & rMAE till now are :21.15 & 33.47% & 1.11\n",
      "for 2023-03-05, MAE is:12.14 & sMAPE is:8.76% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :21.00 & 33.09% & 1.09\n",
      "for 2023-03-06, MAE is:9.55 & sMAPE is:6.70% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :20.83 & 32.68% & 1.08\n",
      "for 2023-03-07, MAE is:18.39 & sMAPE is:14.66% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :20.79 & 32.41% & 1.09\n",
      "for 2023-03-08, MAE is:20.14 & sMAPE is:19.96% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :20.78 & 32.22% & 1.08\n",
      "for 2023-03-09, MAE is:38.61 & sMAPE is:48.69% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :21.04 & 32.46% & 1.07\n",
      "for 2023-03-10, MAE is:32.32 & sMAPE is:79.77% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :21.21 & 33.15% & 1.06\n",
      "for 2023-03-11, MAE is:33.64 & sMAPE is:100.38% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :21.39 & 34.11% & 1.05\n",
      "for 2023-03-12, MAE is:27.15 & sMAPE is:36.61% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :21.47 & 34.15% & 1.04\n",
      "for 2023-03-13, MAE is:49.00 & sMAPE is:89.25% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :21.85 & 34.91% & 1.03\n",
      "for 2023-03-14, MAE is:40.10 & sMAPE is:75.23% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :22.10 & 35.46% & 1.02\n",
      "for 2023-03-15, MAE is:16.58 & sMAPE is:12.67% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :22.02 & 35.16% & 1.02\n",
      "for 2023-03-16, MAE is:41.73 & sMAPE is:43.48% & rMAE is:1.85 ||| daily mean of MAE & sMAPE & rMAE till now are :22.29 & 35.27% & 1.03\n",
      "for 2023-03-17, MAE is:27.06 & sMAPE is:39.13% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :22.35 & 35.32% & 1.03\n",
      "for 2023-03-18, MAE is:16.64 & sMAPE is:16.64% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :22.28 & 35.07% & 1.02\n",
      "for 2023-03-19, MAE is:21.94 & sMAPE is:23.57% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :22.27 & 34.93% & 1.02\n",
      "for 2023-03-20, MAE is:13.53 & sMAPE is:11.12% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :22.16 & 34.63% & 1.01\n",
      "for 2023-03-21, MAE is:10.88 & sMAPE is:9.35% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :22.02 & 34.31% & 1.00\n",
      "for 2023-03-22, MAE is:23.70 & sMAPE is:23.79% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :22.04 & 34.18% & 1.00\n",
      "for 2023-03-23, MAE is:24.12 & sMAPE is:28.66% & rMAE is:2.09 ||| daily mean of MAE & sMAPE & rMAE till now are :22.07 & 34.11% & 1.01\n",
      "for 2023-03-24, MAE is:36.71 & sMAPE is:54.21% & rMAE is:2.62 ||| daily mean of MAE & sMAPE & rMAE till now are :22.24 & 34.35% & 1.03\n",
      "for 2023-03-25, MAE is:43.15 & sMAPE is:75.11% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :22.49 & 34.84% & 1.03\n",
      "for 2023-03-26, MAE is:24.56 & sMAPE is:93.36% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :22.52 & 35.53% & 1.02\n",
      "for 2023-03-27, MAE is:40.24 & sMAPE is:42.87% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :22.72 & 35.61% & 1.02\n",
      "for 2023-03-28, MAE is:22.39 & sMAPE is:20.38% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :22.72 & 35.44% & 1.03\n",
      "for 2023-03-29, MAE is:41.29 & sMAPE is:61.91% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :22.93 & 35.74% & 1.03\n",
      "for 2023-03-30, MAE is:44.78 & sMAPE is:96.57% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :23.17 & 36.42% & 1.03\n",
      "for 2023-03-31, MAE is:20.33 & sMAPE is:89.24% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :23.14 & 37.01% & 1.02\n",
      "for 2023-04-01, MAE is:20.19 & sMAPE is:73.30% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :23.11 & 37.41% & 1.03\n",
      "for 2023-04-02, MAE is:14.09 & sMAPE is:88.45% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :23.01 & 37.96% & 1.03\n",
      "for 2023-04-03, MAE is:38.37 & sMAPE is:69.56% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :23.18 & 38.30% & 1.02\n",
      "for 2023-04-04, MAE is:34.35 & sMAPE is:53.98% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :23.30 & 38.47% & 1.02\n",
      "for 2023-04-05, MAE is:35.41 & sMAPE is:36.21% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :23.42 & 38.45% & 1.02\n",
      "for 2023-04-06, MAE is:27.61 & sMAPE is:28.49% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :23.47 & 38.34% & 1.01\n",
      "for 2023-04-07, MAE is:22.02 & sMAPE is:23.31% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :23.45 & 38.19% & 1.01\n",
      "for 2023-04-08, MAE is:29.99 & sMAPE is:46.09% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :23.52 & 38.27% & 1.00\n",
      "for 2023-04-09, MAE is:33.79 & sMAPE is:66.41% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :23.62 & 38.55% & 1.00\n",
      "for 2023-04-10, MAE is:31.67 & sMAPE is:65.59% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :23.70 & 38.82% & 1.00\n",
      "for 2023-04-11, MAE is:33.92 & sMAPE is:40.50% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :23.80 & 38.84% & 1.00\n",
      "for 2023-04-12, MAE is:67.81 & sMAPE is:107.34% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :24.24 & 39.51% & 1.00\n",
      "for 2023-04-13, MAE is:37.81 & sMAPE is:77.78% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :24.37 & 39.88% & 1.00\n",
      "for 2023-04-14, MAE is:41.07 & sMAPE is:73.88% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :24.53 & 40.21% & 1.00\n",
      "for 2023-04-15, MAE is:17.08 & sMAPE is:83.31% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :24.46 & 40.62% & 0.99\n",
      "for 2023-04-16, MAE is:15.69 & sMAPE is:41.62% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :24.37 & 40.63% & 0.98\n",
      "for 2023-04-17, MAE is:23.15 & sMAPE is:30.73% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :24.36 & 40.54% & 0.98\n",
      "for 2023-04-18, MAE is:19.31 & sMAPE is:19.67% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :24.32 & 40.34% & 0.98\n",
      "for 2023-04-19, MAE is:18.05 & sMAPE is:16.17% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :24.26 & 40.12% & 0.97\n",
      "for 2023-04-20, MAE is:18.12 & sMAPE is:16.15% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :24.20 & 39.90% & 0.97\n",
      "for 2023-04-21, MAE is:24.92 & sMAPE is:30.64% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :24.21 & 39.82% & 0.96\n",
      "for 2023-04-22, MAE is:29.55 & sMAPE is:46.62% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :24.26 & 39.88% & 0.96\n",
      "for 2023-04-23, MAE is:41.25 & sMAPE is:96.44% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :24.41 & 40.38% & 0.96\n",
      "for 2023-04-24, MAE is:17.98 & sMAPE is:18.49% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :24.35 & 40.19% & 0.96\n",
      "for 2023-04-25, MAE is:23.31 & sMAPE is:25.67% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :24.34 & 40.06% & 0.96\n",
      "for 2023-04-26, MAE is:12.03 & sMAPE is:11.16% & rMAE is:1.75 ||| daily mean of MAE & sMAPE & rMAE till now are :24.24 & 39.81% & 0.97\n",
      "for 2023-04-27, MAE is:11.98 & sMAPE is:11.03% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :24.13 & 39.57% & 0.97\n",
      "for 2023-04-28, MAE is:10.63 & sMAPE is:10.05% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :24.02 & 39.32% & 0.97\n",
      "for 2023-04-29, MAE is:18.57 & sMAPE is:26.32% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :23.97 & 39.21% & 0.97\n",
      "for 2023-04-30, MAE is:21.10 & sMAPE is:33.00% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :23.95 & 39.16% & 0.97\n",
      "for 2023-05-01, MAE is:18.99 & sMAPE is:22.18% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :23.91 & 39.02% & 0.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2023-05-02, MAE is:12.61 & sMAPE is:11.47% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :23.81 & 38.79% & 0.96\n",
      "for 2023-05-03, MAE is:29.68 & sMAPE is:36.31% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :23.86 & 38.77% & 0.96\n",
      "for 2023-05-04, MAE is:12.90 & sMAPE is:14.12% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :23.77 & 38.57% & 0.96\n",
      "for 2023-05-05, MAE is:10.12 & sMAPE is:10.29% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :23.66 & 38.35% & 0.96\n",
      "for 2023-05-06, MAE is:16.20 & sMAPE is:19.29% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :23.60 & 38.19% & 0.97\n",
      "for 2023-05-07, MAE is:26.39 & sMAPE is:52.79% & rMAE is:2.60 ||| daily mean of MAE & sMAPE & rMAE till now are :23.63 & 38.31% & 0.98\n",
      "for 2023-05-08, MAE is:10.57 & sMAPE is:10.66% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :23.52 & 38.09% & 0.98\n",
      "for 2023-05-09, MAE is:21.74 & sMAPE is:25.99% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :23.51 & 38.00% & 0.98\n",
      "for 2023-05-10, MAE is:15.36 & sMAPE is:19.40% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :23.45 & 37.86% & 0.98\n",
      "for 2023-05-11, MAE is:17.89 & sMAPE is:23.07% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :23.41 & 37.74% & 0.98\n",
      "for 2023-05-12, MAE is:22.58 & sMAPE is:36.42% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :23.40 & 37.73% & 0.98\n",
      "for 2023-05-13, MAE is:27.50 & sMAPE is:71.73% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :23.43 & 37.99% & 0.98\n",
      "for 2023-05-14, MAE is:19.63 & sMAPE is:61.32% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :23.40 & 38.16% & 0.98\n",
      "for 2023-05-15, MAE is:30.62 & sMAPE is:66.17% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :23.45 & 38.37% & 0.97\n",
      "for 2023-05-16, MAE is:28.16 & sMAPE is:63.54% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :23.49 & 38.56% & 0.97\n",
      "for 2023-05-17, MAE is:20.75 & sMAPE is:40.24% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :23.47 & 38.57% & 0.97\n",
      "for 2023-05-18, MAE is:19.32 & sMAPE is:41.10% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :23.44 & 38.59% & 0.97\n",
      "for 2023-05-19, MAE is:16.15 & sMAPE is:28.48% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :23.39 & 38.51% & 0.97\n",
      "for 2023-05-20, MAE is:23.25 & sMAPE is:60.89% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :23.39 & 38.67% & 0.97\n",
      "for 2023-05-21, MAE is:23.11 & sMAPE is:55.38% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :23.38 & 38.79% & 0.97\n",
      "for 2023-05-22, MAE is:21.62 & sMAPE is:27.45% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :23.37 & 38.71% & 0.97\n",
      "for 2023-05-23, MAE is:7.73 & sMAPE is:9.56% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :23.26 & 38.51% & 0.96\n",
      "for 2023-05-24, MAE is:7.40 & sMAPE is:8.78% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :23.15 & 38.30% & 0.96\n",
      "for 2023-05-25, MAE is:15.90 & sMAPE is:22.90% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :23.10 & 38.20% & 0.95\n",
      "for 2023-05-26, MAE is:26.59 & sMAPE is:45.94% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :23.13 & 38.25% & 0.96\n",
      "for 2023-05-27, MAE is:7.98 & sMAPE is:9.55% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :23.02 & 38.05% & 0.95\n",
      "for 2023-05-28, MAE is:10.13 & sMAPE is:12.62% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :22.94 & 37.88% & 0.95\n",
      "for 2023-05-29, MAE is:8.59 & sMAPE is:8.80% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :22.84 & 37.69% & 0.95\n",
      "for 2023-05-30, MAE is:16.66 & sMAPE is:17.08% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :22.80 & 37.55% & 0.95\n",
      "for 2023-05-31, MAE is:12.49 & sMAPE is:14.55% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :22.73 & 37.40% & 0.96\n",
      "for 2023-06-01, MAE is:8.01 & sMAPE is:9.55% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :22.63 & 37.21% & 0.95\n",
      "for 2023-06-02, MAE is:6.42 & sMAPE is:7.57% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :22.53 & 37.02% & 0.95\n",
      "for 2023-06-03, MAE is:7.12 & sMAPE is:8.80% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :22.43 & 36.84% & 0.95\n",
      "for 2023-06-04, MAE is:9.02 & sMAPE is:12.57% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :22.34 & 36.68% & 0.95\n",
      "for 2023-06-05, MAE is:8.92 & sMAPE is:10.54% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :22.25 & 36.51% & 0.95\n",
      "for 2023-06-06, MAE is:8.46 & sMAPE is:10.03% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :22.17 & 36.34% & 0.95\n",
      "for 2023-06-07, MAE is:5.34 & sMAPE is:6.43% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :22.06 & 36.15% & 0.94\n",
      "for 2023-06-08, MAE is:6.51 & sMAPE is:8.18% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :21.96 & 35.98% & 0.95\n",
      "for 2023-06-09, MAE is:9.56 & sMAPE is:12.12% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :21.89 & 35.83% & 0.95\n",
      "for 2023-06-10, MAE is:8.93 & sMAPE is:11.45% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :21.80 & 35.68% & 0.95\n",
      "for 2023-06-11, MAE is:10.81 & sMAPE is:14.12% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :21.74 & 35.54% & 0.95\n",
      "for 2023-06-12, MAE is:9.33 & sMAPE is:9.82% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :21.66 & 35.39% & 0.95\n",
      "for 2023-06-13, MAE is:12.37 & sMAPE is:14.24% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :21.60 & 35.26% & 0.96\n",
      "for 2023-06-14, MAE is:12.79 & sMAPE is:15.13% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :21.55 & 35.14% & 0.96\n",
      "for 2023-06-15, MAE is:10.10 & sMAPE is:9.70% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :21.48 & 34.98% & 0.95\n",
      "for 2023-06-16, MAE is:15.32 & sMAPE is:12.79% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :21.44 & 34.85% & 0.95\n",
      "for 2023-06-17, MAE is:17.74 & sMAPE is:20.16% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :21.42 & 34.76% & 0.95\n",
      "for 2023-06-18, MAE is:21.94 & sMAPE is:26.12% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :21.43 & 34.71% & 0.95\n",
      "for 2023-06-19, MAE is:12.36 & sMAPE is:11.43% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :21.37 & 34.57% & 0.95\n",
      "for 2023-06-20, MAE is:8.54 & sMAPE is:7.73% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :21.30 & 34.42% & 0.95\n",
      "for 2023-06-21, MAE is:8.36 & sMAPE is:6.98% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :21.22 & 34.26% & 0.95\n",
      "for 2023-06-22, MAE is:15.91 & sMAPE is:13.31% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :21.19 & 34.14% & 0.94\n",
      "for 2023-06-23, MAE is:10.12 & sMAPE is:9.37% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :21.13 & 33.99% & 0.94\n",
      "for 2023-06-24, MAE is:16.12 & sMAPE is:18.19% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :21.10 & 33.90% & 0.95\n",
      "for 2023-06-25, MAE is:6.10 & sMAPE is:6.06% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :21.01 & 33.75% & 0.94\n",
      "for 2023-06-26, MAE is:15.67 & sMAPE is:15.96% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :20.98 & 33.65% & 0.94\n",
      "for 2023-06-27, MAE is:16.80 & sMAPE is:16.01% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :20.96 & 33.55% & 0.95\n",
      "for 2023-06-28, MAE is:7.61 & sMAPE is:7.25% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :20.89 & 33.40% & 0.94\n",
      "for 2023-06-29, MAE is:15.21 & sMAPE is:14.37% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :20.85 & 33.29% & 0.94\n",
      "for 2023-06-30, MAE is:10.40 & sMAPE is:10.77% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :20.80 & 33.17% & 0.94\n",
      "CPU times: total: 1d 20h 23min 13s\n",
      "Wall time: 21h 14min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "large_scale_predictor(zone, first_year=2018, last_year=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
