{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from large_scale_prediction import large_scale_predictor, large_scale_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "zones = ['DK_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 16:26:36,171]\u001b[0m A new study created in RDB with name: DK_1_2018\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:27:01,947]\u001b[0m Trial 1 finished with value: 5.859595659117681 and parameters: {'n_hidden': 3, 'learning_rate': 0.016561008517985806, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04049885218530256, 'dropout_rate_Layer_2': 0.37347656344181984, 'dropout_rate_Layer_3': 0.15298166971531316, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.115218121951689e-05, 'l1_Layer_2': 0.0003074324618782241, 'l1_Layer_3': 2.9039811339945014e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 245, 'n_units_Layer_3': 150}. Best is trial 1 with value: 5.859595659117681.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.86 | sMAPE for Validation Set is: 22.91% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 10.99 | sMAPE for Test Set is: 28.62% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 16:27:02,220]\u001b[0m Trial 0 pruned. Trial was pruned at epoch 59.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:27:08,556]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:27:12,010]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:27:14,413]\u001b[0m Trial 2 finished with value: 5.355916015340408 and parameters: {'n_hidden': 3, 'learning_rate': 0.016007531747562292, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33625692412506875, 'dropout_rate_Layer_2': 0.1295009002554742, 'dropout_rate_Layer_3': 0.17380766486915014, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0071450316759927345, 'l1_Layer_2': 5.960285364414608e-05, 'l1_Layer_3': 2.6096295011469398e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 270, 'n_units_Layer_3': 90}. Best is trial 2 with value: 5.355916015340408.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.36 | sMAPE for Validation Set is: 21.25% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.92 | sMAPE for Test Set is: 27.94% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 16:27:16,555]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:27:19,685]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:27:36,382]\u001b[0m Trial 4 finished with value: 5.359105891191317 and parameters: {'n_hidden': 3, 'learning_rate': 0.014478893487728675, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.357487300436528, 'dropout_rate_Layer_2': 0.11578444860058151, 'dropout_rate_Layer_3': 0.2413129984114446, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.016068640977022812, 'l1_Layer_2': 0.010738684497156587, 'l1_Layer_3': 0.0003258366241743084, 'n_units_Layer_1': 190, 'n_units_Layer_2': 140, 'n_units_Layer_3': 285}. Best is trial 2 with value: 5.355916015340408.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.36 | sMAPE for Validation Set is: 21.26% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.73 | sMAPE for Test Set is: 27.77% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 16:27:39,422]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:27:42,340]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.61 | sMAPE for Validation Set is: 22.38% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 12.07 | sMAPE for Test Set is: 31.09% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 16:27:44,302]\u001b[0m Trial 3 finished with value: 5.60502558479318 and parameters: {'n_hidden': 4, 'learning_rate': 0.0024508526625549713, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2015880497947581, 'dropout_rate_Layer_2': 0.22829725081085117, 'dropout_rate_Layer_3': 0.048638426552798514, 'dropout_rate_Layer_4': 0.2866328234585765, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0015114903949282796, 'l1_Layer_2': 4.468913954159658e-05, 'l1_Layer_3': 1.494819219954282e-05, 'l1_Layer_4': 0.023322690022819406, 'n_units_Layer_1': 140, 'n_units_Layer_2': 70, 'n_units_Layer_3': 70, 'n_units_Layer_4': 210}. Best is trial 2 with value: 5.355916015340408.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:27:48,193]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:27:49,461]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:27:53,446]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:28:00,939]\u001b[0m Trial 8 finished with value: 5.456320521087842 and parameters: {'n_hidden': 4, 'learning_rate': 0.027073733534368007, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03758822768197745, 'dropout_rate_Layer_2': 0.30684448685231325, 'dropout_rate_Layer_3': 0.03941709894018062, 'dropout_rate_Layer_4': 0.03826560500354934, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0004138965546942081, 'l1_Layer_2': 0.000392933374889865, 'l1_Layer_3': 0.00047167104232823066, 'l1_Layer_4': 0.026150684651660098, 'n_units_Layer_1': 155, 'n_units_Layer_2': 175, 'n_units_Layer_3': 105, 'n_units_Layer_4': 50}. Best is trial 2 with value: 5.355916015340408.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.46 | sMAPE for Validation Set is: 21.71% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 12.75 | sMAPE for Test Set is: 32.72% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 16:28:02,986]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:28:05,636]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:28:07,103]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:28:09,104]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:28:13,906]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:28:13,953]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:28:14,337]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:28:21,198]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:28:22,502]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:28:25,381]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:28:27,958]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:28:33,381]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:28:37,159]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:28:46,646]\u001b[0m Trial 10 finished with value: 6.775611206752628 and parameters: {'n_hidden': 4, 'learning_rate': 0.057777873587274715, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03357898956491195, 'dropout_rate_Layer_2': 0.14136843391001577, 'dropout_rate_Layer_3': 0.05194961844587445, 'dropout_rate_Layer_4': 0.052400830160461626, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0018882925443692057, 'l1_Layer_2': 2.9316879064361032e-05, 'l1_Layer_3': 0.017062844955411143, 'l1_Layer_4': 0.0001836746983591343, 'n_units_Layer_1': 245, 'n_units_Layer_2': 235, 'n_units_Layer_3': 65, 'n_units_Layer_4': 225}. Best is trial 2 with value: 5.355916015340408.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.78 | sMAPE for Validation Set is: 25.33% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 18.19 | sMAPE for Test Set is: 48.87% | rMAE for Test Set is: 1.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 16:28:50,825]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:28:53,329]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:28:53,569]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:28:57,126]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:29:02,081]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:29:06,264]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:29:12,672]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:29:22,177]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:29:26,338]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:29:27,823]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:29:28,743]\u001b[0m Trial 35 finished with value: 5.551903480880753 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027558502040207155, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3561022533655184, 'dropout_rate_Layer_2': 0.02431796240143762, 'dropout_rate_Layer_3': 0.21016550707915235, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0035334075620210717, 'l1_Layer_2': 4.23905403430334e-05, 'l1_Layer_3': 0.003285518364036711, 'n_units_Layer_1': 135, 'n_units_Layer_2': 220, 'n_units_Layer_3': 155}. Best is trial 2 with value: 5.355916015340408.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.55 | sMAPE for Validation Set is: 22.20% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 11.16 | sMAPE for Test Set is: 28.61% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 16:29:33,002]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:29:39,020]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:29:39,176]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:29:39,726]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:29:46,845]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:29:49,140]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:29:49,774]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:29:53,634]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:29:55,126]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:29:57,243]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:30:00,910]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:30:05,803]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:30:08,572]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:30:15,521]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:30:16,895]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:30:20,751]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:30:23,895]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:30:27,321]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:30:28,629]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:30:30,008]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.49 | sMAPE for Validation Set is: 21.72% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 8.26 | sMAPE for Test Set is: 21.86% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 16:30:33,003]\u001b[0m Trial 39 finished with value: 5.49416405467542 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005061100529793472, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12933369028613995, 'dropout_rate_Layer_2': 0.1409121601334616, 'dropout_rate_Layer_3': 0.030425704772152385, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.7118966222833785e-05, 'l1_Layer_2': 0.0017338240497006643, 'l1_Layer_3': 7.456506213797862e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 100, 'n_units_Layer_3': 285}. Best is trial 2 with value: 5.355916015340408.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:30:34,317]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:30:34,508]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:30:34,991]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:30:39,376]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:30:43,641]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:30:44,339]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:30:45,150]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:30:50,748]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:30:53,590]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:30:53,960]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:30:59,993]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:31:03,304]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:31:03,443]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:31:03,703]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:31:10,077]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:31:10,525]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:31:10,995]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:31:18,677]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:31:19,042]\u001b[0m Trial 71 finished with value: 5.400386892332933 and parameters: {'n_hidden': 3, 'learning_rate': 0.002642054034517301, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.159203951755768, 'dropout_rate_Layer_2': 0.24720277086149395, 'dropout_rate_Layer_3': 0.11714576166894608, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006508345308725471, 'l1_Layer_2': 0.0003057663491573204, 'l1_Layer_3': 8.095575443087057e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 130, 'n_units_Layer_3': 110}. Best is trial 2 with value: 5.355916015340408.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.40 | sMAPE for Validation Set is: 21.51% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.60 | sMAPE for Test Set is: 27.37% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 16:31:19,664]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:31:26,044]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:31:26,223]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:31:28,334]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:31:33,878]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:31:35,345]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:31:38,537]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:31:40,685]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:31:41,344]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:31:43,079]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:31:47,631]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:31:48,981]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:31:51,155]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:31:53,883]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:31:56,954]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:31:57,303]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:31:57,974]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:32:03,835]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:32:03,975]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:32:11,016]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:32:11,365]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:32:11,823]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:32:16,492]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:32:21,096]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:32:21,599]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:32:21,768]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:32:27,813]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:32:29,079]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:32:35,270]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:32:35,523]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:32:45,799]\u001b[0m Trial 109 finished with value: 5.686965640809951 and parameters: {'n_hidden': 4, 'learning_rate': 0.02585509914708575, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3360579468126823, 'dropout_rate_Layer_2': 0.26989846826852854, 'dropout_rate_Layer_3': 0.3175511018401206, 'dropout_rate_Layer_4': 0.2740536383189334, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 8.666556940266904e-05, 'l1_Layer_2': 0.0002677204794179428, 'l1_Layer_3': 0.015174033358482069, 'l1_Layer_4': 0.09979968133918876, 'n_units_Layer_1': 270, 'n_units_Layer_2': 235, 'n_units_Layer_3': 125, 'n_units_Layer_4': 145}. Best is trial 2 with value: 5.355916015340408.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.69 | sMAPE for Validation Set is: 22.50% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 12.36 | sMAPE for Test Set is: 31.58% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 16:32:51,597]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:32:58,860]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:32:59,241]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:32:59,391]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:33:07,003]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:33:13,126]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:33:18,081]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:33:25,531]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:33:31,098]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:33:33,033]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:33:38,378]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:33:42,382]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:33:49,834]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:33:52,185]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:33:57,850]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:34:00,332]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:34:04,081]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:34:07,680]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:34:09,122]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:34:14,136]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:34:17,991]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:34:20,444]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:34:24,301]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:34:26,593]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:34:28,091]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:34:34,490]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:34:35,046]\u001b[0m Trial 119 finished with value: 5.226897258856777 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011877385749091496, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2964466902754773, 'dropout_rate_Layer_2': 0.27859318344925416, 'dropout_rate_Layer_3': 0.336215570253523, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00016637362185002185, 'l1_Layer_2': 0.00013935369366347244, 'l1_Layer_3': 0.0012785862811593568, 'n_units_Layer_1': 165, 'n_units_Layer_2': 150, 'n_units_Layer_3': 160}. Best is trial 119 with value: 5.226897258856777.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.23 | sMAPE for Validation Set is: 20.99% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.25 | sMAPE for Test Set is: 17.27% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 16:34:55,239]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:35:00,606]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:35:03,789]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:35:05,785]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:35:10,969]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:35:19,719]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:35:26,063]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:35:37,620]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:35:41,099]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:35:44,988]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:35:45,266]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:35:50,798]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:35:54,169]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:35:56,370]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:36:01,120]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:36:03,661]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:36:07,325]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:36:09,723]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:36:09,950]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:36:19,241]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:36:19,466]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:36:35,175]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:36:37,020]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:36:41,858]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:36:53,699]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:36:56,382]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:37:00,469]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:37:28,557]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:37:40,794]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:37:53,821]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:37:59,617]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:38:17,582]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:38:24,767]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:38:32,165]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:38:38,544]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:38:53,222]\u001b[0m Trial 168 finished with value: 5.456337120415057 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027753737144914164, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3449153492816829, 'dropout_rate_Layer_2': 0.2313779530767966, 'dropout_rate_Layer_3': 0.3499303880262696, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00212106616438364, 'l1_Layer_2': 0.0017708842233280407, 'l1_Layer_3': 7.521012730772237e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 135, 'n_units_Layer_3': 170}. Best is trial 119 with value: 5.226897258856777.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.46 | sMAPE for Validation Set is: 22.16% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.59 | sMAPE for Test Set is: 20.66% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 16:39:01,739]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:39:08,527]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:39:14,352]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:39:31,115]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:40:02,167]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:40:05,549]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:40:18,088]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:40:20,707]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:40:21,358]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:40:27,140]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:40:43,321]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:40:47,989]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:40:55,623]\u001b[0m Trial 186 finished with value: 5.899868728333124 and parameters: {'n_hidden': 3, 'learning_rate': 0.07858028445251274, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32538857369241114, 'dropout_rate_Layer_2': 0.2728113702020473, 'dropout_rate_Layer_3': 0.12259358605724863, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.004053139367018119, 'l1_Layer_2': 5.323097560092841e-05, 'l1_Layer_3': 0.00043400527544544624, 'n_units_Layer_1': 175, 'n_units_Layer_2': 50, 'n_units_Layer_3': 50}. Best is trial 119 with value: 5.226897258856777.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.90 | sMAPE for Validation Set is: 22.94% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 11.88 | sMAPE for Test Set is: 30.59% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 16:41:13,778]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:41:14,060]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:41:21,083]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:41:27,223]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:41:33,672]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:41:45,138]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:41:50,156]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:41:52,617]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:41:56,510]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:41:57,366]\u001b[0m Trial 184 finished with value: 5.417580270344874 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009453846444759626, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0017087966034091198, 'dropout_rate_Layer_2': 0.08148898920378966, 'dropout_rate_Layer_3': 0.31319410746692483, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1215053371234371e-05, 'l1_Layer_2': 0.0025075314786804047, 'l1_Layer_3': 8.151976955630707e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 75, 'n_units_Layer_3': 140}. Best is trial 119 with value: 5.226897258856777.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.42 | sMAPE for Validation Set is: 21.79% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.32 | sMAPE for Test Set is: 29.16% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 16:41:57,493]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:42:06,913]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:42:10,914]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:42:13,593]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:42:17,526]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:42:18,099]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:42:23,885]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:42:33,559]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:42:35,433]\u001b[0m Trial 187 finished with value: 5.405595936512704 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008511935350011476, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.005304841909010743, 'dropout_rate_Layer_2': 0.2673403202527731, 'dropout_rate_Layer_3': 0.2857297197104903, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.650703419452602e-05, 'l1_Layer_2': 0.00198294540602117, 'l1_Layer_3': 0.000427166304918951, 'n_units_Layer_1': 205, 'n_units_Layer_2': 75, 'n_units_Layer_3': 135}. Best is trial 119 with value: 5.226897258856777.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.41 | sMAPE for Validation Set is: 21.80% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 12.31 | sMAPE for Test Set is: 31.82% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 16:42:35,641]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:42:40,928]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:42:43,385]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:42:48,100]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:42:55,431]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:43:04,018]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:43:07,607]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:43:36,602]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:43:36,891]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:43:41,419]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:43:53,193]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:43:56,093]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:44:04,990]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:44:13,905]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:44:20,802]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:44:25,960]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:44:26,527]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:44:31,685]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:44:33,996]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:44:36,159]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:44:36,726]\u001b[0m Trial 210 finished with value: 5.447449203665253 and parameters: {'n_hidden': 3, 'learning_rate': 0.007041650061745918, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31109670629057457, 'dropout_rate_Layer_2': 0.13433574672978743, 'dropout_rate_Layer_3': 0.12566529751736916, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005129807956243828, 'l1_Layer_2': 2.5272008740079994e-05, 'l1_Layer_3': 0.0001253516919563823, 'n_units_Layer_1': 170, 'n_units_Layer_2': 225, 'n_units_Layer_3': 90}. Best is trial 119 with value: 5.226897258856777.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.45 | sMAPE for Validation Set is: 21.77% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 12.45 | sMAPE for Test Set is: 32.17% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 16:44:41,588]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:44:43,549]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:44:48,735]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:44:49,102]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:44:56,296]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:44:56,481]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:44:57,128]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:45:01,689]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:45:01,891]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:45:02,754]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:45:03,037]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:45:10,494]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:45:11,591]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:45:15,324]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:45:15,497]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:45:20,555]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:45:23,697]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:45:27,439]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:45:40,066]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:45:45,546]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:45:47,243]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:45:49,991]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:45:56,095]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:45:56,140]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:45:59,993]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:46:04,037]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:46:09,793]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:46:17,827]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:46:19,557]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:46:26,114]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:46:34,791]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:46:44,130]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:46:47,129]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:46:50,566]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:46:50,813]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:46:53,572]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:46:59,172]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:47:03,563]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:47:06,138]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:47:20,339]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:47:27,114]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:47:35,649]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:47:41,833]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:47:42,255]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:47:52,438]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:47:55,591]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:47:58,687]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:48:02,844]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:48:05,087]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:48:09,259]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:48:12,258]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:48:13,317]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:48:25,101]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:48:35,656]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:48:40,241]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:48:43,198]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:48:50,992]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:48:55,204]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:48:57,730]\u001b[0m Trial 281 finished with value: 5.301252825414725 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005149915171894923, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13291816891282962, 'dropout_rate_Layer_2': 0.11532203694876089, 'dropout_rate_Layer_3': 0.006093254523142133, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0001218580411319118, 'l1_Layer_2': 0.0016677360781985062, 'l1_Layer_3': 6.782885605351708e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 95, 'n_units_Layer_3': 300}. Best is trial 119 with value: 5.226897258856777.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.30 | sMAPE for Validation Set is: 21.21% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.06 | sMAPE for Test Set is: 26.11% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 16:49:02,837]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:49:09,559]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:49:11,586]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:49:23,995]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:49:29,235]\u001b[0m Trial 260 finished with value: 5.286171292435357 and parameters: {'n_hidden': 3, 'learning_rate': 0.006921258079786567, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03119257348542309, 'dropout_rate_Layer_2': 0.2891648307748463, 'dropout_rate_Layer_3': 0.19077816608018938, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007940757110020178, 'l1_Layer_2': 3.683291774229035e-05, 'l1_Layer_3': 0.00010180097898762005, 'n_units_Layer_1': 175, 'n_units_Layer_2': 190, 'n_units_Layer_3': 80}. Best is trial 119 with value: 5.226897258856777.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.29 | sMAPE for Validation Set is: 21.47% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 7.23 | sMAPE for Test Set is: 19.75% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 16:49:29,489]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:49:36,524]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:49:38,628]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:49:42,453]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:49:45,182]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:49:49,490]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:49:53,345]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:50:01,316]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:50:04,858]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:50:04,964]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:50:06,040]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:50:13,324]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:50:22,144]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:50:27,346]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:50:38,047]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:50:40,753]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:50:42,448]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:50:45,873]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:50:45,950]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:50:48,781]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:50:55,356]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:51:04,396]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:51:08,800]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:51:08,943]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:51:23,271]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:51:31,438]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:51:37,187]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:51:38,948]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:51:41,690]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:51:45,200]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:51:57,358]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:52:01,476]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:52:03,703]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:52:08,754]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:52:13,403]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:52:18,570]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:52:27,915]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:52:29,462]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:52:34,330]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:52:34,638]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:52:34,891]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:52:39,794]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:52:44,368]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:52:46,384]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:52:50,955]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:53:04,175]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:53:05,757]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:53:13,789]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:53:16,150]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:53:24,860]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:53:30,827]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:53:31,094]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:53:38,188]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:53:38,325]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:53:43,790]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:53:48,635]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:53:51,392]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:53:52,618]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:54:28,134]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:54:29,490]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:54:44,164]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:54:47,812]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:54:52,759]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:54:53,035]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:55:04,188]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:55:10,576]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:55:30,252]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:55:41,427]\u001b[0m Trial 350 finished with value: 5.466411304864582 and parameters: {'n_hidden': 3, 'learning_rate': 0.015568449758729758, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10547706690912154, 'dropout_rate_Layer_2': 0.1224824817177999, 'dropout_rate_Layer_3': 0.14470824073396854, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.003285738737528149, 'l1_Layer_2': 0.00020091515376457656, 'l1_Layer_3': 0.00016025140970550778, 'n_units_Layer_1': 80, 'n_units_Layer_2': 135, 'n_units_Layer_3': 225}. Best is trial 119 with value: 5.226897258856777.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.47 | sMAPE for Validation Set is: 21.65% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 11.08 | sMAPE for Test Set is: 28.50% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 16:55:50,256]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:55:59,499]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:56:02,628]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:56:08,785]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:56:17,746]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:56:17,820]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:56:22,095]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:56:32,020]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:56:38,185]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:56:45,837]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:56:48,148]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:56:48,727]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:56:55,935]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:57:04,172]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:57:06,609]\u001b[0m Trial 372 finished with value: 5.726397243232036 and parameters: {'n_hidden': 4, 'learning_rate': 0.02822699565496242, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27965704001813957, 'dropout_rate_Layer_2': 0.07112799127502299, 'dropout_rate_Layer_3': 0.08504153837879569, 'dropout_rate_Layer_4': 0.18756629623582063, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0006344847100268305, 'l1_Layer_2': 0.0029097622312716075, 'l1_Layer_3': 0.0005442343410713549, 'l1_Layer_4': 0.005441484839999709, 'n_units_Layer_1': 165, 'n_units_Layer_2': 80, 'n_units_Layer_3': 180, 'n_units_Layer_4': 165}. Best is trial 119 with value: 5.226897258856777.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.73 | sMAPE for Validation Set is: 22.41% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 13.14 | sMAPE for Test Set is: 33.92% | rMAE for Test Set is: 1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 16:57:11,653]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:57:28,508]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:57:37,131]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:57:43,178]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:57:53,118]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:58:07,153]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:58:16,019]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:58:24,643]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:58:27,689]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:58:31,273]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:58:37,338]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:58:45,306]\u001b[0m Trial 373 finished with value: 5.307485729797815 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005062298835185562, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1583489970505579, 'dropout_rate_Layer_2': 0.2838189196616749, 'dropout_rate_Layer_3': 0.013897040316335145, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.406975802942306e-05, 'l1_Layer_2': 0.0014574441614512489, 'l1_Layer_3': 1.1110291981634146e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 55, 'n_units_Layer_3': 170}. Best is trial 119 with value: 5.226897258856777.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.31 | sMAPE for Validation Set is: 21.28% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 9.38 | sMAPE for Test Set is: 24.32% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 16:58:47,433]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:58:55,080]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:58:56,902]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:58:58,919]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:59:01,908]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:59:02,276]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:59:30,933]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:59:34,368]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:59:35,807]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:59:45,199]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:59:48,148]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:59:53,072]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:59:55,889]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:59:57,440]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 16:59:58,275]\u001b[0m Trial 398 finished with value: 6.41215688309412 and parameters: {'n_hidden': 3, 'learning_rate': 0.05438635144351832, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.030528003102476123, 'dropout_rate_Layer_2': 0.18430670835617327, 'dropout_rate_Layer_3': 0.035177189965995684, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002330049464176442, 'l1_Layer_2': 0.0009907766188375381, 'l1_Layer_3': 0.00035328710588476724, 'n_units_Layer_1': 270, 'n_units_Layer_2': 165, 'n_units_Layer_3': 135}. Best is trial 119 with value: 5.226897258856777.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.41 | sMAPE for Validation Set is: 24.75% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 13.11 | sMAPE for Test Set is: 34.05% | rMAE for Test Set is: 1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:00:03,481]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:00:04,230]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:00:09,177]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:00:12,792]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:00:15,637]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:00:20,696]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:00:22,427]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:00:28,426]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:00:29,383]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:00:37,142]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:00:37,777]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:00:46,174]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:00:48,476]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:00:59,974]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:01:02,104]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:01:02,624]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:01:09,691]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:01:12,085]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:01:14,396]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:01:17,832]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:01:43,857]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:01:49,697]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:01:52,551]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:02:01,034]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:02:03,034]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:02:11,957]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:02:16,373]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:02:20,228]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:02:58,220]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:03:03,253]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:03:07,690]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:03:13,455]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:03:19,419]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:03:20,081]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:03:24,094]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:03:28,102]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:03:32,358]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:03:34,218]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:03:39,835]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:03:41,792]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:03:47,235]\u001b[0m Trial 435 finished with value: 5.681442064176726 and parameters: {'n_hidden': 3, 'learning_rate': 0.0039014496292133485, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2260748964190028, 'dropout_rate_Layer_2': 0.3875491722949982, 'dropout_rate_Layer_3': 0.3751889772596977, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0002556672203184003, 'l1_Layer_2': 0.01088263130159033, 'l1_Layer_3': 0.00025398265476235093, 'n_units_Layer_1': 215, 'n_units_Layer_2': 195, 'n_units_Layer_3': 160}. Best is trial 119 with value: 5.226897258856777.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.68 | sMAPE for Validation Set is: 22.40% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 13.90 | sMAPE for Test Set is: 35.91% | rMAE for Test Set is: 1.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:03:47,419]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:03:47,758]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:04:05,705]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:04:14,376]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:04:19,810]\u001b[0m Trial 446 finished with value: 5.564561284454176 and parameters: {'n_hidden': 3, 'learning_rate': 0.005097419947121321, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1465460386174997, 'dropout_rate_Layer_2': 0.09360142770016212, 'dropout_rate_Layer_3': 0.06117766703559416, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0005439302663874434, 'l1_Layer_2': 3.5189064590679896e-05, 'l1_Layer_3': 2.8238635067633924e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 185, 'n_units_Layer_3': 200}. Best is trial 119 with value: 5.226897258856777.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.56 | sMAPE for Validation Set is: 22.07% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 12.92 | sMAPE for Test Set is: 33.19% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:04:22,143]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:04:26,117]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:04:30,977]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:04:37,572]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:04:46,904]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:04:52,707]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:04:58,521]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:05:03,562]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:05:08,515]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:05:10,550]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:05:15,345]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:05:20,439]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:05:30,147]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:05:33,809]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:05:36,603]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:05:38,777]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:05:58,209]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:06:06,914]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:06:10,987]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:06:19,219]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:06:23,003]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:06:33,158]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:06:43,937]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:06:48,800]\u001b[0m Trial 447 finished with value: 5.342927061199476 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031195322720573545, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.027054172857778225, 'dropout_rate_Layer_2': 0.27330396324316564, 'dropout_rate_Layer_3': 0.23485411095350928, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002798383433811136, 'l1_Layer_2': 2.1165370451463872e-05, 'l1_Layer_3': 2.457313361258776e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 210, 'n_units_Layer_3': 150}. Best is trial 119 with value: 5.226897258856777.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.34 | sMAPE for Validation Set is: 21.26% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 12.02 | sMAPE for Test Set is: 30.84% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:06:49,338]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:06:52,681]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:06:53,415]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:06:58,153]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:07:03,928]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:07:06,297]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:07:06,625]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:07:08,108]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:07:14,316]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:07:16,731]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:07:21,411]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:07:27,023]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:07:30,430]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:07:39,026]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:07:47,704]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:07:53,147]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:07:53,392]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:08:01,651]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:08:09,706]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:08:13,397]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:08:15,914]\u001b[0m Trial 476 finished with value: 5.667745318881181 and parameters: {'n_hidden': 3, 'learning_rate': 0.00308143479078151, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 8.179576364328311e-06, 'dropout_rate_Layer_2': 0.19945562829815502, 'dropout_rate_Layer_3': 0.23583173662903975, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.628449076119044e-05, 'l1_Layer_2': 1.7599672543590045e-05, 'l1_Layer_3': 3.7041136089321114e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 220, 'n_units_Layer_3': 180}. Best is trial 119 with value: 5.226897258856777.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.67 | sMAPE for Validation Set is: 22.29% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 13.24 | sMAPE for Test Set is: 34.03% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:08:20,904]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:08:26,745]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:08:30,974]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:08:31,679]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:08:36,739]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:08:38,303]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:08:48,526]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:08:53,011]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:09:05,310]\u001b[0m Trial 488 finished with value: 5.481214621054838 and parameters: {'n_hidden': 3, 'learning_rate': 0.001550280059911076, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3501435999704243, 'dropout_rate_Layer_2': 0.20173548506722605, 'dropout_rate_Layer_3': 0.32923974821255286, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.761853382088791e-05, 'l1_Layer_2': 0.035033672813030346, 'l1_Layer_3': 7.925665279111506e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 170, 'n_units_Layer_3': 155}. Best is trial 119 with value: 5.226897258856777.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.48 | sMAPE for Validation Set is: 22.17% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 7.25 | sMAPE for Test Set is: 20.04% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:09:05,888]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:09:11,781]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:09:17,813]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:09:21,892]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:09:27,257]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:09:30,498]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:09:37,665]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:09:40,422]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:09:44,808]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:09:47,259]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:09:52,055]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:09:57,920]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:09:58,526]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:10:00,909]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:10:06,456]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:10:09,064]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:10:15,141]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:10:18,533]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:10:21,923]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:10:22,162]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:10:24,502]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:10:28,049]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:10:28,301]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:10:29,280]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:10:34,303]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:10:36,094]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:10:37,799]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:10:40,404]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:10:44,459]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:10:44,948]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:10:45,292]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:10:46,855]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:11:03,362]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:11:03,934]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:11:14,779]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:11:16,380]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:11:19,507]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:11:24,418]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:11:27,404]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:11:28,128]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:11:36,710]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:11:37,413]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:11:42,835]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:11:50,525]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:11:56,503]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:11:59,502]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:12:03,554]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:12:09,229]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:12:12,876]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:12:17,655]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:12:23,497]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:12:29,257]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:12:32,212]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:12:34,134]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:12:37,541]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:12:42,249]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:12:47,740]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:12:47,885]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:12:53,455]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:12:56,059]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:13:04,800]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:13:10,635]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:13:22,893]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:13:28,595]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:13:40,063]\u001b[0m Trial 566 finished with value: 5.401574275739132 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011287449252489277, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17206291509282187, 'dropout_rate_Layer_2': 0.07981690790201691, 'dropout_rate_Layer_3': 0.02772154175068296, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.4542073794750583e-05, 'l1_Layer_2': 0.0021493012838392526, 'l1_Layer_3': 1.958227205947235e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 120, 'n_units_Layer_3': 300}. Best is trial 119 with value: 5.226897258856777.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.40 | sMAPE for Validation Set is: 21.50% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 9.03 | sMAPE for Test Set is: 23.62% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:13:51,924]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:14:01,066]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:15:02,388]\u001b[0m Trial 568 finished with value: 5.363619188365547 and parameters: {'n_hidden': 3, 'learning_rate': 0.001448114203782657, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3859843682649926, 'dropout_rate_Layer_2': 0.1952705553011172, 'dropout_rate_Layer_3': 0.18289904553509775, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.494820644863285e-05, 'l1_Layer_2': 2.9151590394177953e-05, 'l1_Layer_3': 0.00199028984309505, 'n_units_Layer_1': 265, 'n_units_Layer_2': 195, 'n_units_Layer_3': 125}. Best is trial 119 with value: 5.226897258856777.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.36 | sMAPE for Validation Set is: 21.08% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 12.04 | sMAPE for Test Set is: 30.87% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:15:05,206]\u001b[0m Trial 563 finished with value: 5.324881060916924 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009370382150661137, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13232325706405726, 'dropout_rate_Layer_2': 0.3884329395782422, 'dropout_rate_Layer_3': 0.10085636288069111, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.5832664114176927e-05, 'l1_Layer_2': 0.002048524524148212, 'l1_Layer_3': 0.0005022852954247985, 'n_units_Layer_1': 170, 'n_units_Layer_2': 125, 'n_units_Layer_3': 300}. Best is trial 119 with value: 5.226897258856777.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.32 | sMAPE for Validation Set is: 21.20% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 9.03 | sMAPE for Test Set is: 23.56% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:15:08,319]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:15:11,051]\u001b[0m Trial 559 finished with value: 5.3521581029531236 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005513917180730558, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20320838211979966, 'dropout_rate_Layer_2': 0.018633393857010377, 'dropout_rate_Layer_3': 0.05679693125145514, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3047746254035201e-05, 'l1_Layer_2': 0.00025449486387817057, 'l1_Layer_3': 0.00026470019555757684, 'n_units_Layer_1': 215, 'n_units_Layer_2': 60, 'n_units_Layer_3': 65}. Best is trial 119 with value: 5.226897258856777.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.35 | sMAPE for Validation Set is: 21.64% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 13.33 | sMAPE for Test Set is: 34.98% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:15:11,314]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:15:16,072]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:15:21,208]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:15:29,210]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:15:38,735]\u001b[0m Trial 571 finished with value: 5.410416045380927 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006878616362020512, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3826355143285671, 'dropout_rate_Layer_2': 0.2284403846641255, 'dropout_rate_Layer_3': 0.1845235956859825, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.410025670818547e-05, 'l1_Layer_2': 2.610135134920796e-05, 'l1_Layer_3': 0.00017045739108987197, 'n_units_Layer_1': 255, 'n_units_Layer_2': 190, 'n_units_Layer_3': 185}. Best is trial 119 with value: 5.226897258856777.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.41 | sMAPE for Validation Set is: 21.54% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.97 | sMAPE for Test Set is: 30.86% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:16:02,776]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:16:24,130]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:16:27,328]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:17:10,833]\u001b[0m Trial 583 finished with value: 5.370521956829346 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010371465959495474, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15892226734265769, 'dropout_rate_Layer_2': 0.3812757995176731, 'dropout_rate_Layer_3': 0.031554328138757026, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.8657885407618917e-05, 'l1_Layer_2': 0.002583865821632019, 'l1_Layer_3': 1.77904209011129e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 120, 'n_units_Layer_3': 300}. Best is trial 119 with value: 5.226897258856777.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.37 | sMAPE for Validation Set is: 21.50% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 9.59 | sMAPE for Test Set is: 24.86% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:17:19,405]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:17:25,113]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:17:28,391]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:18:07,267]\u001b[0m Trial 581 finished with value: 5.371744717017747 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005014973380431346, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22476143261577447, 'dropout_rate_Layer_2': 0.05373650019052176, 'dropout_rate_Layer_3': 0.0693682789324438, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.6984381104254768e-05, 'l1_Layer_2': 0.0004420512227144147, 'l1_Layer_3': 0.0001321533003633027, 'n_units_Layer_1': 150, 'n_units_Layer_2': 55, 'n_units_Layer_3': 55}. Best is trial 119 with value: 5.226897258856777.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.37 | sMAPE for Validation Set is: 21.72% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 9.63 | sMAPE for Test Set is: 25.04% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:18:12,122]\u001b[0m Trial 575 finished with value: 5.2244477688150015 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006739417564384466, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19836154518423307, 'dropout_rate_Layer_2': 0.013630222079520998, 'dropout_rate_Layer_3': 0.040876802505419696, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.5549562968297925e-05, 'l1_Layer_2': 0.0002491035374338352, 'l1_Layer_3': 0.0002733769476472652, 'n_units_Layer_1': 130, 'n_units_Layer_2': 60, 'n_units_Layer_3': 60}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.22 | sMAPE for Validation Set is: 21.33% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 11.27 | sMAPE for Test Set is: 28.82% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:18:24,598]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:18:28,221]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:18:41,125]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:18:41,714]\u001b[0m Trial 579 finished with value: 5.396673083126935 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006776114552432312, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22192247582690397, 'dropout_rate_Layer_2': 0.037717082830372395, 'dropout_rate_Layer_3': 0.06928992314281945, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.7886475292800066e-05, 'l1_Layer_2': 0.0002517553552626993, 'l1_Layer_3': 0.0003758483542743292, 'n_units_Layer_1': 145, 'n_units_Layer_2': 55, 'n_units_Layer_3': 60}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.40 | sMAPE for Validation Set is: 21.83% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.40 | sMAPE for Test Set is: 29.38% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:19:05,015]\u001b[0m Trial 587 finished with value: 5.401423676123417 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006823790307189349, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20093050704580545, 'dropout_rate_Layer_2': 0.01511240174958957, 'dropout_rate_Layer_3': 0.07676938725517134, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.6148737454906937e-05, 'l1_Layer_2': 0.0002595822289167238, 'l1_Layer_3': 0.00011657896012642374, 'n_units_Layer_1': 140, 'n_units_Layer_2': 55, 'n_units_Layer_3': 65}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.40 | sMAPE for Validation Set is: 21.75% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.69 | sMAPE for Test Set is: 27.55% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:19:12,435]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:19:15,843]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:19:20,357]\u001b[0m Trial 592 finished with value: 5.350258452112005 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010571944315985334, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3909003589986144, 'dropout_rate_Layer_2': 0.2312008590667799, 'dropout_rate_Layer_3': 0.15452441234089104, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.198775776391658e-05, 'l1_Layer_2': 2.969650371134148e-05, 'l1_Layer_3': 0.0007231595809987853, 'n_units_Layer_1': 155, 'n_units_Layer_2': 175, 'n_units_Layer_3': 185}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.35 | sMAPE for Validation Set is: 21.42% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 13.00 | sMAPE for Test Set is: 33.58% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:19:25,388]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:19:29,550]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:19:35,591]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:19:48,405]\u001b[0m Trial 593 finished with value: 5.405893110752218 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006598843849235308, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3846514195110088, 'dropout_rate_Layer_2': 0.22961380724517375, 'dropout_rate_Layer_3': 0.2168572507053826, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.236407379091664e-05, 'l1_Layer_2': 5.4751208264585344e-05, 'l1_Layer_3': 0.0020274937929094044, 'n_units_Layer_1': 280, 'n_units_Layer_2': 165, 'n_units_Layer_3': 185}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.41 | sMAPE for Validation Set is: 21.74% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.44 | sMAPE for Test Set is: 29.48% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:20:04,975]\u001b[0m Trial 588 finished with value: 5.359790808055446 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006559772350365674, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2509683069206917, 'dropout_rate_Layer_2': 0.019519650856918064, 'dropout_rate_Layer_3': 0.08491220014299505, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.6902332239448486e-05, 'l1_Layer_2': 0.0002750022903189049, 'l1_Layer_3': 0.00015318212038152487, 'n_units_Layer_1': 140, 'n_units_Layer_2': 50, 'n_units_Layer_3': 60}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.36 | sMAPE for Validation Set is: 21.49% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 9.53 | sMAPE for Test Set is: 24.66% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:20:27,016]\u001b[0m Trial 600 finished with value: 5.384377001130146 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010915094680106604, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16174058310225556, 'dropout_rate_Layer_2': 0.3848389445928695, 'dropout_rate_Layer_3': 0.029598643512824006, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.5647541138750205e-05, 'l1_Layer_2': 0.0024466646528665302, 'l1_Layer_3': 1.560022219654491e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 120, 'n_units_Layer_3': 295}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.38 | sMAPE for Validation Set is: 21.65% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 8.67 | sMAPE for Test Set is: 23.17% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:21:06,770]\u001b[0m Trial 602 finished with value: 5.324424377185895 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006662316943015599, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.392515081030182, 'dropout_rate_Layer_2': 0.2357063395862314, 'dropout_rate_Layer_3': 0.21031204111471513, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.893078462960717e-05, 'l1_Layer_2': 2.2255902088577736e-05, 'l1_Layer_3': 0.001959081579705603, 'n_units_Layer_1': 150, 'n_units_Layer_2': 165, 'n_units_Layer_3': 190}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.32 | sMAPE for Validation Set is: 21.47% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 12.32 | sMAPE for Test Set is: 31.76% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:21:26,975]\u001b[0m Trial 598 finished with value: 5.359546806855575 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006183026371526533, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3881355914900031, 'dropout_rate_Layer_2': 0.2291532381097108, 'dropout_rate_Layer_3': 0.12412192869735356, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.958476021827006e-05, 'l1_Layer_2': 2.7173341405672906e-05, 'l1_Layer_3': 0.0019631082630994336, 'n_units_Layer_1': 150, 'n_units_Layer_2': 165, 'n_units_Layer_3': 180}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.36 | sMAPE for Validation Set is: 21.85% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 11.25 | sMAPE for Test Set is: 29.07% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:21:38,529]\u001b[0m Trial 601 finished with value: 5.3411474011676106 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006114917108117981, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38857120696800945, 'dropout_rate_Layer_2': 0.2295763698863663, 'dropout_rate_Layer_3': 0.15457950193869424, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.008207379906221e-05, 'l1_Layer_2': 2.1831334088969985e-05, 'l1_Layer_3': 0.0019736926214449536, 'n_units_Layer_1': 155, 'n_units_Layer_2': 165, 'n_units_Layer_3': 180}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.34 | sMAPE for Validation Set is: 21.50% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 11.65 | sMAPE for Test Set is: 30.08% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:21:51,758]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:22:05,539]\u001b[0m Trial 603 finished with value: 5.3589599367827745 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006566706619757714, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24830838408013758, 'dropout_rate_Layer_2': 0.018173425063739396, 'dropout_rate_Layer_3': 0.0682767243805425, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.389686238454444e-05, 'l1_Layer_2': 0.0002933195963430769, 'l1_Layer_3': 0.00012409252748316808, 'n_units_Layer_1': 145, 'n_units_Layer_2': 50, 'n_units_Layer_3': 60}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.36 | sMAPE for Validation Set is: 21.57% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.12 | sMAPE for Test Set is: 26.10% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:22:42,384]\u001b[0m Trial 604 finished with value: 5.392143717745401 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006814845410971383, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2548601450349617, 'dropout_rate_Layer_2': 0.01826474433628946, 'dropout_rate_Layer_3': 0.0748664890817241, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.5863636912888234e-05, 'l1_Layer_2': 0.0003066793374465251, 'l1_Layer_3': 0.00016508652829125224, 'n_units_Layer_1': 145, 'n_units_Layer_2': 50, 'n_units_Layer_3': 60}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.39 | sMAPE for Validation Set is: 21.71% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.33 | sMAPE for Test Set is: 26.48% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:22:53,509]\u001b[0m Trial 607 finished with value: 5.405304036742316 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016562189767131126, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15949738216420323, 'dropout_rate_Layer_2': 0.3791608428415108, 'dropout_rate_Layer_3': 0.08769852563884414, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.0332467787040215e-05, 'l1_Layer_2': 0.004046646945704697, 'l1_Layer_3': 1.1034142107721412e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 85, 'n_units_Layer_3': 285}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.41 | sMAPE for Validation Set is: 21.40% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 8.66 | sMAPE for Test Set is: 22.93% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:22:56,473]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:23:00,440]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:23:03,052]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:23:07,380]\u001b[0m Trial 608 finished with value: 5.413791166701853 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007474333415206905, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2539110511135466, 'dropout_rate_Layer_2': 0.015031331916003714, 'dropout_rate_Layer_3': 0.07786974255601972, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.232610903327252e-05, 'l1_Layer_2': 0.00022606311415749873, 'l1_Layer_3': 0.00014395319090075839, 'n_units_Layer_1': 130, 'n_units_Layer_2': 50, 'n_units_Layer_3': 50}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.41 | sMAPE for Validation Set is: 21.49% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.24 | sMAPE for Test Set is: 28.60% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:23:20,104]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:23:24,178]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:23:28,585]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:23:32,323]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:23:34,689]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:23:39,126]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:23:39,644]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:23:49,302]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:24:00,186]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:24:08,794]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:24:17,560]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:24:30,043]\u001b[0m Trial 612 finished with value: 5.403960221540842 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007295474020629549, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2632819926260674, 'dropout_rate_Layer_2': 0.03990045565463138, 'dropout_rate_Layer_3': 0.07831079823313605, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1743159584044588e-05, 'l1_Layer_2': 0.00023206339932862457, 'l1_Layer_3': 0.0001481416419321166, 'n_units_Layer_1': 130, 'n_units_Layer_2': 50, 'n_units_Layer_3': 50}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.40 | sMAPE for Validation Set is: 21.67% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.80 | sMAPE for Test Set is: 27.77% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:24:43,847]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:24:59,343]\u001b[0m Trial 622 finished with value: 5.3813473036374 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009829088336957862, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18679067107947853, 'dropout_rate_Layer_2': 0.38092216308204446, 'dropout_rate_Layer_3': 0.11214644023425471, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.747682308086813e-05, 'l1_Layer_2': 0.007406850016352706, 'l1_Layer_3': 3.222480446721511e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 65, 'n_units_Layer_3': 300}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.38 | sMAPE for Validation Set is: 21.87% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 8.08 | sMAPE for Test Set is: 21.65% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:25:03,028]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:25:16,361]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:25:21,494]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:25:24,135]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:25:29,153]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:25:32,351]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:25:34,273]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:25:39,498]\u001b[0m Trial 620 finished with value: 5.395576494194333 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007428685846899039, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24746771851305865, 'dropout_rate_Layer_2': 0.03259193922303431, 'dropout_rate_Layer_3': 0.09416922502023117, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2053338117985299e-05, 'l1_Layer_2': 0.00023293033627361882, 'l1_Layer_3': 0.00013972022410318742, 'n_units_Layer_1': 130, 'n_units_Layer_2': 50, 'n_units_Layer_3': 50}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.40 | sMAPE for Validation Set is: 21.58% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 9.50 | sMAPE for Test Set is: 24.74% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:25:48,515]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:25:51,552]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:26:04,493]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:26:56,985]\u001b[0m Trial 635 finished with value: 5.379919774361386 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006291356984421491, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24939420938754736, 'dropout_rate_Layer_2': 0.052673387962703766, 'dropout_rate_Layer_3': 0.06413818153613278, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0200444958121252e-05, 'l1_Layer_2': 0.00034237929002370364, 'l1_Layer_3': 8.235241208662269e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 55, 'n_units_Layer_3': 65}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.38 | sMAPE for Validation Set is: 21.69% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.08 | sMAPE for Test Set is: 28.40% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:27:06,368]\u001b[0m Trial 637 finished with value: 5.408398054801346 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006428986753552789, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24899702843123, 'dropout_rate_Layer_2': 0.04843857761314618, 'dropout_rate_Layer_3': 0.08242466678261101, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0419784937705557e-05, 'l1_Layer_2': 0.00018201071479930018, 'l1_Layer_3': 8.34392593245403e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 55, 'n_units_Layer_3': 65}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.41 | sMAPE for Validation Set is: 21.68% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.28 | sMAPE for Test Set is: 26.48% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:27:33,689]\u001b[0m Trial 639 finished with value: 5.383265978391985 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006399872884874877, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24491485714349454, 'dropout_rate_Layer_2': 0.05355617724897811, 'dropout_rate_Layer_3': 0.06452479700325256, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0052598652981169e-05, 'l1_Layer_2': 0.00034028866577371665, 'l1_Layer_3': 0.0002058930169781408, 'n_units_Layer_1': 135, 'n_units_Layer_2': 55, 'n_units_Layer_3': 65}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.38 | sMAPE for Validation Set is: 21.68% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.37 | sMAPE for Test Set is: 26.75% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:27:36,803]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:27:42,509]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:27:42,627]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:28:45,829]\u001b[0m Trial 640 finished with value: 5.416396081148747 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012916431685667995, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38909822790982784, 'dropout_rate_Layer_2': 0.2399629577588111, 'dropout_rate_Layer_3': 0.11672463274706348, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.207835338327271e-05, 'l1_Layer_2': 2.7024870092509195e-05, 'l1_Layer_3': 0.00246230987499118, 'n_units_Layer_1': 170, 'n_units_Layer_2': 180, 'n_units_Layer_3': 200}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.42 | sMAPE for Validation Set is: 21.50% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 12.22 | sMAPE for Test Set is: 31.35% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:28:58,519]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.40 | sMAPE for Validation Set is: 21.59% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.18 | sMAPE for Test Set is: 28.87% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:29:05,851]\u001b[0m Trial 641 finished with value: 5.40350667743876 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010191583249870052, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38955420185158884, 'dropout_rate_Layer_2': 0.23528998141322324, 'dropout_rate_Layer_3': 0.2408573384962922, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0769694473174627e-05, 'l1_Layer_2': 1.3522457796197598e-05, 'l1_Layer_3': 0.002412207892389013, 'n_units_Layer_1': 160, 'n_units_Layer_2': 180, 'n_units_Layer_3': 200}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:29:16,150]\u001b[0m Trial 644 finished with value: 5.392446552222974 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006179821691431791, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2516680259371317, 'dropout_rate_Layer_2': 0.04889776909095106, 'dropout_rate_Layer_3': 0.08034064942822224, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0564301685874093e-05, 'l1_Layer_2': 0.000184381001870767, 'l1_Layer_3': 0.00014460544175041236, 'n_units_Layer_1': 135, 'n_units_Layer_2': 55, 'n_units_Layer_3': 65}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.39 | sMAPE for Validation Set is: 21.73% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.19 | sMAPE for Test Set is: 26.29% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:29:23,604]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:29:28,391]\u001b[0m Trial 645 finished with value: 5.3603369627304005 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006431315235482938, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2513690981669244, 'dropout_rate_Layer_2': 0.05115333314141393, 'dropout_rate_Layer_3': 0.08137647069681586, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3838287207387271e-05, 'l1_Layer_2': 0.0003391380150897417, 'l1_Layer_3': 0.00020295737177011602, 'n_units_Layer_1': 135, 'n_units_Layer_2': 55, 'n_units_Layer_3': 65}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.36 | sMAPE for Validation Set is: 21.59% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.21 | sMAPE for Test Set is: 26.30% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:29:30,456]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:29:34,790]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:30:00,308]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:30:23,036]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:30:26,685]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:30:44,465]\u001b[0m Trial 648 finished with value: 5.432769606990647 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006267857513216619, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24957013568599734, 'dropout_rate_Layer_2': 0.05237342031726668, 'dropout_rate_Layer_3': 0.08365272813221536, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1055243202271593e-05, 'l1_Layer_2': 0.00018534721773222904, 'l1_Layer_3': 0.00021108699622942397, 'n_units_Layer_1': 135, 'n_units_Layer_2': 55, 'n_units_Layer_3': 55}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.43 | sMAPE for Validation Set is: 21.86% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.53 | sMAPE for Test Set is: 27.04% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:30:51,862]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:30:52,579]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:31:13,068]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:31:38,341]\u001b[0m Trial 656 finished with value: 5.342809818140345 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008864094323333636, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1896519479121047, 'dropout_rate_Layer_2': 0.3973509483095692, 'dropout_rate_Layer_3': 0.11131861223167432, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 4.1063241365745346e-05, 'l1_Layer_2': 0.007590730894234457, 'l1_Layer_3': 3.222357595639398e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 105, 'n_units_Layer_3': 280}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.34 | sMAPE for Validation Set is: 21.47% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 9.10 | sMAPE for Test Set is: 23.90% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:31:46,660]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:32:05,848]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:32:14,594]\u001b[0m Trial 647 finished with value: 5.439470849905434 and parameters: {'n_hidden': 3, 'learning_rate': 0.003224822061891893, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0065075491183477305, 'dropout_rate_Layer_2': 0.20190887695128365, 'dropout_rate_Layer_3': 0.21725676343156441, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005813697587504351, 'l1_Layer_2': 1.1725833803742824e-05, 'l1_Layer_3': 6.187142348825144e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 200, 'n_units_Layer_3': 90}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.44 | sMAPE for Validation Set is: 22.13% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 8.86 | sMAPE for Test Set is: 23.37% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:32:31,372]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:32:39,749]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:32:54,274]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:33:14,634]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:33:33,983]\u001b[0m Trial 662 finished with value: 5.325421035454386 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006846679736228762, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26217426905288854, 'dropout_rate_Layer_2': 0.03007897185448941, 'dropout_rate_Layer_3': 0.10528073384188143, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.8822037820093124e-05, 'l1_Layer_2': 0.0005040413259284088, 'l1_Layer_3': 0.0001637301431907783, 'n_units_Layer_1': 120, 'n_units_Layer_2': 50, 'n_units_Layer_3': 75}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.33 | sMAPE for Validation Set is: 21.54% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.40 | sMAPE for Test Set is: 26.74% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:33:48,069]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:33:55,876]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:33:58,167]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:34:02,764]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:34:12,978]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:34:32,624]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:34:35,435]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:34:44,160]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:35:04,884]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:35:17,110]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:35:25,970]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:35:49,782]\u001b[0m Trial 672 finished with value: 5.321707773312816 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007778257562409101, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27057315160075107, 'dropout_rate_Layer_2': 0.3555196681446212, 'dropout_rate_Layer_3': 0.24905401542614516, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 4.4166380413124636e-05, 'l1_Layer_2': 0.013854463262343214, 'l1_Layer_3': 3.1306473051536434e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 70, 'n_units_Layer_3': 280}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.32 | sMAPE for Validation Set is: 21.47% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 9.82 | sMAPE for Test Set is: 25.64% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:35:56,311]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:35:56,837]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:36:04,330]\u001b[0m Trial 674 finished with value: 5.348250229203973 and parameters: {'n_hidden': 3, 'learning_rate': 0.000827827207576955, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22306141262904292, 'dropout_rate_Layer_2': 0.36618425048799547, 'dropout_rate_Layer_3': 0.2522688937865625, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 3.6197789116579676e-05, 'l1_Layer_2': 0.016296242886525918, 'l1_Layer_3': 2.1854812413768116e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 70, 'n_units_Layer_3': 280}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.35 | sMAPE for Validation Set is: 21.62% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 9.16 | sMAPE for Test Set is: 24.25% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:36:07,654]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:36:50,355]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:36:56,482]\u001b[0m Trial 680 finished with value: 5.28036922779746 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007655171022228729, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2679376532363841, 'dropout_rate_Layer_2': 0.3959394046669401, 'dropout_rate_Layer_3': 0.24967920683914635, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 4.7216201497257136e-05, 'l1_Layer_2': 0.01612998003767575, 'l1_Layer_3': 2.610294641299773e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 105, 'n_units_Layer_3': 280}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.28 | sMAPE for Validation Set is: 21.25% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 9.69 | sMAPE for Test Set is: 25.17% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:37:05,821]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:37:13,792]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:37:31,806]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:37:40,058]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:37:47,317]\u001b[0m Trial 685 finished with value: 5.2747782648313155 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007619468221386718, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35981343864160253, 'dropout_rate_Layer_2': 0.356568511740581, 'dropout_rate_Layer_3': 0.2533225017462957, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 3.595501165534262e-05, 'l1_Layer_2': 0.017585911514930018, 'l1_Layer_3': 2.7941729408682338e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 50, 'n_units_Layer_3': 280}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.27 | sMAPE for Validation Set is: 21.36% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 9.37 | sMAPE for Test Set is: 24.63% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:38:04,699]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:38:17,511]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:38:17,693]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.30 | sMAPE for Validation Set is: 21.26% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.00 | sMAPE for Test Set is: 25.95% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:38:20,870]\u001b[0m Trial 689 finished with value: 5.304186205550529 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007789478481766503, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.258976309320303, 'dropout_rate_Layer_2': 0.3611666645993796, 'dropout_rate_Layer_3': 0.25510890773154254, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 4.110945380901049e-05, 'l1_Layer_2': 0.014909118671629758, 'l1_Layer_3': 3.034518945908743e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 50, 'n_units_Layer_3': 275}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:38:26,935]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:38:40,399]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:38:45,206]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:39:23,316]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:39:31,540]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:39:47,159]\u001b[0m Trial 699 finished with value: 5.364888784188703 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005757773740908956, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38148926039364656, 'dropout_rate_Layer_2': 0.29345362204117664, 'dropout_rate_Layer_3': 0.24270650010934888, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.4746282456292713e-05, 'l1_Layer_2': 7.869986166904989e-05, 'l1_Layer_3': 0.000916841405223598, 'n_units_Layer_1': 265, 'n_units_Layer_2': 165, 'n_units_Layer_3': 300}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.36 | sMAPE for Validation Set is: 21.59% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 11.82 | sMAPE for Test Set is: 30.45% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:40:18,432]\u001b[0m Trial 695 finished with value: 5.341677845167603 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005594886398157785, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2587795521729569, 'dropout_rate_Layer_2': 0.03829954685265222, 'dropout_rate_Layer_3': 0.11053441564841081, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.0189738103543298e-05, 'l1_Layer_2': 0.0001981945697541342, 'l1_Layer_3': 0.00011913156846544017, 'n_units_Layer_1': 115, 'n_units_Layer_2': 50, 'n_units_Layer_3': 65}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.34 | sMAPE for Validation Set is: 21.47% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.30 | sMAPE for Test Set is: 26.58% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:40:20,433]\u001b[0m Trial 698 finished with value: 5.401938455003684 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005810172354488198, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33869929095596574, 'dropout_rate_Layer_2': 0.20673713977740343, 'dropout_rate_Layer_3': 0.2472998416196178, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010614061960409698, 'l1_Layer_2': 6.82756847212831e-05, 'l1_Layer_3': 0.0027041538710581223, 'n_units_Layer_1': 265, 'n_units_Layer_2': 165, 'n_units_Layer_3': 235}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.40 | sMAPE for Validation Set is: 21.85% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 12.03 | sMAPE for Test Set is: 31.09% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:40:31,254]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:40:33,044]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:40:58,108]\u001b[0m Trial 701 finished with value: 5.4607828799026095 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005819384855590322, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3691888422729162, 'dropout_rate_Layer_2': 0.2984554239645781, 'dropout_rate_Layer_3': 0.24761626487184973, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3812607097916908e-05, 'l1_Layer_2': 6.950280660339894e-05, 'l1_Layer_3': 0.00287291881655298, 'n_units_Layer_1': 265, 'n_units_Layer_2': 190, 'n_units_Layer_3': 235}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.46 | sMAPE for Validation Set is: 22.12% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 12.58 | sMAPE for Test Set is: 32.63% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:41:45,751]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:41:46,267]\u001b[0m Trial 705 finished with value: 5.404208888124043 and parameters: {'n_hidden': 3, 'learning_rate': 0.003618693515372381, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3251463021903399, 'dropout_rate_Layer_2': 0.06018168902899826, 'dropout_rate_Layer_3': 0.25174571040499505, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003755212775689457, 'l1_Layer_2': 1.3200065358391902e-05, 'l1_Layer_3': 2.4343548154020852e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 120, 'n_units_Layer_3': 95}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.40 | sMAPE for Validation Set is: 21.35% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 13.05 | sMAPE for Test Set is: 33.49% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:41:53,242]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:41:53,337]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:41:53,647]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.44 | sMAPE for Validation Set is: 21.75% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.39 | sMAPE for Test Set is: 26.53% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:41:56,199]\u001b[0m Trial 706 finished with value: 5.440215862155156 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006357824326823156, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23221661467298468, 'dropout_rate_Layer_2': 0.03899149347410936, 'dropout_rate_Layer_3': 0.05743558671168647, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.7978836563694724e-05, 'l1_Layer_2': 0.00026505064134363626, 'l1_Layer_3': 0.00011334157717258503, 'n_units_Layer_1': 110, 'n_units_Layer_2': 55, 'n_units_Layer_3': 55}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:42:03,601]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:42:06,325]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:42:38,311]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:42:52,801]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:43:08,976]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:43:14,675]\u001b[0m Trial 713 finished with value: 5.4752871400062375 and parameters: {'n_hidden': 3, 'learning_rate': 0.003738769021312032, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3377966173783795, 'dropout_rate_Layer_2': 0.0707539682279933, 'dropout_rate_Layer_3': 0.2366917361448921, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00028117525186878244, 'l1_Layer_2': 1.2122152458794823e-05, 'l1_Layer_3': 1.8020559885887835e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 210, 'n_units_Layer_3': 95}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.48 | sMAPE for Validation Set is: 21.33% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 13.62 | sMAPE for Test Set is: 35.11% | rMAE for Test Set is: 1.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:43:26,634]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:43:32,952]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:43:36,483]\u001b[0m Trial 714 finished with value: 5.405956936322112 and parameters: {'n_hidden': 3, 'learning_rate': 0.003673012661802405, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31414996482388696, 'dropout_rate_Layer_2': 0.08598562188468829, 'dropout_rate_Layer_3': 0.23606620275391618, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00041393741510808204, 'l1_Layer_2': 1.0559928431528508e-05, 'l1_Layer_3': 1.7248898614306133e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 210, 'n_units_Layer_3': 95}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.41 | sMAPE for Validation Set is: 21.45% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.33 | sMAPE for Test Set is: 28.96% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:43:41,718]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:43:56,067]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:44:00,970]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:44:09,911]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:44:49,320]\u001b[0m Trial 724 finished with value: 5.455525744812672 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008474343194775008, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3620137437458582, 'dropout_rate_Layer_2': 0.289156296673917, 'dropout_rate_Layer_3': 0.2226586349267698, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.3718711754562564e-05, 'l1_Layer_2': 8.375220241012632e-05, 'l1_Layer_3': 0.0017683839143766578, 'n_units_Layer_1': 275, 'n_units_Layer_2': 165, 'n_units_Layer_3': 250}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.46 | sMAPE for Validation Set is: 22.14% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.89 | sMAPE for Test Set is: 30.80% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:44:49,747]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:45:06,621]\u001b[0m Trial 722 finished with value: 5.33812060989509 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005003957157570283, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25694152014034777, 'dropout_rate_Layer_2': 0.06842149333314398, 'dropout_rate_Layer_3': 0.04831492054532203, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1238681143543271e-05, 'l1_Layer_2': 0.00033232857986383735, 'l1_Layer_3': 5.749700036963572e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 65, 'n_units_Layer_3': 75}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.34 | sMAPE for Validation Set is: 21.40% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.59 | sMAPE for Test Set is: 27.03% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:45:12,926]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:45:17,066]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:45:48,119]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:46:41,831]\u001b[0m Trial 732 finished with value: 5.3293167435815585 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006146060185978137, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35326469306149, 'dropout_rate_Layer_2': 0.20555893300089617, 'dropout_rate_Layer_3': 0.2708622259632478, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010159050122924701, 'l1_Layer_2': 0.00017134375653018321, 'l1_Layer_3': 0.0009067399572661321, 'n_units_Layer_1': 160, 'n_units_Layer_2': 150, 'n_units_Layer_3': 300}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.33 | sMAPE for Validation Set is: 21.51% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 11.93 | sMAPE for Test Set is: 30.89% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:46:50,488]\u001b[0m Trial 727 finished with value: 5.434245024113683 and parameters: {'n_hidden': 3, 'learning_rate': 0.002744131912203821, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33570291107794475, 'dropout_rate_Layer_2': 0.0647959101052047, 'dropout_rate_Layer_3': 0.24308378875386136, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020960604112786385, 'l1_Layer_2': 1.0182631252117605e-05, 'l1_Layer_3': 1.1606899805067728e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 220, 'n_units_Layer_3': 105}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.43 | sMAPE for Validation Set is: 21.56% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 12.87 | sMAPE for Test Set is: 33.34% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:46:55,898]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:46:58,213]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:47:05,006]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:47:11,075]\u001b[0m Trial 726 finished with value: 5.307285725596454 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034462607092994326, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3351838891693681, 'dropout_rate_Layer_2': 0.06639255341517608, 'dropout_rate_Layer_3': 0.2336949189375704, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00019019309475357097, 'l1_Layer_2': 1.1904240607644509e-05, 'l1_Layer_3': 1.0646506983092194e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 220, 'n_units_Layer_3': 90}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.31 | sMAPE for Validation Set is: 21.19% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 11.92 | sMAPE for Test Set is: 30.72% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:47:27,024]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:47:35,963]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:47:44,037]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:47:50,227]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:47:50,717]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:48:02,547]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:48:16,731]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:48:56,850]\u001b[0m Trial 742 finished with value: 5.338318711986257 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006795961834213985, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24323643210229284, 'dropout_rate_Layer_2': 0.010352290711023579, 'dropout_rate_Layer_3': 0.06825849231613959, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2139605539182541e-05, 'l1_Layer_2': 0.0003895396800877436, 'l1_Layer_3': 6.237640976976256e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 65, 'n_units_Layer_3': 60}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.34 | sMAPE for Validation Set is: 21.40% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 11.30 | sMAPE for Test Set is: 28.85% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:49:04,440]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:49:12,027]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:49:18,290]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:50:17,550]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:50:29,716]\u001b[0m Trial 745 finished with value: 5.342485636947625 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007051684867527429, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22320317082365024, 'dropout_rate_Layer_2': 0.010111902759291816, 'dropout_rate_Layer_3': 0.044836664325593086, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.5077375318783039e-05, 'l1_Layer_2': 0.0003230418366431487, 'l1_Layer_3': 5.9312642524057706e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 55, 'n_units_Layer_3': 65}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.34 | sMAPE for Validation Set is: 21.53% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 9.81 | sMAPE for Test Set is: 25.49% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:50:32,544]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:50:33,063]\u001b[0m Trial 736 finished with value: 5.239691187169966 and parameters: {'n_hidden': 3, 'learning_rate': 0.003152653390486869, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3274796983077483, 'dropout_rate_Layer_2': 0.06665800915584756, 'dropout_rate_Layer_3': 0.2524489626192606, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022323390298535046, 'l1_Layer_2': 1.1970459986302555e-05, 'l1_Layer_3': 1.537370846946948e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 215, 'n_units_Layer_3': 100}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.24 | sMAPE for Validation Set is: 20.96% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 13.40 | sMAPE for Test Set is: 34.81% | rMAE for Test Set is: 1.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:50:37,323]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:50:58,569]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:51:40,532]\u001b[0m Trial 755 finished with value: 5.37396826241998 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010011364002041575, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35577735208208594, 'dropout_rate_Layer_2': 0.20594819778923246, 'dropout_rate_Layer_3': 0.2445624132350166, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000115145308273198, 'l1_Layer_2': 0.00018277433604246354, 'l1_Layer_3': 0.0012247150471671408, 'n_units_Layer_1': 160, 'n_units_Layer_2': 125, 'n_units_Layer_3': 290}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.37 | sMAPE for Validation Set is: 21.54% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 11.37 | sMAPE for Test Set is: 29.31% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:51:49,531]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:51:56,313]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:51:57,680]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:52:22,534]\u001b[0m Trial 752 finished with value: 5.401479994078589 and parameters: {'n_hidden': 3, 'learning_rate': 0.003087517878303502, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3312324414927939, 'dropout_rate_Layer_2': 0.06467777398014883, 'dropout_rate_Layer_3': 0.23489694131421535, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013461514627064686, 'l1_Layer_2': 1.044050301232407e-05, 'l1_Layer_3': 1.7499214984996974e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 225, 'n_units_Layer_3': 105}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.40 | sMAPE for Validation Set is: 21.41% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 13.08 | sMAPE for Test Set is: 33.63% | rMAE for Test Set is: 1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:53:29,787]\u001b[0m Trial 759 finished with value: 5.305561941766304 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005825148312813461, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2540571155417563, 'dropout_rate_Layer_2': 0.00023480248153965287, 'dropout_rate_Layer_3': 0.051805112313931145, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.4595900658253677e-05, 'l1_Layer_2': 0.00046903980904510655, 'l1_Layer_3': 4.4544523053009066e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 55, 'n_units_Layer_3': 80}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.31 | sMAPE for Validation Set is: 21.37% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.59 | sMAPE for Test Set is: 27.28% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:53:36,220]\u001b[0m Trial 758 finished with value: 5.307872631191043 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005838232726241287, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2531091673338486, 'dropout_rate_Layer_2': 0.02846490683492301, 'dropout_rate_Layer_3': 0.0504677501304134, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.4191490700200256e-05, 'l1_Layer_2': 0.0004451890574956798, 'l1_Layer_3': 6.373964243862408e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 55, 'n_units_Layer_3': 80}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.31 | sMAPE for Validation Set is: 21.37% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 9.88 | sMAPE for Test Set is: 25.46% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:53:45,180]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:53:49,120]\u001b[0m Trial 757 finished with value: 5.293482463106902 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005861510482187703, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2509311086996971, 'dropout_rate_Layer_2': 0.027631730130981746, 'dropout_rate_Layer_3': 0.051919159176427844, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.3536904836879556e-05, 'l1_Layer_2': 0.00044018659491451356, 'l1_Layer_3': 7.049906166809003e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 55, 'n_units_Layer_3': 80}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.29 | sMAPE for Validation Set is: 21.32% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 9.49 | sMAPE for Test Set is: 24.67% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:53:55,286]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:54:04,020]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:54:21,969]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:55:03,684]\u001b[0m Trial 763 finished with value: 5.37747120348435 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007623193236680244, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35674723209993764, 'dropout_rate_Layer_2': 0.20638330051504228, 'dropout_rate_Layer_3': 0.2654729851026028, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010436541618744614, 'l1_Layer_2': 0.00018404495845149134, 'l1_Layer_3': 0.0013400479819426158, 'n_units_Layer_1': 145, 'n_units_Layer_2': 115, 'n_units_Layer_3': 280}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.38 | sMAPE for Validation Set is: 21.41% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 11.23 | sMAPE for Test Set is: 28.90% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:55:37,530]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:55:49,119]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:56:22,476]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:56:31,003]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:56:40,335]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:56:48,575]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:56:57,016]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:57:10,686]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:57:15,917]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:57:20,531]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:57:55,742]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:58:25,919]\u001b[0m Trial 770 finished with value: 5.313073590080527 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005672526260817163, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25227904552393243, 'dropout_rate_Layer_2': 0.029625934049902915, 'dropout_rate_Layer_3': 0.05213825678051977, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.6368043063910042e-05, 'l1_Layer_2': 0.0006880481053025116, 'l1_Layer_3': 3.7922103723176255e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 60, 'n_units_Layer_3': 80}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.31 | sMAPE for Validation Set is: 21.30% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 9.18 | sMAPE for Test Set is: 24.02% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:58:31,667]\u001b[0m Trial 778 finished with value: 5.431663786665688 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028073976276854653, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3284510031936378, 'dropout_rate_Layer_2': 0.08272920624317645, 'dropout_rate_Layer_3': 0.2429532203648993, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011122948102488576, 'l1_Layer_2': 1.1798909781689996e-05, 'l1_Layer_3': 1.4194723381782426e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 230, 'n_units_Layer_3': 100}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.43 | sMAPE for Validation Set is: 21.35% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 12.32 | sMAPE for Test Set is: 31.38% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 17:58:40,908]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:58:48,792]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:59:01,564]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:59:16,708]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 17:59:56,418]\u001b[0m Trial 784 finished with value: 5.405109216068045 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008574089394175848, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30148478808511087, 'dropout_rate_Layer_2': 0.21543673685983544, 'dropout_rate_Layer_3': 0.25746753689568685, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017970253978167363, 'l1_Layer_2': 0.0003438960265898234, 'l1_Layer_3': 0.0006314274209462597, 'n_units_Layer_1': 130, 'n_units_Layer_2': 100, 'n_units_Layer_3': 285}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.41 | sMAPE for Validation Set is: 21.48% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.96 | sMAPE for Test Set is: 28.27% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:00:39,296]\u001b[0m Trial 785 finished with value: 5.399510274217561 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023184997623945714, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32627825610221944, 'dropout_rate_Layer_2': 0.09542777029367272, 'dropout_rate_Layer_3': 0.21607436446503828, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001308572651487438, 'l1_Layer_2': 1.2248000327201064e-05, 'l1_Layer_3': 1.1785455821837288e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 225, 'n_units_Layer_3': 105}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.40 | sMAPE for Validation Set is: 21.25% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.73 | sMAPE for Test Set is: 29.87% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:00:44,263]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:00:53,670]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:01:14,456]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:01:19,367]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:01:19,883]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:01:26,399]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:01:30,900]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:01:33,914]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:01:38,786]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:01:48,981]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:02:01,409]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:02:17,477]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:02:27,524]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:02:36,573]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:02:46,534]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:02:51,936]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:03:09,530]\u001b[0m Trial 797 finished with value: 5.529625245440385 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024706065405429656, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34534883094883273, 'dropout_rate_Layer_2': 0.02538341555146982, 'dropout_rate_Layer_3': 0.22310652004013629, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000164041403090955, 'l1_Layer_2': 1.592929175319417e-05, 'l1_Layer_3': 1.0302322577663337e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 230, 'n_units_Layer_3': 125}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.53 | sMAPE for Validation Set is: 21.79% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 11.40 | sMAPE for Test Set is: 29.27% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:03:42,603]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:04:19,833]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:04:28,034]\u001b[0m Trial 802 finished with value: 5.351989307128297 and parameters: {'n_hidden': 3, 'learning_rate': 0.002977816722615083, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3240323908128308, 'dropout_rate_Layer_2': 0.08467725251579958, 'dropout_rate_Layer_3': 0.20813068922258693, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.873676609837521e-05, 'l1_Layer_2': 0.00010333886872607338, 'l1_Layer_3': 1.0259252877399e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 225, 'n_units_Layer_3': 110}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.35 | sMAPE for Validation Set is: 21.30% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 11.29 | sMAPE for Test Set is: 28.76% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:04:31,304]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:04:40,150]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:04:54,459]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:05:07,496]\u001b[0m Trial 801 finished with value: 5.3571686169721575 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006310707572224518, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35230853587198313, 'dropout_rate_Layer_2': 0.20768291863229466, 'dropout_rate_Layer_3': 0.24431231474275014, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.856359885753791e-05, 'l1_Layer_2': 9.441563681457928e-05, 'l1_Layer_3': 0.0013344278582988586, 'n_units_Layer_1': 160, 'n_units_Layer_2': 140, 'n_units_Layer_3': 300}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.36 | sMAPE for Validation Set is: 21.68% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 12.00 | sMAPE for Test Set is: 30.78% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:05:14,935]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:05:17,606]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:05:24,277]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:05:31,152]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:05:34,944]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:05:35,487]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:05:48,980]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:05:59,214]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:05:59,386]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:06:06,808]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:06:11,847]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:06:18,167]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:06:27,354]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:06:27,696]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:06:32,799]\u001b[0m Trial 806 finished with value: 5.359590318202419 and parameters: {'n_hidden': 3, 'learning_rate': 0.002821055775831131, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35519832022600734, 'dropout_rate_Layer_2': 0.08161444986914483, 'dropout_rate_Layer_3': 0.2078563833175417, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.7024169847131e-05, 'l1_Layer_2': 0.00020144768990244948, 'l1_Layer_3': 1.4461320605166328e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 235, 'n_units_Layer_3': 125}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.36 | sMAPE for Validation Set is: 21.51% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 11.54 | sMAPE for Test Set is: 29.50% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:06:39,672]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:06:48,823]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:06:52,717]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:06:58,973]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:07:13,043]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:07:13,190]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:07:20,107]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:07:30,992]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:07:42,094]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:07:46,117]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:07:52,809]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:08:06,119]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:08:08,961]\u001b[0m Trial 819 finished with value: 5.41018238128952 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007915915303028809, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24544816617140697, 'dropout_rate_Layer_2': 0.3974701517273601, 'dropout_rate_Layer_3': 0.25302231104536604, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 5.101869755637979e-05, 'l1_Layer_2': 0.020465109229294592, 'l1_Layer_3': 6.238885662578184e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 60, 'n_units_Layer_3': 290}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.41 | sMAPE for Validation Set is: 21.55% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 8.88 | sMAPE for Test Set is: 23.38% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:08:29,431]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:08:39,476]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:08:48,381]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:09:09,485]\u001b[0m Trial 837 finished with value: 5.517154106980596 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032340371180833664, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3750715960168489, 'dropout_rate_Layer_2': 0.07732799044277791, 'dropout_rate_Layer_3': 0.22219578935913298, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001723654539376024, 'l1_Layer_2': 6.905797786232985e-05, 'l1_Layer_3': 1.2421565776624125e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 225, 'n_units_Layer_3': 95}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.52 | sMAPE for Validation Set is: 21.64% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 12.26 | sMAPE for Test Set is: 31.44% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:09:23,207]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:09:37,203]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:09:41,366]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:09:59,996]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:10:05,057]\u001b[0m Trial 835 finished with value: 5.437613529858478 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007423805160244477, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30312962007241057, 'dropout_rate_Layer_2': 0.29880949601583234, 'dropout_rate_Layer_3': 0.25629364938125204, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.2711345685450334e-05, 'l1_Layer_2': 0.00398022755528504, 'l1_Layer_3': 3.217449196214908e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 85, 'n_units_Layer_3': 275}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.44 | sMAPE for Validation Set is: 21.61% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 9.70 | sMAPE for Test Set is: 25.43% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:10:08,924]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:10:27,143]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:10:31,601]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:10:36,398]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:10:51,280]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:11:09,630]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:11:17,101]\u001b[0m Trial 847 finished with value: 5.5053612311481315 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032688913692776305, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3217673963977215, 'dropout_rate_Layer_2': 0.10730219778620514, 'dropout_rate_Layer_3': 0.2100962677148244, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.416598607812026e-05, 'l1_Layer_2': 7.754804225356348e-05, 'l1_Layer_3': 1.0060512908015822e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 235, 'n_units_Layer_3': 100}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:11:17,165]\u001b[0m Trial 848 finished with value: 5.318394239333146 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005685026756631928, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2882806095561911, 'dropout_rate_Layer_2': 0.35136328062353417, 'dropout_rate_Layer_3': 0.2908716448492752, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.3420117734318194e-05, 'l1_Layer_2': 0.00628106238368499, 'l1_Layer_3': 2.1654062351099977e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 105, 'n_units_Layer_3': 255}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.51 | sMAPE for Validation Set is: 21.67% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 11.23 | sMAPE for Test Set is: 28.69% | rMAE for Test Set is: 1.07\n",
      "MAE for Validation Set is: 5.32 | sMAPE for Validation Set is: 21.35% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 9.77 | sMAPE for Test Set is: 25.78% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:11:23,779]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:11:34,337]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:11:38,331]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:11:41,173]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:11:51,050]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:11:51,586]\u001b[0m Trial 851 finished with value: 5.526091981668934 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028338970242196564, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36674910083893086, 'dropout_rate_Layer_2': 0.10164394150861182, 'dropout_rate_Layer_3': 0.2190581337828869, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.225423842241014e-05, 'l1_Layer_2': 6.918382620929357e-05, 'l1_Layer_3': 2.236478706762678e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 260, 'n_units_Layer_3': 100}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.53 | sMAPE for Validation Set is: 21.61% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 12.74 | sMAPE for Test Set is: 32.70% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:11:54,702]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:12:03,350]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:12:04,479]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:12:08,997]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:12:15,407]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:12:18,587]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:12:24,608]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:12:27,950]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:12:32,017]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:12:35,121]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:12:45,728]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:12:51,584]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:13:00,406]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:13:03,992]\u001b[0m Trial 859 finished with value: 5.410334801330357 and parameters: {'n_hidden': 3, 'learning_rate': 0.000898555690052526, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3667319999325192, 'dropout_rate_Layer_2': 0.30855953804044384, 'dropout_rate_Layer_3': 0.12932191331799303, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.4845696904507173e-05, 'l1_Layer_2': 0.0005677032786564023, 'l1_Layer_3': 0.003470843610274227, 'n_units_Layer_1': 155, 'n_units_Layer_2': 155, 'n_units_Layer_3': 295}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.41 | sMAPE for Validation Set is: 21.85% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 12.83 | sMAPE for Test Set is: 33.20% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:13:08,144]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:13:17,426]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:13:38,908]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:13:41,658]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:13:51,808]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:13:57,652]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:14:05,468]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:14:14,253]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:14:20,052]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:14:24,744]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:14:34,311]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:14:37,146]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:14:55,421]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:14:58,164]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:15:03,182]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:15:09,341]\u001b[0m Trial 871 finished with value: 5.375069298843127 and parameters: {'n_hidden': 3, 'learning_rate': 0.000594668891414904, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2888293834825032, 'dropout_rate_Layer_2': 0.34739825708404404, 'dropout_rate_Layer_3': 0.2999413172795693, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.5112194555382979e-05, 'l1_Layer_2': 0.0060277397929722, 'l1_Layer_3': 2.1954515206123512e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 50, 'n_units_Layer_3': 255}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.38 | sMAPE for Validation Set is: 21.48% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 9.47 | sMAPE for Test Set is: 25.09% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:15:13,928]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:15:23,185]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:15:34,267]\u001b[0m Trial 879 finished with value: 5.236716046137129 and parameters: {'n_hidden': 3, 'learning_rate': 0.000502602333978518, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38323100842897717, 'dropout_rate_Layer_2': 0.37230868596506433, 'dropout_rate_Layer_3': 0.23666552483737358, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.0057252306932377e-05, 'l1_Layer_2': 0.011925429130698542, 'l1_Layer_3': 2.177842137564176e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 85, 'n_units_Layer_3': 245}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.24 | sMAPE for Validation Set is: 21.08% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 8.85 | sMAPE for Test Set is: 23.47% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:15:42,921]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:16:00,280]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:16:06,883]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:17:09,541]\u001b[0m Trial 896 finished with value: 5.328281860915976 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007000337065494234, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35489532523318323, 'dropout_rate_Layer_2': 0.3713191806371576, 'dropout_rate_Layer_3': 0.2824890344832952, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 3.11036494025374e-05, 'l1_Layer_2': 0.0034880370931188913, 'l1_Layer_3': 1.1537445137206192e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 130, 'n_units_Layer_3': 190}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.33 | sMAPE for Validation Set is: 21.36% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 9.09 | sMAPE for Test Set is: 23.94% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:17:23,029]\u001b[0m Trial 894 finished with value: 5.37593755546881 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005580536050460691, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34093155758492666, 'dropout_rate_Layer_2': 0.198903554161812, 'dropout_rate_Layer_3': 0.24531913141253933, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011495031994779637, 'l1_Layer_2': 7.03375218082562e-05, 'l1_Layer_3': 0.0018952461045791892, 'n_units_Layer_1': 295, 'n_units_Layer_2': 170, 'n_units_Layer_3': 255}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.38 | sMAPE for Validation Set is: 21.72% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 12.71 | sMAPE for Test Set is: 32.76% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:17:28,346]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:17:33,950]\u001b[0m Trial 890 finished with value: 5.292523083729077 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006091927362894123, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2555286787242398, 'dropout_rate_Layer_2': 0.0007058622830804634, 'dropout_rate_Layer_3': 0.026547933658056452, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4467397411788642e-05, 'l1_Layer_2': 0.0004731184226283222, 'l1_Layer_3': 0.00016358199596873448, 'n_units_Layer_1': 135, 'n_units_Layer_2': 70, 'n_units_Layer_3': 80}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.29 | sMAPE for Validation Set is: 21.32% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 9.94 | sMAPE for Test Set is: 25.74% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:17:42,918]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:17:43,182]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:17:59,174]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:18:05,068]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:18:08,777]\u001b[0m Trial 898 finished with value: 5.372934923629924 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006534829244880607, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23203789881244677, 'dropout_rate_Layer_2': 0.021731911989143544, 'dropout_rate_Layer_3': 0.03900080041363495, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.839904900999166e-05, 'l1_Layer_2': 0.0003200534686818919, 'l1_Layer_3': 5.61807748939591e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 50, 'n_units_Layer_3': 70}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.37 | sMAPE for Validation Set is: 21.45% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 9.99 | sMAPE for Test Set is: 25.98% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:19:12,614]\u001b[0m Trial 904 finished with value: 5.38525986387195 and parameters: {'n_hidden': 3, 'learning_rate': 0.000666813629203935, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26592937007151657, 'dropout_rate_Layer_2': 0.007452168536165502, 'dropout_rate_Layer_3': 0.038807298034579274, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.216108446641306e-05, 'l1_Layer_2': 0.0005312620766067962, 'l1_Layer_3': 0.00016186151179833149, 'n_units_Layer_1': 130, 'n_units_Layer_2': 65, 'n_units_Layer_3': 60}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.39 | sMAPE for Validation Set is: 21.50% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.52 | sMAPE for Test Set is: 26.96% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:19:44,671]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:20:14,631]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:21:10,947]\u001b[0m Trial 906 finished with value: 5.51552610649188 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009319863707473012, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3833259520529925, 'dropout_rate_Layer_2': 0.3374920230063699, 'dropout_rate_Layer_3': 0.2731712820560561, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.0317534119965616e-05, 'l1_Layer_2': 0.017791266774421187, 'l1_Layer_3': 1.4896316744476689e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 110, 'n_units_Layer_3': 240}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.52 | sMAPE for Validation Set is: 22.16% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.87 | sMAPE for Test Set is: 28.14% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:21:14,209]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:21:19,560]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:21:27,908]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:21:33,996]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:21:39,978]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:22:02,274]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:22:11,160]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:22:28,215]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:22:36,639]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:23:31,491]\u001b[0m Trial 914 finished with value: 5.304785552366883 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005002761373972748, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26734193375450854, 'dropout_rate_Layer_2': 0.006910371919933174, 'dropout_rate_Layer_3': 0.03974649194498805, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1726180320791386e-05, 'l1_Layer_2': 0.0005971285709245567, 'l1_Layer_3': 0.0001666999033824676, 'n_units_Layer_1': 110, 'n_units_Layer_2': 65, 'n_units_Layer_3': 295}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.30 | sMAPE for Validation Set is: 21.33% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 9.52 | sMAPE for Test Set is: 24.65% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:23:40,296]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:23:51,803]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:23:55,473]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:24:01,047]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:24:07,621]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:24:26,612]\u001b[0m Trial 918 finished with value: 5.3061723852602976 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006537405133227024, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2644899237177514, 'dropout_rate_Layer_2': 0.007136315149807298, 'dropout_rate_Layer_3': 0.04082875375011802, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2519658705684031e-05, 'l1_Layer_2': 0.0005230614769853518, 'l1_Layer_3': 0.0001623109772995602, 'n_units_Layer_1': 110, 'n_units_Layer_2': 65, 'n_units_Layer_3': 75}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.31 | sMAPE for Validation Set is: 21.36% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.47 | sMAPE for Test Set is: 27.06% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:24:35,163]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:25:23,336]\u001b[0m Trial 923 finished with value: 5.462530862898801 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030066449635963487, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3177482340365955, 'dropout_rate_Layer_2': 0.07257837309279842, 'dropout_rate_Layer_3': 0.2400345326264487, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.486570710259067e-05, 'l1_Layer_2': 1.5478567509238255e-05, 'l1_Layer_3': 1.4091430751518304e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 220, 'n_units_Layer_3': 95}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.46 | sMAPE for Validation Set is: 21.74% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 12.26 | sMAPE for Test Set is: 31.46% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:26:11,953]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:26:15,788]\u001b[0m Trial 928 finished with value: 5.426333051202628 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006187555224473941, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22333050877438404, 'dropout_rate_Layer_2': 0.2631536141875713, 'dropout_rate_Layer_3': 0.21437420659309678, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.163820045092801e-05, 'l1_Layer_2': 0.001623048484959227, 'l1_Layer_3': 3.9689506129999333e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 80, 'n_units_Layer_3': 275}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.43 | sMAPE for Validation Set is: 21.68% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 9.56 | sMAPE for Test Set is: 24.80% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:26:39,669]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:26:45,259]\u001b[0m Trial 926 finished with value: 5.262871401907818 and parameters: {'n_hidden': 3, 'learning_rate': 0.000555828805264405, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27867565520117704, 'dropout_rate_Layer_2': 0.014832133850763799, 'dropout_rate_Layer_3': 0.028207822414256713, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4939617834560297e-05, 'l1_Layer_2': 0.0009231696498130179, 'l1_Layer_3': 0.00019948769820595983, 'n_units_Layer_1': 105, 'n_units_Layer_2': 65, 'n_units_Layer_3': 280}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.26 | sMAPE for Validation Set is: 21.02% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.17 | sMAPE for Test Set is: 26.18% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:27:05,304]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:27:05,745]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:27:34,208]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:27:35,602]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:27:37,506]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:28:20,818]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:28:40,064]\u001b[0m Trial 929 finished with value: 5.230636847216492 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005053331063364237, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27746246273936914, 'dropout_rate_Layer_2': 0.015402813928943737, 'dropout_rate_Layer_3': 0.02817264830247242, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.5588600705569777e-05, 'l1_Layer_2': 0.0008248761881838761, 'l1_Layer_3': 0.00021843205311241972, 'n_units_Layer_1': 105, 'n_units_Layer_2': 65, 'n_units_Layer_3': 85}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.23 | sMAPE for Validation Set is: 21.04% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 9.37 | sMAPE for Test Set is: 24.33% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:28:41,008]\u001b[0m Trial 937 finished with value: 5.427039500059806 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006989157649433012, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34273693991755844, 'dropout_rate_Layer_2': 0.3067512837999448, 'dropout_rate_Layer_3': 0.1892913339205851, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0001410175049347412, 'l1_Layer_2': 0.004955215511437074, 'l1_Layer_3': 0.00022897508890442443, 'n_units_Layer_1': 145, 'n_units_Layer_2': 95, 'n_units_Layer_3': 295}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.43 | sMAPE for Validation Set is: 21.44% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 12.11 | sMAPE for Test Set is: 31.25% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:29:01,737]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:29:31,615]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:29:41,040]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:30:08,175]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:30:44,223]\u001b[0m Trial 942 finished with value: 5.270895562537182 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005055920041971686, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2961132320899547, 'dropout_rate_Layer_2': 0.007481931937207826, 'dropout_rate_Layer_3': 0.04213533637173187, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.808766019669193e-05, 'l1_Layer_2': 0.0006083392676569942, 'l1_Layer_3': 0.00019145416422941655, 'n_units_Layer_1': 100, 'n_units_Layer_2': 60, 'n_units_Layer_3': 290}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.27 | sMAPE for Validation Set is: 21.38% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.18 | sMAPE for Test Set is: 26.19% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:31:01,865]\u001b[0m Trial 941 finished with value: 5.248500430316178 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005019714416807707, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26899133924475693, 'dropout_rate_Layer_2': 0.007660046060183327, 'dropout_rate_Layer_3': 0.031101660513628858, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.845418494381058e-05, 'l1_Layer_2': 0.0009251967382902241, 'l1_Layer_3': 0.0002025243171627076, 'n_units_Layer_1': 100, 'n_units_Layer_2': 60, 'n_units_Layer_3': 295}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.25 | sMAPE for Validation Set is: 21.13% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.14 | sMAPE for Test Set is: 26.15% | rMAE for Test Set is: 0.97\n",
      "MAE for Validation Set is: 5.27 | sMAPE for Validation Set is: 21.28% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 9.31 | sMAPE for Test Set is: 24.32% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:31:06,273]\u001b[0m Trial 938 finished with value: 5.273369983376614 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005516285445508585, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2694133214315477, 'dropout_rate_Layer_2': 0.012570865967251064, 'dropout_rate_Layer_3': 0.020459578181870906, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3588129826644263e-05, 'l1_Layer_2': 0.0006097771201278589, 'l1_Layer_3': 0.00020415496533415388, 'n_units_Layer_1': 100, 'n_units_Layer_2': 70, 'n_units_Layer_3': 295}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:31:08,817]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:31:13,793]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:31:43,483]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:32:14,362]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:32:45,751]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:32:49,334]\u001b[0m Trial 946 finished with value: 5.282803102343638 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005397812263937487, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30765865139128734, 'dropout_rate_Layer_2': 0.020283040941118314, 'dropout_rate_Layer_3': 0.031311752501364594, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.9596360020672135e-05, 'l1_Layer_2': 0.0009520657993881635, 'l1_Layer_3': 0.00020347406090979266, 'n_units_Layer_1': 95, 'n_units_Layer_2': 60, 'n_units_Layer_3': 285}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.28 | sMAPE for Validation Set is: 21.26% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.23 | sMAPE for Test Set is: 26.47% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:32:55,600]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:32:58,996]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:33:05,297]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:33:08,123]\u001b[0m Trial 945 finished with value: 5.300221108581656 and parameters: {'n_hidden': 3, 'learning_rate': 0.00059629268093555, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36806227842841077, 'dropout_rate_Layer_2': 0.373643311755737, 'dropout_rate_Layer_3': 0.262604778831985, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00030768065048709345, 'l1_Layer_2': 0.008534715272974298, 'l1_Layer_3': 7.634550868111253e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 80, 'n_units_Layer_3': 260}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.30 | sMAPE for Validation Set is: 21.64% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 8.95 | sMAPE for Test Set is: 23.52% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:33:20,523]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:34:25,234]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:34:25,735]\u001b[0m Trial 949 finished with value: 5.344820043066139 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005573445253647334, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24787520991571987, 'dropout_rate_Layer_2': 0.37154838144982694, 'dropout_rate_Layer_3': 0.3358403266711788, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0002707078051910717, 'l1_Layer_2': 0.011614254841512794, 'l1_Layer_3': 0.0006021364402940504, 'n_units_Layer_1': 250, 'n_units_Layer_2': 70, 'n_units_Layer_3': 285}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.34 | sMAPE for Validation Set is: 21.83% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 8.37 | sMAPE for Test Set is: 22.13% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:34:33,816]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:34:34,449]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:34:44,198]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:34:52,942]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:34:53,375]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:35:04,231]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:35:04,912]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:35:21,212]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:35:35,882]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:35:44,421]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:35:44,764]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:35:46,005]\u001b[0m Trial 956 finished with value: 5.244575525860076 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005116449208768547, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3145557131744827, 'dropout_rate_Layer_2': 0.016627069944822194, 'dropout_rate_Layer_3': 0.017007389309201308, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.415239105686795e-05, 'l1_Layer_2': 0.0009172514703263397, 'l1_Layer_3': 0.0002592497955451457, 'n_units_Layer_1': 85, 'n_units_Layer_2': 70, 'n_units_Layer_3': 290}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.24 | sMAPE for Validation Set is: 21.29% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 9.91 | sMAPE for Test Set is: 25.64% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:35:50,148]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:36:00,067]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:36:02,120]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:36:09,425]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:36:11,800]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:36:19,262]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:36:24,150]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:36:24,256]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:36:31,786]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:36:34,206]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:36:34,233]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:37:45,961]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:37:54,466]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:38:00,182]\u001b[0m Trial 969 finished with value: 5.263164481430141 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005146473187775949, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3085363685414828, 'dropout_rate_Layer_2': 0.015214601463187798, 'dropout_rate_Layer_3': 0.018848292870834043, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.589049377932767e-05, 'l1_Layer_2': 0.0011360502065980798, 'l1_Layer_3': 0.00022873669856360141, 'n_units_Layer_1': 90, 'n_units_Layer_2': 70, 'n_units_Layer_3': 290}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.26 | sMAPE for Validation Set is: 21.14% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 9.55 | sMAPE for Test Set is: 24.70% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:38:23,719]\u001b[0m Trial 984 finished with value: 5.252670163796631 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005020584614754758, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32300080257500186, 'dropout_rate_Layer_2': 0.00028869197231281955, 'dropout_rate_Layer_3': 0.020730359351978915, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.1021933824577486e-05, 'l1_Layer_2': 0.0008682540458897493, 'l1_Layer_3': 0.0003227883819577313, 'n_units_Layer_1': 95, 'n_units_Layer_2': 75, 'n_units_Layer_3': 285}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.25 | sMAPE for Validation Set is: 21.25% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.03 | sMAPE for Test Set is: 25.82% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:38:25,413]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:38:33,258]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:38:47,518]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:38:56,352]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:39:05,194]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:39:11,675]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:39:30,574]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:39:50,238]\u001b[0m Trial 982 finished with value: 5.292696502070069 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005094678237845721, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3179310052652264, 'dropout_rate_Layer_2': 0.0009002448462782729, 'dropout_rate_Layer_3': 0.018500953438469615, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.999830369075006e-05, 'l1_Layer_2': 0.0009795473612370404, 'l1_Layer_3': 0.00019964514266825124, 'n_units_Layer_1': 95, 'n_units_Layer_2': 75, 'n_units_Layer_3': 280}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.29 | sMAPE for Validation Set is: 21.51% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 9.27 | sMAPE for Test Set is: 24.08% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:40:05,953]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:40:16,490]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:41:00,122]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:41:10,392]\u001b[0m Trial 987 finished with value: 5.299938880975465 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029613152058259435, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31404849822453873, 'dropout_rate_Layer_2': 0.13654378338203357, 'dropout_rate_Layer_3': 0.23140254941790037, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011062503830475111, 'l1_Layer_2': 7.976592394235563e-05, 'l1_Layer_3': 1.8216678168508536e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 215, 'n_units_Layer_3': 130}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.30 | sMAPE for Validation Set is: 21.08% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 11.11 | sMAPE for Test Set is: 28.43% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:41:39,408]\u001b[0m Trial 998 finished with value: 5.4675744218799665 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034676220986702574, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3331873302221462, 'dropout_rate_Layer_2': 0.08334463726858705, 'dropout_rate_Layer_3': 0.20842235593871167, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015510544172894953, 'l1_Layer_2': 2.081768478425763e-05, 'l1_Layer_3': 1.9498167624227567e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 230, 'n_units_Layer_3': 105}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.47 | sMAPE for Validation Set is: 21.42% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 14.11 | sMAPE for Test Set is: 36.36% | rMAE for Test Set is: 1.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:42:21,328]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:42:58,214]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:43:06,120]\u001b[0m Trial 995 finished with value: 5.295935408398647 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007030047678017019, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31741548367211203, 'dropout_rate_Layer_2': 0.370928218779635, 'dropout_rate_Layer_3': 0.2308454246541966, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00035821135587502237, 'l1_Layer_2': 0.007993246817225115, 'l1_Layer_3': 3.6816183317479084e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 55, 'n_units_Layer_3': 270}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.30 | sMAPE for Validation Set is: 21.61% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.89 | sMAPE for Test Set is: 28.32% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:43:11,158]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:43:28,007]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:43:33,503]\u001b[0m Trial 1000 finished with value: 5.268503196711273 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005517137718594394, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.308206324704204, 'dropout_rate_Layer_2': 0.012366114567803496, 'dropout_rate_Layer_3': 0.017502001364035638, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.0429306110462844e-05, 'l1_Layer_2': 0.0013197640916320472, 'l1_Layer_3': 0.00023701916448660285, 'n_units_Layer_1': 80, 'n_units_Layer_2': 75, 'n_units_Layer_3': 300}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.27 | sMAPE for Validation Set is: 21.23% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.10 | sMAPE for Test Set is: 26.13% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:43:46,553]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:43:47,506]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:43:57,867]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:44:00,918]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:44:08,273]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:44:23,755]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:44:28,451]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:44:40,755]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:44:54,285]\u001b[0m Trial 1007 finished with value: 5.45796692633984 and parameters: {'n_hidden': 3, 'learning_rate': 0.003524826421781483, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29615948223861954, 'dropout_rate_Layer_2': 0.069970144495011, 'dropout_rate_Layer_3': 0.23285162751367916, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013538453901047474, 'l1_Layer_2': 8.248539104453418e-05, 'l1_Layer_3': 2.4055678986891013e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 210, 'n_units_Layer_3': 125}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.46 | sMAPE for Validation Set is: 21.32% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 13.23 | sMAPE for Test Set is: 33.80% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:45:03,736]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:45:14,498]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:45:16,523]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:45:22,944]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:45:25,651]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:45:35,915]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:45:46,301]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:45:55,573]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:45:56,175]\u001b[0m Trial 1014 finished with value: 5.472995240595087 and parameters: {'n_hidden': 3, 'learning_rate': 0.003914326184560385, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35113925450010575, 'dropout_rate_Layer_2': 0.06404936908285919, 'dropout_rate_Layer_3': 0.23807285818926355, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00021934355579772787, 'l1_Layer_2': 5.960898171743067e-05, 'l1_Layer_3': 2.674094530094673e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 140, 'n_units_Layer_3': 145}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.47 | sMAPE for Validation Set is: 21.32% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 13.65 | sMAPE for Test Set is: 35.22% | rMAE for Test Set is: 1.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:46:11,763]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:46:21,073]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:47:10,530]\u001b[0m Trial 1025 finished with value: 5.415077526401002 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007014943191947666, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3396281659940495, 'dropout_rate_Layer_2': 0.22052754816798403, 'dropout_rate_Layer_3': 0.2551131938121758, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.554562376195804e-05, 'l1_Layer_2': 9.590300933967458e-05, 'l1_Layer_3': 0.00264631473842367, 'n_units_Layer_1': 275, 'n_units_Layer_2': 160, 'n_units_Layer_3': 285}. Best is trial 575 with value: 5.2244477688150015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.42 | sMAPE for Validation Set is: 21.88% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.46 | sMAPE for Test Set is: 29.57% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:47:20,555]\u001b[0m Trial 1002 finished with value: 5.160942939116413 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006823635798705893, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3170513027909092, 'dropout_rate_Layer_2': 0.3729712492005765, 'dropout_rate_Layer_3': 0.22188463715025766, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0003497190149739773, 'l1_Layer_2': 0.0082047590697561, 'l1_Layer_3': 0.0004183834740410995, 'n_units_Layer_1': 210, 'n_units_Layer_2': 55, 'n_units_Layer_3': 270}. Best is trial 1002 with value: 5.160942939116413.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.16 | sMAPE for Validation Set is: 21.12% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 9.69 | sMAPE for Test Set is: 25.15% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:47:25,686]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:47:31,622]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:47:36,874]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:47:50,761]\u001b[0m Trial 1020 finished with value: 5.2920476034421355 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005668721577473915, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31066784130586106, 'dropout_rate_Layer_2': 0.00032899316590288553, 'dropout_rate_Layer_3': 0.024652033687579646, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.236416879809115e-05, 'l1_Layer_2': 0.0008736344305400154, 'l1_Layer_3': 0.00020588264698919752, 'n_units_Layer_1': 85, 'n_units_Layer_2': 75, 'n_units_Layer_3': 275}. Best is trial 1002 with value: 5.160942939116413.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.29 | sMAPE for Validation Set is: 21.23% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 9.65 | sMAPE for Test Set is: 25.01% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:47:57,995]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:48:07,383]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:48:18,096]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:48:32,894]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:48:41,485]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:48:45,317]\u001b[0m Trial 1027 finished with value: 5.290028102916269 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006503056859917689, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3523623045035223, 'dropout_rate_Layer_2': 0.34832942382978455, 'dropout_rate_Layer_3': 0.22617183026523088, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00038792501729557666, 'l1_Layer_2': 0.008378293819593907, 'l1_Layer_3': 5.352449627329341e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 55, 'n_units_Layer_3': 250}. Best is trial 1002 with value: 5.160942939116413.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.29 | sMAPE for Validation Set is: 21.60% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 9.69 | sMAPE for Test Set is: 25.23% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:49:00,106]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:49:03,468]\u001b[0m Trial 1033 finished with value: 5.4902107447709065 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008272966873466959, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3698460244565205, 'dropout_rate_Layer_2': 0.20753315546499418, 'dropout_rate_Layer_3': 0.1916097449582002, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.5487596809458556e-05, 'l1_Layer_2': 6.37336934992566e-05, 'l1_Layer_3': 0.001286252518849068, 'n_units_Layer_1': 185, 'n_units_Layer_2': 160, 'n_units_Layer_3': 110}. Best is trial 1002 with value: 5.160942939116413.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.49 | sMAPE for Validation Set is: 22.26% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 12.51 | sMAPE for Test Set is: 32.59% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:50:40,190]\u001b[0m Trial 1039 finished with value: 5.363004837031693 and parameters: {'n_hidden': 3, 'learning_rate': 0.002629846442704649, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32838250354841025, 'dropout_rate_Layer_2': 0.08592942804447845, 'dropout_rate_Layer_3': 0.1998794094906875, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001892965247690033, 'l1_Layer_2': 0.00011899512486715887, 'l1_Layer_3': 1.2178125581282567e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 220, 'n_units_Layer_3': 135}. Best is trial 1002 with value: 5.160942939116413.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.36 | sMAPE for Validation Set is: 21.33% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 12.34 | sMAPE for Test Set is: 31.55% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:51:06,851]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:51:38,004]\u001b[0m Trial 1041 finished with value: 5.245436097684784 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005568059265863977, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30113420124920226, 'dropout_rate_Layer_2': 0.008465343592369147, 'dropout_rate_Layer_3': 0.019198517201530527, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.37898689912229e-05, 'l1_Layer_2': 0.0011921991004551094, 'l1_Layer_3': 0.0001910146608944154, 'n_units_Layer_1': 85, 'n_units_Layer_2': 75, 'n_units_Layer_3': 290}. Best is trial 1002 with value: 5.160942939116413.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.25 | sMAPE for Validation Set is: 21.20% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 9.53 | sMAPE for Test Set is: 24.64% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:51:43,458]\u001b[0m Trial 1040 finished with value: 5.2586612913463435 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005002653619203085, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3065687540450297, 'dropout_rate_Layer_2': 0.0014994773393863618, 'dropout_rate_Layer_3': 0.0009222536445538214, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.727649694775066e-05, 'l1_Layer_2': 0.0009808130145547737, 'l1_Layer_3': 0.00019733688073010887, 'n_units_Layer_1': 85, 'n_units_Layer_2': 80, 'n_units_Layer_3': 290}. Best is trial 1002 with value: 5.160942939116413.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.26 | sMAPE for Validation Set is: 21.19% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 9.61 | sMAPE for Test Set is: 24.87% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:51:46,672]\u001b[0m Trial 1038 finished with value: 5.252744792677269 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005544739648153782, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29999081650766507, 'dropout_rate_Layer_2': 0.0030062234787194275, 'dropout_rate_Layer_3': 0.01581620401391613, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.107106991452582e-05, 'l1_Layer_2': 0.001239256777865144, 'l1_Layer_3': 0.00021445058865501832, 'n_units_Layer_1': 85, 'n_units_Layer_2': 80, 'n_units_Layer_3': 285}. Best is trial 1002 with value: 5.160942939116413.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.25 | sMAPE for Validation Set is: 21.08% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.30 | sMAPE for Test Set is: 26.53% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:51:55,941]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:52:07,520]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:52:15,557]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:52:20,440]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:52:23,117]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:52:28,132]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:52:44,784]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:52:50,535]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:53:15,935]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:53:36,039]\u001b[0m Trial 1045 finished with value: 5.212907319313586 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005540099362285693, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30335497400196515, 'dropout_rate_Layer_2': 0.0017045747753410417, 'dropout_rate_Layer_3': 0.016460743925333976, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.072704968048789e-05, 'l1_Layer_2': 0.0012354552550497863, 'l1_Layer_3': 0.00019463143081469171, 'n_units_Layer_1': 80, 'n_units_Layer_2': 80, 'n_units_Layer_3': 290}. Best is trial 1002 with value: 5.160942939116413.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.21 | sMAPE for Validation Set is: 21.13% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 9.45 | sMAPE for Test Set is: 24.59% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:55:06,499]\u001b[0m Trial 1052 finished with value: 5.2980961648512155 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006714429166504364, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31712585431955315, 'dropout_rate_Layer_2': 0.374644838082679, 'dropout_rate_Layer_3': 0.20280854554924987, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0003694287966442375, 'l1_Layer_2': 1.0269228366841023e-05, 'l1_Layer_3': 0.00010923630651836536, 'n_units_Layer_1': 105, 'n_units_Layer_2': 55, 'n_units_Layer_3': 270}. Best is trial 1002 with value: 5.160942939116413.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.30 | sMAPE for Validation Set is: 21.65% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 9.60 | sMAPE for Test Set is: 25.13% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:55:34,439]\u001b[0m Trial 1054 finished with value: 5.27864222833474 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005752851587837878, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29568827526487235, 'dropout_rate_Layer_2': 0.003226395190759043, 'dropout_rate_Layer_3': 0.001449012875440487, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.419658186167626e-05, 'l1_Layer_2': 0.0009958762905719566, 'l1_Layer_3': 0.00026821045969108853, 'n_units_Layer_1': 80, 'n_units_Layer_2': 80, 'n_units_Layer_3': 300}. Best is trial 1002 with value: 5.160942939116413.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.28 | sMAPE for Validation Set is: 21.24% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 9.66 | sMAPE for Test Set is: 24.94% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:55:35,034]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:55:36,834]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:55:47,808]\u001b[0m Trial 1056 finished with value: 5.359362736372087 and parameters: {'n_hidden': 3, 'learning_rate': 0.003488705306821512, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3282002369770983, 'dropout_rate_Layer_2': 0.053944288754061466, 'dropout_rate_Layer_3': 0.1978695408317596, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001816797045781793, 'l1_Layer_2': 7.382145255945253e-05, 'l1_Layer_3': 1.849664871923231e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 110, 'n_units_Layer_3': 130}. Best is trial 1002 with value: 5.160942939116413.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.36 | sMAPE for Validation Set is: 21.65% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 13.26 | sMAPE for Test Set is: 34.37% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:55:52,609]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:56:05,779]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:56:17,560]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:56:31,604]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:56:44,534]\u001b[0m Trial 1060 finished with value: 5.330969222085673 and parameters: {'n_hidden': 3, 'learning_rate': 0.001156216433084723, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3128080297750317, 'dropout_rate_Layer_2': 0.22773143926261755, 'dropout_rate_Layer_3': 0.2364021827600677, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001849321945359087, 'l1_Layer_2': 4.0915965336378166e-05, 'l1_Layer_3': 0.000949918620304338, 'n_units_Layer_1': 130, 'n_units_Layer_2': 175, 'n_units_Layer_3': 265}. Best is trial 1002 with value: 5.160942939116413.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.33 | sMAPE for Validation Set is: 21.42% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 13.64 | sMAPE for Test Set is: 35.66% | rMAE for Test Set is: 1.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:57:32,743]\u001b[0m Trial 1058 finished with value: 5.170413646347149 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005620912693174378, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.300618915601535, 'dropout_rate_Layer_2': 0.0013095552188763723, 'dropout_rate_Layer_3': 0.009563203107697812, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.395832497430865e-05, 'l1_Layer_2': 0.001426483231088365, 'l1_Layer_3': 0.0003242742465670996, 'n_units_Layer_1': 85, 'n_units_Layer_2': 85, 'n_units_Layer_3': 300}. Best is trial 1002 with value: 5.160942939116413.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.17 | sMAPE for Validation Set is: 21.11% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 9.46 | sMAPE for Test Set is: 24.74% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:57:51,014]\u001b[0m Trial 1066 finished with value: 5.490539200954154 and parameters: {'n_hidden': 3, 'learning_rate': 0.004522412826493086, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33841247070735686, 'dropout_rate_Layer_2': 0.05565975970856348, 'dropout_rate_Layer_3': 0.19181199097983323, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017484205319160913, 'l1_Layer_2': 1.0184877379973083e-05, 'l1_Layer_3': 1.5683943991990657e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 220, 'n_units_Layer_3': 125}. Best is trial 1002 with value: 5.160942939116413.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.49 | sMAPE for Validation Set is: 21.58% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 12.20 | sMAPE for Test Set is: 31.10% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:58:11,867]\u001b[0m Trial 1064 finished with value: 5.228064591791238 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006303379866942077, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3412798809759322, 'dropout_rate_Layer_2': 0.37442210988804014, 'dropout_rate_Layer_3': 0.20047292371145775, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0005143839430094215, 'l1_Layer_2': 2.4322109827798743e-05, 'l1_Layer_3': 0.00035602374777411614, 'n_units_Layer_1': 110, 'n_units_Layer_2': 60, 'n_units_Layer_3': 250}. Best is trial 1002 with value: 5.160942939116413.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.23 | sMAPE for Validation Set is: 21.33% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 9.52 | sMAPE for Test Set is: 24.96% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:58:25,310]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:58:30,044]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:58:33,160]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:58:40,525]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:58:50,721]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:58:56,694]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:59:04,984]\u001b[0m Trial 1065 finished with value: 5.212839673927655 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006450671874951817, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34301802866073705, 'dropout_rate_Layer_2': 0.37331202460170826, 'dropout_rate_Layer_3': 0.20095816585734766, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004516953749776304, 'l1_Layer_2': 0.008807361005486946, 'l1_Layer_3': 0.00037226228665049777, 'n_units_Layer_1': 105, 'n_units_Layer_2': 60, 'n_units_Layer_3': 250}. Best is trial 1002 with value: 5.160942939116413.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.21 | sMAPE for Validation Set is: 21.10% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.97 | sMAPE for Test Set is: 19.24% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 18:59:09,392]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:59:13,996]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:59:19,761]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:59:25,494]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:59:29,884]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:59:36,381]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:59:45,835]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:59:45,940]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:59:49,505]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 18:59:52,556]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:00:02,004]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:00:07,511]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:00:07,906]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:00:15,935]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:00:19,453]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:00:23,667]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:00:26,485]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:00:52,190]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:01:05,542]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:01:05,707]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:01:36,856]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:02:02,996]\u001b[0m Trial 1089 finished with value: 5.306260048842797 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010577317940266516, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32221013196203907, 'dropout_rate_Layer_2': 0.2244781752162569, 'dropout_rate_Layer_3': 0.16146543401061667, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001498987778075382, 'l1_Layer_2': 2.8128159368580923e-05, 'l1_Layer_3': 0.0017164240903861443, 'n_units_Layer_1': 125, 'n_units_Layer_2': 180, 'n_units_Layer_3': 275}. Best is trial 1002 with value: 5.160942939116413.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.31 | sMAPE for Validation Set is: 21.42% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 12.84 | sMAPE for Test Set is: 33.26% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:02:16,875]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:02:21,183]\u001b[0m Trial 1093 finished with value: 5.1245860908337955 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005404969458903582, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29357804069575333, 'dropout_rate_Layer_2': 0.007442345739017803, 'dropout_rate_Layer_3': 0.016948981170761927, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.579327460343206e-05, 'l1_Layer_2': 0.0014699885279279557, 'l1_Layer_3': 0.0001906915451085695, 'n_units_Layer_1': 95, 'n_units_Layer_2': 75, 'n_units_Layer_3': 285}. Best is trial 1093 with value: 5.1245860908337955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.12 | sMAPE for Validation Set is: 20.62% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 8.38 | sMAPE for Test Set is: 22.03% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:02:22,987]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:02:48,377]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:03:00,856]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:03:25,535]\u001b[0m Trial 1100 finished with value: 5.359209820474853 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011131985017119451, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27804279985983127, 'dropout_rate_Layer_2': 0.22510185655621848, 'dropout_rate_Layer_3': 0.21983550706346766, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.875083774468888e-05, 'l1_Layer_2': 2.687860727252137e-05, 'l1_Layer_3': 0.0009951762765802329, 'n_units_Layer_1': 125, 'n_units_Layer_2': 200, 'n_units_Layer_3': 290}. Best is trial 1093 with value: 5.1245860908337955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.36 | sMAPE for Validation Set is: 21.62% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 12.83 | sMAPE for Test Set is: 33.31% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:03:28,395]\u001b[0m Trial 1101 finished with value: 5.323209740755181 and parameters: {'n_hidden': 3, 'learning_rate': 0.001008924348123389, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3280276813687815, 'dropout_rate_Layer_2': 0.22306246603551277, 'dropout_rate_Layer_3': 0.1642324164656732, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00024169374894657657, 'l1_Layer_2': 3.0019741342655577e-05, 'l1_Layer_3': 0.001029137822493533, 'n_units_Layer_1': 125, 'n_units_Layer_2': 200, 'n_units_Layer_3': 290}. Best is trial 1093 with value: 5.1245860908337955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.32 | sMAPE for Validation Set is: 21.50% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 13.63 | sMAPE for Test Set is: 35.25% | rMAE for Test Set is: 1.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:03:35,591]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:03:38,202]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:03:42,849]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:03:49,623]\u001b[0m Trial 1099 finished with value: 5.190799060440077 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005050975212283789, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2969104194349884, 'dropout_rate_Layer_2': 0.008226799584716046, 'dropout_rate_Layer_3': 0.020086650359060886, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.7193132992713766e-05, 'l1_Layer_2': 0.0016447526344470931, 'l1_Layer_3': 0.000195012811549792, 'n_units_Layer_1': 95, 'n_units_Layer_2': 75, 'n_units_Layer_3': 275}. Best is trial 1093 with value: 5.1245860908337955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.19 | sMAPE for Validation Set is: 20.92% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 8.59 | sMAPE for Test Set is: 22.32% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:03:58,784]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:04:50,599]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:04:59,441]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:05:02,718]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:05:05,381]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:05:07,760]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:05:10,849]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:05:20,266]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:05:42,157]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:06:23,673]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:06:54,650]\u001b[0m Trial 1118 finished with value: 5.40751397929822 and parameters: {'n_hidden': 3, 'learning_rate': 0.002636597820735576, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32716051385379613, 'dropout_rate_Layer_2': 0.09255222163616848, 'dropout_rate_Layer_3': 0.08768438744862761, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00035848512046608456, 'l1_Layer_2': 2.2625174761509762e-05, 'l1_Layer_3': 2.7994909291608568e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 230, 'n_units_Layer_3': 110}. Best is trial 1093 with value: 5.1245860908337955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.41 | sMAPE for Validation Set is: 21.05% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 13.95 | sMAPE for Test Set is: 35.76% | rMAE for Test Set is: 1.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:06:59,084]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:07:04,456]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:07:07,677]\u001b[0m Trial 1114 finished with value: 5.105069178163284 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005009356188633394, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29302391490977797, 'dropout_rate_Layer_2': 0.000407245969356684, 'dropout_rate_Layer_3': 0.027567860417973364, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.026486585435429e-05, 'l1_Layer_2': 0.0013485209061237543, 'l1_Layer_3': 0.00019525651130785152, 'n_units_Layer_1': 90, 'n_units_Layer_2': 90, 'n_units_Layer_3': 285}. Best is trial 1114 with value: 5.105069178163284.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.11 | sMAPE for Validation Set is: 20.60% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 8.30 | sMAPE for Test Set is: 21.76% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:07:15,448]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:07:18,452]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:07:24,425]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:07:48,622]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:07:55,121]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:08:10,363]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:08:10,401]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:08:19,175]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:08:38,669]\u001b[0m Trial 1126 finished with value: 5.392646402415839 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025622569097168875, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3279370744791431, 'dropout_rate_Layer_2': 0.06238077087654924, 'dropout_rate_Layer_3': 0.09204099500014389, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00027479421542111224, 'l1_Layer_2': 2.4617057401860373e-05, 'l1_Layer_3': 2.1895089146735048e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 215, 'n_units_Layer_3': 120}. Best is trial 1114 with value: 5.105069178163284.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.39 | sMAPE for Validation Set is: 21.23% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 13.34 | sMAPE for Test Set is: 34.07% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:08:48,052]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:10:08,083]\u001b[0m Trial 1131 finished with value: 5.133760299375091 and parameters: {'n_hidden': 3, 'learning_rate': 0.000547588059312747, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3084375384061479, 'dropout_rate_Layer_2': 0.007328171268101224, 'dropout_rate_Layer_3': 0.020990345246114782, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.152476381952508e-05, 'l1_Layer_2': 0.0017344239854121173, 'l1_Layer_3': 0.00019056788765912502, 'n_units_Layer_1': 95, 'n_units_Layer_2': 85, 'n_units_Layer_3': 280}. Best is trial 1114 with value: 5.105069178163284.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.13 | sMAPE for Validation Set is: 20.78% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 8.51 | sMAPE for Test Set is: 22.22% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:10:19,016]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:10:28,832]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:10:36,652]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:10:39,365]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:10:51,294]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:11:05,250]\u001b[0m Trial 1130 finished with value: 5.0884375323135895 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005543250420744777, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3102000778405824, 'dropout_rate_Layer_2': 0.007686634048405607, 'dropout_rate_Layer_3': 0.02008080489312628, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.0856648022475255e-05, 'l1_Layer_2': 0.0018495317045562395, 'l1_Layer_3': 0.00019143015241064202, 'n_units_Layer_1': 95, 'n_units_Layer_2': 85, 'n_units_Layer_3': 280}. Best is trial 1130 with value: 5.0884375323135895.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.09 | sMAPE for Validation Set is: 20.64% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 8.44 | sMAPE for Test Set is: 22.17% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:11:18,111]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:11:20,589]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:11:26,253]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:11:52,662]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:11:53,366]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:12:11,494]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:12:21,461]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:12:25,275]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:12:28,202]\u001b[0m Trial 1141 finished with value: 5.488779014935875 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012297985548653321, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38990372488791974, 'dropout_rate_Layer_2': 0.2153882879341769, 'dropout_rate_Layer_3': 0.18027005743615324, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.489625877813432e-05, 'l1_Layer_2': 2.5653918843542956e-05, 'l1_Layer_3': 0.00040374447878600855, 'n_units_Layer_1': 110, 'n_units_Layer_2': 215, 'n_units_Layer_3': 290}. Best is trial 1130 with value: 5.0884375323135895.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.49 | sMAPE for Validation Set is: 21.81% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 12.18 | sMAPE for Test Set is: 31.27% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:12:33,332]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:12:35,797]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:12:39,566]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:12:44,549]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:12:52,154]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:13:31,671]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:13:38,364]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:13:56,824]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:14:04,630]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:14:14,010]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:14:41,397]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:14:56,273]\u001b[0m Trial 1156 finished with value: 5.399625080302219 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027166603201632627, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3309415471073359, 'dropout_rate_Layer_2': 0.08880376595476065, 'dropout_rate_Layer_3': 0.06805151742001317, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002023323492303231, 'l1_Layer_2': 2.5472094240767967e-05, 'l1_Layer_3': 1.9595896918503523e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 215, 'n_units_Layer_3': 115}. Best is trial 1130 with value: 5.0884375323135895.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.40 | sMAPE for Validation Set is: 21.20% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 13.32 | sMAPE for Test Set is: 34.11% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:15:05,405]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:15:30,871]\u001b[0m Trial 1146 finished with value: 5.245563483761011 and parameters: {'n_hidden': 3, 'learning_rate': 0.00246750353847601, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3139220808013149, 'dropout_rate_Layer_2': 0.09685151894037576, 'dropout_rate_Layer_3': 0.08698801880578781, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00041754966601785905, 'l1_Layer_2': 2.3311777367240045e-05, 'l1_Layer_3': 2.7423441508228182e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 220, 'n_units_Layer_3': 105}. Best is trial 1130 with value: 5.0884375323135895.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.25 | sMAPE for Validation Set is: 21.05% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 12.52 | sMAPE for Test Set is: 32.32% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:15:36,844]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:15:42,238]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:15:52,457]\u001b[0m Trial 1162 finished with value: 5.334383951131831 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009735015331282299, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2902238762038562, 'dropout_rate_Layer_2': 0.32189481976986006, 'dropout_rate_Layer_3': 0.16016332166923813, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.920400105749412e-05, 'l1_Layer_2': 3.750641111705248e-05, 'l1_Layer_3': 0.0010325032201020132, 'n_units_Layer_1': 160, 'n_units_Layer_2': 200, 'n_units_Layer_3': 280}. Best is trial 1130 with value: 5.0884375323135895.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.33 | sMAPE for Validation Set is: 21.31% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 12.59 | sMAPE for Test Set is: 32.40% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:16:06,889]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:16:12,575]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:16:16,952]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:16:20,550]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:16:27,240]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:16:45,395]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:16:46,211]\u001b[0m Trial 1160 finished with value: 5.35656128550153 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019496819150182515, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3249000048572457, 'dropout_rate_Layer_2': 0.060259683506399875, 'dropout_rate_Layer_3': 0.010195957898663982, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002292668897004213, 'l1_Layer_2': 1.586392825671577e-05, 'l1_Layer_3': 1.8648591139673017e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 230, 'n_units_Layer_3': 125}. Best is trial 1130 with value: 5.0884375323135895.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.36 | sMAPE for Validation Set is: 21.34% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 12.19 | sMAPE for Test Set is: 31.32% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:16:54,489]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:17:00,280]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:17:05,422]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:17:27,484]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:17:27,491]\u001b[0m Trial 1157 finished with value: 5.323858236943544 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006874418851579151, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31599793321685565, 'dropout_rate_Layer_2': 0.3911764098328435, 'dropout_rate_Layer_3': 0.18336131883097065, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0003288929662589328, 'l1_Layer_2': 0.010652203362677047, 'l1_Layer_3': 0.00041249693403309527, 'n_units_Layer_1': 130, 'n_units_Layer_2': 65, 'n_units_Layer_3': 265}. Best is trial 1130 with value: 5.0884375323135895.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.32 | sMAPE for Validation Set is: 21.55% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 11.14 | sMAPE for Test Set is: 28.83% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:17:35,921]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:17:43,109]\u001b[0m Trial 1172 finished with value: 5.183524444580038 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006083292155863477, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29883124992497756, 'dropout_rate_Layer_2': 0.007719069472639303, 'dropout_rate_Layer_3': 0.005574620846723374, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.727891010923293e-05, 'l1_Layer_2': 0.0009996958984135615, 'l1_Layer_3': 0.00018827763626481177, 'n_units_Layer_1': 100, 'n_units_Layer_2': 75, 'n_units_Layer_3': 270}. Best is trial 1130 with value: 5.0884375323135895.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:17:43,145]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.18 | sMAPE for Validation Set is: 20.95% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 9.46 | sMAPE for Test Set is: 24.49% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:17:44,001]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:17:55,237]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:17:59,632]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:18:05,955]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:18:11,993]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:18:16,848]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:18:33,026]\u001b[0m Trial 1181 finished with value: 5.363273639489499 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009053458428688867, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29771193722459594, 'dropout_rate_Layer_2': 0.34276829785203483, 'dropout_rate_Layer_3': 0.17200231975137875, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.840604058014576e-05, 'l1_Layer_2': 3.948377435013253e-05, 'l1_Layer_3': 0.0015166312355316762, 'n_units_Layer_1': 150, 'n_units_Layer_2': 190, 'n_units_Layer_3': 275}. Best is trial 1130 with value: 5.0884375323135895.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.36 | sMAPE for Validation Set is: 21.57% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 12.85 | sMAPE for Test Set is: 33.14% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:18:49,623]\u001b[0m Trial 1186 finished with value: 5.476526727564565 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011522640219024708, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2796836742010968, 'dropout_rate_Layer_2': 0.3295882635117218, 'dropout_rate_Layer_3': 0.12467622031625482, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.9670583205155314e-05, 'l1_Layer_2': 3.859404872751735e-05, 'l1_Layer_3': 0.0009996852681317685, 'n_units_Layer_1': 140, 'n_units_Layer_2': 185, 'n_units_Layer_3': 300}. Best is trial 1130 with value: 5.0884375323135895.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.48 | sMAPE for Validation Set is: 21.80% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 12.17 | sMAPE for Test Set is: 31.33% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:18:58,992]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:19:02,586]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:19:07,477]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:19:10,253]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:19:18,091]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:19:20,653]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:19:24,122]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:19:32,819]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:19:33,743]\u001b[0m Trial 1187 finished with value: 5.346914504331362 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005568809085851076, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32966917574308774, 'dropout_rate_Layer_2': 0.3999156387662547, 'dropout_rate_Layer_3': 0.16575322617373695, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00042393815174717576, 'l1_Layer_2': 2.758233143407715e-05, 'l1_Layer_3': 0.0001038411070642697, 'n_units_Layer_1': 120, 'n_units_Layer_2': 70, 'n_units_Layer_3': 160}. Best is trial 1130 with value: 5.0884375323135895.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.35 | sMAPE for Validation Set is: 21.54% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 11.79 | sMAPE for Test Set is: 30.32% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:19:40,832]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:19:43,247]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:19:48,192]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:19:50,155]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:19:51,957]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:19:54,562]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:19:56,782]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:19:59,495]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:20:13,285]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:20:17,006]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:20:22,676]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:20:31,213]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:21:14,247]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:21:42,277]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:21:42,442]\u001b[0m Trial 1203 finished with value: 5.065547900666176 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006152106817638221, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2815927042613164, 'dropout_rate_Layer_2': 0.014515043260736212, 'dropout_rate_Layer_3': 0.03291666513430304, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.802698793573475e-05, 'l1_Layer_2': 0.0011540805311089166, 'l1_Layer_3': 0.00018548814560921494, 'n_units_Layer_1': 105, 'n_units_Layer_2': 80, 'n_units_Layer_3': 300}. Best is trial 1203 with value: 5.065547900666176.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.07 | sMAPE for Validation Set is: 20.35% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 7.97 | sMAPE for Test Set is: 21.03% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:22:03,560]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:22:15,664]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:22:17,391]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:22:26,264]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:22:29,444]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:22:39,267]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:22:41,178]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:22:54,029]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:22:58,883]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:22:59,269]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:23:03,715]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:23:10,682]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:23:49,270]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:23:59,514]\u001b[0m Trial 1222 finished with value: 5.278235656631005 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009882127420985192, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2711690438169132, 'dropout_rate_Layer_2': 0.21494832459227065, 'dropout_rate_Layer_3': 0.1363531450741316, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012614622540635013, 'l1_Layer_2': 4.679919247349353e-05, 'l1_Layer_3': 0.0011456066217990907, 'n_units_Layer_1': 165, 'n_units_Layer_2': 170, 'n_units_Layer_3': 295}. Best is trial 1203 with value: 5.065547900666176.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.28 | sMAPE for Validation Set is: 21.12% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 12.42 | sMAPE for Test Set is: 32.00% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:24:16,056]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:24:21,328]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:24:28,193]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:24:37,135]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:24:41,866]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:24:48,546]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:24:54,380]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:24:58,917]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:25:35,942]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:25:39,529]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:25:46,059]\u001b[0m Trial 1227 finished with value: 5.117350232823157 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005532019612881714, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2961694516992925, 'dropout_rate_Layer_2': 0.02244753210060598, 'dropout_rate_Layer_3': 0.015092702190624844, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.477009930264905e-05, 'l1_Layer_2': 0.0008841126123227636, 'l1_Layer_3': 0.00026901747370628, 'n_units_Layer_1': 100, 'n_units_Layer_2': 90, 'n_units_Layer_3': 290}. Best is trial 1203 with value: 5.065547900666176.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.12 | sMAPE for Validation Set is: 20.60% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 8.54 | sMAPE for Test Set is: 22.32% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:26:17,092]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:26:22,524]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:26:28,168]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:26:32,968]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:26:46,408]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:26:56,466]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:27:01,420]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:27:15,474]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:27:21,786]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:27:32,567]\u001b[0m Trial 1239 finished with value: 5.317671260869398 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009400889920502773, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2653266478775762, 'dropout_rate_Layer_2': 0.25540550008674584, 'dropout_rate_Layer_3': 0.14286632540394037, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.93269118719006e-05, 'l1_Layer_2': 4.647136718078039e-05, 'l1_Layer_3': 0.0006938548909161679, 'n_units_Layer_1': 170, 'n_units_Layer_2': 170, 'n_units_Layer_3': 295}. Best is trial 1203 with value: 5.065547900666176.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.32 | sMAPE for Validation Set is: 21.61% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 11.95 | sMAPE for Test Set is: 30.90% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:27:36,646]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:27:51,216]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:28:01,936]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:28:05,491]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:28:11,442]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:28:11,562]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:28:22,310]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:28:40,048]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:28:46,301]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:28:46,441]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:28:54,327]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:29:03,411]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:29:06,627]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:29:10,291]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:29:14,781]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:29:20,733]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:29:21,123]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:29:24,039]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:29:26,532]\u001b[0m Trial 1254 finished with value: 5.252177595607313 and parameters: {'n_hidden': 3, 'learning_rate': 0.001108004127713647, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2628030469291531, 'dropout_rate_Layer_2': 0.25607502943462224, 'dropout_rate_Layer_3': 0.13583154619557797, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013330782534969757, 'l1_Layer_2': 4.541523254201506e-05, 'l1_Layer_3': 0.00068278043452687, 'n_units_Layer_1': 170, 'n_units_Layer_2': 190, 'n_units_Layer_3': 180}. Best is trial 1203 with value: 5.065547900666176.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.25 | sMAPE for Validation Set is: 21.30% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 12.16 | sMAPE for Test Set is: 31.44% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:29:27,915]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:29:41,086]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:29:45,333]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:29:47,594]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:29:52,422]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:30:00,327]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:30:09,087]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:30:24,805]\u001b[0m Trial 1265 finished with value: 5.340630790316735 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008806002646753243, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24876370003480064, 'dropout_rate_Layer_2': 0.21568159992659672, 'dropout_rate_Layer_3': 0.13949927352313923, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.58647490501199e-05, 'l1_Layer_2': 2.8948234959500123e-05, 'l1_Layer_3': 0.0011185946937640448, 'n_units_Layer_1': 175, 'n_units_Layer_2': 190, 'n_units_Layer_3': 180}. Best is trial 1203 with value: 5.065547900666176.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.34 | sMAPE for Validation Set is: 21.32% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 12.36 | sMAPE for Test Set is: 31.86% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:31:06,986]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:31:16,026]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:31:21,384]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:31:29,701]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:31:32,308]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:31:38,348]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:32:02,319]\u001b[0m Trial 1275 finished with value: 5.180885525482709 and parameters: {'n_hidden': 3, 'learning_rate': 0.00070125324668583, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2790069639649517, 'dropout_rate_Layer_2': 0.018084784409396808, 'dropout_rate_Layer_3': 0.02665918736038476, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.415944721905678e-05, 'l1_Layer_2': 0.0008119164403335095, 'l1_Layer_3': 0.0002428402918543233, 'n_units_Layer_1': 85, 'n_units_Layer_2': 100, 'n_units_Layer_3': 290}. Best is trial 1203 with value: 5.065547900666176.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.18 | sMAPE for Validation Set is: 20.80% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 8.69 | sMAPE for Test Set is: 22.70% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:32:11,290]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:32:30,459]\u001b[0m Trial 1274 finished with value: 5.287653614633771 and parameters: {'n_hidden': 3, 'learning_rate': 0.000502102012591775, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31993384840295724, 'dropout_rate_Layer_2': 0.3636818384660205, 'dropout_rate_Layer_3': 0.26576196228065624, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.000453555237473735, 'l1_Layer_2': 0.008715665801617591, 'l1_Layer_3': 5.281171874571509e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 90, 'n_units_Layer_3': 255}. Best is trial 1203 with value: 5.065547900666176.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.29 | sMAPE for Validation Set is: 21.57% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 9.34 | sMAPE for Test Set is: 24.42% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:32:38,795]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:32:45,244]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:32:55,505]\u001b[0m Trial 1280 finished with value: 5.233194916580615 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008366380521441641, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25320195894045455, 'dropout_rate_Layer_2': 0.2535555860942197, 'dropout_rate_Layer_3': 0.1218204748052562, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014582753341514795, 'l1_Layer_2': 2.3068660594478834e-05, 'l1_Layer_3': 0.0005355941467801283, 'n_units_Layer_1': 175, 'n_units_Layer_2': 155, 'n_units_Layer_3': 180}. Best is trial 1203 with value: 5.065547900666176.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.23 | sMAPE for Validation Set is: 20.93% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 11.61 | sMAPE for Test Set is: 29.74% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:32:59,348]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:33:08,510]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:33:22,400]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:33:41,024]\u001b[0m Trial 1281 finished with value: 5.209222607826832 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006201495961584543, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3373750469862853, 'dropout_rate_Layer_2': 0.37850679926470554, 'dropout_rate_Layer_3': 0.23123979754702736, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00014278708074150925, 'l1_Layer_2': 0.0033361606995579284, 'l1_Layer_3': 0.00012583562484316883, 'n_units_Layer_1': 115, 'n_units_Layer_2': 75, 'n_units_Layer_3': 255}. Best is trial 1203 with value: 5.065547900666176.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.21 | sMAPE for Validation Set is: 21.36% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 9.32 | sMAPE for Test Set is: 24.33% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:34:08,644]\u001b[0m Trial 1284 finished with value: 5.201891972569114 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008226934096245872, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2627663264208789, 'dropout_rate_Layer_2': 0.276026882350617, 'dropout_rate_Layer_3': 0.12214584187395074, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014753426114842846, 'l1_Layer_2': 3.054403915761977e-05, 'l1_Layer_3': 0.0005629810935781749, 'n_units_Layer_1': 175, 'n_units_Layer_2': 155, 'n_units_Layer_3': 180}. Best is trial 1203 with value: 5.065547900666176.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.20 | sMAPE for Validation Set is: 20.86% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 11.94 | sMAPE for Test Set is: 30.34% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:34:11,115]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:34:18,699]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:34:25,294]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:34:27,965]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:34:34,730]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:34:40,454]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:34:46,066]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:34:55,445]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:35:01,120]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:35:01,753]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:35:06,837]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:35:30,088]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:35:39,134]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:35:53,640]\u001b[0m Trial 1290 finished with value: 5.384252008086477 and parameters: {'n_hidden': 3, 'learning_rate': 0.002945033444883328, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3307882397172962, 'dropout_rate_Layer_2': 0.08307991141352829, 'dropout_rate_Layer_3': 0.24232473613217018, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.413922478870587e-05, 'l1_Layer_2': 1.1822900899907222e-05, 'l1_Layer_3': 1.5185022700212789e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 200, 'n_units_Layer_3': 90}. Best is trial 1203 with value: 5.065547900666176.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.38 | sMAPE for Validation Set is: 21.59% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 13.64 | sMAPE for Test Set is: 35.24% | rMAE for Test Set is: 1.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:35:57,401]\u001b[0m Trial 1291 finished with value: 5.321755686692159 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008423103585685741, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3064823048193744, 'dropout_rate_Layer_2': 0.39029321709948733, 'dropout_rate_Layer_3': 0.18193128686046434, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014478430623225444, 'l1_Layer_2': 0.013033382072222254, 'l1_Layer_3': 0.00012346095862231942, 'n_units_Layer_1': 115, 'n_units_Layer_2': 60, 'n_units_Layer_3': 55}. Best is trial 1203 with value: 5.065547900666176.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.32 | sMAPE for Validation Set is: 21.88% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.68 | sMAPE for Test Set is: 18.56% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:36:03,985]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:36:15,551]\u001b[0m Trial 1303 finished with value: 5.45829357676666 and parameters: {'n_hidden': 3, 'learning_rate': 0.002732502859743104, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33865829667864417, 'dropout_rate_Layer_2': 0.048783627955685645, 'dropout_rate_Layer_3': 0.10064942616383889, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011953530501447373, 'l1_Layer_2': 1.6444987067549675e-05, 'l1_Layer_3': 1.3727977455616002e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 205, 'n_units_Layer_3': 95}. Best is trial 1203 with value: 5.065547900666176.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.46 | sMAPE for Validation Set is: 21.40% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 13.31 | sMAPE for Test Set is: 34.07% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:36:36,239]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:36:45,060]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:36:50,022]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:36:55,524]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:36:56,292]\u001b[0m Trial 1308 finished with value: 5.254226882457734 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008216725141150982, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.258563272422794, 'dropout_rate_Layer_2': 0.2515684854433959, 'dropout_rate_Layer_3': 0.14008807676950016, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014281817781128337, 'l1_Layer_2': 2.268722447518739e-05, 'l1_Layer_3': 0.0007364243309082842, 'n_units_Layer_1': 190, 'n_units_Layer_2': 155, 'n_units_Layer_3': 180}. Best is trial 1203 with value: 5.065547900666176.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.25 | sMAPE for Validation Set is: 20.92% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 12.11 | sMAPE for Test Set is: 30.95% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:37:00,119]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:37:07,472]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:37:14,219]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:37:29,170]\u001b[0m Trial 1305 finished with value: 5.190164202586288 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008468051880224976, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29713335441838407, 'dropout_rate_Layer_2': 0.3477847873703315, 'dropout_rate_Layer_3': 0.23988273672234292, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011510590330945309, 'l1_Layer_2': 0.004119822746775877, 'l1_Layer_3': 0.0001244205751395901, 'n_units_Layer_1': 105, 'n_units_Layer_2': 60, 'n_units_Layer_3': 215}. Best is trial 1203 with value: 5.065547900666176.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.19 | sMAPE for Validation Set is: 21.18% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.24 | sMAPE for Test Set is: 17.32% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:37:34,017]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:38:04,167]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:38:18,586]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:38:47,385]\u001b[0m Trial 1315 finished with value: 5.198379115993557 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005616408884910001, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34791633036116765, 'dropout_rate_Layer_2': 0.3788669668494232, 'dropout_rate_Layer_3': 0.2060082939646186, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00023618383588704155, 'l1_Layer_2': 0.010652335230769886, 'l1_Layer_3': 0.0001727164682773862, 'n_units_Layer_1': 110, 'n_units_Layer_2': 85, 'n_units_Layer_3': 245}. Best is trial 1203 with value: 5.065547900666176.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.20 | sMAPE for Validation Set is: 21.04% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 7.12 | sMAPE for Test Set is: 19.58% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:38:49,532]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:38:58,099]\u001b[0m Trial 1314 finished with value: 5.212173567102525 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005661753706036764, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34717413496461136, 'dropout_rate_Layer_2': 0.3801418786972074, 'dropout_rate_Layer_3': 0.20511189041524627, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001547293998252622, 'l1_Layer_2': 0.010708529580236716, 'l1_Layer_3': 0.00018852671875107347, 'n_units_Layer_1': 105, 'n_units_Layer_2': 85, 'n_units_Layer_3': 245}. Best is trial 1203 with value: 5.065547900666176.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.21 | sMAPE for Validation Set is: 21.30% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 7.24 | sMAPE for Test Set is: 19.79% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:39:00,152]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:39:04,295]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:39:09,330]\u001b[0m Trial 1317 finished with value: 5.097886632654255 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008075265229258777, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3109381136187935, 'dropout_rate_Layer_2': 0.37877232066065203, 'dropout_rate_Layer_3': 0.2058051212587311, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00022370016268333232, 'l1_Layer_2': 0.004241643454772443, 'l1_Layer_3': 0.0001855608660407271, 'n_units_Layer_1': 105, 'n_units_Layer_2': 70, 'n_units_Layer_3': 215}. Best is trial 1203 with value: 5.065547900666176.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.10 | sMAPE for Validation Set is: 20.72% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 7.31 | sMAPE for Test Set is: 19.83% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:39:14,966]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:39:15,250]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:39:22,268]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:39:59,695]\u001b[0m Trial 1324 finished with value: 5.303563014977653 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008180658886591419, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23782565744661716, 'dropout_rate_Layer_2': 0.28231979629759874, 'dropout_rate_Layer_3': 0.0947911484041101, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001563940175596367, 'l1_Layer_2': 2.2069105456544777e-05, 'l1_Layer_3': 0.00037788546271080696, 'n_units_Layer_1': 180, 'n_units_Layer_2': 155, 'n_units_Layer_3': 165}. Best is trial 1203 with value: 5.065547900666176.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.30 | sMAPE for Validation Set is: 21.22% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 11.50 | sMAPE for Test Set is: 29.63% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:40:05,078]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:40:10,186]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:40:10,656]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:40:20,282]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:40:25,618]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:40:26,495]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:40:38,243]\u001b[0m Trial 1330 finished with value: 5.264258328659576 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008213231844173256, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2633383615622829, 'dropout_rate_Layer_2': 0.25408118345590897, 'dropout_rate_Layer_3': 0.14168056119268335, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002822177590529752, 'l1_Layer_2': 1.980462401842965e-05, 'l1_Layer_3': 0.000351677063024369, 'n_units_Layer_1': 180, 'n_units_Layer_2': 155, 'n_units_Layer_3': 180}. Best is trial 1203 with value: 5.065547900666176.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.26 | sMAPE for Validation Set is: 21.17% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.93 | sMAPE for Test Set is: 27.93% | rMAE for Test Set is: 1.04\n",
      "MAE for Validation Set is: 5.24 | sMAPE for Validation Set is: 21.05% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 12.34 | sMAPE for Test Set is: 31.55% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:40:40,132]\u001b[0m Trial 1329 finished with value: 5.23745724782431 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007418497201171393, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2572163240554884, 'dropout_rate_Layer_2': 0.2785676948653104, 'dropout_rate_Layer_3': 0.1362395409717297, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013312541889678756, 'l1_Layer_2': 2.1213332132739878e-05, 'l1_Layer_3': 0.000334012588619258, 'n_units_Layer_1': 180, 'n_units_Layer_2': 155, 'n_units_Layer_3': 180}. Best is trial 1203 with value: 5.065547900666176.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:40:45,415]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:40:54,278]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:41:00,630]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:41:05,757]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:41:10,341]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:41:12,500]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:41:21,637]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:41:27,578]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:41:27,967]\u001b[0m Trial 1337 finished with value: 5.280485581961329 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008053310217429261, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25688697243438335, 'dropout_rate_Layer_2': 0.2780708452488613, 'dropout_rate_Layer_3': 0.1005761425118413, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015043564145307933, 'l1_Layer_2': 2.3067098817085294e-05, 'l1_Layer_3': 0.0003248930739171366, 'n_units_Layer_1': 190, 'n_units_Layer_2': 155, 'n_units_Layer_3': 165}. Best is trial 1203 with value: 5.065547900666176.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.28 | sMAPE for Validation Set is: 21.09% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 11.58 | sMAPE for Test Set is: 29.59% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:41:32,997]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:41:35,882]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:41:40,288]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:41:54,945]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:42:01,089]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:42:15,995]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:42:44,317]\u001b[0m Trial 1336 finished with value: 5.168775000315112 and parameters: {'n_hidden': 3, 'learning_rate': 0.000560006946001967, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32704853051341104, 'dropout_rate_Layer_2': 0.3831612899276992, 'dropout_rate_Layer_3': 0.19285261311777713, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00016100233331486235, 'l1_Layer_2': 0.0043183222854253425, 'l1_Layer_3': 0.0003682748115565798, 'n_units_Layer_1': 80, 'n_units_Layer_2': 85, 'n_units_Layer_3': 215}. Best is trial 1203 with value: 5.065547900666176.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.17 | sMAPE for Validation Set is: 20.96% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.62 | sMAPE for Test Set is: 18.25% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:42:53,277]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:42:54,415]\u001b[0m Trial 1344 finished with value: 5.186745342717991 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005703697098259837, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3280147150567244, 'dropout_rate_Layer_2': 0.38641036332506373, 'dropout_rate_Layer_3': 0.20761900523859467, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00016313737288259274, 'l1_Layer_2': 0.0037413256468665146, 'l1_Layer_3': 0.00018732208843091571, 'n_units_Layer_1': 95, 'n_units_Layer_2': 85, 'n_units_Layer_3': 200}. Best is trial 1203 with value: 5.065547900666176.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.19 | sMAPE for Validation Set is: 21.22% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.61 | sMAPE for Test Set is: 18.37% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:43:01,168]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:43:04,131]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:43:20,269]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:43:22,518]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:43:28,382]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:43:36,847]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:43:37,411]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:43:44,073]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:44:14,013]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:44:24,544]\u001b[0m Trial 1349 finished with value: 5.3329883592643785 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031724082009448435, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3274975515973037, 'dropout_rate_Layer_2': 0.11747900587685028, 'dropout_rate_Layer_3': 0.14325703661399197, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010151507782360445, 'l1_Layer_2': 1.3980272950963889e-05, 'l1_Layer_3': 1.1439312913113403e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 230, 'n_units_Layer_3': 140}. Best is trial 1203 with value: 5.065547900666176.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.33 | sMAPE for Validation Set is: 21.15% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 12.03 | sMAPE for Test Set is: 30.73% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:44:34,237]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:44:43,980]\u001b[0m Trial 1358 finished with value: 5.408274459501442 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028888705703283657, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3274233027717395, 'dropout_rate_Layer_2': 0.03747116846310723, 'dropout_rate_Layer_3': 0.2355832399646881, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00019642773944567417, 'l1_Layer_2': 1.8849412532268307e-05, 'l1_Layer_3': 1.602882322147845e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 225, 'n_units_Layer_3': 95}. Best is trial 1203 with value: 5.065547900666176.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.41 | sMAPE for Validation Set is: 21.39% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 12.60 | sMAPE for Test Set is: 32.26% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:44:44,844]\u001b[0m Trial 1363 finished with value: 5.193167012608586 and parameters: {'n_hidden': 3, 'learning_rate': 0.000821617098965145, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32706434745703833, 'dropout_rate_Layer_2': 0.35697690181660297, 'dropout_rate_Layer_3': 0.17145743799804386, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002148441920679162, 'l1_Layer_2': 0.002286388918074313, 'l1_Layer_3': 0.00041697458754110157, 'n_units_Layer_1': 95, 'n_units_Layer_2': 70, 'n_units_Layer_3': 190}. Best is trial 1203 with value: 5.065547900666176.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.19 | sMAPE for Validation Set is: 21.05% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.61 | sMAPE for Test Set is: 18.29% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:44:45,864]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:44:56,990]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:45:10,331]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:45:23,436]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:45:26,835]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:45:32,355]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:45:42,522]\u001b[0m Trial 1369 finished with value: 5.293743110416629 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007488195492954021, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26371578448604566, 'dropout_rate_Layer_2': 0.28323819648469106, 'dropout_rate_Layer_3': 0.0941114285596069, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00021669726007440872, 'l1_Layer_2': 2.2197881020908728e-05, 'l1_Layer_3': 0.00027585353998931574, 'n_units_Layer_1': 190, 'n_units_Layer_2': 145, 'n_units_Layer_3': 165}. Best is trial 1203 with value: 5.065547900666176.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.29 | sMAPE for Validation Set is: 21.11% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 11.45 | sMAPE for Test Set is: 29.24% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:46:11,150]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:46:16,713]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.20 | sMAPE for Validation Set is: 20.83% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 12.10 | sMAPE for Test Set is: 31.05% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:46:18,679]\u001b[0m Trial 1375 finished with value: 5.201271962222802 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007410581946532748, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2545590542201742, 'dropout_rate_Layer_2': 0.27948595379079555, 'dropout_rate_Layer_3': 0.10120185744492245, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015072261338459995, 'l1_Layer_2': 2.1403220523827282e-05, 'l1_Layer_3': 0.00035411265256783735, 'n_units_Layer_1': 190, 'n_units_Layer_2': 145, 'n_units_Layer_3': 170}. Best is trial 1203 with value: 5.065547900666176.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:46:27,160]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:46:29,699]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.11 | sMAPE for Validation Set is: 20.56% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 8.81 | sMAPE for Test Set is: 22.97% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:46:32,095]\u001b[0m Trial 1370 finished with value: 5.112785887897737 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007319144045353806, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30753107736835034, 'dropout_rate_Layer_2': 0.0072073280675329044, 'dropout_rate_Layer_3': 0.013613837921594592, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.800297792344164e-05, 'l1_Layer_2': 0.0010638914366639177, 'l1_Layer_3': 0.00015067795109247693, 'n_units_Layer_1': 90, 'n_units_Layer_2': 85, 'n_units_Layer_3': 290}. Best is trial 1203 with value: 5.065547900666176.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:46:33,788]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:46:46,134]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:46:51,461]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:47:00,478]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:47:01,318]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:47:09,086]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:47:13,049]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:47:18,739]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:47:33,093]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:47:57,077]\u001b[0m Trial 1381 finished with value: 5.169742177023209 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009244954691676474, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31050113271768887, 'dropout_rate_Layer_2': 0.3818152314686636, 'dropout_rate_Layer_3': 0.17604410826425473, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001255076074110074, 'l1_Layer_2': 0.0012022775081172545, 'l1_Layer_3': 0.0005089365509388475, 'n_units_Layer_1': 80, 'n_units_Layer_2': 75, 'n_units_Layer_3': 190}. Best is trial 1203 with value: 5.065547900666176.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.17 | sMAPE for Validation Set is: 20.96% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.72 | sMAPE for Test Set is: 18.63% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:48:06,464]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:48:25,256]\u001b[0m Trial 1390 finished with value: 5.134013604316549 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007938270501981906, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3478495772240877, 'dropout_rate_Layer_2': 0.3918790133624435, 'dropout_rate_Layer_3': 0.20915144516530793, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00025345036376193573, 'l1_Layer_2': 0.00416855739665343, 'l1_Layer_3': 0.0005124996502737728, 'n_units_Layer_1': 95, 'n_units_Layer_2': 75, 'n_units_Layer_3': 200}. Best is trial 1203 with value: 5.065547900666176.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.13 | sMAPE for Validation Set is: 20.77% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.99 | sMAPE for Test Set is: 19.04% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:48:42,512]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:48:47,171]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:48:58,684]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:49:02,271]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:49:08,596]\u001b[0m Trial 1382 finished with value: 5.333207461711859 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028876587002434227, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33986731865156955, 'dropout_rate_Layer_2': 0.11032534430382382, 'dropout_rate_Layer_3': 0.16520199462389173, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00019694987935617845, 'l1_Layer_2': 1.1844305589985739e-05, 'l1_Layer_3': 1.008326666307912e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 225, 'n_units_Layer_3': 135}. Best is trial 1203 with value: 5.065547900666176.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.33 | sMAPE for Validation Set is: 21.18% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.74 | sMAPE for Test Set is: 27.57% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:49:16,911]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:49:18,500]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:49:59,774]\u001b[0m Trial 1402 finished with value: 5.28513971810498 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007786974838041083, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2400255884967419, 'dropout_rate_Layer_2': 0.2751188691960085, 'dropout_rate_Layer_3': 0.08551104483695449, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00022591428364092804, 'l1_Layer_2': 2.253430987086985e-05, 'l1_Layer_3': 0.000361484126013044, 'n_units_Layer_1': 185, 'n_units_Layer_2': 155, 'n_units_Layer_3': 165}. Best is trial 1203 with value: 5.065547900666176.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.29 | sMAPE for Validation Set is: 21.08% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 11.90 | sMAPE for Test Set is: 30.54% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:50:10,775]\u001b[0m Trial 1398 finished with value: 5.184830220640955 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008230803374613165, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.241341808577237, 'dropout_rate_Layer_2': 0.27726392605216493, 'dropout_rate_Layer_3': 0.09836469086653857, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00031064762398512593, 'l1_Layer_2': 2.2191867791003974e-05, 'l1_Layer_3': 0.0003654656220624857, 'n_units_Layer_1': 190, 'n_units_Layer_2': 155, 'n_units_Layer_3': 165}. Best is trial 1203 with value: 5.065547900666176.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.18 | sMAPE for Validation Set is: 20.89% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 12.27 | sMAPE for Test Set is: 31.26% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:50:23,515]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:50:26,607]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:50:30,111]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:50:33,733]\u001b[0m Trial 1394 finished with value: 5.3651167259092 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034705892830676865, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.341535082415089, 'dropout_rate_Layer_2': 0.10074601488016136, 'dropout_rate_Layer_3': 0.20984195034871028, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004040986209754509, 'l1_Layer_2': 1.152923814856038e-05, 'l1_Layer_3': 1.164306188035802e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 225, 'n_units_Layer_3': 145}. Best is trial 1203 with value: 5.065547900666176.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.37 | sMAPE for Validation Set is: 21.28% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 12.19 | sMAPE for Test Set is: 31.48% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:50:38,853]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:50:44,221]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:50:55,046]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:51:22,670]\u001b[0m Trial 1401 finished with value: 5.324147314047251 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008208029940447909, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24182462398947346, 'dropout_rate_Layer_2': 0.27559021839368436, 'dropout_rate_Layer_3': 0.06652894696674605, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00023397147213854245, 'l1_Layer_2': 2.237644940167223e-05, 'l1_Layer_3': 0.0003444559600468471, 'n_units_Layer_1': 185, 'n_units_Layer_2': 155, 'n_units_Layer_3': 165}. Best is trial 1203 with value: 5.065547900666176.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.32 | sMAPE for Validation Set is: 21.34% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 11.32 | sMAPE for Test Set is: 29.02% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:51:50,197]\u001b[0m Trial 1411 finished with value: 5.040512172446571 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009640099692568737, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3108827619254844, 'dropout_rate_Layer_2': 0.39106265922549566, 'dropout_rate_Layer_3': 0.17254231134516962, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00021730935498014153, 'l1_Layer_2': 0.001273387806590495, 'l1_Layer_3': 0.0005200799011446549, 'n_units_Layer_1': 95, 'n_units_Layer_2': 70, 'n_units_Layer_3': 200}. Best is trial 1411 with value: 5.040512172446571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.04 | sMAPE for Validation Set is: 20.39% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 7.20 | sMAPE for Test Set is: 19.49% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:51:53,678]\u001b[0m Trial 1407 finished with value: 5.189429386585043 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006338356981945116, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31524979040863027, 'dropout_rate_Layer_2': 0.021319214417952807, 'dropout_rate_Layer_3': 0.030843619034868864, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.19303628876687e-05, 'l1_Layer_2': 0.0008369805399829511, 'l1_Layer_3': 0.00018807450327706321, 'n_units_Layer_1': 85, 'n_units_Layer_2': 95, 'n_units_Layer_3': 290}. Best is trial 1411 with value: 5.040512172446571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.19 | sMAPE for Validation Set is: 20.84% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 8.72 | sMAPE for Test Set is: 22.76% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:52:05,095]\u001b[0m Trial 1410 finished with value: 5.173411173034925 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007751161671300955, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2391428113448305, 'dropout_rate_Layer_2': 0.27714088232748707, 'dropout_rate_Layer_3': 0.06599571461266383, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00031154115038504586, 'l1_Layer_2': 2.2246585353276697e-05, 'l1_Layer_3': 0.0003605208805904181, 'n_units_Layer_1': 190, 'n_units_Layer_2': 155, 'n_units_Layer_3': 165}. Best is trial 1411 with value: 5.040512172446571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.17 | sMAPE for Validation Set is: 20.84% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 11.25 | sMAPE for Test Set is: 28.77% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:52:27,110]\u001b[0m Trial 1412 finished with value: 5.105818410961017 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009985460800491248, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3066425915655986, 'dropout_rate_Layer_2': 0.3938793906059608, 'dropout_rate_Layer_3': 0.17310084662381797, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00023215768581705138, 'l1_Layer_2': 0.0011124413903316065, 'l1_Layer_3': 0.0005141228464812723, 'n_units_Layer_1': 95, 'n_units_Layer_2': 75, 'n_units_Layer_3': 200}. Best is trial 1411 with value: 5.040512172446571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.11 | sMAPE for Validation Set is: 20.65% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 7.07 | sMAPE for Test Set is: 19.15% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:52:35,977]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:52:43,405]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:52:53,176]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:53:04,173]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:53:09,249]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:53:09,652]\u001b[0m Trial 1415 finished with value: 5.075892537593344 and parameters: {'n_hidden': 3, 'learning_rate': 0.001145493935783942, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3073992185319933, 'dropout_rate_Layer_2': 0.39948445522986736, 'dropout_rate_Layer_3': 0.14674248145077046, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002469270932723077, 'l1_Layer_2': 0.0012485773846048632, 'l1_Layer_3': 0.0005113351452838917, 'n_units_Layer_1': 95, 'n_units_Layer_2': 75, 'n_units_Layer_3': 195}. Best is trial 1411 with value: 5.040512172446571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.08 | sMAPE for Validation Set is: 20.57% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.92 | sMAPE for Test Set is: 18.92% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:53:10,395]\u001b[0m Trial 1413 finished with value: 5.2353395477499225 and parameters: {'n_hidden': 3, 'learning_rate': 0.000818977566628114, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24002647799928933, 'dropout_rate_Layer_2': 0.2769925368015204, 'dropout_rate_Layer_3': 0.08656718162499562, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00030431327216426363, 'l1_Layer_2': 2.1966640297460123e-05, 'l1_Layer_3': 0.0003638442386999573, 'n_units_Layer_1': 190, 'n_units_Layer_2': 155, 'n_units_Layer_3': 165}. Best is trial 1411 with value: 5.040512172446571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.24 | sMAPE for Validation Set is: 21.08% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 11.87 | sMAPE for Test Set is: 30.44% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:53:18,736]\u001b[0m Trial 1414 finished with value: 5.186757521746851 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011563972866835291, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.306148323545925, 'dropout_rate_Layer_2': 0.392181831608707, 'dropout_rate_Layer_3': 0.15027310175084002, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00024087118113720198, 'l1_Layer_2': 0.0010280391937683127, 'l1_Layer_3': 0.0005213683492853495, 'n_units_Layer_1': 75, 'n_units_Layer_2': 75, 'n_units_Layer_3': 180}. Best is trial 1411 with value: 5.040512172446571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.19 | sMAPE for Validation Set is: 21.10% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.78 | sMAPE for Test Set is: 18.66% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:53:22,798]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:53:26,386]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:53:30,458]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:53:34,318]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:53:44,182]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:54:00,984]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:54:07,863]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:54:08,901]\u001b[0m Trial 1422 finished with value: 5.247551123618983 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007986531962362822, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26433340929110954, 'dropout_rate_Layer_2': 0.2845025685510972, 'dropout_rate_Layer_3': 0.08696050237650234, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00029003106830258196, 'l1_Layer_2': 1.6236493804631457e-05, 'l1_Layer_3': 0.0002451688083499381, 'n_units_Layer_1': 190, 'n_units_Layer_2': 145, 'n_units_Layer_3': 160}. Best is trial 1411 with value: 5.040512172446571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.25 | sMAPE for Validation Set is: 20.90% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 11.98 | sMAPE for Test Set is: 30.60% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:54:13,164]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:54:22,360]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:54:26,053]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:54:29,595]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:54:34,308]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:54:39,589]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:54:43,805]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:54:44,509]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:54:46,659]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:54:49,915]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:54:53,702]\u001b[0m Trial 1426 finished with value: 5.378108890220884 and parameters: {'n_hidden': 3, 'learning_rate': 0.003499907361650053, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33136270737898044, 'dropout_rate_Layer_2': 0.09731537527252748, 'dropout_rate_Layer_3': 0.17926464536105272, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00026538319808668166, 'l1_Layer_2': 1.3855899620633234e-05, 'l1_Layer_3': 1.7321731523502613e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 220, 'n_units_Layer_3': 140}. Best is trial 1411 with value: 5.040512172446571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.38 | sMAPE for Validation Set is: 20.94% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 12.65 | sMAPE for Test Set is: 32.20% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:55:03,561]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:55:07,425]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:55:13,567]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:55:16,304]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:55:20,524]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:55:24,931]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:55:28,404]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:55:35,890]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:55:41,258]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:55:41,770]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:55:48,235]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:55:50,253]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:56:03,933]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:56:06,304]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:56:14,508]\u001b[0m Trial 1442 finished with value: 5.352906560480484 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031708401432124717, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3291343935270189, 'dropout_rate_Layer_2': 0.10569980590397857, 'dropout_rate_Layer_3': 0.17706429293006687, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003250129424073303, 'l1_Layer_2': 0.000581852637523348, 'l1_Layer_3': 2.1578695137705877e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 215, 'n_units_Layer_3': 140}. Best is trial 1411 with value: 5.040512172446571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.35 | sMAPE for Validation Set is: 21.17% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 12.08 | sMAPE for Test Set is: 30.75% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:56:15,528]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:56:20,556]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:56:21,188]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:56:32,493]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:56:45,791]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:56:46,188]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:57:23,373]\u001b[0m Trial 1460 finished with value: 5.134480026204078 and parameters: {'n_hidden': 3, 'learning_rate': 0.001140823786197537, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2874210848975075, 'dropout_rate_Layer_2': 0.39100185439024715, 'dropout_rate_Layer_3': 0.13317188867285176, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00020227669626321108, 'l1_Layer_2': 0.0007380577743301136, 'l1_Layer_3': 0.0005548060378061814, 'n_units_Layer_1': 75, 'n_units_Layer_2': 200, 'n_units_Layer_3': 195}. Best is trial 1411 with value: 5.040512172446571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.13 | sMAPE for Validation Set is: 20.72% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.74 | sMAPE for Test Set is: 18.42% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 19:57:29,583]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:57:33,611]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:57:41,324]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:57:45,127]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:57:45,800]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:57:54,641]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:57:59,148]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:58:05,140]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:58:11,404]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:58:15,401]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:58:20,309]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:58:26,197]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:58:26,973]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:58:30,256]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:58:37,287]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:58:42,607]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:58:47,285]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:58:53,278]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:58:59,857]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:59:02,572]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:59:03,726]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:59:10,026]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:59:10,247]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:59:22,235]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:59:39,628]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:59:49,075]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 19:59:57,860]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 20:00:07,954]\u001b[0m Trial 1486 finished with value: 5.188227903743724 and parameters: {'n_hidden': 3, 'learning_rate': 0.001908784952487953, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2864550955992854, 'dropout_rate_Layer_2': 0.3907879986390693, 'dropout_rate_Layer_3': 0.1323395817247512, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00019017293009862784, 'l1_Layer_2': 0.0008180388766290712, 'l1_Layer_3': 0.0005253327057858035, 'n_units_Layer_1': 65, 'n_units_Layer_2': 275, 'n_units_Layer_3': 195}. Best is trial 1411 with value: 5.040512172446571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.19 | sMAPE for Validation Set is: 20.92% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.93 | sMAPE for Test Set is: 19.10% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 20:00:12,176]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 20:00:22,327]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 20:00:23,941]\u001b[0m Trial 1487 finished with value: 5.217212342695789 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008193493610457988, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23982633642437928, 'dropout_rate_Layer_2': 0.27568824871917375, 'dropout_rate_Layer_3': 0.09859497414438619, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005626552952500439, 'l1_Layer_2': 1.4298559139545529e-05, 'l1_Layer_3': 0.0002162524040594621, 'n_units_Layer_1': 205, 'n_units_Layer_2': 155, 'n_units_Layer_3': 170}. Best is trial 1411 with value: 5.040512172446571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.22 | sMAPE for Validation Set is: 21.06% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 11.10 | sMAPE for Test Set is: 28.30% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 20:00:30,817]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 20:00:33,285]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 20:00:37,236]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 20:01:13,476]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 20:01:42,949]\u001b[0m Trial 1494 finished with value: 5.190469098558366 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008187890488518682, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3090661752499898, 'dropout_rate_Layer_2': 0.014254450233355299, 'dropout_rate_Layer_3': 0.012117892799949456, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.5942572289177834e-05, 'l1_Layer_2': 0.0006750313117078231, 'l1_Layer_3': 0.0001181239890325698, 'n_units_Layer_1': 90, 'n_units_Layer_2': 85, 'n_units_Layer_3': 290}. Best is trial 1411 with value: 5.040512172446571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.19 | sMAPE for Validation Set is: 20.67% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 8.69 | sMAPE for Test Set is: 22.58% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 20:02:01,322]\u001b[0m Trial 1499 finished with value: 5.2279458224737345 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006014699142583029, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3063300810910117, 'dropout_rate_Layer_2': 0.014768341320626073, 'dropout_rate_Layer_3': 0.014090907998185475, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.739988064726901e-05, 'l1_Layer_2': 0.0007718166210945832, 'l1_Layer_3': 0.000352108604568797, 'n_units_Layer_1': 90, 'n_units_Layer_2': 70, 'n_units_Layer_3': 290}. Best is trial 1411 with value: 5.040512172446571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.23 | sMAPE for Validation Set is: 20.98% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.01 | sMAPE for Test Set is: 25.73% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 20:02:03,428]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-01-01, MAE is:11.61 & sMAPE is:69.59% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :11.61 & 69.59% & 0.93\n",
      "for 2018-01-02, MAE is:10.73 & sMAPE is:37.16% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :11.17 & 53.38% & 0.66\n",
      "for 2018-01-03, MAE is:7.23 & sMAPE is:49.90% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :9.86 & 52.22% & 0.75\n",
      "WARNING:tensorflow:5 out of the last 28 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002298D2799D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "for 2018-01-04, MAE is:5.63 & sMAPE is:16.23% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :8.80 & 43.22% & 0.81\n",
      "WARNING:tensorflow:6 out of the last 29 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000228A614BDC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "for 2018-01-05, MAE is:8.10 & sMAPE is:28.57% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :8.66 & 40.29% & 0.78\n",
      "for 2018-01-06, MAE is:3.26 & sMAPE is:8.69% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :7.76 & 35.02% & 0.70\n",
      "for 2018-01-07, MAE is:4.08 & sMAPE is:14.92% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :7.23 & 32.15% & 0.68\n",
      "for 2018-01-08, MAE is:4.77 & sMAPE is:15.66% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 30.09% & 0.64\n",
      "for 2018-01-09, MAE is:3.90 & sMAPE is:19.71% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.59 & 28.94% & 0.63\n",
      "for 2018-01-10, MAE is:6.72 & sMAPE is:16.71% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :6.60 & 27.71% & 0.60\n",
      "for 2018-01-11, MAE is:7.76 & sMAPE is:17.40% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 26.78% & 0.62\n",
      "for 2018-01-12, MAE is:2.83 & sMAPE is:7.66% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :6.38 & 25.18% & 0.59\n",
      "for 2018-01-13, MAE is:2.00 & sMAPE is:6.18% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.05 & 23.72% & 0.58\n",
      "for 2018-01-14, MAE is:1.10 & sMAPE is:3.84% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :5.69 & 22.30% & 0.58\n",
      "for 2018-01-15, MAE is:8.00 & sMAPE is:34.34% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :5.85 & 23.10% & 0.59\n",
      "for 2018-01-16, MAE is:12.31 & sMAPE is:71.18% & rMAE is:1.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.25 & 26.11% & 0.66\n",
      "for 2018-01-17, MAE is:2.63 & sMAPE is:7.91% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 25.04% & 0.65\n",
      "for 2018-01-18, MAE is:3.40 & sMAPE is:9.48% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :5.89 & 24.17% & 0.64\n",
      "for 2018-01-19, MAE is:3.74 & sMAPE is:9.25% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :5.78 & 23.39% & 0.65\n",
      "for 2018-01-20, MAE is:4.63 & sMAPE is:12.63% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :5.72 & 22.85% & 0.65\n",
      "for 2018-01-21, MAE is:3.08 & sMAPE is:8.44% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :5.60 & 22.16% & 0.65\n",
      "for 2018-01-22, MAE is:4.31 & sMAPE is:10.79% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :5.54 & 21.65% & 0.63\n",
      "for 2018-01-23, MAE is:5.44 & sMAPE is:15.98% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :5.53 & 21.40% & 0.62\n",
      "for 2018-01-24, MAE is:5.20 & sMAPE is:25.54% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 21.57% & 0.62\n",
      "for 2018-01-25, MAE is:6.38 & sMAPE is:36.54% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :5.55 & 22.17% & 0.62\n",
      "for 2018-01-26, MAE is:2.71 & sMAPE is:7.42% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :5.44 & 21.60% & 0.61\n",
      "for 2018-01-27, MAE is:4.16 & sMAPE is:19.72% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :5.40 & 21.53% & 0.61\n",
      "for 2018-01-28, MAE is:8.74 & sMAPE is:87.86% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 23.90% & 0.60\n",
      "for 2018-01-29, MAE is:17.07 & sMAPE is:70.85% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 25.52% & 0.61\n",
      "for 2018-01-30, MAE is:4.52 & sMAPE is:16.72% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :5.87 & 25.23% & 0.61\n",
      "for 2018-01-31, MAE is:4.43 & sMAPE is:14.64% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :5.82 & 24.89% & 0.61\n",
      "for 2018-02-01, MAE is:1.98 & sMAPE is:6.87% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :5.70 & 24.32% & 0.60\n",
      "for 2018-02-02, MAE is:2.42 & sMAPE is:6.39% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :5.60 & 23.78% & 0.62\n",
      "for 2018-02-03, MAE is:1.36 & sMAPE is:3.77% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :5.48 & 23.19% & 0.61\n",
      "for 2018-02-04, MAE is:4.04 & sMAPE is:12.68% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :5.44 & 22.89% & 0.59\n",
      "for 2018-02-05, MAE is:5.08 & sMAPE is:11.03% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :5.43 & 22.56% & 0.58\n",
      "for 2018-02-06, MAE is:7.14 & sMAPE is:14.46% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :5.47 & 22.34% & 0.58\n",
      "for 2018-02-07, MAE is:6.62 & sMAPE is:14.04% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :5.50 & 22.12% & 0.57\n",
      "for 2018-02-08, MAE is:7.13 & sMAPE is:16.60% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :5.54 & 21.98% & 0.58\n",
      "for 2018-02-09, MAE is:3.22 & sMAPE is:9.31% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :5.49 & 21.67% & 0.58\n",
      "for 2018-02-10, MAE is:1.51 & sMAPE is:4.60% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :5.39 & 21.25% & 0.59\n",
      "for 2018-02-11, MAE is:18.23 & sMAPE is:101.85% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :5.69 & 23.17% & 0.59\n",
      "for 2018-02-12, MAE is:4.92 & sMAPE is:18.99% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :5.68 & 23.07% & 0.59\n",
      "for 2018-02-13, MAE is:4.19 & sMAPE is:11.17% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :5.64 & 22.80% & 0.58\n",
      "for 2018-02-14, MAE is:3.24 & sMAPE is:8.48% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :5.59 & 22.48% & 0.58\n",
      "for 2018-02-15, MAE is:4.90 & sMAPE is:15.80% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :5.57 & 22.34% & 0.57\n",
      "for 2018-02-16, MAE is:1.91 & sMAPE is:5.03% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :5.50 & 21.97% & 0.57\n",
      "for 2018-02-17, MAE is:4.50 & sMAPE is:11.89% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :5.48 & 21.76% & 0.58\n",
      "for 2018-02-18, MAE is:2.40 & sMAPE is:6.51% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :5.41 & 21.45% & 0.57\n",
      "for 2018-02-19, MAE is:9.83 & sMAPE is:20.77% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :5.50 & 21.44% & 0.56\n",
      "for 2018-02-20, MAE is:9.59 & sMAPE is:20.25% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :5.58 & 21.41% & 0.57\n",
      "for 2018-02-21, MAE is:4.48 & sMAPE is:9.05% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :5.56 & 21.17% & 0.57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-02-22, MAE is:4.02 & sMAPE is:7.86% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :5.53 & 20.92% & 0.56\n",
      "for 2018-02-23, MAE is:4.15 & sMAPE is:8.87% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :5.51 & 20.70% & 0.56\n",
      "for 2018-02-24, MAE is:5.40 & sMAPE is:15.71% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :5.50 & 20.61% & 0.57\n",
      "for 2018-02-25, MAE is:4.59 & sMAPE is:12.77% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :5.49 & 20.47% & 0.59\n",
      "for 2018-02-26, MAE is:5.81 & sMAPE is:11.73% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :5.49 & 20.32% & 0.59\n",
      "for 2018-02-27, MAE is:7.15 & sMAPE is:15.66% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 20.24% & 0.60\n",
      "for 2018-02-28, MAE is:8.85 & sMAPE is:21.75% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :5.58 & 20.26% & 0.60\n",
      "for 2018-03-01, MAE is:13.80 & sMAPE is:34.53% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :5.71 & 20.50% & 0.61\n",
      "for 2018-03-02, MAE is:7.19 & sMAPE is:16.72% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :5.74 & 20.44% & 0.61\n",
      "for 2018-03-03, MAE is:5.34 & sMAPE is:13.17% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :5.73 & 20.32% & 0.62\n",
      "for 2018-03-04, MAE is:3.27 & sMAPE is:9.93% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :5.69 & 20.15% & 0.62\n",
      "for 2018-03-05, MAE is:15.31 & sMAPE is:34.62% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :5.84 & 20.38% & 0.63\n",
      "for 2018-03-06, MAE is:4.69 & sMAPE is:9.47% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :5.83 & 20.21% & 0.63\n",
      "for 2018-03-07, MAE is:6.93 & sMAPE is:14.89% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :5.84 & 20.13% & 0.63\n",
      "for 2018-03-08, MAE is:2.50 & sMAPE is:5.93% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :5.79 & 19.92% & 0.63\n",
      "for 2018-03-09, MAE is:3.22 & sMAPE is:7.94% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :5.75 & 19.74% & 0.62\n",
      "for 2018-03-10, MAE is:2.20 & sMAPE is:6.00% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :5.70 & 19.54% & 0.63\n",
      "for 2018-03-11, MAE is:4.62 & sMAPE is:14.79% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :5.69 & 19.48% & 0.63\n",
      "for 2018-03-12, MAE is:6.84 & sMAPE is:17.14% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :5.70 & 19.44% & 0.63\n",
      "for 2018-03-13, MAE is:2.64 & sMAPE is:6.19% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :5.66 & 19.26% & 0.63\n",
      "for 2018-03-14, MAE is:8.71 & sMAPE is:18.51% & rMAE is:3.80 ||| daily mean of MAE & sMAPE & rMAE till now are :5.70 & 19.25% & 0.67\n",
      "for 2018-03-15, MAE is:21.36 & sMAPE is:63.08% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 19.84% & 0.68\n",
      "for 2018-03-16, MAE is:6.66 & sMAPE is:28.04% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :5.92 & 19.95% & 0.68\n",
      "for 2018-03-17, MAE is:26.74 & sMAPE is:162.98% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :6.20 & 21.83% & 0.68\n",
      "for 2018-03-18, MAE is:14.67 & sMAPE is:106.80% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 22.94% & 0.68\n",
      "for 2018-03-19, MAE is:5.90 & sMAPE is:15.87% & rMAE is:2.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.30 & 22.85% & 0.71\n",
      "for 2018-03-20, MAE is:5.66 & sMAPE is:13.22% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :6.30 & 22.72% & 0.72\n",
      "for 2018-03-21, MAE is:4.21 & sMAPE is:10.82% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.27 & 22.58% & 0.72\n",
      "for 2018-03-22, MAE is:9.68 & sMAPE is:21.21% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 22.56% & 0.72\n",
      "for 2018-03-23, MAE is:5.80 & sMAPE is:12.16% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 22.43% & 0.71\n",
      "for 2018-03-24, MAE is:3.49 & sMAPE is:9.06% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.27 & 22.27% & 0.70\n",
      "for 2018-03-25, MAE is:4.78 & sMAPE is:12.84% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :6.25 & 22.16% & 0.70\n",
      "for 2018-03-26, MAE is:3.13 & sMAPE is:6.23% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.22 & 21.97% & 0.70\n",
      "for 2018-03-27, MAE is:3.86 & sMAPE is:8.09% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :6.19 & 21.81% & 0.69\n",
      "for 2018-03-28, MAE is:2.27 & sMAPE is:5.91% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.14 & 21.63% & 0.69\n",
      "for 2018-03-29, MAE is:5.16 & sMAPE is:16.43% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.13 & 21.57% & 0.69\n",
      "for 2018-03-30, MAE is:2.71 & sMAPE is:7.04% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 21.40% & 0.69\n",
      "for 2018-03-31, MAE is:3.94 & sMAPE is:11.92% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 21.30% & 0.69\n",
      "for 2018-04-01, MAE is:4.40 & sMAPE is:11.99% & rMAE is:2.94 ||| daily mean of MAE & sMAPE & rMAE till now are :6.05 & 21.20% & 0.71\n",
      "for 2018-04-02, MAE is:1.41 & sMAPE is:3.68% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 21.01% & 0.71\n",
      "for 2018-04-03, MAE is:3.21 & sMAPE is:7.67% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :5.97 & 20.86% & 0.70\n",
      "for 2018-04-04, MAE is:5.02 & sMAPE is:15.26% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :5.96 & 20.80% & 0.71\n",
      "for 2018-04-05, MAE is:4.33 & sMAPE is:11.87% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :5.94 & 20.71% & 0.70\n",
      "for 2018-04-06, MAE is:4.46 & sMAPE is:11.99% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :5.93 & 20.62% & 0.71\n",
      "for 2018-04-07, MAE is:17.36 & sMAPE is:79.90% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :6.05 & 21.23% & 0.71\n",
      "for 2018-04-08, MAE is:8.54 & sMAPE is:24.91% & rMAE is:4.93 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 21.27% & 0.75\n",
      "for 2018-04-09, MAE is:3.96 & sMAPE is:8.99% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.05 & 21.14% & 0.75\n",
      "for 2018-04-10, MAE is:3.08 & sMAPE is:8.62% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.02 & 21.02% & 0.75\n",
      "for 2018-04-11, MAE is:5.47 & sMAPE is:18.25% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.02 & 20.99% & 0.75\n",
      "for 2018-04-12, MAE is:7.59 & sMAPE is:24.64% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :6.03 & 21.03% & 0.75\n",
      "for 2018-04-13, MAE is:2.68 & sMAPE is:7.67% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 20.90% & 0.75\n",
      "for 2018-04-14, MAE is:3.66 & sMAPE is:10.01% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :5.98 & 20.79% & 0.75\n",
      "for 2018-04-15, MAE is:3.21 & sMAPE is:8.77% & rMAE is:3.07 ||| daily mean of MAE & sMAPE & rMAE till now are :5.95 & 20.68% & 0.77\n",
      "for 2018-04-16, MAE is:7.79 & sMAPE is:17.02% & rMAE is:1.82 ||| daily mean of MAE & sMAPE & rMAE till now are :5.97 & 20.64% & 0.78\n",
      "for 2018-04-17, MAE is:4.44 & sMAPE is:10.27% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :5.95 & 20.55% & 0.78\n",
      "for 2018-04-18, MAE is:3.99 & sMAPE is:9.49% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :5.93 & 20.44% & 0.78\n",
      "for 2018-04-19, MAE is:3.59 & sMAPE is:9.07% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 20.34% & 0.77\n",
      "for 2018-04-20, MAE is:3.25 & sMAPE is:8.63% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :5.89 & 20.23% & 0.77\n",
      "for 2018-04-21, MAE is:3.68 & sMAPE is:11.82% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :5.87 & 20.16% & 0.77\n",
      "for 2018-04-22, MAE is:4.98 & sMAPE is:15.74% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :5.86 & 20.12% & 0.77\n",
      "for 2018-04-23, MAE is:6.35 & sMAPE is:23.50% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :5.87 & 20.15% & 0.77\n",
      "for 2018-04-24, MAE is:5.48 & sMAPE is:16.22% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :5.86 & 20.11% & 0.77\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-04-25, MAE is:2.74 & sMAPE is:8.80% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :5.84 & 20.02% & 0.77\n",
      "for 2018-04-26, MAE is:4.31 & sMAPE is:13.35% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :5.82 & 19.96% & 0.77\n",
      "for 2018-04-27, MAE is:5.19 & sMAPE is:13.42% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :5.82 & 19.90% & 0.77\n",
      "for 2018-04-28, MAE is:3.43 & sMAPE is:10.20% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :5.80 & 19.82% & 0.77\n",
      "for 2018-04-29, MAE is:2.64 & sMAPE is:8.02% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :5.77 & 19.72% & 0.77\n",
      "for 2018-04-30, MAE is:17.57 & sMAPE is:82.37% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :5.87 & 20.24% & 0.78\n",
      "for 2018-05-01, MAE is:8.54 & sMAPE is:46.18% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :5.89 & 20.46% & 0.78\n",
      "for 2018-05-02, MAE is:7.46 & sMAPE is:23.28% & rMAE is:2.67 ||| daily mean of MAE & sMAPE & rMAE till now are :5.90 & 20.48% & 0.79\n",
      "for 2018-05-03, MAE is:2.76 & sMAPE is:6.96% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 20.37% & 0.79\n",
      "for 2018-05-04, MAE is:6.21 & sMAPE is:15.70% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 20.33% & 0.80\n",
      "for 2018-05-05, MAE is:3.31 & sMAPE is:10.29% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :5.86 & 20.25% & 0.80\n",
      "for 2018-05-06, MAE is:7.61 & sMAPE is:30.43% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :5.87 & 20.33% & 0.80\n",
      "for 2018-05-07, MAE is:7.33 & sMAPE is:22.86% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 20.35% & 0.79\n",
      "for 2018-05-08, MAE is:5.40 & sMAPE is:19.52% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 20.35% & 0.79\n",
      "for 2018-05-09, MAE is:9.46 & sMAPE is:38.80% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 20.49% & 0.79\n",
      "for 2018-05-10, MAE is:9.17 & sMAPE is:60.96% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :5.93 & 20.80% & 0.79\n",
      "for 2018-05-11, MAE is:21.02 & sMAPE is:79.87% & rMAE is:1.67 ||| daily mean of MAE & sMAPE & rMAE till now are :6.05 & 21.25% & 0.79\n",
      "for 2018-05-12, MAE is:3.70 & sMAPE is:11.38% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.03 & 21.18% & 0.80\n",
      "for 2018-05-13, MAE is:5.08 & sMAPE is:27.18% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :6.02 & 21.22% & 0.80\n",
      "for 2018-05-14, MAE is:9.95 & sMAPE is:29.22% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.05 & 21.28% & 0.81\n",
      "for 2018-05-15, MAE is:7.91 & sMAPE is:18.97% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 21.26% & 0.81\n",
      "for 2018-05-16, MAE is:4.19 & sMAPE is:10.81% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.05 & 21.19% & 0.80\n",
      "for 2018-05-17, MAE is:5.45 & sMAPE is:27.20% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.05 & 21.23% & 0.80\n",
      "for 2018-05-18, MAE is:9.00 & sMAPE is:34.64% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 21.33% & 0.81\n",
      "for 2018-05-19, MAE is:4.61 & sMAPE is:12.51% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :6.06 & 21.27% & 0.81\n",
      "for 2018-05-20, MAE is:4.39 & sMAPE is:17.38% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.05 & 21.24% & 0.81\n",
      "for 2018-05-21, MAE is:11.57 & sMAPE is:57.93% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 21.50% & 0.81\n",
      "for 2018-05-22, MAE is:6.61 & sMAPE is:15.10% & rMAE is:1.62 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 21.45% & 0.81\n",
      "for 2018-05-23, MAE is:4.10 & sMAPE is:9.39% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 21.37% & 0.82\n",
      "for 2018-05-24, MAE is:3.00 & sMAPE is:7.85% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.06 & 21.27% & 0.81\n",
      "for 2018-05-25, MAE is:2.97 & sMAPE is:7.70% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :6.03 & 21.18% & 0.81\n",
      "for 2018-05-26, MAE is:1.29 & sMAPE is:3.24% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 21.06% & 0.81\n",
      "for 2018-05-27, MAE is:4.32 & sMAPE is:11.91% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :5.99 & 21.00% & 0.80\n",
      "for 2018-05-28, MAE is:6.28 & sMAPE is:14.97% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :5.99 & 20.96% & 0.80\n",
      "for 2018-05-29, MAE is:2.84 & sMAPE is:6.43% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :5.97 & 20.86% & 0.80\n",
      "for 2018-05-30, MAE is:5.51 & sMAPE is:11.98% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :5.97 & 20.80% & 0.80\n",
      "for 2018-05-31, MAE is:4.51 & sMAPE is:9.42% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :5.96 & 20.72% & 0.80\n",
      "for 2018-06-01, MAE is:9.49 & sMAPE is:17.73% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :5.98 & 20.70% & 0.80\n",
      "for 2018-06-02, MAE is:2.50 & sMAPE is:5.86% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :5.96 & 20.61% & 0.80\n",
      "for 2018-06-03, MAE is:3.41 & sMAPE is:8.51% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :5.94 & 20.53% & 0.80\n",
      "for 2018-06-04, MAE is:3.46 & sMAPE is:8.09% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :5.93 & 20.45% & 0.80\n",
      "for 2018-06-05, MAE is:5.68 & sMAPE is:12.09% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :5.92 & 20.39% & 0.80\n",
      "for 2018-06-06, MAE is:4.99 & sMAPE is:10.16% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :5.92 & 20.33% & 0.81\n",
      "for 2018-06-07, MAE is:5.26 & sMAPE is:10.54% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 20.27% & 0.81\n",
      "for 2018-06-08, MAE is:4.51 & sMAPE is:9.57% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 20.20% & 0.81\n",
      "for 2018-06-09, MAE is:2.25 & sMAPE is:5.08% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 20.11% & 0.80\n",
      "for 2018-06-10, MAE is:4.63 & sMAPE is:10.65% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 20.05% & 0.81\n",
      "for 2018-06-11, MAE is:4.19 & sMAPE is:8.63% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :5.86 & 19.98% & 0.81\n",
      "for 2018-06-12, MAE is:3.15 & sMAPE is:6.47% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :5.85 & 19.89% & 0.81\n",
      "for 2018-06-13, MAE is:2.87 & sMAPE is:5.92% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :5.83 & 19.81% & 0.81\n",
      "for 2018-06-14, MAE is:6.58 & sMAPE is:13.16% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :5.83 & 19.77% & 0.81\n",
      "for 2018-06-15, MAE is:4.18 & sMAPE is:8.47% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :5.82 & 19.70% & 0.81\n",
      "for 2018-06-16, MAE is:1.46 & sMAPE is:3.28% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :5.80 & 19.60% & 0.81\n",
      "for 2018-06-17, MAE is:9.68 & sMAPE is:38.91% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :5.82 & 19.72% & 0.81\n",
      "for 2018-06-18, MAE is:3.35 & sMAPE is:7.43% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :5.81 & 19.64% & 0.82\n",
      "for 2018-06-19, MAE is:4.86 & sMAPE is:11.47% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :5.80 & 19.60% & 0.81\n",
      "for 2018-06-20, MAE is:9.02 & sMAPE is:18.36% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :5.82 & 19.59% & 0.82\n",
      "for 2018-06-21, MAE is:9.72 & sMAPE is:27.47% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :5.84 & 19.63% & 0.82\n",
      "for 2018-06-22, MAE is:12.49 & sMAPE is:49.61% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 19.81% & 0.82\n",
      "for 2018-06-23, MAE is:6.08 & sMAPE is:25.02% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 19.84% & 0.81\n",
      "for 2018-06-24, MAE is:7.27 & sMAPE is:19.04% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :5.89 & 19.83% & 0.81\n",
      "for 2018-06-25, MAE is:2.63 & sMAPE is:5.78% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :5.87 & 19.75% & 0.81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-06-26, MAE is:18.30 & sMAPE is:27.91% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :5.94 & 19.80% & 0.81\n",
      "for 2018-06-27, MAE is:6.16 & sMAPE is:10.93% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :5.94 & 19.75% & 0.81\n",
      "for 2018-06-28, MAE is:3.03 & sMAPE is:6.47% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :5.93 & 19.67% & 0.81\n",
      "for 2018-06-29, MAE is:6.20 & sMAPE is:12.79% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :5.93 & 19.64% & 0.81\n",
      "for 2018-06-30, MAE is:2.25 & sMAPE is:5.13% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 19.56% & 0.80\n",
      "for 2018-07-01, MAE is:3.29 & sMAPE is:7.57% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :5.89 & 19.49% & 0.80\n",
      "for 2018-07-02, MAE is:4.80 & sMAPE is:9.92% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :5.89 & 19.44% & 0.80\n",
      "for 2018-07-03, MAE is:4.44 & sMAPE is:8.60% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 19.38% & 0.80\n",
      "for 2018-07-04, MAE is:4.02 & sMAPE is:7.79% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :5.87 & 19.32% & 0.80\n",
      "for 2018-07-05, MAE is:2.64 & sMAPE is:4.97% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :5.85 & 19.24% & 0.80\n",
      "for 2018-07-06, MAE is:2.13 & sMAPE is:4.35% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :5.83 & 19.16% & 0.80\n",
      "for 2018-07-07, MAE is:9.38 & sMAPE is:28.28% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :5.85 & 19.21% & 0.80\n",
      "for 2018-07-08, MAE is:3.59 & sMAPE is:7.75% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :5.84 & 19.15% & 0.80\n",
      "for 2018-07-09, MAE is:3.90 & sMAPE is:7.79% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :5.83 & 19.09% & 0.80\n",
      "for 2018-07-10, MAE is:3.36 & sMAPE is:6.52% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :5.82 & 19.02% & 0.81\n",
      "for 2018-07-11, MAE is:2.94 & sMAPE is:5.81% & rMAE is:1.88 ||| daily mean of MAE & sMAPE & rMAE till now are :5.80 & 18.95% & 0.81\n",
      "for 2018-07-12, MAE is:2.68 & sMAPE is:5.21% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :5.79 & 18.88% & 0.81\n",
      "for 2018-07-13, MAE is:3.21 & sMAPE is:6.30% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :5.77 & 18.82% & 0.81\n",
      "for 2018-07-14, MAE is:4.45 & sMAPE is:9.05% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :5.76 & 18.77% & 0.81\n",
      "for 2018-07-15, MAE is:2.93 & sMAPE is:5.97% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :5.75 & 18.70% & 0.81\n",
      "for 2018-07-16, MAE is:2.61 & sMAPE is:4.83% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :5.73 & 18.63% & 0.81\n",
      "for 2018-07-17, MAE is:2.99 & sMAPE is:5.83% & rMAE is:1.79 ||| daily mean of MAE & sMAPE & rMAE till now are :5.72 & 18.57% & 0.82\n",
      "for 2018-07-18, MAE is:3.69 & sMAPE is:7.42% & rMAE is:1.96 ||| daily mean of MAE & sMAPE & rMAE till now are :5.71 & 18.51% & 0.82\n",
      "for 2018-07-19, MAE is:3.84 & sMAPE is:7.52% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :5.70 & 18.46% & 0.82\n",
      "for 2018-07-20, MAE is:3.49 & sMAPE is:6.72% & rMAE is:2.00 ||| daily mean of MAE & sMAPE & rMAE till now are :5.69 & 18.40% & 0.83\n",
      "for 2018-07-21, MAE is:3.82 & sMAPE is:7.63% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :5.68 & 18.34% & 0.83\n",
      "for 2018-07-22, MAE is:4.38 & sMAPE is:8.83% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :5.67 & 18.30% & 0.84\n",
      "for 2018-07-23, MAE is:5.38 & sMAPE is:10.20% & rMAE is:4.81 ||| daily mean of MAE & sMAPE & rMAE till now are :5.67 & 18.26% & 0.86\n",
      "for 2018-07-24, MAE is:4.45 & sMAPE is:8.03% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :5.67 & 18.21% & 0.86\n",
      "for 2018-07-25, MAE is:4.77 & sMAPE is:8.39% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :5.66 & 18.16% & 0.86\n",
      "for 2018-07-26, MAE is:2.86 & sMAPE is:5.21% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :5.65 & 18.10% & 0.86\n",
      "for 2018-07-27, MAE is:4.18 & sMAPE is:7.87% & rMAE is:1.97 ||| daily mean of MAE & sMAPE & rMAE till now are :5.64 & 18.05% & 0.86\n",
      "for 2018-07-28, MAE is:1.55 & sMAPE is:3.17% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :5.62 & 17.98% & 0.86\n",
      "for 2018-07-29, MAE is:2.03 & sMAPE is:4.03% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :5.61 & 17.91% & 0.86\n",
      "for 2018-07-30, MAE is:3.16 & sMAPE is:5.78% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :5.59 & 17.85% & 0.87\n",
      "for 2018-07-31, MAE is:4.52 & sMAPE is:8.02% & rMAE is:2.23 ||| daily mean of MAE & sMAPE & rMAE till now are :5.59 & 17.81% & 0.87\n",
      "for 2018-08-01, MAE is:3.82 & sMAPE is:6.72% & rMAE is:2.10 ||| daily mean of MAE & sMAPE & rMAE till now are :5.58 & 17.75% & 0.88\n",
      "for 2018-08-02, MAE is:7.14 & sMAPE is:12.35% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :5.59 & 17.73% & 0.88\n",
      "for 2018-08-03, MAE is:6.39 & sMAPE is:10.28% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :5.59 & 17.69% & 0.88\n",
      "for 2018-08-04, MAE is:3.30 & sMAPE is:6.03% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :5.58 & 17.64% & 0.88\n",
      "for 2018-08-05, MAE is:3.34 & sMAPE is:7.18% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :5.57 & 17.59% & 0.88\n",
      "for 2018-08-06, MAE is:7.22 & sMAPE is:11.41% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :5.58 & 17.56% & 0.88\n",
      "for 2018-08-07, MAE is:4.98 & sMAPE is:7.63% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :5.58 & 17.52% & 0.88\n",
      "for 2018-08-08, MAE is:6.17 & sMAPE is:10.86% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :5.58 & 17.49% & 0.88\n",
      "for 2018-08-09, MAE is:4.02 & sMAPE is:7.36% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :5.57 & 17.44% & 0.88\n",
      "for 2018-08-10, MAE is:6.68 & sMAPE is:18.70% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :5.58 & 17.45% & 0.88\n",
      "for 2018-08-11, MAE is:4.64 & sMAPE is:10.38% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :5.57 & 17.42% & 0.88\n",
      "for 2018-08-12, MAE is:4.96 & sMAPE is:10.18% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :5.57 & 17.38% & 0.88\n",
      "for 2018-08-13, MAE is:3.87 & sMAPE is:6.88% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :5.56 & 17.34% & 0.88\n",
      "for 2018-08-14, MAE is:4.05 & sMAPE is:7.26% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :5.55 & 17.29% & 0.88\n",
      "for 2018-08-15, MAE is:3.60 & sMAPE is:6.41% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :5.55 & 17.25% & 0.88\n",
      "for 2018-08-16, MAE is:5.27 & sMAPE is:9.17% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :5.55 & 17.21% & 0.88\n",
      "for 2018-08-17, MAE is:4.04 & sMAPE is:7.04% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :5.54 & 17.17% & 0.87\n",
      "for 2018-08-18, MAE is:4.66 & sMAPE is:9.14% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :5.53 & 17.13% & 0.87\n",
      "for 2018-08-19, MAE is:5.30 & sMAPE is:10.36% & rMAE is:2.20 ||| daily mean of MAE & sMAPE & rMAE till now are :5.53 & 17.10% & 0.88\n",
      "for 2018-08-20, MAE is:6.43 & sMAPE is:11.52% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :5.54 & 17.08% & 0.88\n",
      "for 2018-08-21, MAE is:12.65 & sMAPE is:20.65% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :5.57 & 17.09% & 0.88\n",
      "for 2018-08-22, MAE is:4.10 & sMAPE is:6.82% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :5.56 & 17.05% & 0.88\n",
      "for 2018-08-23, MAE is:6.58 & sMAPE is:10.65% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :5.57 & 17.02% & 0.88\n",
      "for 2018-08-24, MAE is:6.54 & sMAPE is:11.72% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :5.57 & 17.00% & 0.88\n",
      "for 2018-08-25, MAE is:2.37 & sMAPE is:4.56% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :5.56 & 16.95% & 0.88\n",
      "for 2018-08-26, MAE is:5.98 & sMAPE is:11.61% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.56 & 16.92% & 0.88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-08-27, MAE is:9.33 & sMAPE is:22.37% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :5.57 & 16.95% & 0.88\n",
      "for 2018-08-28, MAE is:14.20 & sMAPE is:23.83% & rMAE is:5.65 ||| daily mean of MAE & sMAPE & rMAE till now are :5.61 & 16.98% & 0.90\n",
      "for 2018-08-29, MAE is:6.05 & sMAPE is:9.49% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :5.61 & 16.94% & 0.90\n",
      "for 2018-08-30, MAE is:4.20 & sMAPE is:7.34% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :5.61 & 16.90% & 0.90\n",
      "for 2018-08-31, MAE is:10.66 & sMAPE is:17.84% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :5.63 & 16.91% & 0.90\n",
      "for 2018-09-01, MAE is:5.30 & sMAPE is:9.20% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :5.63 & 16.88% & 0.90\n",
      "for 2018-09-02, MAE is:3.61 & sMAPE is:6.34% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :5.62 & 16.83% & 0.90\n",
      "for 2018-09-03, MAE is:7.89 & sMAPE is:12.76% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :5.63 & 16.82% & 0.90\n",
      "for 2018-09-04, MAE is:8.21 & sMAPE is:12.77% & rMAE is:3.70 ||| daily mean of MAE & sMAPE & rMAE till now are :5.64 & 16.80% & 0.91\n",
      "for 2018-09-05, MAE is:8.89 & sMAPE is:13.57% & rMAE is:3.40 ||| daily mean of MAE & sMAPE & rMAE till now are :5.65 & 16.79% & 0.92\n",
      "for 2018-09-06, MAE is:5.53 & sMAPE is:8.83% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :5.65 & 16.76% & 0.92\n",
      "for 2018-09-07, MAE is:4.25 & sMAPE is:6.79% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :5.64 & 16.72% & 0.92\n",
      "for 2018-09-08, MAE is:7.01 & sMAPE is:15.56% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :5.65 & 16.71% & 0.92\n",
      "for 2018-09-09, MAE is:9.08 & sMAPE is:18.66% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :5.66 & 16.72% & 0.92\n",
      "for 2018-09-10, MAE is:8.75 & sMAPE is:14.32% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :5.68 & 16.71% & 0.92\n",
      "for 2018-09-11, MAE is:9.03 & sMAPE is:15.69% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :5.69 & 16.71% & 0.92\n",
      "for 2018-09-12, MAE is:5.41 & sMAPE is:9.64% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :5.69 & 16.68% & 0.92\n",
      "for 2018-09-13, MAE is:11.65 & sMAPE is:17.28% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :5.71 & 16.68% & 0.92\n",
      "for 2018-09-14, MAE is:5.46 & sMAPE is:8.70% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :5.71 & 16.65% & 0.92\n",
      "for 2018-09-15, MAE is:5.41 & sMAPE is:9.97% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :5.71 & 16.62% & 0.92\n",
      "for 2018-09-16, MAE is:10.87 & sMAPE is:22.20% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :5.73 & 16.64% & 0.93\n",
      "for 2018-09-17, MAE is:11.65 & sMAPE is:18.59% & rMAE is:2.23 ||| daily mean of MAE & sMAPE & rMAE till now are :5.75 & 16.65% & 0.93\n",
      "for 2018-09-18, MAE is:11.69 & sMAPE is:21.71% & rMAE is:1.99 ||| daily mean of MAE & sMAPE & rMAE till now are :5.77 & 16.67% & 0.94\n",
      "for 2018-09-19, MAE is:7.67 & sMAPE is:15.23% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :5.78 & 16.67% & 0.94\n",
      "for 2018-09-20, MAE is:8.16 & sMAPE is:15.65% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :5.79 & 16.66% & 0.93\n",
      "for 2018-09-21, MAE is:22.76 & sMAPE is:54.09% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :5.85 & 16.80% & 0.93\n",
      "for 2018-09-22, MAE is:14.12 & sMAPE is:81.68% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :5.89 & 17.05% & 0.93\n",
      "for 2018-09-23, MAE is:12.72 & sMAPE is:44.22% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 17.15% & 0.93\n",
      "for 2018-09-24, MAE is:7.72 & sMAPE is:29.09% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :5.92 & 17.20% & 0.93\n",
      "for 2018-09-25, MAE is:10.92 & sMAPE is:20.29% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :5.94 & 17.21% & 0.93\n",
      "for 2018-09-26, MAE is:15.33 & sMAPE is:48.16% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :5.97 & 17.32% & 0.93\n",
      "for 2018-09-27, MAE is:5.01 & sMAPE is:16.28% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :5.97 & 17.32% & 0.93\n",
      "for 2018-09-28, MAE is:2.97 & sMAPE is:7.57% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :5.96 & 17.28% & 0.93\n",
      "for 2018-09-29, MAE is:6.86 & sMAPE is:17.88% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :5.96 & 17.28% & 0.92\n",
      "for 2018-09-30, MAE is:11.29 & sMAPE is:26.44% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :5.98 & 17.32% & 0.92\n",
      "for 2018-10-01, MAE is:5.84 & sMAPE is:9.79% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :5.98 & 17.29% & 0.92\n",
      "for 2018-10-02, MAE is:12.88 & sMAPE is:32.50% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 17.35% & 0.92\n",
      "for 2018-10-03, MAE is:24.05 & sMAPE is:143.69% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 17.80% & 0.92\n",
      "for 2018-10-04, MAE is:10.74 & sMAPE is:17.74% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 17.80% & 0.92\n",
      "for 2018-10-05, MAE is:10.10 & sMAPE is:16.84% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.10 & 17.80% & 0.92\n",
      "for 2018-10-06, MAE is:9.46 & sMAPE is:17.43% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.11 & 17.80% & 0.92\n",
      "for 2018-10-07, MAE is:6.06 & sMAPE is:10.51% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.11 & 17.77% & 0.91\n",
      "for 2018-10-08, MAE is:12.84 & sMAPE is:23.26% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :6.14 & 17.79% & 0.91\n",
      "for 2018-10-09, MAE is:6.49 & sMAPE is:13.36% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.14 & 17.78% & 0.91\n",
      "for 2018-10-10, MAE is:11.94 & sMAPE is:20.05% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.16 & 17.78% & 0.91\n",
      "for 2018-10-11, MAE is:12.34 & sMAPE is:25.48% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.18 & 17.81% & 0.91\n",
      "for 2018-10-12, MAE is:4.11 & sMAPE is:10.07% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :6.17 & 17.78% & 0.91\n",
      "for 2018-10-13, MAE is:9.72 & sMAPE is:26.33% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.19 & 17.81% & 0.91\n",
      "for 2018-10-14, MAE is:11.45 & sMAPE is:68.17% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.20 & 17.99% & 0.90\n",
      "for 2018-10-15, MAE is:26.84 & sMAPE is:68.84% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :6.28 & 18.17% & 0.90\n",
      "for 2018-10-16, MAE is:18.85 & sMAPE is:29.27% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.32 & 18.21% & 0.90\n",
      "for 2018-10-17, MAE is:16.86 & sMAPE is:24.63% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.36 & 18.23% & 0.91\n",
      "for 2018-10-18, MAE is:7.80 & sMAPE is:12.53% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.36 & 18.21% & 0.90\n",
      "for 2018-10-19, MAE is:11.77 & sMAPE is:17.90% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.38 & 18.21% & 0.90\n",
      "for 2018-10-20, MAE is:5.75 & sMAPE is:10.86% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.38 & 18.18% & 0.90\n",
      "for 2018-10-21, MAE is:6.62 & sMAPE is:14.47% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.38 & 18.17% & 0.90\n",
      "for 2018-10-22, MAE is:9.16 & sMAPE is:23.68% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 18.19% & 0.90\n",
      "for 2018-10-23, MAE is:7.64 & sMAPE is:27.62% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 18.22% & 0.89\n",
      "for 2018-10-24, MAE is:10.69 & sMAPE is:48.78% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 18.32% & 0.89\n",
      "for 2018-10-25, MAE is:3.17 & sMAPE is:8.23% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 18.29% & 0.89\n",
      "for 2018-10-26, MAE is:7.09 & sMAPE is:12.38% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 18.27% & 0.89\n",
      "for 2018-10-27, MAE is:5.80 & sMAPE is:15.23% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 18.26% & 0.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-10-28, MAE is:2.01 & sMAPE is:4.57% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.38 & 18.21% & 0.89\n",
      "for 2018-10-29, MAE is:13.66 & sMAPE is:32.09% & rMAE is:2.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 18.26% & 0.89\n",
      "for 2018-10-30, MAE is:6.24 & sMAPE is:19.04% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 18.26% & 0.89\n",
      "for 2018-10-31, MAE is:8.79 & sMAPE is:17.26% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 18.26% & 0.89\n",
      "for 2018-11-01, MAE is:6.39 & sMAPE is:12.56% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 18.24% & 0.89\n",
      "for 2018-11-02, MAE is:4.64 & sMAPE is:9.55% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 18.21% & 0.89\n",
      "for 2018-11-03, MAE is:11.90 & sMAPE is:25.10% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 18.23% & 0.89\n",
      "for 2018-11-04, MAE is:3.99 & sMAPE is:8.10% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 18.20% & 0.89\n",
      "for 2018-11-05, MAE is:7.01 & sMAPE is:12.12% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 18.18% & 0.89\n",
      "for 2018-11-06, MAE is:7.72 & sMAPE is:13.21% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 18.17% & 0.89\n",
      "for 2018-11-07, MAE is:5.59 & sMAPE is:10.03% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 18.14% & 0.89\n",
      "for 2018-11-08, MAE is:12.23 & sMAPE is:20.34% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :6.44 & 18.15% & 0.89\n",
      "for 2018-11-09, MAE is:5.42 & sMAPE is:10.03% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.44 & 18.12% & 0.89\n",
      "for 2018-11-10, MAE is:2.09 & sMAPE is:4.94% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 18.08% & 0.88\n",
      "for 2018-11-11, MAE is:2.70 & sMAPE is:6.92% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 18.04% & 0.88\n",
      "for 2018-11-12, MAE is:7.27 & sMAPE is:13.82% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 18.03% & 0.88\n",
      "for 2018-11-13, MAE is:3.16 & sMAPE is:6.34% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 17.99% & 0.88\n",
      "for 2018-11-14, MAE is:10.64 & sMAPE is:18.49% & rMAE is:3.00 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 17.99% & 0.89\n",
      "for 2018-11-15, MAE is:9.03 & sMAPE is:14.97% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 17.98% & 0.89\n",
      "for 2018-11-16, MAE is:6.89 & sMAPE is:12.36% & rMAE is:2.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.43 & 17.97% & 0.89\n",
      "for 2018-11-17, MAE is:3.91 & sMAPE is:7.96% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 17.94% & 0.89\n",
      "for 2018-11-18, MAE is:1.97 & sMAPE is:4.18% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 17.89% & 0.89\n",
      "for 2018-11-19, MAE is:5.65 & sMAPE is:11.10% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 17.87% & 0.89\n",
      "for 2018-11-20, MAE is:4.92 & sMAPE is:12.00% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 17.85% & 0.89\n",
      "for 2018-11-21, MAE is:3.80 & sMAPE is:7.41% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 17.82% & 0.89\n",
      "for 2018-11-22, MAE is:19.40 & sMAPE is:27.21% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.43 & 17.85% & 0.89\n",
      "for 2018-11-23, MAE is:18.96 & sMAPE is:24.68% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 17.87% & 0.89\n",
      "for 2018-11-24, MAE is:6.67 & sMAPE is:10.70% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 17.85% & 0.89\n",
      "for 2018-11-25, MAE is:3.67 & sMAPE is:6.63% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 17.82% & 0.89\n",
      "for 2018-11-26, MAE is:17.39 & sMAPE is:23.77% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 17.83% & 0.89\n",
      "for 2018-11-27, MAE is:14.52 & sMAPE is:19.34% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.52 & 17.84% & 0.89\n",
      "for 2018-11-28, MAE is:14.63 & sMAPE is:24.36% & rMAE is:2.90 ||| daily mean of MAE & sMAPE & rMAE till now are :6.54 & 17.86% & 0.90\n",
      "for 2018-11-29, MAE is:6.74 & sMAPE is:13.60% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.54 & 17.84% & 0.89\n",
      "for 2018-11-30, MAE is:2.32 & sMAPE is:5.05% & rMAE is:0.07 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 17.81% & 0.89\n",
      "for 2018-12-01, MAE is:4.49 & sMAPE is:10.72% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.52 & 17.79% & 0.89\n",
      "for 2018-12-02, MAE is:8.74 & sMAPE is:27.09% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 17.81% & 0.89\n",
      "for 2018-12-03, MAE is:3.64 & sMAPE is:7.70% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :6.52 & 17.78% & 0.89\n",
      "for 2018-12-04, MAE is:5.48 & sMAPE is:12.57% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :6.52 & 17.77% & 0.88\n",
      "for 2018-12-05, MAE is:4.26 & sMAPE is:7.95% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 17.74% & 0.88\n",
      "for 2018-12-06, MAE is:3.81 & sMAPE is:7.39% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 17.71% & 0.88\n",
      "for 2018-12-07, MAE is:5.74 & sMAPE is:14.61% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 17.70% & 0.88\n",
      "for 2018-12-08, MAE is:18.79 & sMAPE is:98.65% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :6.54 & 17.94% & 0.88\n",
      "for 2018-12-09, MAE is:12.06 & sMAPE is:91.79% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 18.15% & 0.88\n",
      "for 2018-12-10, MAE is:14.52 & sMAPE is:65.69% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 18.29% & 0.88\n",
      "for 2018-12-11, MAE is:12.20 & sMAPE is:28.87% & rMAE is:2.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.59 & 18.32% & 0.89\n",
      "for 2018-12-12, MAE is:14.28 & sMAPE is:24.26% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 18.34% & 0.89\n",
      "for 2018-12-13, MAE is:5.00 & sMAPE is:8.27% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 18.31% & 0.89\n",
      "for 2018-12-14, MAE is:6.40 & sMAPE is:10.72% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 18.29% & 0.89\n",
      "for 2018-12-15, MAE is:4.53 & sMAPE is:8.73% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :6.60 & 18.26% & 0.89\n",
      "for 2018-12-16, MAE is:4.90 & sMAPE is:10.45% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.60 & 18.24% & 0.88\n",
      "for 2018-12-17, MAE is:8.91 & sMAPE is:13.35% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.60 & 18.22% & 0.88\n",
      "for 2018-12-18, MAE is:5.64 & sMAPE is:9.50% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.60 & 18.20% & 0.88\n",
      "for 2018-12-19, MAE is:4.82 & sMAPE is:9.64% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.60 & 18.17% & 0.88\n",
      "for 2018-12-20, MAE is:4.44 & sMAPE is:7.76% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :6.59 & 18.14% & 0.88\n",
      "for 2018-12-21, MAE is:2.29 & sMAPE is:4.32% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 18.11% & 0.88\n",
      "for 2018-12-22, MAE is:3.19 & sMAPE is:6.34% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.57 & 18.07% & 0.88\n",
      "for 2018-12-23, MAE is:4.54 & sMAPE is:8.80% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 18.05% & 0.88\n",
      "for 2018-12-24, MAE is:3.75 & sMAPE is:8.03% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 18.02% & 0.88\n",
      "for 2018-12-25, MAE is:23.70 & sMAPE is:92.23% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.60 & 18.23% & 0.88\n",
      "for 2018-12-26, MAE is:12.14 & sMAPE is:30.97% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 18.26% & 0.88\n",
      "for 2018-12-27, MAE is:4.65 & sMAPE is:9.64% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 18.24% & 0.88\n",
      "for 2018-12-28, MAE is:8.80 & sMAPE is:17.89% & rMAE is:2.73 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 18.24% & 0.88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-12-29, MAE is:6.17 & sMAPE is:17.97% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 18.23% & 0.89\n",
      "for 2018-12-30, MAE is:18.21 & sMAPE is:74.20% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 18.39% & 0.89\n",
      "for 2018-12-31, MAE is:4.77 & sMAPE is:10.88% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 18.37% & 0.89\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:08:34,259]\u001b[0m A new study created in RDB with name: DK_1_2019\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:08:49,531]\u001b[0m Trial 2 finished with value: 16.31842775998391 and parameters: {'n_hidden': 3, 'learning_rate': 0.08408607298378647, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36982055167986005, 'dropout_rate_Layer_2': 0.2718645712879357, 'dropout_rate_Layer_3': 0.05387248571753629, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.09710870876898092, 'l1_Layer_2': 0.00014033685746877542, 'l1_Layer_3': 0.0004025006361924325, 'n_units_Layer_1': 75, 'n_units_Layer_2': 245, 'n_units_Layer_3': 240}. Best is trial 2 with value: 16.31842775998391.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.32 | sMAPE for Validation Set is: 42.67% | rMAE for Validation Set is: 1.55\n",
      "MAE for Test Set is: 11.31 | sMAPE for Test Set is: 33.53% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:08:53,224]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:09:09,050]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:09:15,145]\u001b[0m Trial 3 finished with value: 8.642762070761046 and parameters: {'n_hidden': 3, 'learning_rate': 0.0831048643159757, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3177086005833897, 'dropout_rate_Layer_2': 0.17320179762786944, 'dropout_rate_Layer_3': 0.2758949442837541, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.06382604463283077, 'l1_Layer_2': 1.2642680589845762e-05, 'l1_Layer_3': 0.00033373380291394167, 'n_units_Layer_1': 125, 'n_units_Layer_2': 220, 'n_units_Layer_3': 65}. Best is trial 3 with value: 8.642762070761046.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.64 | sMAPE for Validation Set is: 23.12% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 7.45 | sMAPE for Test Set is: 23.31% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:09:20,607]\u001b[0m Trial 0 finished with value: 8.14325887091555 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006044752726955805, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.391924075487015, 'dropout_rate_Layer_2': 0.1952136056636606, 'dropout_rate_Layer_3': 0.1666060963968269, 'dropout_rate_Layer_4': 0.08134575462498224, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.004738955728533929, 'l1_Layer_2': 0.0001796155392957706, 'l1_Layer_3': 0.0013469187820025867, 'l1_Layer_4': 3.914810302101972e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 150, 'n_units_Layer_3': 260, 'n_units_Layer_4': 245}. Best is trial 0 with value: 8.14325887091555.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.14 | sMAPE for Validation Set is: 21.23% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 6.39 | sMAPE for Test Set is: 20.16% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:09:41,105]\u001b[0m Trial 7 finished with value: 7.358447475868452 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011509260372319808, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.024251383708232457, 'dropout_rate_Layer_2': 0.05172543907394918, 'dropout_rate_Layer_3': 0.24101832612548812, 'dropout_rate_Layer_4': 0.04252973536644525, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.08352374765833788, 'l1_Layer_2': 0.0023060456424064844, 'l1_Layer_3': 0.013474705077672193, 'l1_Layer_4': 0.001781715634607541, 'n_units_Layer_1': 60, 'n_units_Layer_2': 155, 'n_units_Layer_3': 200, 'n_units_Layer_4': 215}. Best is trial 7 with value: 7.358447475868452.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.36 | sMAPE for Validation Set is: 19.78% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 7.75 | sMAPE for Test Set is: 23.75% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:09:45,137]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:09:45,822]\u001b[0m Trial 8 finished with value: 16.30203769623456 and parameters: {'n_hidden': 4, 'learning_rate': 0.027976579445918633, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05233133809689239, 'dropout_rate_Layer_2': 0.11122383927698683, 'dropout_rate_Layer_3': 0.06774611096251247, 'dropout_rate_Layer_4': 0.0517578518433198, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 1.0638173761226215e-05, 'l1_Layer_2': 0.030639975909502865, 'l1_Layer_3': 0.009833419797065913, 'l1_Layer_4': 0.0007103477144699994, 'n_units_Layer_1': 85, 'n_units_Layer_2': 140, 'n_units_Layer_3': 300, 'n_units_Layer_4': 265}. Best is trial 7 with value: 7.358447475868452.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.30 | sMAPE for Validation Set is: 42.57% | rMAE for Validation Set is: 1.55\n",
      "MAE for Test Set is: 11.30 | sMAPE for Test Set is: 33.46% | rMAE for Test Set is: 1.26\n",
      "MAE for Validation Set is: 7.77 | sMAPE for Validation Set is: 20.48% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 7.21 | sMAPE for Test Set is: 22.08% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:09:49,490]\u001b[0m Trial 1 finished with value: 7.7675909253183475 and parameters: {'n_hidden': 3, 'learning_rate': 0.00231089452725189, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19312935456261737, 'dropout_rate_Layer_2': 0.3124281006609268, 'dropout_rate_Layer_3': 0.34389175649414505, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0058249903548617575, 'l1_Layer_2': 0.07886754428842853, 'l1_Layer_3': 0.0005478730429936896, 'n_units_Layer_1': 200, 'n_units_Layer_2': 215, 'n_units_Layer_3': 210}. Best is trial 7 with value: 7.358447475868452.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:09:49,942]\u001b[0m Trial 6 finished with value: 14.538259541566589 and parameters: {'n_hidden': 4, 'learning_rate': 0.0179036081978187, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22036087928687975, 'dropout_rate_Layer_2': 0.35831323671603843, 'dropout_rate_Layer_3': 0.36756711133619024, 'dropout_rate_Layer_4': 0.04409795896581392, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00123586854215762, 'l1_Layer_2': 0.00025662027892120665, 'l1_Layer_3': 0.0343080834829963, 'l1_Layer_4': 0.00029388971977359677, 'n_units_Layer_1': 270, 'n_units_Layer_2': 185, 'n_units_Layer_3': 270, 'n_units_Layer_4': 110}. Best is trial 7 with value: 7.358447475868452.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.54 | sMAPE for Validation Set is: 37.70% | rMAE for Validation Set is: 1.38\n",
      "MAE for Test Set is: 9.99 | sMAPE for Test Set is: 30.00% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:09:55,930]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:09:59,138]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:09:59,290]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:09:59,695]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:10:06,837]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:10:12,956]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:10:13,391]\u001b[0m Trial 15 finished with value: 11.279812901450716 and parameters: {'n_hidden': 3, 'learning_rate': 0.017019529492409553, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35645847416656207, 'dropout_rate_Layer_2': 0.1303723322325981, 'dropout_rate_Layer_3': 0.39627179355497366, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0002520749320943457, 'l1_Layer_2': 2.986191802996698e-05, 'l1_Layer_3': 4.605722830905487e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 245, 'n_units_Layer_3': 230}. Best is trial 7 with value: 7.358447475868452.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.28 | sMAPE for Validation Set is: 28.40% | rMAE for Validation Set is: 1.07\n",
      "MAE for Test Set is: 7.64 | sMAPE for Test Set is: 22.72% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:10:18,635]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:10:23,135]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:10:23,646]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:10:23,735]\u001b[0m Trial 18 finished with value: 9.54218157122699 and parameters: {'n_hidden': 4, 'learning_rate': 0.017792638863989938, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.384784393874236, 'dropout_rate_Layer_2': 0.11583015234605148, 'dropout_rate_Layer_3': 0.32086899675438313, 'dropout_rate_Layer_4': 0.34977558058287467, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0011902708726561025, 'l1_Layer_2': 0.0007565527984435533, 'l1_Layer_3': 6.296181789924584e-05, 'l1_Layer_4': 0.00024411802082712454, 'n_units_Layer_1': 130, 'n_units_Layer_2': 205, 'n_units_Layer_3': 150, 'n_units_Layer_4': 115}. Best is trial 7 with value: 7.358447475868452.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.54 | sMAPE for Validation Set is: 24.29% | rMAE for Validation Set is: 0.91\n",
      "MAE for Test Set is: 7.75 | sMAPE for Test Set is: 23.16% | rMAE for Test Set is: 0.86\n",
      "MAE for Validation Set is: 6.77 | sMAPE for Validation Set is: 18.41% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.49 | sMAPE for Test Set is: 20.27% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:10:29,048]\u001b[0m Trial 17 finished with value: 6.769707766147522 and parameters: {'n_hidden': 3, 'learning_rate': 0.006168409538383416, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08375567569961194, 'dropout_rate_Layer_2': 0.05600176266339823, 'dropout_rate_Layer_3': 0.32464649164067816, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.033691245933229565, 'l1_Layer_2': 0.04194561307580373, 'l1_Layer_3': 2.3689964915174908e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 105, 'n_units_Layer_3': 240}. Best is trial 17 with value: 6.769707766147522.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:10:31,369]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:10:35,730]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:10:37,541]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:10:38,053]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:10:39,714]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:10:43,596]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:10:48,378]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:10:54,041]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:10:54,909]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.18 | sMAPE for Validation Set is: 33.88% | rMAE for Validation Set is: 1.26\n",
      "MAE for Test Set is: 9.08 | sMAPE for Test Set is: 26.78% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:10:56,112]\u001b[0m Trial 28 finished with value: 13.18131247912927 and parameters: {'n_hidden': 4, 'learning_rate': 0.0471506712389874, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28982350027722337, 'dropout_rate_Layer_2': 0.06714234346674167, 'dropout_rate_Layer_3': 0.39919698383211766, 'dropout_rate_Layer_4': 0.02122456531204886, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.016612603662143524, 'l1_Layer_2': 0.00030021022169599183, 'l1_Layer_3': 0.0001295728459333639, 'l1_Layer_4': 0.008088221658462015, 'n_units_Layer_1': 270, 'n_units_Layer_2': 145, 'n_units_Layer_3': 250, 'n_units_Layer_4': 125}. Best is trial 17 with value: 6.769707766147522.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:11:01,728]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:11:01,997]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:11:02,141]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:11:11,156]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:11:12,839]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:11:12,950]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:11:17,928]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:11:21,016]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:11:24,720]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:11:25,072]\u001b[0m Trial 29 finished with value: 12.125627663268725 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030960553749439378, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3710016105157323, 'dropout_rate_Layer_2': 0.13706291667716872, 'dropout_rate_Layer_3': 0.1627487345709091, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.08177662041860591, 'l1_Layer_2': 1.9760238948263527e-05, 'l1_Layer_3': 0.011371831101319464, 'n_units_Layer_1': 220, 'n_units_Layer_2': 235, 'n_units_Layer_3': 60}. Best is trial 17 with value: 6.769707766147522.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.13 | sMAPE for Validation Set is: 30.83% | rMAE for Validation Set is: 1.15\n",
      "MAE for Test Set is: 8.17 | sMAPE for Test Set is: 24.36% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:11:28,450]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:11:30,301]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:11:32,467]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:11:36,693]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:11:37,142]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:11:42,729]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:11:46,395]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:11:46,658]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:11:53,281]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:11:53,475]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:12:06,918]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:12:07,796]\u001b[0m Trial 49 finished with value: 6.640680239407044 and parameters: {'n_hidden': 4, 'learning_rate': 0.001916600933132191, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1651389278245147, 'dropout_rate_Layer_2': 0.28050623426106597, 'dropout_rate_Layer_3': 0.28397148499961744, 'dropout_rate_Layer_4': 0.1729471890230428, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.000728047572055346, 'l1_Layer_2': 5.567578122792275e-05, 'l1_Layer_3': 9.729929799973831e-05, 'l1_Layer_4': 0.03182975099485374, 'n_units_Layer_1': 115, 'n_units_Layer_2': 140, 'n_units_Layer_3': 235, 'n_units_Layer_4': 225}. Best is trial 49 with value: 6.640680239407044.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.64 | sMAPE for Validation Set is: 18.17% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.27 | sMAPE for Test Set is: 19.84% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:12:12,397]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:12:12,616]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:12:12,759]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:12:19,885]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:12:20,298]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:12:20,504]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:12:26,565]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:12:27,077]\u001b[0m Trial 41 finished with value: 7.921708600024938 and parameters: {'n_hidden': 3, 'learning_rate': 0.010350047153816242, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13376361002669307, 'dropout_rate_Layer_2': 0.3063697920828156, 'dropout_rate_Layer_3': 0.3249508743562346, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1521410504974052e-05, 'l1_Layer_2': 0.00023010652880466414, 'l1_Layer_3': 1.6434162999500472e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 80, 'n_units_Layer_3': 190}. Best is trial 49 with value: 6.640680239407044.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.92 | sMAPE for Validation Set is: 20.96% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 6.87 | sMAPE for Test Set is: 21.06% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:12:29,702]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:12:34,128]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:12:38,986]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:12:42,005]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:12:42,313]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:12:43,791]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:12:45,524]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:12:49,271]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:12:51,206]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:12:52,419]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:12:55,711]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:13:00,698]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:13:08,807]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:13:10,336]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:13:14,343]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:13:17,739]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:13:21,777]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:13:23,885]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:13:25,343]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:13:25,903]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:13:31,409]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:13:32,075]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:13:36,121]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:13:37,751]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:13:40,212]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:13:40,565]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:13:49,441]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:13:53,102]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:13:56,106]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:13:59,546]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:14:03,331]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:14:15,198]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:14:37,582]\u001b[0m Trial 95 finished with value: 6.58528371663067 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020978525593879456, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0850611810592613, 'dropout_rate_Layer_2': 0.18898257289512493, 'dropout_rate_Layer_3': 0.3971504452024073, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.02712300700257344, 'l1_Layer_2': 0.007156869030240655, 'l1_Layer_3': 0.006929551296598765, 'n_units_Layer_1': 160, 'n_units_Layer_2': 85, 'n_units_Layer_3': 245}. Best is trial 95 with value: 6.58528371663067.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:14:37,726]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.59 | sMAPE for Validation Set is: 18.12% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.60 | sMAPE for Test Set is: 20.84% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:14:45,462]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:14:47,840]\u001b[0m Trial 97 finished with value: 6.670077702031233 and parameters: {'n_hidden': 3, 'learning_rate': 0.002328311708912751, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07422728668932618, 'dropout_rate_Layer_2': 0.14584369544772563, 'dropout_rate_Layer_3': 0.384780249547476, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0057231054737988925, 'l1_Layer_2': 0.05950737153373819, 'l1_Layer_3': 0.009798949565252292, 'n_units_Layer_1': 170, 'n_units_Layer_2': 90, 'n_units_Layer_3': 245}. Best is trial 95 with value: 6.58528371663067.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.67 | sMAPE for Validation Set is: 18.31% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.56 | sMAPE for Test Set is: 20.72% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:14:49,768]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:15:00,922]\u001b[0m Trial 70 finished with value: 6.827402799371455 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016009795826460733, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.321698023133581, 'dropout_rate_Layer_2': 0.3484472150204975, 'dropout_rate_Layer_3': 0.1886197002479232, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.6190115051062337e-05, 'l1_Layer_2': 0.0015794419063415244, 'l1_Layer_3': 0.06957403662545558, 'n_units_Layer_1': 60, 'n_units_Layer_2': 300, 'n_units_Layer_3': 110}. Best is trial 95 with value: 6.58528371663067.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.83 | sMAPE for Validation Set is: 18.68% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.57 | sMAPE for Test Set is: 20.88% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:15:04,581]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:15:14,322]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:15:17,578]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:15:23,966]\u001b[0m Trial 98 finished with value: 6.308491790554378 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016036180858503472, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13220751670038827, 'dropout_rate_Layer_2': 0.14526414957235181, 'dropout_rate_Layer_3': 0.38112256789825183, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005068674310468575, 'l1_Layer_2': 0.04399506843457636, 'l1_Layer_3': 7.993152481590238e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 70, 'n_units_Layer_3': 260}. Best is trial 98 with value: 6.308491790554378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.31 | sMAPE for Validation Set is: 17.46% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.52 | sMAPE for Test Set is: 20.63% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:15:30,271]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:15:32,571]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:15:38,020]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:15:43,011]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:15:49,084]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:16:11,453]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:16:14,874]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:16:20,341]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:16:24,555]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:16:24,768]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:16:25,302]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:16:30,027]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:16:32,638]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:16:35,714]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:16:38,877]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:16:43,211]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:16:48,197]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:16:48,302]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:16:54,899]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:16:58,883]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:17:01,305]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:17:04,732]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:17:11,222]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:17:11,330]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:17:16,265]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:17:19,602]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:17:27,620]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:17:31,763]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:17:35,921]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:17:40,057]\u001b[0m Trial 121 finished with value: 11.085532558688017 and parameters: {'n_hidden': 3, 'learning_rate': 0.07144135378904172, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00010610682980152775, 'dropout_rate_Layer_2': 0.2585358824678658, 'dropout_rate_Layer_3': 0.2489451376067915, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0007872873499595071, 'l1_Layer_2': 6.60601887708813e-05, 'l1_Layer_3': 1.484284027917648e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 50, 'n_units_Layer_3': 300}. Best is trial 98 with value: 6.308491790554378.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:17:40,185]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.09 | sMAPE for Validation Set is: 28.31% | rMAE for Validation Set is: 1.06\n",
      "MAE for Test Set is: 7.99 | sMAPE for Test Set is: 24.11% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:17:47,572]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:17:51,658]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:17:55,143]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:17:57,543]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:18:01,518]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:18:02,966]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:18:16,488]\u001b[0m Trial 128 finished with value: 6.971704205446625 and parameters: {'n_hidden': 3, 'learning_rate': 0.004206422590985749, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19808098022399226, 'dropout_rate_Layer_2': 0.2153479505639253, 'dropout_rate_Layer_3': 0.30296467890292206, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.347785093717403e-05, 'l1_Layer_2': 0.06454627919138944, 'l1_Layer_3': 0.03976551422785922, 'n_units_Layer_1': 110, 'n_units_Layer_2': 130, 'n_units_Layer_3': 160}. Best is trial 98 with value: 6.308491790554378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.97 | sMAPE for Validation Set is: 18.96% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.48 | sMAPE for Test Set is: 20.70% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:19:08,278]\u001b[0m Trial 139 finished with value: 6.474030546481051 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010125373841866328, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17705937138756989, 'dropout_rate_Layer_2': 0.39593219393199447, 'dropout_rate_Layer_3': 0.006524916415376003, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.1664514123200425e-05, 'l1_Layer_2': 0.00012908902346688, 'l1_Layer_3': 0.028820372606916774, 'n_units_Layer_1': 95, 'n_units_Layer_2': 165, 'n_units_Layer_3': 290}. Best is trial 98 with value: 6.308491790554378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.47 | sMAPE for Validation Set is: 17.79% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.16 | sMAPE for Test Set is: 20.00% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:19:11,468]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:19:12,459]\u001b[0m Trial 144 finished with value: 6.332545388408657 and parameters: {'n_hidden': 3, 'learning_rate': 0.00544461163360321, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28806723976153314, 'dropout_rate_Layer_2': 0.03449610539099829, 'dropout_rate_Layer_3': 0.22224027679641212, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.8155775638015794e-05, 'l1_Layer_2': 0.004584968113939608, 'l1_Layer_3': 0.0009388241897195942, 'n_units_Layer_1': 135, 'n_units_Layer_2': 275, 'n_units_Layer_3': 135}. Best is trial 98 with value: 6.308491790554378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.33 | sMAPE for Validation Set is: 17.39% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.28 | sMAPE for Test Set is: 19.93% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:19:12,701]\u001b[0m Trial 143 finished with value: 6.506532596406878 and parameters: {'n_hidden': 3, 'learning_rate': 0.005357854604209642, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2899265732049303, 'dropout_rate_Layer_2': 0.05830732212077955, 'dropout_rate_Layer_3': 0.35069071578122324, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.1592113017746066e-05, 'l1_Layer_2': 0.0043061642459786865, 'l1_Layer_3': 0.0006278536190846611, 'n_units_Layer_1': 125, 'n_units_Layer_2': 285, 'n_units_Layer_3': 190}. Best is trial 98 with value: 6.308491790554378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.51 | sMAPE for Validation Set is: 17.59% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.19 | sMAPE for Test Set is: 19.74% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:19:20,159]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:19:24,304]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:19:25,162]\u001b[0m Trial 145 finished with value: 6.985639280522558 and parameters: {'n_hidden': 3, 'learning_rate': 0.006498556192592775, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.185041567877621, 'dropout_rate_Layer_2': 0.3787614956067652, 'dropout_rate_Layer_3': 0.0009108099801497793, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.031415172352834e-05, 'l1_Layer_2': 0.08985291047275043, 'l1_Layer_3': 0.03446046133832726, 'n_units_Layer_1': 95, 'n_units_Layer_2': 100, 'n_units_Layer_3': 85}. Best is trial 98 with value: 6.308491790554378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.99 | sMAPE for Validation Set is: 18.90% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.50 | sMAPE for Test Set is: 20.50% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:19:34,266]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:19:36,276]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:19:39,930]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:19:42,744]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:19:43,272]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:19:45,214]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:19:50,260]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:19:53,325]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:19:53,934]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:19:55,473]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:20:00,501]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:20:05,927]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:20:10,996]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:20:15,015]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:20:20,309]\u001b[0m Trial 151 finished with value: 5.956430806639696 and parameters: {'n_hidden': 3, 'learning_rate': 0.003647128947073168, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.036359836294933556, 'dropout_rate_Layer_2': 0.13740605763675393, 'dropout_rate_Layer_3': 0.36379652708591903, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0036486528015158256, 'l1_Layer_2': 0.0002852620269807138, 'l1_Layer_3': 0.000584234008771414, 'n_units_Layer_1': 190, 'n_units_Layer_2': 50, 'n_units_Layer_3': 95}. Best is trial 151 with value: 5.956430806639696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.96 | sMAPE for Validation Set is: 16.35% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.84 | sMAPE for Test Set is: 18.79% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:20:29,095]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:20:37,633]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:20:39,992]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:20:44,786]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:20:49,266]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:20:52,891]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:20:58,259]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:20:59,777]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:21:06,458]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:21:14,327]\u001b[0m Trial 164 finished with value: 6.424377332026872 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009648422343202334, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2479034157258717, 'dropout_rate_Layer_2': 0.3409692574235226, 'dropout_rate_Layer_3': 0.002789246946441837, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.180499860709825e-05, 'l1_Layer_2': 0.0001230806342305267, 'l1_Layer_3': 0.0029259553653543393, 'n_units_Layer_1': 150, 'n_units_Layer_2': 180, 'n_units_Layer_3': 295}. Best is trial 151 with value: 5.956430806639696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.42 | sMAPE for Validation Set is: 17.81% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.03 | sMAPE for Test Set is: 19.56% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:21:18,582]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:21:22,926]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:21:23,043]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:21:35,104]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:21:42,216]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:21:46,519]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:21:58,787]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:22:02,880]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:22:26,405]\u001b[0m Trial 185 finished with value: 6.803660202687069 and parameters: {'n_hidden': 4, 'learning_rate': 0.009420804105321754, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14138461901796684, 'dropout_rate_Layer_2': 0.14836496085180229, 'dropout_rate_Layer_3': 0.3163342597826671, 'dropout_rate_Layer_4': 0.0937691765051167, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.001462099529033428, 'l1_Layer_2': 0.07073028716030057, 'l1_Layer_3': 6.26061901731953e-05, 'l1_Layer_4': 0.00018251700279955008, 'n_units_Layer_1': 300, 'n_units_Layer_2': 290, 'n_units_Layer_3': 225, 'n_units_Layer_4': 220}. Best is trial 151 with value: 5.956430806639696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.80 | sMAPE for Validation Set is: 18.50% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.61 | sMAPE for Test Set is: 20.80% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:22:29,026]\u001b[0m Trial 181 finished with value: 6.40100362410037 and parameters: {'n_hidden': 3, 'learning_rate': 0.002760792818207433, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26671397560806287, 'dropout_rate_Layer_2': 0.14592827803741187, 'dropout_rate_Layer_3': 0.12160076781500703, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015278746561246749, 'l1_Layer_2': 1.1426766551941628e-05, 'l1_Layer_3': 0.00015288640352837597, 'n_units_Layer_1': 165, 'n_units_Layer_2': 300, 'n_units_Layer_3': 140}. Best is trial 151 with value: 5.956430806639696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.40 | sMAPE for Validation Set is: 17.64% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.15 | sMAPE for Test Set is: 19.87% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:22:30,051]\u001b[0m Trial 179 finished with value: 6.6983076143042775 and parameters: {'n_hidden': 4, 'learning_rate': 0.005381400902158411, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.057276077840288764, 'dropout_rate_Layer_2': 0.3521692326742264, 'dropout_rate_Layer_3': 0.3492529562194203, 'dropout_rate_Layer_4': 0.268871497595906, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0012265015563381377, 'l1_Layer_2': 0.08852805137231567, 'l1_Layer_3': 0.007711999992292018, 'l1_Layer_4': 0.004150761586745961, 'n_units_Layer_1': 210, 'n_units_Layer_2': 190, 'n_units_Layer_3': 150, 'n_units_Layer_4': 180}. Best is trial 151 with value: 5.956430806639696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.70 | sMAPE for Validation Set is: 18.28% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.28 | sMAPE for Test Set is: 19.93% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:22:34,375]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:22:37,094]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:22:42,539]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:22:45,318]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:22:49,046]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:22:53,148]\u001b[0m Trial 183 finished with value: 6.13458678232114 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008609006465277279, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24789113429776455, 'dropout_rate_Layer_2': 0.3045402594429135, 'dropout_rate_Layer_3': 0.0021143986593369912, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001389632855352277, 'l1_Layer_2': 6.575068614547041e-05, 'l1_Layer_3': 0.000604387355550435, 'n_units_Layer_1': 160, 'n_units_Layer_2': 180, 'n_units_Layer_3': 285}. Best is trial 151 with value: 5.956430806639696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.13 | sMAPE for Validation Set is: 16.86% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.71 | sMAPE for Test Set is: 18.57% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:22:59,675]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:23:05,983]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:23:09,949]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:23:13,473]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:23:18,165]\u001b[0m Trial 192 finished with value: 6.148340919444014 and parameters: {'n_hidden': 3, 'learning_rate': 0.00241640784184422, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10069290073610616, 'dropout_rate_Layer_2': 0.15251767075216144, 'dropout_rate_Layer_3': 0.3653307058670183, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004360148967742644, 'l1_Layer_2': 8.908412569837077e-05, 'l1_Layer_3': 0.0009746485492531741, 'n_units_Layer_1': 80, 'n_units_Layer_2': 75, 'n_units_Layer_3': 180}. Best is trial 151 with value: 5.956430806639696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.15 | sMAPE for Validation Set is: 17.02% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.25 | sMAPE for Test Set is: 19.91% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:23:30,035]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:23:34,602]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:23:38,148]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:23:41,471]\u001b[0m Trial 194 finished with value: 6.204451115434121 and parameters: {'n_hidden': 3, 'learning_rate': 0.001489470025227093, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07855780067386327, 'dropout_rate_Layer_2': 0.13710624371728505, 'dropout_rate_Layer_3': 0.20830908255991099, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002548628889249001, 'l1_Layer_2': 7.833303499938215e-05, 'l1_Layer_3': 0.0011217895402285847, 'n_units_Layer_1': 170, 'n_units_Layer_2': 75, 'n_units_Layer_3': 140}. Best is trial 151 with value: 5.956430806639696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.20 | sMAPE for Validation Set is: 16.98% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.98 | sMAPE for Test Set is: 19.24% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:23:51,460]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:24:05,497]\u001b[0m Trial 186 finished with value: 6.257010299764588 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009043434431137668, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2659574941966121, 'dropout_rate_Layer_2': 0.3612043756516143, 'dropout_rate_Layer_3': 0.012711935213658007, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015428152650328865, 'l1_Layer_2': 5.966214052342775e-05, 'l1_Layer_3': 0.0031769134469215865, 'n_units_Layer_1': 130, 'n_units_Layer_2': 110, 'n_units_Layer_3': 270}. Best is trial 151 with value: 5.956430806639696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.26 | sMAPE for Validation Set is: 17.20% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.98 | sMAPE for Test Set is: 19.25% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:24:11,611]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:24:15,516]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:24:21,442]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:24:24,429]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:24:24,685]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:24:31,135]\u001b[0m Trial 204 finished with value: 6.663856249874253 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008867658692396341, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24680564455621698, 'dropout_rate_Layer_2': 0.2732164729595537, 'dropout_rate_Layer_3': 0.0018226318744572114, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013983074886452293, 'l1_Layer_2': 6.476128835472967e-05, 'l1_Layer_3': 0.0021877935763061442, 'n_units_Layer_1': 140, 'n_units_Layer_2': 185, 'n_units_Layer_3': 270}. Best is trial 151 with value: 5.956430806639696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.66 | sMAPE for Validation Set is: 18.41% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.26 | sMAPE for Test Set is: 20.11% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:24:32,467]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:24:36,854]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:24:37,145]\u001b[0m Trial 203 finished with value: 5.852935425088059 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019864210045727913, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3871090286647908, 'dropout_rate_Layer_2': 0.09908471436710511, 'dropout_rate_Layer_3': 0.1849706799382892, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001928906153340821, 'l1_Layer_2': 9.336213243630272e-05, 'l1_Layer_3': 0.0014996498461339843, 'n_units_Layer_1': 125, 'n_units_Layer_2': 95, 'n_units_Layer_3': 245}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.85 | sMAPE for Validation Set is: 16.14% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.93 | sMAPE for Test Set is: 18.80% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:24:40,828]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:24:45,126]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:24:49,069]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:24:52,291]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:24:52,536]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:25:03,758]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:25:07,387]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:25:12,899]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:25:14,607]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:25:21,841]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:25:25,927]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:25:31,776]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:25:34,158]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:25:34,532]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:25:41,021]\u001b[0m Trial 223 finished with value: 7.15444714282922 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007280542166804297, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2787616334846884, 'dropout_rate_Layer_2': 0.0552235235054423, 'dropout_rate_Layer_3': 0.3801436973203973, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012681133422360073, 'l1_Layer_2': 0.00019828478747507846, 'l1_Layer_3': 0.00047004251517742253, 'n_units_Layer_1': 105, 'n_units_Layer_2': 175, 'n_units_Layer_3': 275}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.15 | sMAPE for Validation Set is: 19.16% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 7.85 | sMAPE for Test Set is: 23.21% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:25:41,835]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.26 | sMAPE for Validation Set is: 17.19% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.35 | sMAPE for Test Set is: 19.91% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:25:45,227]\u001b[0m Trial 213 finished with value: 6.260532167479674 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008484012425019254, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13961645350660148, 'dropout_rate_Layer_2': 0.09863218780193425, 'dropout_rate_Layer_3': 0.12291976661474974, 'dropout_rate_Layer_4': 0.17512001491737522, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 6.122383523910769e-05, 'l1_Layer_2': 0.00018897516542290576, 'l1_Layer_3': 8.86644530910892e-05, 'l1_Layer_4': 0.003371807705896418, 'n_units_Layer_1': 280, 'n_units_Layer_2': 300, 'n_units_Layer_3': 220, 'n_units_Layer_4': 235}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:25:47,671]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:25:50,600]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:25:52,226]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:25:57,432]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:26:00,452]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:26:04,355]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:26:13,902]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:26:17,593]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:26:22,951]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:26:26,286]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:26:29,570]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:26:33,036]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:26:36,587]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:26:37,777]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:26:41,250]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:26:42,084]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:26:46,776]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:26:52,815]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:26:53,166]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:26:59,271]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:27:01,029]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:27:04,532]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:27:07,169]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:27:09,484]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:27:14,947]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:27:24,625]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:27:33,581]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:27:36,358]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:27:36,753]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:27:41,106]\u001b[0m Trial 232 finished with value: 6.205978766069566 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006259279048812555, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06333063115698712, 'dropout_rate_Layer_2': 0.01877681803207107, 'dropout_rate_Layer_3': 0.12628442511606125, 'dropout_rate_Layer_4': 0.19428964861122383, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0010258576208763267, 'l1_Layer_2': 0.00027901962527260673, 'l1_Layer_3': 0.0001457900667127061, 'l1_Layer_4': 0.0047673469296405585, 'n_units_Layer_1': 285, 'n_units_Layer_2': 175, 'n_units_Layer_3': 225, 'n_units_Layer_4': 215}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.21 | sMAPE for Validation Set is: 17.15% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.13 | sMAPE for Test Set is: 19.54% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:27:41,990]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:27:45,795]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:27:48,188]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:27:49,473]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:27:50,536]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:27:52,596]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:27:55,351]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:28:01,909]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:28:04,890]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:28:33,242]\u001b[0m Trial 269 finished with value: 6.552301508442842 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009561504898038435, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06330564340484544, 'dropout_rate_Layer_2': 0.16109046790091006, 'dropout_rate_Layer_3': 0.16794714703880845, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007401310007289411, 'l1_Layer_2': 0.0006510808418811663, 'l1_Layer_3': 2.6345968829693713e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 60, 'n_units_Layer_3': 175}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.55 | sMAPE for Validation Set is: 17.97% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.73 | sMAPE for Test Set is: 20.74% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:29:02,686]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:29:14,517]\u001b[0m Trial 270 finished with value: 6.433769805507121 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025004626907295232, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2786473452796307, 'dropout_rate_Layer_2': 0.24534104822108016, 'dropout_rate_Layer_3': 0.04245758694974785, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005650993334869112, 'l1_Layer_2': 3.438816704371447e-05, 'l1_Layer_3': 0.0009682909497467023, 'n_units_Layer_1': 170, 'n_units_Layer_2': 225, 'n_units_Layer_3': 230}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.43 | sMAPE for Validation Set is: 17.70% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.14 | sMAPE for Test Set is: 19.94% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:29:16,748]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:29:22,022]\u001b[0m Trial 271 finished with value: 6.521221197432868 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005121146325659565, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1345433662133732, 'dropout_rate_Layer_2': 0.33440992829313865, 'dropout_rate_Layer_3': 0.38713105134466486, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0029647824608777886, 'l1_Layer_2': 0.013373691816972406, 'l1_Layer_3': 4.693210712257623e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 255, 'n_units_Layer_3': 255}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.52 | sMAPE for Validation Set is: 17.88% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.64 | sMAPE for Test Set is: 20.77% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:29:24,949]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:29:29,036]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:29:39,517]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:29:41,831]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:29:51,815]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:29:55,198]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:29:59,628]\u001b[0m Trial 278 finished with value: 6.544273160012575 and parameters: {'n_hidden': 3, 'learning_rate': 0.002563670913136126, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.024437805894220933, 'dropout_rate_Layer_2': 0.12856666980658268, 'dropout_rate_Layer_3': 0.301519576230709, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005261057052514885, 'l1_Layer_2': 0.001103408597480158, 'l1_Layer_3': 2.089499691533701e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 55, 'n_units_Layer_3': 150}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.54 | sMAPE for Validation Set is: 17.81% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 7.00 | sMAPE for Test Set is: 21.10% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:30:02,779]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:30:03,122]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:30:05,557]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:30:10,225]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:30:10,895]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:30:16,812]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:30:20,637]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:30:23,370]\u001b[0m Trial 282 finished with value: 6.649842195365321 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007708475063648259, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.028686089462902246, 'dropout_rate_Layer_2': 0.12451727207946557, 'dropout_rate_Layer_3': 0.18589052885765509, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00029957381287983964, 'l1_Layer_2': 0.0010286971801666443, 'l1_Layer_3': 1.5942135539564484e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 160, 'n_units_Layer_3': 175}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.65 | sMAPE for Validation Set is: 18.01% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 7.29 | sMAPE for Test Set is: 21.93% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:30:24,827]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:30:36,194]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:30:39,592]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:30:48,193]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:30:48,505]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:30:48,721]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:30:53,802]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:30:56,736]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:30:57,762]\u001b[0m Trial 285 finished with value: 6.675383891577188 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007912685743822812, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03283870043497709, 'dropout_rate_Layer_2': 0.12821131550405473, 'dropout_rate_Layer_3': 0.18529565663485734, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003032162061147388, 'l1_Layer_2': 0.0015531740328675804, 'l1_Layer_3': 1.7631124750058307e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 65, 'n_units_Layer_3': 180}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.68 | sMAPE for Validation Set is: 18.10% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.01 | sMAPE for Test Set is: 21.28% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:31:00,513]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:31:05,086]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:31:06,413]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:31:07,757]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:31:10,100]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:31:14,527]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:31:17,838]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:31:20,161]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:31:23,023]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:31:25,597]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:31:27,171]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:31:28,138]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:31:33,816]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:31:39,463]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:31:39,767]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:31:52,393]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:31:53,567]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:31:54,572]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:31:55,106]\u001b[0m Trial 310 finished with value: 7.693771754070369 and parameters: {'n_hidden': 3, 'learning_rate': 0.001156135394444111, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16263841216871616, 'dropout_rate_Layer_2': 0.31319523221008455, 'dropout_rate_Layer_3': 0.11373914228928732, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.909404713184396e-05, 'l1_Layer_2': 0.0001889749374395362, 'l1_Layer_3': 0.00023498651442037315, 'n_units_Layer_1': 150, 'n_units_Layer_2': 155, 'n_units_Layer_3': 255}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.69 | sMAPE for Validation Set is: 20.34% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 6.52 | sMAPE for Test Set is: 20.72% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:32:00,767]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:32:02,512]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:32:04,010]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:32:04,125]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:32:10,610]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:32:13,083]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:32:20,907]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:32:24,563]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:32:29,031]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:32:35,963]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:32:40,361]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:32:44,684]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:32:52,571]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:32:56,028]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:33:04,170]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:33:08,784]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:33:19,078]\u001b[0m Trial 321 finished with value: 6.694079622700673 and parameters: {'n_hidden': 3, 'learning_rate': 0.001311211878420287, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2700089619839362, 'dropout_rate_Layer_2': 0.35773835426113826, 'dropout_rate_Layer_3': 0.030702171187854253, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.4238894290827153e-05, 'l1_Layer_2': 4.022256105516203e-05, 'l1_Layer_3': 0.0058269921045928, 'n_units_Layer_1': 190, 'n_units_Layer_2': 265, 'n_units_Layer_3': 280}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.69 | sMAPE for Validation Set is: 18.31% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.28 | sMAPE for Test Set is: 20.03% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:33:23,149]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:33:24,958]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:33:28,437]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:33:32,521]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:33:33,105]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:33:47,213]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:33:52,822]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:33:55,890]\u001b[0m Trial 334 finished with value: 7.425625579992389 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007748214692223531, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21215906331845696, 'dropout_rate_Layer_2': 0.3012685417109504, 'dropout_rate_Layer_3': 0.06925436484280356, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.4231164244761206e-05, 'l1_Layer_2': 0.00010790966528016134, 'l1_Layer_3': 0.0005008440390593556, 'n_units_Layer_1': 130, 'n_units_Layer_2': 200, 'n_units_Layer_3': 265}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.43 | sMAPE for Validation Set is: 19.73% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 6.74 | sMAPE for Test Set is: 21.04% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:33:56,306]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:34:00,458]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:34:04,160]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:34:04,827]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:34:07,202]\u001b[0m Trial 330 finished with value: 7.054073445765888 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011694129120938578, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2683844399107784, 'dropout_rate_Layer_2': 0.35707247612670384, 'dropout_rate_Layer_3': 0.03240180204557823, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002881815653546622, 'l1_Layer_2': 3.346418783761678e-05, 'l1_Layer_3': 0.005879315170778249, 'n_units_Layer_1': 190, 'n_units_Layer_2': 260, 'n_units_Layer_3': 275}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.05 | sMAPE for Validation Set is: 19.06% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.34 | sMAPE for Test Set is: 20.29% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:34:09,691]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:34:09,843]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:34:18,699]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:34:18,998]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:34:19,132]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:34:21,712]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:34:27,863]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:34:28,222]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:34:29,060]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:34:29,187]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:34:39,203]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:34:39,342]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:34:43,548]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:34:43,843]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:34:48,348]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:34:49,159]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:34:54,377]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:34:54,826]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:34:55,502]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:35:01,612]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:35:02,035]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:35:06,900]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:35:09,715]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:35:12,468]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:35:13,213]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:35:19,887]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:35:23,254]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:35:24,610]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:35:26,342]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:35:30,586]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:35:31,313]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:35:33,540]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:35:34,760]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:35:36,745]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:35:38,799]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:35:40,696]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:35:48,010]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:35:52,081]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:35:52,750]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:35:56,622]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:35:56,887]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:35:57,395]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:36:05,124]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:36:07,812]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:36:10,752]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:36:12,073]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:36:15,198]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:36:18,449]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:36:19,467]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:36:26,353]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:36:26,837]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:36:26,838]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:36:32,451]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:36:33,662]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:36:37,505]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:36:40,098]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:36:40,231]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:36:45,948]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:36:49,976]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:36:50,334]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:36:55,639]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:36:59,305]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:37:02,890]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:37:05,259]\u001b[0m Trial 403 finished with value: 6.65847352383523 and parameters: {'n_hidden': 4, 'learning_rate': 0.008825593260339874, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08243599945862334, 'dropout_rate_Layer_2': 0.1397205575847335, 'dropout_rate_Layer_3': 0.1256005071809191, 'dropout_rate_Layer_4': 0.24100186658565637, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0008322414896185939, 'l1_Layer_2': 0.00017037904423385845, 'l1_Layer_3': 8.347992748428225e-05, 'l1_Layer_4': 0.08330061425589458, 'n_units_Layer_1': 175, 'n_units_Layer_2': 245, 'n_units_Layer_3': 260, 'n_units_Layer_4': 190}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.66 | sMAPE for Validation Set is: 18.22% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.36 | sMAPE for Test Set is: 20.07% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:37:07,502]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:37:10,678]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:37:11,228]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:37:13,940]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:37:15,123]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:37:18,192]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:37:20,009]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:37:21,640]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:37:23,775]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:37:28,888]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:37:29,007]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:37:29,630]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:37:39,566]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:37:40,025]\u001b[0m Trial 416 finished with value: 6.272245795247552 and parameters: {'n_hidden': 3, 'learning_rate': 0.004775692197842117, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11857347091669097, 'dropout_rate_Layer_2': 0.1742050432062645, 'dropout_rate_Layer_3': 0.03156428530345225, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2435837225246101e-05, 'l1_Layer_2': 0.00039478152706198577, 'l1_Layer_3': 0.00045612936237685205, 'n_units_Layer_1': 145, 'n_units_Layer_2': 290, 'n_units_Layer_3': 225}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.27 | sMAPE for Validation Set is: 17.15% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 7.38 | sMAPE for Test Set is: 22.12% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:37:45,231]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:37:47,748]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:37:48,133]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:37:54,358]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:37:55,001]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:37:59,643]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:38:01,945]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:38:08,898]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:38:12,492]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:38:19,794]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:38:24,518]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:38:28,011]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:38:30,034]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:38:31,315]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:38:32,505]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:38:33,709]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:38:41,881]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:38:45,692]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:38:47,513]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:38:47,982]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:38:53,952]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:38:54,285]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:38:59,709]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:39:02,796]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:39:03,232]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:39:11,632]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:39:16,341]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:39:18,317]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:39:22,172]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:39:24,542]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:39:26,469]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:39:30,101]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:39:34,972]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:39:39,287]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:39:44,992]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:39:49,339]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:40:03,047]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:40:03,280]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:40:08,737]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:40:11,573]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:40:13,553]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:40:15,034]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:40:20,039]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:40:23,012]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:40:23,415]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:40:27,855]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:40:28,429]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:40:34,273]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:40:34,396]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:40:40,528]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:40:41,334]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:40:46,764]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:40:48,913]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:40:52,564]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:40:56,020]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:41:00,582]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:41:03,179]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:41:03,709]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:41:04,548]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:41:10,126]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:41:10,632]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:41:12,018]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:41:20,398]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:41:23,253]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:41:26,256]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:41:33,206]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:41:37,727]\u001b[0m Trial 471 finished with value: 6.277796209178436 and parameters: {'n_hidden': 3, 'learning_rate': 0.001896333791407745, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1560648311105974, 'dropout_rate_Layer_2': 0.3793186072746221, 'dropout_rate_Layer_3': 0.017402241504880078, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.095959951072299e-05, 'l1_Layer_2': 0.0002880953288780519, 'l1_Layer_3': 1.704675121241953e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 175, 'n_units_Layer_3': 300}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.28 | sMAPE for Validation Set is: 17.20% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.85 | sMAPE for Test Set is: 18.96% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:41:44,788]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:41:49,398]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:41:53,137]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:41:57,089]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:41:59,699]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:42:01,967]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:42:06,482]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:42:06,691]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:42:07,888]\u001b[0m Trial 486 finished with value: 6.405857085343624 and parameters: {'n_hidden': 3, 'learning_rate': 0.002141375180673797, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15488737452538662, 'dropout_rate_Layer_2': 0.32472618663096503, 'dropout_rate_Layer_3': 0.02072054057651484, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.012923283675285e-05, 'l1_Layer_2': 0.000284516653287414, 'l1_Layer_3': 0.0008364938970171072, 'n_units_Layer_1': 70, 'n_units_Layer_2': 120, 'n_units_Layer_3': 300}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.41 | sMAPE for Validation Set is: 17.44% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.21 | sMAPE for Test Set is: 19.97% | rMAE for Test Set is: 0.69\n",
      "MAE for Validation Set is: 6.31 | sMAPE for Validation Set is: 17.31% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.18 | sMAPE for Test Set is: 20.08% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:42:12,913]\u001b[0m Trial 488 finished with value: 6.306773035064533 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021598174680490323, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2370918458370705, 'dropout_rate_Layer_2': 0.37432983838482725, 'dropout_rate_Layer_3': 0.020324069229708933, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.086366604276734e-05, 'l1_Layer_2': 4.712085223022001e-05, 'l1_Layer_3': 0.0007702066416765826, 'n_units_Layer_1': 80, 'n_units_Layer_2': 125, 'n_units_Layer_3': 300}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:42:13,321]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:42:14,406]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:42:14,720]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:42:24,474]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:42:24,905]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:42:25,363]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:42:32,600]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:42:36,301]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:42:36,515]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:42:36,988]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:42:38,751]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:42:42,668]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:42:45,817]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:42:48,889]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:42:49,980]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:42:53,302]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:42:55,471]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:42:59,853]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:43:00,655]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:43:06,697]\u001b[0m Trial 512 finished with value: 10.621666010509434 and parameters: {'n_hidden': 3, 'learning_rate': 0.026492414189657216, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0706005373337074, 'dropout_rate_Layer_2': 0.3618041342504683, 'dropout_rate_Layer_3': 0.27814282232664045, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00023437453049096613, 'l1_Layer_2': 1.3523240670117992e-05, 'l1_Layer_3': 0.00013326465746502157, 'n_units_Layer_1': 125, 'n_units_Layer_2': 200, 'n_units_Layer_3': 215}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.62 | sMAPE for Validation Set is: 27.07% | rMAE for Validation Set is: 1.01\n",
      "MAE for Test Set is: 7.70 | sMAPE for Test Set is: 23.11% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:43:19,376]\u001b[0m Trial 521 finished with value: 7.2649798648833555 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015530144822363092, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10271813675913785, 'dropout_rate_Layer_2': 0.3756892170249063, 'dropout_rate_Layer_3': 0.07689254797434719, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.853467772650937e-05, 'l1_Layer_2': 0.00024704481207942213, 'l1_Layer_3': 1.641616615151903e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 70, 'n_units_Layer_3': 300}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.26 | sMAPE for Validation Set is: 19.63% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 6.75 | sMAPE for Test Set is: 21.23% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:43:20,060]\u001b[0m Trial 523 finished with value: 9.550854767936125 and parameters: {'n_hidden': 3, 'learning_rate': 0.028818855600855363, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09691326388502161, 'dropout_rate_Layer_2': 0.33714618815747055, 'dropout_rate_Layer_3': 0.3461196144972921, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00025366103484982303, 'l1_Layer_2': 1.32191799435036e-05, 'l1_Layer_3': 0.00013766700188645227, 'n_units_Layer_1': 155, 'n_units_Layer_2': 195, 'n_units_Layer_3': 155}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.55 | sMAPE for Validation Set is: 24.30% | rMAE for Validation Set is: 0.91\n",
      "MAE for Test Set is: 7.37 | sMAPE for Test Set is: 22.01% | rMAE for Test Set is: 0.82\n",
      "MAE for Validation Set is: 6.57 | sMAPE for Validation Set is: 17.98% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.66 | sMAPE for Test Set is: 20.84% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:43:21,539]\u001b[0m Trial 518 finished with value: 6.573027802619188 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010733939424281455, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08459151287367078, 'dropout_rate_Layer_2': 0.27407092614198053, 'dropout_rate_Layer_3': 0.3687015656537923, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002819711566254151, 'l1_Layer_2': 0.027143877698754093, 'l1_Layer_3': 3.2805837451577196e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 235, 'n_units_Layer_3': 270}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:43:27,484]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:43:30,253]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:43:30,662]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:43:30,831]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:43:31,664]\u001b[0m Trial 522 finished with value: 6.609551226062703 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010607954313119354, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09881060880147649, 'dropout_rate_Layer_2': 0.24098183638764703, 'dropout_rate_Layer_3': 0.37479800197690016, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0030951512594894655, 'l1_Layer_2': 0.030098744042401024, 'l1_Layer_3': 2.7854876045158685e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 240, 'n_units_Layer_3': 270}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.61 | sMAPE for Validation Set is: 18.01% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.68 | sMAPE for Test Set is: 20.82% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:43:37,784]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:43:39,858]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:43:40,255]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:43:42,642]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:43:47,116]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:43:48,909]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:43:50,839]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:43:56,075]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:43:56,304]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:44:01,586]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:44:02,067]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:44:08,236]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:44:20,089]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:44:24,652]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:44:33,304]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:44:36,813]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:44:37,536]\u001b[0m Trial 533 finished with value: 6.462072478359638 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006931399804036741, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12451868310578007, 'dropout_rate_Layer_2': 0.2395290338811232, 'dropout_rate_Layer_3': 0.37828201611608064, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0019099493595767527, 'l1_Layer_2': 0.02579778348283385, 'l1_Layer_3': 5.089271165689803e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 285, 'n_units_Layer_3': 270}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.46 | sMAPE for Validation Set is: 17.68% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.83 | sMAPE for Test Set is: 21.22% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:44:43,617]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:44:47,541]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:44:55,124]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:44:59,372]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:45:06,705]\u001b[0m Trial 545 finished with value: 6.365399487067424 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007223477858916134, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12447959761523683, 'dropout_rate_Layer_2': 0.1808899029062551, 'dropout_rate_Layer_3': 0.38006219851788975, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002111145754498565, 'l1_Layer_2': 0.023614952850942075, 'l1_Layer_3': 5.70769745802494e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 250, 'n_units_Layer_3': 270}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.37 | sMAPE for Validation Set is: 17.57% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.46 | sMAPE for Test Set is: 20.48% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:45:07,341]\u001b[0m Trial 543 finished with value: 6.195112237852601 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007282761721221529, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1214361458444328, 'dropout_rate_Layer_2': 0.289534748385368, 'dropout_rate_Layer_3': 0.3787216384194302, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0019636898869610864, 'l1_Layer_2': 0.012268174059466142, 'l1_Layer_3': 5.055219634231247e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 245, 'n_units_Layer_3': 270}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.20 | sMAPE for Validation Set is: 16.97% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.48 | sMAPE for Test Set is: 20.45% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:45:14,626]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:45:19,643]\u001b[0m Trial 547 finished with value: 6.351504620329184 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016871104341072436, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2133603163406945, 'dropout_rate_Layer_2': 0.12084647294027023, 'dropout_rate_Layer_3': 0.19373300923612186, 'dropout_rate_Layer_4': 0.01929961701190867, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.003127077307850778, 'l1_Layer_2': 7.282142569430501e-05, 'l1_Layer_3': 0.00805228499360719, 'l1_Layer_4': 0.00010648587820919397, 'n_units_Layer_1': 190, 'n_units_Layer_2': 75, 'n_units_Layer_3': 145, 'n_units_Layer_4': 55}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.35 | sMAPE for Validation Set is: 17.46% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.31 | sMAPE for Test Set is: 19.74% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:45:25,249]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:45:33,951]\u001b[0m Trial 553 finished with value: 9.077858153961223 and parameters: {'n_hidden': 4, 'learning_rate': 0.006324453779005419, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16146042172981917, 'dropout_rate_Layer_2': 0.3230159995706055, 'dropout_rate_Layer_3': 0.021533238143164584, 'dropout_rate_Layer_4': 0.1505728098987527, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.249316222059754e-05, 'l1_Layer_2': 0.0009390064316296487, 'l1_Layer_3': 9.478276399290404e-05, 'l1_Layer_4': 6.357037251965656e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 125, 'n_units_Layer_3': 180, 'n_units_Layer_4': 60}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.08 | sMAPE for Validation Set is: 23.29% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 8.18 | sMAPE for Test Set is: 23.97% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:45:47,480]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:45:55,528]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:45:59,759]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:46:03,742]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:46:04,429]\u001b[0m Trial 552 finished with value: 6.170806870292213 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007265873152888722, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1272685218733453, 'dropout_rate_Layer_2': 0.2375947542069024, 'dropout_rate_Layer_3': 0.37611404971948337, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0020472160699082764, 'l1_Layer_2': 0.011934763055340839, 'l1_Layer_3': 4.788473190770185e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 250, 'n_units_Layer_3': 270}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.17 | sMAPE for Validation Set is: 17.02% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.34 | sMAPE for Test Set is: 20.25% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:46:04,850]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:46:13,207]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:46:13,357]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:46:13,569]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:46:20,863]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:46:21,484]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:46:25,944]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:46:28,120]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:46:29,215]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:46:30,378]\u001b[0m Trial 555 finished with value: 6.073489576114317 and parameters: {'n_hidden': 3, 'learning_rate': 0.000730420199674665, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1238593255895406, 'dropout_rate_Layer_2': 0.18029843423267922, 'dropout_rate_Layer_3': 0.3769971163444279, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0018064065132523627, 'l1_Layer_2': 0.01159942858475006, 'l1_Layer_3': 4.4091382801323404e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 285, 'n_units_Layer_3': 270}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.07 | sMAPE for Validation Set is: 16.72% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.13 | sMAPE for Test Set is: 19.55% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:46:30,555]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:46:39,439]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:46:39,849]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:46:46,004]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:46:50,081]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:46:53,329]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:46:53,786]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:46:54,115]\u001b[0m Trial 573 finished with value: 8.148241075184092 and parameters: {'n_hidden': 3, 'learning_rate': 0.003046491066676382, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0975460386321108, 'dropout_rate_Layer_2': 0.10831997412768204, 'dropout_rate_Layer_3': 0.02135225495537045, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.300005970761179e-05, 'l1_Layer_2': 0.0003198675438965982, 'l1_Layer_3': 2.977833408682778e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 85, 'n_units_Layer_3': 285}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.15 | sMAPE for Validation Set is: 21.35% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 7.56 | sMAPE for Test Set is: 22.82% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:47:00,893]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:47:04,119]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:47:04,643]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:47:10,767]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:47:13,933]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:47:14,129]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:47:21,658]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:47:25,573]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:47:29,578]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:47:33,582]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:47:47,680]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:48:03,284]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:48:07,668]\u001b[0m Trial 584 finished with value: 6.3609650971364475 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017394140026396891, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2362258292356842, 'dropout_rate_Layer_2': 0.34176503129019437, 'dropout_rate_Layer_3': 0.0464312818664112, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.042062248056356e-05, 'l1_Layer_2': 7.54659787712753e-05, 'l1_Layer_3': 0.0012657752593911008, 'n_units_Layer_1': 120, 'n_units_Layer_2': 135, 'n_units_Layer_3': 300}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.36 | sMAPE for Validation Set is: 17.45% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.07 | sMAPE for Test Set is: 19.57% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:48:11,267]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:48:18,749]\u001b[0m Trial 583 finished with value: 6.157347191427063 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016238928657779318, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23517408588516905, 'dropout_rate_Layer_2': 0.3412602312055295, 'dropout_rate_Layer_3': 0.34950162165897547, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.480125304687152e-05, 'l1_Layer_2': 8.241347300356412e-05, 'l1_Layer_3': 0.0003202915068028501, 'n_units_Layer_1': 115, 'n_units_Layer_2': 140, 'n_units_Layer_3': 295}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.16 | sMAPE for Validation Set is: 17.06% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.93 | sMAPE for Test Set is: 19.31% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:48:43,357]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:48:46,638]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:48:49,955]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:48:53,298]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:48:54,103]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:49:01,601]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:49:06,121]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:49:06,746]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:49:12,484]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:49:13,581]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:49:17,814]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:49:26,337]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:49:31,317]\u001b[0m Trial 593 finished with value: 6.2091872279526354 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015958581270143777, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23860962975817276, 'dropout_rate_Layer_2': 0.34009161107843167, 'dropout_rate_Layer_3': 0.08196913750658272, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.294695974433893e-05, 'l1_Layer_2': 7.688199780187326e-05, 'l1_Layer_3': 0.0007751934177425798, 'n_units_Layer_1': 120, 'n_units_Layer_2': 135, 'n_units_Layer_3': 295}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.21 | sMAPE for Validation Set is: 17.37% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.02 | sMAPE for Test Set is: 19.73% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:49:31,616]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:49:38,171]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:49:41,486]\u001b[0m Trial 600 finished with value: 6.07430484945839 and parameters: {'n_hidden': 3, 'learning_rate': 0.001377354203002075, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23571845416422973, 'dropout_rate_Layer_2': 0.2804158618350146, 'dropout_rate_Layer_3': 0.135827522373807, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00080266378055003, 'l1_Layer_2': 0.00013725960966656163, 'l1_Layer_3': 4.0928357267743105e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 285, 'n_units_Layer_3': 255}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.07 | sMAPE for Validation Set is: 16.63% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.14 | sMAPE for Test Set is: 19.38% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:49:43,698]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:49:47,619]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:49:50,274]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:49:53,745]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:49:54,100]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:49:58,875]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:49:59,500]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:50:05,667]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:50:09,162]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:50:11,889]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:50:13,690]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:50:15,183]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:50:16,951]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:50:22,024]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:50:22,833]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:50:26,761]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:50:30,543]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:50:32,239]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:50:35,207]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:50:39,675]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:50:50,633]\u001b[0m Trial 618 finished with value: 6.124316896377219 and parameters: {'n_hidden': 3, 'learning_rate': 0.01591716562537443, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2064259876545635, 'dropout_rate_Layer_2': 0.37754324262379085, 'dropout_rate_Layer_3': 0.22094274738639624, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012984967611760984, 'l1_Layer_2': 5.4106126227680645e-05, 'l1_Layer_3': 0.0006889217133983892, 'n_units_Layer_1': 120, 'n_units_Layer_2': 140, 'n_units_Layer_3': 280}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.12 | sMAPE for Validation Set is: 16.78% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.81 | sMAPE for Test Set is: 18.76% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:50:53,684]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:50:57,385]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:51:03,997]\u001b[0m Trial 630 finished with value: 6.81932407312997 and parameters: {'n_hidden': 3, 'learning_rate': 0.05823592618550866, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2332286052049589, 'dropout_rate_Layer_2': 0.36241846037633435, 'dropout_rate_Layer_3': 0.35782432261463665, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012828785412544579, 'l1_Layer_2': 1.541618757028751e-05, 'l1_Layer_3': 0.00072913731938027, 'n_units_Layer_1': 120, 'n_units_Layer_2': 160, 'n_units_Layer_3': 285}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.82 | sMAPE for Validation Set is: 18.47% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.47 | sMAPE for Test Set is: 20.23% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:51:08,075]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:51:14,338]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:51:18,706]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:51:18,798]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:51:24,499]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:51:27,446]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:51:27,695]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:51:33,724]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:51:40,729]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:51:46,365]\u001b[0m Trial 625 finished with value: 6.162347391830477 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005997832189704953, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.144731908072181, 'dropout_rate_Layer_2': 0.196198540843196, 'dropout_rate_Layer_3': 0.39944320933669314, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0027720757722235556, 'l1_Layer_2': 0.013305886460075751, 'l1_Layer_3': 5.955826401904833e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 250, 'n_units_Layer_3': 290}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.16 | sMAPE for Validation Set is: 16.90% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.10 | sMAPE for Test Set is: 19.59% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:51:50,036]\u001b[0m Trial 642 finished with value: 9.44176979185261 and parameters: {'n_hidden': 4, 'learning_rate': 0.030236232913668417, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20003430249685364, 'dropout_rate_Layer_2': 0.385793280614613, 'dropout_rate_Layer_3': 0.2721958523362267, 'dropout_rate_Layer_4': 0.30867909377149905, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00019937439200771027, 'l1_Layer_2': 2.9235436612664585e-05, 'l1_Layer_3': 0.000417892868649743, 'l1_Layer_4': 9.487193677706093e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 175, 'n_units_Layer_3': 270, 'n_units_Layer_4': 295}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.44 | sMAPE for Validation Set is: 24.00% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 7.93 | sMAPE for Test Set is: 23.47% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:51:50,230]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:51:56,680]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:51:59,911]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:52:03,840]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:52:03,908]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:52:04,129]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:52:06,118]\u001b[0m Trial 635 finished with value: 6.296636663331292 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006145965697198029, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13612873705959733, 'dropout_rate_Layer_2': 0.18953531751391575, 'dropout_rate_Layer_3': 0.36939814083623196, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0026329745427800355, 'l1_Layer_2': 0.01909711858288436, 'l1_Layer_3': 2.2705223898995014e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 250, 'n_units_Layer_3': 290}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.30 | sMAPE for Validation Set is: 17.29% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.57 | sMAPE for Test Set is: 20.69% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:52:11,243]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:52:12,738]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:52:15,754]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:52:19,825]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:52:21,780]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:52:26,246]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:52:27,981]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:52:31,646]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:52:31,693]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:52:31,713]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:52:34,960]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:52:39,684]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:52:41,081]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:52:41,849]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:52:43,785]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:52:47,313]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:52:53,850]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:52:54,398]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:53:00,252]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:53:06,630]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:53:12,299]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:53:21,046]\u001b[0m Trial 667 finished with value: 6.297428922312442 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013568999511336332, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24057873088585038, 'dropout_rate_Layer_2': 0.2802319068154504, 'dropout_rate_Layer_3': 0.12242579005652113, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007710051417576133, 'l1_Layer_2': 0.00021456676934068116, 'l1_Layer_3': 7.681110124561091e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 290, 'n_units_Layer_3': 250}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.30 | sMAPE for Validation Set is: 17.42% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.87 | sMAPE for Test Set is: 19.00% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:53:24,459]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:53:24,557]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:53:33,086]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:53:37,002]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:53:40,297]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:53:41,079]\u001b[0m Trial 673 finished with value: 6.671142521144291 and parameters: {'n_hidden': 3, 'learning_rate': 0.022519069892854064, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2505885010028257, 'dropout_rate_Layer_2': 0.36778606591762625, 'dropout_rate_Layer_3': 0.33754911454178105, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.344663748517716e-05, 'l1_Layer_2': 5.002837237138237e-05, 'l1_Layer_3': 0.0013437375221558678, 'n_units_Layer_1': 90, 'n_units_Layer_2': 100, 'n_units_Layer_3': 290}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.67 | sMAPE for Validation Set is: 18.35% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.30 | sMAPE for Test Set is: 20.15% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:53:46,435]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:53:59,341]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:54:06,568]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:54:10,747]\u001b[0m Trial 670 finished with value: 6.071128059474116 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005802204045682098, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1615625083432026, 'dropout_rate_Layer_2': 0.21861219188274877, 'dropout_rate_Layer_3': 0.35464456270714734, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011064099317567744, 'l1_Layer_2': 0.012010805286967557, 'l1_Layer_3': 6.0814365726254054e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 260, 'n_units_Layer_3': 290}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.07 | sMAPE for Validation Set is: 16.71% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.28 | sMAPE for Test Set is: 19.93% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:54:15,820]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:54:20,989]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:54:22,159]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:54:28,077]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:54:30,885]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:54:33,864]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:54:37,906]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:54:43,841]\u001b[0m Trial 680 finished with value: 6.46177293853373 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008324161263328655, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24569676318315814, 'dropout_rate_Layer_2': 0.26100609276820375, 'dropout_rate_Layer_3': 0.12500668133237597, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011487202291298783, 'l1_Layer_2': 9.664761721519524e-05, 'l1_Layer_3': 0.000497086758609097, 'n_units_Layer_1': 290, 'n_units_Layer_2': 275, 'n_units_Layer_3': 245}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.46 | sMAPE for Validation Set is: 17.61% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.87 | sMAPE for Test Set is: 20.94% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:54:47,239]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:54:59,943]\u001b[0m Trial 685 finished with value: 6.380567025488982 and parameters: {'n_hidden': 3, 'learning_rate': 0.014027901060671324, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22966853142073013, 'dropout_rate_Layer_2': 0.35010800630101735, 'dropout_rate_Layer_3': 0.2429767671884017, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001419034479248037, 'l1_Layer_2': 8.878965869801076e-05, 'l1_Layer_3': 0.0006884891739896473, 'n_units_Layer_1': 105, 'n_units_Layer_2': 145, 'n_units_Layer_3': 260}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.38 | sMAPE for Validation Set is: 17.54% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.96 | sMAPE for Test Set is: 19.14% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:55:04,527]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:55:07,663]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:55:11,343]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:55:15,797]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:55:16,686]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:55:20,703]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:55:25,003]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:55:37,761]\u001b[0m Trial 693 finished with value: 6.109557065384071 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006099060700399748, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15964851264966085, 'dropout_rate_Layer_2': 0.22704171503048665, 'dropout_rate_Layer_3': 0.3329988640509278, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00047043933218196186, 'l1_Layer_2': 0.008180122862340912, 'l1_Layer_3': 6.522975582474911e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 265, 'n_units_Layer_3': 280}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.11 | sMAPE for Validation Set is: 16.79% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.41 | sMAPE for Test Set is: 20.36% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:55:41,272]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:55:42,318]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:55:48,302]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:55:50,943]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:55:54,997]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:55:59,210]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:55:59,509]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:56:06,748]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:56:11,328]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:56:11,359]\u001b[0m Trial 701 finished with value: 6.426855041270094 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006059080814482487, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24318625617011502, 'dropout_rate_Layer_2': 0.07292205604941526, 'dropout_rate_Layer_3': 0.11789001183319239, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0017250078523746379, 'l1_Layer_2': 7.395500734695294e-05, 'l1_Layer_3': 0.0006531021858531887, 'n_units_Layer_1': 295, 'n_units_Layer_2': 270, 'n_units_Layer_3': 235}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.43 | sMAPE for Validation Set is: 17.44% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 7.26 | sMAPE for Test Set is: 21.72% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:56:16,913]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:56:20,232]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:56:24,145]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:56:27,658]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:56:30,720]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:56:30,885]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:56:36,588]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:56:40,081]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:56:40,696]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:56:45,677]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:56:49,472]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:56:49,959]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:56:55,236]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:56:55,539]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:56:55,692]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:57:02,869]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:57:06,529]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:57:06,646]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:57:10,101]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:57:14,768]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:57:15,167]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:57:15,511]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:57:22,510]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:57:23,646]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:57:28,300]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:57:31,743]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:57:35,032]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:57:36,625]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:57:40,952]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:57:51,685]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:57:56,539]\u001b[0m Trial 743 finished with value: 6.214932394229167 and parameters: {'n_hidden': 3, 'learning_rate': 0.03894316833486406, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2535807916398541, 'dropout_rate_Layer_2': 0.3338047411955578, 'dropout_rate_Layer_3': 0.16858053468991258, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7559511075865275e-05, 'l1_Layer_2': 5.316870139825892e-05, 'l1_Layer_3': 0.0003553238744839718, 'n_units_Layer_1': 85, 'n_units_Layer_2': 130, 'n_units_Layer_3': 290}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.21 | sMAPE for Validation Set is: 16.94% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.24 | sMAPE for Test Set is: 19.64% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:58:00,351]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:58:03,771]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:58:09,933]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:58:16,260]\u001b[0m Trial 744 finished with value: 6.019123231883488 and parameters: {'n_hidden': 3, 'learning_rate': 0.005362488972148723, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17169264716778376, 'dropout_rate_Layer_2': 0.3300164100092028, 'dropout_rate_Layer_3': 0.1673195904728857, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.8734372881665e-05, 'l1_Layer_2': 2.7953879036313887e-05, 'l1_Layer_3': 0.00012246247857534336, 'n_units_Layer_1': 130, 'n_units_Layer_2': 130, 'n_units_Layer_3': 280}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.02 | sMAPE for Validation Set is: 16.52% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.76 | sMAPE for Test Set is: 18.48% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:58:20,550]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:58:25,101]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:58:30,356]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:58:33,780]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:58:34,030]\u001b[0m Trial 732 finished with value: 6.119426779971359 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008280363911547707, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1609354611511564, 'dropout_rate_Layer_2': 0.15251446756352158, 'dropout_rate_Layer_3': 0.3337316740659858, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003338642610499387, 'l1_Layer_2': 0.005840245261984662, 'l1_Layer_3': 4.0076151919566086e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 225, 'n_units_Layer_3': 280}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.12 | sMAPE for Validation Set is: 16.83% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.16 | sMAPE for Test Set is: 19.65% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 22:58:41,279]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:58:42,009]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:58:42,294]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:58:42,435]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:58:49,079]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:58:52,128]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:58:57,535]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:58:58,227]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:59:02,339]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:59:03,157]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:59:10,612]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:59:15,011]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:59:19,244]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:59:22,772]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:59:23,340]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:59:30,377]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:59:31,506]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:59:37,031]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:59:39,955]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:59:40,619]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:59:41,153]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:59:41,270]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:59:49,273]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:59:53,452]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:59:53,709]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:59:53,896]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 22:59:58,766]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:00:04,748]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:00:04,985]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:00:05,060]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:00:13,510]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:00:14,020]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:00:14,149]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:00:20,621]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:00:22,181]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:00:23,928]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:00:26,874]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:00:26,941]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:00:32,707]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:00:34,572]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:00:36,992]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:00:38,592]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:00:41,013]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:00:43,787]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:00:46,400]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:00:50,058]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:00:52,662]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:00:54,484]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:00:55,812]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:01:00,318]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:01:04,031]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:01:10,622]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:01:14,125]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:01:17,722]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:01:18,646]\u001b[0m Trial 805 finished with value: 6.308720134805118 and parameters: {'n_hidden': 3, 'learning_rate': 0.009372000246241546, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25410481765108983, 'dropout_rate_Layer_2': 0.31528510411824356, 'dropout_rate_Layer_3': 0.14644688484768012, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0034800724409557522, 'l1_Layer_2': 1.0990706270612737e-05, 'l1_Layer_3': 0.00028637207377602133, 'n_units_Layer_1': 140, 'n_units_Layer_2': 105, 'n_units_Layer_3': 245}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.31 | sMAPE for Validation Set is: 17.69% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.43 | sMAPE for Test Set is: 20.63% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:01:24,850]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:01:28,336]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:01:28,852]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:01:28,916]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:01:36,601]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:01:36,858]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:01:39,198]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:01:46,136]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:01:47,796]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:01:50,837]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:01:53,539]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:01:56,569]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:01:59,648]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:02:00,068]\u001b[0m Trial 813 finished with value: 6.1688405026281785 and parameters: {'n_hidden': 3, 'learning_rate': 0.012773700070484416, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2794282658799372, 'dropout_rate_Layer_2': 0.32614181536248177, 'dropout_rate_Layer_3': 0.1357680930419955, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003816938196514798, 'l1_Layer_2': 1.6312838271610687e-05, 'l1_Layer_3': 0.00019519383297245758, 'n_units_Layer_1': 125, 'n_units_Layer_2': 115, 'n_units_Layer_3': 150}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.17 | sMAPE for Validation Set is: 16.95% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.94 | sMAPE for Test Set is: 19.05% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:02:04,892]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:02:05,426]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:02:05,658]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:02:14,137]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:02:14,501]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:02:17,542]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:02:22,713]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:02:25,482]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:02:26,090]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:02:27,176]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:02:29,019]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:02:34,032]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:02:37,023]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:02:39,233]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:02:39,297]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:02:39,927]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:02:45,513]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:02:52,412]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:02:54,007]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:02:54,088]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:02:56,433]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:02:59,479]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:03:03,372]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:03:08,717]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:03:09,841]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:03:16,514]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:03:20,983]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:03:22,515]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:03:26,116]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:03:30,558]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:03:33,436]\u001b[0m Trial 846 finished with value: 6.320281809472949 and parameters: {'n_hidden': 3, 'learning_rate': 0.09313515953862535, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31853476142378523, 'dropout_rate_Layer_2': 0.2599350479074288, 'dropout_rate_Layer_3': 0.2096970674189382, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003699181034512691, 'l1_Layer_2': 2.6587438482755376e-05, 'l1_Layer_3': 0.00012454045646942093, 'n_units_Layer_1': 125, 'n_units_Layer_2': 120, 'n_units_Layer_3': 140}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.32 | sMAPE for Validation Set is: 17.22% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.19 | sMAPE for Test Set is: 19.57% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:03:34,116]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:03:41,869]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:03:46,000]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:03:49,411]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:03:53,151]\u001b[0m Trial 852 finished with value: 6.160697937434057 and parameters: {'n_hidden': 3, 'learning_rate': 0.005148126162032554, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2741727141603826, 'dropout_rate_Layer_2': 0.30491648998229814, 'dropout_rate_Layer_3': 0.180182962374792, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003445136285599862, 'l1_Layer_2': 2.5347951189898533e-05, 'l1_Layer_3': 0.00036436368507685357, 'n_units_Layer_1': 110, 'n_units_Layer_2': 135, 'n_units_Layer_3': 140}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.16 | sMAPE for Validation Set is: 16.98% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.82 | sMAPE for Test Set is: 19.02% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:03:57,712]\u001b[0m Trial 854 finished with value: 6.476991035165734 and parameters: {'n_hidden': 3, 'learning_rate': 0.004087808920909267, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10200288360203236, 'dropout_rate_Layer_2': 0.013888766509409373, 'dropout_rate_Layer_3': 0.32333476798931926, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006188738422804819, 'l1_Layer_2': 0.001230453944145964, 'l1_Layer_3': 0.0012648788179049455, 'n_units_Layer_1': 190, 'n_units_Layer_2': 175, 'n_units_Layer_3': 135}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.48 | sMAPE for Validation Set is: 17.88% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.08 | sMAPE for Test Set is: 19.40% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:04:01,633]\u001b[0m Trial 855 finished with value: 6.195868087706036 and parameters: {'n_hidden': 3, 'learning_rate': 0.019961584533499777, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.278704441180124, 'dropout_rate_Layer_2': 0.30910070955511015, 'dropout_rate_Layer_3': 0.1757598564257966, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013741759400075053, 'l1_Layer_2': 1.7385499191481666e-05, 'l1_Layer_3': 0.0003499882512305537, 'n_units_Layer_1': 110, 'n_units_Layer_2': 135, 'n_units_Layer_3': 175}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:04:01,682]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.20 | sMAPE for Validation Set is: 17.08% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.86 | sMAPE for Test Set is: 18.99% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:04:08,058]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:04:12,310]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:04:12,631]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:04:18,588]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:04:21,394]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:04:22,743]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:04:33,912]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:04:39,338]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:04:44,727]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:04:48,229]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:04:49,368]\u001b[0m Trial 858 finished with value: 6.4185462809778615 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007965546500501072, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08858400566117858, 'dropout_rate_Layer_2': 0.30535001628835773, 'dropout_rate_Layer_3': 0.09789860685734333, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014526989181512064, 'l1_Layer_2': 0.00016136428768964424, 'l1_Layer_3': 0.00039806227040045027, 'n_units_Layer_1': 125, 'n_units_Layer_2': 275, 'n_units_Layer_3': 260}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.42 | sMAPE for Validation Set is: 17.50% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 7.77 | sMAPE for Test Set is: 22.63% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:04:54,150]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:04:54,946]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:05:00,405]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:05:00,652]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:05:01,220]\u001b[0m Trial 862 finished with value: 6.436321237784302 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009700174164689171, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13293390900745053, 'dropout_rate_Layer_2': 0.26537854532064464, 'dropout_rate_Layer_3': 0.37628980820426033, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013152853863573533, 'l1_Layer_2': 0.024175709085276727, 'l1_Layer_3': 3.347891274198852e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 290, 'n_units_Layer_3': 285}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.44 | sMAPE for Validation Set is: 17.56% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.86 | sMAPE for Test Set is: 21.25% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:05:02,287]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:05:10,202]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:05:12,745]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:05:13,358]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:05:14,419]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:05:21,387]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:05:23,016]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:05:30,154]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:05:45,790]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:05:49,881]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:05:50,645]\u001b[0m Trial 886 finished with value: 6.240007197819719 and parameters: {'n_hidden': 3, 'learning_rate': 0.022089100034158926, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2833742977137345, 'dropout_rate_Layer_2': 0.3107309419691334, 'dropout_rate_Layer_3': 0.18310443806175736, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006465467919475124, 'l1_Layer_2': 1.723023730370986e-05, 'l1_Layer_3': 0.0001730848984898916, 'n_units_Layer_1': 110, 'n_units_Layer_2': 145, 'n_units_Layer_3': 175}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.24 | sMAPE for Validation Set is: 17.21% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.87 | sMAPE for Test Set is: 19.06% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:05:56,334]\u001b[0m Trial 879 finished with value: 6.374342364201138 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008758854040299597, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09454927600021357, 'dropout_rate_Layer_2': 0.28304850926281705, 'dropout_rate_Layer_3': 0.08593920898904842, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001239859108432373, 'l1_Layer_2': 0.00015861693006026422, 'l1_Layer_3': 0.00039857006328151376, 'n_units_Layer_1': 115, 'n_units_Layer_2': 290, 'n_units_Layer_3': 255}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.37 | sMAPE for Validation Set is: 17.56% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 7.93 | sMAPE for Test Set is: 23.15% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:05:56,882]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:05:56,897]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:06:03,292]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:06:06,287]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:06:07,318]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:06:12,149]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:06:16,789]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:06:20,171]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:06:23,874]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:06:24,463]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:06:25,332]\u001b[0m Trial 884 finished with value: 6.067990782052778 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011344857573466142, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06551652328221763, 'dropout_rate_Layer_2': 0.16728158365831158, 'dropout_rate_Layer_3': 0.35290303913128906, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015737581390284968, 'l1_Layer_2': 0.00026076120256923464, 'l1_Layer_3': 0.0005001415727591406, 'n_units_Layer_1': 130, 'n_units_Layer_2': 295, 'n_units_Layer_3': 270}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.07 | sMAPE for Validation Set is: 16.79% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.10 | sMAPE for Test Set is: 19.55% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:06:31,825]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:06:34,119]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:06:35,327]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:06:39,403]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:06:40,837]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:06:41,718]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:06:43,441]\u001b[0m Trial 894 finished with value: 6.103115549298138 and parameters: {'n_hidden': 3, 'learning_rate': 0.005132989243473874, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2756658549820996, 'dropout_rate_Layer_2': 0.2820778889717706, 'dropout_rate_Layer_3': 0.15014076733857856, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003819209144652671, 'l1_Layer_2': 1.2292403110413422e-05, 'l1_Layer_3': 0.0005584761995410402, 'n_units_Layer_1': 155, 'n_units_Layer_2': 135, 'n_units_Layer_3': 190}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.10 | sMAPE for Validation Set is: 16.87% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.88 | sMAPE for Test Set is: 19.19% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:06:43,636]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:06:48,468]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:06:54,416]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:06:54,980]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:06:55,926]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:07:02,791]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:07:05,934]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:07:10,242]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:07:10,920]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:07:15,839]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:07:16,589]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:07:22,461]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:07:25,633]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:07:26,378]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:07:30,615]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:07:32,376]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:07:36,085]\u001b[0m Trial 912 finished with value: 6.210393306321049 and parameters: {'n_hidden': 3, 'learning_rate': 0.005674596545915614, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27598678978486973, 'dropout_rate_Layer_2': 0.28070656442830444, 'dropout_rate_Layer_3': 0.14946226761883746, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00042005239352715387, 'l1_Layer_2': 1.1541160953762146e-05, 'l1_Layer_3': 0.0005628779308836501, 'n_units_Layer_1': 155, 'n_units_Layer_2': 160, 'n_units_Layer_3': 105}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.21 | sMAPE for Validation Set is: 17.10% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.05 | sMAPE for Test Set is: 19.58% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:07:37,230]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:07:39,806]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:07:42,887]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:07:43,192]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:07:53,482]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:07:53,877]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:08:07,295]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:08:13,211]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:08:14,177]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:08:18,179]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:08:19,790]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:08:23,275]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:08:23,847]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:08:24,839]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:08:27,346]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:08:30,755]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:08:33,282]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:08:36,495]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:08:39,766]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:08:44,637]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:08:44,977]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:08:52,502]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:08:56,066]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:09:00,788]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:09:06,903]\u001b[0m Trial 942 finished with value: 6.185410145329143 and parameters: {'n_hidden': 3, 'learning_rate': 0.008021509983011998, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2972107352968487, 'dropout_rate_Layer_2': 0.23337363461791474, 'dropout_rate_Layer_3': 0.15766519332185686, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000255191570715767, 'l1_Layer_2': 1.84964085193272e-05, 'l1_Layer_3': 0.00047109631219864406, 'n_units_Layer_1': 205, 'n_units_Layer_2': 150, 'n_units_Layer_3': 130}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.19 | sMAPE for Validation Set is: 17.15% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.86 | sMAPE for Test Set is: 19.37% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:09:11,091]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.14 | sMAPE for Validation Set is: 16.91% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.08 | sMAPE for Test Set is: 19.66% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:09:13,215]\u001b[0m Trial 946 finished with value: 6.136528276052999 and parameters: {'n_hidden': 3, 'learning_rate': 0.008019582943540132, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2937183161980637, 'dropout_rate_Layer_2': 0.22939281484366306, 'dropout_rate_Layer_3': 0.1595691311143124, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002351653745338442, 'l1_Layer_2': 1.320397435551034e-05, 'l1_Layer_3': 0.00043107578000640306, 'n_units_Layer_1': 165, 'n_units_Layer_2': 115, 'n_units_Layer_3': 135}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:09:17,228]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:09:17,746]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:09:22,556]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:09:23,366]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.22 | sMAPE for Validation Set is: 17.29% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.08 | sMAPE for Test Set is: 20.01% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:09:25,541]\u001b[0m Trial 949 finished with value: 6.217646802437373 and parameters: {'n_hidden': 3, 'learning_rate': 0.008605201928847152, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3602723629884341, 'dropout_rate_Layer_2': 0.3030499743568827, 'dropout_rate_Layer_3': 0.1798676846698383, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00024589488089359334, 'l1_Layer_2': 1.2923180622723992e-05, 'l1_Layer_3': 0.00022767853919368483, 'n_units_Layer_1': 160, 'n_units_Layer_2': 115, 'n_units_Layer_3': 165}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:09:32,439]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:09:32,720]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:09:36,465]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:09:38,762]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:09:41,745]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:09:42,071]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:09:53,700]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:09:54,249]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:09:58,639]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:10:02,206]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:10:02,383]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:10:05,505]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:10:09,961]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:10:10,136]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:10:16,480]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:10:18,943]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:10:20,931]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:10:23,638]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:10:26,092]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:10:29,249]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:10:32,245]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:10:38,459]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:10:38,980]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:10:39,985]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:10:48,305]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:10:49,810]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:10:50,617]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:10:57,862]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:11:01,723]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:11:12,269]\u001b[0m Trial 969 finished with value: 6.263693344987637 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011371999878837607, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04345350661690864, 'dropout_rate_Layer_2': 0.07328836753932648, 'dropout_rate_Layer_3': 0.09314986578978617, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0022707645488788987, 'l1_Layer_2': 0.00029215718578850326, 'l1_Layer_3': 0.0004094708847295284, 'n_units_Layer_1': 105, 'n_units_Layer_2': 280, 'n_units_Layer_3': 275}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.26 | sMAPE for Validation Set is: 17.04% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.12 | sMAPE for Test Set is: 19.66% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:11:14,659]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:11:16,158]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:11:19,576]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:11:22,254]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:11:25,720]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:11:32,701]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:11:36,395]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:11:36,820]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:11:42,412]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:11:55,298]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:12:00,667]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:12:01,497]\u001b[0m Trial 992 finished with value: 6.424011397972371 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022877521155173935, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0914890198112739, 'dropout_rate_Layer_2': 0.1601617036242568, 'dropout_rate_Layer_3': 0.05231799560363225, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009520012750254864, 'l1_Layer_2': 0.0004821661883903398, 'l1_Layer_3': 0.0006962733568565869, 'n_units_Layer_1': 210, 'n_units_Layer_2': 165, 'n_units_Layer_3': 250}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.42 | sMAPE for Validation Set is: 17.61% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.88 | sMAPE for Test Set is: 21.14% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:12:08,249]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:12:31,581]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:12:35,501]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:12:41,883]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:12:46,141]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:12:49,759]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:12:54,223]\u001b[0m Trial 997 finished with value: 6.349630107479778 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012695572754846036, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.032315363816327804, 'dropout_rate_Layer_2': 0.08600994909578771, 'dropout_rate_Layer_3': 0.09310175874105575, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003075336351810708, 'l1_Layer_2': 0.00031932911730209526, 'l1_Layer_3': 0.000597737133810398, 'n_units_Layer_1': 75, 'n_units_Layer_2': 285, 'n_units_Layer_3': 275}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.35 | sMAPE for Validation Set is: 17.22% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.28 | sMAPE for Test Set is: 19.78% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:13:02,389]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:13:05,031]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:13:06,208]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:13:16,970]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:13:27,226]\u001b[0m Trial 1003 finished with value: 6.226782042113872 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010813050885054814, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03554572217605763, 'dropout_rate_Layer_2': 0.17601591599147906, 'dropout_rate_Layer_3': 0.08997084918417389, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001210484795355697, 'l1_Layer_2': 0.000380951777323318, 'l1_Layer_3': 0.0005434819467829089, 'n_units_Layer_1': 120, 'n_units_Layer_2': 300, 'n_units_Layer_3': 275}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.23 | sMAPE for Validation Set is: 17.06% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.24 | sMAPE for Test Set is: 19.83% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:13:29,762]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:13:33,455]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:13:36,082]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:13:39,240]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:13:45,602]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.45 | sMAPE for Validation Set is: 17.45% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.50 | sMAPE for Test Set is: 20.18% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:13:48,678]\u001b[0m Trial 1009 finished with value: 6.446254138972063 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020954532938736864, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10331445132543844, 'dropout_rate_Layer_2': 0.20536347270330071, 'dropout_rate_Layer_3': 0.1307312672127221, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0010454561883730042, 'l1_Layer_2': 0.00036373547992447637, 'l1_Layer_3': 0.001199044444712693, 'n_units_Layer_1': 205, 'n_units_Layer_2': 160, 'n_units_Layer_3': 255}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:13:49,394]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:13:50,714]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:13:59,236]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:14:02,340]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:14:07,880]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:14:15,586]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:14:20,500]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:14:25,848]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:14:28,058]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:14:34,521]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:14:39,623]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:14:39,851]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:14:46,823]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:14:53,192]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:14:55,851]\u001b[0m Trial 1010 finished with value: 6.260055014905094 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009519967341988909, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.016255866981540565, 'dropout_rate_Layer_2': 0.1680857219074913, 'dropout_rate_Layer_3': 0.0887189106661696, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0029108462223971137, 'l1_Layer_2': 0.00039368609546121627, 'l1_Layer_3': 0.000533302506534626, 'n_units_Layer_1': 125, 'n_units_Layer_2': 300, 'n_units_Layer_3': 280}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.26 | sMAPE for Validation Set is: 17.12% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.77 | sMAPE for Test Set is: 18.53% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:14:58,773]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:15:01,261]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:15:07,080]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:15:07,764]\u001b[0m Trial 1019 finished with value: 6.309382059720641 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010468992275039345, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3332026052383463, 'dropout_rate_Layer_2': 0.17544631741121325, 'dropout_rate_Layer_3': 0.0865507192252059, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004165727043253087, 'l1_Layer_2': 0.0216526854234353, 'l1_Layer_3': 1.0900833331188084e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 295, 'n_units_Layer_3': 275}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.31 | sMAPE for Validation Set is: 17.35% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.32 | sMAPE for Test Set is: 19.80% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:15:14,362]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:15:15,337]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:15:16,012]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:15:25,979]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:15:26,292]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:15:26,354]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:15:26,580]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:15:38,963]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:15:41,847]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:15:42,898]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:15:44,049]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:15:49,703]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:15:54,200]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:15:54,734]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:15:54,956]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:16:04,260]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:16:07,119]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:16:08,547]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:16:11,592]\u001b[0m Trial 1047 finished with value: 6.3037901844425575 and parameters: {'n_hidden': 3, 'learning_rate': 0.013136843493001154, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2712475868589652, 'dropout_rate_Layer_2': 0.254525778007443, 'dropout_rate_Layer_3': 0.15638540404205328, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.277258149295558e-05, 'l1_Layer_2': 1.8647423637283903e-05, 'l1_Layer_3': 0.000413945563947194, 'n_units_Layer_1': 180, 'n_units_Layer_2': 165, 'n_units_Layer_3': 80}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.30 | sMAPE for Validation Set is: 17.26% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.98 | sMAPE for Test Set is: 19.59% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:16:14,770]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:16:21,439]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:16:21,583]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:16:22,429]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:16:23,465]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:16:32,418]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:16:32,580]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:16:33,758]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:16:41,486]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:16:41,711]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:16:42,238]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:16:43,168]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:16:50,417]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:16:54,100]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:16:54,424]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:16:56,290]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:16:56,674]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:17:00,142]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:17:02,786]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:17:05,780]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:17:08,749]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:17:12,959]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:17:13,123]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:17:14,579]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:17:22,131]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:17:26,236]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:17:29,597]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:17:29,736]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:17:35,215]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:17:37,693]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:17:40,636]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:17:44,417]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:17:46,285]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:17:49,742]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:17:54,217]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:17:56,928]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:18:01,251]\u001b[0m Trial 1082 finished with value: 6.238695179316973 and parameters: {'n_hidden': 3, 'learning_rate': 0.003895271101031247, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21113323023772984, 'dropout_rate_Layer_2': 0.17455680578220928, 'dropout_rate_Layer_3': 0.25477325074306345, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00018031671984495255, 'l1_Layer_2': 3.912211100320191e-05, 'l1_Layer_3': 0.00015687346164027877, 'n_units_Layer_1': 195, 'n_units_Layer_2': 115, 'n_units_Layer_3': 135}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.24 | sMAPE for Validation Set is: 17.12% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.25 | sMAPE for Test Set is: 19.82% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:18:01,623]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:18:07,082]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:18:07,593]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:18:12,588]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:18:16,484]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:18:18,261]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:18:22,972]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:18:24,761]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:18:29,851]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:18:31,271]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:18:37,383]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:18:44,273]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:18:47,352]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:18:50,154]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:18:52,802]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:18:57,423]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:18:59,349]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:19:04,018]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:19:07,642]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:19:12,500]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:19:13,594]\u001b[0m Trial 1079 finished with value: 6.223718017966277 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008609789263475246, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31222035649846397, 'dropout_rate_Layer_2': 0.1850998092539928, 'dropout_rate_Layer_3': 0.08139470433174603, 'dropout_rate_Layer_4': 0.3496576865137252, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.003423166995346451, 'l1_Layer_2': 0.0007034242875582969, 'l1_Layer_3': 1.04352831851123e-05, 'l1_Layer_4': 0.0001529754446473643, 'n_units_Layer_1': 105, 'n_units_Layer_2': 295, 'n_units_Layer_3': 280, 'n_units_Layer_4': 285}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.22 | sMAPE for Validation Set is: 16.86% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.25 | sMAPE for Test Set is: 19.61% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:19:18,220]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:19:19,572]\u001b[0m Trial 1106 finished with value: 6.095573833874208 and parameters: {'n_hidden': 3, 'learning_rate': 0.006474419692409765, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2580164449439388, 'dropout_rate_Layer_2': 0.3222788400853662, 'dropout_rate_Layer_3': 0.1630471884230167, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004256444880571065, 'l1_Layer_2': 1.3740992987073046e-05, 'l1_Layer_3': 0.000602957913027163, 'n_units_Layer_1': 135, 'n_units_Layer_2': 105, 'n_units_Layer_3': 130}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.10 | sMAPE for Validation Set is: 16.77% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.80 | sMAPE for Test Set is: 19.01% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:19:19,999]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:19:24,204]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:19:30,522]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:19:33,045]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:19:34,515]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:19:34,821]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:19:35,643]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:19:39,134]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:19:43,513]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:19:46,456]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:19:47,282]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:19:47,343]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:19:58,546]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:19:58,734]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:20:03,824]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:20:05,233]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:20:05,587]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:20:05,639]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:20:13,085]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:20:17,590]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:20:21,239]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:20:25,270]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:20:26,512]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:20:31,953]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:20:35,981]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:20:42,142]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:20:45,522]\u001b[0m Trial 1133 finished with value: 6.153994771761325 and parameters: {'n_hidden': 3, 'learning_rate': 0.006628275770217264, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2723247313452475, 'dropout_rate_Layer_2': 0.2894788444522525, 'dropout_rate_Layer_3': 0.1632861192472052, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000287434998141744, 'l1_Layer_2': 1.8410619123860708e-05, 'l1_Layer_3': 0.0006014685100309723, 'n_units_Layer_1': 145, 'n_units_Layer_2': 130, 'n_units_Layer_3': 145}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.15 | sMAPE for Validation Set is: 17.24% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.03 | sMAPE for Test Set is: 19.91% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:20:47,313]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:20:52,105]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:20:52,616]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:20:59,694]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:21:01,868]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:21:01,974]\u001b[0m Trial 1134 finished with value: 6.093882073437314 and parameters: {'n_hidden': 3, 'learning_rate': 0.005066440676366596, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3101792622146083, 'dropout_rate_Layer_2': 0.26968018477445865, 'dropout_rate_Layer_3': 0.1646725434531692, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00028910514450166834, 'l1_Layer_2': 2.0366386405722304e-05, 'l1_Layer_3': 0.0005893826891949755, 'n_units_Layer_1': 145, 'n_units_Layer_2': 105, 'n_units_Layer_3': 130}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.09 | sMAPE for Validation Set is: 16.79% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.88 | sMAPE for Test Set is: 19.16% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:21:02,081]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:21:09,168]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:21:14,384]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:21:14,695]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:21:20,638]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:21:21,823]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:21:24,562]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:21:29,100]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:21:30,311]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:21:30,897]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:21:36,875]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:21:39,196]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:21:41,647]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:21:42,302]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:21:43,378]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:21:51,107]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:21:54,533]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:21:55,676]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:21:56,412]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:22:05,175]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:22:05,637]\u001b[0m Trial 1158 finished with value: 6.286301215679231 and parameters: {'n_hidden': 3, 'learning_rate': 0.006475235314779709, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19359738384451725, 'dropout_rate_Layer_2': 0.2706835251171286, 'dropout_rate_Layer_3': 0.3194754848324676, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000768837222785765, 'l1_Layer_2': 1.033823518435223e-05, 'l1_Layer_3': 0.0006092413259648671, 'n_units_Layer_1': 145, 'n_units_Layer_2': 105, 'n_units_Layer_3': 130}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.29 | sMAPE for Validation Set is: 17.38% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.03 | sMAPE for Test Set is: 19.53% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:22:06,721]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:22:12,120]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:22:15,042]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:22:15,520]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:22:16,938]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:22:22,892]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:22:26,579]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:22:28,253]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:22:31,598]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:22:32,921]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:22:34,708]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:22:34,939]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:22:43,147]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:22:46,824]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:22:49,814]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:22:50,510]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:22:56,895]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:23:01,327]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.45 | sMAPE for Validation Set is: 17.59% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.05 | sMAPE for Test Set is: 19.61% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:23:03,549]\u001b[0m Trial 1180 finished with value: 6.453497298240829 and parameters: {'n_hidden': 3, 'learning_rate': 0.004301872457013747, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3090982425416382, 'dropout_rate_Layer_2': 0.3046439968353991, 'dropout_rate_Layer_3': 0.16119795515333996, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000308734478344377, 'l1_Layer_2': 3.251470266946663e-05, 'l1_Layer_3': 0.0021483848841709983, 'n_units_Layer_1': 135, 'n_units_Layer_2': 130, 'n_units_Layer_3': 100}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:23:06,629]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:23:07,793]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:23:16,101]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:23:19,035]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:23:20,314]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:23:25,073]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:23:25,244]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:23:25,866]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:23:33,718]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:23:33,903]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:23:34,322]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:23:42,090]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:23:46,170]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:23:47,089]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:23:53,111]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:23:54,587]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:23:58,411]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:23:59,191]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:24:00,172]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:24:00,651]\u001b[0m Trial 1194 finished with value: 6.101626405559716 and parameters: {'n_hidden': 3, 'learning_rate': 0.005633316257918476, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02007574075702409, 'dropout_rate_Layer_2': 0.2686209475169263, 'dropout_rate_Layer_3': 0.10423620811436524, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.458400670047701e-05, 'l1_Layer_2': 0.002779029515624146, 'l1_Layer_3': 0.00040864604603280867, 'n_units_Layer_1': 160, 'n_units_Layer_2': 135, 'n_units_Layer_3': 125}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.10 | sMAPE for Validation Set is: 16.96% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.93 | sMAPE for Test Set is: 19.39% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:24:07,232]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:24:09,489]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:24:13,115]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:24:13,260]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:24:21,594]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:24:21,934]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:24:23,088]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:24:25,509]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:24:29,582]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:24:35,308]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:24:37,398]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:24:40,741]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:24:41,643]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:24:43,839]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:24:44,704]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:24:50,681]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:24:53,169]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:24:54,223]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:24:57,567]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:24:58,499]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:25:05,121]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:25:09,168]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:25:10,177]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:25:15,457]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:25:20,601]\u001b[0m Trial 1227 finished with value: 6.123486891825522 and parameters: {'n_hidden': 3, 'learning_rate': 0.005411091567819961, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02640220463486187, 'dropout_rate_Layer_2': 0.01823877502399668, 'dropout_rate_Layer_3': 0.18420316601669892, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016025751712546603, 'l1_Layer_2': 0.002472141533193995, 'l1_Layer_3': 0.0007514006226038252, 'n_units_Layer_1': 155, 'n_units_Layer_2': 130, 'n_units_Layer_3': 140}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.12 | sMAPE for Validation Set is: 16.85% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.90 | sMAPE for Test Set is: 19.08% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:25:21,023]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:25:28,619]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:25:29,076]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:25:32,280]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:25:36,546]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:25:39,072]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:25:42,478]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:25:43,241]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:25:46,670]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.12 | sMAPE for Validation Set is: 16.86% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.92 | sMAPE for Test Set is: 19.20% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:25:51,667]\u001b[0m Trial 1234 finished with value: 6.119008528937619 and parameters: {'n_hidden': 3, 'learning_rate': 0.004472694656034606, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0063020828493194105, 'dropout_rate_Layer_2': 0.23918467284100017, 'dropout_rate_Layer_3': 0.2134627266010485, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016320995157625753, 'l1_Layer_2': 0.002198967604447744, 'l1_Layer_3': 0.000724287705992313, 'n_units_Layer_1': 155, 'n_units_Layer_2': 110, 'n_units_Layer_3': 115}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:25:52,314]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:25:54,003]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:25:56,908]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:26:01,327]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:26:01,716]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:26:08,927]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:26:09,112]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:26:10,494]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:26:18,728]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:26:19,421]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:26:26,095]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:26:26,716]\u001b[0m Trial 1244 finished with value: 6.181531310262959 and parameters: {'n_hidden': 3, 'learning_rate': 0.007307591044244775, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.013344329123374056, 'dropout_rate_Layer_2': 0.23888150635078648, 'dropout_rate_Layer_3': 0.19180045778528845, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016238631283109, 'l1_Layer_2': 0.0038298901725827895, 'l1_Layer_3': 0.0008130652822333181, 'n_units_Layer_1': 160, 'n_units_Layer_2': 110, 'n_units_Layer_3': 115}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.18 | sMAPE for Validation Set is: 16.98% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.09 | sMAPE for Test Set is: 19.58% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:26:30,114]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:26:34,652]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:26:38,055]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:26:42,637]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:26:42,787]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:26:49,982]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:26:51,033]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:26:54,876]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:26:55,584]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:26:58,090]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:27:04,582]\u001b[0m Trial 1250 finished with value: 6.31858336084687 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008896636550662522, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0443037708138447, 'dropout_rate_Layer_2': 0.16401884915859263, 'dropout_rate_Layer_3': 0.10744349774102029, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001501402634557318, 'l1_Layer_2': 0.00029631359715632263, 'l1_Layer_3': 9.937614002151728e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 270, 'n_units_Layer_3': 290}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.32 | sMAPE for Validation Set is: 17.19% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.65 | sMAPE for Test Set is: 20.26% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:27:05,544]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:27:07,229]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:27:08,685]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:27:17,230]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:27:18,766]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:27:19,933]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:27:22,866]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:27:25,181]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:27:29,387]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:27:35,941]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:27:38,659]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:27:42,044]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:27:44,553]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:27:47,624]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:27:48,459]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:27:50,117]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:27:52,013]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:27:56,668]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:27:57,004]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:28:03,210]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:28:08,694]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:28:12,624]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:28:16,915]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:28:18,111]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:28:22,511]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:28:22,667]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:28:30,104]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:28:30,246]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:28:37,165]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:28:37,319]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:28:38,454]\u001b[0m Trial 1284 finished with value: 6.580891020826344 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011746307279094821, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09839403632019658, 'dropout_rate_Layer_2': 0.3229737958321407, 'dropout_rate_Layer_3': 0.3726667724473442, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0029808273582582027, 'l1_Layer_2': 0.032903895306362695, 'l1_Layer_3': 2.6180185784258956e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 240, 'n_units_Layer_3': 270}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.58 | sMAPE for Validation Set is: 17.99% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.58 | sMAPE for Test Set is: 20.64% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:28:42,430]\u001b[0m Trial 1290 finished with value: 6.110999201390773 and parameters: {'n_hidden': 3, 'learning_rate': 0.005593561065755991, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.012485468112472059, 'dropout_rate_Layer_2': 0.10952966351577247, 'dropout_rate_Layer_3': 0.2348994784138119, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.500378241063259e-05, 'l1_Layer_2': 0.0017346612694941772, 'l1_Layer_3': 0.0019898098862215882, 'n_units_Layer_1': 135, 'n_units_Layer_2': 105, 'n_units_Layer_3': 155}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.11 | sMAPE for Validation Set is: 16.91% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.97 | sMAPE for Test Set is: 19.45% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:28:49,654]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:28:50,395]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:28:56,800]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:28:57,216]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:28:58,599]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:29:06,028]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:29:07,396]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:29:10,158]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:29:17,757]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:29:18,173]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:29:20,083]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:29:26,751]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:29:29,401]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:29:31,927]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:29:33,679]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:29:35,890]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:29:41,587]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:29:43,228]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:29:49,158]\u001b[0m Trial 1298 finished with value: 6.405868159246178 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006909045644473875, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11199274588688267, 'dropout_rate_Layer_2': 0.34322410584968543, 'dropout_rate_Layer_3': 0.38670390648604513, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002532254022142564, 'l1_Layer_2': 0.017162225554170116, 'l1_Layer_3': 4.0536600805613606e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 260, 'n_units_Layer_3': 280}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.41 | sMAPE for Validation Set is: 17.60% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.23 | sMAPE for Test Set is: 19.83% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:29:50,057]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:29:57,439]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:29:58,325]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:29:58,621]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:30:04,684]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:30:07,155]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:30:09,903]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:30:10,740]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:30:14,075]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:30:18,987]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:30:20,626]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:30:24,469]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:30:28,911]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:30:34,196]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:30:34,376]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:30:34,891]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:30:42,773]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:30:44,134]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:30:44,889]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:30:44,891]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:30:49,785]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:30:53,374]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:30:58,464]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:31:02,903]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:31:04,271]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:31:07,343]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:31:08,063]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:31:18,829]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:31:19,107]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:31:19,267]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:31:19,396]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:31:30,507]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:31:30,937]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:31:33,145]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:31:38,294]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:31:41,027]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:31:44,757]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:31:49,465]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:31:53,724]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:31:57,316]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:31:57,683]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:32:02,055]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:32:02,745]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:32:08,079]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:32:12,547]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:32:13,443]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:32:13,648]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:32:15,766]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:32:24,855]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:32:26,898]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:32:31,525]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:32:33,984]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:32:38,312]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:32:39,349]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:32:45,422]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:32:49,335]\u001b[0m Trial 1365 finished with value: 6.169736294498878 and parameters: {'n_hidden': 3, 'learning_rate': 0.0037949994143366274, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.016960781367044778, 'dropout_rate_Layer_2': 0.01649953140281335, 'dropout_rate_Layer_3': 0.23565227795174554, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020470000885549765, 'l1_Layer_2': 0.0013871011071835623, 'l1_Layer_3': 0.0021048181000157622, 'n_units_Layer_1': 155, 'n_units_Layer_2': 110, 'n_units_Layer_3': 155}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.17 | sMAPE for Validation Set is: 16.89% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.88 | sMAPE for Test Set is: 19.08% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:32:51,005]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:32:54,635]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:32:59,567]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:33:02,935]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:33:03,667]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:33:05,802]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:33:11,311]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:33:13,307]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:33:14,963]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:33:17,470]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:33:20,825]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:33:24,601]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:33:31,947]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:33:32,911]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:33:39,490]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:33:39,912]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:33:40,285]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:33:49,669]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:33:50,925]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:33:51,893]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:33:52,936]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:33:58,843]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:34:03,810]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:34:04,953]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:34:07,131]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:34:12,682]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:34:14,147]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:34:18,707]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:34:23,427]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:34:23,699]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:34:30,455]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:34:30,909]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:34:31,970]\u001b[0m Trial 1395 finished with value: 6.162719590053989 and parameters: {'n_hidden': 3, 'learning_rate': 0.00543966911425942, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.005664831600919206, 'dropout_rate_Layer_2': 0.1221840288814209, 'dropout_rate_Layer_3': 0.20747323002825746, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.84119865139189e-05, 'l1_Layer_2': 0.0009758884344970547, 'l1_Layer_3': 0.000784942062386236, 'n_units_Layer_1': 140, 'n_units_Layer_2': 115, 'n_units_Layer_3': 130}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.16 | sMAPE for Validation Set is: 16.91% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.83 | sMAPE for Test Set is: 18.93% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:34:38,690]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:34:42,835]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:34:44,494]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:34:47,406]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:34:48,630]\u001b[0m Trial 1396 finished with value: 6.155753384779313 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011502178854479977, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.031615701755903496, 'dropout_rate_Layer_2': 0.15062659045405125, 'dropout_rate_Layer_3': 0.09842309596352848, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001034296623555223, 'l1_Layer_2': 0.00022266261076329556, 'l1_Layer_3': 1.6452098094040768e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 295, 'n_units_Layer_3': 175}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.16 | sMAPE for Validation Set is: 16.86% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.20 | sMAPE for Test Set is: 20.20% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:34:49,049]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:34:54,795]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:34:56,140]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:35:01,407]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:35:04,418]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:35:07,619]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:35:10,347]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:35:16,511]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:35:17,037]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:35:18,700]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:35:19,086]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:35:30,331]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:35:30,951]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:35:37,597]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:35:40,819]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:35:41,729]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:35:41,869]\u001b[0m Trial 1421 finished with value: 6.441891380058987 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011565145890967358, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.025771358453757512, 'dropout_rate_Layer_2': 0.15298918659391716, 'dropout_rate_Layer_3': 0.0894256460760687, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003014522285541306, 'l1_Layer_2': 0.00025949762714009986, 'l1_Layer_3': 2.0629967395428228e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 225, 'n_units_Layer_3': 130}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.44 | sMAPE for Validation Set is: 17.52% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.99 | sMAPE for Test Set is: 21.35% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:35:52,147]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:35:54,769]\u001b[0m Trial 1425 finished with value: 6.155735922354782 and parameters: {'n_hidden': 3, 'learning_rate': 0.008760324182377119, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11189012674487188, 'dropout_rate_Layer_2': 0.18715155199949002, 'dropout_rate_Layer_3': 0.1727910812255918, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014625204758946786, 'l1_Layer_2': 0.0021433833564241155, 'l1_Layer_3': 0.0004154366734788537, 'n_units_Layer_1': 150, 'n_units_Layer_2': 135, 'n_units_Layer_3': 115}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.16 | sMAPE for Validation Set is: 16.80% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.98 | sMAPE for Test Set is: 19.02% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:35:57,126]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:36:02,558]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:36:10,176]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:36:15,880]\u001b[0m Trial 1428 finished with value: 5.959656256510698 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014264748831082715, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02272600421757844, 'dropout_rate_Layer_2': 0.15344957253031913, 'dropout_rate_Layer_3': 0.08444100885429842, 'dropout_rate_Layer_4': 0.19532386704390362, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00023050052322576438, 'l1_Layer_2': 0.000198638340679051, 'l1_Layer_3': 1.9595871203690086e-05, 'l1_Layer_4': 3.7593389854199884e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 210, 'n_units_Layer_3': 125, 'n_units_Layer_4': 215}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.96 | sMAPE for Validation Set is: 16.56% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.91 | sMAPE for Test Set is: 19.26% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:36:16,067]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:36:24,255]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:36:24,748]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:36:31,420]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:36:32,049]\u001b[0m Trial 1430 finished with value: 6.134045307592419 and parameters: {'n_hidden': 3, 'learning_rate': 0.003370721720638153, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.031294677092838216, 'dropout_rate_Layer_2': 0.26460009860327177, 'dropout_rate_Layer_3': 0.2544100973795767, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001232032534285951, 'l1_Layer_2': 0.0011126379688588108, 'l1_Layer_3': 0.0027624629656147035, 'n_units_Layer_1': 175, 'n_units_Layer_2': 125, 'n_units_Layer_3': 140}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.13 | sMAPE for Validation Set is: 16.84% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.01 | sMAPE for Test Set is: 19.35% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:36:32,252]\u001b[0m Trial 1432 finished with value: 6.269905952400696 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014517372633053645, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007096049960487575, 'dropout_rate_Layer_2': 0.24815118434430908, 'dropout_rate_Layer_3': 0.08735848168904346, 'dropout_rate_Layer_4': 0.1556994003989193, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00021066801413660458, 'l1_Layer_2': 0.000354405296572591, 'l1_Layer_3': 2.1311350609817346e-05, 'l1_Layer_4': 0.0009889634162181145, 'n_units_Layer_1': 110, 'n_units_Layer_2': 135, 'n_units_Layer_3': 135, 'n_units_Layer_4': 80}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.27 | sMAPE for Validation Set is: 17.18% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.21 | sMAPE for Test Set is: 19.99% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:36:33,570]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:36:36,945]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:36:44,179]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:36:47,317]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:36:48,853]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:36:50,187]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:37:00,299]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:37:01,396]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:37:01,463]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:37:09,464]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:37:13,521]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:37:14,136]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:37:20,589]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:37:20,953]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:37:27,123]\u001b[0m Trial 1445 finished with value: 6.806020918363078 and parameters: {'n_hidden': 4, 'learning_rate': 0.0047419563930778535, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.015501593084405735, 'dropout_rate_Layer_2': 0.15671852824974872, 'dropout_rate_Layer_3': 0.1871036429754413, 'dropout_rate_Layer_4': 0.30875375140888595, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005008965745988535, 'l1_Layer_2': 0.0012640107040715546, 'l1_Layer_3': 4.7119157918111775e-05, 'l1_Layer_4': 0.03971851249079663, 'n_units_Layer_1': 200, 'n_units_Layer_2': 60, 'n_units_Layer_3': 230, 'n_units_Layer_4': 65}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.81 | sMAPE for Validation Set is: 18.57% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.71 | sMAPE for Test Set is: 20.83% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:37:27,872]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:37:35,765]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:37:36,480]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:37:36,506]\u001b[0m Trial 1447 finished with value: 6.144340316410727 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015608547638478155, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.012363618258618056, 'dropout_rate_Layer_2': 0.2517104018783573, 'dropout_rate_Layer_3': 0.06638355310550759, 'dropout_rate_Layer_4': 0.1288049436114139, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00021222394173143507, 'l1_Layer_2': 0.00038941322941235854, 'l1_Layer_3': 2.2232406079714573e-05, 'l1_Layer_4': 8.668814552788958e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 110, 'n_units_Layer_3': 130, 'n_units_Layer_4': 65}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.14 | sMAPE for Validation Set is: 16.91% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.13 | sMAPE for Test Set is: 19.81% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:37:47,600]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:37:48,075]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:37:48,176]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:37:58,557]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:37:59,118]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:38:05,767]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:38:06,415]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:38:06,735]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:38:17,019]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:38:19,841]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:38:21,799]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:38:28,959]\u001b[0m Trial 1461 finished with value: 6.248104441780008 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015601715003916313, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.015571157035398126, 'dropout_rate_Layer_2': 0.23964419801284212, 'dropout_rate_Layer_3': 0.07802975097967418, 'dropout_rate_Layer_4': 0.12363867252852381, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00022064084235480722, 'l1_Layer_2': 0.0006669141373685946, 'l1_Layer_3': 1.3808259614099543e-05, 'l1_Layer_4': 4.425323259951536e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 85, 'n_units_Layer_3': 130, 'n_units_Layer_4': 130}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.25 | sMAPE for Validation Set is: 17.15% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.20 | sMAPE for Test Set is: 19.97% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:38:32,453]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:38:35,091]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:38:35,742]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:38:36,139]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:38:40,123]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:38:40,683]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:38:50,444]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:38:50,987]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:38:57,493]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:39:01,377]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:39:02,977]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:39:09,026]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:39:09,870]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:39:15,430]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:39:16,921]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:39:16,968]\u001b[0m Trial 1474 finished with value: 6.25844263854792 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015191782934705726, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008026225111172763, 'dropout_rate_Layer_2': 0.24857970536107904, 'dropout_rate_Layer_3': 0.0806678049468319, 'dropout_rate_Layer_4': 0.10514424669843783, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0001961340202356884, 'l1_Layer_2': 0.000516900254231134, 'l1_Layer_3': 1.2850239651369583e-05, 'l1_Layer_4': 7.510770974847444e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 135, 'n_units_Layer_3': 120, 'n_units_Layer_4': 110}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.26 | sMAPE for Validation Set is: 17.06% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.06 | sMAPE for Test Set is: 19.61% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:39:22,191]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:39:24,005]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:39:32,647]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:39:33,551]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:39:41,036]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:39:41,226]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:39:42,062]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:39:49,312]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:39:51,675]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:39:54,420]\u001b[0m Trial 1486 finished with value: 6.17799424744629 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016621425993943186, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.003354698557065836, 'dropout_rate_Layer_2': 0.24893229847027884, 'dropout_rate_Layer_3': 0.0589646534632657, 'dropout_rate_Layer_4': 0.1091308538027916, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00018277566736379816, 'l1_Layer_2': 0.00047601318817375355, 'l1_Layer_3': 1.2761837377765929e-05, 'l1_Layer_4': 0.00014189102439119395, 'n_units_Layer_1': 105, 'n_units_Layer_2': 110, 'n_units_Layer_3': 130, 'n_units_Layer_4': 130}. Best is trial 203 with value: 5.852935425088059.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.18 | sMAPE for Validation Set is: 17.06% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.03 | sMAPE for Test Set is: 19.53% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 23:39:57,725]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:39:58,375]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:39:59,434]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:40:01,989]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:40:04,565]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 23:40:04,850]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-01-01, MAE is:33.80 & sMAPE is:182.33% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :33.80 & 182.33% & 1.40\n",
      "for 2019-01-02, MAE is:30.99 & sMAPE is:111.57% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :32.39 & 146.95% & 1.55\n",
      "for 2019-01-03, MAE is:13.48 & sMAPE is:26.91% & rMAE is:2.20 ||| daily mean of MAE & sMAPE & rMAE till now are :26.09 & 106.94% & 1.77\n",
      "for 2019-01-04, MAE is:3.48 & sMAPE is:7.54% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :20.44 & 82.09% & 1.54\n",
      "for 2019-01-05, MAE is:12.52 & sMAPE is:31.73% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :18.85 & 72.02% & 1.44\n",
      "for 2019-01-06, MAE is:8.09 & sMAPE is:17.32% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :17.06 & 62.90% & 1.27\n",
      "for 2019-01-07, MAE is:7.13 & sMAPE is:17.28% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :15.64 & 56.38% & 1.31\n",
      "for 2019-01-08, MAE is:10.94 & sMAPE is:35.07% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :15.05 & 53.72% & 1.18\n",
      "for 2019-01-09, MAE is:11.04 & sMAPE is:35.53% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :14.61 & 51.70% & 1.13\n",
      "for 2019-01-10, MAE is:10.67 & sMAPE is:18.89% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :14.21 & 48.42% & 1.16\n",
      "for 2019-01-11, MAE is:3.44 & sMAPE is:6.80% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :13.23 & 44.63% & 1.17\n",
      "for 2019-01-12, MAE is:1.49 & sMAPE is:3.08% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :12.26 & 41.17% & 1.09\n",
      "for 2019-01-13, MAE is:16.71 & sMAPE is:48.63% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :12.60 & 41.74% & 1.07\n",
      "for 2019-01-14, MAE is:16.22 & sMAPE is:79.55% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :12.86 & 44.44% & 1.05\n",
      "for 2019-01-15, MAE is:8.08 & sMAPE is:18.66% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :12.54 & 42.73% & 1.02\n",
      "for 2019-01-16, MAE is:3.77 & sMAPE is:7.57% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :11.99 & 40.53% & 0.97\n",
      "for 2019-01-17, MAE is:4.61 & sMAPE is:10.04% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :11.56 & 38.74% & 0.94\n",
      "for 2019-01-18, MAE is:7.33 & sMAPE is:12.22% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :11.32 & 37.26% & 0.92\n",
      "for 2019-01-19, MAE is:2.58 & sMAPE is:4.74% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :10.86 & 35.55% & 0.90\n",
      "for 2019-01-20, MAE is:7.14 & sMAPE is:13.73% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :10.68 & 34.46% & 0.87\n",
      "for 2019-01-21, MAE is:12.35 & sMAPE is:18.61% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :10.76 & 33.70% & 0.84\n",
      "for 2019-01-22, MAE is:4.48 & sMAPE is:6.85% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :10.47 & 32.48% & 0.82\n",
      "for 2019-01-23, MAE is:10.85 & sMAPE is:15.67% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :10.49 & 31.75% & 0.81\n",
      "for 2019-01-24, MAE is:18.80 & sMAPE is:23.95% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :10.83 & 31.43% & 0.81\n",
      "for 2019-01-25, MAE is:7.22 & sMAPE is:10.68% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :10.69 & 30.60% & 0.82\n",
      "for 2019-01-26, MAE is:3.07 & sMAPE is:6.04% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :10.40 & 29.65% & 0.82\n",
      "for 2019-01-27, MAE is:7.48 & sMAPE is:19.33% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :10.29 & 29.27% & 0.82\n",
      "for 2019-01-28, MAE is:4.01 & sMAPE is:7.08% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :10.06 & 28.48% & 0.80\n",
      "for 2019-01-29, MAE is:4.39 & sMAPE is:7.09% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :9.87 & 27.74% & 0.82\n",
      "for 2019-01-30, MAE is:4.18 & sMAPE is:7.42% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :9.68 & 27.06% & 0.80\n",
      "for 2019-01-31, MAE is:3.01 & sMAPE is:5.73% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :9.46 & 26.38% & 0.78\n",
      "for 2019-02-01, MAE is:2.78 & sMAPE is:5.09% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :9.25 & 25.71% & 0.76\n",
      "for 2019-02-02, MAE is:1.60 & sMAPE is:3.14% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :9.02 & 25.03% & 0.75\n",
      "for 2019-02-03, MAE is:1.75 & sMAPE is:3.45% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :8.81 & 24.39% & 0.74\n",
      "for 2019-02-04, MAE is:9.22 & sMAPE is:18.29% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :8.82 & 24.22% & 0.75\n",
      "for 2019-02-05, MAE is:8.66 & sMAPE is:19.47% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :8.82 & 24.09% & 0.75\n",
      "for 2019-02-06, MAE is:3.88 & sMAPE is:7.12% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :8.68 & 23.63% & 0.77\n",
      "for 2019-02-07, MAE is:8.71 & sMAPE is:17.39% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :8.68 & 23.46% & 0.78\n",
      "for 2019-02-08, MAE is:6.59 & sMAPE is:17.40% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :8.63 & 23.31% & 0.77\n",
      "for 2019-02-09, MAE is:22.34 & sMAPE is:145.91% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :8.97 & 26.37% & 0.76\n",
      "for 2019-02-10, MAE is:20.13 & sMAPE is:101.20% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :9.24 & 28.20% & 0.77\n",
      "for 2019-02-11, MAE is:10.96 & sMAPE is:47.01% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :9.28 & 28.65% & 0.77\n",
      "for 2019-02-12, MAE is:3.67 & sMAPE is:8.20% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :9.15 & 28.17% & 0.77\n",
      "for 2019-02-13, MAE is:2.43 & sMAPE is:5.76% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :9.00 & 27.66% & 0.76\n",
      "for 2019-02-14, MAE is:4.18 & sMAPE is:8.56% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :8.89 & 27.24% & 0.76\n",
      "for 2019-02-15, MAE is:3.73 & sMAPE is:8.31% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :8.78 & 26.82% & 0.76\n",
      "for 2019-02-16, MAE is:2.59 & sMAPE is:6.79% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :8.65 & 26.40% & 0.74\n",
      "for 2019-02-17, MAE is:4.68 & sMAPE is:11.73% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :8.57 & 26.09% & 0.74\n",
      "for 2019-02-18, MAE is:2.85 & sMAPE is:6.31% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :8.45 & 25.69% & 0.73\n",
      "for 2019-02-19, MAE is:3.43 & sMAPE is:8.62% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :8.35 & 25.35% & 0.72\n",
      "for 2019-02-20, MAE is:4.62 & sMAPE is:10.42% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :8.28 & 25.06% & 0.74\n",
      "for 2019-02-21, MAE is:3.06 & sMAPE is:6.88% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :8.18 & 24.71% & 0.74\n",
      "for 2019-02-22, MAE is:3.50 & sMAPE is:7.37% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :8.09 & 24.38% & 0.75\n",
      "for 2019-02-23, MAE is:2.13 & sMAPE is:5.17% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :7.98 & 24.02% & 0.75\n",
      "for 2019-02-24, MAE is:2.45 & sMAPE is:6.37% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :7.88 & 23.70% & 0.75\n",
      "for 2019-02-25, MAE is:3.66 & sMAPE is:8.27% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :7.80 & 23.43% & 0.76\n",
      "for 2019-02-26, MAE is:3.85 & sMAPE is:8.39% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :7.73 & 23.16% & 0.77\n",
      "for 2019-02-27, MAE is:2.80 & sMAPE is:6.67% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :7.65 & 22.88% & 0.76\n",
      "for 2019-02-28, MAE is:4.10 & sMAPE is:10.37% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :7.59 & 22.67% & 0.77\n",
      "for 2019-03-01, MAE is:4.94 & sMAPE is:11.27% & rMAE is:1.78 ||| daily mean of MAE & sMAPE & rMAE till now are :7.54 & 22.48% & 0.79\n",
      "for 2019-03-02, MAE is:3.94 & sMAPE is:10.22% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :7.48 & 22.28% & 0.79\n",
      "for 2019-03-03, MAE is:19.18 & sMAPE is:118.62% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :7.67 & 23.83% & 0.79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-03-04, MAE is:21.72 & sMAPE is:99.83% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :7.90 & 25.04% & 0.79\n",
      "for 2019-03-05, MAE is:14.88 & sMAPE is:85.47% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :8.01 & 25.98% & 0.80\n",
      "for 2019-03-06, MAE is:6.52 & sMAPE is:17.40% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :7.98 & 25.85% & 0.80\n",
      "for 2019-03-07, MAE is:8.39 & sMAPE is:22.74% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :7.99 & 25.80% & 0.81\n",
      "for 2019-03-08, MAE is:7.16 & sMAPE is:22.77% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :7.98 & 25.76% & 0.81\n",
      "for 2019-03-09, MAE is:27.16 & sMAPE is:139.51% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :8.26 & 27.43% & 0.81\n",
      "for 2019-03-10, MAE is:16.48 & sMAPE is:86.29% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :8.38 & 28.28% & 0.81\n",
      "for 2019-03-11, MAE is:4.69 & sMAPE is:11.41% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :8.33 & 28.04% & 0.80\n",
      "for 2019-03-12, MAE is:8.82 & sMAPE is:26.48% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :8.33 & 28.02% & 0.79\n",
      "for 2019-03-13, MAE is:13.05 & sMAPE is:45.41% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :8.40 & 28.26% & 0.80\n",
      "for 2019-03-14, MAE is:3.46 & sMAPE is:9.94% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :8.33 & 28.01% & 0.81\n",
      "for 2019-03-15, MAE is:7.40 & sMAPE is:25.27% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :8.32 & 27.97% & 0.80\n",
      "for 2019-03-16, MAE is:12.00 & sMAPE is:86.98% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :8.37 & 28.76% & 0.80\n",
      "for 2019-03-17, MAE is:13.78 & sMAPE is:109.27% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :8.44 & 29.82% & 0.80\n",
      "for 2019-03-18, MAE is:7.81 & sMAPE is:31.00% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :8.43 & 29.83% & 0.79\n",
      "for 2019-03-19, MAE is:5.29 & sMAPE is:12.32% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :8.39 & 29.61% & 0.79\n",
      "for 2019-03-20, MAE is:3.10 & sMAPE is:7.15% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :8.32 & 29.32% & 0.79\n",
      "for 2019-03-21, MAE is:5.56 & sMAPE is:13.44% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :8.29 & 29.13% & 0.80\n",
      "for 2019-03-22, MAE is:4.53 & sMAPE is:10.81% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :8.24 & 28.90% & 0.79\n",
      "for 2019-03-23, MAE is:3.40 & sMAPE is:9.87% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :8.18 & 28.67% & 0.79\n",
      "for 2019-03-24, MAE is:3.73 & sMAPE is:11.54% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :8.13 & 28.46% & 0.78\n",
      "for 2019-03-25, MAE is:6.52 & sMAPE is:19.76% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :8.11 & 28.36% & 0.78\n",
      "for 2019-03-26, MAE is:4.30 & sMAPE is:11.30% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :8.06 & 28.16% & 0.78\n",
      "for 2019-03-27, MAE is:2.26 & sMAPE is:5.76% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :8.00 & 27.90% & 0.79\n",
      "for 2019-03-28, MAE is:3.15 & sMAPE is:7.48% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :7.94 & 27.66% & 0.79\n",
      "for 2019-03-29, MAE is:3.63 & sMAPE is:9.47% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :7.89 & 27.46% & 0.79\n",
      "for 2019-03-30, MAE is:5.20 & sMAPE is:15.13% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :7.86 & 27.32% & 0.80\n",
      "for 2019-03-31, MAE is:7.09 & sMAPE is:33.75% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :7.85 & 27.39% & 0.80\n",
      "for 2019-04-01, MAE is:4.58 & sMAPE is:11.46% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :7.82 & 27.21% & 0.80\n",
      "for 2019-04-02, MAE is:3.68 & sMAPE is:11.03% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :7.77 & 27.04% & 0.80\n",
      "for 2019-04-03, MAE is:9.37 & sMAPE is:25.98% & rMAE is:3.23 ||| daily mean of MAE & sMAPE & rMAE till now are :7.79 & 27.03% & 0.83\n",
      "for 2019-04-04, MAE is:2.10 & sMAPE is:5.18% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :7.73 & 26.79% & 0.83\n",
      "for 2019-04-05, MAE is:2.85 & sMAPE is:6.65% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :7.68 & 26.58% & 0.83\n",
      "for 2019-04-06, MAE is:4.58 & sMAPE is:12.30% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :7.65 & 26.43% & 0.82\n",
      "for 2019-04-07, MAE is:6.45 & sMAPE is:17.28% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :7.63 & 26.34% & 0.82\n",
      "for 2019-04-08, MAE is:2.19 & sMAPE is:5.63% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :7.58 & 26.13% & 0.82\n",
      "for 2019-04-09, MAE is:2.31 & sMAPE is:5.48% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :7.52 & 25.92% & 0.81\n",
      "for 2019-04-10, MAE is:2.68 & sMAPE is:6.30% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :7.48 & 25.72% & 0.81\n",
      "for 2019-04-11, MAE is:4.72 & sMAPE is:10.64% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :7.45 & 25.57% & 0.81\n",
      "for 2019-04-12, MAE is:3.19 & sMAPE is:7.01% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :7.41 & 25.39% & 0.81\n",
      "for 2019-04-13, MAE is:3.50 & sMAPE is:8.53% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :7.37 & 25.23% & 0.81\n",
      "for 2019-04-14, MAE is:3.48 & sMAPE is:9.44% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :7.33 & 25.08% & 0.82\n",
      "for 2019-04-15, MAE is:4.93 & sMAPE is:11.34% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :7.31 & 24.95% & 0.82\n",
      "for 2019-04-16, MAE is:5.93 & sMAPE is:14.49% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :7.30 & 24.85% & 0.82\n",
      "for 2019-04-17, MAE is:4.87 & sMAPE is:11.67% & rMAE is:2.54 ||| daily mean of MAE & sMAPE & rMAE till now are :7.27 & 24.72% & 0.84\n",
      "for 2019-04-18, MAE is:5.48 & sMAPE is:13.16% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :7.26 & 24.62% & 0.84\n",
      "for 2019-04-19, MAE is:2.19 & sMAPE is:5.49% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :7.21 & 24.44% & 0.84\n",
      "for 2019-04-20, MAE is:1.99 & sMAPE is:4.97% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :7.16 & 24.26% & 0.84\n",
      "for 2019-04-21, MAE is:1.50 & sMAPE is:3.95% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :7.11 & 24.08% & 0.84\n",
      "for 2019-04-22, MAE is:22.77 & sMAPE is:93.71% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :7.25 & 24.70% & 0.84\n",
      "for 2019-04-23, MAE is:12.99 & sMAPE is:91.69% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :7.30 & 25.30% & 0.83\n",
      "for 2019-04-24, MAE is:8.74 & sMAPE is:43.91% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :7.31 & 25.46% & 0.83\n",
      "for 2019-04-25, MAE is:6.06 & sMAPE is:15.25% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :7.30 & 25.37% & 0.83\n",
      "for 2019-04-26, MAE is:7.17 & sMAPE is:17.35% & rMAE is:1.95 ||| daily mean of MAE & sMAPE & rMAE till now are :7.30 & 25.30% & 0.84\n",
      "for 2019-04-27, MAE is:2.53 & sMAPE is:7.66% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :7.26 & 25.15% & 0.84\n",
      "for 2019-04-28, MAE is:3.10 & sMAPE is:8.45% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :7.23 & 25.01% & 0.84\n",
      "for 2019-04-29, MAE is:5.84 & sMAPE is:14.23% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :7.22 & 24.92% & 0.83\n",
      "for 2019-04-30, MAE is:4.05 & sMAPE is:9.08% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :7.19 & 24.79% & 0.83\n",
      "for 2019-05-01, MAE is:16.91 & sMAPE is:60.09% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :7.27 & 25.08% & 0.83\n",
      "for 2019-05-02, MAE is:9.94 & sMAPE is:46.62% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :7.29 & 25.25% & 0.83\n",
      "for 2019-05-03, MAE is:3.39 & sMAPE is:8.26% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :7.26 & 25.12% & 0.83\n",
      "for 2019-05-04, MAE is:3.61 & sMAPE is:9.18% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :7.23 & 24.99% & 0.83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-05-05, MAE is:9.10 & sMAPE is:28.08% & rMAE is:1.88 ||| daily mean of MAE & sMAPE & rMAE till now are :7.24 & 25.01% & 0.84\n",
      "for 2019-05-06, MAE is:3.87 & sMAPE is:9.77% & rMAE is:1.81 ||| daily mean of MAE & sMAPE & rMAE till now are :7.22 & 24.89% & 0.84\n",
      "for 2019-05-07, MAE is:3.55 & sMAPE is:7.56% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :7.19 & 24.76% & 0.84\n",
      "for 2019-05-08, MAE is:7.34 & sMAPE is:16.17% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :7.19 & 24.69% & 0.84\n",
      "for 2019-05-09, MAE is:6.11 & sMAPE is:13.85% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :7.18 & 24.60% & 0.84\n",
      "for 2019-05-10, MAE is:4.43 & sMAPE is:9.85% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :7.16 & 24.49% & 0.84\n",
      "for 2019-05-11, MAE is:4.09 & sMAPE is:10.44% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :7.14 & 24.38% & 0.84\n",
      "for 2019-05-12, MAE is:16.36 & sMAPE is:67.64% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :7.21 & 24.71% & 0.85\n",
      "for 2019-05-13, MAE is:4.11 & sMAPE is:10.04% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :7.18 & 24.60% & 0.85\n",
      "for 2019-05-14, MAE is:4.18 & sMAPE is:9.28% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :7.16 & 24.49% & 0.85\n",
      "for 2019-05-15, MAE is:3.08 & sMAPE is:7.17% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :7.13 & 24.36% & 0.85\n",
      "for 2019-05-16, MAE is:3.17 & sMAPE is:7.65% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :7.10 & 24.24% & 0.85\n",
      "for 2019-05-17, MAE is:4.99 & sMAPE is:12.55% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 24.15% & 0.85\n",
      "for 2019-05-18, MAE is:5.16 & sMAPE is:13.18% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :7.07 & 24.07% & 0.85\n",
      "for 2019-05-19, MAE is:2.81 & sMAPE is:7.28% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :7.04 & 23.95% & 0.85\n",
      "for 2019-05-20, MAE is:4.95 & sMAPE is:10.56% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :7.03 & 23.85% & 0.85\n",
      "for 2019-05-21, MAE is:3.28 & sMAPE is:7.61% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :7.00 & 23.74% & 0.85\n",
      "for 2019-05-22, MAE is:2.98 & sMAPE is:7.42% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.97 & 23.62% & 0.85\n",
      "for 2019-05-23, MAE is:5.60 & sMAPE is:13.40% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 23.55% & 0.85\n",
      "for 2019-05-24, MAE is:6.82 & sMAPE is:16.06% & rMAE is:1.98 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 23.50% & 0.86\n",
      "for 2019-05-25, MAE is:2.18 & sMAPE is:6.01% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 23.38% & 0.86\n",
      "for 2019-05-26, MAE is:7.29 & sMAPE is:25.99% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 23.40% & 0.86\n",
      "for 2019-05-27, MAE is:4.67 & sMAPE is:17.75% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 23.36% & 0.85\n",
      "for 2019-05-28, MAE is:4.61 & sMAPE is:10.99% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 23.28% & 0.85\n",
      "for 2019-05-29, MAE is:3.45 & sMAPE is:8.03% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.88 & 23.17% & 0.86\n",
      "for 2019-05-30, MAE is:18.29 & sMAPE is:96.44% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 23.66% & 0.86\n",
      "for 2019-05-31, MAE is:4.10 & sMAPE is:11.45% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 23.58% & 0.86\n",
      "for 2019-06-01, MAE is:5.65 & sMAPE is:18.60% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 23.55% & 0.86\n",
      "for 2019-06-02, MAE is:5.51 & sMAPE is:19.26% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 23.52% & 0.86\n",
      "for 2019-06-03, MAE is:6.42 & sMAPE is:18.20% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.91 & 23.49% & 0.86\n",
      "for 2019-06-04, MAE is:4.46 & sMAPE is:11.16% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 23.41% & 0.86\n",
      "for 2019-06-05, MAE is:9.26 & sMAPE is:29.59% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.91 & 23.45% & 0.87\n",
      "for 2019-06-06, MAE is:2.57 & sMAPE is:7.65% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :6.88 & 23.35% & 0.86\n",
      "for 2019-06-07, MAE is:7.27 & sMAPE is:18.07% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 23.31% & 0.86\n",
      "for 2019-06-08, MAE is:17.86 & sMAPE is:119.38% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 23.92% & 0.86\n",
      "for 2019-06-09, MAE is:10.26 & sMAPE is:93.46% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.98 & 24.35% & 0.86\n",
      "for 2019-06-10, MAE is:2.29 & sMAPE is:7.42% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 24.25% & 0.86\n",
      "for 2019-06-11, MAE is:6.14 & sMAPE is:16.70% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 24.20% & 0.86\n",
      "for 2019-06-12, MAE is:7.83 & sMAPE is:18.63% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 24.16% & 0.86\n",
      "for 2019-06-13, MAE is:12.01 & sMAPE is:37.01% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.98 & 24.24% & 0.86\n",
      "for 2019-06-14, MAE is:7.27 & sMAPE is:17.12% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.98 & 24.20% & 0.86\n",
      "for 2019-06-15, MAE is:2.50 & sMAPE is:8.76% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 24.11% & 0.86\n",
      "for 2019-06-16, MAE is:5.17 & sMAPE is:15.36% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 24.05% & 0.85\n",
      "for 2019-06-17, MAE is:8.74 & sMAPE is:20.15% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 24.03% & 0.85\n",
      "for 2019-06-18, MAE is:7.00 & sMAPE is:17.09% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 23.99% & 0.86\n",
      "for 2019-06-19, MAE is:5.01 & sMAPE is:11.87% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 23.92% & 0.86\n",
      "for 2019-06-20, MAE is:3.78 & sMAPE is:9.47% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 23.83% & 0.86\n",
      "for 2019-06-21, MAE is:3.88 & sMAPE is:10.67% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.91 & 23.76% & 0.86\n",
      "for 2019-06-22, MAE is:2.60 & sMAPE is:8.57% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.88 & 23.67% & 0.85\n",
      "for 2019-06-23, MAE is:3.22 & sMAPE is:12.01% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.86 & 23.60% & 0.85\n",
      "for 2019-06-24, MAE is:4.80 & sMAPE is:13.56% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 23.55% & 0.85\n",
      "for 2019-06-25, MAE is:5.92 & sMAPE is:14.57% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :6.84 & 23.49% & 0.85\n",
      "for 2019-06-26, MAE is:8.08 & sMAPE is:22.94% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 23.49% & 0.85\n",
      "for 2019-06-27, MAE is:2.75 & sMAPE is:11.39% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 23.42% & 0.85\n",
      "for 2019-06-28, MAE is:8.04 & sMAPE is:17.99% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 23.39% & 0.85\n",
      "for 2019-06-29, MAE is:5.50 & sMAPE is:15.56% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 23.35% & 0.85\n",
      "for 2019-06-30, MAE is:12.56 & sMAPE is:63.13% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :6.86 & 23.57% & 0.86\n",
      "for 2019-07-01, MAE is:5.21 & sMAPE is:16.87% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 23.53% & 0.86\n",
      "for 2019-07-02, MAE is:4.10 & sMAPE is:13.04% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 23.48% & 0.86\n",
      "for 2019-07-03, MAE is:8.19 & sMAPE is:23.34% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.84 & 23.47% & 0.86\n",
      "for 2019-07-04, MAE is:5.82 & sMAPE is:17.68% & rMAE is:2.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.84 & 23.44% & 0.87\n",
      "for 2019-07-05, MAE is:3.68 & sMAPE is:11.35% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 23.38% & 0.86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-07-06, MAE is:2.13 & sMAPE is:7.61% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 23.29% & 0.86\n",
      "for 2019-07-07, MAE is:5.60 & sMAPE is:24.54% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 23.30% & 0.86\n",
      "for 2019-07-08, MAE is:2.34 & sMAPE is:7.24% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 23.22% & 0.86\n",
      "for 2019-07-09, MAE is:5.53 & sMAPE is:15.62% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 23.18% & 0.86\n",
      "for 2019-07-10, MAE is:4.58 & sMAPE is:11.01% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 23.11% & 0.85\n",
      "for 2019-07-11, MAE is:3.76 & sMAPE is:8.24% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 23.03% & 0.85\n",
      "for 2019-07-12, MAE is:5.01 & sMAPE is:11.05% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 22.97% & 0.85\n",
      "for 2019-07-13, MAE is:2.54 & sMAPE is:7.05% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 22.89% & 0.84\n",
      "for 2019-07-14, MAE is:3.86 & sMAPE is:11.42% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.69 & 22.83% & 0.84\n",
      "for 2019-07-15, MAE is:3.65 & sMAPE is:9.58% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 22.76% & 0.84\n",
      "for 2019-07-16, MAE is:5.50 & sMAPE is:13.31% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 22.72% & 0.84\n",
      "for 2019-07-17, MAE is:3.68 & sMAPE is:8.01% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 22.64% & 0.84\n",
      "for 2019-07-18, MAE is:3.44 & sMAPE is:7.76% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.63 & 22.57% & 0.84\n",
      "for 2019-07-19, MAE is:4.68 & sMAPE is:10.39% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 22.51% & 0.85\n",
      "for 2019-07-20, MAE is:2.12 & sMAPE is:5.63% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :6.60 & 22.42% & 0.85\n",
      "for 2019-07-21, MAE is:1.48 & sMAPE is:4.23% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 22.33% & 0.85\n",
      "for 2019-07-22, MAE is:4.96 & sMAPE is:13.40% & rMAE is:4.29 ||| daily mean of MAE & sMAPE & rMAE till now are :6.57 & 22.29% & 0.87\n",
      "for 2019-07-23, MAE is:9.84 & sMAPE is:22.42% & rMAE is:2.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 22.29% & 0.87\n",
      "for 2019-07-24, MAE is:7.01 & sMAPE is:13.44% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.59 & 22.25% & 0.88\n",
      "for 2019-07-25, MAE is:5.23 & sMAPE is:10.15% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 22.19% & 0.88\n",
      "for 2019-07-26, MAE is:5.54 & sMAPE is:12.58% & rMAE is:2.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.57 & 22.14% & 0.89\n",
      "for 2019-07-27, MAE is:2.24 & sMAPE is:6.15% & rMAE is:1.94 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 22.06% & 0.89\n",
      "for 2019-07-28, MAE is:3.65 & sMAPE is:10.66% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :6.54 & 22.01% & 0.89\n",
      "for 2019-07-29, MAE is:7.82 & sMAPE is:17.73% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 21.99% & 0.89\n",
      "for 2019-07-30, MAE is:3.77 & sMAPE is:8.37% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 21.92% & 0.89\n",
      "for 2019-07-31, MAE is:7.36 & sMAPE is:14.99% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.54 & 21.89% & 0.90\n",
      "for 2019-08-01, MAE is:5.27 & sMAPE is:10.88% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 21.84% & 0.90\n",
      "for 2019-08-02, MAE is:2.25 & sMAPE is:5.28% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 21.76% & 0.89\n",
      "for 2019-08-03, MAE is:1.38 & sMAPE is:3.51% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 21.68% & 0.89\n",
      "for 2019-08-04, MAE is:3.83 & sMAPE is:10.22% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 21.62% & 0.89\n",
      "for 2019-08-05, MAE is:4.68 & sMAPE is:10.14% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 21.57% & 0.89\n",
      "for 2019-08-06, MAE is:3.78 & sMAPE is:8.66% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :6.45 & 21.51% & 0.90\n",
      "for 2019-08-07, MAE is:3.92 & sMAPE is:8.84% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :6.44 & 21.45% & 0.89\n",
      "for 2019-08-08, MAE is:3.46 & sMAPE is:8.98% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.43 & 21.40% & 0.89\n",
      "for 2019-08-09, MAE is:3.62 & sMAPE is:9.19% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 21.34% & 0.89\n",
      "for 2019-08-10, MAE is:14.73 & sMAPE is:68.49% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.45 & 21.55% & 0.89\n",
      "for 2019-08-11, MAE is:15.46 & sMAPE is:75.62% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 21.80% & 0.89\n",
      "for 2019-08-12, MAE is:8.10 & sMAPE is:18.17% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 21.78% & 0.89\n",
      "for 2019-08-13, MAE is:4.34 & sMAPE is:10.46% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 21.73% & 0.89\n",
      "for 2019-08-14, MAE is:6.69 & sMAPE is:15.72% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 21.70% & 0.89\n",
      "for 2019-08-15, MAE is:4.48 & sMAPE is:12.35% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 21.66% & 0.89\n",
      "for 2019-08-16, MAE is:4.16 & sMAPE is:10.51% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 21.61% & 0.89\n",
      "for 2019-08-17, MAE is:4.86 & sMAPE is:19.86% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 21.61% & 0.88\n",
      "for 2019-08-18, MAE is:1.34 & sMAPE is:4.00% & rMAE is:0.06 ||| daily mean of MAE & sMAPE & rMAE till now are :6.44 & 21.53% & 0.88\n",
      "for 2019-08-19, MAE is:5.33 & sMAPE is:14.82% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.44 & 21.50% & 0.88\n",
      "for 2019-08-20, MAE is:4.09 & sMAPE is:9.91% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :6.43 & 21.45% & 0.88\n",
      "for 2019-08-21, MAE is:7.10 & sMAPE is:16.01% & rMAE is:2.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.43 & 21.43% & 0.89\n",
      "for 2019-08-22, MAE is:4.87 & sMAPE is:12.52% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :6.43 & 21.39% & 0.89\n",
      "for 2019-08-23, MAE is:5.69 & sMAPE is:14.22% & rMAE is:2.93 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 21.36% & 0.90\n",
      "for 2019-08-24, MAE is:3.19 & sMAPE is:9.65% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 21.31% & 0.90\n",
      "for 2019-08-25, MAE is:4.39 & sMAPE is:12.95% & rMAE is:2.21 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 21.27% & 0.90\n",
      "for 2019-08-26, MAE is:8.12 & sMAPE is:17.59% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 21.26% & 0.90\n",
      "for 2019-08-27, MAE is:5.35 & sMAPE is:11.49% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 21.22% & 0.90\n",
      "for 2019-08-28, MAE is:7.72 & sMAPE is:14.46% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 21.19% & 0.90\n",
      "for 2019-08-29, MAE is:4.05 & sMAPE is:8.84% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 21.14% & 0.90\n",
      "for 2019-08-30, MAE is:5.08 & sMAPE is:12.02% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 21.10% & 0.90\n",
      "for 2019-08-31, MAE is:3.68 & sMAPE is:10.59% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :6.38 & 21.06% & 0.90\n",
      "for 2019-09-01, MAE is:2.72 & sMAPE is:8.82% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.37 & 21.01% & 0.90\n",
      "for 2019-09-02, MAE is:4.53 & sMAPE is:11.69% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.36 & 20.97% & 0.90\n",
      "for 2019-09-03, MAE is:5.01 & sMAPE is:13.67% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.35 & 20.94% & 0.90\n",
      "for 2019-09-04, MAE is:5.98 & sMAPE is:16.59% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :6.35 & 20.92% & 0.89\n",
      "for 2019-09-05, MAE is:4.09 & sMAPE is:12.85% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :6.34 & 20.89% & 0.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-09-06, MAE is:2.22 & sMAPE is:7.00% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :6.33 & 20.83% & 0.89\n",
      "for 2019-09-07, MAE is:4.65 & sMAPE is:13.06% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :6.32 & 20.80% & 0.89\n",
      "for 2019-09-08, MAE is:6.44 & sMAPE is:18.24% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :6.32 & 20.79% & 0.89\n",
      "for 2019-09-09, MAE is:7.99 & sMAPE is:17.54% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :6.33 & 20.78% & 0.89\n",
      "for 2019-09-10, MAE is:4.88 & sMAPE is:12.59% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.32 & 20.75% & 0.90\n",
      "for 2019-09-11, MAE is:3.69 & sMAPE is:11.09% & rMAE is:3.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 20.71% & 0.91\n",
      "for 2019-09-12, MAE is:5.18 & sMAPE is:13.46% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 20.68% & 0.91\n",
      "for 2019-09-13, MAE is:5.04 & sMAPE is:13.62% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :6.30 & 20.65% & 0.91\n",
      "for 2019-09-14, MAE is:4.39 & sMAPE is:13.80% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.29 & 20.63% & 0.91\n",
      "for 2019-09-15, MAE is:8.90 & sMAPE is:53.85% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.30 & 20.75% & 0.90\n",
      "for 2019-09-16, MAE is:8.69 & sMAPE is:30.91% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 20.79% & 0.90\n",
      "for 2019-09-17, MAE is:5.88 & sMAPE is:18.51% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 20.79% & 0.90\n",
      "for 2019-09-18, MAE is:7.45 & sMAPE is:20.00% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.32 & 20.78% & 0.91\n",
      "for 2019-09-19, MAE is:7.35 & sMAPE is:16.28% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :6.32 & 20.77% & 0.91\n",
      "for 2019-09-20, MAE is:5.90 & sMAPE is:13.91% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.32 & 20.74% & 0.91\n",
      "for 2019-09-21, MAE is:5.69 & sMAPE is:16.18% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :6.32 & 20.72% & 0.91\n",
      "for 2019-09-22, MAE is:3.28 & sMAPE is:10.69% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :6.30 & 20.68% & 0.90\n",
      "for 2019-09-23, MAE is:9.22 & sMAPE is:22.38% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :6.32 & 20.69% & 0.91\n",
      "for 2019-09-24, MAE is:6.91 & sMAPE is:14.49% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.32 & 20.67% & 0.90\n",
      "for 2019-09-25, MAE is:6.11 & sMAPE is:13.01% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.32 & 20.64% & 0.90\n",
      "for 2019-09-26, MAE is:3.93 & sMAPE is:10.00% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 20.60% & 0.90\n",
      "for 2019-09-27, MAE is:5.60 & sMAPE is:14.71% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 20.58% & 0.90\n",
      "for 2019-09-28, MAE is:2.60 & sMAPE is:8.59% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.29 & 20.53% & 0.90\n",
      "for 2019-09-29, MAE is:6.59 & sMAPE is:34.73% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.29 & 20.59% & 0.90\n",
      "for 2019-09-30, MAE is:7.78 & sMAPE is:27.03% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.30 & 20.61% & 0.90\n",
      "for 2019-10-01, MAE is:10.24 & sMAPE is:26.19% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 20.63% & 0.90\n",
      "for 2019-10-02, MAE is:4.26 & sMAPE is:10.84% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 20.59% & 0.90\n",
      "for 2019-10-03, MAE is:5.61 & sMAPE is:14.07% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :6.30 & 20.57% & 0.90\n",
      "for 2019-10-04, MAE is:8.88 & sMAPE is:22.04% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 20.58% & 0.90\n",
      "for 2019-10-05, MAE is:4.35 & sMAPE is:11.37% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.30 & 20.54% & 0.90\n",
      "for 2019-10-06, MAE is:1.68 & sMAPE is:4.94% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :6.29 & 20.49% & 0.90\n",
      "for 2019-10-07, MAE is:6.04 & sMAPE is:13.38% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :6.29 & 20.46% & 0.90\n",
      "for 2019-10-08, MAE is:3.44 & sMAPE is:10.24% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.28 & 20.42% & 0.90\n",
      "for 2019-10-09, MAE is:4.03 & sMAPE is:12.04% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :6.27 & 20.39% & 0.90\n",
      "for 2019-10-10, MAE is:5.34 & sMAPE is:17.09% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :6.27 & 20.38% & 0.90\n",
      "for 2019-10-11, MAE is:5.16 & sMAPE is:21.05% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.26 & 20.39% & 0.89\n",
      "for 2019-10-12, MAE is:8.19 & sMAPE is:62.28% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.27 & 20.53% & 0.89\n",
      "for 2019-10-13, MAE is:4.75 & sMAPE is:19.51% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :6.26 & 20.53% & 0.89\n",
      "for 2019-10-14, MAE is:16.44 & sMAPE is:65.21% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.30 & 20.68% & 0.89\n",
      "for 2019-10-15, MAE is:11.72 & sMAPE is:27.98% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.32 & 20.71% & 0.90\n",
      "for 2019-10-16, MAE is:10.84 & sMAPE is:24.36% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :6.33 & 20.72% & 0.90\n",
      "for 2019-10-17, MAE is:11.57 & sMAPE is:26.57% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :6.35 & 20.74% & 0.90\n",
      "for 2019-10-18, MAE is:5.81 & sMAPE is:14.10% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.35 & 20.72% & 0.89\n",
      "for 2019-10-19, MAE is:4.26 & sMAPE is:12.70% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.34 & 20.69% & 0.89\n",
      "for 2019-10-20, MAE is:4.82 & sMAPE is:13.46% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.34 & 20.67% & 0.89\n",
      "for 2019-10-21, MAE is:10.50 & sMAPE is:24.87% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.35 & 20.68% & 0.89\n",
      "for 2019-10-22, MAE is:4.94 & sMAPE is:10.11% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :6.35 & 20.65% & 0.89\n",
      "for 2019-10-23, MAE is:4.76 & sMAPE is:10.60% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.34 & 20.61% & 0.89\n",
      "for 2019-10-24, MAE is:3.70 & sMAPE is:9.43% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.33 & 20.57% & 0.89\n",
      "for 2019-10-25, MAE is:5.20 & sMAPE is:13.88% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.33 & 20.55% & 0.89\n",
      "for 2019-10-26, MAE is:4.05 & sMAPE is:17.00% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.32 & 20.54% & 0.89\n",
      "for 2019-10-27, MAE is:7.05 & sMAPE is:33.31% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :6.32 & 20.58% & 0.89\n",
      "for 2019-10-28, MAE is:6.41 & sMAPE is:14.73% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.32 & 20.56% & 0.89\n",
      "for 2019-10-29, MAE is:7.29 & sMAPE is:15.42% & rMAE is:1.88 ||| daily mean of MAE & sMAPE & rMAE till now are :6.33 & 20.55% & 0.90\n",
      "for 2019-10-30, MAE is:6.33 & sMAPE is:13.33% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :6.33 & 20.52% & 0.90\n",
      "for 2019-10-31, MAE is:3.67 & sMAPE is:8.19% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.32 & 20.48% & 0.90\n",
      "for 2019-11-01, MAE is:7.29 & sMAPE is:19.94% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :6.32 & 20.48% & 0.90\n",
      "for 2019-11-02, MAE is:3.33 & sMAPE is:11.03% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 20.45% & 0.90\n",
      "for 2019-11-03, MAE is:6.96 & sMAPE is:21.11% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 20.45% & 0.90\n",
      "for 2019-11-04, MAE is:3.73 & sMAPE is:10.93% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 20.42% & 0.90\n",
      "for 2019-11-05, MAE is:6.67 & sMAPE is:15.60% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 20.40% & 0.90\n",
      "for 2019-11-06, MAE is:11.91 & sMAPE is:23.83% & rMAE is:2.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.32 & 20.42% & 0.90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-11-07, MAE is:3.27 & sMAPE is:7.58% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 20.37% & 0.90\n",
      "for 2019-11-08, MAE is:9.38 & sMAPE is:20.36% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.32 & 20.37% & 0.90\n",
      "for 2019-11-09, MAE is:2.11 & sMAPE is:5.03% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 20.33% & 0.90\n",
      "for 2019-11-10, MAE is:3.31 & sMAPE is:7.56% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.30 & 20.28% & 0.90\n",
      "for 2019-11-11, MAE is:4.97 & sMAPE is:11.95% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.30 & 20.26% & 0.90\n",
      "for 2019-11-12, MAE is:3.98 & sMAPE is:10.08% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :6.29 & 20.23% & 0.90\n",
      "for 2019-11-13, MAE is:5.09 & sMAPE is:10.21% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.29 & 20.19% & 0.90\n",
      "for 2019-11-14, MAE is:3.97 & sMAPE is:8.48% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :6.28 & 20.16% & 0.90\n",
      "for 2019-11-15, MAE is:4.11 & sMAPE is:10.80% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.27 & 20.13% & 0.89\n",
      "for 2019-11-16, MAE is:3.33 & sMAPE is:8.91% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :6.26 & 20.09% & 0.90\n",
      "for 2019-11-17, MAE is:4.20 & sMAPE is:11.72% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :6.26 & 20.07% & 0.90\n",
      "for 2019-11-18, MAE is:5.46 & sMAPE is:13.60% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :6.25 & 20.05% & 0.90\n",
      "for 2019-11-19, MAE is:9.29 & sMAPE is:17.88% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :6.26 & 20.04% & 0.90\n",
      "for 2019-11-20, MAE is:7.64 & sMAPE is:14.33% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.27 & 20.02% & 0.90\n",
      "for 2019-11-21, MAE is:6.07 & sMAPE is:12.06% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.27 & 20.00% & 0.90\n",
      "for 2019-11-22, MAE is:3.08 & sMAPE is:7.24% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.26 & 19.96% & 0.90\n",
      "for 2019-11-23, MAE is:6.23 & sMAPE is:18.10% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :6.26 & 19.95% & 0.90\n",
      "for 2019-11-24, MAE is:6.42 & sMAPE is:26.36% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :6.26 & 19.97% & 0.90\n",
      "for 2019-11-25, MAE is:6.66 & sMAPE is:13.03% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.26 & 19.95% & 0.90\n",
      "for 2019-11-26, MAE is:2.87 & sMAPE is:6.00% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.25 & 19.91% & 0.90\n",
      "for 2019-11-27, MAE is:3.13 & sMAPE is:7.32% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 19.87% & 0.89\n",
      "for 2019-11-28, MAE is:3.67 & sMAPE is:9.45% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.23 & 19.84% & 0.89\n",
      "for 2019-11-29, MAE is:7.48 & sMAPE is:22.16% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 19.85% & 0.89\n",
      "for 2019-11-30, MAE is:2.71 & sMAPE is:6.29% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :6.22 & 19.81% & 0.89\n",
      "for 2019-12-01, MAE is:2.15 & sMAPE is:5.14% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.21 & 19.76% & 0.89\n",
      "for 2019-12-02, MAE is:4.11 & sMAPE is:8.67% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.21 & 19.73% & 0.89\n",
      "for 2019-12-03, MAE is:5.76 & sMAPE is:10.99% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :6.20 & 19.70% & 0.89\n",
      "for 2019-12-04, MAE is:5.22 & sMAPE is:10.71% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :6.20 & 19.68% & 0.89\n",
      "for 2019-12-05, MAE is:5.19 & sMAPE is:12.52% & rMAE is:1.88 ||| daily mean of MAE & sMAPE & rMAE till now are :6.20 & 19.66% & 0.89\n",
      "for 2019-12-06, MAE is:4.88 & sMAPE is:16.27% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.20 & 19.65% & 0.89\n",
      "for 2019-12-07, MAE is:6.49 & sMAPE is:49.32% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :6.20 & 19.73% & 0.89\n",
      "for 2019-12-08, MAE is:38.56 & sMAPE is:171.75% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :6.29 & 20.18% & 0.89\n",
      "for 2019-12-09, MAE is:8.96 & sMAPE is:65.15% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.30 & 20.31% & 0.89\n",
      "for 2019-12-10, MAE is:8.64 & sMAPE is:24.28% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 20.32% & 0.89\n",
      "for 2019-12-11, MAE is:8.17 & sMAPE is:37.27% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 20.37% & 0.89\n",
      "for 2019-12-12, MAE is:4.50 & sMAPE is:9.85% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 20.34% & 0.89\n",
      "for 2019-12-13, MAE is:3.26 & sMAPE is:11.97% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :6.30 & 20.32% & 0.89\n",
      "for 2019-12-14, MAE is:9.77 & sMAPE is:32.20% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 20.35% & 0.89\n",
      "for 2019-12-15, MAE is:7.77 & sMAPE is:52.22% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 20.44% & 0.89\n",
      "for 2019-12-16, MAE is:3.75 & sMAPE is:9.13% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.30 & 20.41% & 0.89\n",
      "for 2019-12-17, MAE is:5.31 & sMAPE is:13.12% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :6.30 & 20.39% & 0.89\n",
      "for 2019-12-18, MAE is:5.54 & sMAPE is:16.05% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.30 & 20.38% & 0.89\n",
      "for 2019-12-19, MAE is:4.27 & sMAPE is:12.14% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.29 & 20.35% & 0.89\n",
      "for 2019-12-20, MAE is:4.94 & sMAPE is:14.82% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :6.29 & 20.34% & 0.89\n",
      "for 2019-12-21, MAE is:4.35 & sMAPE is:14.86% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.28 & 20.32% & 0.89\n",
      "for 2019-12-22, MAE is:5.09 & sMAPE is:16.54% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.28 & 20.31% & 0.89\n",
      "for 2019-12-23, MAE is:4.52 & sMAPE is:14.30% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.28 & 20.29% & 0.89\n",
      "for 2019-12-24, MAE is:6.35 & sMAPE is:22.14% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :6.28 & 20.30% & 0.89\n",
      "for 2019-12-25, MAE is:3.71 & sMAPE is:11.45% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.27 & 20.27% & 0.89\n",
      "for 2019-12-26, MAE is:3.30 & sMAPE is:9.43% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :6.26 & 20.24% & 0.89\n",
      "for 2019-12-27, MAE is:3.43 & sMAPE is:8.92% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.25 & 20.21% & 0.89\n",
      "for 2019-12-28, MAE is:1.92 & sMAPE is:5.45% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 20.17% & 0.88\n",
      "for 2019-12-29, MAE is:4.76 & sMAPE is:16.18% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 20.16% & 0.88\n",
      "for 2019-12-30, MAE is:4.55 & sMAPE is:27.82% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.23 & 20.18% & 0.88\n",
      "for 2019-12-31, MAE is:4.96 & sMAPE is:22.09% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :6.23 & 20.19% & 0.88\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:09:00,490]\u001b[0m A new study created in RDB with name: DK_1_2020\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:09:17,070]\u001b[0m Trial 1 pruned. Trial was pruned at epoch 4.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.38 | sMAPE for Validation Set is: 19.87% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 12.58 | sMAPE for Test Set is: 57.45% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:09:17,169]\u001b[0m Trial 2 finished with value: 6.378285626539305 and parameters: {'n_hidden': 3, 'learning_rate': 0.011666898188252554, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20970040041651866, 'dropout_rate_Layer_2': 0.20614604087245342, 'dropout_rate_Layer_3': 0.1708834218158335, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.619695955751154e-05, 'l1_Layer_2': 0.0014377407948352645, 'l1_Layer_3': 0.00022601624006864929, 'n_units_Layer_1': 65, 'n_units_Layer_2': 170, 'n_units_Layer_3': 125}. Best is trial 2 with value: 6.378285626539305.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:09:21,642]\u001b[0m Trial 0 finished with value: 6.509358639042247 and parameters: {'n_hidden': 3, 'learning_rate': 0.06936344901242887, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38585287392165885, 'dropout_rate_Layer_2': 0.16467960748264, 'dropout_rate_Layer_3': 0.37860847201278286, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.871495919947506e-05, 'l1_Layer_2': 1.1724463512893335e-05, 'l1_Layer_3': 0.00025105364960536933, 'n_units_Layer_1': 110, 'n_units_Layer_2': 70, 'n_units_Layer_3': 185}. Best is trial 2 with value: 6.378285626539305.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.51 | sMAPE for Validation Set is: 20.34% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 12.35 | sMAPE for Test Set is: 56.78% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:09:21,916]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:09:28,262]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:09:32,027]\u001b[0m Trial 3 finished with value: 5.933831981542613 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020350414051805506, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3390107902628202, 'dropout_rate_Layer_2': 0.18074949060227963, 'dropout_rate_Layer_3': 0.09552396821808369, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008502791438221876, 'l1_Layer_2': 0.0011075405162796663, 'l1_Layer_3': 4.055891350428093e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 160, 'n_units_Layer_3': 260}. Best is trial 3 with value: 5.933831981542613.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.93 | sMAPE for Validation Set is: 18.97% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 11.71 | sMAPE for Test Set is: 54.74% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:09:34,198]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:09:37,287]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:09:40,445]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:09:44,968]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:09:58,635]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:10:01,450]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:10:01,823]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:10:06,555]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:10:14,628]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:10:18,072]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:10:21,075]\u001b[0m Trial 11 finished with value: 7.220950819615767 and parameters: {'n_hidden': 3, 'learning_rate': 0.03511520229865803, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21735567286055857, 'dropout_rate_Layer_2': 0.3551793893926718, 'dropout_rate_Layer_3': 0.19693628275241407, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0991230049703725, 'l1_Layer_2': 0.0003074103007115804, 'l1_Layer_3': 0.024647943941113915, 'n_units_Layer_1': 150, 'n_units_Layer_2': 190, 'n_units_Layer_3': 125}. Best is trial 3 with value: 5.933831981542613.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.22 | sMAPE for Validation Set is: 22.10% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 12.98 | sMAPE for Test Set is: 58.09% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:10:24,212]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:10:24,774]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:10:30,647]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:10:33,095]\u001b[0m Trial 15 finished with value: 6.185777201079787 and parameters: {'n_hidden': 4, 'learning_rate': 0.0027092064498264847, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.002619258931393187, 'dropout_rate_Layer_2': 0.32083868322382003, 'dropout_rate_Layer_3': 0.12234353759839434, 'dropout_rate_Layer_4': 0.051634865260821394, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00042809575407745903, 'l1_Layer_2': 5.787929790730971e-05, 'l1_Layer_3': 1.1635376253845954e-05, 'l1_Layer_4': 0.00025486074029571816, 'n_units_Layer_1': 135, 'n_units_Layer_2': 160, 'n_units_Layer_3': 265, 'n_units_Layer_4': 260}. Best is trial 3 with value: 5.933831981542613.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.19 | sMAPE for Validation Set is: 19.65% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 11.09 | sMAPE for Test Set is: 53.71% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:10:34,853]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:10:36,954]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:10:41,352]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:10:41,470]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:10:44,440]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:10:48,505]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:10:53,345]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:10:55,882]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:10:59,141]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:11:00,560]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.40 | sMAPE for Validation Set is: 20.03% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 11.89 | sMAPE for Test Set is: 55.59% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:11:03,365]\u001b[0m Trial 4 finished with value: 6.402208434003691 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015055052968347097, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22858570786874874, 'dropout_rate_Layer_2': 0.32853428908433574, 'dropout_rate_Layer_3': 0.0014541068218337117, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.000855040843102414, 'l1_Layer_2': 0.012458103161969125, 'l1_Layer_3': 0.003531048013998247, 'n_units_Layer_1': 100, 'n_units_Layer_2': 55, 'n_units_Layer_3': 285}. Best is trial 3 with value: 5.933831981542613.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:11:03,657]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:11:09,355]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:11:12,740]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:11:13,137]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:11:13,563]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:11:20,450]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:11:21,877]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:11:22,744]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:11:24,622]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:11:27,547]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:11:30,604]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:11:30,983]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:11:32,731]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:11:34,970]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:11:37,942]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:11:40,457]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:11:42,977]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:11:43,388]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:11:47,343]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:11:47,466]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:11:47,836]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:11:52,851]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:11:56,626]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:11:58,390]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:12:01,739]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:12:06,095]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:12:07,569]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:12:11,845]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:12:12,169]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:12:15,121]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:12:16,495]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:12:18,098]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:12:18,783]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:12:25,785]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:12:28,059]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:12:30,273]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:12:33,234]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:12:36,612]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:12:38,203]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:12:42,317]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:12:46,665]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:12:51,666]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:12:55,503]\u001b[0m Trial 66 finished with value: 5.917976051762118 and parameters: {'n_hidden': 3, 'learning_rate': 0.00326998869515392, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1360722147507738, 'dropout_rate_Layer_2': 0.21594366735215245, 'dropout_rate_Layer_3': 0.3599563099907313, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0022779771830429966, 'l1_Layer_2': 0.002294978497690776, 'l1_Layer_3': 3.504455073657247e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 180, 'n_units_Layer_3': 155}. Best is trial 66 with value: 5.917976051762118.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.92 | sMAPE for Validation Set is: 18.84% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 11.08 | sMAPE for Test Set is: 53.52% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:12:56,055]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:13:02,607]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:13:03,221]\u001b[0m Trial 70 finished with value: 5.906256497314746 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014454896013320001, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05552879384552609, 'dropout_rate_Layer_2': 0.11336790265842453, 'dropout_rate_Layer_3': 0.2989842246475852, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010812955352911843, 'l1_Layer_2': 0.00031166477576041886, 'l1_Layer_3': 0.00029310893952155185, 'n_units_Layer_1': 200, 'n_units_Layer_2': 200, 'n_units_Layer_3': 220}. Best is trial 70 with value: 5.906256497314746.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.91 | sMAPE for Validation Set is: 18.85% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 11.22 | sMAPE for Test Set is: 53.95% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:13:08,572]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:13:09,941]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:13:11,099]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:13:12,685]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:13:16,527]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:13:20,681]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:13:22,927]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:13:24,858]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:13:26,773]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:13:29,446]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:13:29,956]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:13:32,250]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:13:36,300]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:13:37,047]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:13:41,878]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:13:42,423]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:13:44,010]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:13:49,489]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:13:50,004]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:13:50,674]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:13:56,939]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:13:57,036]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:14:02,391]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:14:02,838]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:14:07,670]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:14:09,608]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:14:10,135]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:14:10,248]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:14:13,637]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:14:18,866]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:14:20,613]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:14:20,806]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:14:24,159]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:14:24,369]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:14:28,495]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:14:30,961]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:14:32,138]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:14:35,999]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:14:36,682]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:14:39,612]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:14:40,779]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:14:43,809]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:14:44,495]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:14:49,989]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:14:50,081]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:14:50,388]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:14:52,622]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:15:01,141]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:15:03,034]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:15:03,734]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:15:06,655]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:15:09,708]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:15:11,447]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:15:17,050]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:15:18,525]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:15:19,526]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:15:24,493]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:15:28,509]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:15:32,812]\u001b[0m Trial 126 finished with value: 6.097431011932521 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022440184355997056, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09448032427123673, 'dropout_rate_Layer_2': 0.16692148082625013, 'dropout_rate_Layer_3': 0.39976640228473287, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000814098214790727, 'l1_Layer_2': 0.000560053406980354, 'l1_Layer_3': 2.788663449773776e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 190, 'n_units_Layer_3': 150}. Best is trial 70 with value: 5.906256497314746.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.10 | sMAPE for Validation Set is: 19.36% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 11.07 | sMAPE for Test Set is: 53.70% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:15:33,897]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:15:34,110]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:15:38,907]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:15:41,389]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:15:43,585]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:15:45,540]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:15:50,298]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:15:52,602]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:15:53,203]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:15:58,387]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:15:58,601]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:16:01,569]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:16:04,369]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:16:05,884]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:16:11,660]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:16:13,534]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:16:15,797]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:16:19,083]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:16:19,571]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:16:19,686]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:16:23,138]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:16:27,955]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:16:30,050]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:16:30,561]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:16:34,558]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:16:37,227]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:16:40,952]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:16:44,345]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:16:47,961]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:16:48,717]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:16:49,694]\u001b[0m Trial 159 finished with value: 6.243546432005847 and parameters: {'n_hidden': 3, 'learning_rate': 0.003051404289237386, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35225481600405495, 'dropout_rate_Layer_2': 0.1521389130421098, 'dropout_rate_Layer_3': 0.18549142233580151, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012275241011493112, 'l1_Layer_2': 3.5010877727629665e-05, 'l1_Layer_3': 4.3069495951660366e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 125, 'n_units_Layer_3': 255}. Best is trial 70 with value: 5.906256497314746.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.24 | sMAPE for Validation Set is: 19.64% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 12.13 | sMAPE for Test Set is: 56.03% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:16:57,439]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:17:02,181]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:17:05,836]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:17:05,969]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:17:11,041]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:17:16,552]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:17:16,982]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:17:23,115]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:17:26,047]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:17:27,302]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:17:28,068]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:17:33,846]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:17:34,539]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:17:38,784]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:17:39,817]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:17:45,155]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:17:48,986]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:17:50,213]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:17:54,993]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:17:59,099]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:18:03,191]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:18:06,946]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:18:10,748]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:18:18,958]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:18:25,887]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:18:29,393]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:18:36,408]\u001b[0m Trial 188 finished with value: 5.675223837151179 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007970728146350602, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20533269615319957, 'dropout_rate_Layer_2': 0.10660789849636511, 'dropout_rate_Layer_3': 0.26836268064331337, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00027528208438667875, 'l1_Layer_2': 8.790382423130233e-05, 'l1_Layer_3': 9.955261520851435e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 270, 'n_units_Layer_3': 130}. Best is trial 188 with value: 5.675223837151179.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.68 | sMAPE for Validation Set is: 18.52% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.51 | sMAPE for Test Set is: 51.26% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:18:46,590]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:18:49,844]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:18:52,333]\u001b[0m Trial 194 finished with value: 5.604842086046088 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013023232284512809, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20398021660494975, 'dropout_rate_Layer_2': 0.06969527105326867, 'dropout_rate_Layer_3': 0.22526194138955083, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00044407789529813134, 'l1_Layer_2': 0.00010923486323722071, 'l1_Layer_3': 7.558781610344548e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 270, 'n_units_Layer_3': 130}. Best is trial 194 with value: 5.604842086046088.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.60 | sMAPE for Validation Set is: 18.27% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.87 | sMAPE for Test Set is: 52.23% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:18:55,180]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:19:00,548]\u001b[0m Trial 172 finished with value: 6.039463614609432 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011503923763152362, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11961588016574108, 'dropout_rate_Layer_2': 0.3262759038490109, 'dropout_rate_Layer_3': 0.32167012376028314, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010195076549687128, 'l1_Layer_2': 0.0029199258068482526, 'l1_Layer_3': 2.6802664859549602e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 75, 'n_units_Layer_3': 200}. Best is trial 194 with value: 5.604842086046088.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.04 | sMAPE for Validation Set is: 19.18% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.90 | sMAPE for Test Set is: 52.86% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:19:04,305]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:19:07,850]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:19:11,528]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:19:14,919]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:19:17,061]\u001b[0m Trial 202 finished with value: 5.982240893806764 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012908039140343342, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20225322682947183, 'dropout_rate_Layer_2': 0.06612269618863292, 'dropout_rate_Layer_3': 0.2668590058696956, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010228254647127678, 'l1_Layer_2': 5.043913691335179e-05, 'l1_Layer_3': 0.00013536066240578556, 'n_units_Layer_1': 160, 'n_units_Layer_2': 300, 'n_units_Layer_3': 125}. Best is trial 194 with value: 5.604842086046088.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.98 | sMAPE for Validation Set is: 19.07% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 11.03 | sMAPE for Test Set is: 53.34% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:19:17,574]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.65 | sMAPE for Validation Set is: 18.43% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.44 | sMAPE for Test Set is: 51.17% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:19:20,438]\u001b[0m Trial 197 finished with value: 5.651918032449605 and parameters: {'n_hidden': 3, 'learning_rate': 0.001951182256929159, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22301691541403626, 'dropout_rate_Layer_2': 0.10813789067313259, 'dropout_rate_Layer_3': 0.2946719202480383, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004490618137941518, 'l1_Layer_2': 0.0003014969878700163, 'l1_Layer_3': 0.00011822491856908082, 'n_units_Layer_1': 150, 'n_units_Layer_2': 245, 'n_units_Layer_3': 190}. Best is trial 194 with value: 5.604842086046088.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:19:24,126]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:19:26,990]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:19:33,376]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:19:36,651]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:19:42,356]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:19:42,769]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:19:47,863]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:19:48,525]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.88 | sMAPE for Validation Set is: 19.03% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.65 | sMAPE for Test Set is: 52.34% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:19:51,999]\u001b[0m Trial 208 finished with value: 5.883988759042122 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005563677220203538, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19240751035734915, 'dropout_rate_Layer_2': 0.02172634148368885, 'dropout_rate_Layer_3': 0.260242067601333, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.479441069054113e-05, 'l1_Layer_2': 4.9029526601686445e-05, 'l1_Layer_3': 0.00010839466356326965, 'n_units_Layer_1': 160, 'n_units_Layer_2': 300, 'n_units_Layer_3': 130}. Best is trial 194 with value: 5.604842086046088.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:19:52,517]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:19:58,556]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:19:58,979]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:20:01,041]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:20:04,132]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:20:05,931]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:20:07,606]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:20:08,595]\u001b[0m Trial 207 finished with value: 5.785909576617368 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005058060940541775, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19689661783207354, 'dropout_rate_Layer_2': 0.03147752720532798, 'dropout_rate_Layer_3': 0.2644110984768922, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002063834283921776, 'l1_Layer_2': 5.3501005463400804e-05, 'l1_Layer_3': 8.99505836083447e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 300, 'n_units_Layer_3': 130}. Best is trial 194 with value: 5.604842086046088.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.79 | sMAPE for Validation Set is: 18.72% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.13 | sMAPE for Test Set is: 53.09% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:20:13,267]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:20:22,147]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:20:25,377]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:20:26,635]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:20:31,116]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:20:34,817]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:20:40,385]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:20:46,348]\u001b[0m Trial 224 finished with value: 5.797436985385706 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005314045167103324, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24389178002516165, 'dropout_rate_Layer_2': 0.01620396901290832, 'dropout_rate_Layer_3': 0.29097766908431727, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023547114298828474, 'l1_Layer_2': 8.475346190847247e-05, 'l1_Layer_3': 0.0001031093480193894, 'n_units_Layer_1': 185, 'n_units_Layer_2': 275, 'n_units_Layer_3': 190}. Best is trial 194 with value: 5.604842086046088.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.80 | sMAPE for Validation Set is: 19.00% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.59 | sMAPE for Test Set is: 51.92% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:20:51,896]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:20:51,992]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:20:57,374]\u001b[0m Trial 225 finished with value: 5.765691149376084 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005003587004795038, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25418137333498003, 'dropout_rate_Layer_2': 0.024209033443626578, 'dropout_rate_Layer_3': 0.29529473414930546, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.27145399069019e-05, 'l1_Layer_2': 8.177462672346538e-05, 'l1_Layer_3': 0.00010175987469706123, 'n_units_Layer_1': 190, 'n_units_Layer_2': 275, 'n_units_Layer_3': 140}. Best is trial 194 with value: 5.604842086046088.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.77 | sMAPE for Validation Set is: 18.81% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.41 | sMAPE for Test Set is: 53.93% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:21:02,396]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:21:04,360]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:21:07,453]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:21:09,795]\u001b[0m Trial 230 finished with value: 5.763304901317706 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005002516969679633, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19034746347236103, 'dropout_rate_Layer_2': 0.02415635864473341, 'dropout_rate_Layer_3': 0.2604498011998688, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.944996049468207e-05, 'l1_Layer_2': 3.296365655131412e-05, 'l1_Layer_3': 8.670847039810163e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 275, 'n_units_Layer_3': 135}. Best is trial 194 with value: 5.604842086046088.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.76 | sMAPE for Validation Set is: 18.83% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.13 | sMAPE for Test Set is: 53.41% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:21:10,007]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:21:16,046]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:21:17,016]\u001b[0m Trial 236 finished with value: 6.101719092625703 and parameters: {'n_hidden': 3, 'learning_rate': 0.007057573762670922, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3246988099981834, 'dropout_rate_Layer_2': 0.12749826652573498, 'dropout_rate_Layer_3': 0.13359781926665243, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005590812094152684, 'l1_Layer_2': 4.473818468857048e-05, 'l1_Layer_3': 0.0002469790725417091, 'n_units_Layer_1': 215, 'n_units_Layer_2': 220, 'n_units_Layer_3': 275}. Best is trial 194 with value: 5.604842086046088.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.10 | sMAPE for Validation Set is: 19.46% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 11.39 | sMAPE for Test Set is: 54.31% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:21:22,379]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:21:28,894]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:21:29,106]\u001b[0m Trial 242 finished with value: 6.283112574689215 and parameters: {'n_hidden': 3, 'learning_rate': 0.00226692694884817, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35507955128691715, 'dropout_rate_Layer_2': 0.02604727384483991, 'dropout_rate_Layer_3': 0.13290656840507103, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020990883323248615, 'l1_Layer_2': 2.0301927839370975e-05, 'l1_Layer_3': 4.67873152858245e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 140, 'n_units_Layer_3': 255}. Best is trial 194 with value: 5.604842086046088.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.28 | sMAPE for Validation Set is: 19.80% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 12.17 | sMAPE for Test Set is: 56.43% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:21:29,535]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:21:32,573]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:21:37,446]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:21:38,916]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:21:42,787]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:21:44,438]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:21:44,879]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:21:45,178]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:21:45,868]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:21:52,041]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:21:52,638]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:21:53,801]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:21:54,332]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:22:00,614]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:22:01,268]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:22:02,684]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:22:05,017]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:22:11,247]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:22:11,369]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:22:11,677]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:22:12,230]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:22:21,901]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:22:23,065]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:22:24,823]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:22:26,880]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:22:29,212]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:22:31,706]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:22:33,484]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:22:33,606]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:22:37,699]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:22:38,966]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:22:41,450]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:22:43,343]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:22:45,256]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:22:48,557]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:22:49,110]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:22:54,007]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:22:57,236]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:22:57,713]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:23:01,100]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:23:03,436]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:23:04,950]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:23:08,600]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:23:09,347]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:23:16,477]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:23:16,671]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:23:17,209]\u001b[0m Trial 288 finished with value: 6.335573123891037 and parameters: {'n_hidden': 3, 'learning_rate': 0.004351536051705112, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3253551122731116, 'dropout_rate_Layer_2': 0.043408097234756, 'dropout_rate_Layer_3': 0.19222741602074583, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0010720123498649044, 'l1_Layer_2': 0.01158281480877834, 'l1_Layer_3': 6.502002969517564e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 110, 'n_units_Layer_3': 285}. Best is trial 194 with value: 5.604842086046088.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.34 | sMAPE for Validation Set is: 19.82% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 12.70 | sMAPE for Test Set is: 57.47% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:23:22,923]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:23:26,524]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:23:29,708]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:23:30,034]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:23:30,582]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:23:36,158]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:23:36,360]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:23:43,397]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:23:45,147]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:23:49,966]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:23:54,250]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:23:56,391]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:23:58,104]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:24:01,719]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:24:04,133]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:24:09,037]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:24:13,553]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:24:19,922]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:24:24,240]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:24:26,041]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:24:29,197]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:24:32,470]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:24:33,227]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:24:38,487]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:24:41,071]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:24:48,042]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:25:02,716]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:25:06,005]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:25:09,558]\u001b[0m Trial 314 finished with value: 5.7438222787799775 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005120443978037944, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2527718418819999, 'dropout_rate_Layer_2': 0.029850659981480086, 'dropout_rate_Layer_3': 0.2916174171956517, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006247692323353078, 'l1_Layer_2': 8.195148177113351e-05, 'l1_Layer_3': 3.2274197972222725e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 275, 'n_units_Layer_3': 150}. Best is trial 194 with value: 5.604842086046088.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.74 | sMAPE for Validation Set is: 18.79% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.55 | sMAPE for Test Set is: 54.41% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:25:12,909]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:25:16,615]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:25:19,626]\u001b[0m Trial 308 finished with value: 5.977980326604882 and parameters: {'n_hidden': 3, 'learning_rate': 0.000955513616133352, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1158869275163111, 'dropout_rate_Layer_2': 0.26800778825404503, 'dropout_rate_Layer_3': 0.22040256446433681, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.655385687083962e-05, 'l1_Layer_2': 0.0011899890705072034, 'l1_Layer_3': 2.4857899494417138e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 140, 'n_units_Layer_3': 230}. Best is trial 194 with value: 5.604842086046088.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.98 | sMAPE for Validation Set is: 19.36% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.81 | sMAPE for Test Set is: 50.06% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:25:24,395]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:25:24,899]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:25:28,956]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:25:31,151]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:25:31,754]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:25:36,145]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:25:37,046]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:25:38,494]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:25:39,615]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:25:43,762]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:25:46,205]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:25:49,817]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:25:50,384]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:25:53,420]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:25:56,505]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:25:56,705]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:25:57,485]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:26:01,822]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:26:02,409]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:26:06,643]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:26:07,187]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:26:07,274]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:26:09,115]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:26:11,388]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:26:15,130]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:26:16,698]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:26:24,009]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:26:27,146]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:26:31,276]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:26:35,835]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:26:39,127]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:26:49,428]\u001b[0m Trial 351 finished with value: 5.7982010723400705 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005802870143344002, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33888569050782896, 'dropout_rate_Layer_2': 0.01602427753975374, 'dropout_rate_Layer_3': 0.27543869537548604, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00028801801844458675, 'l1_Layer_2': 8.60893923990633e-05, 'l1_Layer_3': 9.063857178880961e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 275, 'n_units_Layer_3': 175}. Best is trial 194 with value: 5.604842086046088.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.80 | sMAPE for Validation Set is: 18.76% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.35 | sMAPE for Test Set is: 53.82% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:26:52,690]\u001b[0m Trial 353 finished with value: 5.806165537170171 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005961550984865201, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3215542365752816, 'dropout_rate_Layer_2': 0.01617702840281774, 'dropout_rate_Layer_3': 0.2782606679884674, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000219792017375292, 'l1_Layer_2': 9.938015161327558e-05, 'l1_Layer_3': 9.220441280904201e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 275, 'n_units_Layer_3': 190}. Best is trial 194 with value: 5.604842086046088.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.81 | sMAPE for Validation Set is: 18.92% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.34 | sMAPE for Test Set is: 51.26% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:26:52,979]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:26:57,120]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:27:03,131]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:27:04,572]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:27:07,589]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:27:08,365]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:27:11,099]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:27:11,988]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:27:12,574]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:27:18,855]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:27:20,344]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:27:22,817]\u001b[0m Trial 358 finished with value: 5.861524756379057 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005569433157846045, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2006239937886545, 'dropout_rate_Layer_2': 0.011363598000318966, 'dropout_rate_Layer_3': 0.2767149032386953, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002713177895215692, 'l1_Layer_2': 9.39415425033608e-05, 'l1_Layer_3': 9.244085269730879e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 275, 'n_units_Layer_3': 190}. Best is trial 194 with value: 5.604842086046088.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.86 | sMAPE for Validation Set is: 18.99% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 11.36 | sMAPE for Test Set is: 53.84% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:27:23,052]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:27:23,105]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:27:23,884]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:27:29,624]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:27:32,325]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:27:32,351]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:27:33,452]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:27:33,560]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:27:41,191]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:27:43,943]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:27:44,031]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:27:44,896]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:27:53,623]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:27:58,414]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:28:02,844]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:28:09,789]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:28:11,308]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:28:20,367]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:28:25,214]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:28:27,388]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:28:30,202]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:28:30,516]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:28:34,772]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:28:35,176]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:28:35,684]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:28:40,989]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:28:42,643]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:28:42,865]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:28:49,008]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:28:51,916]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:29:03,877]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:29:04,266]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:29:08,675]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:29:18,483]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:29:18,783]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:29:24,364]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:29:31,290]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:29:34,976]\u001b[0m Trial 404 finished with value: 6.0963707008930115 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009774123652693326, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38694977349509607, 'dropout_rate_Layer_2': 0.3302845475537146, 'dropout_rate_Layer_3': 0.09265515351576839, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011184688603466048, 'l1_Layer_2': 3.847673483102337e-05, 'l1_Layer_3': 3.165780746906966e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 140, 'n_units_Layer_3': 285}. Best is trial 194 with value: 5.604842086046088.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.10 | sMAPE for Validation Set is: 19.62% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.64 | sMAPE for Test Set is: 52.63% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:29:38,884]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:29:40,649]\u001b[0m Trial 382 finished with value: 5.778773494438585 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007344769643809341, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12001154266815264, 'dropout_rate_Layer_2': 0.1494571248172004, 'dropout_rate_Layer_3': 0.19388150150971278, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02090747337795057, 'l1_Layer_2': 0.0010585640588773543, 'l1_Layer_3': 0.00014735121141010513, 'n_units_Layer_1': 165, 'n_units_Layer_2': 85, 'n_units_Layer_3': 145}. Best is trial 194 with value: 5.604842086046088.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.78 | sMAPE for Validation Set is: 18.68% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.20 | sMAPE for Test Set is: 50.20% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:29:42,821]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:29:46,278]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:30:03,857]\u001b[0m Trial 407 finished with value: 5.719217462879736 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007156254289578362, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.360320085618755, 'dropout_rate_Layer_2': 0.028067708420872275, 'dropout_rate_Layer_3': 0.21965060322166793, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002708815714787062, 'l1_Layer_2': 0.00013374182728972012, 'l1_Layer_3': 6.739640342955683e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 270, 'n_units_Layer_3': 175}. Best is trial 194 with value: 5.604842086046088.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.72 | sMAPE for Validation Set is: 18.61% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.96 | sMAPE for Test Set is: 52.69% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:30:05,738]\u001b[0m Trial 411 finished with value: 5.9082576618492055 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009560727870645848, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13178103153216203, 'dropout_rate_Layer_2': 0.3092545882142545, 'dropout_rate_Layer_3': 0.15213980232367189, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.629130032306034e-05, 'l1_Layer_2': 5.5249556783770455e-05, 'l1_Layer_3': 1.6521705237435368e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 215, 'n_units_Layer_3': 300}. Best is trial 194 with value: 5.604842086046088.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.91 | sMAPE for Validation Set is: 18.94% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.30 | sMAPE for Test Set is: 51.29% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:30:08,284]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:30:22,541]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:30:27,071]\u001b[0m Trial 412 finished with value: 5.782511016334887 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007048199793456275, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3840449318113849, 'dropout_rate_Layer_2': 0.0015638181002383695, 'dropout_rate_Layer_3': 0.2205127858376052, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003014135777483228, 'l1_Layer_2': 0.00018638788009181075, 'l1_Layer_3': 7.073186243654767e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 270, 'n_units_Layer_3': 170}. Best is trial 194 with value: 5.604842086046088.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.78 | sMAPE for Validation Set is: 18.80% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.54 | sMAPE for Test Set is: 51.83% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:30:31,216]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:30:39,775]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:30:46,578]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:30:49,300]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:30:52,096]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:30:52,799]\u001b[0m Trial 414 finished with value: 5.914170918804307 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008067213895986758, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.006143277513777171, 'dropout_rate_Layer_2': 0.17651785324691174, 'dropout_rate_Layer_3': 0.1948184007506044, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.00134145567699e-05, 'l1_Layer_2': 0.0023447757591648407, 'l1_Layer_3': 0.00012325588534157288, 'n_units_Layer_1': 155, 'n_units_Layer_2': 165, 'n_units_Layer_3': 160}. Best is trial 194 with value: 5.604842086046088.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.91 | sMAPE for Validation Set is: 19.19% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.95 | sMAPE for Test Set is: 49.81% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:30:58,798]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:31:10,127]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:31:23,708]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:31:24,100]\u001b[0m Trial 425 finished with value: 5.879520131116473 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005999951019837604, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1315593926265474, 'dropout_rate_Layer_2': 0.3619291053017524, 'dropout_rate_Layer_3': 0.12348798373327322, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011566714170533651, 'l1_Layer_2': 3.4275997446236594e-05, 'l1_Layer_3': 1.1817316215607529e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 235, 'n_units_Layer_3': 295}. Best is trial 194 with value: 5.604842086046088.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.88 | sMAPE for Validation Set is: 18.85% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.24 | sMAPE for Test Set is: 51.46% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:31:38,388]\u001b[0m Trial 427 finished with value: 5.935583741478413 and parameters: {'n_hidden': 3, 'learning_rate': 0.000608160700865024, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12648345045091233, 'dropout_rate_Layer_2': 0.34662158130447007, 'dropout_rate_Layer_3': 0.009884694500824603, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000113292519353779, 'l1_Layer_2': 3.337570388630917e-05, 'l1_Layer_3': 3.082576442437036e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 145, 'n_units_Layer_3': 300}. Best is trial 194 with value: 5.604842086046088.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.94 | sMAPE for Validation Set is: 19.00% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.23 | sMAPE for Test Set is: 51.33% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:31:55,413]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:31:57,323]\u001b[0m Trial 428 finished with value: 5.857472588316688 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006476296861656808, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3312252285632725, 'dropout_rate_Layer_2': 0.37239322424789356, 'dropout_rate_Layer_3': 0.10085404552150982, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.136907508810567e-05, 'l1_Layer_2': 3.132701419427215e-05, 'l1_Layer_3': 2.173345464185359e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 230, 'n_units_Layer_3': 295}. Best is trial 194 with value: 5.604842086046088.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.86 | sMAPE for Validation Set is: 18.82% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.31 | sMAPE for Test Set is: 51.57% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:32:02,430]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:32:04,622]\u001b[0m Trial 430 finished with value: 5.88213528900395 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011800974604090095, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3927591184640237, 'dropout_rate_Layer_2': 0.07571109139580905, 'dropout_rate_Layer_3': 0.21780926067718734, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016175239470534738, 'l1_Layer_2': 0.00016989876874538018, 'l1_Layer_3': 2.040146926088464e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 260, 'n_units_Layer_3': 135}. Best is trial 194 with value: 5.604842086046088.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.88 | sMAPE for Validation Set is: 18.86% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.62 | sMAPE for Test Set is: 52.24% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:32:09,334]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:32:17,204]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:32:19,648]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:32:22,053]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:32:25,011]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:32:54,369]\u001b[0m Trial 439 finished with value: 5.917165356887786 and parameters: {'n_hidden': 3, 'learning_rate': 0.000614197861445269, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13217657069304348, 'dropout_rate_Layer_2': 0.36450148710482455, 'dropout_rate_Layer_3': 0.007888277588586935, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010084929981010194, 'l1_Layer_2': 5.8667294815362924e-05, 'l1_Layer_3': 3.0377514606791354e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 230, 'n_units_Layer_3': 295}. Best is trial 194 with value: 5.604842086046088.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.92 | sMAPE for Validation Set is: 18.95% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.63 | sMAPE for Test Set is: 52.30% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:32:59,251]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:33:04,307]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:33:04,515]\u001b[0m Trial 424 finished with value: 5.606083591524061 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005087226355308551, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.003240739601465711, 'dropout_rate_Layer_2': 0.13829783827255834, 'dropout_rate_Layer_3': 0.045613664927281077, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.541158301424864e-05, 'l1_Layer_2': 0.0020862313080484457, 'l1_Layer_3': 0.0001351392967448548, 'n_units_Layer_1': 170, 'n_units_Layer_2': 80, 'n_units_Layer_3': 130}. Best is trial 194 with value: 5.604842086046088.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.61 | sMAPE for Validation Set is: 18.43% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 8.69 | sMAPE for Test Set is: 45.67% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:33:09,296]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:33:09,408]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:33:16,937]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:33:31,995]\u001b[0m Trial 433 finished with value: 5.652266882224566 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006720597762463049, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0007957307264065665, 'dropout_rate_Layer_2': 0.1733306175544539, 'dropout_rate_Layer_3': 0.18412770345795534, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.71705189796074e-05, 'l1_Layer_2': 0.002186077451893472, 'l1_Layer_3': 0.00014427295778726798, 'n_units_Layer_1': 165, 'n_units_Layer_2': 85, 'n_units_Layer_3': 130}. Best is trial 194 with value: 5.604842086046088.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.65 | sMAPE for Validation Set is: 18.45% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 8.90 | sMAPE for Test Set is: 46.61% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:33:47,644]\u001b[0m Trial 446 finished with value: 5.874476968531724 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006130401453109245, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13570193774211287, 'dropout_rate_Layer_2': 0.35982782570657007, 'dropout_rate_Layer_3': 0.010243045138450924, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001051210034597995, 'l1_Layer_2': 6.0415529242223177e-05, 'l1_Layer_3': 1.287470773739064e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 235, 'n_units_Layer_3': 295}. Best is trial 194 with value: 5.604842086046088.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.87 | sMAPE for Validation Set is: 18.87% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.35 | sMAPE for Test Set is: 51.71% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:33:51,056]\u001b[0m Trial 445 finished with value: 5.78445987021814 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005768408512791675, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3053832437715278, 'dropout_rate_Layer_2': 0.009462977593182108, 'dropout_rate_Layer_3': 0.2643344861431502, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00025471992362162074, 'l1_Layer_2': 0.00021109622327721489, 'l1_Layer_3': 0.00011948218833104193, 'n_units_Layer_1': 185, 'n_units_Layer_2': 270, 'n_units_Layer_3': 170}. Best is trial 194 with value: 5.604842086046088.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.78 | sMAPE for Validation Set is: 18.77% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.11 | sMAPE for Test Set is: 53.22% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:33:55,179]\u001b[0m Trial 441 finished with value: 5.800339110935423 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005080313862900708, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1284963773618676, 'dropout_rate_Layer_2': 0.35959461285454686, 'dropout_rate_Layer_3': 0.014923061680116211, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.681222429945905e-05, 'l1_Layer_2': 6.237700473252786e-05, 'l1_Layer_3': 2.956108097915938e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 235, 'n_units_Layer_3': 300}. Best is trial 194 with value: 5.604842086046088.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.80 | sMAPE for Validation Set is: 18.87% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 9.88 | sMAPE for Test Set is: 50.02% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:33:58,070]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:34:01,467]\u001b[0m Trial 447 finished with value: 5.86442743039886 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005297826225368499, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13520826630725144, 'dropout_rate_Layer_2': 0.3600608298328635, 'dropout_rate_Layer_3': 0.0015011956118081687, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010934702693242662, 'l1_Layer_2': 0.00011105422632929154, 'l1_Layer_3': 1.3701553757476085e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 245, 'n_units_Layer_3': 295}. Best is trial 194 with value: 5.604842086046088.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.86 | sMAPE for Validation Set is: 18.78% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.51 | sMAPE for Test Set is: 52.18% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:34:05,969]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:34:11,821]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:34:14,883]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:34:23,212]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:34:31,923]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:34:36,032]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:34:51,539]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:35:33,889]\u001b[0m Trial 452 finished with value: 5.590118991862741 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006553531887385731, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007563400324183812, 'dropout_rate_Layer_2': 0.13165366051943747, 'dropout_rate_Layer_3': 0.19048564508698504, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.760263090709662e-05, 'l1_Layer_2': 0.002107412608320681, 'l1_Layer_3': 0.00013752719729850528, 'n_units_Layer_1': 165, 'n_units_Layer_2': 90, 'n_units_Layer_3': 135}. Best is trial 452 with value: 5.590118991862741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.59 | sMAPE for Validation Set is: 18.34% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 8.72 | sMAPE for Test Set is: 46.22% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:35:36,125]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:35:39,334]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:35:43,819]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:35:44,071]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:35:48,233]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:35:48,688]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:35:53,818]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:36:00,068]\u001b[0m Trial 456 finished with value: 5.611004477010371 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006696463171467106, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.006543428133378191, 'dropout_rate_Layer_2': 0.13429589357288216, 'dropout_rate_Layer_3': 0.18881410979534738, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.200945135372243e-05, 'l1_Layer_2': 0.0020745281578877315, 'l1_Layer_3': 0.00022583624360231747, 'n_units_Layer_1': 165, 'n_units_Layer_2': 85, 'n_units_Layer_3': 120}. Best is trial 452 with value: 5.590118991862741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.61 | sMAPE for Validation Set is: 18.31% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 8.83 | sMAPE for Test Set is: 46.22% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:36:03,602]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:36:16,408]\u001b[0m Trial 466 finished with value: 5.863106818825173 and parameters: {'n_hidden': 3, 'learning_rate': 0.000852513786839307, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10289193897902871, 'dropout_rate_Layer_2': 0.37121626111172396, 'dropout_rate_Layer_3': 0.009125441695383664, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.5244275252338935e-05, 'l1_Layer_2': 7.12305936294293e-05, 'l1_Layer_3': 3.0832275611596024e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 270, 'n_units_Layer_3': 290}. Best is trial 452 with value: 5.590118991862741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.86 | sMAPE for Validation Set is: 18.98% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.43 | sMAPE for Test Set is: 51.92% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:36:19,847]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:36:23,034]\u001b[0m Trial 454 finished with value: 5.725043665052875 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006456529551949611, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0022314048156312567, 'dropout_rate_Layer_2': 0.1397039583567396, 'dropout_rate_Layer_3': 0.187394257935237, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007321393668863886, 'l1_Layer_2': 0.0019088603438321837, 'l1_Layer_3': 0.0001126442679302526, 'n_units_Layer_1': 165, 'n_units_Layer_2': 90, 'n_units_Layer_3': 135}. Best is trial 452 with value: 5.590118991862741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.73 | sMAPE for Validation Set is: 18.61% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 8.89 | sMAPE for Test Set is: 46.12% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:36:27,417]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:36:41,162]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:37:03,349]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:37:07,863]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:37:11,133]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:37:14,663]\u001b[0m Trial 473 finished with value: 5.711644297164259 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007032860993217263, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17644199859813403, 'dropout_rate_Layer_2': 0.18348956740339273, 'dropout_rate_Layer_3': 0.24586823077708914, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005383641915701983, 'l1_Layer_2': 5.727258231779871e-05, 'l1_Layer_3': 5.796828798512601e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 295, 'n_units_Layer_3': 125}. Best is trial 452 with value: 5.590118991862741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.71 | sMAPE for Validation Set is: 18.72% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.40 | sMAPE for Test Set is: 50.96% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:37:16,746]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:37:19,117]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:37:26,209]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:37:44,596]\u001b[0m Trial 479 finished with value: 5.857014024586206 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005839539089493544, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16471763948953536, 'dropout_rate_Layer_2': 0.3875467068620999, 'dropout_rate_Layer_3': 0.030940972417238005, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.085595667551145e-05, 'l1_Layer_2': 5.031315094655684e-05, 'l1_Layer_3': 1.651834378940475e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 275, 'n_units_Layer_3': 285}. Best is trial 452 with value: 5.590118991862741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.86 | sMAPE for Validation Set is: 18.75% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.45 | sMAPE for Test Set is: 52.00% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:37:46,571]\u001b[0m Trial 478 finished with value: 5.869239363790226 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005831102605779588, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15269656772639592, 'dropout_rate_Layer_2': 0.39170270826463166, 'dropout_rate_Layer_3': 0.025857484459670798, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.0932995603158176e-05, 'l1_Layer_2': 8.95577005327478e-05, 'l1_Layer_3': 2.9352304655356155e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 275, 'n_units_Layer_3': 280}. Best is trial 452 with value: 5.590118991862741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.87 | sMAPE for Validation Set is: 18.71% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.78 | sMAPE for Test Set is: 52.86% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:37:49,555]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:38:01,738]\u001b[0m Trial 481 finished with value: 5.843223307942989 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005847068898913413, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08403360330872439, 'dropout_rate_Layer_2': 0.309492757309204, 'dropout_rate_Layer_3': 0.02685376121008843, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.239334787884092e-05, 'l1_Layer_2': 4.9991720476183355e-05, 'l1_Layer_3': 2.2046572393866414e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 265, 'n_units_Layer_3': 280}. Best is trial 452 with value: 5.590118991862741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.84 | sMAPE for Validation Set is: 18.76% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.80 | sMAPE for Test Set is: 52.86% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:38:04,950]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:38:06,959]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:38:09,444]\u001b[0m Trial 469 finished with value: 5.588400919058221 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007194613069908532, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015095942422617858, 'dropout_rate_Layer_2': 0.13985543800448128, 'dropout_rate_Layer_3': 0.14180983080904944, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.296217049822239e-05, 'l1_Layer_2': 0.002669133515080255, 'l1_Layer_3': 0.00020120909228676115, 'n_units_Layer_1': 165, 'n_units_Layer_2': 75, 'n_units_Layer_3': 130}. Best is trial 469 with value: 5.588400919058221.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.59 | sMAPE for Validation Set is: 18.31% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 8.72 | sMAPE for Test Set is: 46.01% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:38:11,316]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:38:45,755]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:38:52,446]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:38:59,523]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:39:07,190]\u001b[0m Trial 489 finished with value: 5.837303124664271 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019467413892185392, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13483645748695725, 'dropout_rate_Layer_2': 0.11019597687301404, 'dropout_rate_Layer_3': 0.22860306976907202, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007305452335192733, 'l1_Layer_2': 0.0001617226506160827, 'l1_Layer_3': 0.00016149790844108823, 'n_units_Layer_1': 230, 'n_units_Layer_2': 280, 'n_units_Layer_3': 160}. Best is trial 469 with value: 5.588400919058221.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.84 | sMAPE for Validation Set is: 19.01% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 9.81 | sMAPE for Test Set is: 49.39% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:39:14,036]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:39:23,364]\u001b[0m Trial 490 finished with value: 5.841801695020062 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005796962541994129, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16373621575636588, 'dropout_rate_Layer_2': 0.37669019493547107, 'dropout_rate_Layer_3': 0.03188206286025061, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.40731336617727e-05, 'l1_Layer_2': 9.232769814072887e-05, 'l1_Layer_3': 2.1040327885674465e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 280, 'n_units_Layer_3': 280}. Best is trial 469 with value: 5.588400919058221.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.84 | sMAPE for Validation Set is: 18.72% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.62 | sMAPE for Test Set is: 52.43% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:39:23,867]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:39:26,057]\u001b[0m Trial 492 finished with value: 5.834551172988348 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006019773922315022, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1763581287293233, 'dropout_rate_Layer_2': 0.0006163603501010972, 'dropout_rate_Layer_3': 0.2626229319680068, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001842804867963718, 'l1_Layer_2': 0.00010944036743002812, 'l1_Layer_3': 3.513017103280102e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 300, 'n_units_Layer_3': 130}. Best is trial 469 with value: 5.588400919058221.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.83 | sMAPE for Validation Set is: 18.99% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.84 | sMAPE for Test Set is: 52.82% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:39:39,813]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:39:40,347]\u001b[0m Trial 486 finished with value: 5.553213424918622 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006857305288945267, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04576575470738602, 'dropout_rate_Layer_2': 0.11938092729952021, 'dropout_rate_Layer_3': 0.18288500497721344, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.239245580377883e-05, 'l1_Layer_2': 0.001865848506714838, 'l1_Layer_3': 0.00016991572492801044, 'n_units_Layer_1': 160, 'n_units_Layer_2': 85, 'n_units_Layer_3': 150}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.55 | sMAPE for Validation Set is: 18.24% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 8.71 | sMAPE for Test Set is: 46.07% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:40:08,215]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:40:12,506]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:40:34,571]\u001b[0m Trial 498 finished with value: 5.892072072237785 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007108012180338774, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07541029673265559, 'dropout_rate_Layer_2': 0.3810470246902021, 'dropout_rate_Layer_3': 0.023372777168690538, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.059925673487233e-05, 'l1_Layer_2': 9.244437803236439e-05, 'l1_Layer_3': 2.2162169530836505e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 275, 'n_units_Layer_3': 285}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.89 | sMAPE for Validation Set is: 18.94% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.96 | sMAPE for Test Set is: 53.25% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:40:37,119]\u001b[0m Trial 499 finished with value: 5.95747945771426 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007066475754874062, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15406464968099523, 'dropout_rate_Layer_2': 0.3043958562510687, 'dropout_rate_Layer_3': 0.028294715783259056, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.271285152376326e-05, 'l1_Layer_2': 0.00016344234708470765, 'l1_Layer_3': 2.1872292832879642e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 270, 'n_units_Layer_3': 285}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.96 | sMAPE for Validation Set is: 19.26% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.45 | sMAPE for Test Set is: 51.85% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:40:40,458]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:41:08,217]\u001b[0m Trial 501 finished with value: 5.874881478692345 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007018235135093749, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14850827081347154, 'dropout_rate_Layer_2': 0.3805885679287079, 'dropout_rate_Layer_3': 0.029407787160754914, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.912944896087341e-05, 'l1_Layer_2': 5.305823995513824e-05, 'l1_Layer_3': 2.244916067280596e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 275, 'n_units_Layer_3': 285}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.87 | sMAPE for Validation Set is: 19.03% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.83 | sMAPE for Test Set is: 52.99% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:41:12,560]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:41:21,853]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:41:24,620]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:41:25,374]\u001b[0m Trial 504 finished with value: 5.977284162475189 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006993659005765681, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07656805667313091, 'dropout_rate_Layer_2': 0.3994008405416024, 'dropout_rate_Layer_3': 0.029779993276944125, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.6726638816317816e-05, 'l1_Layer_2': 9.502501986071941e-05, 'l1_Layer_3': 2.1737662747354896e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 270, 'n_units_Layer_3': 300}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.98 | sMAPE for Validation Set is: 19.04% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.89 | sMAPE for Test Set is: 53.23% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:41:25,959]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:41:32,763]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:41:35,944]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:41:43,793]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:41:44,342]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:41:47,317]\u001b[0m Trial 495 finished with value: 5.604801512160918 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006195449067981497, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00033172540408117016, 'dropout_rate_Layer_2': 0.11976793831676102, 'dropout_rate_Layer_3': 0.15964365462503838, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.0947571465270136e-05, 'l1_Layer_2': 0.0018058147923254242, 'l1_Layer_3': 0.0001725700541631199, 'n_units_Layer_1': 175, 'n_units_Layer_2': 70, 'n_units_Layer_3': 125}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.60 | sMAPE for Validation Set is: 18.51% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 8.53 | sMAPE for Test Set is: 45.89% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:41:48,132]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:41:52,178]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:41:52,878]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:41:57,510]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:42:00,372]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:42:06,393]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:42:14,860]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:42:15,385]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:42:37,198]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:42:38,182]\u001b[0m Trial 523 finished with value: 5.913343213465848 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007821756145719705, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14831212655080458, 'dropout_rate_Layer_2': 0.37115508971486477, 'dropout_rate_Layer_3': 0.03849027068480912, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.298042331331746e-05, 'l1_Layer_2': 8.022856188526122e-05, 'l1_Layer_3': 1.1718050737013512e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 290, 'n_units_Layer_3': 290}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.91 | sMAPE for Validation Set is: 18.78% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.82 | sMAPE for Test Set is: 53.16% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:42:42,872]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:42:43,175]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:42:48,410]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:42:48,778]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:42:54,875]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:42:57,737]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:42:58,603]\u001b[0m Trial 521 finished with value: 5.840828632098559 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005610981405093755, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15033363269717184, 'dropout_rate_Layer_2': 0.3689134237832684, 'dropout_rate_Layer_3': 0.044908113880055174, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.303630878342918e-05, 'l1_Layer_2': 5.211519286681009e-05, 'l1_Layer_3': 1.370808946325926e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 260, 'n_units_Layer_3': 290}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.84 | sMAPE for Validation Set is: 18.79% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.44 | sMAPE for Test Set is: 51.83% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:43:14,224]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:43:22,080]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:43:24,802]\u001b[0m Trial 522 finished with value: 5.875901196455961 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005577801680912021, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14816552424193088, 'dropout_rate_Layer_2': 0.3687035893528229, 'dropout_rate_Layer_3': 0.038759205040958186, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.556078426011333e-05, 'l1_Layer_2': 7.73932783112282e-05, 'l1_Layer_3': 1.3258894902387685e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 295, 'n_units_Layer_3': 290}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.88 | sMAPE for Validation Set is: 19.19% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.42 | sMAPE for Test Set is: 51.37% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:43:25,630]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:43:25,719]\u001b[0m Trial 530 finished with value: 5.87503963320615 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007976790603746273, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14575652675512824, 'dropout_rate_Layer_2': 0.36850423511293934, 'dropout_rate_Layer_3': 0.0404954745346607, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.327464803406465e-05, 'l1_Layer_2': 7.353691048100233e-05, 'l1_Layer_3': 1.257302155661478e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 260, 'n_units_Layer_3': 290}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.88 | sMAPE for Validation Set is: 19.05% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.23 | sMAPE for Test Set is: 51.39% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:43:31,698]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:43:37,490]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:43:39,079]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:43:39,674]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:43:43,630]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:44:38,068]\u001b[0m Trial 538 finished with value: 5.604197566277197 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007334427250477604, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.024964604626544, 'dropout_rate_Layer_2': 0.13959379330384714, 'dropout_rate_Layer_3': 0.15033066775870343, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.960385081531097e-05, 'l1_Layer_2': 0.0017971261433371106, 'l1_Layer_3': 0.0001522491037896764, 'n_units_Layer_1': 165, 'n_units_Layer_2': 75, 'n_units_Layer_3': 140}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.60 | sMAPE for Validation Set is: 18.37% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 8.77 | sMAPE for Test Set is: 46.41% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:44:49,465]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:44:56,449]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:45:12,870]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:45:21,151]\u001b[0m Trial 541 finished with value: 5.6859505565875175 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007789262310692512, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05937881871277753, 'dropout_rate_Layer_2': 0.137163912890345, 'dropout_rate_Layer_3': 0.18569503340524823, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.6619151165629955e-05, 'l1_Layer_2': 6.705937727851215e-05, 'l1_Layer_3': 0.0001534347041853177, 'n_units_Layer_1': 170, 'n_units_Layer_2': 90, 'n_units_Layer_3': 140}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.69 | sMAPE for Validation Set is: 18.47% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 9.74 | sMAPE for Test Set is: 49.39% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:45:28,014]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:45:33,238]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:45:34,990]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:45:41,363]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:45:46,006]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:45:55,225]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:46:39,429]\u001b[0m Trial 552 finished with value: 5.969684503284912 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007058135287841296, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1668613716942289, 'dropout_rate_Layer_2': 0.3837029758132505, 'dropout_rate_Layer_3': 0.05529834041879734, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.603947838379561e-05, 'l1_Layer_2': 5.108503594705964e-05, 'l1_Layer_3': 1.5566469102141676e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 280, 'n_units_Layer_3': 290}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.97 | sMAPE for Validation Set is: 19.06% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.56 | sMAPE for Test Set is: 52.26% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:46:40,028]\u001b[0m Trial 550 finished with value: 5.933250508279552 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006794487221679437, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1426635628263488, 'dropout_rate_Layer_2': 0.3827291084650345, 'dropout_rate_Layer_3': 0.05252986005045908, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.203257921434121e-05, 'l1_Layer_2': 5.1274991466629e-05, 'l1_Layer_3': 1.6235316089003224e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 275, 'n_units_Layer_3': 290}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.93 | sMAPE for Validation Set is: 19.01% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 11.00 | sMAPE for Test Set is: 53.38% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:46:46,958]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:46:49,826]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:46:56,824]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:46:59,205]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:47:01,253]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:47:05,839]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:47:09,297]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:47:11,445]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:47:14,828]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:47:21,617]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:47:21,859]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.59 | sMAPE for Validation Set is: 18.29% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 8.87 | sMAPE for Test Set is: 46.61% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:47:26,102]\u001b[0m Trial 542 finished with value: 5.593940686913732 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005752779049283524, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.014151789163903916, 'dropout_rate_Layer_2': 0.13739794869262048, 'dropout_rate_Layer_3': 0.13403614088821786, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.037795784049258e-05, 'l1_Layer_2': 0.0019552070143253344, 'l1_Layer_3': 0.00012584191873581295, 'n_units_Layer_1': 150, 'n_units_Layer_2': 75, 'n_units_Layer_3': 150}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:47:32,292]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:47:33,921]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:47:37,268]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:47:49,799]\u001b[0m Trial 553 finished with value: 5.555913291095133 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007188311270534995, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.026605803083352066, 'dropout_rate_Layer_2': 0.13515737778541695, 'dropout_rate_Layer_3': 0.19985494003153237, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.7843614521780776e-05, 'l1_Layer_2': 4.533424624091579e-05, 'l1_Layer_3': 0.00017224295981218852, 'n_units_Layer_1': 170, 'n_units_Layer_2': 90, 'n_units_Layer_3': 150}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.56 | sMAPE for Validation Set is: 18.30% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 8.80 | sMAPE for Test Set is: 46.20% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:47:54,385]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:48:06,410]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:48:09,022]\u001b[0m Trial 570 finished with value: 5.880229391880763 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005691594476679623, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11476110874497204, 'dropout_rate_Layer_2': 0.3653614821877653, 'dropout_rate_Layer_3': 0.02384429833803063, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.281606878599533e-05, 'l1_Layer_2': 7.342452343734315e-05, 'l1_Layer_3': 1.8608638488408786e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 290, 'n_units_Layer_3': 295}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.88 | sMAPE for Validation Set is: 18.81% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.39 | sMAPE for Test Set is: 51.85% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:48:12,065]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:48:16,458]\u001b[0m Trial 566 finished with value: 5.828165471908989 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005342633874010787, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1859315250617785, 'dropout_rate_Layer_2': 0.3756818591655063, 'dropout_rate_Layer_3': 0.03749355769898343, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.214247639761474e-05, 'l1_Layer_2': 6.844700581096891e-05, 'l1_Layer_3': 1.1798148435157752e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 265, 'n_units_Layer_3': 285}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.83 | sMAPE for Validation Set is: 18.87% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.93 | sMAPE for Test Set is: 53.13% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:48:23,316]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:48:28,529]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:48:33,061]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:48:36,631]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:48:39,418]\u001b[0m Trial 568 finished with value: 5.858243126685781 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005581231836288323, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11552904725023404, 'dropout_rate_Layer_2': 0.3458219657178244, 'dropout_rate_Layer_3': 0.023992255752429605, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.163524661591181e-05, 'l1_Layer_2': 0.00011782862649325457, 'l1_Layer_3': 1.137508252157855e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 260, 'n_units_Layer_3': 285}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.86 | sMAPE for Validation Set is: 18.92% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 11.53 | sMAPE for Test Set is: 54.45% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:48:41,425]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:48:45,175]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:48:52,565]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:48:55,335]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:48:59,511]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:49:01,637]\u001b[0m Trial 573 finished with value: 5.870812703841669 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005785088095242128, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1180831623185869, 'dropout_rate_Layer_2': 0.36600738934502175, 'dropout_rate_Layer_3': 0.00015929043662888526, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.998072411755366e-05, 'l1_Layer_2': 5.956866037181472e-05, 'l1_Layer_3': 1.9088646279682468e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 290, 'n_units_Layer_3': 295}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.87 | sMAPE for Validation Set is: 18.99% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.14 | sMAPE for Test Set is: 50.99% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:49:04,315]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:49:05,171]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:49:15,219]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:49:16,552]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:49:20,733]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:49:27,477]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:49:50,328]\u001b[0m Trial 584 finished with value: 5.80545699545732 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005627811010326541, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34733095598719393, 'dropout_rate_Layer_2': 0.017306230191926494, 'dropout_rate_Layer_3': 0.2751977202615211, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003069117283644726, 'l1_Layer_2': 8.758070462410705e-05, 'l1_Layer_3': 8.9972735195144e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 280, 'n_units_Layer_3': 170}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.81 | sMAPE for Validation Set is: 19.02% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.54 | sMAPE for Test Set is: 51.63% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:49:53,673]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:50:01,405]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:50:04,463]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:50:07,875]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:50:11,205]\u001b[0m Trial 586 finished with value: 5.871031926266912 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006406720104707509, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08840605645429146, 'dropout_rate_Layer_2': 0.36593289623678066, 'dropout_rate_Layer_3': 0.016388300756171807, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.940672333085443e-05, 'l1_Layer_2': 0.00012314890549156775, 'l1_Layer_3': 1.886722628068471e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 260, 'n_units_Layer_3': 285}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.87 | sMAPE for Validation Set is: 19.26% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.97 | sMAPE for Test Set is: 53.57% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:50:14,908]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:50:15,441]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:50:20,285]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:50:26,364]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:50:30,820]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:50:35,225]\u001b[0m Trial 591 finished with value: 5.842053387491397 and parameters: {'n_hidden': 3, 'learning_rate': 0.000568086353303651, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10172792127202858, 'dropout_rate_Layer_2': 0.3786970554466295, 'dropout_rate_Layer_3': 0.03169473376610555, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.731933485020884e-05, 'l1_Layer_2': 9.484801811721718e-05, 'l1_Layer_3': 2.346756538000063e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 290, 'n_units_Layer_3': 285}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.84 | sMAPE for Validation Set is: 18.88% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.84 | sMAPE for Test Set is: 52.73% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:51:07,921]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:51:10,990]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:51:15,046]\u001b[0m Trial 593 finished with value: 5.739612694346317 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005698762924790602, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08387833497500216, 'dropout_rate_Layer_2': 0.37983070944693237, 'dropout_rate_Layer_3': 0.03354039549057616, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.362107381892327e-05, 'l1_Layer_2': 9.785643164800802e-05, 'l1_Layer_3': 2.412300073506443e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 290, 'n_units_Layer_3': 285}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:51:15,124]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.74 | sMAPE for Validation Set is: 18.84% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.96 | sMAPE for Test Set is: 53.11% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:51:21,123]\u001b[0m Trial 603 finished with value: 5.818214077377896 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005771750394935414, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09917912605747964, 'dropout_rate_Layer_2': 0.375869654482922, 'dropout_rate_Layer_3': 0.03115156290551232, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.513832937913257e-05, 'l1_Layer_2': 0.00020538659641516005, 'l1_Layer_3': 1.8478905922940757e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 290, 'n_units_Layer_3': 285}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.82 | sMAPE for Validation Set is: 18.91% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.93 | sMAPE for Test Set is: 53.23% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:51:24,420]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:51:42,096]\u001b[0m Trial 605 finished with value: 5.878232530265685 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006358745612207552, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08282678210562502, 'dropout_rate_Layer_2': 0.37755549589519116, 'dropout_rate_Layer_3': 0.03697325718809184, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.297244308194976e-05, 'l1_Layer_2': 9.456781097591074e-05, 'l1_Layer_3': 1.8433036521947773e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 255, 'n_units_Layer_3': 280}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.88 | sMAPE for Validation Set is: 19.18% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.52 | sMAPE for Test Set is: 52.33% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:51:42,483]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:51:54,237]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:52:10,507]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:52:13,579]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:52:16,873]\u001b[0m Trial 608 finished with value: 5.840747884871575 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006704837165139115, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08641136865253696, 'dropout_rate_Layer_2': 0.37712164413031074, 'dropout_rate_Layer_3': 0.045951473715862286, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.208433902636976e-05, 'l1_Layer_2': 9.356490569661849e-05, 'l1_Layer_3': 2.4341091896176716e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 285, 'n_units_Layer_3': 280}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.84 | sMAPE for Validation Set is: 18.94% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.49 | sMAPE for Test Set is: 51.97% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:52:27,178]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:52:30,101]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:52:30,514]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:52:34,264]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:52:39,600]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:52:42,874]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:52:46,009]\u001b[0m Trial 609 finished with value: 5.891752227073607 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006530432228398178, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08856850673292589, 'dropout_rate_Layer_2': 0.37922204762461803, 'dropout_rate_Layer_3': 0.04144244736675318, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.032762462416799e-05, 'l1_Layer_2': 0.0001037184246743261, 'l1_Layer_3': 2.4895594132985714e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 255, 'n_units_Layer_3': 285}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:52:46,183]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.89 | sMAPE for Validation Set is: 19.04% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 11.08 | sMAPE for Test Set is: 53.53% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:52:46,389]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:52:53,458]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:52:56,436]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:52:58,867]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:53:06,313]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:53:10,096]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:53:13,140]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:53:16,501]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:53:19,415]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:53:22,703]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:53:28,558]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:53:31,845]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:53:35,478]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:53:41,460]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:53:44,870]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:53:51,993]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:53:52,304]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:53:58,055]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:54:01,929]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:54:04,395]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:54:04,987]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:54:08,480]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:54:16,543]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:54:19,267]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:54:21,887]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:54:45,355]\u001b[0m Trial 624 finished with value: 5.7497155153824915 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005008595818222577, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1949538734256388, 'dropout_rate_Layer_2': 0.35815002634110366, 'dropout_rate_Layer_3': 0.02839296835067345, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.544359554132693e-05, 'l1_Layer_2': 6.053591150237369e-05, 'l1_Layer_3': 1.9045729269528712e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 265, 'n_units_Layer_3': 270}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.75 | sMAPE for Validation Set is: 18.76% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.27 | sMAPE for Test Set is: 54.06% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:54:45,676]\u001b[0m Trial 627 finished with value: 5.803267959722525 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008218745630930014, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05357453753989185, 'dropout_rate_Layer_2': 0.3565344552106711, 'dropout_rate_Layer_3': 0.032593926339140086, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.518177159625555e-05, 'l1_Layer_2': 6.615546645213865e-05, 'l1_Layer_3': 1.9025522086111446e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 265, 'n_units_Layer_3': 270}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.80 | sMAPE for Validation Set is: 18.97% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 11.21 | sMAPE for Test Set is: 53.77% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:54:50,654]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:54:57,082]\u001b[0m Trial 646 finished with value: 5.779955108834211 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005596087932260815, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3429159732084839, 'dropout_rate_Layer_2': 0.016847175487513865, 'dropout_rate_Layer_3': 0.2729702176752536, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00031628754609882437, 'l1_Layer_2': 9.492242765715667e-05, 'l1_Layer_3': 9.593488536641895e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 280, 'n_units_Layer_3': 170}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.78 | sMAPE for Validation Set is: 18.73% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.80 | sMAPE for Test Set is: 52.24% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:55:03,765]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:55:10,538]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:55:45,603]\u001b[0m Trial 653 finished with value: 5.88136130476908 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005538783379032753, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20148326164810684, 'dropout_rate_Layer_2': 0.2750415264225903, 'dropout_rate_Layer_3': 0.0010899798905511897, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013315224767462944, 'l1_Layer_2': 4.3641061422620406e-05, 'l1_Layer_3': 2.8304114715692578e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 300, 'n_units_Layer_3': 270}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.88 | sMAPE for Validation Set is: 18.93% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.71 | sMAPE for Test Set is: 52.59% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:55:48,601]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:55:53,157]\u001b[0m Trial 651 finished with value: 5.85056083897257 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005593808465039535, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19903554632034462, 'dropout_rate_Layer_2': 0.3543788820410874, 'dropout_rate_Layer_3': 0.01678838178254554, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012710850438928803, 'l1_Layer_2': 4.4086054804228976e-05, 'l1_Layer_3': 2.92887733020606e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 245, 'n_units_Layer_3': 270}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.85 | sMAPE for Validation Set is: 18.98% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.61 | sMAPE for Test Set is: 52.37% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:55:59,912]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:56:02,417]\u001b[0m Trial 654 finished with value: 5.785606362331637 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006948690330517552, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3362556835156451, 'dropout_rate_Layer_2': 0.012532099946965997, 'dropout_rate_Layer_3': 0.26643476410496164, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00043954355615042327, 'l1_Layer_2': 0.00010317057887640016, 'l1_Layer_3': 9.514874612729197e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 285, 'n_units_Layer_3': 145}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.79 | sMAPE for Validation Set is: 18.78% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.74 | sMAPE for Test Set is: 51.95% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:56:05,650]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:56:08,218]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:56:17,089]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:56:20,878]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:56:24,529]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:56:28,117]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:56:37,181]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.73 | sMAPE for Validation Set is: 18.71% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.93 | sMAPE for Test Set is: 53.24% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:56:38,878]\u001b[0m Trial 656 finished with value: 5.733196404587818 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005734492516510323, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.024181525929819585, 'dropout_rate_Layer_2': 0.3287262554276675, 'dropout_rate_Layer_3': 0.0005611008688654346, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001337110080755262, 'l1_Layer_2': 8.602893153578567e-05, 'l1_Layer_3': 2.2177476965072586e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 275, 'n_units_Layer_3': 270}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:56:42,209]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:56:47,236]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:56:51,234]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:57:48,709]\u001b[0m Trial 660 finished with value: 5.763681332281404 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005015247626976314, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22332453517489723, 'dropout_rate_Layer_2': 0.3275051109120641, 'dropout_rate_Layer_3': 0.01131526085413366, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010289133577643086, 'l1_Layer_2': 9.145999739380429e-05, 'l1_Layer_3': 2.0003553638358463e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 245, 'n_units_Layer_3': 275}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.76 | sMAPE for Validation Set is: 18.82% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.34 | sMAPE for Test Set is: 51.56% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:57:52,087]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:57:59,117]\u001b[0m Trial 669 finished with value: 5.855560595070391 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005919603496769175, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04655564534482472, 'dropout_rate_Layer_2': 0.3433623325320104, 'dropout_rate_Layer_3': 0.020399356991215728, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001333758990635504, 'l1_Layer_2': 0.00010262234789916302, 'l1_Layer_3': 2.0578597520751114e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 265, 'n_units_Layer_3': 265}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.86 | sMAPE for Validation Set is: 18.88% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.55 | sMAPE for Test Set is: 52.28% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:58:03,936]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:58:08,196]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:58:08,912]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:58:13,293]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:58:20,462]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:58:22,722]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:58:25,380]\u001b[0m Trial 672 finished with value: 5.640192206631409 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005374579334535425, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2576740753260064, 'dropout_rate_Layer_2': 0.14595147340562903, 'dropout_rate_Layer_3': 0.16904472322725517, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006966944490210648, 'l1_Layer_2': 0.002209952377601408, 'l1_Layer_3': 0.00013847599250996104, 'n_units_Layer_1': 160, 'n_units_Layer_2': 85, 'n_units_Layer_3': 155}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.64 | sMAPE for Validation Set is: 18.41% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 8.65 | sMAPE for Test Set is: 46.04% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 01:58:29,167]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:58:34,603]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:58:38,622]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:58:43,039]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:58:47,323]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:58:47,527]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:58:53,331]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:58:55,685]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:59:00,409]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:59:01,417]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:59:01,975]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:59:11,275]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:59:11,656]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:59:16,868]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:59:19,909]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:59:23,315]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:59:26,279]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:59:26,471]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:59:32,183]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:59:32,565]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:59:49,054]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:59:52,787]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 01:59:55,572]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:00:05,009]\u001b[0m Trial 694 finished with value: 5.804509643268472 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005742712815665762, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3248181926086871, 'dropout_rate_Layer_2': 0.015549543222293382, 'dropout_rate_Layer_3': 0.2733260044574915, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000291398847939398, 'l1_Layer_2': 0.00010505416292250719, 'l1_Layer_3': 8.94508202457681e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 280, 'n_units_Layer_3': 170}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.80 | sMAPE for Validation Set is: 18.98% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.31 | sMAPE for Test Set is: 50.97% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:00:22,504]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:00:28,424]\u001b[0m Trial 696 finished with value: 5.778734203351164 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006784180725333275, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0279388858054386, 'dropout_rate_Layer_2': 0.30010048705288983, 'dropout_rate_Layer_3': 0.04824863109173082, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.419924577007414e-05, 'l1_Layer_2': 5.639127714217561e-05, 'l1_Layer_3': 1.6177028567527803e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 255, 'n_units_Layer_3': 280}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.78 | sMAPE for Validation Set is: 18.94% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.17 | sMAPE for Test Set is: 53.86% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:00:31,617]\u001b[0m Trial 702 finished with value: 5.800594551215986 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006906069800176402, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.054857883206690584, 'dropout_rate_Layer_2': 0.3549929158360525, 'dropout_rate_Layer_3': 0.047343547645420245, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.24511157925454e-05, 'l1_Layer_2': 5.328354424770631e-05, 'l1_Layer_3': 1.6431871472766132e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 285, 'n_units_Layer_3': 280}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.80 | sMAPE for Validation Set is: 18.78% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.06 | sMAPE for Test Set is: 53.57% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:00:35,815]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:00:38,968]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:00:42,219]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:00:50,008]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:00:53,939]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:00:57,937]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:01:01,578]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:01:07,662]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:01:10,774]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:01:47,720]\u001b[0m Trial 705 finished with value: 5.796914793999669 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007277664084573634, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.018690888963501715, 'dropout_rate_Layer_2': 0.35451502987118216, 'dropout_rate_Layer_3': 0.05179404877307336, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.346358448319344e-05, 'l1_Layer_2': 4.4971493918039444e-05, 'l1_Layer_3': 1.6551790911136393e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 280, 'n_units_Layer_3': 280}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.80 | sMAPE for Validation Set is: 18.90% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.12 | sMAPE for Test Set is: 54.11% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:01:50,997]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:01:55,594]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:02:02,436]\u001b[0m Trial 716 finished with value: 5.8970219939418165 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007065238542802604, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02757322907976491, 'dropout_rate_Layer_2': 0.3539598976895914, 'dropout_rate_Layer_3': 0.05163185217535547, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010124249326328536, 'l1_Layer_2': 5.425306909839812e-05, 'l1_Layer_3': 1.4750856215884278e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 250, 'n_units_Layer_3': 275}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.90 | sMAPE for Validation Set is: 19.15% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.81 | sMAPE for Test Set is: 52.80% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:02:13,984]\u001b[0m Trial 713 finished with value: 5.864190187243332 and parameters: {'n_hidden': 3, 'learning_rate': 0.000707050016921491, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0279830663087507, 'dropout_rate_Layer_2': 0.3203414208637592, 'dropout_rate_Layer_3': 0.05958253117983647, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.99285735957889e-05, 'l1_Layer_2': 5.279373308020352e-05, 'l1_Layer_3': 1.592527221121943e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 245, 'n_units_Layer_3': 275}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.86 | sMAPE for Validation Set is: 18.98% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 12.01 | sMAPE for Test Set is: 55.83% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:02:37,107]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:02:41,384]\u001b[0m Trial 718 finished with value: 5.8094131686412185 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007149446782028515, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.026719128317584863, 'dropout_rate_Layer_2': 0.2913773600093988, 'dropout_rate_Layer_3': 0.05242563555505041, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010566906719618576, 'l1_Layer_2': 5.6159801316676264e-05, 'l1_Layer_3': 1.495425601944379e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 245, 'n_units_Layer_3': 275}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.81 | sMAPE for Validation Set is: 19.01% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.80 | sMAPE for Test Set is: 52.73% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:02:44,181]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:02:48,222]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:02:48,891]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:02:56,851]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:03:02,587]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:03:09,476]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:03:16,302]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:03:19,627]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:03:20,246]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:03:25,706]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:03:28,729]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:03:32,236]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:03:51,043]\u001b[0m Trial 728 finished with value: 5.8348352800333245 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008920155575990219, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007224733060860897, 'dropout_rate_Layer_2': 0.30121647962357706, 'dropout_rate_Layer_3': 0.05307071650900976, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.811640418779135e-05, 'l1_Layer_2': 4.139049577091373e-05, 'l1_Layer_3': 2.0078997956601023e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 285, 'n_units_Layer_3': 280}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.83 | sMAPE for Validation Set is: 18.86% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 11.22 | sMAPE for Test Set is: 54.15% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:03:53,296]\u001b[0m Trial 727 finished with value: 5.825857177233076 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008947203326212472, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05254627521860632, 'dropout_rate_Layer_2': 0.3041135477728093, 'dropout_rate_Layer_3': 0.04249581034160501, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.825336349174201e-05, 'l1_Layer_2': 4.4175615157655415e-05, 'l1_Layer_3': 2.0350346650520595e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 280, 'n_units_Layer_3': 280}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.83 | sMAPE for Validation Set is: 18.78% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 11.34 | sMAPE for Test Set is: 54.28% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:03:56,877]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:04:10,402]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:04:15,381]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:04:17,372]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:04:31,083]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:04:37,863]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:04:57,577]\u001b[0m Trial 741 finished with value: 5.727369406471094 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005911318580799169, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33386368061979477, 'dropout_rate_Layer_2': 0.015787359590051824, 'dropout_rate_Layer_3': 0.2737793155030434, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020973709321975075, 'l1_Layer_2': 0.00010689678979125765, 'l1_Layer_3': 9.081035229512876e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 285, 'n_units_Layer_3': 170}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.73 | sMAPE for Validation Set is: 18.63% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.85 | sMAPE for Test Set is: 52.25% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:05:10,908]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:05:14,745]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:05:25,956]\u001b[0m Trial 745 finished with value: 5.749154874513851 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005742859606100696, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3230918144198621, 'dropout_rate_Layer_2': 0.017064387934826897, 'dropout_rate_Layer_3': 0.2721495390123217, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00026505813383512027, 'l1_Layer_2': 0.00010889851210125905, 'l1_Layer_3': 9.54250698287294e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 280, 'n_units_Layer_3': 180}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.75 | sMAPE for Validation Set is: 18.81% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.36 | sMAPE for Test Set is: 51.18% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:05:31,329]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:05:51,101]\u001b[0m Trial 743 finished with value: 5.586863047041457 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008315383911452331, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11405054848783894, 'dropout_rate_Layer_2': 0.15383873375800072, 'dropout_rate_Layer_3': 0.15508855979772052, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.0388468094653412e-05, 'l1_Layer_2': 0.0017543277919782095, 'l1_Layer_3': 0.00023611907893686247, 'n_units_Layer_1': 110, 'n_units_Layer_2': 105, 'n_units_Layer_3': 115}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.59 | sMAPE for Validation Set is: 18.31% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 8.90 | sMAPE for Test Set is: 46.51% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:05:59,623]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:06:12,534]\u001b[0m Trial 748 finished with value: 5.900811365234008 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005009894234856442, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04441992727567618, 'dropout_rate_Layer_2': 0.3248419977996771, 'dropout_rate_Layer_3': 0.03780472261049288, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.824160049828186e-05, 'l1_Layer_2': 6.179586511410038e-05, 'l1_Layer_3': 2.4201034108678143e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 240, 'n_units_Layer_3': 275}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.90 | sMAPE for Validation Set is: 19.03% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.40 | sMAPE for Test Set is: 51.79% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:06:15,414]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:06:18,907]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:06:22,011]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:06:24,546]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:06:28,060]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:06:40,331]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:06:41,713]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:06:45,348]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:06:49,192]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:06:49,671]\u001b[0m Trial 749 finished with value: 5.867227681116852 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005137267558300551, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04422472453803712, 'dropout_rate_Layer_2': 0.2805708011376722, 'dropout_rate_Layer_3': 0.039335335640489084, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.379909847004519e-05, 'l1_Layer_2': 6.278920565344521e-05, 'l1_Layer_3': 2.486480949154545e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 240, 'n_units_Layer_3': 275}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.87 | sMAPE for Validation Set is: 19.13% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 11.01 | sMAPE for Test Set is: 53.19% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:06:55,049]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:07:01,193]\u001b[0m Trial 750 finished with value: 5.827269957819207 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005001497639307747, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.023634927115567625, 'dropout_rate_Layer_2': 0.324167755844431, 'dropout_rate_Layer_3': 0.040697001254030425, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.666382080023916e-05, 'l1_Layer_2': 6.227777286244312e-05, 'l1_Layer_3': 2.4862485244558392e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 240, 'n_units_Layer_3': 275}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:07:01,265]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.83 | sMAPE for Validation Set is: 18.86% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.88 | sMAPE for Test Set is: 53.20% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:07:07,554]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:07:15,386]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:07:19,595]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:07:23,449]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:07:38,440]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:07:50,586]\u001b[0m Trial 762 finished with value: 5.823682526108051 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006437183721961664, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02164876986005908, 'dropout_rate_Layer_2': 0.3004993096733754, 'dropout_rate_Layer_3': 0.05375028455720629, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00017301166140728011, 'l1_Layer_2': 3.755185090512472e-05, 'l1_Layer_3': 1.2564570523765735e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 290, 'n_units_Layer_3': 285}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.82 | sMAPE for Validation Set is: 18.86% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 11.08 | sMAPE for Test Set is: 53.58% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:07:54,037]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:07:55,582]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:07:59,763]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:08:02,886]\u001b[0m Trial 765 finished with value: 5.758569810758839 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006520089351292874, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.024882948666123603, 'dropout_rate_Layer_2': 0.2612489988985152, 'dropout_rate_Layer_3': 0.054046832309371164, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015095900576129868, 'l1_Layer_2': 3.977190962304805e-05, 'l1_Layer_3': 1.7402378717949037e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 295, 'n_units_Layer_3': 270}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.76 | sMAPE for Validation Set is: 18.69% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.01 | sMAPE for Test Set is: 53.48% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:08:08,074]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:08:12,009]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:08:13,677]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:08:16,048]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:08:19,118]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:08:24,641]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:08:28,671]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:08:34,111]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:08:37,629]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:08:38,268]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:08:43,589]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:08:44,010]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:08:53,467]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:09:12,563]\u001b[0m Trial 774 finished with value: 5.81881541616965 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006077079526157109, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.025746126565879622, 'dropout_rate_Layer_2': 0.29785281075543546, 'dropout_rate_Layer_3': 0.051828156938230265, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00016221906502330357, 'l1_Layer_2': 3.9999111572653075e-05, 'l1_Layer_3': 1.7742334296424873e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 295, 'n_units_Layer_3': 280}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.82 | sMAPE for Validation Set is: 18.94% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 11.05 | sMAPE for Test Set is: 53.64% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:09:22,488]\u001b[0m Trial 759 finished with value: 5.664316670735065 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005041938360827399, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11860273850975958, 'dropout_rate_Layer_2': 0.11491196135141755, 'dropout_rate_Layer_3': 0.1861770631247742, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.1479349120435796e-05, 'l1_Layer_2': 0.0020885924335096676, 'l1_Layer_3': 0.00018956067575207308, 'n_units_Layer_1': 100, 'n_units_Layer_2': 70, 'n_units_Layer_3': 125}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.66 | sMAPE for Validation Set is: 18.64% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 8.86 | sMAPE for Test Set is: 46.98% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:09:37,715]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:09:51,960]\u001b[0m Trial 787 finished with value: 5.8085318596189355 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006029485775797703, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.023595928293807397, 'dropout_rate_Layer_2': 0.25335968470514636, 'dropout_rate_Layer_3': 0.041588771234511546, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001903579448534128, 'l1_Layer_2': 5.06646630768502e-05, 'l1_Layer_3': 1.374218573040703e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 300, 'n_units_Layer_3': 270}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.81 | sMAPE for Validation Set is: 19.01% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 11.38 | sMAPE for Test Set is: 54.52% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:10:03,563]\u001b[0m Trial 789 finished with value: 5.842366637357023 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006011637978838441, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23947214946308087, 'dropout_rate_Layer_2': 0.30039124253336447, 'dropout_rate_Layer_3': 0.057863308542037126, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001639131706213499, 'l1_Layer_2': 7.204099227690396e-05, 'l1_Layer_3': 1.558902109535113e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 290, 'n_units_Layer_3': 265}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.84 | sMAPE for Validation Set is: 18.94% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 11.22 | sMAPE for Test Set is: 53.93% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:10:10,268]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:10:16,135]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:10:24,273]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:10:27,862]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:10:30,806]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:10:38,777]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:10:42,378]\u001b[0m Trial 790 finished with value: 5.812217345741236 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006739605469109634, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02601959646823083, 'dropout_rate_Layer_2': 0.3054475123272123, 'dropout_rate_Layer_3': 0.06011711383577868, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00016506541762934313, 'l1_Layer_2': 3.560041517343023e-05, 'l1_Layer_3': 2.1083726149142723e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 295, 'n_units_Layer_3': 265}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.81 | sMAPE for Validation Set is: 18.93% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 11.03 | sMAPE for Test Set is: 53.75% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:10:54,622]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:10:54,852]\u001b[0m Trial 793 finished with value: 5.870988443997208 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007690146165901305, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.026225267032585136, 'dropout_rate_Layer_2': 0.2679407359794342, 'dropout_rate_Layer_3': 0.06031920311870688, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00018261083700047857, 'l1_Layer_2': 3.508528882051593e-05, 'l1_Layer_3': 1.3941008560404234e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 300, 'n_units_Layer_3': 280}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.87 | sMAPE for Validation Set is: 19.17% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 11.06 | sMAPE for Test Set is: 53.86% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:11:04,093]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:11:04,415]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:11:15,598]\u001b[0m Trial 800 finished with value: 5.808021174700482 and parameters: {'n_hidden': 3, 'learning_rate': 0.000710284183374653, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3254474702656962, 'dropout_rate_Layer_2': 0.009673711995992254, 'dropout_rate_Layer_3': 0.2590212246509245, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003153974677813653, 'l1_Layer_2': 0.0001326600596220406, 'l1_Layer_3': 0.00012041969603077322, 'n_units_Layer_1': 185, 'n_units_Layer_2': 265, 'n_units_Layer_3': 175}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.81 | sMAPE for Validation Set is: 18.81% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.68 | sMAPE for Test Set is: 52.21% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:11:16,136]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:11:23,189]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:11:25,570]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:11:26,258]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:11:26,408]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:11:34,997]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:11:35,228]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:11:41,036]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:11:43,978]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:11:57,398]\u001b[0m Trial 798 finished with value: 5.875825636204908 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007750081830480833, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24703279754507984, 'dropout_rate_Layer_2': 0.261179502515987, 'dropout_rate_Layer_3': 0.059727367901409104, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00017731347098297198, 'l1_Layer_2': 3.381301636205232e-05, 'l1_Layer_3': 1.3691686343492156e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 295, 'n_units_Layer_3': 280}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.88 | sMAPE for Validation Set is: 18.97% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.90 | sMAPE for Test Set is: 53.13% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:12:00,930]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:12:17,636]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:12:22,675]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:12:31,144]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:12:38,947]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:12:41,969]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:12:45,783]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:12:47,415]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:12:55,762]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:12:56,671]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:13:01,644]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:13:02,227]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:13:05,926]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:13:06,820]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:13:06,859]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:13:09,530]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:13:16,729]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:13:20,401]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:13:20,781]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:13:29,617]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:13:36,660]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:13:51,514]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:13:54,958]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:13:58,207]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:14:02,482]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:14:13,599]\u001b[0m Trial 833 finished with value: 5.833906388830678 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006626338710382929, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.024055846456820365, 'dropout_rate_Layer_2': 0.28152593049278724, 'dropout_rate_Layer_3': 0.05261001498573085, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011924536725114178, 'l1_Layer_2': 6.844356891957307e-05, 'l1_Layer_3': 1.5446444722872085e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 290, 'n_units_Layer_3': 275}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.83 | sMAPE for Validation Set is: 18.95% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 11.04 | sMAPE for Test Set is: 53.74% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:14:14,361]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:14:18,968]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:14:24,379]\u001b[0m Trial 816 finished with value: 5.64579679777308 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007749804063681069, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11370993116142257, 'dropout_rate_Layer_2': 0.13006413000301506, 'dropout_rate_Layer_3': 0.10225652143558918, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.742875279269849e-05, 'l1_Layer_2': 0.002391852052386028, 'l1_Layer_3': 3.80690245994094e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 55, 'n_units_Layer_3': 145}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.65 | sMAPE for Validation Set is: 18.56% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 8.78 | sMAPE for Test Set is: 46.11% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:14:24,614]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:14:32,072]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:14:32,154]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:14:36,544]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:14:36,882]\u001b[0m Trial 835 finished with value: 5.8247197992018185 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006116425710375656, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32525095419708505, 'dropout_rate_Layer_2': 0.02795524183476946, 'dropout_rate_Layer_3': 0.2753259550342679, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022743986299038075, 'l1_Layer_2': 0.00010830368800726264, 'l1_Layer_3': 0.00010293724680045818, 'n_units_Layer_1': 180, 'n_units_Layer_2': 285, 'n_units_Layer_3': 190}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.82 | sMAPE for Validation Set is: 19.00% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.70 | sMAPE for Test Set is: 52.16% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:14:41,501]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:14:47,335]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:14:47,829]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:14:56,663]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:14:56,999]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:14:57,466]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:15:03,580]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:15:03,807]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:15:03,965]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:15:21,974]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:15:31,018]\u001b[0m Trial 848 finished with value: 5.778813772924501 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007231102162939377, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02485148620326412, 'dropout_rate_Layer_2': 0.27905656097616116, 'dropout_rate_Layer_3': 0.05356834228955994, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.881290452716853e-05, 'l1_Layer_2': 5.813064313699873e-05, 'l1_Layer_3': 1.7943539878472766e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 295, 'n_units_Layer_3': 175}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.78 | sMAPE for Validation Set is: 18.82% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.06 | sMAPE for Test Set is: 53.57% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:15:38,659]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:15:48,613]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:15:53,964]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:16:20,862]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:16:27,584]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:16:44,966]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:16:48,097]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:16:50,655]\u001b[0m Trial 860 finished with value: 5.837048858824347 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007242033836522868, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.023363970093454655, 'dropout_rate_Layer_2': 0.281651082734473, 'dropout_rate_Layer_3': 0.07156797779013845, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012136573788451605, 'l1_Layer_2': 5.67550440177214e-05, 'l1_Layer_3': 1.893826583228675e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 295, 'n_units_Layer_3': 275}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.84 | sMAPE for Validation Set is: 18.91% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.88 | sMAPE for Test Set is: 52.95% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:16:55,377]\u001b[0m Trial 858 finished with value: 5.764610233074904 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007101950120407337, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.023298228263881813, 'dropout_rate_Layer_2': 0.27943850966290396, 'dropout_rate_Layer_3': 0.06698819226503668, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012141362045812579, 'l1_Layer_2': 0.0005281965900224372, 'l1_Layer_3': 2.1004951703408847e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 295, 'n_units_Layer_3': 275}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.76 | sMAPE for Validation Set is: 18.85% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.99 | sMAPE for Test Set is: 53.21% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:17:03,504]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:17:17,663]\u001b[0m Trial 864 finished with value: 5.82019243100044 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007232216174651262, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.001958787711428444, 'dropout_rate_Layer_2': 0.2843197855940366, 'dropout_rate_Layer_3': 0.06623828115450553, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012378939675065635, 'l1_Layer_2': 5.817455632813068e-05, 'l1_Layer_3': 1.862457739221396e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 295, 'n_units_Layer_3': 275}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.82 | sMAPE for Validation Set is: 18.86% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 11.05 | sMAPE for Test Set is: 53.55% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:17:25,598]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:17:33,430]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:17:41,333]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:17:48,010]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:17:51,526]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:18:02,685]\u001b[0m Trial 869 finished with value: 5.806993330338732 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007328855481425483, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.014927193552949492, 'dropout_rate_Layer_2': 0.285308462735213, 'dropout_rate_Layer_3': 0.07246241392849936, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014367465708893214, 'l1_Layer_2': 4.866102445996026e-05, 'l1_Layer_3': 1.8227677168617238e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 295, 'n_units_Layer_3': 110}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.81 | sMAPE for Validation Set is: 18.98% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.90 | sMAPE for Test Set is: 53.16% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:18:17,866]\u001b[0m Trial 868 finished with value: 5.6775673044617925 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005058300389814359, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05424662453609722, 'dropout_rate_Layer_2': 0.13612749807143892, 'dropout_rate_Layer_3': 0.09585685291662005, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.163561676969318e-05, 'l1_Layer_2': 6.291103602220567e-05, 'l1_Layer_3': 3.2965391965798916e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 175, 'n_units_Layer_3': 160}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.68 | sMAPE for Validation Set is: 18.50% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 8.84 | sMAPE for Test Set is: 46.63% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:18:32,553]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:18:46,020]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:19:02,681]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:19:19,285]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:19:28,118]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:19:32,477]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:19:41,407]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:19:46,491]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:20:49,249]\u001b[0m Trial 884 finished with value: 5.731534408074796 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008737039146464525, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03444065720597854, 'dropout_rate_Layer_2': 0.2959211546593172, 'dropout_rate_Layer_3': 0.05973748813123571, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013068597891005638, 'l1_Layer_2': 6.272040609566696e-05, 'l1_Layer_3': 2.1125826209200632e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 290, 'n_units_Layer_3': 95}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.73 | sMAPE for Validation Set is: 18.50% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.40 | sMAPE for Test Set is: 51.15% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:20:51,392]\u001b[0m Trial 882 finished with value: 5.74406567039388 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005880138282596961, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.050740258072190444, 'dropout_rate_Layer_2': 0.12376296383990998, 'dropout_rate_Layer_3': 0.10145043488584551, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.981451037607804e-05, 'l1_Layer_2': 7.837972425492424e-05, 'l1_Layer_3': 4.4281087810817074e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 170, 'n_units_Layer_3': 155}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.74 | sMAPE for Validation Set is: 18.61% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 8.70 | sMAPE for Test Set is: 46.64% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:20:58,074]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:21:02,499]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:21:11,392]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:21:20,652]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:21:23,210]\u001b[0m Trial 877 finished with value: 5.837462116319902 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007482807134935497, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.022304763460020836, 'dropout_rate_Layer_2': 0.2846027611161075, 'dropout_rate_Layer_3': 0.07498374962459882, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011681557629046213, 'l1_Layer_2': 6.459242667996571e-05, 'l1_Layer_3': 0.0009813531825865135, 'n_units_Layer_1': 75, 'n_units_Layer_2': 295, 'n_units_Layer_3': 270}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.84 | sMAPE for Validation Set is: 19.09% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.68 | sMAPE for Test Set is: 52.46% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:21:31,778]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:21:37,633]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:21:37,911]\u001b[0m Trial 887 finished with value: 5.828769007858923 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008725883987757312, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.020327535138481137, 'dropout_rate_Layer_2': 0.296264504003964, 'dropout_rate_Layer_3': 0.06249921067232342, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.979957542837923e-05, 'l1_Layer_2': 3.965974893204856e-05, 'l1_Layer_3': 2.709692851930849e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 300, 'n_units_Layer_3': 105}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.83 | sMAPE for Validation Set is: 18.80% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 12.63 | sMAPE for Test Set is: 56.26% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:21:46,389]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:21:48,052]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:21:55,982]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:21:56,849]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:22:02,584]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:22:08,461]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:22:13,366]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:22:17,927]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:22:26,594]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:22:35,749]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:22:40,831]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:22:48,277]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:22:51,483]\u001b[0m Trial 901 finished with value: 5.701729053913353 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005492626157161887, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05819651125337781, 'dropout_rate_Layer_2': 0.12165969066843561, 'dropout_rate_Layer_3': 0.1261704729951379, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.3564195865841866e-05, 'l1_Layer_2': 7.060012187303834e-05, 'l1_Layer_3': 2.246434685308408e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 175, 'n_units_Layer_3': 145}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.70 | sMAPE for Validation Set is: 18.66% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 8.48 | sMAPE for Test Set is: 46.25% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:22:57,501]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:22:59,914]\u001b[0m Trial 889 finished with value: 5.6829480743354095 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005824681739492593, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.043683500597887455, 'dropout_rate_Layer_2': 0.10661981386655354, 'dropout_rate_Layer_3': 0.09293329539839212, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.425400552174513e-05, 'l1_Layer_2': 6.668483438864138e-05, 'l1_Layer_3': 3.782676553398777e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 170, 'n_units_Layer_3': 155}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.68 | sMAPE for Validation Set is: 18.49% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 8.91 | sMAPE for Test Set is: 46.60% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:23:04,008]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:23:06,258]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:23:08,684]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:23:16,409]\u001b[0m Trial 895 finished with value: 5.644388616632469 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006156210473467215, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04612911893955545, 'dropout_rate_Layer_2': 0.11745297749186276, 'dropout_rate_Layer_3': 0.09138510099699458, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.899371393282681e-05, 'l1_Layer_2': 6.0843544663107354e-05, 'l1_Layer_3': 3.961197711693969e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 165, 'n_units_Layer_3': 170}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.64 | sMAPE for Validation Set is: 18.31% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 8.79 | sMAPE for Test Set is: 46.27% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:23:17,970]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:23:23,665]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:23:27,832]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:23:33,008]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:23:42,084]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:23:56,186]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:24:03,923]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:24:13,567]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:24:19,454]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:24:26,778]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:24:29,405]\u001b[0m Trial 921 finished with value: 5.748670278280085 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006790937360214576, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36415270948727874, 'dropout_rate_Layer_2': 0.026585443455195777, 'dropout_rate_Layer_3': 0.26569683476436196, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002693347682999535, 'l1_Layer_2': 0.00010179934239833368, 'l1_Layer_3': 5.9131053379838574e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 210, 'n_units_Layer_3': 185}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.75 | sMAPE for Validation Set is: 18.82% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.41 | sMAPE for Test Set is: 51.49% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:24:33,418]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:24:35,435]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:24:43,712]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:24:51,241]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:24:57,780]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:24:59,936]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:25:07,913]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:25:08,912]\u001b[0m Trial 916 finished with value: 5.615817509026613 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005499699711309993, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05549599604847692, 'dropout_rate_Layer_2': 0.11235189410508992, 'dropout_rate_Layer_3': 0.09544472391796593, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.3321189682885758e-05, 'l1_Layer_2': 4.955105115466394e-05, 'l1_Layer_3': 5.2868949444331006e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 170, 'n_units_Layer_3': 170}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.62 | sMAPE for Validation Set is: 18.40% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 8.78 | sMAPE for Test Set is: 46.36% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:25:10,529]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:25:18,196]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:25:21,631]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:25:21,829]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:25:28,264]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:25:32,482]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:25:37,126]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:25:42,091]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:25:46,084]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:25:50,148]\u001b[0m Trial 930 finished with value: 5.7805872995897545 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005039522918909684, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05832017886911395, 'dropout_rate_Layer_2': 0.11925761549575989, 'dropout_rate_Layer_3': 0.09250395413705917, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.1764865805982114e-05, 'l1_Layer_2': 7.602114908130361e-05, 'l1_Layer_3': 9.079420316123101e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 110, 'n_units_Layer_3': 170}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.78 | sMAPE for Validation Set is: 18.78% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 8.97 | sMAPE for Test Set is: 47.29% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:25:54,910]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:26:03,741]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:26:24,935]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:26:36,263]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:26:54,375]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:27:23,082]\u001b[0m Trial 948 finished with value: 5.8032225841380916 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005432011291500098, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.026654514695517252, 'dropout_rate_Layer_2': 0.3018350232602747, 'dropout_rate_Layer_3': 0.05618571576965413, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013160035915140415, 'l1_Layer_2': 6.104741457003246e-05, 'l1_Layer_3': 2.0857492436651044e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 300, 'n_units_Layer_3': 265}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.80 | sMAPE for Validation Set is: 18.77% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.90 | sMAPE for Test Set is: 53.04% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:27:50,434]\u001b[0m Trial 947 finished with value: 5.579462367888728 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005613147794692998, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0563964286303955, 'dropout_rate_Layer_2': 0.11921924465089687, 'dropout_rate_Layer_3': 0.10574145319153716, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.8173997437409884e-05, 'l1_Layer_2': 5.1212622096781786e-05, 'l1_Layer_3': 9.419027941928405e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 110, 'n_units_Layer_3': 170}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.58 | sMAPE for Validation Set is: 18.27% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 8.76 | sMAPE for Test Set is: 46.36% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:27:50,943]\u001b[0m Trial 939 finished with value: 5.627950277336261 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005575885048888363, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06927490439402487, 'dropout_rate_Layer_2': 0.09782314391921959, 'dropout_rate_Layer_3': 0.11543788579124255, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5608743868200493e-05, 'l1_Layer_2': 7.797380480177491e-05, 'l1_Layer_3': 7.127469169635203e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 170, 'n_units_Layer_3': 170}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.63 | sMAPE for Validation Set is: 18.55% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 8.54 | sMAPE for Test Set is: 46.03% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:28:47,943]\u001b[0m Trial 951 finished with value: 5.771834845795908 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005433105468693387, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05383653805209093, 'dropout_rate_Layer_2': 0.3107354671310509, 'dropout_rate_Layer_3': 0.0428504992899144, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001970001787740579, 'l1_Layer_2': 7.814882415942598e-05, 'l1_Layer_3': 1.7321832244487974e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 290, 'n_units_Layer_3': 265}. Best is trial 486 with value: 5.553213424918622.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.77 | sMAPE for Validation Set is: 18.79% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.80 | sMAPE for Test Set is: 52.89% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:29:01,628]\u001b[0m Trial 950 finished with value: 5.532818834851436 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005722411291166087, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06074319948305987, 'dropout_rate_Layer_2': 0.11915899302996531, 'dropout_rate_Layer_3': 0.11532968409102176, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.03553204929235e-05, 'l1_Layer_2': 5.9226110957953165e-05, 'l1_Layer_3': 6.99099064302927e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 110, 'n_units_Layer_3': 180}. Best is trial 950 with value: 5.532818834851436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.53 | sMAPE for Validation Set is: 18.26% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 8.78 | sMAPE for Test Set is: 46.60% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:29:30,050]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:29:41,195]\u001b[0m Trial 953 finished with value: 5.492525091859021 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005983323945816456, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07139558170244736, 'dropout_rate_Layer_2': 0.0980913031327137, 'dropout_rate_Layer_3': 0.11803658980502903, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2821087305343307e-05, 'l1_Layer_2': 5.3520938427641316e-05, 'l1_Layer_3': 6.464168495328439e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 120, 'n_units_Layer_3': 180}. Best is trial 953 with value: 5.492525091859021.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.49 | sMAPE for Validation Set is: 17.91% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 11.17 | sMAPE for Test Set is: 52.73% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:29:48,282]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:29:50,796]\u001b[0m Trial 952 finished with value: 5.534520463912542 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005516141098679113, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07269267666112361, 'dropout_rate_Layer_2': 0.09847812224927839, 'dropout_rate_Layer_3': 0.11771187875465877, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4845714784008782e-05, 'l1_Layer_2': 4.684370570029984e-05, 'l1_Layer_3': 6.574937538851714e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 95, 'n_units_Layer_3': 170}. Best is trial 953 with value: 5.492525091859021.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.53 | sMAPE for Validation Set is: 18.07% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.36 | sMAPE for Test Set is: 50.94% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:30:04,453]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:30:49,970]\u001b[0m Trial 955 finished with value: 5.6458850207128455 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005761019834527278, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06653199631214744, 'dropout_rate_Layer_2': 0.0938113831660408, 'dropout_rate_Layer_3': 0.11684804921477054, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.213230479715177e-05, 'l1_Layer_2': 5.671945384826681e-05, 'l1_Layer_3': 6.74475585119292e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 115, 'n_units_Layer_3': 180}. Best is trial 953 with value: 5.492525091859021.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.65 | sMAPE for Validation Set is: 18.67% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 8.51 | sMAPE for Test Set is: 45.96% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:30:55,421]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:31:07,683]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:31:15,582]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:31:20,873]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:31:28,359]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:31:30,444]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:31:37,329]\u001b[0m Trial 959 finished with value: 5.538870100629978 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005492857522219319, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0746864984488597, 'dropout_rate_Layer_2': 0.08498701907073196, 'dropout_rate_Layer_3': 0.11759097058086639, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2160693966448814e-05, 'l1_Layer_2': 3.562519850000948e-05, 'l1_Layer_3': 7.200654259385415e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 115, 'n_units_Layer_3': 180}. Best is trial 953 with value: 5.492525091859021.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.54 | sMAPE for Validation Set is: 17.94% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 11.00 | sMAPE for Test Set is: 52.83% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:31:58,930]\u001b[0m Trial 960 finished with value: 5.545355918330091 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005013627110529004, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07928004055606197, 'dropout_rate_Layer_2': 0.08753406549404377, 'dropout_rate_Layer_3': 0.11635498703010577, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2173991017881412e-05, 'l1_Layer_2': 3.685364948131452e-05, 'l1_Layer_3': 6.488617058136949e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 115, 'n_units_Layer_3': 180}. Best is trial 953 with value: 5.492525091859021.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.55 | sMAPE for Validation Set is: 18.07% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.73 | sMAPE for Test Set is: 52.43% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:32:37,128]\u001b[0m Trial 966 finished with value: 5.6224921129005 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005311315927748713, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06524911489845267, 'dropout_rate_Layer_2': 0.09520885729690397, 'dropout_rate_Layer_3': 0.11179956390950505, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.240039919328752e-05, 'l1_Layer_2': 3.510165260722314e-05, 'l1_Layer_3': 6.63045709174312e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 110, 'n_units_Layer_3': 180}. Best is trial 953 with value: 5.492525091859021.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.62 | sMAPE for Validation Set is: 18.18% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.55 | sMAPE for Test Set is: 52.09% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:32:40,863]\u001b[0m Trial 967 finished with value: 5.826989550609802 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006202292529814893, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06771803814458656, 'dropout_rate_Layer_2': 0.28871220442372514, 'dropout_rate_Layer_3': 0.04509614824520131, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00020174431880507862, 'l1_Layer_2': 6.062270012682299e-05, 'l1_Layer_3': 1.666401210199473e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 290, 'n_units_Layer_3': 265}. Best is trial 953 with value: 5.492525091859021.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.83 | sMAPE for Validation Set is: 18.88% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 11.02 | sMAPE for Test Set is: 53.01% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:32:46,154]\u001b[0m Trial 968 finished with value: 5.607299297379271 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005015353442958542, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07559868324451825, 'dropout_rate_Layer_2': 0.08216678571145619, 'dropout_rate_Layer_3': 0.10862292233218994, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1610299561335484e-05, 'l1_Layer_2': 3.347546988686247e-05, 'l1_Layer_3': 5.286964815590093e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 115, 'n_units_Layer_3': 180}. Best is trial 953 with value: 5.492525091859021.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.61 | sMAPE for Validation Set is: 18.13% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.51 | sMAPE for Test Set is: 51.50% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:33:07,718]\u001b[0m Trial 969 finished with value: 5.642598423946517 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005163212689832449, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07887140471001669, 'dropout_rate_Layer_2': 0.0895275674963028, 'dropout_rate_Layer_3': 0.10963149047658444, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.320257975923858e-05, 'l1_Layer_2': 3.250470601463186e-05, 'l1_Layer_3': 6.326385044409462e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 115, 'n_units_Layer_3': 180}. Best is trial 953 with value: 5.492525091859021.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.64 | sMAPE for Validation Set is: 18.21% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.64 | sMAPE for Test Set is: 51.85% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:33:23,163]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:33:38,761]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:33:45,606]\u001b[0m Trial 970 finished with value: 5.877248201014811 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006143903692499937, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07009125129763732, 'dropout_rate_Layer_2': 0.3049079205931783, 'dropout_rate_Layer_3': 0.04638573225131452, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00020430092931371429, 'l1_Layer_2': 6.070916953040958e-05, 'l1_Layer_3': 2.332195474521078e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 290, 'n_units_Layer_3': 265}. Best is trial 953 with value: 5.492525091859021.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.88 | sMAPE for Validation Set is: 19.18% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.95 | sMAPE for Test Set is: 53.44% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:33:55,090]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:34:24,162]\u001b[0m Trial 971 finished with value: 5.541268127158117 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005309248365584484, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0856103837707656, 'dropout_rate_Layer_2': 0.08416608243791755, 'dropout_rate_Layer_3': 0.12182514338435169, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2012142211959756e-05, 'l1_Layer_2': 2.994083411837606e-05, 'l1_Layer_3': 6.166605481387129e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 110, 'n_units_Layer_3': 180}. Best is trial 953 with value: 5.492525091859021.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.54 | sMAPE for Validation Set is: 18.02% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 11.45 | sMAPE for Test Set is: 53.09% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:34:36,078]\u001b[0m Trial 972 finished with value: 5.5100979778804655 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005466147947735855, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07392294485846766, 'dropout_rate_Layer_2': 0.079186922128791, 'dropout_rate_Layer_3': 0.1213061039315491, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4257911026416345e-05, 'l1_Layer_2': 3.409973896480674e-05, 'l1_Layer_3': 5.897212988734507e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 115, 'n_units_Layer_3': 180}. Best is trial 953 with value: 5.492525091859021.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.51 | sMAPE for Validation Set is: 17.94% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 10.55 | sMAPE for Test Set is: 51.71% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:34:43,344]\u001b[0m Trial 976 finished with value: 5.652120629026307 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005047399235724855, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08121370464091474, 'dropout_rate_Layer_2': 0.0824559945438185, 'dropout_rate_Layer_3': 0.11950396502212089, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2976754220491248e-05, 'l1_Layer_2': 2.7929442775459607e-05, 'l1_Layer_3': 6.059720826785438e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 115, 'n_units_Layer_3': 180}. Best is trial 953 with value: 5.492525091859021.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.65 | sMAPE for Validation Set is: 18.22% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.52 | sMAPE for Test Set is: 51.68% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:35:05,302]\u001b[0m Trial 977 finished with value: 5.7860159637528215 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006772184247308845, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0488574845360884, 'dropout_rate_Layer_2': 0.2900687289925611, 'dropout_rate_Layer_3': 0.05505091527589456, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00023620946790479542, 'l1_Layer_2': 4.854946570582563e-05, 'l1_Layer_3': 1.6966672747115255e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 295, 'n_units_Layer_3': 255}. Best is trial 953 with value: 5.492525091859021.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.79 | sMAPE for Validation Set is: 18.78% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.08 | sMAPE for Test Set is: 53.45% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:35:17,715]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:35:25,829]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:35:41,177]\u001b[0m Trial 978 finished with value: 5.578775260557509 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005070470185721713, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08138991271547229, 'dropout_rate_Layer_2': 0.07406987424452936, 'dropout_rate_Layer_3': 0.11008592482348642, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3743954761639114e-05, 'l1_Layer_2': 2.932454601799132e-05, 'l1_Layer_3': 6.323683295198659e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 110, 'n_units_Layer_3': 180}. Best is trial 953 with value: 5.492525091859021.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.58 | sMAPE for Validation Set is: 18.07% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 11.62 | sMAPE for Test Set is: 54.50% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:35:57,776]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:36:24,375]\u001b[0m Trial 980 finished with value: 5.578123241033704 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005467253095740815, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07371094683522506, 'dropout_rate_Layer_2': 0.07520424704344045, 'dropout_rate_Layer_3': 0.10880878590536666, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.298777414175998e-05, 'l1_Layer_2': 3.327445056183773e-05, 'l1_Layer_3': 5.600055622362611e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 125, 'n_units_Layer_3': 180}. Best is trial 953 with value: 5.492525091859021.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.58 | sMAPE for Validation Set is: 18.03% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 11.27 | sMAPE for Test Set is: 52.90% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:36:32,035]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:36:38,237]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:36:38,888]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:36:47,550]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:36:51,865]\u001b[0m Trial 981 finished with value: 5.544782539644527 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005055086397932262, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07867663210017974, 'dropout_rate_Layer_2': 0.07395338673684726, 'dropout_rate_Layer_3': 0.11024844823451257, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3749161123787855e-05, 'l1_Layer_2': 3.147333091893745e-05, 'l1_Layer_3': 5.730957138234649e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 120, 'n_units_Layer_3': 185}. Best is trial 953 with value: 5.492525091859021.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.54 | sMAPE for Validation Set is: 18.10% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 11.55 | sMAPE for Test Set is: 53.66% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:36:55,639]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:37:25,618]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:37:34,939]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:37:50,373]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:37:58,237]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:38:03,332]\u001b[0m Trial 992 finished with value: 5.802914662722991 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006796302210911161, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03466694759477876, 'dropout_rate_Layer_2': 0.2553207212308466, 'dropout_rate_Layer_3': 0.054246200994337454, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014752429987865, 'l1_Layer_2': 7.666618598571873e-05, 'l1_Layer_3': 1.669255388395608e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 275, 'n_units_Layer_3': 255}. Best is trial 953 with value: 5.492525091859021.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.80 | sMAPE for Validation Set is: 18.87% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 11.19 | sMAPE for Test Set is: 53.85% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:38:18,700]\u001b[0m Trial 988 finished with value: 5.484665592725716 and parameters: {'n_hidden': 3, 'learning_rate': 0.000501961979141468, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0836753327374852, 'dropout_rate_Layer_2': 0.08362657014787339, 'dropout_rate_Layer_3': 0.12593020741463734, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.5827402776055407e-05, 'l1_Layer_2': 2.23699930761421e-05, 'l1_Layer_3': 5.649299534902991e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 125, 'n_units_Layer_3': 175}. Best is trial 988 with value: 5.484665592725716.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:38:18,722]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.48 | sMAPE for Validation Set is: 17.88% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 10.41 | sMAPE for Test Set is: 50.64% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:38:22,140]\u001b[0m Trial 993 finished with value: 5.662282991874513 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006122790647312916, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.088709895716646, 'dropout_rate_Layer_2': 0.08658955642582879, 'dropout_rate_Layer_3': 0.11420568605614491, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2090385631187513e-05, 'l1_Layer_2': 2.809275600572742e-05, 'l1_Layer_3': 7.586569540939557e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 125, 'n_units_Layer_3': 190}. Best is trial 988 with value: 5.484665592725716.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.66 | sMAPE for Validation Set is: 18.30% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 11.21 | sMAPE for Test Set is: 53.73% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:39:32,634]\u001b[0m Trial 999 finished with value: 5.5494150688388215 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005039951045053944, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09026310185314165, 'dropout_rate_Layer_2': 0.07861581531439116, 'dropout_rate_Layer_3': 0.13310003072979015, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.008247202644397e-05, 'l1_Layer_2': 2.1053429532259322e-05, 'l1_Layer_3': 5.781088864500493e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 130, 'n_units_Layer_3': 195}. Best is trial 988 with value: 5.484665592725716.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.55 | sMAPE for Validation Set is: 18.03% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.95 | sMAPE for Test Set is: 52.96% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:39:48,450]\u001b[0m Trial 1000 finished with value: 5.7804610594677674 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005660844106279723, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02900007626296149, 'dropout_rate_Layer_2': 0.23851668221102298, 'dropout_rate_Layer_3': 0.05644379883417369, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002353200352658524, 'l1_Layer_2': 7.476128840893727e-05, 'l1_Layer_3': 1.3698131601690345e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 300, 'n_units_Layer_3': 230}. Best is trial 988 with value: 5.484665592725716.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.78 | sMAPE for Validation Set is: 18.81% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.47 | sMAPE for Test Set is: 51.82% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:39:49,216]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:40:06,105]\u001b[0m Trial 998 finished with value: 5.577628824223436 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005068853348414376, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08816260074922484, 'dropout_rate_Layer_2': 0.08117932823057533, 'dropout_rate_Layer_3': 0.1357529268352618, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0045799856218364e-05, 'l1_Layer_2': 2.150878241142909e-05, 'l1_Layer_3': 5.264912161469431e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 120, 'n_units_Layer_3': 195}. Best is trial 988 with value: 5.484665592725716.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.58 | sMAPE for Validation Set is: 18.19% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 9.97 | sMAPE for Test Set is: 49.60% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:40:08,423]\u001b[0m Trial 996 finished with value: 5.577497191076866 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005694963470332206, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.055322887173106454, 'dropout_rate_Layer_2': 0.26556892389735554, 'dropout_rate_Layer_3': 0.05307130335422696, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002262465384270807, 'l1_Layer_2': 0.0013408283659260456, 'l1_Layer_3': 1.3894819956090895e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 285, 'n_units_Layer_3': 175}. Best is trial 988 with value: 5.484665592725716.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.58 | sMAPE for Validation Set is: 18.18% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.50 | sMAPE for Test Set is: 51.66% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:40:17,865]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:40:32,751]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:40:49,128]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:41:35,491]\u001b[0m Trial 1006 finished with value: 5.570666518594854 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005049799044308085, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08700536161866607, 'dropout_rate_Layer_2': 0.07524556612099358, 'dropout_rate_Layer_3': 0.13370511572173632, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0929358095070772e-05, 'l1_Layer_2': 1.9333986815754592e-05, 'l1_Layer_3': 5.330535195920535e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 130, 'n_units_Layer_3': 185}. Best is trial 988 with value: 5.484665592725716.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.57 | sMAPE for Validation Set is: 18.10% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 9.90 | sMAPE for Test Set is: 50.68% | rMAE for Test Set is: 0.76\n",
      "MAE for Validation Set is: 5.54 | sMAPE for Validation Set is: 18.02% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.31 | sMAPE for Test Set is: 50.93% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:41:36,901]\u001b[0m Trial 1004 finished with value: 5.541472843368599 and parameters: {'n_hidden': 3, 'learning_rate': 0.000503677748248262, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0880271765732542, 'dropout_rate_Layer_2': 0.07572882276126142, 'dropout_rate_Layer_3': 0.1360284084874815, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0329582014583803e-05, 'l1_Layer_2': 2.441395870194316e-05, 'l1_Layer_3': 5.600787513777605e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 120, 'n_units_Layer_3': 195}. Best is trial 988 with value: 5.484665592725716.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:41:43,615]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:41:50,779]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:41:51,371]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:41:58,059]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:43:06,197]\u001b[0m Trial 1008 finished with value: 5.523060884883479 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005076808475169193, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08543867720644902, 'dropout_rate_Layer_2': 0.0709173035607875, 'dropout_rate_Layer_3': 0.13251500931875615, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0157091367764963e-05, 'l1_Layer_2': 2.1381709481606966e-05, 'l1_Layer_3': 8.098701790416219e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 130, 'n_units_Layer_3': 195}. Best is trial 988 with value: 5.484665592725716.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.52 | sMAPE for Validation Set is: 18.07% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 11.16 | sMAPE for Test Set is: 52.53% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:43:42,937]\u001b[0m Trial 1014 finished with value: 5.603849950261844 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005811962877380316, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04940932230655866, 'dropout_rate_Layer_2': 0.2592314263099929, 'dropout_rate_Layer_3': 0.052130190289755816, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00020004615853058737, 'l1_Layer_2': 0.0011313407462773485, 'l1_Layer_3': 1.4530440021087925e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 275, 'n_units_Layer_3': 245}. Best is trial 988 with value: 5.484665592725716.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.60 | sMAPE for Validation Set is: 18.20% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.53 | sMAPE for Test Set is: 51.77% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:43:46,277]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:43:52,315]\u001b[0m Trial 1015 finished with value: 5.79323762801592 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005915284843394322, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32202265612227704, 'dropout_rate_Layer_2': 0.010345913275258151, 'dropout_rate_Layer_3': 0.2772281649728847, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015520932376232496, 'l1_Layer_2': 0.00010009909751409373, 'l1_Layer_3': 8.763899956156957e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 280, 'n_units_Layer_3': 205}. Best is trial 988 with value: 5.484665592725716.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.79 | sMAPE for Validation Set is: 18.88% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.10 | sMAPE for Test Set is: 53.16% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:44:04,814]\u001b[0m Trial 1010 finished with value: 5.530001237133388 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005064922199910128, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09120975636174858, 'dropout_rate_Layer_2': 0.038069968894101594, 'dropout_rate_Layer_3': 0.13604591017775314, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0106503325977457e-05, 'l1_Layer_2': 2.0071775492479014e-05, 'l1_Layer_3': 6.0826686928159046e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 125, 'n_units_Layer_3': 195}. Best is trial 988 with value: 5.484665592725716.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.53 | sMAPE for Validation Set is: 18.08% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 10.71 | sMAPE for Test Set is: 52.01% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:44:09,719]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:44:17,615]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:44:29,199]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:44:33,358]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:44:43,187]\u001b[0m Trial 1016 finished with value: 5.686408344749188 and parameters: {'n_hidden': 3, 'learning_rate': 0.000598597351819921, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.092883422316567, 'dropout_rate_Layer_2': 0.07410154387954142, 'dropout_rate_Layer_3': 0.12673592852923665, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.5190313015514426e-05, 'l1_Layer_2': 2.4724861026623493e-05, 'l1_Layer_3': 6.214311214464439e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 130, 'n_units_Layer_3': 195}. Best is trial 988 with value: 5.484665592725716.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.69 | sMAPE for Validation Set is: 18.28% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.48 | sMAPE for Test Set is: 54.69% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:44:48,451]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:46:15,135]\u001b[0m Trial 1022 finished with value: 5.537665938077498 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005003993278578433, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09261842137531918, 'dropout_rate_Layer_2': 0.039572923201678566, 'dropout_rate_Layer_3': 0.13028545904420638, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4184599245183292e-05, 'l1_Layer_2': 2.0006008207024136e-05, 'l1_Layer_3': 4.982512656003394e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 130, 'n_units_Layer_3': 200}. Best is trial 988 with value: 5.484665592725716.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.54 | sMAPE for Validation Set is: 18.07% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.28 | sMAPE for Test Set is: 50.50% | rMAE for Test Set is: 0.79\n",
      "MAE for Validation Set is: 5.59 | sMAPE for Validation Set is: 18.19% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.69 | sMAPE for Test Set is: 52.68% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:46:16,644]\u001b[0m Trial 1025 finished with value: 5.586747823375064 and parameters: {'n_hidden': 3, 'learning_rate': 0.000555552846309475, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07849928777305039, 'dropout_rate_Layer_2': 0.0639290212995215, 'dropout_rate_Layer_3': 0.12142053661930824, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2907330677679378e-05, 'l1_Layer_2': 2.1693580969349567e-05, 'l1_Layer_3': 8.511596823626933e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 135, 'n_units_Layer_3': 190}. Best is trial 988 with value: 5.484665592725716.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:46:24,646]\u001b[0m Trial 1023 finished with value: 5.547118161375074 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005586020540077377, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.049022437855289806, 'dropout_rate_Layer_2': 0.24375730513045044, 'dropout_rate_Layer_3': 0.06417584129790205, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002700923219321168, 'l1_Layer_2': 0.002496054978745247, 'l1_Layer_3': 1.4117450508460161e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 195, 'n_units_Layer_3': 245}. Best is trial 988 with value: 5.484665592725716.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.55 | sMAPE for Validation Set is: 18.10% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.31 | sMAPE for Test Set is: 51.15% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:46:33,047]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:46:58,131]\u001b[0m Trial 1027 finished with value: 5.77306506849867 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006578280670777327, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2652193407649418, 'dropout_rate_Layer_2': 0.025783143599349856, 'dropout_rate_Layer_3': 0.21431251414844454, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00018749378271205858, 'l1_Layer_2': 8.29334576780701e-05, 'l1_Layer_3': 2.0112765244196294e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 275, 'n_units_Layer_3': 130}. Best is trial 988 with value: 5.484665592725716.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.77 | sMAPE for Validation Set is: 18.80% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.14 | sMAPE for Test Set is: 53.35% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:47:05,750]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:47:09,077]\u001b[0m Trial 1019 finished with value: 5.537955737376041 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005573103599560634, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06095147032423817, 'dropout_rate_Layer_2': 0.24877975300208666, 'dropout_rate_Layer_3': 0.06282657727562539, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003135985130826937, 'l1_Layer_2': 0.0013633915119030337, 'l1_Layer_3': 1.412749801906986e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 280, 'n_units_Layer_3': 175}. Best is trial 988 with value: 5.484665592725716.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.54 | sMAPE for Validation Set is: 18.07% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.25 | sMAPE for Test Set is: 51.01% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:47:21,169]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:47:28,001]\u001b[0m Trial 1029 finished with value: 5.777531166472081 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006567323085658786, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31924014500907877, 'dropout_rate_Layer_2': 0.02417751884455853, 'dropout_rate_Layer_3': 0.2877173808655039, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016918005669360375, 'l1_Layer_2': 7.848714697178718e-05, 'l1_Layer_3': 5.6942525922983967e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 275, 'n_units_Layer_3': 160}. Best is trial 988 with value: 5.484665592725716.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.78 | sMAPE for Validation Set is: 18.96% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.43 | sMAPE for Test Set is: 51.44% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:47:35,263]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:47:48,765]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:47:51,119]\u001b[0m Trial 1033 finished with value: 5.877737322988291 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006337276739131366, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26029906653143775, 'dropout_rate_Layer_2': 0.028076032383134934, 'dropout_rate_Layer_3': 0.21698911666567883, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016722304560499678, 'l1_Layer_2': 0.00012016211146095996, 'l1_Layer_3': 5.825130692323638e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 270, 'n_units_Layer_3': 205}. Best is trial 988 with value: 5.484665592725716.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.88 | sMAPE for Validation Set is: 19.14% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.29 | sMAPE for Test Set is: 51.14% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:48:00,447]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:48:11,609]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:48:42,509]\u001b[0m Trial 1038 finished with value: 5.904298112343587 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007731915408969681, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24849000010409278, 'dropout_rate_Layer_2': 0.024256108143855582, 'dropout_rate_Layer_3': 0.29192301979527857, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.952865416442372e-05, 'l1_Layer_2': 4.718583678902388e-05, 'l1_Layer_3': 1.5819764411094097e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 275, 'n_units_Layer_3': 130}. Best is trial 988 with value: 5.484665592725716.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.90 | sMAPE for Validation Set is: 19.07% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.25 | sMAPE for Test Set is: 50.65% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:48:57,805]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:49:16,847]\u001b[0m Trial 1036 finished with value: 5.5490080741249725 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005036565974412883, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06991999373985791, 'dropout_rate_Layer_2': 0.060380916298075946, 'dropout_rate_Layer_3': 0.1359348642626329, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3484667464325735e-05, 'l1_Layer_2': 2.7017966765822903e-05, 'l1_Layer_3': 6.011650950245607e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 135, 'n_units_Layer_3': 195}. Best is trial 988 with value: 5.484665592725716.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.55 | sMAPE for Validation Set is: 18.04% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 11.37 | sMAPE for Test Set is: 53.08% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:49:31,729]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:49:38,072]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:49:38,747]\u001b[0m Trial 1035 finished with value: 5.555325111668883 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005451567136054317, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05636394136658211, 'dropout_rate_Layer_2': 0.22996278595679767, 'dropout_rate_Layer_3': 0.07959684900863469, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00026951629171766134, 'l1_Layer_2': 0.0016169055998396557, 'l1_Layer_3': 1.0262629989605262e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 275, 'n_units_Layer_3': 250}. Best is trial 988 with value: 5.484665592725716.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.56 | sMAPE for Validation Set is: 18.14% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.65 | sMAPE for Test Set is: 52.64% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:49:52,063]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:49:57,842]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:50:00,435]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:50:02,335]\u001b[0m Trial 1039 finished with value: 5.658910982092735 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005336624454697885, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.058078293245957785, 'dropout_rate_Layer_2': 0.246383264314067, 'dropout_rate_Layer_3': 0.07296350821389734, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003276498233129274, 'l1_Layer_2': 0.0011247379982957319, 'l1_Layer_3': 1.0318865511542e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 200, 'n_units_Layer_3': 170}. Best is trial 988 with value: 5.484665592725716.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.66 | sMAPE for Validation Set is: 18.42% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.47 | sMAPE for Test Set is: 51.59% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:50:55,672]\u001b[0m Trial 1041 finished with value: 5.58072418092613 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005457575136871643, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.059189129034638896, 'dropout_rate_Layer_2': 0.2269984247866347, 'dropout_rate_Layer_3': 0.06976836255998695, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00034626776298540596, 'l1_Layer_2': 0.0012311585656203541, 'l1_Layer_3': 1.3069524873205652e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 275, 'n_units_Layer_3': 175}. Best is trial 988 with value: 5.484665592725716.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.58 | sMAPE for Validation Set is: 18.19% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.38 | sMAPE for Test Set is: 51.07% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:51:12,181]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:51:18,045]\u001b[0m Trial 1048 finished with value: 5.581287142347329 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005075415495844926, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08454405942457678, 'dropout_rate_Layer_2': 0.08425686198351075, 'dropout_rate_Layer_3': 0.1186880792702748, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.7638061060732957e-05, 'l1_Layer_2': 1.2710307232618934e-05, 'l1_Layer_3': 7.456669359159017e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 135, 'n_units_Layer_3': 195}. Best is trial 988 with value: 5.484665592725716.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.58 | sMAPE for Validation Set is: 18.17% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.52 | sMAPE for Test Set is: 52.51% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:51:20,697]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:51:49,189]\u001b[0m Trial 1047 finished with value: 5.520216705225741 and parameters: {'n_hidden': 3, 'learning_rate': 0.000556718883752231, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08759639757447113, 'dropout_rate_Layer_2': 0.031314571205900546, 'dropout_rate_Layer_3': 0.11812576744642733, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.7592929610429274e-05, 'l1_Layer_2': 1.3115944257603552e-05, 'l1_Layer_3': 7.257134572148882e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 135, 'n_units_Layer_3': 195}. Best is trial 988 with value: 5.484665592725716.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.52 | sMAPE for Validation Set is: 18.09% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 10.04 | sMAPE for Test Set is: 50.05% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:51:58,471]\u001b[0m Trial 1049 finished with value: 5.472224370857468 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005545804761842332, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08733352920279325, 'dropout_rate_Layer_2': 0.023914301039997872, 'dropout_rate_Layer_3': 0.11844877356145586, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.8042239885086266e-05, 'l1_Layer_2': 1.2443419652574856e-05, 'l1_Layer_3': 6.845340824775916e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 135, 'n_units_Layer_3': 195}. Best is trial 1049 with value: 5.472224370857468.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.47 | sMAPE for Validation Set is: 17.87% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 10.91 | sMAPE for Test Set is: 52.71% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:52:01,875]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:52:30,208]\u001b[0m Trial 1054 finished with value: 5.706023100600812 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005045044749771017, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3258598401192326, 'dropout_rate_Layer_2': 0.01435080722198592, 'dropout_rate_Layer_3': 0.09416184568146269, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00021374755188471916, 'l1_Layer_2': 0.00010554944427597349, 'l1_Layer_3': 7.161260589232187e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 275, 'n_units_Layer_3': 160}. Best is trial 1049 with value: 5.472224370857468.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.71 | sMAPE for Validation Set is: 18.68% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.76 | sMAPE for Test Set is: 52.32% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:52:43,058]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:52:59,213]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:53:13,308]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:53:38,321]\u001b[0m Trial 1052 finished with value: 5.553099912236578 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005382418060928507, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0627337012018805, 'dropout_rate_Layer_2': 0.2230907050169845, 'dropout_rate_Layer_3': 0.0682825543550039, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004475658476744381, 'l1_Layer_2': 0.0014593483118041893, 'l1_Layer_3': 1.1442527166996721e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 270, 'n_units_Layer_3': 180}. Best is trial 1049 with value: 5.472224370857468.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.55 | sMAPE for Validation Set is: 18.05% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.58 | sMAPE for Test Set is: 51.90% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:53:45,491]\u001b[0m Trial 1055 finished with value: 5.541070917151188 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005110942046296469, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08812146001825523, 'dropout_rate_Layer_2': 0.03182265943640122, 'dropout_rate_Layer_3': 0.11666141586413228, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.8937302765826345e-05, 'l1_Layer_2': 1.5310769960362694e-05, 'l1_Layer_3': 7.150931160261961e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 140, 'n_units_Layer_3': 195}. Best is trial 1049 with value: 5.472224370857468.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.54 | sMAPE for Validation Set is: 18.09% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.74 | sMAPE for Test Set is: 51.47% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:53:50,743]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:53:57,688]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:54:15,028]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:54:20,092]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:54:28,548]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:55:32,601]\u001b[0m Trial 1059 finished with value: 5.545256066275779 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005024014582993451, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.053059739909812685, 'dropout_rate_Layer_2': 0.22629644676281405, 'dropout_rate_Layer_3': 0.0685195376976426, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00025948221533102553, 'l1_Layer_2': 0.0018323417560216083, 'l1_Layer_3': 1.19465650164032e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 275, 'n_units_Layer_3': 170}. Best is trial 1049 with value: 5.472224370857468.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.55 | sMAPE for Validation Set is: 18.16% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.53 | sMAPE for Test Set is: 51.53% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:55:40,444]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:55:48,955]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:55:53,794]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:55:56,485]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:56:01,960]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.53 | sMAPE for Validation Set is: 17.95% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.83 | sMAPE for Test Set is: 53.34% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:56:04,443]\u001b[0m Trial 1067 finished with value: 5.533186419566806 and parameters: {'n_hidden': 3, 'learning_rate': 0.000502405904464755, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07010100212207801, 'dropout_rate_Layer_2': 0.023837610475773267, 'dropout_rate_Layer_3': 0.13085404496663383, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2692759623520029e-05, 'l1_Layer_2': 1.031053864621626e-05, 'l1_Layer_3': 6.82802341127971e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 120, 'n_units_Layer_3': 185}. Best is trial 1049 with value: 5.472224370857468.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:56:09,095]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:56:10,599]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:56:18,889]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:56:25,618]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:56:25,906]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:56:34,873]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:56:35,171]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:56:42,356]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:56:52,516]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:56:54,185]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:57:09,784]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:57:17,716]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:57:34,417]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:57:46,720]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:58:27,941]\u001b[0m Trial 1082 finished with value: 5.503663216020004 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005577637150446472, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07931801988085926, 'dropout_rate_Layer_2': 0.02638038733693602, 'dropout_rate_Layer_3': 0.12205918498192882, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2055920413596148e-05, 'l1_Layer_2': 1.4350487157693476e-05, 'l1_Layer_3': 5.80329740362373e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 130, 'n_units_Layer_3': 195}. Best is trial 1049 with value: 5.472224370857468.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.50 | sMAPE for Validation Set is: 18.02% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 10.89 | sMAPE for Test Set is: 52.10% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:58:43,139]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:59:12,923]\u001b[0m Trial 1080 finished with value: 5.524217828952705 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005043204682378859, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.056810201448186576, 'dropout_rate_Layer_2': 0.21126471492412335, 'dropout_rate_Layer_3': 0.07348929555955978, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00026017426600338117, 'l1_Layer_2': 0.0020020045796642415, 'l1_Layer_3': 1.022618144383932e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 280, 'n_units_Layer_3': 240}. Best is trial 1049 with value: 5.472224370857468.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.52 | sMAPE for Validation Set is: 17.98% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 10.33 | sMAPE for Test Set is: 51.57% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:59:20,580]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:59:35,091]\u001b[0m Trial 1088 finished with value: 5.636599552088332 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006043842636770805, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07617942245261455, 'dropout_rate_Layer_2': 0.22431769864447842, 'dropout_rate_Layer_3': 0.07515940385258744, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00023642197021877352, 'l1_Layer_2': 0.0011081522753472724, 'l1_Layer_3': 1.0002182632574643e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 280, 'n_units_Layer_3': 235}. Best is trial 1049 with value: 5.472224370857468.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.64 | sMAPE for Validation Set is: 18.44% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 9.97 | sMAPE for Test Set is: 50.56% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 02:59:37,309]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:59:41,386]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 02:59:49,785]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:00:28,202]\u001b[0m Trial 1090 finished with value: 5.662262764260021 and parameters: {'n_hidden': 3, 'learning_rate': 0.000606994391940235, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07505752216146402, 'dropout_rate_Layer_2': 0.21111240292645786, 'dropout_rate_Layer_3': 0.07649629638163635, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00024303851157079286, 'l1_Layer_2': 0.0008774085205993332, 'l1_Layer_3': 1.0177143540001695e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 280, 'n_units_Layer_3': 240}. Best is trial 1049 with value: 5.472224370857468.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.66 | sMAPE for Validation Set is: 18.49% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.60 | sMAPE for Test Set is: 52.29% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:00:31,280]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:00:36,003]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:00:38,328]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:00:45,470]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:00:49,263]\u001b[0m Trial 1086 finished with value: 5.6555556633868695 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005958293045111026, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07560269030078909, 'dropout_rate_Layer_2': 0.22222409323837747, 'dropout_rate_Layer_3': 0.07555976175341104, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00024695358891165924, 'l1_Layer_2': 0.0009847566446770854, 'l1_Layer_3': 1.017863089464898e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 280, 'n_units_Layer_3': 240}. Best is trial 1049 with value: 5.472224370857468.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.66 | sMAPE for Validation Set is: 18.58% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.46 | sMAPE for Test Set is: 51.91% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:00:52,720]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:00:59,491]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:01:01,120]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:01:09,334]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:01:20,897]\u001b[0m Trial 1094 finished with value: 5.5283163406288525 and parameters: {'n_hidden': 3, 'learning_rate': 0.000630569853708832, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06457157075858037, 'dropout_rate_Layer_2': 0.05812097162848451, 'dropout_rate_Layer_3': 0.12636910346205552, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.232995867657397e-05, 'l1_Layer_2': 1.2468042052394902e-05, 'l1_Layer_3': 4.401552330487602e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 135, 'n_units_Layer_3': 190}. Best is trial 1049 with value: 5.472224370857468.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.53 | sMAPE for Validation Set is: 18.05% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 10.20 | sMAPE for Test Set is: 50.43% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:01:36,260]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:01:51,117]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:02:32,815]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:02:37,792]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:02:50,128]\u001b[0m Trial 1105 finished with value: 5.539903835123352 and parameters: {'n_hidden': 3, 'learning_rate': 0.000559459737894252, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07499019365179996, 'dropout_rate_Layer_2': 0.07940308021103744, 'dropout_rate_Layer_3': 0.12860000070088737, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2023449214086383e-05, 'l1_Layer_2': 1.586056832217566e-05, 'l1_Layer_3': 4.577845761521973e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 135, 'n_units_Layer_3': 195}. Best is trial 1049 with value: 5.472224370857468.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.54 | sMAPE for Validation Set is: 18.05% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.25 | sMAPE for Test Set is: 50.39% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:02:52,356]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:02:56,686]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:02:58,961]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:02:59,586]\u001b[0m Trial 1106 finished with value: 5.683086913238441 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006175558303930419, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05788195092664898, 'dropout_rate_Layer_2': 0.22901447682844311, 'dropout_rate_Layer_3': 0.08638833602478531, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004009432705405274, 'l1_Layer_2': 0.0006354426648758181, 'l1_Layer_3': 1.268435208862279e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 280, 'n_units_Layer_3': 235}. Best is trial 1049 with value: 5.472224370857468.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.68 | sMAPE for Validation Set is: 18.50% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 11.03 | sMAPE for Test Set is: 53.57% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:03:06,139]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:03:09,572]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:03:21,913]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:04:16,165]\u001b[0m Trial 1118 finished with value: 5.70976766671354 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005712210374023019, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32343901598918995, 'dropout_rate_Layer_2': 0.014296299970781766, 'dropout_rate_Layer_3': 0.26927517279844837, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00027343025349081446, 'l1_Layer_2': 0.00010559369095125779, 'l1_Layer_3': 8.401099023472202e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 280, 'n_units_Layer_3': 180}. Best is trial 1049 with value: 5.472224370857468.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.71 | sMAPE for Validation Set is: 18.65% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.76 | sMAPE for Test Set is: 52.06% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:04:24,309]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.50 | sMAPE for Validation Set is: 18.05% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 10.55 | sMAPE for Test Set is: 51.58% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:04:27,200]\u001b[0m Trial 1116 finished with value: 5.496890820070713 and parameters: {'n_hidden': 3, 'learning_rate': 0.000646801442259077, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07270788650760224, 'dropout_rate_Layer_2': 0.08784117838779552, 'dropout_rate_Layer_3': 0.12791515643288434, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.0113499864275984e-05, 'l1_Layer_2': 1.187560095852727e-05, 'l1_Layer_3': 6.435604347488594e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 130, 'n_units_Layer_3': 190}. Best is trial 1049 with value: 5.472224370857468.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:04:28,206]\u001b[0m Trial 1111 finished with value: 5.568325628114508 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005542746526499326, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07565954406841884, 'dropout_rate_Layer_2': 0.08748227357615608, 'dropout_rate_Layer_3': 0.14358958093866328, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0049813583116885e-05, 'l1_Layer_2': 1.4636946769572897e-05, 'l1_Layer_3': 4.4436509146636926e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 130, 'n_units_Layer_3': 185}. Best is trial 1049 with value: 5.472224370857468.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.57 | sMAPE for Validation Set is: 18.12% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 11.01 | sMAPE for Test Set is: 52.38% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:04:35,523]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:04:44,030]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:05:07,329]\u001b[0m Trial 1119 finished with value: 5.53548583525977 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005552311357735993, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08228104651072689, 'dropout_rate_Layer_2': 0.05739322944085566, 'dropout_rate_Layer_3': 0.14461386363424655, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2366518379311986e-05, 'l1_Layer_2': 1.171111688241244e-05, 'l1_Layer_3': 8.18194621591863e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 125, 'n_units_Layer_3': 175}. Best is trial 1049 with value: 5.472224370857468.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.54 | sMAPE for Validation Set is: 18.07% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.24 | sMAPE for Test Set is: 50.70% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:05:11,715]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:05:11,894]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:05:20,932]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:05:28,703]\u001b[0m Trial 1125 finished with value: 5.7756113493624985 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005722984421455112, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3237090848507623, 'dropout_rate_Layer_2': 0.005498742997260195, 'dropout_rate_Layer_3': 0.26623480074138517, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00035424143716917953, 'l1_Layer_2': 9.610004064496533e-05, 'l1_Layer_3': 7.697090585650053e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 275, 'n_units_Layer_3': 185}. Best is trial 1049 with value: 5.472224370857468.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.78 | sMAPE for Validation Set is: 18.89% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.62 | sMAPE for Test Set is: 52.07% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:05:31,469]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:05:38,707]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:05:50,223]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:06:13,587]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:06:20,379]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:06:21,146]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:06:29,835]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:06:39,305]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:06:42,402]\u001b[0m Trial 1133 finished with value: 5.722888431309599 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006507956014793679, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2954275380918528, 'dropout_rate_Layer_2': 0.009817569869970752, 'dropout_rate_Layer_3': 0.040972262294658945, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003757383391092038, 'l1_Layer_2': 0.0001231906799552602, 'l1_Layer_3': 6.99493007377297e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 285, 'n_units_Layer_3': 180}. Best is trial 1049 with value: 5.472224370857468.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.72 | sMAPE for Validation Set is: 18.69% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.60 | sMAPE for Test Set is: 51.80% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:06:46,755]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:06:47,329]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:06:54,532]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:07:10,312]\u001b[0m Trial 1129 finished with value: 5.6868985466489805 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005674105654797628, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06019321241264535, 'dropout_rate_Layer_2': 0.19579950978830762, 'dropout_rate_Layer_3': 0.09022471060731223, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00038653838616940176, 'l1_Layer_2': 0.0007427136024709945, 'l1_Layer_3': 1.2267455202522338e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 270, 'n_units_Layer_3': 240}. Best is trial 1049 with value: 5.472224370857468.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.69 | sMAPE for Validation Set is: 18.51% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 11.04 | sMAPE for Test Set is: 53.47% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:07:17,996]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:07:31,805]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:07:34,261]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:07:41,419]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:08:30,391]\u001b[0m Trial 1146 finished with value: 5.646208950810731 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006011358317225927, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07279247290820108, 'dropout_rate_Layer_2': 0.06391021232597935, 'dropout_rate_Layer_3': 0.10480814503411305, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.476698939333845e-05, 'l1_Layer_2': 2.7724935293356748e-05, 'l1_Layer_3': 7.469881093633147e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 135, 'n_units_Layer_3': 190}. Best is trial 1049 with value: 5.472224370857468.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.65 | sMAPE for Validation Set is: 18.11% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 11.56 | sMAPE for Test Set is: 54.46% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:08:34,436]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:08:40,453]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:08:47,942]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:08:52,669]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:09:16,047]\u001b[0m Trial 1142 finished with value: 5.575980099029632 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005031936430334995, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06358743081595786, 'dropout_rate_Layer_2': 0.220958470197286, 'dropout_rate_Layer_3': 0.0662559874513024, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00023720351484604472, 'l1_Layer_2': 0.0016747476488945005, 'l1_Layer_3': 1.2053400337567767e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 265, 'n_units_Layer_3': 160}. Best is trial 1049 with value: 5.472224370857468.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.58 | sMAPE for Validation Set is: 18.12% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.56 | sMAPE for Test Set is: 52.20% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:09:29,970]\u001b[0m Trial 1147 finished with value: 5.677428268560589 and parameters: {'n_hidden': 3, 'learning_rate': 0.000501235385843162, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06272425895678632, 'dropout_rate_Layer_2': 0.19698300897607698, 'dropout_rate_Layer_3': 0.08611587896367462, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000357536408265611, 'l1_Layer_2': 0.0005740362277662139, 'l1_Layer_3': 1.2475462266209086e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 265, 'n_units_Layer_3': 240}. Best is trial 1049 with value: 5.472224370857468.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.68 | sMAPE for Validation Set is: 18.53% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.74 | sMAPE for Test Set is: 52.93% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:09:37,650]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:10:11,046]\u001b[0m Trial 1153 finished with value: 5.588555067429801 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006062142957160524, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06095019831080147, 'dropout_rate_Layer_2': 0.03179912352634004, 'dropout_rate_Layer_3': 0.13099038079784744, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1771464335687196e-05, 'l1_Layer_2': 4.0837962963980544e-05, 'l1_Layer_3': 9.26073428938028e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 140, 'n_units_Layer_3': 205}. Best is trial 1049 with value: 5.472224370857468.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.59 | sMAPE for Validation Set is: 18.15% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.90 | sMAPE for Test Set is: 52.12% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:10:19,449]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:10:24,604]\u001b[0m Trial 1152 finished with value: 5.492484654378514 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005006295984846823, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09077571002479612, 'dropout_rate_Layer_2': 0.03275020801974008, 'dropout_rate_Layer_3': 0.1331259178840258, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.213893957482789e-05, 'l1_Layer_2': 3.99316055602466e-05, 'l1_Layer_3': 9.38598085405222e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 135, 'n_units_Layer_3': 205}. Best is trial 1049 with value: 5.472224370857468.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.49 | sMAPE for Validation Set is: 17.88% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 10.72 | sMAPE for Test Set is: 51.55% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:10:25,525]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:10:37,629]\u001b[0m Trial 1151 finished with value: 5.734429444096276 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006050655548186792, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26133175995034397, 'dropout_rate_Layer_2': 0.22113477208558974, 'dropout_rate_Layer_3': 0.08777026804737434, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002998834972849388, 'l1_Layer_2': 0.0006032963550043253, 'l1_Layer_3': 1.000493225391694e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 270, 'n_units_Layer_3': 240}. Best is trial 1049 with value: 5.472224370857468.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.73 | sMAPE for Validation Set is: 18.58% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.46 | sMAPE for Test Set is: 52.01% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:10:43,887]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:10:44,846]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:10:53,518]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:10:54,391]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:11:02,320]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:11:08,212]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:11:16,483]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:11:23,971]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:11:37,325]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:11:41,518]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:11:47,098]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:12:04,048]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:12:08,663]\u001b[0m Trial 1158 finished with value: 5.446783953078327 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005039366320440881, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08629832400807227, 'dropout_rate_Layer_2': 0.04488149933422133, 'dropout_rate_Layer_3': 0.12553683400126567, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3653985053460544e-05, 'l1_Layer_2': 2.8906023554624946e-05, 'l1_Layer_3': 8.053517368366648e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 135, 'n_units_Layer_3': 195}. Best is trial 1158 with value: 5.446783953078327.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.45 | sMAPE for Validation Set is: 17.75% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 10.79 | sMAPE for Test Set is: 52.66% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:12:13,275]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:12:21,073]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:12:25,587]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:12:29,199]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:12:51,475]\u001b[0m Trial 1155 finished with value: 5.588867116199679 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005040968991163678, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07238722795639252, 'dropout_rate_Layer_2': 0.18675949085271648, 'dropout_rate_Layer_3': 0.08977747162908468, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005240132311669462, 'l1_Layer_2': 0.0017998180064026051, 'l1_Layer_3': 1.2077550845808621e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 265, 'n_units_Layer_3': 245}. Best is trial 1158 with value: 5.446783953078327.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.59 | sMAPE for Validation Set is: 18.26% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.21 | sMAPE for Test Set is: 51.07% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:13:22,105]\u001b[0m Trial 1177 finished with value: 5.850568820721846 and parameters: {'n_hidden': 3, 'learning_rate': 0.000627964977809419, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2795395695473005, 'dropout_rate_Layer_2': 0.25126206538692875, 'dropout_rate_Layer_3': 0.24656281520583262, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00047849513025747766, 'l1_Layer_2': 0.000194721493363471, 'l1_Layer_3': 6.396923605882378e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 295, 'n_units_Layer_3': 180}. Best is trial 1158 with value: 5.446783953078327.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.85 | sMAPE for Validation Set is: 19.15% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.10 | sMAPE for Test Set is: 50.32% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:13:27,384]\u001b[0m Trial 1176 finished with value: 5.842995007653864 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006149789049172426, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27954260162382855, 'dropout_rate_Layer_2': 0.11837879809212926, 'dropout_rate_Layer_3': 0.02499338578464666, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000454223678011457, 'l1_Layer_2': 0.00017118291387472527, 'l1_Layer_3': 6.073443155061029e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 295, 'n_units_Layer_3': 130}. Best is trial 1158 with value: 5.446783953078327.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.84 | sMAPE for Validation Set is: 18.95% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.51 | sMAPE for Test Set is: 51.33% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:13:31,679]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:13:38,362]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:13:43,026]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:13:47,323]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:13:55,646]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:14:03,992]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:14:16,439]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:14:26,963]\u001b[0m Trial 1183 finished with value: 5.759969451636548 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005543964513546763, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2931587581772624, 'dropout_rate_Layer_2': 0.020023180223667107, 'dropout_rate_Layer_3': 0.02426386206641203, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002254655838998347, 'l1_Layer_2': 8.807427966471318e-05, 'l1_Layer_3': 0.00010005694460606476, 'n_units_Layer_1': 185, 'n_units_Layer_2': 275, 'n_units_Layer_3': 190}. Best is trial 1158 with value: 5.446783953078327.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.76 | sMAPE for Validation Set is: 18.81% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.67 | sMAPE for Test Set is: 51.89% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:14:43,398]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:14:59,340]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:15:02,719]\u001b[0m Trial 1179 finished with value: 5.486391038391912 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005017857171141281, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08584665098003666, 'dropout_rate_Layer_2': 0.022516001490956523, 'dropout_rate_Layer_3': 0.12262712563558795, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.1221522731863724e-05, 'l1_Layer_2': 2.7656238972594972e-05, 'l1_Layer_3': 6.49518426605916e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 120, 'n_units_Layer_3': 180}. Best is trial 1158 with value: 5.446783953078327.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.49 | sMAPE for Validation Set is: 17.95% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 10.97 | sMAPE for Test Set is: 52.17% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:15:16,632]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:15:21,919]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:15:27,271]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:15:27,892]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:15:36,861]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:15:53,709]\u001b[0m Trial 1186 finished with value: 5.531055712963227 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005503546675211716, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08509820373180398, 'dropout_rate_Layer_2': 0.00753167600707997, 'dropout_rate_Layer_3': 0.11363314291722036, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.504263572915025e-05, 'l1_Layer_2': 1.2258291983339611e-05, 'l1_Layer_3': 7.674553312780321e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 110, 'n_units_Layer_3': 190}. Best is trial 1158 with value: 5.446783953078327.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.53 | sMAPE for Validation Set is: 18.06% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 11.42 | sMAPE for Test Set is: 53.49% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:16:02,031]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:16:13,850]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:16:33,202]\u001b[0m Trial 1191 finished with value: 5.526182709741761 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006001520925637097, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09315842960003268, 'dropout_rate_Layer_2': 0.027097030872686015, 'dropout_rate_Layer_3': 0.10864749365167672, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.1087279610085912e-05, 'l1_Layer_2': 1.3328290337512202e-05, 'l1_Layer_3': 4.9212063986455405e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 120, 'n_units_Layer_3': 180}. Best is trial 1158 with value: 5.446783953078327.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.53 | sMAPE for Validation Set is: 18.14% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 10.22 | sMAPE for Test Set is: 50.52% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:16:39,923]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:16:45,154]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:16:50,415]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:16:57,206]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:17:07,140]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:17:14,583]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:17:38,043]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:17:40,259]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:17:47,103]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:17:49,609]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:17:54,515]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:18:00,013]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:18:02,589]\u001b[0m Trial 1199 finished with value: 5.517367577859004 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006170592928944145, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08487272122094751, 'dropout_rate_Layer_2': 0.017739019690049013, 'dropout_rate_Layer_3': 0.11143342408686038, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.9970994007621365e-05, 'l1_Layer_2': 1.1535378678246113e-05, 'l1_Layer_3': 9.840545490963145e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 105, 'n_units_Layer_3': 190}. Best is trial 1158 with value: 5.446783953078327.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.52 | sMAPE for Validation Set is: 17.93% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 11.35 | sMAPE for Test Set is: 53.15% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:18:03,503]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:18:07,526]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:18:11,265]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:18:11,674]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:18:15,386]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:18:22,570]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:18:24,390]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:18:27,307]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:18:32,778]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:18:37,299]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:18:39,594]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:18:43,069]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:18:43,565]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:18:50,722]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:18:53,626]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:19:02,050]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:19:04,911]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:19:12,677]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:19:17,073]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:19:21,634]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:19:34,704]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:19:35,847]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:19:37,144]\u001b[0m Trial 1218 finished with value: 5.562378229205557 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006796264550750389, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07595078595627329, 'dropout_rate_Layer_2': 0.03493555237105972, 'dropout_rate_Layer_3': 0.10396955998922201, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.9406448377693095e-05, 'l1_Layer_2': 1.0316338257383206e-05, 'l1_Layer_3': 9.964607033670768e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 105, 'n_units_Layer_3': 175}. Best is trial 1158 with value: 5.446783953078327.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.56 | sMAPE for Validation Set is: 18.08% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.80 | sMAPE for Test Set is: 52.13% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:19:42,906]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:19:51,617]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:19:57,872]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:20:06,215]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:20:14,464]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:20:21,346]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:20:23,914]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:20:36,333]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:20:39,406]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:20:43,606]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:20:48,824]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:20:49,301]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:20:57,149]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:21:08,985]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:21:09,716]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:21:19,290]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:21:26,889]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:21:27,241]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:21:45,731]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:22:05,294]\u001b[0m Trial 1253 finished with value: 5.777864503575075 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005559424424183968, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32778709591799876, 'dropout_rate_Layer_2': 0.01607304918567415, 'dropout_rate_Layer_3': 0.28323473315636966, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023151627189753942, 'l1_Layer_2': 0.00011132522939714675, 'l1_Layer_3': 7.990521881783905e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 275, 'n_units_Layer_3': 180}. Best is trial 1158 with value: 5.446783953078327.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.78 | sMAPE for Validation Set is: 18.82% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.80 | sMAPE for Test Set is: 52.71% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:22:23,258]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:22:30,462]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:22:41,648]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:22:54,126]\u001b[0m Trial 1249 finished with value: 5.444199701341032 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006172447180970972, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09323509307044615, 'dropout_rate_Layer_2': 0.02792332138697165, 'dropout_rate_Layer_3': 0.13138124477430466, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.683766189406281e-05, 'l1_Layer_2': 2.217163097733383e-05, 'l1_Layer_3': 5.680059495831952e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 115, 'n_units_Layer_3': 180}. Best is trial 1249 with value: 5.444199701341032.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.44 | sMAPE for Validation Set is: 17.78% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 11.68 | sMAPE for Test Set is: 53.60% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:23:02,682]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:23:02,696]\u001b[0m Trial 1250 finished with value: 5.513316631935524 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006251871616610186, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06346383925557994, 'dropout_rate_Layer_2': 0.027427781926205052, 'dropout_rate_Layer_3': 0.10088372228721182, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1518283155891294e-05, 'l1_Layer_2': 2.1598136740803375e-05, 'l1_Layer_3': 4.0877313324380196e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 115, 'n_units_Layer_3': 185}. Best is trial 1249 with value: 5.444199701341032.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.51 | sMAPE for Validation Set is: 17.92% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 11.42 | sMAPE for Test Set is: 53.41% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:23:09,878]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:23:13,290]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:23:21,049]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:23:24,037]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:23:26,676]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:23:32,856]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:23:49,405]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:23:55,361]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:24:00,331]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:24:07,413]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:24:24,105]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:24:25,165]\u001b[0m Trial 1258 finished with value: 5.5092386778345555 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005512020516186284, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07526377464687077, 'dropout_rate_Layer_2': 0.027954005453562157, 'dropout_rate_Layer_3': 0.12315469638980299, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0008981397583884e-05, 'l1_Layer_2': 1.4621353281777833e-05, 'l1_Layer_3': 5.074820060052281e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 135, 'n_units_Layer_3': 180}. Best is trial 1249 with value: 5.444199701341032.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.51 | sMAPE for Validation Set is: 18.02% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 10.69 | sMAPE for Test Set is: 51.39% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:24:42,580]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:24:51,764]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:24:57,185]\u001b[0m Trial 1267 finished with value: 5.480648583575139 and parameters: {'n_hidden': 3, 'learning_rate': 0.000647099812566595, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07243799590716701, 'dropout_rate_Layer_2': 0.04044403087795352, 'dropout_rate_Layer_3': 0.14764837239923878, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4607478593667434e-05, 'l1_Layer_2': 1.692829215739444e-05, 'l1_Layer_3': 4.758223593895617e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 120, 'n_units_Layer_3': 190}. Best is trial 1249 with value: 5.444199701341032.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.48 | sMAPE for Validation Set is: 17.82% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 11.19 | sMAPE for Test Set is: 53.40% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:24:57,600]\u001b[0m Trial 1259 finished with value: 5.489331892774868 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005006634781535623, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07197330140074451, 'dropout_rate_Layer_2': 0.05450510841608393, 'dropout_rate_Layer_3': 0.10943827800130018, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0057065919257288e-05, 'l1_Layer_2': 1.5433762334780866e-05, 'l1_Layer_3': 4.8626181470862e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 135, 'n_units_Layer_3': 180}. Best is trial 1249 with value: 5.444199701341032.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.49 | sMAPE for Validation Set is: 18.04% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 10.50 | sMAPE for Test Set is: 51.29% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:25:05,472]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:25:13,134]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:25:14,525]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:25:19,492]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:25:55,880]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:26:11,260]\u001b[0m Trial 1276 finished with value: 5.562635530942646 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005974142097643285, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06550563457676799, 'dropout_rate_Layer_2': 0.038356050137103, 'dropout_rate_Layer_3': 0.12245840893912457, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.930965932583346e-05, 'l1_Layer_2': 2.1991203117537187e-05, 'l1_Layer_3': 5.431700639808251e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 120, 'n_units_Layer_3': 180}. Best is trial 1249 with value: 5.444199701341032.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.56 | sMAPE for Validation Set is: 18.26% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 11.30 | sMAPE for Test Set is: 53.18% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:26:14,115]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:26:19,002]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:26:25,898]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:26:31,094]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:26:31,295]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:26:39,117]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:26:43,894]\u001b[0m Trial 1282 finished with value: 5.612504036871083 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006660081933770787, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06240577672978453, 'dropout_rate_Layer_2': 0.2168487011869891, 'dropout_rate_Layer_3': 0.06472031572322054, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002517021280892557, 'l1_Layer_2': 0.0014778188214378378, 'l1_Layer_3': 1.4675910451412504e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 275, 'n_units_Layer_3': 180}. Best is trial 1249 with value: 5.444199701341032.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.61 | sMAPE for Validation Set is: 18.24% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.85 | sMAPE for Test Set is: 53.01% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:26:49,636]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:26:57,398]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:26:58,124]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:27:05,118]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:27:17,822]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:27:34,558]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:27:41,596]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:27:47,710]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:27:57,574]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:28:04,652]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:28:10,192]\u001b[0m Trial 1289 finished with value: 5.513110201024283 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005902424630931285, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.058768811894828625, 'dropout_rate_Layer_2': 0.04350985515119707, 'dropout_rate_Layer_3': 0.13688440643686833, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2461842087498276e-05, 'l1_Layer_2': 1.2356721768506277e-05, 'l1_Layer_3': 5.870526405064759e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 140, 'n_units_Layer_3': 175}. Best is trial 1249 with value: 5.444199701341032.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.51 | sMAPE for Validation Set is: 17.88% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 10.63 | sMAPE for Test Set is: 52.19% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:28:18,545]\u001b[0m Trial 1295 finished with value: 5.501671397016423 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005496836417331448, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08198961221291856, 'dropout_rate_Layer_2': 0.015994339044483948, 'dropout_rate_Layer_3': 0.11033083471373917, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2621307469348108e-05, 'l1_Layer_2': 1.003567918224216e-05, 'l1_Layer_3': 3.2269304056807685e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 135, 'n_units_Layer_3': 175}. Best is trial 1249 with value: 5.444199701341032.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.50 | sMAPE for Validation Set is: 17.87% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 10.69 | sMAPE for Test Set is: 53.73% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:28:34,361]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:28:46,191]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:28:51,837]\u001b[0m Trial 1293 finished with value: 5.551659366991267 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005001401082637214, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06188370804836118, 'dropout_rate_Layer_2': 0.016965550074582014, 'dropout_rate_Layer_3': 0.10960026068649001, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1942985216882865e-05, 'l1_Layer_2': 1.7945814175224146e-05, 'l1_Layer_3': 3.284888666306277e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 145, 'n_units_Layer_3': 180}. Best is trial 1249 with value: 5.444199701341032.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.55 | sMAPE for Validation Set is: 18.15% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.76 | sMAPE for Test Set is: 51.87% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:29:07,444]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:29:18,076]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:29:26,791]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:29:49,445]\u001b[0m Trial 1305 finished with value: 5.62206888944691 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005007365578685916, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10578587820324285, 'dropout_rate_Layer_2': 0.008013355129720009, 'dropout_rate_Layer_3': 0.1097655356998605, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.0766758528631634e-05, 'l1_Layer_2': 1.3556726473995803e-05, 'l1_Layer_3': 3.5702065487142576e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 135, 'n_units_Layer_3': 190}. Best is trial 1249 with value: 5.444199701341032.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.62 | sMAPE for Validation Set is: 18.30% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.88 | sMAPE for Test Set is: 52.57% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:29:53,191]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:29:53,774]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:30:01,002]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:30:02,462]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:30:09,604]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:30:10,297]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:30:15,504]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:30:23,356]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:30:31,681]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:30:34,546]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:30:41,410]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:30:44,582]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:30:57,311]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:31:00,671]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:31:03,518]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:31:07,572]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:31:08,289]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:31:10,578]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:31:26,410]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:31:29,419]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:31:31,581]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:31:34,686]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:31:39,871]\u001b[0m Trial 1309 finished with value: 5.580794225687254 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005946341278775101, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04087623297034657, 'dropout_rate_Layer_2': 0.20673570031704194, 'dropout_rate_Layer_3': 0.08950019710122036, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006886973038408087, 'l1_Layer_2': 0.0008806797789178346, 'l1_Layer_3': 1.3433875821823572e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 270, 'n_units_Layer_3': 240}. Best is trial 1249 with value: 5.444199701341032.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.58 | sMAPE for Validation Set is: 18.15% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.09 | sMAPE for Test Set is: 50.65% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:31:49,895]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:31:53,249]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:32:07,431]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:32:15,499]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:32:23,684]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:32:32,010]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:32:40,164]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:32:45,656]\u001b[0m Trial 1327 finished with value: 5.521066892963368 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006034287878718053, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09312925090160702, 'dropout_rate_Layer_2': 0.028709507751904704, 'dropout_rate_Layer_3': 0.11150200762280987, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4013705228403381e-05, 'l1_Layer_2': 1.4027230781153344e-05, 'l1_Layer_3': 3.985659225038436e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 130, 'n_units_Layer_3': 180}. Best is trial 1249 with value: 5.444199701341032.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.52 | sMAPE for Validation Set is: 18.09% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 11.24 | sMAPE for Test Set is: 52.96% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:32:50,826]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:32:55,683]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:32:57,778]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:33:05,197]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:33:05,742]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:33:14,803]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:33:23,121]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:33:26,051]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:33:30,609]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:33:31,019]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:33:38,907]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:33:41,367]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:33:42,382]\u001b[0m Trial 1335 finished with value: 5.495667154203538 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006389422860354578, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06161564396932329, 'dropout_rate_Layer_2': 0.04907133713015764, 'dropout_rate_Layer_3': 0.10293516456054795, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.6619382398098227e-05, 'l1_Layer_2': 1.271514280292346e-05, 'l1_Layer_3': 4.868467291438105e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 120, 'n_units_Layer_3': 190}. Best is trial 1249 with value: 5.444199701341032.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.50 | sMAPE for Validation Set is: 18.03% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 10.64 | sMAPE for Test Set is: 51.40% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:33:47,398]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:33:52,873]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:33:54,213]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:34:00,078]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:34:00,234]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:34:11,547]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:34:11,914]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:34:14,251]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:34:20,329]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:34:22,948]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:34:29,775]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:34:30,445]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:34:35,432]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:34:36,529]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:34:44,527]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:34:49,916]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:34:54,928]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:34:59,320]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:35:00,091]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:35:08,356]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:35:10,944]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:35:39,010]\u001b[0m Trial 1367 finished with value: 5.5728906892835255 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006720538526567539, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0942598980057775, 'dropout_rate_Layer_2': 0.026898546140041703, 'dropout_rate_Layer_3': 0.12121413869392986, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.581810412711465e-05, 'l1_Layer_2': 2.0259786686258583e-05, 'l1_Layer_3': 5.498336293674207e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 130, 'n_units_Layer_3': 210}. Best is trial 1249 with value: 5.444199701341032.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.57 | sMAPE for Validation Set is: 18.04% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 11.18 | sMAPE for Test Set is: 55.73% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:35:46,961]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:35:52,369]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:35:56,535]\u001b[0m Trial 1362 finished with value: 5.558556756492517 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006648051736424435, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07655300466493385, 'dropout_rate_Layer_2': 0.030394593471623585, 'dropout_rate_Layer_3': 0.11024893960476106, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3797572640113435e-05, 'l1_Layer_2': 2.24133741965033e-05, 'l1_Layer_3': 4.860725798412465e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 145, 'n_units_Layer_3': 185}. Best is trial 1249 with value: 5.444199701341032.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.56 | sMAPE for Validation Set is: 18.02% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.49 | sMAPE for Test Set is: 50.78% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:36:03,660]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:36:10,110]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:36:12,973]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:36:28,787]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:36:45,147]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:36:50,937]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:37:08,892]\u001b[0m Trial 1375 finished with value: 5.548199713189896 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005630382775347473, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09639369855420937, 'dropout_rate_Layer_2': 0.03722098836257119, 'dropout_rate_Layer_3': 0.10782537853936364, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.503565061906838e-05, 'l1_Layer_2': 1.4043300168698927e-05, 'l1_Layer_3': 5.485961272119477e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 125, 'n_units_Layer_3': 190}. Best is trial 1249 with value: 5.444199701341032.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.55 | sMAPE for Validation Set is: 18.11% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 11.36 | sMAPE for Test Set is: 53.67% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:37:24,881]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:37:30,920]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:37:33,225]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:37:41,759]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:37:45,579]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:37:50,224]\u001b[0m Trial 1381 finished with value: 5.518849883548416 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005561488914479821, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05709072579247126, 'dropout_rate_Layer_2': 0.04317294093870295, 'dropout_rate_Layer_3': 0.12598915187639215, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.873557339025626e-05, 'l1_Layer_2': 1.0087049957580782e-05, 'l1_Layer_3': 3.512544657770696e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 135, 'n_units_Layer_3': 195}. Best is trial 1249 with value: 5.444199701341032.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.52 | sMAPE for Validation Set is: 18.05% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 10.69 | sMAPE for Test Set is: 51.63% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:37:53,628]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:37:59,434]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:38:03,042]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:38:07,387]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:38:12,735]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:38:18,414]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:38:22,238]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:38:27,480]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:38:35,005]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:38:35,332]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:38:40,838]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:38:41,980]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:38:47,874]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:38:55,684]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:38:59,936]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:39:03,075]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:39:11,344]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:39:16,494]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:39:22,678]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:39:27,687]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:39:28,264]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:39:33,143]\u001b[0m Trial 1389 finished with value: 5.6732829685364905 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005447333543188566, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05819284618747087, 'dropout_rate_Layer_2': 0.23178133319460598, 'dropout_rate_Layer_3': 0.08689786164996242, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002028631520115894, 'l1_Layer_2': 0.0008554231405272144, 'l1_Layer_3': 1.3684092734766988e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 285, 'n_units_Layer_3': 240}. Best is trial 1249 with value: 5.444199701341032.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.67 | sMAPE for Validation Set is: 18.38% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.96 | sMAPE for Test Set is: 53.19% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:39:37,340]\u001b[0m Trial 1395 finished with value: 5.5332339544241185 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005008822967779329, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04831824597082442, 'dropout_rate_Layer_2': 0.04973357207583806, 'dropout_rate_Layer_3': 0.15110878290421248, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.385720999974221e-05, 'l1_Layer_2': 1.8592687311870098e-05, 'l1_Layer_3': 2.776440036474329e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 135, 'n_units_Layer_3': 205}. Best is trial 1249 with value: 5.444199701341032.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.53 | sMAPE for Validation Set is: 18.03% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.89 | sMAPE for Test Set is: 52.21% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:39:43,177]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:39:47,615]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:39:52,509]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:39:52,724]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:39:53,935]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:40:05,530]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:40:09,703]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:40:15,228]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:40:17,612]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:40:20,434]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:40:25,339]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:40:28,244]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:40:28,792]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:40:33,545]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:40:40,572]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:40:44,838]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:40:50,665]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:40:54,053]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:40:54,635]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:41:11,816]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:41:23,080]\u001b[0m Trial 1412 finished with value: 5.458490093977466 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005002944607528563, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07847623517512865, 'dropout_rate_Layer_2': 0.05677369751835849, 'dropout_rate_Layer_3': 0.11728008529116771, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.1552814350128875e-05, 'l1_Layer_2': 2.393053401407835e-05, 'l1_Layer_3': 4.3460715561076904e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 125, 'n_units_Layer_3': 175}. Best is trial 1249 with value: 5.444199701341032.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.46 | sMAPE for Validation Set is: 17.77% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 10.65 | sMAPE for Test Set is: 51.23% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:41:30,772]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:41:33,746]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:41:41,839]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:41:54,699]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:41:58,579]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:42:15,296]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:42:39,884]\u001b[0m Trial 1439 finished with value: 5.740540926945179 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006780542094699502, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3262678448095279, 'dropout_rate_Layer_2': 0.0006343843398843949, 'dropout_rate_Layer_3': 0.29529812661354565, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.081753082208571e-05, 'l1_Layer_2': 7.156486341954596e-05, 'l1_Layer_3': 7.145878656592558e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 285, 'n_units_Layer_3': 215}. Best is trial 1249 with value: 5.444199701341032.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.74 | sMAPE for Validation Set is: 18.83% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.91 | sMAPE for Test Set is: 52.67% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:42:45,644]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:42:50,924]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:42:56,021]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:43:01,050]\u001b[0m Trial 1442 finished with value: 5.761761311974091 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006837201288682093, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17175189164260815, 'dropout_rate_Layer_2': 0.022358128618912648, 'dropout_rate_Layer_3': 0.2958239374710754, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013467904102641291, 'l1_Layer_2': 6.926899942048896e-05, 'l1_Layer_3': 4.548929472865535e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 285, 'n_units_Layer_3': 150}. Best is trial 1249 with value: 5.444199701341032.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.76 | sMAPE for Validation Set is: 18.64% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.24 | sMAPE for Test Set is: 50.70% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:43:01,877]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:43:07,003]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:43:12,581]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:43:17,146]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:43:21,669]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:43:26,495]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:43:31,431]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:43:43,685]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:43:59,133]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:44:42,041]\u001b[0m Trial 1443 finished with value: 5.568547979930149 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005479040478914147, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05443684095969174, 'dropout_rate_Layer_2': 0.23334000409168026, 'dropout_rate_Layer_3': 0.065338174684099, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00018929797519396004, 'l1_Layer_2': 0.0023296615772800877, 'l1_Layer_3': 1.616527137769738e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 270, 'n_units_Layer_3': 245}. Best is trial 1249 with value: 5.444199701341032.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.57 | sMAPE for Validation Set is: 18.13% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.48 | sMAPE for Test Set is: 52.06% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:44:46,574]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:44:50,665]\u001b[0m Trial 1452 finished with value: 5.4641101350769885 and parameters: {'n_hidden': 3, 'learning_rate': 0.000551895850004926, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08265291579256467, 'dropout_rate_Layer_2': 0.056846141310044895, 'dropout_rate_Layer_3': 0.12484776785319315, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.2885463439343232e-05, 'l1_Layer_2': 1.1749303429144795e-05, 'l1_Layer_3': 5.213146144515926e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 140, 'n_units_Layer_3': 185}. Best is trial 1249 with value: 5.444199701341032.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.46 | sMAPE for Validation Set is: 17.89% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 10.54 | sMAPE for Test Set is: 50.93% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:45:01,195]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:45:17,034]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:45:25,502]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:45:30,422]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:45:31,208]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:45:35,579]\u001b[0m Trial 1456 finished with value: 5.769975965886587 and parameters: {'n_hidden': 3, 'learning_rate': 0.001041210463446749, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1630834826405331, 'dropout_rate_Layer_2': 0.006416544378551605, 'dropout_rate_Layer_3': 0.3051592826612459, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.5062098494569002e-05, 'l1_Layer_2': 0.00010998274474450758, 'l1_Layer_3': 4.1898240752878006e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 275, 'n_units_Layer_3': 150}. Best is trial 1249 with value: 5.444199701341032.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.77 | sMAPE for Validation Set is: 18.77% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.41 | sMAPE for Test Set is: 50.85% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:45:38,346]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:45:38,930]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:45:39,308]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:45:40,222]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:45:45,919]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:45:52,665]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:46:00,515]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:46:04,009]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:46:06,019]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:46:14,264]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:46:19,566]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:46:20,526]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:46:25,766]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:46:35,082]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:46:39,969]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:46:52,915]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:46:57,506]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:47:09,795]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:47:14,791]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:47:20,134]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:47:28,007]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:47:28,710]\u001b[0m Trial 1468 finished with value: 5.496511733257516 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005899669773379581, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07944375711333052, 'dropout_rate_Layer_2': 0.026597480416121963, 'dropout_rate_Layer_3': 0.10552656229951761, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.7520792451290035e-05, 'l1_Layer_2': 2.393519594583398e-05, 'l1_Layer_3': 5.515112156960395e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 120, 'n_units_Layer_3': 185}. Best is trial 1249 with value: 5.444199701341032.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.50 | sMAPE for Validation Set is: 17.95% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 11.59 | sMAPE for Test Set is: 53.57% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:47:39,496]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:47:43,504]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:47:48,557]\u001b[0m Trial 1473 finished with value: 5.967777951580629 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009524809319628736, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14686036973525782, 'dropout_rate_Layer_2': 0.00534736248533278, 'dropout_rate_Layer_3': 0.3137758990117301, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.5069297045969245e-05, 'l1_Layer_2': 0.00017612070121073877, 'l1_Layer_3': 2.877750794860006e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 260, 'n_units_Layer_3': 155}. Best is trial 1249 with value: 5.444199701341032.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.97 | sMAPE for Validation Set is: 19.05% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.56 | sMAPE for Test Set is: 52.21% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:47:57,195]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:47:57,244]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:48:05,041]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:48:05,411]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:48:13,944]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:48:14,695]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:48:19,253]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:48:24,428]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:48:26,877]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:49:07,288]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:49:07,982]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 03:49:12,547]\u001b[0m Trial 1489 finished with value: 5.567675730651608 and parameters: {'n_hidden': 3, 'learning_rate': 0.000551301492126948, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07536587863591096, 'dropout_rate_Layer_2': 0.04712808070627928, 'dropout_rate_Layer_3': 0.08700435490361248, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.618582365986526e-05, 'l1_Layer_2': 3.5619068825906304e-05, 'l1_Layer_3': 0.00010428899753832267, 'n_units_Layer_1': 105, 'n_units_Layer_2': 150, 'n_units_Layer_3': 195}. Best is trial 1249 with value: 5.444199701341032.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.57 | sMAPE for Validation Set is: 18.09% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.82 | sMAPE for Test Set is: 51.64% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 03:49:26,159]\u001b[0m Trial 1495 finished with value: 5.4989840752506565 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005499141660740576, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07970116082376333, 'dropout_rate_Layer_2': 0.03655268514708109, 'dropout_rate_Layer_3': 0.12022517755696752, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.644861273117101e-05, 'l1_Layer_2': 2.4678736566564926e-05, 'l1_Layer_3': 7.668988876229603e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 125, 'n_units_Layer_3': 185}. Best is trial 1249 with value: 5.444199701341032.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.50 | sMAPE for Validation Set is: 18.01% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 12.08 | sMAPE for Test Set is: 54.86% | rMAE for Test Set is: 0.92\n",
      "for 2020-01-01, MAE is:3.67 & sMAPE is:11.63% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :3.67 & 11.63% & 0.92\n",
      "for 2020-01-02, MAE is:2.47 & sMAPE is:7.94% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :3.07 & 9.79% & 0.68\n",
      "for 2020-01-03, MAE is:5.22 & sMAPE is:35.08% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :3.78 & 18.22% & 0.57\n",
      "for 2020-01-04, MAE is:6.70 & sMAPE is:45.98% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :4.51 & 25.16% & 0.54\n",
      "for 2020-01-05, MAE is:2.60 & sMAPE is:8.47% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :4.13 & 21.82% & 0.58\n",
      "for 2020-01-06, MAE is:7.16 & sMAPE is:20.86% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :4.64 & 21.66% & 0.67\n",
      "for 2020-01-07, MAE is:4.76 & sMAPE is:13.80% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :4.65 & 20.54% & 0.65\n",
      "for 2020-01-08, MAE is:7.44 & sMAPE is:41.77% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :5.00 & 23.19% & 0.68\n",
      "for 2020-01-09, MAE is:4.64 & sMAPE is:14.22% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :4.96 & 22.20% & 0.70\n",
      "for 2020-01-10, MAE is:5.65 & sMAPE is:18.76% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :5.03 & 21.85% & 0.69\n",
      "for 2020-01-11, MAE is:6.85 & sMAPE is:23.79% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :5.20 & 22.03% & 0.68\n",
      "for 2020-01-12, MAE is:1.59 & sMAPE is:7.32% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 20.80% & 0.64\n",
      "for 2020-01-13, MAE is:6.06 & sMAPE is:18.13% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :4.99 & 20.60% & 0.65\n",
      "for 2020-01-14, MAE is:9.74 & sMAPE is:44.98% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :5.33 & 22.34% & 0.67\n",
      "for 2020-01-15, MAE is:10.05 & sMAPE is:47.92% & rMAE is:2.49 ||| daily mean of MAE & sMAPE & rMAE till now are :5.64 & 24.04% & 0.79\n",
      "for 2020-01-16, MAE is:3.71 & sMAPE is:13.91% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 23.41% & 0.76\n",
      "for 2020-01-17, MAE is:3.70 & sMAPE is:12.58% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :5.41 & 22.77% & 0.75\n",
      "for 2020-01-18, MAE is:2.12 & sMAPE is:8.83% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :5.23 & 22.00% & 0.75\n",
      "for 2020-01-19, MAE is:4.45 & sMAPE is:15.36% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :5.19 & 21.65% & 0.76\n",
      "for 2020-01-20, MAE is:11.06 & sMAPE is:36.91% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :5.48 & 22.41% & 0.77\n",
      "for 2020-01-21, MAE is:8.82 & sMAPE is:36.01% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :5.64 & 23.06% & 0.81\n",
      "for 2020-01-22, MAE is:5.85 & sMAPE is:23.44% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :5.65 & 23.08% & 0.82\n",
      "for 2020-01-23, MAE is:6.74 & sMAPE is:26.54% & rMAE is:1.73 ||| daily mean of MAE & sMAPE & rMAE till now are :5.70 & 23.23% & 0.86\n",
      "for 2020-01-24, MAE is:2.91 & sMAPE is:13.99% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :5.58 & 22.84% & 0.84\n",
      "for 2020-01-25, MAE is:5.01 & sMAPE is:21.98% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :5.56 & 22.81% & 0.85\n",
      "for 2020-01-26, MAE is:4.23 & sMAPE is:18.78% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :5.51 & 22.65% & 0.84\n",
      "for 2020-01-27, MAE is:6.08 & sMAPE is:24.05% & rMAE is:2.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.53 & 22.70% & 0.90\n",
      "for 2020-01-28, MAE is:3.80 & sMAPE is:14.24% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :5.47 & 22.40% & 0.89\n",
      "for 2020-01-29, MAE is:10.26 & sMAPE is:41.35% & rMAE is:3.04 ||| daily mean of MAE & sMAPE & rMAE till now are :5.63 & 23.06% & 0.96\n",
      "for 2020-01-30, MAE is:6.39 & sMAPE is:27.38% & rMAE is:4.83 ||| daily mean of MAE & sMAPE & rMAE till now are :5.66 & 23.20% & 1.09\n",
      "for 2020-01-31, MAE is:7.92 & sMAPE is:61.94% & rMAE is:1.67 ||| daily mean of MAE & sMAPE & rMAE till now are :5.73 & 24.45% & 1.11\n",
      "for 2020-02-01, MAE is:11.14 & sMAPE is:114.69% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :5.90 & 27.27% & 1.10\n",
      "for 2020-02-02, MAE is:4.63 & sMAPE is:38.26% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.86 & 27.60% & 1.07\n",
      "for 2020-02-03, MAE is:4.08 & sMAPE is:16.72% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :5.81 & 27.28% & 1.06\n",
      "for 2020-02-04, MAE is:3.27 & sMAPE is:12.48% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :5.74 & 26.86% & 1.05\n",
      "for 2020-02-05, MAE is:13.19 & sMAPE is:50.96% & rMAE is:2.49 ||| daily mean of MAE & sMAPE & rMAE till now are :5.94 & 27.53% & 1.09\n",
      "for 2020-02-06, MAE is:9.01 & sMAPE is:42.53% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :6.03 & 27.93% & 1.09\n",
      "for 2020-02-07, MAE is:5.93 & sMAPE is:20.21% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.02 & 27.73% & 1.07\n",
      "for 2020-02-08, MAE is:5.40 & sMAPE is:30.55% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.01 & 27.80% & 1.06\n",
      "for 2020-02-09, MAE is:14.08 & sMAPE is:113.28% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :6.21 & 29.94% & 1.05\n",
      "for 2020-02-10, MAE is:14.63 & sMAPE is:116.83% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 32.06% & 1.05\n",
      "for 2020-02-11, MAE is:17.64 & sMAPE is:96.06% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 33.58% & 1.05\n",
      "for 2020-02-12, MAE is:9.95 & sMAPE is:72.20% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 34.48% & 1.05\n",
      "for 2020-02-13, MAE is:11.95 & sMAPE is:67.88% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :6.88 & 35.24% & 1.05\n",
      "for 2020-02-14, MAE is:7.43 & sMAPE is:26.19% & rMAE is:2.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 35.04% & 1.08\n",
      "for 2020-02-15, MAE is:8.19 & sMAPE is:59.60% & rMAE is:2.20 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 35.57% & 1.11\n",
      "for 2020-02-16, MAE is:11.13 & sMAPE is:153.60% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :7.01 & 38.08% & 1.12\n",
      "for 2020-02-17, MAE is:4.45 & sMAPE is:73.85% & rMAE is:1.75 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 38.83% & 1.13\n",
      "for 2020-02-18, MAE is:11.90 & sMAPE is:57.91% & rMAE is:2.29 ||| daily mean of MAE & sMAPE & rMAE till now are :7.05 & 39.22% & 1.15\n",
      "for 2020-02-19, MAE is:7.44 & sMAPE is:35.37% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :7.06 & 39.14% & 1.14\n",
      "for 2020-02-20, MAE is:12.45 & sMAPE is:63.53% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :7.17 & 39.62% & 1.13\n",
      "for 2020-02-21, MAE is:4.35 & sMAPE is:39.05% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :7.11 & 39.61% & 1.11\n",
      "for 2020-02-22, MAE is:12.83 & sMAPE is:179.62% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :7.22 & 42.25% & 1.11\n",
      "for 2020-02-23, MAE is:5.69 & sMAPE is:96.00% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :7.19 & 43.25% & 1.11\n",
      "for 2020-02-24, MAE is:15.12 & sMAPE is:81.33% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :7.34 & 43.94% & 1.11\n",
      "for 2020-02-25, MAE is:6.89 & sMAPE is:38.59% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :7.33 & 43.84% & 1.12\n",
      "for 2020-02-26, MAE is:2.74 & sMAPE is:13.01% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :7.25 & 43.30% & 1.12\n",
      "for 2020-02-27, MAE is:9.93 & sMAPE is:28.50% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :7.30 & 43.05% & 1.11\n",
      "for 2020-02-28, MAE is:4.23 & sMAPE is:13.88% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :7.24 & 42.55% & 1.09\n",
      "for 2020-02-29, MAE is:12.68 & sMAPE is:83.89% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :7.33 & 43.24% & 1.09\n",
      "for 2020-03-01, MAE is:10.25 & sMAPE is:144.82% & rMAE is:2.01 ||| daily mean of MAE & sMAPE & rMAE till now are :7.38 & 44.91% & 1.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-03-02, MAE is:10.81 & sMAPE is:38.12% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :7.44 & 44.80% & 1.11\n",
      "for 2020-03-03, MAE is:4.10 & sMAPE is:10.76% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :7.38 & 44.26% & 1.10\n",
      "for 2020-03-04, MAE is:4.60 & sMAPE is:10.48% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :7.34 & 43.73% & 1.09\n",
      "for 2020-03-05, MAE is:3.79 & sMAPE is:10.51% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :7.29 & 43.22% & 1.08\n",
      "for 2020-03-06, MAE is:4.55 & sMAPE is:18.77% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :7.24 & 42.85% & 1.07\n",
      "for 2020-03-07, MAE is:3.89 & sMAPE is:14.73% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :7.19 & 42.43% & 1.06\n",
      "for 2020-03-08, MAE is:10.86 & sMAPE is:63.03% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :7.25 & 42.73% & 1.06\n",
      "for 2020-03-09, MAE is:13.33 & sMAPE is:47.49% & rMAE is:2.14 ||| daily mean of MAE & sMAPE & rMAE till now are :7.34 & 42.80% & 1.08\n",
      "for 2020-03-10, MAE is:22.68 & sMAPE is:98.02% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :7.56 & 43.59% & 1.08\n",
      "for 2020-03-11, MAE is:10.91 & sMAPE is:96.00% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :7.60 & 44.33% & 1.07\n",
      "for 2020-03-12, MAE is:14.31 & sMAPE is:121.03% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :7.70 & 45.39% & 1.06\n",
      "for 2020-03-13, MAE is:8.94 & sMAPE is:69.65% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :7.71 & 45.72% & 1.05\n",
      "for 2020-03-14, MAE is:12.62 & sMAPE is:60.60% & rMAE is:2.39 ||| daily mean of MAE & sMAPE & rMAE till now are :7.78 & 45.93% & 1.07\n",
      "for 2020-03-15, MAE is:11.71 & sMAPE is:120.81% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :7.83 & 46.92% & 1.08\n",
      "for 2020-03-16, MAE is:6.17 & sMAPE is:51.42% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :7.81 & 46.98% & 1.07\n",
      "for 2020-03-17, MAE is:14.60 & sMAPE is:70.40% & rMAE is:2.04 ||| daily mean of MAE & sMAPE & rMAE till now are :7.90 & 47.29% & 1.08\n",
      "for 2020-03-18, MAE is:9.65 & sMAPE is:56.46% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :7.92 & 47.41% & 1.09\n",
      "for 2020-03-19, MAE is:10.05 & sMAPE is:58.53% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :7.95 & 47.55% & 1.08\n",
      "for 2020-03-20, MAE is:10.72 & sMAPE is:74.91% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :7.98 & 47.89% & 1.08\n",
      "for 2020-03-21, MAE is:4.35 & sMAPE is:39.27% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :7.94 & 47.78% & 1.07\n",
      "for 2020-03-22, MAE is:4.36 & sMAPE is:49.91% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :7.89 & 47.81% & 1.07\n",
      "for 2020-03-23, MAE is:8.19 & sMAPE is:55.48% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :7.90 & 47.90% & 1.07\n",
      "for 2020-03-24, MAE is:9.98 & sMAPE is:74.61% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :7.92 & 48.22% & 1.07\n",
      "for 2020-03-25, MAE is:4.79 & sMAPE is:57.41% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :7.88 & 48.33% & 1.07\n",
      "for 2020-03-26, MAE is:5.11 & sMAPE is:20.90% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :7.85 & 48.01% & 1.06\n",
      "for 2020-03-27, MAE is:3.98 & sMAPE is:20.22% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :7.81 & 47.69% & 1.06\n",
      "for 2020-03-28, MAE is:12.70 & sMAPE is:96.45% & rMAE is:1.96 ||| daily mean of MAE & sMAPE & rMAE till now are :7.86 & 48.24% & 1.07\n",
      "for 2020-03-29, MAE is:6.97 & sMAPE is:102.90% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :7.85 & 48.86% & 1.07\n",
      "for 2020-03-30, MAE is:7.45 & sMAPE is:59.40% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :7.85 & 48.97% & 1.07\n",
      "for 2020-03-31, MAE is:13.96 & sMAPE is:74.38% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :7.92 & 49.25% & 1.07\n",
      "for 2020-04-01, MAE is:8.08 & sMAPE is:72.45% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :7.92 & 49.50% & 1.06\n",
      "for 2020-04-02, MAE is:10.08 & sMAPE is:92.92% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :7.94 & 49.97% & 1.06\n",
      "for 2020-04-03, MAE is:8.88 & sMAPE is:92.34% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :7.95 & 50.42% & 1.05\n",
      "for 2020-04-04, MAE is:10.02 & sMAPE is:70.84% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :7.97 & 50.64% & 1.05\n",
      "for 2020-04-05, MAE is:11.72 & sMAPE is:106.27% & rMAE is:1.95 ||| daily mean of MAE & sMAPE & rMAE till now are :8.01 & 51.22% & 1.06\n",
      "for 2020-04-06, MAE is:7.10 & sMAPE is:71.72% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :8.00 & 51.43% & 1.06\n",
      "for 2020-04-07, MAE is:7.32 & sMAPE is:35.17% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :8.00 & 51.26% & 1.05\n",
      "for 2020-04-08, MAE is:6.95 & sMAPE is:28.22% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :7.99 & 51.03% & 1.05\n",
      "for 2020-04-09, MAE is:10.12 & sMAPE is:67.22% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :8.01 & 51.19% & 1.05\n",
      "for 2020-04-10, MAE is:9.77 & sMAPE is:50.54% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :8.02 & 51.18% & 1.04\n",
      "for 2020-04-11, MAE is:8.87 & sMAPE is:54.71% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :8.03 & 51.22% & 1.05\n",
      "for 2020-04-12, MAE is:8.08 & sMAPE is:92.76% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :8.03 & 51.62% & 1.05\n",
      "for 2020-04-13, MAE is:16.62 & sMAPE is:163.81% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :8.12 & 52.70% & 1.05\n",
      "for 2020-04-14, MAE is:14.73 & sMAPE is:122.31% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :8.18 & 53.36% & 1.05\n",
      "for 2020-04-15, MAE is:9.71 & sMAPE is:90.26% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :8.19 & 53.71% & 1.04\n",
      "for 2020-04-16, MAE is:7.28 & sMAPE is:59.84% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :8.18 & 53.77% & 1.04\n",
      "for 2020-04-17, MAE is:7.50 & sMAPE is:29.12% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :8.18 & 53.54% & 1.04\n",
      "for 2020-04-18, MAE is:4.57 & sMAPE is:22.20% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :8.14 & 53.25% & 1.04\n",
      "for 2020-04-19, MAE is:7.71 & sMAPE is:65.52% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :8.14 & 53.37% & 1.04\n",
      "for 2020-04-20, MAE is:7.05 & sMAPE is:79.88% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :8.13 & 53.60% & 1.04\n",
      "for 2020-04-21, MAE is:5.08 & sMAPE is:67.10% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :8.10 & 53.72% & 1.03\n",
      "for 2020-04-22, MAE is:6.56 & sMAPE is:62.83% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :8.09 & 53.81% & 1.03\n",
      "for 2020-04-23, MAE is:10.04 & sMAPE is:48.13% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :8.11 & 53.76% & 1.03\n",
      "for 2020-04-24, MAE is:14.24 & sMAPE is:70.10% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :8.16 & 53.90% & 1.03\n",
      "for 2020-04-25, MAE is:4.82 & sMAPE is:34.17% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :8.13 & 53.73% & 1.03\n",
      "for 2020-04-26, MAE is:5.09 & sMAPE is:30.42% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :8.11 & 53.53% & 1.03\n",
      "for 2020-04-27, MAE is:4.68 & sMAPE is:17.64% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :8.08 & 53.22% & 1.02\n",
      "for 2020-04-28, MAE is:4.39 & sMAPE is:15.83% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :8.05 & 52.91% & 1.01\n",
      "for 2020-04-29, MAE is:4.54 & sMAPE is:21.22% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :8.02 & 52.65% & 1.01\n",
      "for 2020-04-30, MAE is:7.87 & sMAPE is:47.31% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :8.02 & 52.60% & 1.01\n",
      "for 2020-05-01, MAE is:8.99 & sMAPE is:82.75% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :8.02 & 52.85% & 1.01\n",
      "for 2020-05-02, MAE is:4.79 & sMAPE is:37.77% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :8.00 & 52.73% & 1.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-05-03, MAE is:6.28 & sMAPE is:49.30% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :7.98 & 52.70% & 1.00\n",
      "for 2020-05-04, MAE is:5.95 & sMAPE is:36.13% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :7.97 & 52.57% & 1.00\n",
      "for 2020-05-05, MAE is:3.90 & sMAPE is:18.46% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :7.93 & 52.30% & 1.00\n",
      "for 2020-05-06, MAE is:10.72 & sMAPE is:67.10% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :7.96 & 52.41% & 1.00\n",
      "for 2020-05-07, MAE is:4.26 & sMAPE is:30.17% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :7.93 & 52.24% & 1.00\n",
      "for 2020-05-08, MAE is:8.45 & sMAPE is:50.28% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :7.93 & 52.22% & 1.00\n",
      "for 2020-05-09, MAE is:3.52 & sMAPE is:16.55% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :7.90 & 51.95% & 1.00\n",
      "for 2020-05-10, MAE is:11.55 & sMAPE is:73.24% & rMAE is:1.86 ||| daily mean of MAE & sMAPE & rMAE till now are :7.93 & 52.11% & 1.00\n",
      "for 2020-05-11, MAE is:4.55 & sMAPE is:54.23% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :7.90 & 52.13% & 1.00\n",
      "for 2020-05-12, MAE is:11.89 & sMAPE is:64.21% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :7.93 & 52.22% & 1.00\n",
      "for 2020-05-13, MAE is:18.85 & sMAPE is:98.48% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :8.01 & 52.56% & 1.01\n",
      "for 2020-05-14, MAE is:9.31 & sMAPE is:41.71% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :8.02 & 52.48% & 1.01\n",
      "for 2020-05-15, MAE is:4.39 & sMAPE is:29.16% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :7.99 & 52.31% & 1.00\n",
      "for 2020-05-16, MAE is:4.86 & sMAPE is:38.44% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :7.97 & 52.21% & 1.00\n",
      "for 2020-05-17, MAE is:7.47 & sMAPE is:71.60% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :7.97 & 52.35% & 1.00\n",
      "for 2020-05-18, MAE is:3.67 & sMAPE is:21.77% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :7.94 & 52.13% & 1.00\n",
      "for 2020-05-19, MAE is:4.40 & sMAPE is:20.71% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :7.91 & 51.91% & 0.99\n",
      "for 2020-05-20, MAE is:6.35 & sMAPE is:19.77% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :7.90 & 51.68% & 0.99\n",
      "for 2020-05-21, MAE is:6.59 & sMAPE is:30.76% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :7.89 & 51.53% & 0.99\n",
      "for 2020-05-22, MAE is:8.37 & sMAPE is:51.88% & rMAE is:1.97 ||| daily mean of MAE & sMAPE & rMAE till now are :7.89 & 51.53% & 1.00\n",
      "for 2020-05-23, MAE is:7.00 & sMAPE is:88.90% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :7.89 & 51.79% & 1.00\n",
      "for 2020-05-24, MAE is:11.31 & sMAPE is:165.93% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :7.91 & 52.58% & 1.00\n",
      "for 2020-05-25, MAE is:7.39 & sMAPE is:49.14% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :7.91 & 52.56% & 1.01\n",
      "for 2020-05-26, MAE is:7.56 & sMAPE is:27.37% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :7.91 & 52.39% & 1.01\n",
      "for 2020-05-27, MAE is:10.91 & sMAPE is:43.46% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :7.93 & 52.32% & 1.01\n",
      "for 2020-05-28, MAE is:3.26 & sMAPE is:18.38% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :7.90 & 52.10% & 1.01\n",
      "for 2020-05-29, MAE is:3.51 & sMAPE is:16.08% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :7.87 & 51.86% & 1.00\n",
      "for 2020-05-30, MAE is:6.33 & sMAPE is:47.38% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :7.86 & 51.83% & 1.00\n",
      "for 2020-05-31, MAE is:8.67 & sMAPE is:98.86% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :7.86 & 52.14% & 1.00\n",
      "for 2020-06-01, MAE is:5.54 & sMAPE is:61.94% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :7.85 & 52.20% & 1.00\n",
      "for 2020-06-02, MAE is:9.63 & sMAPE is:30.68% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :7.86 & 52.06% & 1.01\n",
      "for 2020-06-03, MAE is:7.52 & sMAPE is:23.45% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :7.86 & 51.88% & 1.01\n",
      "for 2020-06-04, MAE is:3.68 & sMAPE is:13.97% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :7.83 & 51.63% & 1.00\n",
      "for 2020-06-05, MAE is:6.15 & sMAPE is:34.38% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :7.82 & 51.52% & 1.00\n",
      "for 2020-06-06, MAE is:13.32 & sMAPE is:123.03% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :7.85 & 51.98% & 1.01\n",
      "for 2020-06-07, MAE is:3.37 & sMAPE is:21.94% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :7.82 & 51.79% & 1.00\n",
      "for 2020-06-08, MAE is:4.81 & sMAPE is:16.46% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :7.81 & 51.57% & 1.00\n",
      "for 2020-06-09, MAE is:5.01 & sMAPE is:13.67% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :7.79 & 51.33% & 0.99\n",
      "for 2020-06-10, MAE is:2.12 & sMAPE is:6.87% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :7.75 & 51.06% & 0.99\n",
      "for 2020-06-11, MAE is:5.16 & sMAPE is:19.27% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :7.74 & 50.86% & 0.99\n",
      "for 2020-06-12, MAE is:5.72 & sMAPE is:25.60% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :7.72 & 50.71% & 0.99\n",
      "for 2020-06-13, MAE is:2.53 & sMAPE is:14.15% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :7.69 & 50.49% & 0.99\n",
      "for 2020-06-14, MAE is:11.54 & sMAPE is:100.08% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :7.72 & 50.78% & 0.99\n",
      "for 2020-06-15, MAE is:4.35 & sMAPE is:16.76% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :7.70 & 50.58% & 0.99\n",
      "for 2020-06-16, MAE is:2.30 & sMAPE is:6.63% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :7.66 & 50.32% & 0.99\n",
      "for 2020-06-17, MAE is:8.39 & sMAPE is:20.63% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :7.67 & 50.14% & 0.99\n",
      "for 2020-06-18, MAE is:4.96 & sMAPE is:13.70% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :7.65 & 49.93% & 0.99\n",
      "for 2020-06-19, MAE is:1.83 & sMAPE is:6.25% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :7.62 & 49.67% & 0.98\n",
      "for 2020-06-20, MAE is:2.82 & sMAPE is:11.99% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :7.59 & 49.45% & 0.98\n",
      "for 2020-06-21, MAE is:6.79 & sMAPE is:35.60% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :7.59 & 49.37% & 0.98\n",
      "for 2020-06-22, MAE is:2.50 & sMAPE is:8.92% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :7.56 & 49.14% & 0.98\n",
      "for 2020-06-23, MAE is:3.80 & sMAPE is:11.07% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :7.54 & 48.92% & 0.98\n",
      "for 2020-06-24, MAE is:5.72 & sMAPE is:14.27% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :7.53 & 48.73% & 0.98\n",
      "for 2020-06-25, MAE is:7.21 & sMAPE is:17.18% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :7.52 & 48.55% & 0.98\n",
      "for 2020-06-26, MAE is:3.01 & sMAPE is:8.90% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :7.50 & 48.33% & 0.98\n",
      "for 2020-06-27, MAE is:5.26 & sMAPE is:18.86% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :7.49 & 48.16% & 0.98\n",
      "for 2020-06-28, MAE is:8.64 & sMAPE is:56.03% & rMAE is:2.36 ||| daily mean of MAE & sMAPE & rMAE till now are :7.49 & 48.21% & 0.99\n",
      "for 2020-06-29, MAE is:4.55 & sMAPE is:18.33% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :7.48 & 48.04% & 0.99\n",
      "for 2020-06-30, MAE is:16.14 & sMAPE is:100.17% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :7.52 & 48.33% & 0.99\n",
      "for 2020-07-01, MAE is:11.21 & sMAPE is:65.20% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :7.54 & 48.42% & 0.99\n",
      "for 2020-07-02, MAE is:7.25 & sMAPE is:20.39% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :7.54 & 48.27% & 0.99\n",
      "for 2020-07-03, MAE is:5.92 & sMAPE is:16.98% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :7.53 & 48.10% & 0.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-07-04, MAE is:18.13 & sMAPE is:128.27% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :7.59 & 48.53% & 0.99\n",
      "for 2020-07-05, MAE is:36.75 & sMAPE is:188.35% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :7.75 & 49.28% & 0.99\n",
      "for 2020-07-06, MAE is:8.32 & sMAPE is:161.13% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :7.75 & 49.87% & 0.99\n",
      "for 2020-07-07, MAE is:6.25 & sMAPE is:65.23% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :7.74 & 49.95% & 0.99\n",
      "for 2020-07-08, MAE is:8.08 & sMAPE is:23.62% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :7.74 & 49.81% & 0.98\n",
      "for 2020-07-09, MAE is:2.89 & sMAPE is:7.29% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :7.72 & 49.59% & 0.98\n",
      "for 2020-07-10, MAE is:7.14 & sMAPE is:24.19% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :7.71 & 49.46% & 0.99\n",
      "for 2020-07-11, MAE is:6.28 & sMAPE is:68.93% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :7.71 & 49.56% & 0.98\n",
      "for 2020-07-12, MAE is:6.93 & sMAPE is:54.76% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :7.70 & 49.59% & 0.98\n",
      "for 2020-07-13, MAE is:11.84 & sMAPE is:45.96% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :7.72 & 49.57% & 0.98\n",
      "for 2020-07-14, MAE is:4.28 & sMAPE is:12.55% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :7.71 & 49.38% & 0.97\n",
      "for 2020-07-15, MAE is:4.33 & sMAPE is:10.66% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :7.69 & 49.18% & 0.97\n",
      "for 2020-07-16, MAE is:9.49 & sMAPE is:22.56% & rMAE is:2.23 ||| daily mean of MAE & sMAPE & rMAE till now are :7.70 & 49.05% & 0.98\n",
      "for 2020-07-17, MAE is:6.07 & sMAPE is:17.28% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :7.69 & 48.89% & 0.98\n",
      "for 2020-07-18, MAE is:4.56 & sMAPE is:17.09% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :7.67 & 48.73% & 0.97\n",
      "for 2020-07-19, MAE is:3.55 & sMAPE is:13.40% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :7.65 & 48.55% & 0.97\n",
      "for 2020-07-20, MAE is:7.26 & sMAPE is:29.70% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :7.65 & 48.46% & 0.97\n",
      "for 2020-07-21, MAE is:11.13 & sMAPE is:54.94% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :7.67 & 48.49% & 0.97\n",
      "for 2020-07-22, MAE is:7.89 & sMAPE is:28.79% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :7.67 & 48.40% & 0.97\n",
      "for 2020-07-23, MAE is:4.60 & sMAPE is:13.34% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :7.66 & 48.23% & 0.97\n",
      "for 2020-07-24, MAE is:9.78 & sMAPE is:41.62% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :7.67 & 48.19% & 0.97\n",
      "for 2020-07-25, MAE is:4.79 & sMAPE is:20.58% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :7.65 & 48.06% & 0.97\n",
      "for 2020-07-26, MAE is:12.65 & sMAPE is:73.42% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :7.68 & 48.18% & 0.97\n",
      "for 2020-07-27, MAE is:7.78 & sMAPE is:30.12% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :7.68 & 48.10% & 0.97\n",
      "for 2020-07-28, MAE is:18.97 & sMAPE is:133.17% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :7.73 & 48.50% & 0.97\n",
      "for 2020-07-29, MAE is:14.11 & sMAPE is:154.06% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :7.76 & 49.00% & 0.97\n",
      "for 2020-07-30, MAE is:14.75 & sMAPE is:135.16% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :7.79 & 49.41% & 0.97\n",
      "for 2020-07-31, MAE is:5.54 & sMAPE is:15.83% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :7.78 & 49.25% & 0.96\n",
      "for 2020-08-01, MAE is:5.83 & sMAPE is:22.86% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :7.77 & 49.13% & 0.97\n",
      "for 2020-08-02, MAE is:5.45 & sMAPE is:21.43% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :7.76 & 49.00% & 0.96\n",
      "for 2020-08-03, MAE is:4.59 & sMAPE is:12.89% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :7.75 & 48.83% & 0.96\n",
      "for 2020-08-04, MAE is:5.39 & sMAPE is:15.71% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :7.74 & 48.68% & 0.96\n",
      "for 2020-08-05, MAE is:7.69 & sMAPE is:27.30% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :7.74 & 48.58% & 0.96\n",
      "for 2020-08-06, MAE is:9.60 & sMAPE is:31.44% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :7.75 & 48.50% & 0.95\n",
      "for 2020-08-07, MAE is:3.75 & sMAPE is:10.24% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :7.73 & 48.33% & 0.95\n",
      "for 2020-08-08, MAE is:3.54 & sMAPE is:11.09% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :7.71 & 48.16% & 0.95\n",
      "for 2020-08-09, MAE is:3.89 & sMAPE is:13.55% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :7.69 & 48.00% & 0.95\n",
      "for 2020-08-10, MAE is:5.97 & sMAPE is:17.93% & rMAE is:2.20 ||| daily mean of MAE & sMAPE & rMAE till now are :7.68 & 47.87% & 0.96\n",
      "for 2020-08-11, MAE is:4.59 & sMAPE is:13.35% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :7.67 & 47.71% & 0.96\n",
      "for 2020-08-12, MAE is:5.00 & sMAPE is:13.84% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :7.66 & 47.56% & 0.96\n",
      "for 2020-08-13, MAE is:3.58 & sMAPE is:9.26% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :7.64 & 47.39% & 0.96\n",
      "for 2020-08-14, MAE is:3.40 & sMAPE is:8.07% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :7.62 & 47.22% & 0.96\n",
      "for 2020-08-15, MAE is:2.76 & sMAPE is:8.65% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :7.60 & 47.05% & 0.96\n",
      "for 2020-08-16, MAE is:3.75 & sMAPE is:13.26% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :7.58 & 46.90% & 0.96\n",
      "for 2020-08-17, MAE is:9.75 & sMAPE is:26.03% & rMAE is:2.80 ||| daily mean of MAE & sMAPE & rMAE till now are :7.59 & 46.81% & 0.97\n",
      "for 2020-08-18, MAE is:4.47 & sMAPE is:10.23% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :7.58 & 46.65% & 0.97\n",
      "for 2020-08-19, MAE is:4.80 & sMAPE is:12.27% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :7.57 & 46.51% & 0.97\n",
      "for 2020-08-20, MAE is:4.31 & sMAPE is:10.42% & rMAE is:1.67 ||| daily mean of MAE & sMAPE & rMAE till now are :7.55 & 46.35% & 0.97\n",
      "for 2020-08-21, MAE is:7.87 & sMAPE is:25.93% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :7.55 & 46.26% & 0.97\n",
      "for 2020-08-22, MAE is:13.48 & sMAPE is:68.64% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :7.58 & 46.36% & 0.97\n",
      "for 2020-08-23, MAE is:11.01 & sMAPE is:69.98% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :7.59 & 46.46% & 0.97\n",
      "for 2020-08-24, MAE is:13.05 & sMAPE is:35.08% & rMAE is:2.55 ||| daily mean of MAE & sMAPE & rMAE till now are :7.62 & 46.41% & 0.98\n",
      "for 2020-08-25, MAE is:9.12 & sMAPE is:22.07% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :7.62 & 46.31% & 0.98\n",
      "for 2020-08-26, MAE is:8.60 & sMAPE is:60.03% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :7.63 & 46.37% & 0.98\n",
      "for 2020-08-27, MAE is:20.98 & sMAPE is:54.64% & rMAE is:1.95 ||| daily mean of MAE & sMAPE & rMAE till now are :7.68 & 46.40% & 0.98\n",
      "for 2020-08-28, MAE is:6.68 & sMAPE is:15.04% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :7.68 & 46.27% & 0.98\n",
      "for 2020-08-29, MAE is:3.10 & sMAPE is:8.58% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :7.66 & 46.12% & 0.98\n",
      "for 2020-08-30, MAE is:3.12 & sMAPE is:9.24% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :7.64 & 45.96% & 0.97\n",
      "for 2020-08-31, MAE is:17.36 & sMAPE is:34.48% & rMAE is:1.82 ||| daily mean of MAE & sMAPE & rMAE till now are :7.68 & 45.92% & 0.98\n",
      "for 2020-09-01, MAE is:4.18 & sMAPE is:8.56% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :7.67 & 45.76% & 0.98\n",
      "for 2020-09-02, MAE is:11.29 & sMAPE is:24.98% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :7.68 & 45.68% & 0.97\n",
      "for 2020-09-03, MAE is:7.19 & sMAPE is:17.59% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :7.68 & 45.57% & 0.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-09-04, MAE is:11.48 & sMAPE is:34.19% & rMAE is:3.50 ||| daily mean of MAE & sMAPE & rMAE till now are :7.70 & 45.52% & 0.98\n",
      "for 2020-09-05, MAE is:4.73 & sMAPE is:15.05% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :7.68 & 45.40% & 0.98\n",
      "for 2020-09-06, MAE is:3.78 & sMAPE is:10.83% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :7.67 & 45.26% & 0.98\n",
      "for 2020-09-07, MAE is:7.39 & sMAPE is:17.98% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :7.67 & 45.15% & 0.98\n",
      "for 2020-09-08, MAE is:7.44 & sMAPE is:23.61% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :7.67 & 45.07% & 0.98\n",
      "for 2020-09-09, MAE is:11.87 & sMAPE is:32.93% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :7.68 & 45.02% & 0.98\n",
      "for 2020-09-10, MAE is:19.94 & sMAPE is:57.50% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :7.73 & 45.07% & 0.98\n",
      "for 2020-09-11, MAE is:8.00 & sMAPE is:18.21% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :7.73 & 44.96% & 0.98\n",
      "for 2020-09-12, MAE is:7.62 & sMAPE is:41.75% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :7.73 & 44.95% & 0.98\n",
      "for 2020-09-13, MAE is:15.76 & sMAPE is:63.46% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :7.76 & 45.02% & 0.98\n",
      "for 2020-09-14, MAE is:18.45 & sMAPE is:39.05% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :7.80 & 45.00% & 0.98\n",
      "for 2020-09-15, MAE is:20.37 & sMAPE is:24.91% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :7.85 & 44.92% & 0.98\n",
      "for 2020-09-16, MAE is:15.87 & sMAPE is:28.26% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :7.88 & 44.86% & 0.98\n",
      "for 2020-09-17, MAE is:11.00 & sMAPE is:33.16% & rMAE is:1.94 ||| daily mean of MAE & sMAPE & rMAE till now are :7.89 & 44.81% & 0.98\n",
      "for 2020-09-18, MAE is:6.20 & sMAPE is:16.07% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :7.89 & 44.70% & 0.98\n",
      "for 2020-09-19, MAE is:5.74 & sMAPE is:16.59% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :7.88 & 44.59% & 0.98\n",
      "for 2020-09-20, MAE is:5.02 & sMAPE is:14.43% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :7.87 & 44.48% & 0.98\n",
      "for 2020-09-21, MAE is:23.06 & sMAPE is:38.12% & rMAE is:2.43 ||| daily mean of MAE & sMAPE & rMAE till now are :7.93 & 44.46% & 0.98\n",
      "for 2020-09-22, MAE is:8.86 & sMAPE is:17.36% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :7.93 & 44.35% & 0.98\n",
      "for 2020-09-23, MAE is:9.65 & sMAPE is:27.26% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :7.94 & 44.29% & 0.98\n",
      "for 2020-09-24, MAE is:13.27 & sMAPE is:67.02% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :7.96 & 44.38% & 0.98\n",
      "for 2020-09-25, MAE is:10.36 & sMAPE is:63.49% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :7.97 & 44.45% & 0.98\n",
      "for 2020-09-26, MAE is:7.62 & sMAPE is:107.37% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :7.96 & 44.68% & 0.97\n",
      "for 2020-09-27, MAE is:4.02 & sMAPE is:78.87% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :7.95 & 44.81% & 0.97\n",
      "for 2020-09-28, MAE is:18.91 & sMAPE is:61.02% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :7.99 & 44.86% & 0.97\n",
      "for 2020-09-29, MAE is:10.79 & sMAPE is:16.75% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :8.00 & 44.76% & 0.97\n",
      "for 2020-09-30, MAE is:6.24 & sMAPE is:13.65% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :7.99 & 44.65% & 0.97\n",
      "for 2020-10-01, MAE is:7.07 & sMAPE is:24.55% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :7.99 & 44.58% & 0.97\n",
      "for 2020-10-02, MAE is:5.90 & sMAPE is:45.76% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :7.98 & 44.58% & 0.97\n",
      "for 2020-10-03, MAE is:5.66 & sMAPE is:118.94% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :7.97 & 44.85% & 0.97\n",
      "for 2020-10-04, MAE is:6.23 & sMAPE is:102.80% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :7.97 & 45.06% & 0.97\n",
      "for 2020-10-05, MAE is:6.32 & sMAPE is:35.98% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :7.96 & 45.02% & 0.97\n",
      "for 2020-10-06, MAE is:7.13 & sMAPE is:22.69% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :7.96 & 44.94% & 0.96\n",
      "for 2020-10-07, MAE is:9.18 & sMAPE is:33.71% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :7.96 & 44.90% & 0.96\n",
      "for 2020-10-08, MAE is:6.40 & sMAPE is:27.24% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :7.96 & 44.84% & 0.96\n",
      "for 2020-10-09, MAE is:14.58 & sMAPE is:55.37% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :7.98 & 44.88% & 0.96\n",
      "for 2020-10-10, MAE is:7.47 & sMAPE is:36.35% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :7.98 & 44.85% & 0.96\n",
      "for 2020-10-11, MAE is:12.21 & sMAPE is:51.74% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :7.99 & 44.87% & 0.96\n",
      "for 2020-10-12, MAE is:9.60 & sMAPE is:20.83% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :8.00 & 44.79% & 0.96\n",
      "for 2020-10-13, MAE is:11.08 & sMAPE is:23.33% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :8.01 & 44.71% & 0.96\n",
      "for 2020-10-14, MAE is:7.82 & sMAPE is:30.64% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :8.01 & 44.67% & 0.95\n",
      "for 2020-10-15, MAE is:13.23 & sMAPE is:39.42% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :8.03 & 44.65% & 0.96\n",
      "for 2020-10-16, MAE is:14.03 & sMAPE is:36.88% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :8.05 & 44.62% & 0.96\n",
      "for 2020-10-17, MAE is:9.21 & sMAPE is:32.67% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :8.05 & 44.58% & 0.96\n",
      "for 2020-10-18, MAE is:5.18 & sMAPE is:34.74% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :8.04 & 44.55% & 0.96\n",
      "for 2020-10-19, MAE is:9.28 & sMAPE is:26.81% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :8.05 & 44.49% & 0.96\n",
      "for 2020-10-20, MAE is:10.44 & sMAPE is:30.26% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :8.06 & 44.44% & 0.95\n",
      "for 2020-10-21, MAE is:8.70 & sMAPE is:29.89% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :8.06 & 44.39% & 0.95\n",
      "for 2020-10-22, MAE is:6.72 & sMAPE is:43.35% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :8.05 & 44.38% & 0.95\n",
      "for 2020-10-23, MAE is:16.68 & sMAPE is:54.67% & rMAE is:2.10 ||| daily mean of MAE & sMAPE & rMAE till now are :8.08 & 44.42% & 0.96\n",
      "for 2020-10-24, MAE is:8.43 & sMAPE is:43.05% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :8.08 & 44.41% & 0.96\n",
      "for 2020-10-25, MAE is:10.83 & sMAPE is:119.73% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :8.09 & 44.67% & 0.95\n",
      "for 2020-10-26, MAE is:9.24 & sMAPE is:36.82% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :8.10 & 44.64% & 0.95\n",
      "for 2020-10-27, MAE is:17.77 & sMAPE is:72.84% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :8.13 & 44.73% & 0.95\n",
      "for 2020-10-28, MAE is:10.98 & sMAPE is:71.78% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :8.14 & 44.82% & 0.95\n",
      "for 2020-10-29, MAE is:14.79 & sMAPE is:55.78% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :8.16 & 44.86% & 0.95\n",
      "for 2020-10-30, MAE is:6.93 & sMAPE is:37.70% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :8.16 & 44.84% & 0.95\n",
      "for 2020-10-31, MAE is:13.87 & sMAPE is:77.18% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :8.17 & 44.94% & 0.95\n",
      "for 2020-11-01, MAE is:8.79 & sMAPE is:82.39% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :8.18 & 45.06% & 0.95\n",
      "for 2020-11-02, MAE is:11.43 & sMAPE is:117.77% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :8.19 & 45.30% & 0.95\n",
      "for 2020-11-03, MAE is:11.85 & sMAPE is:96.80% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :8.20 & 45.47% & 0.95\n",
      "for 2020-11-04, MAE is:13.70 & sMAPE is:108.59% & rMAE is:2.30 ||| daily mean of MAE & sMAPE & rMAE till now are :8.22 & 45.67% & 0.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-11-05, MAE is:13.41 & sMAPE is:155.31% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :8.23 & 46.03% & 0.95\n",
      "for 2020-11-06, MAE is:17.88 & sMAPE is:99.43% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :8.26 & 46.20% & 0.95\n",
      "for 2020-11-07, MAE is:7.98 & sMAPE is:24.68% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :8.26 & 46.13% & 0.95\n",
      "for 2020-11-08, MAE is:5.41 & sMAPE is:15.45% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :8.25 & 46.03% & 0.95\n",
      "for 2020-11-09, MAE is:8.25 & sMAPE is:19.00% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :8.25 & 45.94% & 0.95\n",
      "for 2020-11-10, MAE is:4.49 & sMAPE is:9.20% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :8.24 & 45.83% & 0.95\n",
      "for 2020-11-11, MAE is:4.67 & sMAPE is:10.65% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :8.23 & 45.72% & 0.94\n",
      "for 2020-11-12, MAE is:8.83 & sMAPE is:37.84% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :8.23 & 45.69% & 0.94\n",
      "for 2020-11-13, MAE is:5.36 & sMAPE is:14.92% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :8.22 & 45.60% & 0.94\n",
      "for 2020-11-14, MAE is:7.90 & sMAPE is:33.59% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :8.22 & 45.56% & 0.94\n",
      "for 2020-11-15, MAE is:15.28 & sMAPE is:157.20% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :8.25 & 45.91% & 0.94\n",
      "for 2020-11-16, MAE is:14.98 & sMAPE is:105.05% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :8.27 & 46.09% & 0.94\n",
      "for 2020-11-17, MAE is:24.26 & sMAPE is:145.81% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :8.32 & 46.40% & 0.93\n",
      "for 2020-11-18, MAE is:20.76 & sMAPE is:188.72% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :8.35 & 46.84% & 0.93\n",
      "for 2020-11-19, MAE is:14.12 & sMAPE is:175.73% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :8.37 & 47.24% & 0.93\n",
      "for 2020-11-20, MAE is:18.63 & sMAPE is:91.28% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :8.40 & 47.37% & 0.93\n",
      "for 2020-11-21, MAE is:21.23 & sMAPE is:181.46% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :8.44 & 47.79% & 0.93\n",
      "for 2020-11-22, MAE is:9.03 & sMAPE is:169.57% & rMAE is:3.38 ||| daily mean of MAE & sMAPE & rMAE till now are :8.45 & 48.16% & 0.94\n",
      "for 2020-11-23, MAE is:10.93 & sMAPE is:120.67% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :8.45 & 48.38% & 0.94\n",
      "for 2020-11-24, MAE is:12.87 & sMAPE is:105.04% & rMAE is:2.98 ||| daily mean of MAE & sMAPE & rMAE till now are :8.47 & 48.55% & 0.95\n",
      "for 2020-11-25, MAE is:10.15 & sMAPE is:85.08% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :8.47 & 48.66% & 0.95\n",
      "for 2020-11-26, MAE is:29.88 & sMAPE is:80.21% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :8.54 & 48.76% & 0.95\n",
      "for 2020-11-27, MAE is:10.21 & sMAPE is:15.09% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :8.54 & 48.66% & 0.94\n",
      "for 2020-11-28, MAE is:3.43 & sMAPE is:7.31% & rMAE is:0.07 ||| daily mean of MAE & sMAPE & rMAE till now are :8.53 & 48.53% & 0.94\n",
      "for 2020-11-29, MAE is:8.69 & sMAPE is:21.19% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :8.53 & 48.45% & 0.94\n",
      "for 2020-11-30, MAE is:14.54 & sMAPE is:36.70% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :8.54 & 48.41% & 0.94\n",
      "for 2020-12-01, MAE is:20.67 & sMAPE is:48.24% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :8.58 & 48.41% & 0.94\n",
      "for 2020-12-02, MAE is:22.64 & sMAPE is:36.61% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :8.62 & 48.38% & 0.93\n",
      "for 2020-12-03, MAE is:13.36 & sMAPE is:44.71% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :8.64 & 48.37% & 0.93\n",
      "for 2020-12-04, MAE is:10.73 & sMAPE is:42.18% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :8.64 & 48.35% & 0.93\n",
      "for 2020-12-05, MAE is:11.33 & sMAPE is:38.35% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :8.65 & 48.32% & 0.93\n",
      "for 2020-12-06, MAE is:7.92 & sMAPE is:22.52% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :8.65 & 48.24% & 0.93\n",
      "for 2020-12-07, MAE is:11.95 & sMAPE is:51.60% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :8.66 & 48.25% & 0.93\n",
      "for 2020-12-08, MAE is:31.36 & sMAPE is:74.83% & rMAE is:3.81 ||| daily mean of MAE & sMAPE & rMAE till now are :8.72 & 48.33% & 0.94\n",
      "for 2020-12-09, MAE is:16.39 & sMAPE is:30.38% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :8.75 & 48.28% & 0.94\n",
      "for 2020-12-10, MAE is:21.37 & sMAPE is:31.03% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :8.78 & 48.23% & 0.94\n",
      "for 2020-12-11, MAE is:22.12 & sMAPE is:51.09% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :8.82 & 48.24% & 0.94\n",
      "for 2020-12-12, MAE is:14.89 & sMAPE is:44.89% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :8.84 & 48.23% & 0.94\n",
      "for 2020-12-13, MAE is:4.18 & sMAPE is:9.95% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :8.83 & 48.12% & 0.94\n",
      "for 2020-12-14, MAE is:8.27 & sMAPE is:27.44% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :8.82 & 48.06% & 0.94\n",
      "for 2020-12-15, MAE is:7.45 & sMAPE is:17.39% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :8.82 & 47.97% & 0.94\n",
      "for 2020-12-16, MAE is:10.22 & sMAPE is:26.40% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :8.82 & 47.91% & 0.94\n",
      "for 2020-12-17, MAE is:8.77 & sMAPE is:26.94% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :8.82 & 47.85% & 0.94\n",
      "for 2020-12-18, MAE is:14.56 & sMAPE is:50.44% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :8.84 & 47.86% & 0.94\n",
      "for 2020-12-19, MAE is:3.27 & sMAPE is:19.12% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :8.82 & 47.78% & 0.93\n",
      "for 2020-12-20, MAE is:8.31 & sMAPE is:58.98% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :8.82 & 47.81% & 0.93\n",
      "for 2020-12-21, MAE is:5.72 & sMAPE is:29.59% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :8.81 & 47.76% & 0.93\n",
      "for 2020-12-22, MAE is:8.71 & sMAPE is:76.17% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :8.81 & 47.84% & 0.93\n",
      "for 2020-12-23, MAE is:8.42 & sMAPE is:26.18% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :8.81 & 47.78% & 0.93\n",
      "for 2020-12-24, MAE is:14.26 & sMAPE is:77.99% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :8.83 & 47.86% & 0.93\n",
      "for 2020-12-25, MAE is:18.80 & sMAPE is:72.49% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :8.86 & 47.93% & 0.93\n",
      "for 2020-12-26, MAE is:23.01 & sMAPE is:85.19% & rMAE is:4.12 ||| daily mean of MAE & sMAPE & rMAE till now are :8.89 & 48.03% & 0.94\n",
      "for 2020-12-27, MAE is:20.01 & sMAPE is:145.77% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :8.93 & 48.30% & 0.94\n",
      "for 2020-12-28, MAE is:17.12 & sMAPE is:91.68% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :8.95 & 48.42% & 0.94\n",
      "for 2020-12-29, MAE is:5.53 & sMAPE is:12.96% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :8.94 & 48.32% & 0.94\n",
      "for 2020-12-30, MAE is:12.32 & sMAPE is:30.81% & rMAE is:1.99 ||| daily mean of MAE & sMAPE & rMAE till now are :8.95 & 48.28% & 0.94\n",
      "for 2020-12-31, MAE is:17.84 & sMAPE is:49.12% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :8.97 & 48.28% & 0.94\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:36:20,633]\u001b[0m A new study created in RDB with name: DK_1_2021\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:36:41,493]\u001b[0m Trial 0 finished with value: 9.29912817955138 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010931675839193314, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22589423857421154, 'dropout_rate_Layer_2': 0.39813259876331375, 'dropout_rate_Layer_3': 0.009135842174556518, 'dropout_rate_Layer_4': 0.185852749754571, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.018984092517404516, 'l1_Layer_2': 0.0002254916227362731, 'l1_Layer_3': 0.00029290702047902404, 'l1_Layer_4': 4.0460048138179195e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 210, 'n_units_Layer_3': 70, 'n_units_Layer_4': 140}. Best is trial 0 with value: 9.29912817955138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.30 | sMAPE for Validation Set is: 49.33% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 35.53 | sMAPE for Test Set is: 40.53% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:36:45,274]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:36:47,843]\u001b[0m Trial 1 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:36:48,389]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:36:53,580]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:36:59,856]\u001b[0m Trial 3 finished with value: 9.309263386904446 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007361719648258573, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.027505476854019363, 'dropout_rate_Layer_2': 0.10921018339423788, 'dropout_rate_Layer_3': 0.14399625989315137, 'dropout_rate_Layer_4': 0.12609657143130013, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00018349102246967855, 'l1_Layer_2': 0.003859273570578909, 'l1_Layer_3': 6.034208717308278e-05, 'l1_Layer_4': 0.003401617893278423, 'n_units_Layer_1': 240, 'n_units_Layer_2': 115, 'n_units_Layer_3': 85, 'n_units_Layer_4': 205}. Best is trial 0 with value: 9.29912817955138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.31 | sMAPE for Validation Set is: 48.64% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 35.62 | sMAPE for Test Set is: 40.26% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:37:11,351]\u001b[0m Trial 2 finished with value: 11.051817775680552 and parameters: {'n_hidden': 3, 'learning_rate': 0.00904633318026342, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11952287857740651, 'dropout_rate_Layer_2': 0.23320075765650344, 'dropout_rate_Layer_3': 0.11479623669233684, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0005515469899586794, 'l1_Layer_2': 0.03818312820184846, 'l1_Layer_3': 2.0056556851913348e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 145, 'n_units_Layer_3': 220}. Best is trial 0 with value: 9.29912817955138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.05 | sMAPE for Validation Set is: 53.16% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 42.08 | sMAPE for Test Set is: 48.81% | rMAE for Test Set is: 1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:37:13,444]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:37:16,926]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:37:17,317]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:37:21,249]\u001b[0m Trial 7 finished with value: 10.265685109277513 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005306229010401618, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15602053305551747, 'dropout_rate_Layer_2': 0.016008631902993998, 'dropout_rate_Layer_3': 0.282706583432516, 'dropout_rate_Layer_4': 0.08113759555798294, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0012002201985672285, 'l1_Layer_2': 0.014968454893770746, 'l1_Layer_3': 0.004850937003992156, 'l1_Layer_4': 3.570149159598071e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 285, 'n_units_Layer_3': 240, 'n_units_Layer_4': 240}. Best is trial 0 with value: 9.29912817955138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.27 | sMAPE for Validation Set is: 51.47% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 34.20 | sMAPE for Test Set is: 38.66% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:37:25,961]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:37:26,494]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:37:32,113]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:37:34,288]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:37:37,944]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:37:38,946]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:37:46,325]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:37:51,364]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:37:57,103]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:37:57,232]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:37:58,122]\u001b[0m Trial 20 finished with value: 10.338740198100844 and parameters: {'n_hidden': 3, 'learning_rate': 0.019532055775613514, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23302154704705963, 'dropout_rate_Layer_2': 0.17870701395985208, 'dropout_rate_Layer_3': 0.3698415743448759, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.9009117168933983e-05, 'l1_Layer_2': 2.0532422419595257e-05, 'l1_Layer_3': 0.00018597707302026064, 'n_units_Layer_1': 140, 'n_units_Layer_2': 260, 'n_units_Layer_3': 110}. Best is trial 0 with value: 9.29912817955138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.34 | sMAPE for Validation Set is: 51.89% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 41.18 | sMAPE for Test Set is: 48.31% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:38:04,401]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:38:09,440]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:38:14,646]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:38:14,966]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:38:19,942]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:38:22,800]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:38:26,364]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:38:28,195]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:38:32,754]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:38:34,666]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:38:36,702]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:38:39,564]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:38:45,657]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:38:48,714]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:38:52,651]\u001b[0m Trial 8 finished with value: 9.55811691703128 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008384258351110327, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23613466097723596, 'dropout_rate_Layer_2': 0.2707361516497377, 'dropout_rate_Layer_3': 0.05217441036984294, 'dropout_rate_Layer_4': 0.0493384712568489, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.09965277722210653, 'l1_Layer_2': 0.00012276594500869344, 'l1_Layer_3': 0.006184734527150328, 'l1_Layer_4': 0.00045563635455799184, 'n_units_Layer_1': 300, 'n_units_Layer_2': 115, 'n_units_Layer_3': 235, 'n_units_Layer_4': 165}. Best is trial 0 with value: 9.29912817955138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.56 | sMAPE for Validation Set is: 49.35% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 33.00 | sMAPE for Test Set is: 36.42% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:38:56,296]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:38:58,980]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:39:02,649]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:39:08,017]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:39:11,720]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:39:12,499]\u001b[0m Trial 35 finished with value: 9.092757750192836 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012955592832165216, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04758293654870598, 'dropout_rate_Layer_2': 0.36960698064441333, 'dropout_rate_Layer_3': 0.037866295990035416, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005706166327031877, 'l1_Layer_2': 0.0019120087193273557, 'l1_Layer_3': 0.03930294995982777, 'n_units_Layer_1': 220, 'n_units_Layer_2': 135, 'n_units_Layer_3': 260}. Best is trial 35 with value: 9.092757750192836.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.09 | sMAPE for Validation Set is: 47.82% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 25.23 | sMAPE for Test Set is: 31.32% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:39:14,162]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:39:19,790]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:39:22,741]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:39:27,057]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:39:30,665]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:39:34,068]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:39:36,687]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:39:38,172]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:39:40,023]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:39:44,223]\u001b[0m Trial 47 finished with value: 9.58060168628957 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005032516586970337, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21403632751045631, 'dropout_rate_Layer_2': 0.15074573688775017, 'dropout_rate_Layer_3': 0.04647107663957239, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012185309545246546, 'l1_Layer_2': 0.0017265750464479962, 'l1_Layer_3': 0.00012709959915546522, 'n_units_Layer_1': 50, 'n_units_Layer_2': 300, 'n_units_Layer_3': 295}. Best is trial 35 with value: 9.092757750192836.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.58 | sMAPE for Validation Set is: 49.63% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 23.63 | sMAPE for Test Set is: 29.21% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:39:46,035]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:39:47,390]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:39:48,083]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:39:49,135]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:39:53,655]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:39:56,056]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:39:58,788]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:40:01,668]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:40:08,041]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:40:10,548]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:40:10,725]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:40:13,147]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:40:18,547]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:40:20,473]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:40:24,464]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:40:27,311]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:40:27,823]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:40:31,154]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:40:33,395]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:40:36,161]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:40:36,604]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:40:39,020]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:40:43,147]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:40:45,694]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:40:50,707]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:40:52,463]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:40:57,258]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:41:01,130]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:41:01,636]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:41:11,740]\u001b[0m Trial 78 finished with value: 8.215356658226538 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005942507053099964, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23744297847128112, 'dropout_rate_Layer_2': 0.19112112434170556, 'dropout_rate_Layer_3': 0.25327135906900594, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00033946892584999216, 'l1_Layer_2': 0.0004668802567781413, 'l1_Layer_3': 1.0568774905178329e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 135, 'n_units_Layer_3': 125}. Best is trial 78 with value: 8.215356658226538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.22 | sMAPE for Validation Set is: 47.44% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 23.41 | sMAPE for Test Set is: 29.05% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:41:12,270]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:41:17,346]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:41:22,850]\u001b[0m Trial 84 finished with value: 10.681102556823689 and parameters: {'n_hidden': 3, 'learning_rate': 0.001640696273205284, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3535457841554792, 'dropout_rate_Layer_2': 0.16911759313543434, 'dropout_rate_Layer_3': 0.032930180375603295, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0008338770772859825, 'l1_Layer_2': 5.3242954131190434e-05, 'l1_Layer_3': 1.4186516168608658e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 250, 'n_units_Layer_3': 175}. Best is trial 78 with value: 8.215356658226538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.68 | sMAPE for Validation Set is: 53.09% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 47.02 | sMAPE for Test Set is: 58.68% | rMAE for Test Set is: 1.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:41:28,166]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:41:39,353]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:41:42,375]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:41:43,894]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:41:47,200]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:41:49,939]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:41:54,672]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:41:54,811]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:42:01,953]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:42:04,034]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:42:08,815]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:42:11,243]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:42:17,550]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:42:19,965]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:42:21,748]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:42:25,646]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:42:26,865]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:42:30,223]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:42:33,173]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:42:35,560]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:42:41,553]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:42:43,191]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:42:46,940]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:42:52,668]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:42:59,514]\u001b[0m Trial 106 finished with value: 8.24725752131569 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013264871629815563, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21285183657286316, 'dropout_rate_Layer_2': 0.29751791897977536, 'dropout_rate_Layer_3': 0.22234202537964445, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005520232430785886, 'l1_Layer_2': 0.0006843512956331994, 'l1_Layer_3': 0.0009249667093600972, 'n_units_Layer_1': 125, 'n_units_Layer_2': 180, 'n_units_Layer_3': 95}. Best is trial 78 with value: 8.215356658226538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.25 | sMAPE for Validation Set is: 46.20% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 25.04 | sMAPE for Test Set is: 31.28% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:43:01,267]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:43:05,887]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:43:07,662]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:43:12,795]\u001b[0m Trial 110 finished with value: 9.863350261088563 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015189103079273022, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19682391889987452, 'dropout_rate_Layer_2': 0.05559104552201495, 'dropout_rate_Layer_3': 0.36677320619001785, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.978938389447088e-05, 'l1_Layer_2': 0.00010128044337770505, 'l1_Layer_3': 0.0024905589882083154, 'n_units_Layer_1': 55, 'n_units_Layer_2': 125, 'n_units_Layer_3': 115}. Best is trial 78 with value: 8.215356658226538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.86 | sMAPE for Validation Set is: 50.62% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 40.57 | sMAPE for Test Set is: 47.14% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:43:23,677]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:43:25,893]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:43:30,132]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:43:32,271]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:43:39,086]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:43:45,778]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:43:49,253]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:43:53,384]\u001b[0m Trial 111 finished with value: 9.863532442387433 and parameters: {'n_hidden': 4, 'learning_rate': 0.001254607226498104, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2230244217332909, 'dropout_rate_Layer_2': 0.10955776655824256, 'dropout_rate_Layer_3': 0.07726904031085985, 'dropout_rate_Layer_4': 0.31832321231930666, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.005488788641830594, 'l1_Layer_2': 0.0009262719041299494, 'l1_Layer_3': 0.00010948856195966894, 'l1_Layer_4': 1.9545330601240174e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 150, 'n_units_Layer_3': 55, 'n_units_Layer_4': 110}. Best is trial 78 with value: 8.215356658226538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.86 | sMAPE for Validation Set is: 50.89% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 38.15 | sMAPE for Test Set is: 43.39% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:43:53,913]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:43:59,237]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:44:02,675]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:44:06,098]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:44:10,292]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:44:13,969]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:44:19,888]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:44:23,560]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:44:25,563]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:44:30,184]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:44:32,440]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:44:40,128]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:44:44,112]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:44:44,275]\u001b[0m Trial 124 finished with value: 9.604969121944386 and parameters: {'n_hidden': 3, 'learning_rate': 0.004422698118680272, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014890439984669348, 'dropout_rate_Layer_2': 0.13877299620751918, 'dropout_rate_Layer_3': 0.07792545921454808, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001296873844738806, 'l1_Layer_2': 0.00042229247191935624, 'l1_Layer_3': 6.610934093582681e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 250, 'n_units_Layer_3': 255}. Best is trial 78 with value: 8.215356658226538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.60 | sMAPE for Validation Set is: 49.65% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 42.06 | sMAPE for Test Set is: 50.16% | rMAE for Test Set is: 1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:44:44,826]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:44:45,113]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:44:53,454]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:44:53,555]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:45:01,402]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:45:01,438]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:45:09,052]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:45:09,552]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:45:15,394]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:45:17,399]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:45:29,063]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:45:32,171]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:45:34,974]\u001b[0m Trial 142 finished with value: 9.385683491202894 and parameters: {'n_hidden': 3, 'learning_rate': 0.005493359731733227, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06714552145470185, 'dropout_rate_Layer_2': 0.16427041597960482, 'dropout_rate_Layer_3': 0.08511025259085553, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005627277420586485, 'l1_Layer_2': 0.002738799993970998, 'l1_Layer_3': 3.274609660611877e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 250, 'n_units_Layer_3': 260}. Best is trial 78 with value: 8.215356658226538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.39 | sMAPE for Validation Set is: 48.79% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 41.05 | sMAPE for Test Set is: 47.79% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:45:36,413]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:45:41,149]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:45:44,735]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:45:55,070]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:46:06,945]\u001b[0m Trial 155 finished with value: 10.007818450480146 and parameters: {'n_hidden': 3, 'learning_rate': 0.001746247935342442, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10528403896268798, 'dropout_rate_Layer_2': 0.18472534736993818, 'dropout_rate_Layer_3': 0.08665874175765402, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00019661844681862962, 'l1_Layer_2': 0.00019110487270933868, 'l1_Layer_3': 1.004449250090701e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 270, 'n_units_Layer_3': 290}. Best is trial 78 with value: 8.215356658226538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.01 | sMAPE for Validation Set is: 50.33% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 40.50 | sMAPE for Test Set is: 47.20% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:46:09,526]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:46:13,997]\u001b[0m Trial 149 finished with value: 9.835149668373768 and parameters: {'n_hidden': 3, 'learning_rate': 0.005867683619390454, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12436923998408264, 'dropout_rate_Layer_2': 0.1075704353363653, 'dropout_rate_Layer_3': 0.31668103132511105, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.989290726360272e-05, 'l1_Layer_2': 0.010654797786000151, 'l1_Layer_3': 0.004748789045139505, 'n_units_Layer_1': 200, 'n_units_Layer_2': 195, 'n_units_Layer_3': 140}. Best is trial 78 with value: 8.215356658226538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.84 | sMAPE for Validation Set is: 52.09% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 39.03 | sMAPE for Test Set is: 45.49% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:46:17,934]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:46:21,139]\u001b[0m Trial 154 finished with value: 9.561914527979072 and parameters: {'n_hidden': 3, 'learning_rate': 0.0037989353823270388, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10432916173631232, 'dropout_rate_Layer_2': 0.1898890333318848, 'dropout_rate_Layer_3': 0.09362755948504038, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003280007122012459, 'l1_Layer_2': 0.0001975872714786986, 'l1_Layer_3': 1.405226717626402e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 270, 'n_units_Layer_3': 285}. Best is trial 78 with value: 8.215356658226538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.56 | sMAPE for Validation Set is: 52.43% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 41.66 | sMAPE for Test Set is: 49.71% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:46:25,494]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:46:26,229]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:46:28,762]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:46:35,048]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:46:37,966]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:46:40,318]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:46:43,244]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:46:49,705]\u001b[0m Trial 160 finished with value: 9.690002521403212 and parameters: {'n_hidden': 3, 'learning_rate': 0.002542209155944485, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0549852830784797, 'dropout_rate_Layer_2': 0.18678010809416076, 'dropout_rate_Layer_3': 0.11883449090839714, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00019629344649626054, 'l1_Layer_2': 8.062607230306838e-05, 'l1_Layer_3': 1.1421037178277687e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 295, 'n_units_Layer_3': 290}. Best is trial 78 with value: 8.215356658226538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.69 | sMAPE for Validation Set is: 50.50% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 42.70 | sMAPE for Test Set is: 50.86% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:46:52,632]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:46:57,891]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:47:01,226]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:47:02,182]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:47:06,776]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:47:10,455]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:47:14,507]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:47:14,633]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:47:20,800]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:47:25,810]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:47:28,666]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:47:31,990]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:47:32,563]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:47:32,998]\u001b[0m Trial 176 finished with value: 12.779385258551537 and parameters: {'n_hidden': 4, 'learning_rate': 0.08790821633434125, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06278859897889366, 'dropout_rate_Layer_2': 0.2783362303449353, 'dropout_rate_Layer_3': 0.31161390876875916, 'dropout_rate_Layer_4': 0.20304805338653606, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0006003750859589256, 'l1_Layer_2': 0.02012477144998105, 'l1_Layer_3': 0.00636459617905993, 'l1_Layer_4': 0.0006345920931728391, 'n_units_Layer_1': 280, 'n_units_Layer_2': 210, 'n_units_Layer_3': 145, 'n_units_Layer_4': 240}. Best is trial 78 with value: 8.215356658226538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.78 | sMAPE for Validation Set is: 57.26% | rMAE for Validation Set is: 0.98\n",
      "MAE for Test Set is: 43.23 | sMAPE for Test Set is: 50.86% | rMAE for Test Set is: 1.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:47:42,523]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:47:42,798]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:47:48,585]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:47:49,453]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:47:55,970]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:47:56,396]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:48:01,736]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:48:08,120]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:48:14,565]\u001b[0m Trial 190 finished with value: 13.272105094481091 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033061207100698524, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08123739338021657, 'dropout_rate_Layer_2': 0.14243853708974466, 'dropout_rate_Layer_3': 0.05747400933356994, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00018856444038912255, 'l1_Layer_2': 0.004337617239909428, 'l1_Layer_3': 0.058485858059021865, 'n_units_Layer_1': 255, 'n_units_Layer_2': 90, 'n_units_Layer_3': 150}. Best is trial 78 with value: 8.215356658226538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.27 | sMAPE for Validation Set is: 61.29% | rMAE for Validation Set is: 1.02\n",
      "MAE for Test Set is: 66.78 | sMAPE for Test Set is: 102.82% | rMAE for Test Set is: 1.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:48:18,991]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:48:20,261]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:48:22,794]\u001b[0m Trial 181 finished with value: 9.627739371819805 and parameters: {'n_hidden': 3, 'learning_rate': 0.004280449689788552, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04629882309653795, 'dropout_rate_Layer_2': 0.21060630508751613, 'dropout_rate_Layer_3': 0.0918596654952373, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002479955258119086, 'l1_Layer_2': 0.00022538571845261545, 'l1_Layer_3': 1.7997934270114794e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 280, 'n_units_Layer_3': 275}. Best is trial 78 with value: 8.215356658226538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.63 | sMAPE for Validation Set is: 50.19% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 43.96 | sMAPE for Test Set is: 53.40% | rMAE for Test Set is: 1.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:48:28,090]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:48:28,647]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:48:33,143]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:48:33,418]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:48:34,293]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:48:43,101]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:48:43,409]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:48:47,948]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:48:51,239]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:48:58,066]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:49:01,021]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:49:02,351]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:49:04,393]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:49:11,956]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:49:16,429]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:49:17,225]\u001b[0m Trial 203 finished with value: 8.22669561414676 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005960573580141812, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22583794645529473, 'dropout_rate_Layer_2': 0.180437778892453, 'dropout_rate_Layer_3': 0.2500706623002635, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00026216294825870775, 'l1_Layer_2': 0.000559943247490018, 'l1_Layer_3': 1.130869511961228e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 245, 'n_units_Layer_3': 115}. Best is trial 78 with value: 8.215356658226538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.23 | sMAPE for Validation Set is: 46.41% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 22.47 | sMAPE for Test Set is: 27.48% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:49:22,617]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:49:24,239]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:49:33,165]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:49:33,548]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:49:36,961]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:49:44,328]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:49:48,349]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:49:52,182]\u001b[0m Trial 208 finished with value: 9.469452324151273 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021057621946109677, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2534205040516191, 'dropout_rate_Layer_2': 0.07860861027939486, 'dropout_rate_Layer_3': 0.12497729722845352, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.8826266504122063e-05, 'l1_Layer_2': 9.306537322833293e-05, 'l1_Layer_3': 0.007434143946860776, 'n_units_Layer_1': 130, 'n_units_Layer_2': 75, 'n_units_Layer_3': 125}. Best is trial 78 with value: 8.215356658226538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.47 | sMAPE for Validation Set is: 49.88% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 41.80 | sMAPE for Test Set is: 48.90% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:49:54,730]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:50:02,226]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:50:02,565]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:50:08,742]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:50:08,906]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.11 | sMAPE for Validation Set is: 48.62% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 26.70 | sMAPE for Test Set is: 33.35% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:50:12,378]\u001b[0m Trial 216 finished with value: 9.108838002309273 and parameters: {'n_hidden': 3, 'learning_rate': 0.008907679344794452, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1649248557597211, 'dropout_rate_Layer_2': 0.16925302087820215, 'dropout_rate_Layer_3': 0.06977464728567766, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002543878978042786, 'l1_Layer_2': 0.00011456542674341041, 'l1_Layer_3': 2.3360318011296668e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 280, 'n_units_Layer_3': 285}. Best is trial 78 with value: 8.215356658226538.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:50:17,182]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:50:25,835]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:50:27,126]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:50:41,346]\u001b[0m Trial 229 finished with value: 9.005372807238539 and parameters: {'n_hidden': 3, 'learning_rate': 0.007869340821647865, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11078129484147294, 'dropout_rate_Layer_2': 0.16965449271484656, 'dropout_rate_Layer_3': 0.07232402457729153, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00020455478198612944, 'l1_Layer_2': 0.0001622833335825613, 'l1_Layer_3': 3.4076255107227806e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 285, 'n_units_Layer_3': 285}. Best is trial 78 with value: 8.215356658226538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.01 | sMAPE for Validation Set is: 48.00% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 23.64 | sMAPE for Test Set is: 29.22% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:50:45,206]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:50:52,705]\u001b[0m Trial 228 finished with value: 8.980863786363559 and parameters: {'n_hidden': 3, 'learning_rate': 0.012531875732552874, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18831129001177505, 'dropout_rate_Layer_2': 0.19696507658834678, 'dropout_rate_Layer_3': 0.07379775611772613, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010151090398048295, 'l1_Layer_2': 0.0001827997465210457, 'l1_Layer_3': 3.403628109357334e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 280, 'n_units_Layer_3': 285}. Best is trial 78 with value: 8.215356658226538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.98 | sMAPE for Validation Set is: 48.12% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 22.54 | sMAPE for Test Set is: 27.82% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:50:57,786]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:51:04,520]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:51:06,991]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:51:10,787]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:51:15,916]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:51:16,414]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:51:19,057]\u001b[0m Trial 230 finished with value: 9.57524960046802 and parameters: {'n_hidden': 4, 'learning_rate': 0.00512112934749208, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23808652506933636, 'dropout_rate_Layer_2': 0.1907890253007087, 'dropout_rate_Layer_3': 0.20855961731920522, 'dropout_rate_Layer_4': 0.29445992417215017, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0020092225908489884, 'l1_Layer_2': 0.0030741405553975695, 'l1_Layer_3': 0.007427376396343435, 'l1_Layer_4': 0.0003113126749563268, 'n_units_Layer_1': 115, 'n_units_Layer_2': 50, 'n_units_Layer_3': 50, 'n_units_Layer_4': 290}. Best is trial 78 with value: 8.215356658226538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.58 | sMAPE for Validation Set is: 53.69% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 25.38 | sMAPE for Test Set is: 30.36% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:51:23,421]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:51:28,485]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:51:28,742]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:51:29,506]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:51:33,348]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:51:35,058]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:51:35,920]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:51:38,127]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:51:45,100]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:51:47,495]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:51:48,274]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:51:54,867]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:51:55,661]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:52:00,878]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:52:05,979]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:52:14,500]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:52:15,051]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:52:23,038]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:52:27,910]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:52:30,403]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:52:33,445]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:52:34,014]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:52:39,856]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:52:48,261]\u001b[0m Trial 259 finished with value: 9.062902026574509 and parameters: {'n_hidden': 3, 'learning_rate': 0.004211649297984984, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39488537136602836, 'dropout_rate_Layer_2': 0.14915222738348052, 'dropout_rate_Layer_3': 0.32258455343806736, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0126997879308685e-05, 'l1_Layer_2': 0.0002538972271496632, 'l1_Layer_3': 1.0121683284355176e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 275, 'n_units_Layer_3': 205}. Best is trial 78 with value: 8.215356658226538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.06 | sMAPE for Validation Set is: 48.30% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 23.11 | sMAPE for Test Set is: 28.63% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:52:52,406]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:52:55,020]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:52:58,931]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:53:07,168]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:53:10,298]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:53:10,815]\u001b[0m Trial 264 finished with value: 9.757157674495447 and parameters: {'n_hidden': 4, 'learning_rate': 0.002659862150029797, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3361628499817225, 'dropout_rate_Layer_2': 0.1810634083505644, 'dropout_rate_Layer_3': 0.14962390417105528, 'dropout_rate_Layer_4': 0.2899993469354847, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0016900697319498022, 'l1_Layer_2': 0.0017712719286538381, 'l1_Layer_3': 0.0011592739867131365, 'l1_Layer_4': 0.00023818282589662854, 'n_units_Layer_1': 110, 'n_units_Layer_2': 50, 'n_units_Layer_3': 65, 'n_units_Layer_4': 300}. Best is trial 78 with value: 8.215356658226538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.76 | sMAPE for Validation Set is: 50.01% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 24.13 | sMAPE for Test Set is: 29.19% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:53:16,489]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:53:19,281]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:53:24,052]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:53:25,080]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:53:31,734]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:53:32,154]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.72 | sMAPE for Validation Set is: 49.92% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 23.61 | sMAPE for Test Set is: 27.78% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:53:37,254]\u001b[0m Trial 265 finished with value: 9.715468862897813 and parameters: {'n_hidden': 3, 'learning_rate': 0.003153300048957397, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32484753101234676, 'dropout_rate_Layer_2': 0.09998586706104587, 'dropout_rate_Layer_3': 0.3219596480410276, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7465982216752864e-05, 'l1_Layer_2': 0.000646474288424308, 'l1_Layer_3': 2.1888690089369774e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 285, 'n_units_Layer_3': 210}. Best is trial 78 with value: 8.215356658226538.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:53:40,061]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:53:40,972]\u001b[0m Trial 270 finished with value: 10.280765834224368 and parameters: {'n_hidden': 3, 'learning_rate': 0.009565066176359962, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3406510254556594, 'dropout_rate_Layer_2': 0.19046058994183912, 'dropout_rate_Layer_3': 0.11989513298659184, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000989699003673253, 'l1_Layer_2': 0.00014236405801576235, 'l1_Layer_3': 1.1350860884952927e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 265, 'n_units_Layer_3': 280}. Best is trial 78 with value: 8.215356658226538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.28 | sMAPE for Validation Set is: 51.70% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 46.00 | sMAPE for Test Set is: 55.92% | rMAE for Test Set is: 1.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:53:41,580]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:53:46,452]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:53:51,519]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:53:55,240]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:53:58,695]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:53:58,768]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:53:59,001]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:54:06,881]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:54:08,455]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:54:08,886]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:54:14,097]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:54:19,380]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:54:23,777]\u001b[0m Trial 277 finished with value: 9.506324252491764 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009788384075392772, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3609207964749875, 'dropout_rate_Layer_2': 0.18765861706378675, 'dropout_rate_Layer_3': 0.16187656327166, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010306829828328747, 'l1_Layer_2': 0.00013944152894918447, 'l1_Layer_3': 2.612426676675224e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 255, 'n_units_Layer_3': 300}. Best is trial 78 with value: 8.215356658226538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.51 | sMAPE for Validation Set is: 51.24% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 42.74 | sMAPE for Test Set is: 50.71% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:54:28,415]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:54:29,002]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:54:34,792]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:54:36,863]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:54:37,658]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:54:41,098]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:54:42,033]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:54:45,035]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:54:47,806]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:54:49,204]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:54:56,963]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:55:06,288]\u001b[0m Trial 288 finished with value: 8.757373107953713 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010565376422773853, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11645131648550919, 'dropout_rate_Layer_2': 0.16471698317163405, 'dropout_rate_Layer_3': 0.08987267006333163, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0010463797477394481, 'l1_Layer_2': 0.0003347259994397008, 'l1_Layer_3': 1.1366705937863034e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 285, 'n_units_Layer_3': 260}. Best is trial 78 with value: 8.215356658226538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.76 | sMAPE for Validation Set is: 46.61% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 23.98 | sMAPE for Test Set is: 30.18% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:55:21,190]\u001b[0m Trial 302 finished with value: 9.229541857875297 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010627518535772157, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13250330779391908, 'dropout_rate_Layer_2': 0.16043339241921697, 'dropout_rate_Layer_3': 0.07036330954432736, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00043889580570674597, 'l1_Layer_2': 0.00034520031027923556, 'l1_Layer_3': 1.054488955007956e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 275, 'n_units_Layer_3': 300}. Best is trial 78 with value: 8.215356658226538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.23 | sMAPE for Validation Set is: 49.67% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 43.71 | sMAPE for Test Set is: 52.11% | rMAE for Test Set is: 1.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:55:24,981]\u001b[0m Trial 301 finished with value: 8.893286741943712 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007696460262465235, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.127184331640938, 'dropout_rate_Layer_2': 0.1821018657578914, 'dropout_rate_Layer_3': 0.07078586294285676, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004273457591765882, 'l1_Layer_2': 0.00021032230851841363, 'l1_Layer_3': 1.1690442297328247e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 275, 'n_units_Layer_3': 300}. Best is trial 78 with value: 8.215356658226538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.89 | sMAPE for Validation Set is: 49.61% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 45.17 | sMAPE for Test Set is: 54.80% | rMAE for Test Set is: 1.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:55:29,399]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:55:44,205]\u001b[0m Trial 300 finished with value: 8.979198034241755 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008375522054140847, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.370521839431297, 'dropout_rate_Layer_2': 0.18247769985955758, 'dropout_rate_Layer_3': 0.0887574507201328, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004336969360098282, 'l1_Layer_2': 0.00022013261738827736, 'l1_Layer_3': 1.1845203657005491e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 275, 'n_units_Layer_3': 300}. Best is trial 78 with value: 8.215356658226538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.98 | sMAPE for Validation Set is: 50.11% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 43.80 | sMAPE for Test Set is: 52.67% | rMAE for Test Set is: 1.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:55:48,616]\u001b[0m Trial 303 finished with value: 8.92815144911443 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006462276590074943, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3681472744323525, 'dropout_rate_Layer_2': 0.1835927383069142, 'dropout_rate_Layer_3': 0.09020837514383344, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0017307526024270571, 'l1_Layer_2': 0.0003148343972008413, 'l1_Layer_3': 2.3061593654267273e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 290, 'n_units_Layer_3': 250}. Best is trial 78 with value: 8.215356658226538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.93 | sMAPE for Validation Set is: 48.99% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 44.75 | sMAPE for Test Set is: 54.34% | rMAE for Test Set is: 1.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:55:52,960]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:56:12,259]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:56:17,333]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:56:24,933]\u001b[0m Trial 304 finished with value: 9.60950708844425 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013624159952834263, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2732432238062982, 'dropout_rate_Layer_2': 0.22174545465624929, 'dropout_rate_Layer_3': 0.1966562307346276, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.5128025509075244e-05, 'l1_Layer_2': 0.000553062830709297, 'l1_Layer_3': 0.00011876203615679606, 'n_units_Layer_1': 50, 'n_units_Layer_2': 275, 'n_units_Layer_3': 50}. Best is trial 78 with value: 8.215356658226538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.61 | sMAPE for Validation Set is: 49.89% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 24.53 | sMAPE for Test Set is: 30.82% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:56:38,167]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:56:42,776]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:56:48,702]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:56:52,038]\u001b[0m Trial 307 finished with value: 9.42145031346598 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014008663181250853, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28791051806879026, 'dropout_rate_Layer_2': 0.1593586868844396, 'dropout_rate_Layer_3': 0.20794818022351558, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.5841599834431002e-05, 'l1_Layer_2': 0.0014628414798407217, 'l1_Layer_3': 0.00010747346300145581, 'n_units_Layer_1': 205, 'n_units_Layer_2': 275, 'n_units_Layer_3': 55}. Best is trial 78 with value: 8.215356658226538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.42 | sMAPE for Validation Set is: 49.68% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 23.09 | sMAPE for Test Set is: 28.94% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:56:58,210]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:57:07,076]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:57:18,154]\u001b[0m Trial 312 finished with value: 8.931053466259561 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006784161097068769, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3704610722268592, 'dropout_rate_Layer_2': 0.18428015321951724, 'dropout_rate_Layer_3': 0.08437213053828271, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018202406912835182, 'l1_Layer_2': 0.0003411867623230803, 'l1_Layer_3': 1.0503650547595766e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 295, 'n_units_Layer_3': 295}. Best is trial 78 with value: 8.215356658226538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.93 | sMAPE for Validation Set is: 49.42% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 41.40 | sMAPE for Test Set is: 48.67% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:57:18,384]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:57:24,972]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:57:29,236]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:57:32,571]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:57:32,799]\u001b[0m Trial 315 finished with value: 8.923264353267621 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007065529309178097, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36376751132465135, 'dropout_rate_Layer_2': 0.1852069980058281, 'dropout_rate_Layer_3': 0.08747458548794478, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011596756936831107, 'l1_Layer_2': 0.0004354372040204902, 'l1_Layer_3': 1.0229483180407516e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 290, 'n_units_Layer_3': 295}. Best is trial 78 with value: 8.215356658226538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.92 | sMAPE for Validation Set is: 50.91% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 42.37 | sMAPE for Test Set is: 49.76% | rMAE for Test Set is: 1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:57:37,040]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:57:44,875]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:57:49,959]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:58:11,615]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:58:20,035]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:58:29,232]\u001b[0m Trial 327 finished with value: 8.9322480969975 and parameters: {'n_hidden': 3, 'learning_rate': 0.000765340669908309, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36809253260457825, 'dropout_rate_Layer_2': 0.17621612800763517, 'dropout_rate_Layer_3': 0.07629386880590679, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0016892799617658622, 'l1_Layer_2': 0.0005932518254446804, 'l1_Layer_3': 1.3306980066682838e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 300, 'n_units_Layer_3': 300}. Best is trial 78 with value: 8.215356658226538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.93 | sMAPE for Validation Set is: 50.46% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 42.62 | sMAPE for Test Set is: 50.63% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:58:36,016]\u001b[0m Trial 326 finished with value: 9.0169550763256 and parameters: {'n_hidden': 3, 'learning_rate': 0.000756352759855321, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36507926509808486, 'dropout_rate_Layer_2': 0.1753841524786047, 'dropout_rate_Layer_3': 0.07579591529221634, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001756673877759462, 'l1_Layer_2': 0.0007783425800378094, 'l1_Layer_3': 1.4293847809616284e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 300, 'n_units_Layer_3': 300}. Best is trial 78 with value: 8.215356658226538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.02 | sMAPE for Validation Set is: 50.51% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 39.77 | sMAPE for Test Set is: 46.06% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:58:40,854]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:58:44,995]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:58:50,802]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:58:53,049]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:59:01,285]\u001b[0m Trial 329 finished with value: 9.233506394592059 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013641705086371674, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2712920703651338, 'dropout_rate_Layer_2': 0.16815912650440207, 'dropout_rate_Layer_3': 0.1246434099778494, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012081641273292283, 'l1_Layer_2': 0.0006106989008083982, 'l1_Layer_3': 2.1016511093513377e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 60, 'n_units_Layer_3': 75}. Best is trial 78 with value: 8.215356658226538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.23 | sMAPE for Validation Set is: 48.27% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 24.07 | sMAPE for Test Set is: 30.84% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:59:10,040]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:59:13,060]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:59:16,452]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:59:29,246]\u001b[0m Trial 334 finished with value: 9.048574478285683 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008130466508351112, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3933738745203804, 'dropout_rate_Layer_2': 0.15138951994328348, 'dropout_rate_Layer_3': 0.06976383099254495, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0014271902175452239, 'l1_Layer_2': 0.0005147387459787791, 'l1_Layer_3': 1.7002053930295214e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 290, 'n_units_Layer_3': 300}. Best is trial 78 with value: 8.215356658226538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.05 | sMAPE for Validation Set is: 51.25% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 43.72 | sMAPE for Test Set is: 52.32% | rMAE for Test Set is: 1.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:59:39,734]\u001b[0m Trial 336 finished with value: 8.933167903974597 and parameters: {'n_hidden': 3, 'learning_rate': 0.000845751107715787, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36847883372786955, 'dropout_rate_Layer_2': 0.1533565883712592, 'dropout_rate_Layer_3': 0.06858427139805569, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0014169094586679346, 'l1_Layer_2': 0.0007187368477698722, 'l1_Layer_3': 1.5413896835917446e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 290, 'n_units_Layer_3': 300}. Best is trial 78 with value: 8.215356658226538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.93 | sMAPE for Validation Set is: 49.71% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 43.37 | sMAPE for Test Set is: 51.68% | rMAE for Test Set is: 1.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 05:59:54,344]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 05:59:57,256]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:00:01,306]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:00:01,684]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:00:11,073]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:00:13,743]\u001b[0m Trial 340 finished with value: 9.393077094152142 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008690589589062082, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3988252172694095, 'dropout_rate_Layer_2': 0.12738843736643618, 'dropout_rate_Layer_3': 0.07054599622839526, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003510783428792959, 'l1_Layer_2': 0.0006200529321839389, 'l1_Layer_3': 2.4292760512676825e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 290, 'n_units_Layer_3': 295}. Best is trial 78 with value: 8.215356658226538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.39 | sMAPE for Validation Set is: 50.07% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 40.78 | sMAPE for Test Set is: 47.62% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:00:14,616]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:00:24,145]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:00:24,760]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:00:38,878]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:01:01,072]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:01:06,807]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:01:11,341]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:01:16,037]\u001b[0m Trial 343 finished with value: 8.993169513612626 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006612623085800424, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35936805784278847, 'dropout_rate_Layer_2': 0.1278256629172663, 'dropout_rate_Layer_3': 0.04849985788951487, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0012615237452738956, 'l1_Layer_2': 0.000962642968443453, 'l1_Layer_3': 1.4124563141381189e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 295, 'n_units_Layer_3': 300}. Best is trial 78 with value: 8.215356658226538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.99 | sMAPE for Validation Set is: 48.71% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 41.50 | sMAPE for Test Set is: 48.62% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:01:16,428]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:01:17,387]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:01:26,006]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:01:29,124]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:01:33,227]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:01:35,880]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:01:42,705]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:01:47,199]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:01:53,558]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:01:59,557]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:02:02,048]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:02:05,021]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:02:08,811]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:02:25,044]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:02:30,234]\u001b[0m Trial 368 finished with value: 8.79643639242562 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005878846247271678, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37799721802271447, 'dropout_rate_Layer_2': 0.15237098077571126, 'dropout_rate_Layer_3': 0.05957035355638378, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00046706925926044354, 'l1_Layer_2': 0.00039910236802999496, 'l1_Layer_3': 1.2288101775270254e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 300, 'n_units_Layer_3': 295}. Best is trial 78 with value: 8.215356658226538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.80 | sMAPE for Validation Set is: 48.04% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 42.41 | sMAPE for Test Set is: 49.75% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:02:34,806]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:02:42,537]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:02:43,038]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:02:53,085]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:03:05,171]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:03:06,007]\u001b[0m Trial 367 finished with value: 8.932566791983357 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006848752927760744, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3314811996965256, 'dropout_rate_Layer_2': 0.08877624780734308, 'dropout_rate_Layer_3': 0.05728731778246322, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004270067290394009, 'l1_Layer_2': 0.0021425994391198865, 'l1_Layer_3': 1.211854846467794e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 300, 'n_units_Layer_3': 295}. Best is trial 78 with value: 8.215356658226538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.93 | sMAPE for Validation Set is: 49.15% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 43.51 | sMAPE for Test Set is: 51.77% | rMAE for Test Set is: 1.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:03:10,229]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:03:13,384]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:03:13,593]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:03:23,537]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:03:37,704]\u001b[0m Trial 378 finished with value: 8.885911814633934 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006619050531106632, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3733080767862447, 'dropout_rate_Layer_2': 0.0868415430368074, 'dropout_rate_Layer_3': 0.07401740346044751, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008556514871540423, 'l1_Layer_2': 0.0002890328360964728, 'l1_Layer_3': 1.382655690787301e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 275, 'n_units_Layer_3': 285}. Best is trial 78 with value: 8.215356658226538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.89 | sMAPE for Validation Set is: 48.89% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 45.24 | sMAPE for Test Set is: 54.74% | rMAE for Test Set is: 1.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:03:45,532]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:03:54,087]\u001b[0m Trial 380 finished with value: 8.83972257449545 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017627474393256172, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3286503405661636, 'dropout_rate_Layer_2': 0.1665542626882806, 'dropout_rate_Layer_3': 0.09646650623159397, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.4653005120783415e-05, 'l1_Layer_2': 0.0005994067175639927, 'l1_Layer_3': 2.0830197965919647e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 245, 'n_units_Layer_3': 95}. Best is trial 78 with value: 8.215356658226538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.84 | sMAPE for Validation Set is: 47.92% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 22.09 | sMAPE for Test Set is: 27.31% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:04:01,731]\u001b[0m Trial 374 finished with value: 8.204584872194099 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006542972839497412, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10879663807401996, 'dropout_rate_Layer_2': 0.2947927114672476, 'dropout_rate_Layer_3': 0.342176655880524, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00042570950880001603, 'l1_Layer_2': 0.0005620234023029027, 'l1_Layer_3': 0.0008333136237769897, 'n_units_Layer_1': 110, 'n_units_Layer_2': 135, 'n_units_Layer_3': 265}. Best is trial 374 with value: 8.204584872194099.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.20 | sMAPE for Validation Set is: 45.83% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 22.07 | sMAPE for Test Set is: 27.34% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:04:15,011]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:04:20,374]\u001b[0m Trial 377 finished with value: 8.911038600273065 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007866213409230559, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3826188660300853, 'dropout_rate_Layer_2': 0.16627595299569406, 'dropout_rate_Layer_3': 0.06325323971620637, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007908298521900409, 'l1_Layer_2': 0.00048304353909707997, 'l1_Layer_3': 1.2163862637101679e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 300, 'n_units_Layer_3': 290}. Best is trial 374 with value: 8.204584872194099.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.91 | sMAPE for Validation Set is: 49.30% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 44.32 | sMAPE for Test Set is: 53.80% | rMAE for Test Set is: 1.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:04:26,047]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:04:31,329]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:04:36,489]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:04:38,569]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:04:40,319]\u001b[0m Trial 385 finished with value: 9.109291986119601 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007773235084922978, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3810611817605132, 'dropout_rate_Layer_2': 0.10124087913453712, 'dropout_rate_Layer_3': 0.06561339735057414, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000938696265812008, 'l1_Layer_2': 0.00036328218720036825, 'l1_Layer_3': 1.8397796074179108e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 280, 'n_units_Layer_3': 300}. Best is trial 374 with value: 8.204584872194099.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.11 | sMAPE for Validation Set is: 48.82% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 43.55 | sMAPE for Test Set is: 51.35% | rMAE for Test Set is: 1.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:04:44,417]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:04:47,195]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:04:47,716]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:04:57,629]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:05:08,460]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:05:15,216]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:05:17,972]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:05:23,992]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:05:27,660]\u001b[0m Trial 394 finished with value: 9.302037177458475 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017963155043513163, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35398412186391043, 'dropout_rate_Layer_2': 0.16936502096557196, 'dropout_rate_Layer_3': 0.042023900399000474, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.606380799797961e-05, 'l1_Layer_2': 0.0017991088778083015, 'l1_Layer_3': 4.9772805038104976e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 170, 'n_units_Layer_3': 100}. Best is trial 374 with value: 8.204584872194099.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.30 | sMAPE for Validation Set is: 48.32% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 23.31 | sMAPE for Test Set is: 28.82% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:05:33,001]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:05:52,469]\u001b[0m Trial 400 finished with value: 8.93117022455977 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007439517882336822, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39167975706554176, 'dropout_rate_Layer_2': 0.15080422685460917, 'dropout_rate_Layer_3': 0.07206246160441122, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0012101194887723342, 'l1_Layer_2': 0.000525251430623574, 'l1_Layer_3': 1.8450674008661754e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 295, 'n_units_Layer_3': 295}. Best is trial 374 with value: 8.204584872194099.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.93 | sMAPE for Validation Set is: 50.92% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 43.91 | sMAPE for Test Set is: 52.24% | rMAE for Test Set is: 1.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:06:01,706]\u001b[0m Trial 401 finished with value: 10.465940238028736 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012818677397105822, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3592764410151571, 'dropout_rate_Layer_2': 0.15009800605573465, 'dropout_rate_Layer_3': 0.08188731073523652, 'dropout_rate_Layer_4': 0.39670247837199357, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005881016990945349, 'l1_Layer_2': 3.9126895941419996e-05, 'l1_Layer_3': 0.008775378305321704, 'l1_Layer_4': 0.00123193653921127, 'n_units_Layer_1': 140, 'n_units_Layer_2': 70, 'n_units_Layer_3': 105, 'n_units_Layer_4': 210}. Best is trial 374 with value: 8.204584872194099.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.47 | sMAPE for Validation Set is: 52.35% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 38.97 | sMAPE for Test Set is: 44.47% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:06:02,068]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:06:06,820]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:06:10,693]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:06:13,381]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:06:16,280]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:06:20,985]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:06:31,661]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:06:38,394]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:06:52,169]\u001b[0m Trial 411 finished with value: 14.105381115999284 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018289225092843018, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20677057179476432, 'dropout_rate_Layer_2': 0.17448908578086453, 'dropout_rate_Layer_3': 0.15560862876217266, 'dropout_rate_Layer_4': 0.2305124464735412, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0012655331539529894, 'l1_Layer_2': 0.0051757796886647564, 'l1_Layer_3': 2.263733696052193e-05, 'l1_Layer_4': 0.0001579763320079808, 'n_units_Layer_1': 100, 'n_units_Layer_2': 65, 'n_units_Layer_3': 125, 'n_units_Layer_4': 280}. Best is trial 374 with value: 8.204584872194099.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.11 | sMAPE for Validation Set is: 65.28% | rMAE for Validation Set is: 1.08\n",
      "MAE for Test Set is: 70.45 | sMAPE for Test Set is: 113.62% | rMAE for Test Set is: 2.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:06:57,065]\u001b[0m Trial 404 finished with value: 8.854348499178471 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007519270495265655, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3918398136020141, 'dropout_rate_Layer_2': 0.14992974958621333, 'dropout_rate_Layer_3': 0.08318239015984763, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0012174610797009678, 'l1_Layer_2': 0.0004717741235683769, 'l1_Layer_3': 1.7391445218798603e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 295, 'n_units_Layer_3': 110}. Best is trial 374 with value: 8.204584872194099.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.85 | sMAPE for Validation Set is: 47.81% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 42.42 | sMAPE for Test Set is: 49.64% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:07:01,670]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:07:09,536]\u001b[0m Trial 407 finished with value: 8.914781583208201 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007341195922485196, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35120051698121213, 'dropout_rate_Layer_2': 0.07347618054732037, 'dropout_rate_Layer_3': 0.07412941505802109, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0012388922514819565, 'l1_Layer_2': 0.0004874835731616377, 'l1_Layer_3': 1.2313828114892878e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 300, 'n_units_Layer_3': 300}. Best is trial 374 with value: 8.204584872194099.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.91 | sMAPE for Validation Set is: 48.89% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 42.56 | sMAPE for Test Set is: 50.47% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:07:14,470]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:07:17,030]\u001b[0m Trial 408 finished with value: 9.00078779303596 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005662916197235862, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3918121601002251, 'dropout_rate_Layer_2': 0.1480091487360859, 'dropout_rate_Layer_3': 0.07138444142666733, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001217962816188694, 'l1_Layer_2': 0.0004649169894271084, 'l1_Layer_3': 1.285162201403489e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 300, 'n_units_Layer_3': 300}. Best is trial 374 with value: 8.204584872194099.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.00 | sMAPE for Validation Set is: 52.21% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 42.31 | sMAPE for Test Set is: 50.18% | rMAE for Test Set is: 1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:07:20,032]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:07:25,678]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:07:26,443]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:07:29,004]\u001b[0m Trial 412 finished with value: 9.1492155414864 and parameters: {'n_hidden': 3, 'learning_rate': 0.002447936336879467, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39515247909893925, 'dropout_rate_Layer_2': 0.18616925648372198, 'dropout_rate_Layer_3': 0.018288515366942037, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0799601029362856e-05, 'l1_Layer_2': 0.003523644795575866, 'l1_Layer_3': 5.072034000890906e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 245, 'n_units_Layer_3': 100}. Best is trial 374 with value: 8.204584872194099.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.15 | sMAPE for Validation Set is: 48.23% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 22.63 | sMAPE for Test Set is: 28.06% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:07:35,926]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:07:48,292]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:07:54,057]\u001b[0m Trial 421 finished with value: 8.765889047890566 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005817060093957773, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3651461316314577, 'dropout_rate_Layer_2': 0.1480682199380325, 'dropout_rate_Layer_3': 0.07905633269308321, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001002124004561728, 'l1_Layer_2': 0.0004255863678831103, 'l1_Layer_3': 1.4151913680990464e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 295, 'n_units_Layer_3': 295}. Best is trial 374 with value: 8.204584872194099.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.77 | sMAPE for Validation Set is: 48.44% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 44.34 | sMAPE for Test Set is: 53.09% | rMAE for Test Set is: 1.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:07:59,038]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:08:03,167]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:08:15,708]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:08:20,780]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:08:24,966]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:08:25,990]\u001b[0m Trial 420 finished with value: 8.770907593804482 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005843574935633265, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3847028622507103, 'dropout_rate_Layer_2': 0.14068254948485354, 'dropout_rate_Layer_3': 0.07624157181956867, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009680636292373722, 'l1_Layer_2': 0.00044479677523054725, 'l1_Layer_3': 1.488625112041997e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 295, 'n_units_Layer_3': 295}. Best is trial 374 with value: 8.204584872194099.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.77 | sMAPE for Validation Set is: 50.28% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 42.61 | sMAPE for Test Set is: 50.37% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:08:51,989]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:08:56,985]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:09:00,159]\u001b[0m Trial 426 finished with value: 8.801812282159661 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006433391737220141, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37058624289401654, 'dropout_rate_Layer_2': 0.16796481198877392, 'dropout_rate_Layer_3': 0.08966245115477912, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0014074824099546456, 'l1_Layer_2': 0.00030701361920424975, 'l1_Layer_3': 1.443045144791657e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 290, 'n_units_Layer_3': 90}. Best is trial 374 with value: 8.204584872194099.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.80 | sMAPE for Validation Set is: 51.01% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 41.82 | sMAPE for Test Set is: 49.19% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:09:03,504]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:09:06,848]\u001b[0m Trial 423 finished with value: 8.807436712700513 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005747684941996389, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35378257432193844, 'dropout_rate_Layer_2': 0.10299930255412391, 'dropout_rate_Layer_3': 0.07690243679960351, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0021438860180163855, 'l1_Layer_2': 0.0005739225435994579, 'l1_Layer_3': 1.4154271577185811e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 295, 'n_units_Layer_3': 295}. Best is trial 374 with value: 8.204584872194099.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.81 | sMAPE for Validation Set is: 47.73% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 41.61 | sMAPE for Test Set is: 48.86% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:09:18,500]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:09:24,187]\u001b[0m Trial 429 finished with value: 9.668710232554982 and parameters: {'n_hidden': 4, 'learning_rate': 0.007072513174495249, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02546559940843531, 'dropout_rate_Layer_2': 0.10546359206758678, 'dropout_rate_Layer_3': 0.06119902357339391, 'dropout_rate_Layer_4': 0.12225947228778478, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.003619962748796177, 'l1_Layer_2': 0.0013057901374145854, 'l1_Layer_3': 0.00395607564790312, 'l1_Layer_4': 0.0003503939093168801, 'n_units_Layer_1': 240, 'n_units_Layer_2': 225, 'n_units_Layer_3': 110, 'n_units_Layer_4': 50}. Best is trial 374 with value: 8.204584872194099.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.67 | sMAPE for Validation Set is: 49.56% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 35.93 | sMAPE for Test Set is: 40.65% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:09:28,580]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:09:33,812]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:09:37,004]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:09:40,495]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:09:41,314]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:09:46,446]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:09:49,593]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:10:03,260]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:10:08,371]\u001b[0m Trial 434 finished with value: 9.200893037743251 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007916690716980785, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36492039073414345, 'dropout_rate_Layer_2': 0.1552806667270262, 'dropout_rate_Layer_3': 0.08305213937112264, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001233368170301126, 'l1_Layer_2': 0.000303393148376593, 'l1_Layer_3': 1.3041570710644519e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 290, 'n_units_Layer_3': 290}. Best is trial 374 with value: 8.204584872194099.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.20 | sMAPE for Validation Set is: 50.48% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 40.93 | sMAPE for Test Set is: 47.84% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:10:12,616]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:10:18,827]\u001b[0m Trial 435 finished with value: 8.930776973649612 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005414583021479513, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33002351860133516, 'dropout_rate_Layer_2': 0.0926132803317581, 'dropout_rate_Layer_3': 0.09686011228981006, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001230511486036724, 'l1_Layer_2': 0.00029341392057193424, 'l1_Layer_3': 1.324689189553574e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 295, 'n_units_Layer_3': 95}. Best is trial 374 with value: 8.204584872194099.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.93 | sMAPE for Validation Set is: 51.26% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 42.02 | sMAPE for Test Set is: 49.72% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:10:22,702]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:10:23,297]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:10:29,055]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:10:33,341]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:10:33,634]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:10:49,749]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:10:51,962]\u001b[0m Trial 444 finished with value: 8.960045229592737 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006397031634495904, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.344108223519705, 'dropout_rate_Layer_2': 0.0784141736054557, 'dropout_rate_Layer_3': 0.08884462244055873, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0016962886421579815, 'l1_Layer_2': 0.00024355672159184004, 'l1_Layer_3': 1.391457098842939e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 290, 'n_units_Layer_3': 290}. Best is trial 374 with value: 8.204584872194099.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.96 | sMAPE for Validation Set is: 49.74% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 39.81 | sMAPE for Test Set is: 46.18% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:10:56,551]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:11:01,570]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:11:03,083]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:11:08,395]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:11:12,406]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:11:17,783]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:11:22,006]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:11:24,658]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:11:29,868]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:11:34,905]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:11:39,554]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:11:44,638]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:12:00,265]\u001b[0m Trial 465 finished with value: 8.693962055434065 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006017376786257399, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.357874752363611, 'dropout_rate_Layer_2': 0.08931227987763916, 'dropout_rate_Layer_3': 0.10109929212613428, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001070289072429186, 'l1_Layer_2': 0.00029114625197164466, 'l1_Layer_3': 1.1824146923904789e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 290, 'n_units_Layer_3': 100}. Best is trial 374 with value: 8.204584872194099.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.69 | sMAPE for Validation Set is: 48.05% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 42.69 | sMAPE for Test Set is: 50.32% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:12:04,729]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:12:09,628]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:12:14,023]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:12:18,608]\u001b[0m Trial 467 finished with value: 8.87547347631641 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016171422329711675, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37660253777302194, 'dropout_rate_Layer_2': 0.13673185172039135, 'dropout_rate_Layer_3': 0.04059208330981576, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001447558398199468, 'l1_Layer_2': 0.0002251440504269822, 'l1_Layer_3': 1.5811270116932678e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 110, 'n_units_Layer_3': 140}. Best is trial 374 with value: 8.204584872194099.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:12:18,634]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.88 | sMAPE for Validation Set is: 47.16% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 25.81 | sMAPE for Test Set is: 29.31% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:12:24,763]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.46 | sMAPE for Validation Set is: 49.71% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 22.72 | sMAPE for Test Set is: 27.57% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:12:27,310]\u001b[0m Trial 466 finished with value: 9.461422407959722 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016230932385932308, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37027486521377145, 'dropout_rate_Layer_2': 0.13793289971472045, 'dropout_rate_Layer_3': 0.005417481797018897, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012417448158565773, 'l1_Layer_2': 0.0002294422808724159, 'l1_Layer_3': 1.4883580540282584e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 145, 'n_units_Layer_3': 135}. Best is trial 374 with value: 8.204584872194099.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:12:30,845]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:12:41,752]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:12:45,953]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:12:50,763]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:12:55,041]\u001b[0m Trial 475 finished with value: 9.02420179435947 and parameters: {'n_hidden': 3, 'learning_rate': 0.002498507246849179, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3966405798475902, 'dropout_rate_Layer_2': 0.11132498267076232, 'dropout_rate_Layer_3': 0.03814056092225558, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002968553082969181, 'l1_Layer_2': 9.543988879463123e-05, 'l1_Layer_3': 1.618424779221415e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 110, 'n_units_Layer_3': 110}. Best is trial 374 with value: 8.204584872194099.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.02 | sMAPE for Validation Set is: 47.77% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 41.92 | sMAPE for Test Set is: 48.65% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:12:59,168]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:12:59,894]\u001b[0m Trial 459 finished with value: 9.312511434742115 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008836528297185045, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3761549544374896, 'dropout_rate_Layer_2': 0.2029932965907306, 'dropout_rate_Layer_3': 0.0015090694488323897, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002536373138689951, 'l1_Layer_2': 0.0011442383309137817, 'l1_Layer_3': 1.5057587332569144e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 250, 'n_units_Layer_3': 85}. Best is trial 374 with value: 8.204584872194099.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.31 | sMAPE for Validation Set is: 49.46% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 25.07 | sMAPE for Test Set is: 29.16% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:13:08,157]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:13:19,955]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:13:24,096]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:13:28,013]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:13:28,326]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:13:36,703]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:13:42,265]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:13:43,431]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:13:47,258]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.41 | sMAPE for Validation Set is: 49.64% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 45.40 | sMAPE for Test Set is: 54.79% | rMAE for Test Set is: 1.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:13:49,438]\u001b[0m Trial 479 finished with value: 9.405528630541783 and parameters: {'n_hidden': 3, 'learning_rate': 0.009286519365613755, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3989115372468194, 'dropout_rate_Layer_2': 0.1045412465777637, 'dropout_rate_Layer_3': 0.03653395110142761, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015257039800070153, 'l1_Layer_2': 8.569868600429445e-05, 'l1_Layer_3': 2.271237366556834e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 105, 'n_units_Layer_3': 115}. Best is trial 374 with value: 8.204584872194099.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:13:53,143]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:13:53,617]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:14:00,164]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:14:04,985]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:14:07,008]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:14:07,552]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:14:13,238]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:14:19,709]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:14:24,556]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:14:41,556]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:14:45,983]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:14:50,422]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:14:54,989]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:14:59,400]\u001b[0m Trial 495 finished with value: 9.003641898650935 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005810403534306506, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3425274385853457, 'dropout_rate_Layer_2': 0.18440484663805773, 'dropout_rate_Layer_3': 0.05452818519520687, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0016986442703986156, 'l1_Layer_2': 0.0004919952701765042, 'l1_Layer_3': 1.001846561508115e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 295, 'n_units_Layer_3': 295}. Best is trial 374 with value: 8.204584872194099.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.00 | sMAPE for Validation Set is: 49.94% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 43.11 | sMAPE for Test Set is: 51.53% | rMAE for Test Set is: 1.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:15:04,138]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:15:04,474]\u001b[0m Trial 498 finished with value: 8.930634005915586 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005685219764160204, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34180280986545475, 'dropout_rate_Layer_2': 0.18277888013708993, 'dropout_rate_Layer_3': 0.08756778519926471, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0015716415085846285, 'l1_Layer_2': 0.0005294798183423607, 'l1_Layer_3': 1.1454434409177261e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 295, 'n_units_Layer_3': 290}. Best is trial 374 with value: 8.204584872194099.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.93 | sMAPE for Validation Set is: 49.87% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 41.93 | sMAPE for Test Set is: 49.55% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:15:10,835]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:15:12,071]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:15:18,069]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:15:24,839]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:15:35,729]\u001b[0m Trial 499 finished with value: 9.192012323408129 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005887444876820645, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3831239210297301, 'dropout_rate_Layer_2': 0.18338675520160092, 'dropout_rate_Layer_3': 0.08887407075592178, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0015757086750455057, 'l1_Layer_2': 0.00032758542892670197, 'l1_Layer_3': 1.0269055726236482e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 295, 'n_units_Layer_3': 290}. Best is trial 374 with value: 8.204584872194099.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.19 | sMAPE for Validation Set is: 49.73% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 41.96 | sMAPE for Test Set is: 49.87% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:15:39,463]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:15:42,466]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:15:45,969]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:15:52,138]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:15:56,443]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:16:09,539]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:16:18,695]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:16:19,508]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:16:25,165]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:16:29,673]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:16:35,247]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:16:35,576]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:16:38,033]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:16:44,320]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:16:44,907]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:16:52,458]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:16:57,069]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:17:01,299]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:17:05,645]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:17:10,868]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:17:16,503]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:17:22,151]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:17:27,169]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:17:30,639]\u001b[0m Trial 525 finished with value: 8.878944861398613 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009027933262103012, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3403733282028625, 'dropout_rate_Layer_2': 0.18938177721758306, 'dropout_rate_Layer_3': 0.08154588080092948, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0017235166088892366, 'l1_Layer_2': 0.0005839344060245482, 'l1_Layer_3': 1.7213317652321028e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 275, 'n_units_Layer_3': 290}. Best is trial 374 with value: 8.204584872194099.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.88 | sMAPE for Validation Set is: 48.26% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 42.61 | sMAPE for Test Set is: 50.22% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:17:32,986]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:17:36,105]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:17:36,908]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:17:39,473]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:17:45,549]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:17:49,199]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:17:56,177]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:18:06,529]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:18:10,359]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:18:12,932]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:18:15,059]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:18:20,964]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:18:24,830]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:18:25,555]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:18:26,300]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:18:32,461]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:18:38,139]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:18:42,568]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:18:42,684]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:18:43,307]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:18:50,837]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:18:54,339]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:18:54,840]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:18:57,136]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:19:02,643]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:19:02,853]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:19:04,285]\u001b[0m Trial 546 finished with value: 8.333197536121643 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016666618838907061, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3871336627674645, 'dropout_rate_Layer_2': 0.18911306418500465, 'dropout_rate_Layer_3': 0.07087065338779631, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0750250220066176e-05, 'l1_Layer_2': 0.00033686295263884346, 'l1_Layer_3': 8.556877819705029e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 155, 'n_units_Layer_3': 125}. Best is trial 374 with value: 8.204584872194099.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.33 | sMAPE for Validation Set is: 46.46% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 25.53 | sMAPE for Test Set is: 31.07% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:19:07,768]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:19:14,177]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:19:16,519]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:19:17,500]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:19:17,962]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:19:27,272]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:19:27,445]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:19:28,681]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:19:34,110]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:19:37,793]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:19:41,935]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:19:42,091]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:19:47,105]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:19:51,629]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:19:51,842]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:19:52,313]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:19:54,247]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:20:02,013]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:20:05,397]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:20:08,416]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:20:12,258]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:20:12,501]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:20:24,237]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:20:34,909]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:20:39,430]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:20:40,055]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:20:40,312]\u001b[0m Trial 586 finished with value: 8.917490637805193 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005671365133472138, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3347151530600024, 'dropout_rate_Layer_2': 0.07066623018994324, 'dropout_rate_Layer_3': 0.08689271272213489, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.1958379320549704e-05, 'l1_Layer_2': 0.0002899389763276219, 'l1_Layer_3': 1.2078886726107797e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 275, 'n_units_Layer_3': 295}. Best is trial 374 with value: 8.204584872194099.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.92 | sMAPE for Validation Set is: 49.24% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 43.41 | sMAPE for Test Set is: 51.69% | rMAE for Test Set is: 1.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:20:50,930]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:20:51,888]\u001b[0m Trial 584 finished with value: 8.328526431867783 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015883255289512001, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34541889551797983, 'dropout_rate_Layer_2': 0.21641566513193633, 'dropout_rate_Layer_3': 0.030456006446791403, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.053835560676839e-05, 'l1_Layer_2': 0.004202438609912828, 'l1_Layer_3': 4.974894314064842e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 175, 'n_units_Layer_3': 130}. Best is trial 374 with value: 8.204584872194099.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.33 | sMAPE for Validation Set is: 48.41% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 23.92 | sMAPE for Test Set is: 29.11% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:20:59,852]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:21:00,731]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:21:08,698]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:21:11,944]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:21:19,980]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:21:23,308]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:21:29,049]\u001b[0m Trial 595 finished with value: 8.35095477552052 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012319187678744884, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37592541191147066, 'dropout_rate_Layer_2': 0.21348325362090198, 'dropout_rate_Layer_3': 0.02871412886461267, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0333541189767787e-05, 'l1_Layer_2': 0.00026003619261047174, 'l1_Layer_3': 6.826280198351538e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 150, 'n_units_Layer_3': 135}. Best is trial 374 with value: 8.204584872194099.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.35 | sMAPE for Validation Set is: 47.66% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 23.20 | sMAPE for Test Set is: 28.03% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:21:34,401]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:21:38,484]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:21:44,324]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:21:44,462]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:21:44,566]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:21:56,995]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:22:05,031]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:22:06,756]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:22:10,523]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:22:10,902]\u001b[0m Trial 590 finished with value: 8.20801621805299 and parameters: {'n_hidden': 3, 'learning_rate': 0.001876735655020168, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02561065497643468, 'dropout_rate_Layer_2': 0.19002555485197564, 'dropout_rate_Layer_3': 0.2638508976106342, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00034258159053988577, 'l1_Layer_2': 0.0005221928635736782, 'l1_Layer_3': 7.52827438429487e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 75, 'n_units_Layer_3': 270}. Best is trial 374 with value: 8.204584872194099.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.21 | sMAPE for Validation Set is: 45.91% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 21.34 | sMAPE for Test Set is: 26.30% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:22:18,901]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:22:21,469]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:22:21,508]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:22:23,797]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:22:32,176]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:22:32,654]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:22:39,714]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:22:48,806]\u001b[0m Trial 612 finished with value: 8.34415168526521 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011601527375581554, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3773360494937374, 'dropout_rate_Layer_2': 0.2662533805382066, 'dropout_rate_Layer_3': 0.023655060516701278, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0142934239500298e-05, 'l1_Layer_2': 0.00011276634850574021, 'l1_Layer_3': 0.00014567004052517797, 'n_units_Layer_1': 120, 'n_units_Layer_2': 155, 'n_units_Layer_3': 125}. Best is trial 374 with value: 8.204584872194099.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.34 | sMAPE for Validation Set is: 47.48% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 23.80 | sMAPE for Test Set is: 29.06% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:22:51,408]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:22:54,107]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:22:57,471]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:22:59,751]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:23:00,262]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:23:06,344]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:23:09,159]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:23:09,244]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:23:10,584]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:23:17,487]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.43 | sMAPE for Validation Set is: 46.98% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 22.95 | sMAPE for Test Set is: 27.79% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:23:19,500]\u001b[0m Trial 617 finished with value: 8.427660782184164 and parameters: {'n_hidden': 3, 'learning_rate': 0.004791331759741729, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3763698089509631, 'dropout_rate_Layer_2': 0.2148915521662627, 'dropout_rate_Layer_3': 0.02683773581751423, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0902056672700842e-05, 'l1_Layer_2': 0.00844885862303736, 'l1_Layer_3': 0.00015031832755534752, 'n_units_Layer_1': 120, 'n_units_Layer_2': 150, 'n_units_Layer_3': 135}. Best is trial 374 with value: 8.204584872194099.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:23:24,271]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:23:24,826]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:23:31,411]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:23:54,751]\u001b[0m Trial 630 finished with value: 8.959736061016567 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016013211323884858, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34638897204965857, 'dropout_rate_Layer_2': 0.2157308624560907, 'dropout_rate_Layer_3': 0.013371931069158943, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.6172267050629345e-05, 'l1_Layer_2': 0.013301044883432193, 'l1_Layer_3': 0.0005038962031214061, 'n_units_Layer_1': 185, 'n_units_Layer_2': 160, 'n_units_Layer_3': 125}. Best is trial 374 with value: 8.204584872194099.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.96 | sMAPE for Validation Set is: 50.89% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 23.52 | sMAPE for Test Set is: 28.56% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:23:57,990]\u001b[0m Trial 626 finished with value: 8.29817286167325 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009125497311216667, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34588809447115787, 'dropout_rate_Layer_2': 0.23754814453818274, 'dropout_rate_Layer_3': 0.07889140783627278, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7195065364374907e-05, 'l1_Layer_2': 0.00019162654287241477, 'l1_Layer_3': 9.779894217107624e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 160, 'n_units_Layer_3': 120}. Best is trial 374 with value: 8.204584872194099.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.30 | sMAPE for Validation Set is: 47.88% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 22.43 | sMAPE for Test Set is: 27.57% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:24:02,512]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:24:11,619]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:24:18,458]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.92 | sMAPE for Validation Set is: 49.79% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 43.97 | sMAPE for Test Set is: 52.41% | rMAE for Test Set is: 1.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:24:20,675]\u001b[0m Trial 633 finished with value: 8.923014949887676 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005586786543825066, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37522585486619303, 'dropout_rate_Layer_2': 0.14475783394638084, 'dropout_rate_Layer_3': 0.05883325318342701, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005711307691501908, 'l1_Layer_2': 0.0005366899819212802, 'l1_Layer_3': 1.6087194506396165e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 300, 'n_units_Layer_3': 300}. Best is trial 374 with value: 8.204584872194099.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:24:24,387]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:24:31,182]\u001b[0m Trial 635 finished with value: 8.250742986088614 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005856257392333077, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3305049087620708, 'dropout_rate_Layer_2': 0.2914652427267695, 'dropout_rate_Layer_3': 0.07310204843879425, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2977467576934095e-05, 'l1_Layer_2': 0.00015576409768996869, 'l1_Layer_3': 0.0002739409737086844, 'n_units_Layer_1': 80, 'n_units_Layer_2': 150, 'n_units_Layer_3': 135}. Best is trial 374 with value: 8.204584872194099.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.25 | sMAPE for Validation Set is: 46.12% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 23.40 | sMAPE for Test Set is: 28.26% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:24:37,355]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.17 | sMAPE for Validation Set is: 47.28% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 23.38 | sMAPE for Test Set is: 28.88% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:24:40,011]\u001b[0m Trial 628 finished with value: 8.170843940466476 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009463298545557601, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3779604769751418, 'dropout_rate_Layer_2': 0.24035321884592595, 'dropout_rate_Layer_3': 0.012147774450633517, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.6237448602177436e-05, 'l1_Layer_2': 0.00017294878021622724, 'l1_Layer_3': 0.00043999790092909995, 'n_units_Layer_1': 185, 'n_units_Layer_2': 150, 'n_units_Layer_3': 120}. Best is trial 628 with value: 8.170843940466476.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:24:40,156]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:24:41,625]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:24:51,591]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:24:51,997]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:24:57,270]\u001b[0m Trial 638 finished with value: 8.895285649698975 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005703486310249929, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3461675579433897, 'dropout_rate_Layer_2': 0.14285585240525633, 'dropout_rate_Layer_3': 0.04491782647647963, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006125613816458353, 'l1_Layer_2': 0.0006978831073460321, 'l1_Layer_3': 2.225215637956738e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 300, 'n_units_Layer_3': 295}. Best is trial 628 with value: 8.170843940466476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.90 | sMAPE for Validation Set is: 49.43% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 42.42 | sMAPE for Test Set is: 50.02% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:25:02,607]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:25:08,604]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:25:08,722]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:25:26,845]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:25:34,325]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:25:38,967]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:25:45,585]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:25:51,761]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:25:52,330]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:25:52,607]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:25:53,200]\u001b[0m Trial 645 finished with value: 8.940883950343979 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006487415497870828, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3553721898480732, 'dropout_rate_Layer_2': 0.13496188401896725, 'dropout_rate_Layer_3': 0.058288551132635494, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007168765903925208, 'l1_Layer_2': 0.0008632658521500223, 'l1_Layer_3': 1.698560631952803e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 300, 'n_units_Layer_3': 290}. Best is trial 628 with value: 8.170843940466476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.94 | sMAPE for Validation Set is: 48.48% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 42.24 | sMAPE for Test Set is: 49.57% | rMAE for Test Set is: 1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:26:00,343]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:26:06,605]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:26:06,934]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:26:11,579]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:26:13,261]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:26:16,071]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:26:20,852]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:26:21,041]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:26:25,412]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:26:28,886]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:26:31,649]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:26:32,198]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:26:33,275]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:26:39,220]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:26:42,715]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:26:46,819]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:26:47,612]\u001b[0m Trial 661 finished with value: 9.888296920667674 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014454828336119602, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2729746042902605, 'dropout_rate_Layer_2': 0.02680126109313424, 'dropout_rate_Layer_3': 0.34197028627548853, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.311292779062735e-05, 'l1_Layer_2': 1.9801943013673746e-05, 'l1_Layer_3': 0.010921762955124235, 'n_units_Layer_1': 85, 'n_units_Layer_2': 140, 'n_units_Layer_3': 110}. Best is trial 628 with value: 8.170843940466476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.89 | sMAPE for Validation Set is: 50.34% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 39.37 | sMAPE for Test Set is: 45.15% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:26:48,194]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:26:55,548]\u001b[0m Trial 671 finished with value: 8.510808742596502 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009234757346597905, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3206442717567706, 'dropout_rate_Layer_2': 0.3131521769816665, 'dropout_rate_Layer_3': 0.11471674864670003, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5412987809270332e-05, 'l1_Layer_2': 0.0003176721955501233, 'l1_Layer_3': 0.00024634213190249227, 'n_units_Layer_1': 115, 'n_units_Layer_2': 185, 'n_units_Layer_3': 120}. Best is trial 628 with value: 8.170843940466476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.51 | sMAPE for Validation Set is: 47.47% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 25.11 | sMAPE for Test Set is: 31.09% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:27:01,456]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:27:01,918]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:27:07,958]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:27:08,809]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:27:14,247]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:27:17,728]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:27:23,519]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:27:24,234]\u001b[0m Trial 674 finished with value: 8.78093657667082 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006212114862509408, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36228082867284117, 'dropout_rate_Layer_2': 0.1432401822804135, 'dropout_rate_Layer_3': 0.04896799680370205, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003471532580639065, 'l1_Layer_2': 0.00047486057497010654, 'l1_Layer_3': 1.4061692678286194e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 300, 'n_units_Layer_3': 215}. Best is trial 628 with value: 8.170843940466476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.78 | sMAPE for Validation Set is: 49.71% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 43.35 | sMAPE for Test Set is: 51.45% | rMAE for Test Set is: 1.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:27:29,133]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:27:32,199]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:27:38,139]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:27:45,260]\u001b[0m Trial 677 finished with value: 8.267551571311587 and parameters: {'n_hidden': 3, 'learning_rate': 0.001854140021648699, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12994242553204982, 'dropout_rate_Layer_2': 0.34233808113062986, 'dropout_rate_Layer_3': 0.2457105974020613, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00041082397056422664, 'l1_Layer_2': 0.001096731923963907, 'l1_Layer_3': 0.002204091175775191, 'n_units_Layer_1': 265, 'n_units_Layer_2': 70, 'n_units_Layer_3': 115}. Best is trial 628 with value: 8.170843940466476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.27 | sMAPE for Validation Set is: 46.60% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 22.64 | sMAPE for Test Set is: 27.53% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:27:49,966]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:27:56,551]\u001b[0m Trial 686 finished with value: 8.20398107008654 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009112575568812135, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3206352155881862, 'dropout_rate_Layer_2': 0.34465792734455786, 'dropout_rate_Layer_3': 0.11390080847032305, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.06838565728901e-05, 'l1_Layer_2': 0.00030017119697473715, 'l1_Layer_3': 0.00020476043258910257, 'n_units_Layer_1': 95, 'n_units_Layer_2': 150, 'n_units_Layer_3': 130}. Best is trial 628 with value: 8.170843940466476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.20 | sMAPE for Validation Set is: 46.09% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 24.88 | sMAPE for Test Set is: 30.38% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:28:00,245]\u001b[0m Trial 688 finished with value: 9.02685357558376 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028862145652263074, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06496147474062346, 'dropout_rate_Layer_2': 0.0018060555642534226, 'dropout_rate_Layer_3': 0.376792673742294, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.851886787258329e-05, 'l1_Layer_2': 0.0001218977921031814, 'l1_Layer_3': 0.004944057836321342, 'n_units_Layer_1': 260, 'n_units_Layer_2': 160, 'n_units_Layer_3': 90}. Best is trial 628 with value: 8.170843940466476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.03 | sMAPE for Validation Set is: 49.55% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 26.07 | sMAPE for Test Set is: 30.23% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:28:05,788]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:28:06,708]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:28:13,306]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.24 | sMAPE for Validation Set is: 46.58% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 24.49 | sMAPE for Test Set is: 29.79% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:28:16,209]\u001b[0m Trial 690 finished with value: 8.236139427055583 and parameters: {'n_hidden': 3, 'learning_rate': 0.000875936089054375, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32049983969286006, 'dropout_rate_Layer_2': 0.3197151392502568, 'dropout_rate_Layer_3': 0.05121914979659417, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.154092685446283e-05, 'l1_Layer_2': 0.0003052755393211078, 'l1_Layer_3': 0.00024501366182520746, 'n_units_Layer_1': 215, 'n_units_Layer_2': 150, 'n_units_Layer_3': 130}. Best is trial 628 with value: 8.170843940466476.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:28:20,104]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:28:22,699]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:28:32,752]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:28:36,750]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:28:37,619]\u001b[0m Trial 697 finished with value: 9.642698111852342 and parameters: {'n_hidden': 3, 'learning_rate': 0.002795876944708651, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04003817881353253, 'dropout_rate_Layer_2': 0.009516805234949743, 'dropout_rate_Layer_3': 0.37626364215024044, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.782771862718744e-05, 'l1_Layer_2': 0.0002268173240104101, 'l1_Layer_3': 0.012831449375217883, 'n_units_Layer_1': 300, 'n_units_Layer_2': 190, 'n_units_Layer_3': 70}. Best is trial 628 with value: 8.170843940466476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.64 | sMAPE for Validation Set is: 49.51% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 25.94 | sMAPE for Test Set is: 30.11% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:28:43,283]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:28:43,814]\u001b[0m Trial 691 finished with value: 9.13471605414516 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006063235303188211, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3920248712306598, 'dropout_rate_Layer_2': 0.058854381698667885, 'dropout_rate_Layer_3': 0.27450542139323836, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00034400248830943617, 'l1_Layer_2': 0.00039700015987624153, 'l1_Layer_3': 1.6528810457247498e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 300, 'n_units_Layer_3': 280}. Best is trial 628 with value: 8.170843940466476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.13 | sMAPE for Validation Set is: 51.54% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 43.31 | sMAPE for Test Set is: 51.37% | rMAE for Test Set is: 1.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:28:44,021]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:28:54,031]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:28:54,131]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:29:01,269]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:29:01,442]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:29:08,174]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:29:11,846]\u001b[0m Trial 702 finished with value: 8.07295418478348 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012149822317339208, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30207797596325114, 'dropout_rate_Layer_2': 0.334368821099747, 'dropout_rate_Layer_3': 0.04968355976704947, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.017984978013733e-05, 'l1_Layer_2': 0.00018451115973393894, 'l1_Layer_3': 9.337708001107414e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 130, 'n_units_Layer_3': 130}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.07 | sMAPE for Validation Set is: 46.33% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 25.00 | sMAPE for Test Set is: 30.51% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:29:15,035]\u001b[0m Trial 693 finished with value: 8.93476368192822 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006079447812786616, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3917943307170508, 'dropout_rate_Layer_2': 0.010870554988684306, 'dropout_rate_Layer_3': 0.04165931327900241, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00031049396368859703, 'l1_Layer_2': 0.0003946770082317417, 'l1_Layer_3': 1.0002989720206149e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 300, 'n_units_Layer_3': 75}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.93 | sMAPE for Validation Set is: 50.99% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 44.08 | sMAPE for Test Set is: 52.75% | rMAE for Test Set is: 1.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:29:15,590]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:29:20,129]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:29:23,823]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:29:24,064]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:29:24,426]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:29:30,576]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:29:32,054]\u001b[0m Trial 707 finished with value: 9.443834298399997 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019658545044465904, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03572686121040245, 'dropout_rate_Layer_2': 0.008049712986094101, 'dropout_rate_Layer_3': 0.37793899156942407, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4599604574788036e-05, 'l1_Layer_2': 0.00018695351563316083, 'l1_Layer_3': 0.012710034137954282, 'n_units_Layer_1': 295, 'n_units_Layer_2': 160, 'n_units_Layer_3': 70}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.44 | sMAPE for Validation Set is: 50.02% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 26.59 | sMAPE for Test Set is: 30.11% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:29:38,950]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:29:40,441]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:29:44,869]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:29:48,666]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:29:49,123]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:29:56,661]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:29:56,942]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:30:08,532]\u001b[0m Trial 718 finished with value: 9.572107183124695 and parameters: {'n_hidden': 3, 'learning_rate': 0.003009855304418202, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04149069438149843, 'dropout_rate_Layer_2': 0.0029659802488546565, 'dropout_rate_Layer_3': 0.37407842915028605, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5266614689168465e-05, 'l1_Layer_2': 0.0001812422122137571, 'l1_Layer_3': 0.013207452746756141, 'n_units_Layer_1': 295, 'n_units_Layer_2': 155, 'n_units_Layer_3': 75}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.57 | sMAPE for Validation Set is: 49.71% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 27.52 | sMAPE for Test Set is: 29.90% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:30:11,469]\u001b[0m Trial 721 finished with value: 8.179651078306028 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008396581765775626, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3110362069688163, 'dropout_rate_Layer_2': 0.34879533261527185, 'dropout_rate_Layer_3': 0.05107048917546063, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.566750604833651e-05, 'l1_Layer_2': 0.00018050831637245922, 'l1_Layer_3': 9.557672375317066e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 140, 'n_units_Layer_3': 130}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.18 | sMAPE for Validation Set is: 46.54% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 23.05 | sMAPE for Test Set is: 27.83% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:30:14,376]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:30:19,000]\u001b[0m Trial 724 finished with value: 9.2407973567826 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020879430132546254, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06481667940708548, 'dropout_rate_Layer_2': 6.349665897990506e-06, 'dropout_rate_Layer_3': 0.3708463774025923, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7064027908850474e-05, 'l1_Layer_2': 0.00023287197049046956, 'l1_Layer_3': 0.0120080874002375, 'n_units_Layer_1': 285, 'n_units_Layer_2': 180, 'n_units_Layer_3': 50}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.24 | sMAPE for Validation Set is: 48.70% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 27.97 | sMAPE for Test Set is: 30.58% | rMAE for Test Set is: 0.83\n",
      "MAE for Validation Set is: 8.24 | sMAPE for Validation Set is: 46.44% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 23.60 | sMAPE for Test Set is: 28.66% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:30:22,014]\u001b[0m Trial 725 finished with value: 8.243514416340735 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012258666881980887, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31705482108756045, 'dropout_rate_Layer_2': 0.38123522980820806, 'dropout_rate_Layer_3': 0.06872717825067534, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.3897472671361514e-05, 'l1_Layer_2': 0.000278243374858949, 'l1_Layer_3': 9.574178414547315e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 140, 'n_units_Layer_3': 130}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:30:26,633]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:30:31,783]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:30:33,805]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:30:38,669]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:30:39,367]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:30:46,310]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:30:51,189]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:30:56,078]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:30:56,129]\u001b[0m Trial 728 finished with value: 8.952430113705365 and parameters: {'n_hidden': 3, 'learning_rate': 0.002034396160165193, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05987058642244155, 'dropout_rate_Layer_2': 0.0039368616816207, 'dropout_rate_Layer_3': 0.3742054518133401, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7520810902785185e-05, 'l1_Layer_2': 0.00020375419929124258, 'l1_Layer_3': 0.028751527357595418, 'n_units_Layer_1': 300, 'n_units_Layer_2': 155, 'n_units_Layer_3': 50}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.95 | sMAPE for Validation Set is: 49.95% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 30.51 | sMAPE for Test Set is: 31.62% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:30:57,456]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:31:04,684]\u001b[0m Trial 735 finished with value: 9.405062003141632 and parameters: {'n_hidden': 3, 'learning_rate': 0.00210320464654393, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.061949027189993525, 'dropout_rate_Layer_2': 0.004302658205299439, 'dropout_rate_Layer_3': 0.3489820269803994, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5388401564124335e-05, 'l1_Layer_2': 8.717653584361204e-05, 'l1_Layer_3': 0.026619578401796136, 'n_units_Layer_1': 290, 'n_units_Layer_2': 160, 'n_units_Layer_3': 50}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.41 | sMAPE for Validation Set is: 49.21% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 25.53 | sMAPE for Test Set is: 31.22% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:31:10,307]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:31:11,443]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:31:15,661]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:31:18,201]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:31:19,071]\u001b[0m Trial 741 finished with value: 8.439594710960138 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005538158905582651, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.286011860903686, 'dropout_rate_Layer_2': 0.3913226782921808, 'dropout_rate_Layer_3': 0.052092081626616424, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.965642829494479e-05, 'l1_Layer_2': 0.00018701222660565087, 'l1_Layer_3': 0.00010341738050428645, 'n_units_Layer_1': 215, 'n_units_Layer_2': 130, 'n_units_Layer_3': 115}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.44 | sMAPE for Validation Set is: 47.27% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 23.87 | sMAPE for Test Set is: 29.51% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:31:19,783]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:31:22,150]\u001b[0m Trial 739 finished with value: 8.270499287307429 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008662845447222098, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3106993280138786, 'dropout_rate_Layer_2': 0.36714725893588784, 'dropout_rate_Layer_3': 0.05170625131256319, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.7884629158999596e-05, 'l1_Layer_2': 0.00019456720893564847, 'l1_Layer_3': 9.590061572218323e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 135, 'n_units_Layer_3': 150}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.27 | sMAPE for Validation Set is: 46.93% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 23.91 | sMAPE for Test Set is: 28.96% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:31:24,430]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:31:32,020]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:31:32,640]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:31:33,543]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:31:36,147]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:31:41,904]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:31:45,853]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:31:50,479]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:31:52,609]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:31:57,484]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:31:59,042]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:32:03,924]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:32:06,879]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:32:08,729]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:32:15,565]\u001b[0m Trial 750 finished with value: 9.325185641049925 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021324929961488996, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06589318278883759, 'dropout_rate_Layer_2': 0.009523919809337, 'dropout_rate_Layer_3': 0.3524937077524205, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4568582099052311e-05, 'l1_Layer_2': 8.3568111674857e-05, 'l1_Layer_3': 0.026862209246622838, 'n_units_Layer_1': 290, 'n_units_Layer_2': 155, 'n_units_Layer_3': 50}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.33 | sMAPE for Validation Set is: 48.78% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 29.44 | sMAPE for Test Set is: 30.47% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:32:16,524]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.04 | sMAPE for Validation Set is: 48.14% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 26.57 | sMAPE for Test Set is: 31.16% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:32:21,490]\u001b[0m Trial 753 finished with value: 9.041093123680122 and parameters: {'n_hidden': 3, 'learning_rate': 0.002099089113384462, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05804835266093578, 'dropout_rate_Layer_2': 0.00038307197057413345, 'dropout_rate_Layer_3': 0.3523404074013136, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5378872676505726e-05, 'l1_Layer_2': 9.772016528392864e-05, 'l1_Layer_3': 0.023973879604845223, 'n_units_Layer_1': 290, 'n_units_Layer_2': 155, 'n_units_Layer_3': 50}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:32:23,766]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:32:27,207]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:32:30,317]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:32:31,202]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:32:36,620]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:32:39,907]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:32:44,313]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:32:44,480]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:32:50,509]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:32:51,407]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:32:57,331]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:32:58,589]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:33:03,594]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:33:03,839]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:33:11,071]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:33:11,111]\u001b[0m Trial 769 finished with value: 9.215035542918365 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016476247919363224, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05916352689409495, 'dropout_rate_Layer_2': 0.0005576314242375752, 'dropout_rate_Layer_3': 0.3516991536087153, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4758361778617997e-05, 'l1_Layer_2': 7.966125611712128e-05, 'l1_Layer_3': 0.02685467380261887, 'n_units_Layer_1': 290, 'n_units_Layer_2': 160, 'n_units_Layer_3': 50}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.22 | sMAPE for Validation Set is: 48.59% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 27.86 | sMAPE for Test Set is: 30.59% | rMAE for Test Set is: 0.82\n",
      "MAE for Validation Set is: 9.71 | sMAPE for Validation Set is: 49.78% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 24.89 | sMAPE for Test Set is: 29.94% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:33:15,728]\u001b[0m Trial 770 finished with value: 9.709741517259994 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018991280067569114, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06884873243121364, 'dropout_rate_Layer_2': 0.00011737064048785578, 'dropout_rate_Layer_3': 0.3565742544719761, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4162901587734057e-05, 'l1_Layer_2': 4.3739983438284423e-05, 'l1_Layer_3': 0.07465170038915082, 'n_units_Layer_1': 290, 'n_units_Layer_2': 165, 'n_units_Layer_3': 50}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:33:20,804]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:33:21,012]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:33:21,934]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:33:29,882]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:33:31,996]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:33:35,147]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:33:38,919]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:33:39,619]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:33:40,103]\u001b[0m Trial 778 finished with value: 8.946218806124305 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018468051325473964, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.061134652845544785, 'dropout_rate_Layer_2': 0.0004134830968593444, 'dropout_rate_Layer_3': 0.35058801248159166, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.560679068518421e-05, 'l1_Layer_2': 7.843132152395338e-05, 'l1_Layer_3': 0.024704894476945242, 'n_units_Layer_1': 290, 'n_units_Layer_2': 160, 'n_units_Layer_3': 50}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.95 | sMAPE for Validation Set is: 49.19% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 28.07 | sMAPE for Test Set is: 30.69% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:33:48,395]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:33:48,940]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:33:58,480]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:34:02,772]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:34:07,241]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:34:09,449]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.45 | sMAPE for Validation Set is: 49.26% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 25.69 | sMAPE for Test Set is: 29.56% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:34:12,847]\u001b[0m Trial 789 finished with value: 9.453366570291193 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017498068646008746, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05719050467472319, 'dropout_rate_Layer_2': 0.01517513265301473, 'dropout_rate_Layer_3': 0.3989203045100299, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.1783712070951843e-05, 'l1_Layer_2': 0.00012380790311660762, 'l1_Layer_3': 0.027894026165572003, 'n_units_Layer_1': 265, 'n_units_Layer_2': 175, 'n_units_Layer_3': 60}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:34:18,726]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:34:23,270]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:34:27,386]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:34:29,467]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:34:41,021]\u001b[0m Trial 796 finished with value: 8.153366683099485 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006450893304342143, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33781394088116856, 'dropout_rate_Layer_2': 0.3498174706189203, 'dropout_rate_Layer_3': 0.06889118309735395, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.061078510294204e-05, 'l1_Layer_2': 6.958719776110392e-05, 'l1_Layer_3': 8.859630645444013e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 135, 'n_units_Layer_3': 130}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.15 | sMAPE for Validation Set is: 46.83% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 24.85 | sMAPE for Test Set is: 30.62% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:34:44,186]\u001b[0m Trial 793 finished with value: 9.528329276188503 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008937542314356845, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05480593541241353, 'dropout_rate_Layer_2': 0.03331741777119898, 'dropout_rate_Layer_3': 0.3985983929917893, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.1146132762066942e-05, 'l1_Layer_2': 0.000129737070230895, 'l1_Layer_3': 0.041863595315925636, 'n_units_Layer_1': 265, 'n_units_Layer_2': 180, 'n_units_Layer_3': 60}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.53 | sMAPE for Validation Set is: 49.39% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 25.83 | sMAPE for Test Set is: 33.37% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:34:48,686]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:34:49,883]\u001b[0m Trial 801 finished with value: 8.14634296543616 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006772797822028684, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2938905720463025, 'dropout_rate_Layer_2': 0.34918219948398055, 'dropout_rate_Layer_3': 0.06871509615690682, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.180116873963746e-05, 'l1_Layer_2': 0.00032334730062943967, 'l1_Layer_3': 0.00018120635058263947, 'n_units_Layer_1': 230, 'n_units_Layer_2': 175, 'n_units_Layer_3': 130}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.15 | sMAPE for Validation Set is: 47.31% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 24.31 | sMAPE for Test Set is: 29.60% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:34:56,638]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:35:03,055]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:35:06,928]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:35:09,534]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:35:10,152]\u001b[0m Trial 803 finished with value: 8.19048323813435 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006548691809311354, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30118955002995734, 'dropout_rate_Layer_2': 0.3613142485739087, 'dropout_rate_Layer_3': 0.05583610294164576, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.156343251992139e-05, 'l1_Layer_2': 6.846849870418046e-05, 'l1_Layer_3': 0.00018728845004792295, 'n_units_Layer_1': 230, 'n_units_Layer_2': 135, 'n_units_Layer_3': 140}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.19 | sMAPE for Validation Set is: 46.29% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 24.88 | sMAPE for Test Set is: 30.29% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:35:11,100]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:35:15,680]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:35:18,769]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:35:21,129]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:35:26,478]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:35:27,774]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:35:30,178]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:35:31,069]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:35:32,574]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:35:36,508]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:35:41,446]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:35:42,398]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:35:44,935]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:35:48,978]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:35:51,678]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:35:52,922]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:35:54,922]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:36:05,574]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:36:10,741]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:36:15,784]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:36:21,365]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:36:25,942]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:36:34,224]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:36:39,643]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:36:47,746]\u001b[0m Trial 829 finished with value: 9.772918217215368 and parameters: {'n_hidden': 3, 'learning_rate': 0.001128952397276951, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1066316818134562, 'dropout_rate_Layer_2': 0.05011417421766621, 'dropout_rate_Layer_3': 0.32325255961674265, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.900845786505835e-05, 'l1_Layer_2': 3.595434470952657e-05, 'l1_Layer_3': 0.09983524765303296, 'n_units_Layer_1': 280, 'n_units_Layer_2': 135, 'n_units_Layer_3': 55}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.77 | sMAPE for Validation Set is: 50.12% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 24.60 | sMAPE for Test Set is: 30.66% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:36:50,316]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:36:53,868]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:36:54,834]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:37:00,870]\u001b[0m Trial 825 finished with value: 9.14304596673355 and parameters: {'n_hidden': 3, 'learning_rate': 0.001217037647994745, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09578282610290732, 'dropout_rate_Layer_2': 0.05039626797130781, 'dropout_rate_Layer_3': 0.325545322719174, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.8030302058975533e-05, 'l1_Layer_2': 3.575830999012457e-05, 'l1_Layer_3': 0.021590503074276214, 'n_units_Layer_1': 255, 'n_units_Layer_2': 135, 'n_units_Layer_3': 55}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.14 | sMAPE for Validation Set is: 49.49% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 25.24 | sMAPE for Test Set is: 29.01% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:37:04,686]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:37:09,000]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:37:12,805]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:37:15,639]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:37:22,202]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:37:25,009]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.21 | sMAPE for Validation Set is: 45.66% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 24.45 | sMAPE for Test Set is: 29.48% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:37:27,404]\u001b[0m Trial 838 finished with value: 8.211322152345522 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005504777624323506, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29048793631784986, 'dropout_rate_Layer_2': 0.34697616110987894, 'dropout_rate_Layer_3': 0.059142231199460944, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.219139566071286e-05, 'l1_Layer_2': 3.743550213961967e-05, 'l1_Layer_3': 0.00016784009208207126, 'n_units_Layer_1': 230, 'n_units_Layer_2': 125, 'n_units_Layer_3': 140}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:37:33,325]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:37:38,142]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:37:43,529]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:37:47,977]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:37:52,512]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:37:57,769]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:38:02,609]\u001b[0m Trial 847 finished with value: 8.833990053436896 and parameters: {'n_hidden': 3, 'learning_rate': 0.000613106292206884, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3763508939172208, 'dropout_rate_Layer_2': 0.17991174109023975, 'dropout_rate_Layer_3': 0.04915491581188866, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011894096073193849, 'l1_Layer_2': 0.0004832000123215461, 'l1_Layer_3': 1.8424071288037575e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 290, 'n_units_Layer_3': 300}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.83 | sMAPE for Validation Set is: 49.89% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 41.99 | sMAPE for Test Set is: 49.10% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:38:05,348]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:38:09,377]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:38:10,381]\u001b[0m Trial 841 finished with value: 9.366230489141486 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012933395917055928, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07802040213359004, 'dropout_rate_Layer_2': 0.016832410824373378, 'dropout_rate_Layer_3': 0.34533897560753607, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0093940872641409e-05, 'l1_Layer_2': 0.0003416583593921342, 'l1_Layer_3': 0.020171430722609678, 'n_units_Layer_1': 255, 'n_units_Layer_2': 150, 'n_units_Layer_3': 55}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.37 | sMAPE for Validation Set is: 49.15% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 25.46 | sMAPE for Test Set is: 28.88% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:38:12,747]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:38:18,958]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:38:24,043]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:38:24,205]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:38:31,418]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:38:31,563]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:38:32,024]\u001b[0m Trial 852 finished with value: 8.188637266830577 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008606898241588337, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2429524666176542, 'dropout_rate_Layer_2': 0.14376393941051901, 'dropout_rate_Layer_3': 0.11610776021416894, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016972279981460108, 'l1_Layer_2': 0.0003835250214271666, 'l1_Layer_3': 0.0003830352742997044, 'n_units_Layer_1': 145, 'n_units_Layer_2': 135, 'n_units_Layer_3': 215}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.19 | sMAPE for Validation Set is: 47.63% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 23.40 | sMAPE for Test Set is: 28.97% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:38:40,035]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:38:44,655]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:38:46,752]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:38:47,390]\u001b[0m Trial 858 finished with value: 9.776374091622088 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023894005337191863, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08662344269068131, 'dropout_rate_Layer_2': 0.02786676128181894, 'dropout_rate_Layer_3': 0.3671424842681258, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.7865304777734834e-05, 'l1_Layer_2': 5.165656579807435e-05, 'l1_Layer_3': 0.022552355578851376, 'n_units_Layer_1': 275, 'n_units_Layer_2': 130, 'n_units_Layer_3': 50}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.78 | sMAPE for Validation Set is: 50.10% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 25.26 | sMAPE for Test Set is: 28.73% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:38:47,820]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:38:56,255]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:39:03,123]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:39:07,363]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:39:16,194]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:39:20,895]\u001b[0m Trial 866 finished with value: 8.939813162389514 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005037781349569458, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38559585310183697, 'dropout_rate_Layer_2': 0.13889700079997452, 'dropout_rate_Layer_3': 0.04880410542029864, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011264671857074767, 'l1_Layer_2': 0.0003485902412034884, 'l1_Layer_3': 1.9335274640852192e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 285, 'n_units_Layer_3': 285}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.94 | sMAPE for Validation Set is: 50.20% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 43.26 | sMAPE for Test Set is: 51.17% | rMAE for Test Set is: 1.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:39:25,078]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:39:29,673]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:39:35,544]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:39:39,647]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:39:43,326]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:39:47,599]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:39:51,433]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:39:56,343]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:40:03,401]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:40:08,576]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:40:11,936]\u001b[0m Trial 868 finished with value: 8.307931388767996 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005030109279048863, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3829102002224752, 'dropout_rate_Layer_2': 0.20269793445696338, 'dropout_rate_Layer_3': 0.05021556065022143, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011181279559546516, 'l1_Layer_2': 0.00046199122013660114, 'l1_Layer_3': 1.81395433632483e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 285, 'n_units_Layer_3': 110}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.31 | sMAPE for Validation Set is: 47.87% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 40.84 | sMAPE for Test Set is: 47.40% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:40:12,370]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:40:14,740]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:40:21,038]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:40:25,430]\u001b[0m Trial 869 finished with value: 8.381693279073266 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006543258856436877, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37874537036650896, 'dropout_rate_Layer_2': 0.1630135216795398, 'dropout_rate_Layer_3': 0.05128733330255632, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001170115132409371, 'l1_Layer_2': 0.0004644374745075221, 'l1_Layer_3': 1.894124777235611e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 285, 'n_units_Layer_3': 285}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.38 | sMAPE for Validation Set is: 45.43% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 42.82 | sMAPE for Test Set is: 50.26% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:40:29,062]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:40:34,598]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:40:36,516]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:40:43,818]\u001b[0m Trial 885 finished with value: 9.400941761421075 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009454975882695605, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.096459658618396, 'dropout_rate_Layer_2': 0.05518546236721173, 'dropout_rate_Layer_3': 0.3872916501655041, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.3120611692877964e-05, 'l1_Layer_2': 9.659436578894883e-05, 'l1_Layer_3': 0.016764937863213526, 'n_units_Layer_1': 285, 'n_units_Layer_2': 145, 'n_units_Layer_3': 85}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.40 | sMAPE for Validation Set is: 48.88% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 23.87 | sMAPE for Test Set is: 29.05% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:40:44,225]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:40:54,744]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:41:01,592]\u001b[0m Trial 893 finished with value: 8.343392793017793 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007664000285650156, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30462125533670714, 'dropout_rate_Layer_2': 0.3001184072338273, 'dropout_rate_Layer_3': 0.011243049072286349, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.093300822904774e-05, 'l1_Layer_2': 3.3237510022732035e-05, 'l1_Layer_3': 0.00012063787379117988, 'n_units_Layer_1': 235, 'n_units_Layer_2': 140, 'n_units_Layer_3': 105}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.34 | sMAPE for Validation Set is: 46.41% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 25.07 | sMAPE for Test Set is: 30.54% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:41:04,998]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:41:12,342]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:41:22,934]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:41:36,429]\u001b[0m Trial 892 finished with value: 9.169572983486658 and parameters: {'n_hidden': 3, 'learning_rate': 0.000817840436394856, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04783119567677632, 'dropout_rate_Layer_2': 0.05513287997950923, 'dropout_rate_Layer_3': 0.3858154706072356, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.570559684048462e-05, 'l1_Layer_2': 7.410418445285953e-05, 'l1_Layer_3': 0.04755121715030918, 'n_units_Layer_1': 285, 'n_units_Layer_2': 115, 'n_units_Layer_3': 85}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.17 | sMAPE for Validation Set is: 48.83% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 25.53 | sMAPE for Test Set is: 29.29% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:41:39,964]\u001b[0m Trial 899 finished with value: 8.24211316780169 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008357645576381359, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.325253568094933, 'dropout_rate_Layer_2': 0.36668325798155593, 'dropout_rate_Layer_3': 0.05043092238756508, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.5237663138298e-05, 'l1_Layer_2': 1.4953822973762752e-05, 'l1_Layer_3': 0.0001321309957902903, 'n_units_Layer_1': 245, 'n_units_Layer_2': 135, 'n_units_Layer_3': 135}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.24 | sMAPE for Validation Set is: 46.79% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 22.88 | sMAPE for Test Set is: 27.78% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:41:44,760]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:42:36,827]\u001b[0m Trial 900 finished with value: 8.322947117317963 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005579387193785793, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3693109207377411, 'dropout_rate_Layer_2': 0.19377394489617264, 'dropout_rate_Layer_3': 0.0513849041004705, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007846055427935234, 'l1_Layer_2': 0.00023693934325424754, 'l1_Layer_3': 2.3408386826171965e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 275, 'n_units_Layer_3': 100}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.32 | sMAPE for Validation Set is: 46.51% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 41.65 | sMAPE for Test Set is: 48.46% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:42:47,897]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:42:53,271]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:42:58,831]\u001b[0m Trial 902 finished with value: 8.273522562663674 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005444250145405288, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36960692493816827, 'dropout_rate_Layer_2': 0.1917525911683077, 'dropout_rate_Layer_3': 0.04688765002273235, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008340352392665091, 'l1_Layer_2': 0.00025872481396661817, 'l1_Layer_3': 1.3751020482635606e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 275, 'n_units_Layer_3': 275}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.27 | sMAPE for Validation Set is: 47.12% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 41.24 | sMAPE for Test Set is: 47.89% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:43:02,969]\u001b[0m Trial 897 finished with value: 8.20760773348111 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005460708886844626, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36921225385810835, 'dropout_rate_Layer_2': 0.19933119852687778, 'dropout_rate_Layer_3': 0.05321649171832931, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008887816366864844, 'l1_Layer_2': 0.00033847190103242686, 'l1_Layer_3': 0.000292101536722358, 'n_units_Layer_1': 125, 'n_units_Layer_2': 275, 'n_units_Layer_3': 125}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.21 | sMAPE for Validation Set is: 45.33% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 40.81 | sMAPE for Test Set is: 47.06% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:43:07,562]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:43:11,026]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:43:15,170]\u001b[0m Trial 889 finished with value: 8.207679369848917 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005431923866079109, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37075353613084194, 'dropout_rate_Layer_2': 0.22139976237063472, 'dropout_rate_Layer_3': 0.049403348362253525, 'dropout_rate_Layer_4': 0.3097936924201231, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0009832591263302074, 'l1_Layer_2': 0.00028326131752881497, 'l1_Layer_3': 2.0916267718810795e-05, 'l1_Layer_4': 0.005240050877926723, 'n_units_Layer_1': 120, 'n_units_Layer_2': 270, 'n_units_Layer_3': 115, 'n_units_Layer_4': 265}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.21 | sMAPE for Validation Set is: 45.40% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 40.41 | sMAPE for Test Set is: 46.72% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:43:20,353]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:43:21,014]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:43:28,146]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:43:35,790]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:43:44,564]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:43:48,213]\u001b[0m Trial 911 finished with value: 8.112394847926945 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007197371668012804, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32299545114642364, 'dropout_rate_Layer_2': 0.341130187052288, 'dropout_rate_Layer_3': 0.0835296167858105, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.7041787325487298e-05, 'l1_Layer_2': 1.437491660477605e-05, 'l1_Layer_3': 0.00012805842246575898, 'n_units_Layer_1': 230, 'n_units_Layer_2': 130, 'n_units_Layer_3': 135}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.11 | sMAPE for Validation Set is: 46.16% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 23.90 | sMAPE for Test Set is: 28.95% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:43:53,477]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:43:55,966]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:44:04,980]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:44:16,299]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:44:21,806]\u001b[0m Trial 909 finished with value: 8.282622934259965 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005030673081888833, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37309402463863117, 'dropout_rate_Layer_2': 0.22727088018879846, 'dropout_rate_Layer_3': 0.02382893921376703, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006420360533849649, 'l1_Layer_2': 0.0002427822057025124, 'l1_Layer_3': 3.0207580860586295e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 265, 'n_units_Layer_3': 120}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.28 | sMAPE for Validation Set is: 46.97% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 40.43 | sMAPE for Test Set is: 46.49% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:44:25,961]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:44:37,438]\u001b[0m Trial 908 finished with value: 8.301241999644036 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005580229841844967, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.366114895965738, 'dropout_rate_Layer_2': 0.20065336054687263, 'dropout_rate_Layer_3': 0.050154334383541554, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006057424792909857, 'l1_Layer_2': 0.0002263741555269521, 'l1_Layer_3': 0.00011152435137610985, 'n_units_Layer_1': 130, 'n_units_Layer_2': 265, 'n_units_Layer_3': 110}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.30 | sMAPE for Validation Set is: 46.68% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 41.75 | sMAPE for Test Set is: 48.65% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:44:44,313]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:44:46,178]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:44:54,877]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:44:55,681]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:45:01,474]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:45:06,169]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:45:09,188]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:45:16,924]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:46:23,072]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:46:34,563]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:46:44,332]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:46:48,980]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:46:59,434]\u001b[0m Trial 931 finished with value: 9.672567557666518 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006650546245737736, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04811835682005189, 'dropout_rate_Layer_2': 0.0441995458101108, 'dropout_rate_Layer_3': 0.3850110333549644, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.405950973201759e-05, 'l1_Layer_2': 6.650314094400543e-05, 'l1_Layer_3': 0.04830534578331333, 'n_units_Layer_1': 250, 'n_units_Layer_2': 115, 'n_units_Layer_3': 75}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.67 | sMAPE for Validation Set is: 50.01% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 24.25 | sMAPE for Test Set is: 29.56% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:47:08,328]\u001b[0m Trial 930 finished with value: 8.309785825378134 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005006563695986684, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3909513695181787, 'dropout_rate_Layer_2': 0.2186149697453556, 'dropout_rate_Layer_3': 0.049661722127143745, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009171750956602275, 'l1_Layer_2': 0.00026093679712761757, 'l1_Layer_3': 2.956379664218201e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 270, 'n_units_Layer_3': 120}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.31 | sMAPE for Validation Set is: 47.62% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 40.03 | sMAPE for Test Set is: 46.05% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:47:23,926]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:47:27,842]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:47:31,192]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:47:39,392]\u001b[0m Trial 918 finished with value: 8.392443665656346 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005035449303898394, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38423805471250183, 'dropout_rate_Layer_2': 0.21541948585751952, 'dropout_rate_Layer_3': 0.04747538645117352, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008348671453874147, 'l1_Layer_2': 0.00017313176798041703, 'l1_Layer_3': 2.0056174360194417e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 265, 'n_units_Layer_3': 110}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.39 | sMAPE for Validation Set is: 46.03% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 41.30 | sMAPE for Test Set is: 47.79% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:47:39,881]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:47:49,793]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:47:51,865]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:47:59,772]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:48:03,847]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:48:06,817]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:48:09,217]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:48:10,137]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:48:20,539]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:48:25,035]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:48:33,783]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:48:41,893]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:48:42,516]\u001b[0m Trial 939 finished with value: 8.3315928821476 and parameters: {'n_hidden': 3, 'learning_rate': 0.000592186158894548, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3867303970604904, 'dropout_rate_Layer_2': 0.2329907774514208, 'dropout_rate_Layer_3': 0.05240709158231767, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004327498668635318, 'l1_Layer_2': 0.00020706225208806206, 'l1_Layer_3': 0.0007953152554235115, 'n_units_Layer_1': 150, 'n_units_Layer_2': 275, 'n_units_Layer_3': 130}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.33 | sMAPE for Validation Set is: 46.65% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 42.47 | sMAPE for Test Set is: 49.89% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:48:48,531]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:48:48,790]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:48:56,680]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:49:00,790]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:49:01,950]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:49:04,675]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:49:08,517]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:49:14,240]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:49:17,278]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:49:17,846]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:49:22,380]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:49:25,077]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:49:29,777]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:49:32,639]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:49:33,877]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:49:38,239]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:49:43,956]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:49:44,977]\u001b[0m Trial 968 finished with value: 8.483083711885998 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012260110049638197, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2894473542622744, 'dropout_rate_Layer_2': 0.38459837294908655, 'dropout_rate_Layer_3': 0.048943327485949976, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.354566568648956e-05, 'l1_Layer_2': 1.80577906031054e-05, 'l1_Layer_3': 5.903850603497696e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 140, 'n_units_Layer_3': 125}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.48 | sMAPE for Validation Set is: 46.54% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 25.74 | sMAPE for Test Set is: 32.47% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:49:45,982]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:49:57,038]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:49:57,471]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:50:03,612]\u001b[0m Trial 947 finished with value: 8.442189632960167 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005007855502221908, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38142611806197635, 'dropout_rate_Layer_2': 0.2257529347988659, 'dropout_rate_Layer_3': 0.04989968798626378, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004618092850477914, 'l1_Layer_2': 0.00016665517940442543, 'l1_Layer_3': 4.466561151556946e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 275, 'n_units_Layer_3': 135}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.44 | sMAPE for Validation Set is: 46.90% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 40.01 | sMAPE for Test Set is: 45.79% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:50:49,349]\u001b[0m Trial 976 finished with value: 9.755158668649122 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008497156446384395, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.021913732364284372, 'dropout_rate_Layer_2': 0.06433019301507316, 'dropout_rate_Layer_3': 0.3308344775894159, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.180051909739268e-05, 'l1_Layer_2': 0.00014909254520275366, 'l1_Layer_3': 0.06917159527586822, 'n_units_Layer_1': 270, 'n_units_Layer_2': 125, 'n_units_Layer_3': 90}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.76 | sMAPE for Validation Set is: 50.01% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 23.57 | sMAPE for Test Set is: 29.16% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:50:54,370]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:51:14,238]\u001b[0m Trial 971 finished with value: 8.343127000292794 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005542592452606949, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37970756947221224, 'dropout_rate_Layer_2': 0.20986088790591395, 'dropout_rate_Layer_3': 0.034671535033069904, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000654680302563905, 'l1_Layer_2': 0.00031072118614498037, 'l1_Layer_3': 4.1813104167302504e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 275, 'n_units_Layer_3': 115}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.34 | sMAPE for Validation Set is: 46.02% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 40.61 | sMAPE for Test Set is: 46.72% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:51:20,559]\u001b[0m Trial 975 finished with value: 8.268788523971896 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006493193812687175, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.371247021544016, 'dropout_rate_Layer_2': 0.24015707890325863, 'dropout_rate_Layer_3': 0.03681372114043618, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00039971479094181607, 'l1_Layer_2': 0.00023408622427419508, 'l1_Layer_3': 4.323644798384923e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 275, 'n_units_Layer_3': 110}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.27 | sMAPE for Validation Set is: 46.97% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 42.50 | sMAPE for Test Set is: 49.94% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:51:21,226]\u001b[0m Trial 974 finished with value: 8.367781264486974 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005592917519243432, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3680088356967804, 'dropout_rate_Layer_2': 0.27206719798048373, 'dropout_rate_Layer_3': 0.03554691080755481, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000417414061554257, 'l1_Layer_2': 0.0002187377677312518, 'l1_Layer_3': 2.9647064798105774e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 250, 'n_units_Layer_3': 125}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.37 | sMAPE for Validation Set is: 47.06% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 41.78 | sMAPE for Test Set is: 48.75% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:51:35,652]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:51:40,631]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:51:47,748]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:52:03,211]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:52:25,208]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:53:10,140]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:53:19,105]\u001b[0m Trial 980 finished with value: 8.27176608969934 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005461773174540435, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3818392280269846, 'dropout_rate_Layer_2': 0.24677746793736396, 'dropout_rate_Layer_3': 0.03244816523872281, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00038998599611875804, 'l1_Layer_2': 0.00014049375152165383, 'l1_Layer_3': 4.22274936091694e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 255, 'n_units_Layer_3': 125}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.27 | sMAPE for Validation Set is: 47.05% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 42.19 | sMAPE for Test Set is: 49.47% | rMAE for Test Set is: 1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:53:19,442]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:53:20,092]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:53:28,324]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:53:30,514]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:53:35,251]\u001b[0m Trial 986 finished with value: 8.293341055183689 and parameters: {'n_hidden': 3, 'learning_rate': 0.00054768434799399, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38912591290313425, 'dropout_rate_Layer_2': 0.3142127192356054, 'dropout_rate_Layer_3': 0.03423992823233536, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003699833555983908, 'l1_Layer_2': 0.0002385846160471096, 'l1_Layer_3': 3.294681879564952e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 260, 'n_units_Layer_3': 145}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.29 | sMAPE for Validation Set is: 46.50% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 41.23 | sMAPE for Test Set is: 47.82% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:53:35,465]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:53:37,344]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:53:43,813]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:53:45,937]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:53:51,456]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:53:55,455]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:54:35,735]\u001b[0m Trial 996 finished with value: 8.488815542497052 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005025320626978268, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3889347100812555, 'dropout_rate_Layer_2': 0.3100075364928749, 'dropout_rate_Layer_3': 0.021063275568136502, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00044964866711748325, 'l1_Layer_2': 0.00017382328010986126, 'l1_Layer_3': 4.5166151286025795e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 250, 'n_units_Layer_3': 135}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.49 | sMAPE for Validation Set is: 47.28% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 40.94 | sMAPE for Test Set is: 47.42% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:54:52,021]\u001b[0m Trial 994 finished with value: 8.393202021477006 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005544876074693932, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3857641674989696, 'dropout_rate_Layer_2': 0.3313928845449328, 'dropout_rate_Layer_3': 0.020916209461187142, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023864345200826307, 'l1_Layer_2': 9.929212175150747e-05, 'l1_Layer_3': 4.6577263447706675e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 260, 'n_units_Layer_3': 140}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.39 | sMAPE for Validation Set is: 46.17% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 43.03 | sMAPE for Test Set is: 51.03% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:54:54,944]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:55:01,775]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:55:04,707]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:55:08,076]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:55:25,271]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:55:39,453]\u001b[0m Trial 998 finished with value: 8.410616298389579 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005557695258283211, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36626714775544605, 'dropout_rate_Layer_2': 0.3149039947876276, 'dropout_rate_Layer_3': 0.0280472465659872, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00024097908688030484, 'l1_Layer_2': 0.0002266197448895072, 'l1_Layer_3': 4.23558403443958e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 250, 'n_units_Layer_3': 135}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.41 | sMAPE for Validation Set is: 45.84% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 42.56 | sMAPE for Test Set is: 49.83% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:55:45,664]\u001b[0m Trial 999 finished with value: 8.347539470760893 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005016532152941843, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3639358414153142, 'dropout_rate_Layer_2': 0.3179962596645095, 'dropout_rate_Layer_3': 0.020092773428376315, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004438863108639167, 'l1_Layer_2': 0.0001778356727454005, 'l1_Layer_3': 4.490997286647018e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 250, 'n_units_Layer_3': 140}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.35 | sMAPE for Validation Set is: 46.69% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 39.65 | sMAPE for Test Set is: 45.55% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:55:49,006]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:55:51,734]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:56:09,318]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:56:09,480]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:56:24,881]\u001b[0m Trial 1004 finished with value: 8.421695675036231 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005646461111613662, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3928806182390594, 'dropout_rate_Layer_2': 0.31985106106029887, 'dropout_rate_Layer_3': 0.01179948940692227, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002712266919648461, 'l1_Layer_2': 9.380845319844476e-05, 'l1_Layer_3': 3.814647792270672e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 250, 'n_units_Layer_3': 145}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.42 | sMAPE for Validation Set is: 46.30% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 42.46 | sMAPE for Test Set is: 49.81% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:56:30,794]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:56:44,014]\u001b[0m Trial 1013 finished with value: 8.207517573554535 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008513529204254647, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3207490549925593, 'dropout_rate_Layer_2': 0.33633644739256574, 'dropout_rate_Layer_3': 0.21975312359972843, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.630765111503143e-05, 'l1_Layer_2': 2.2949593428877805e-05, 'l1_Layer_3': 0.00043271604438744433, 'n_units_Layer_1': 230, 'n_units_Layer_2': 130, 'n_units_Layer_3': 135}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.21 | sMAPE for Validation Set is: 47.15% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 25.81 | sMAPE for Test Set is: 31.60% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:56:54,480]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:57:05,396]\u001b[0m Trial 1012 finished with value: 8.425302036677797 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005443345494533764, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3852357708326777, 'dropout_rate_Layer_2': 0.3048416414747642, 'dropout_rate_Layer_3': 0.014381614285261284, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020023789903064342, 'l1_Layer_2': 0.000137764029437673, 'l1_Layer_3': 3.864377649296129e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 245, 'n_units_Layer_3': 140}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.43 | sMAPE for Validation Set is: 46.93% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 41.20 | sMAPE for Test Set is: 47.70% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:57:10,649]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:57:11,192]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:57:18,650]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:57:22,143]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:57:27,196]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:57:36,377]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:57:37,698]\u001b[0m Trial 1014 finished with value: 8.390820721181294 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005011909752030502, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3932125393019265, 'dropout_rate_Layer_2': 0.3090309858906498, 'dropout_rate_Layer_3': 0.015222692987656949, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022200184045655203, 'l1_Layer_2': 7.445753467722239e-05, 'l1_Layer_3': 4.232616258863176e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 240, 'n_units_Layer_3': 145}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.39 | sMAPE for Validation Set is: 46.13% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 41.96 | sMAPE for Test Set is: 48.99% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:57:44,336]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:57:50,040]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:57:55,232]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:57:55,946]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:58:01,506]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:58:05,983]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:58:13,567]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:58:21,762]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:58:30,727]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:58:40,668]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:58:52,264]\u001b[0m Trial 1023 finished with value: 8.495201474711015 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005448187505431939, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39923902611266804, 'dropout_rate_Layer_2': 0.3128613370410718, 'dropout_rate_Layer_3': 0.0003851882975535667, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015907683512025698, 'l1_Layer_2': 0.00010143914550682614, 'l1_Layer_3': 4.7830811828121324e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 250, 'n_units_Layer_3': 155}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.50 | sMAPE for Validation Set is: 45.91% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 42.81 | sMAPE for Test Set is: 50.23% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:59:34,006]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 06:59:45,216]\u001b[0m Trial 1027 finished with value: 8.399475157559333 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005018771359073113, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39927225668593463, 'dropout_rate_Layer_2': 0.30953426822927416, 'dropout_rate_Layer_3': 0.01229253420896629, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016291085685188195, 'l1_Layer_2': 9.612877601652583e-05, 'l1_Layer_3': 4.784787713905547e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 235, 'n_units_Layer_3': 145}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.40 | sMAPE for Validation Set is: 46.14% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 40.96 | sMAPE for Test Set is: 47.26% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 06:59:59,589]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:00:04,404]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:00:04,802]\u001b[0m Trial 1034 finished with value: 8.34474018697702 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005015333482279047, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3878504505029029, 'dropout_rate_Layer_2': 0.3030768423766059, 'dropout_rate_Layer_3': 0.01780504577513637, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002312274726716623, 'l1_Layer_2': 5.921376585707108e-05, 'l1_Layer_3': 4.881842539185547e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 240, 'n_units_Layer_3': 150}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.34 | sMAPE for Validation Set is: 47.69% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 42.00 | sMAPE for Test Set is: 49.03% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:00:17,598]\u001b[0m Trial 1039 finished with value: 8.490422569478906 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010321010244851222, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3382886460023618, 'dropout_rate_Layer_2': 0.368882361333252, 'dropout_rate_Layer_3': 0.25029801803206275, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.2357719836906966e-05, 'l1_Layer_2': 3.201315206102522e-05, 'l1_Layer_3': 7.492545205062505e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 145, 'n_units_Layer_3': 135}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.49 | sMAPE for Validation Set is: 48.15% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 25.49 | sMAPE for Test Set is: 31.82% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:00:23,159]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:00:27,539]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:01:17,279]\u001b[0m Trial 1040 finished with value: 8.464628943029995 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005012472546245641, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.387633813175781, 'dropout_rate_Layer_2': 0.32687641403897255, 'dropout_rate_Layer_3': 0.01344531441545739, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002570273900573223, 'l1_Layer_2': 8.407832762710642e-05, 'l1_Layer_3': 7.602931454764176e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 240, 'n_units_Layer_3': 145}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.46 | sMAPE for Validation Set is: 46.55% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 41.36 | sMAPE for Test Set is: 47.96% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:01:22,114]\u001b[0m Trial 1036 finished with value: 8.345299263417013 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005043119317159476, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39975385217543513, 'dropout_rate_Layer_2': 0.3010429531653737, 'dropout_rate_Layer_3': 0.011593041960282931, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002465056523645979, 'l1_Layer_2': 0.00011814202537882106, 'l1_Layer_3': 5.4992035526446413e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 240, 'n_units_Layer_3': 155}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.35 | sMAPE for Validation Set is: 46.54% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 42.97 | sMAPE for Test Set is: 50.80% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:01:25,581]\u001b[0m Trial 1037 finished with value: 8.258077922795614 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005420349583422718, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3897603744128452, 'dropout_rate_Layer_2': 0.303346884159593, 'dropout_rate_Layer_3': 0.016705938319630863, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002383777821638633, 'l1_Layer_2': 0.00011081162009208782, 'l1_Layer_3': 6.180919546116175e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 255, 'n_units_Layer_3': 135}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.26 | sMAPE for Validation Set is: 46.51% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 41.05 | sMAPE for Test Set is: 47.44% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:01:28,449]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:01:32,621]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:01:34,177]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:01:49,340]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:01:57,583]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:02:03,672]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:02:13,260]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.40 | sMAPE for Validation Set is: 47.15% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 42.29 | sMAPE for Test Set is: 49.61% | rMAE for Test Set is: 1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:02:18,637]\u001b[0m Trial 1043 finished with value: 8.402529351562263 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005026279405660348, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3867203056936731, 'dropout_rate_Layer_2': 0.3009441986526517, 'dropout_rate_Layer_3': 0.020564063796863492, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00018087814597157634, 'l1_Layer_2': 4.2468443060853014e-05, 'l1_Layer_3': 3.349236966544342e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 240, 'n_units_Layer_3': 140}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:02:34,805]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:02:38,518]\u001b[0m Trial 1050 finished with value: 8.541529685296602 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005678743095344473, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3891823162082336, 'dropout_rate_Layer_2': 0.30231743890262763, 'dropout_rate_Layer_3': 0.011406644200752911, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002308416714971727, 'l1_Layer_2': 9.651396757920613e-05, 'l1_Layer_3': 6.128570776365841e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 240, 'n_units_Layer_3': 140}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.54 | sMAPE for Validation Set is: 47.21% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 40.95 | sMAPE for Test Set is: 47.21% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:03:11,346]\u001b[0m Trial 1053 finished with value: 8.525888939901577 and parameters: {'n_hidden': 3, 'learning_rate': 0.000584519557398731, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3882745538545567, 'dropout_rate_Layer_2': 0.28836407639990563, 'dropout_rate_Layer_3': 0.007646284015357379, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017553454366781276, 'l1_Layer_2': 9.786906962327464e-05, 'l1_Layer_3': 3.498567856567956e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 240, 'n_units_Layer_3': 140}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.53 | sMAPE for Validation Set is: 47.80% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 41.58 | sMAPE for Test Set is: 48.41% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:03:18,866]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:03:23,082]\u001b[0m Trial 1051 finished with value: 8.46333797424319 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005742312417381412, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38885672036152447, 'dropout_rate_Layer_2': 0.3006781721208504, 'dropout_rate_Layer_3': 0.010896235031746068, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017945318326265708, 'l1_Layer_2': 4.318801324036347e-05, 'l1_Layer_3': 3.316945439508684e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 240, 'n_units_Layer_3': 165}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.46 | sMAPE for Validation Set is: 46.88% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 43.46 | sMAPE for Test Set is: 51.39% | rMAE for Test Set is: 1.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:03:26,900]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:03:31,257]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:03:39,525]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:03:40,101]\u001b[0m Trial 1055 finished with value: 8.397528968109517 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005783409834544127, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3988949252823858, 'dropout_rate_Layer_2': 0.29983754915106503, 'dropout_rate_Layer_3': 0.026738559732149187, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017096234300910797, 'l1_Layer_2': 0.00010562934710964573, 'l1_Layer_3': 6.192276603141797e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 240, 'n_units_Layer_3': 165}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.40 | sMAPE for Validation Set is: 46.65% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 42.37 | sMAPE for Test Set is: 49.73% | rMAE for Test Set is: 1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:03:46,259]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:03:48,553]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:03:48,641]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:03:58,760]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:04:07,956]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:04:14,987]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:04:18,150]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:04:26,456]\u001b[0m Trial 1056 finished with value: 8.359836362874484 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005019196783621432, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3848568563049167, 'dropout_rate_Layer_2': 0.2955718923284586, 'dropout_rate_Layer_3': 0.02755917652599695, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016960546884289422, 'l1_Layer_2': 0.00011736849189000752, 'l1_Layer_3': 3.7204489406657695e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 230, 'n_units_Layer_3': 130}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.36 | sMAPE for Validation Set is: 46.00% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 42.55 | sMAPE for Test Set is: 49.88% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:04:34,773]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:04:47,175]\u001b[0m Trial 1072 finished with value: 8.824919357753343 and parameters: {'n_hidden': 3, 'learning_rate': 0.014324769172368511, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32271541275677124, 'dropout_rate_Layer_2': 0.3179197065420852, 'dropout_rate_Layer_3': 0.19322177196557633, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.5368411884534646e-05, 'l1_Layer_2': 8.104261288773626e-05, 'l1_Layer_3': 0.00022038151354711295, 'n_units_Layer_1': 215, 'n_units_Layer_2': 155, 'n_units_Layer_3': 130}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.82 | sMAPE for Validation Set is: 50.73% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 27.48 | sMAPE for Test Set is: 34.57% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:04:52,345]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:05:01,877]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:05:02,893]\u001b[0m Trial 1071 finished with value: 9.19845862608033 and parameters: {'n_hidden': 3, 'learning_rate': 0.000782117914727994, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05743360838078551, 'dropout_rate_Layer_2': 0.03479697703613919, 'dropout_rate_Layer_3': 0.3544765386217389, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2142767906552167e-05, 'l1_Layer_2': 4.956758925904849e-05, 'l1_Layer_3': 0.024124206992371777, 'n_units_Layer_1': 285, 'n_units_Layer_2': 155, 'n_units_Layer_3': 50}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.20 | sMAPE for Validation Set is: 48.85% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 25.15 | sMAPE for Test Set is: 30.09% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:05:09,283]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:05:10,054]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:05:10,826]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:05:25,293]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:05:32,995]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:05:45,094]\u001b[0m Trial 1077 finished with value: 8.119951250137573 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014144741532632597, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02756475558849493, 'dropout_rate_Layer_2': 0.22553270553899796, 'dropout_rate_Layer_3': 0.06990267697749303, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00043169457969193133, 'l1_Layer_2': 0.0007734927786318579, 'l1_Layer_3': 0.0010851566422288368, 'n_units_Layer_1': 145, 'n_units_Layer_2': 50, 'n_units_Layer_3': 120}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.12 | sMAPE for Validation Set is: 44.81% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 23.40 | sMAPE for Test Set is: 28.70% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:06:02,844]\u001b[0m Trial 1079 finished with value: 8.641406577759376 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006139434526995712, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3915226341894378, 'dropout_rate_Layer_2': 0.30940704556001497, 'dropout_rate_Layer_3': 0.0074062073176326265, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00021276463459693313, 'l1_Layer_2': 8.913743522516045e-05, 'l1_Layer_3': 3.8644859420909185e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 245, 'n_units_Layer_3': 160}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.64 | sMAPE for Validation Set is: 46.68% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 43.62 | sMAPE for Test Set is: 51.53% | rMAE for Test Set is: 1.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:06:05,619]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:06:26,150]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:06:40,172]\u001b[0m Trial 1081 finished with value: 8.373101243441068 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006160220022268417, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39275675826183065, 'dropout_rate_Layer_2': 0.30934445474830014, 'dropout_rate_Layer_3': 0.019455442879021734, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00029179214773940423, 'l1_Layer_2': 7.357644373924011e-05, 'l1_Layer_3': 4.14499517794478e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 245, 'n_units_Layer_3': 125}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.37 | sMAPE for Validation Set is: 46.58% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 41.52 | sMAPE for Test Set is: 48.03% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:06:49,065]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:06:53,835]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:07:10,110]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:07:29,390]\u001b[0m Trial 1087 finished with value: 9.731063602583875 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007457089293500199, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05609810735391426, 'dropout_rate_Layer_2': 0.04036328676534831, 'dropout_rate_Layer_3': 0.35843128645521466, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2277161721436845e-05, 'l1_Layer_2': 1.4450960777162146e-05, 'l1_Layer_3': 0.054956582825189323, 'n_units_Layer_1': 290, 'n_units_Layer_2': 110, 'n_units_Layer_3': 55}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.73 | sMAPE for Validation Set is: 49.99% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 26.14 | sMAPE for Test Set is: 29.25% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:07:34,254]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:07:38,184]\u001b[0m Trial 1083 finished with value: 8.298308270203924 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005963669721933578, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39981210278628965, 'dropout_rate_Layer_2': 0.31354074639759133, 'dropout_rate_Layer_3': 0.01624059816093285, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00028163469334130023, 'l1_Layer_2': 7.226781161928631e-05, 'l1_Layer_3': 4.127344238370634e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 260, 'n_units_Layer_3': 125}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.30 | sMAPE for Validation Set is: 46.60% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 40.50 | sMAPE for Test Set is: 46.76% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:07:43,022]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:07:48,012]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:07:54,163]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:07:56,727]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:08:02,127]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:08:05,095]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:08:05,468]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:08:07,020]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:08:13,128]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:08:28,590]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:08:28,787]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:08:33,951]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:08:36,413]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:08:42,869]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:08:46,180]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:08:47,221]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:08:52,232]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:08:56,156]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:08:56,285]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:08:56,618]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:09:25,961]\u001b[0m Trial 1099 finished with value: 8.667803408281607 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006291775450067009, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3759493482971018, 'dropout_rate_Layer_2': 0.30330279133783766, 'dropout_rate_Layer_3': 0.027145729644702243, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022943293266548419, 'l1_Layer_2': 8.616033463339917e-05, 'l1_Layer_3': 0.0005712738609501987, 'n_units_Layer_1': 170, 'n_units_Layer_2': 255, 'n_units_Layer_3': 115}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.67 | sMAPE for Validation Set is: 46.57% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 44.83 | sMAPE for Test Set is: 53.63% | rMAE for Test Set is: 1.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:09:41,867]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:09:42,150]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:09:49,178]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:09:57,544]\u001b[0m Trial 1111 finished with value: 8.479146169513886 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006624143941475826, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3851814569272741, 'dropout_rate_Layer_2': 0.26585094667613524, 'dropout_rate_Layer_3': 0.024992179522569, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00039914985535987436, 'l1_Layer_2': 0.0001179713115865802, 'l1_Layer_3': 2.8304804573113586e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 265, 'n_units_Layer_3': 120}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.48 | sMAPE for Validation Set is: 46.69% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 41.73 | sMAPE for Test Set is: 48.33% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:09:59,949]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:10:04,539]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:10:07,196]\u001b[0m Trial 1110 finished with value: 9.34955651469093 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012124437014468638, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07606321593197764, 'dropout_rate_Layer_2': 0.025731250752542744, 'dropout_rate_Layer_3': 0.33024695328966364, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.8470765421812876e-05, 'l1_Layer_2': 0.00010952150406783764, 'l1_Layer_3': 0.009834042348396568, 'n_units_Layer_1': 250, 'n_units_Layer_2': 130, 'n_units_Layer_3': 85}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.35 | sMAPE for Validation Set is: 50.48% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 24.74 | sMAPE for Test Set is: 28.78% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:10:14,298]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:10:17,298]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:10:19,878]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:10:26,678]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:10:36,795]\u001b[0m Trial 1123 finished with value: 8.366787871806507 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006108384698427442, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33185036250440564, 'dropout_rate_Layer_2': 0.3354978108708347, 'dropout_rate_Layer_3': 0.17816279015754077, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3498642003234697e-05, 'l1_Layer_2': 0.00026060359997787954, 'l1_Layer_3': 0.0002659661276559633, 'n_units_Layer_1': 205, 'n_units_Layer_2': 150, 'n_units_Layer_3': 130}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.37 | sMAPE for Validation Set is: 46.30% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 23.64 | sMAPE for Test Set is: 28.53% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:10:42,624]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:10:46,250]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:10:49,420]\u001b[0m Trial 1124 finished with value: 8.192878853749612 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005923294499320256, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33392393855364577, 'dropout_rate_Layer_2': 0.3077447825624664, 'dropout_rate_Layer_3': 0.07428285206089258, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3140823008268858e-05, 'l1_Layer_2': 0.00025296635003913974, 'l1_Layer_3': 0.0002590548888192518, 'n_units_Layer_1': 230, 'n_units_Layer_2': 150, 'n_units_Layer_3': 135}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.19 | sMAPE for Validation Set is: 46.32% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 23.99 | sMAPE for Test Set is: 28.87% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:10:54,908]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:10:59,288]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:11:03,080]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:11:05,371]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:11:09,853]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:11:18,475]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:11:28,057]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:11:32,869]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:11:38,257]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:11:38,804]\u001b[0m Trial 1127 finished with value: 8.558539897252546 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005893196244536453, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3803826286169098, 'dropout_rate_Layer_2': 0.2956963373513393, 'dropout_rate_Layer_3': 0.034029321462871236, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00025909493137468, 'l1_Layer_2': 0.00018309648785912633, 'l1_Layer_3': 3.1988768293729925e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 270, 'n_units_Layer_3': 110}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.56 | sMAPE for Validation Set is: 46.86% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 40.59 | sMAPE for Test Set is: 46.74% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:11:49,096]\u001b[0m Trial 1129 finished with value: 8.390561828284541 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006020208701117544, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39991563074929076, 'dropout_rate_Layer_2': 0.21993514260357222, 'dropout_rate_Layer_3': 0.018772662674540943, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000348890661169494, 'l1_Layer_2': 0.00010511649773254087, 'l1_Layer_3': 4.689784822168762e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 270, 'n_units_Layer_3': 140}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.39 | sMAPE for Validation Set is: 47.24% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 42.67 | sMAPE for Test Set is: 50.41% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:11:52,235]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:11:58,397]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:12:01,745]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:12:08,847]\u001b[0m Trial 1132 finished with value: 8.441521600351988 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006764790787674493, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3873317395441381, 'dropout_rate_Layer_2': 0.314821540100168, 'dropout_rate_Layer_3': 0.041736590979298126, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004512656137379051, 'l1_Layer_2': 0.000142396825780088, 'l1_Layer_3': 7.850438864257611e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 250, 'n_units_Layer_3': 140}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.44 | sMAPE for Validation Set is: 46.86% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 41.29 | sMAPE for Test Set is: 47.89% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:12:09,006]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:12:20,748]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.31 | sMAPE for Validation Set is: 46.84% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 41.50 | sMAPE for Test Set is: 48.09% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:12:22,859]\u001b[0m Trial 1137 finished with value: 8.308751961939528 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006665026679391398, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37637112992126426, 'dropout_rate_Layer_2': 0.21825205924754837, 'dropout_rate_Layer_3': 0.2042904526209873, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000426447648932919, 'l1_Layer_2': 6.800157216892331e-05, 'l1_Layer_3': 5.4253034208159414e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 255, 'n_units_Layer_3': 140}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:12:28,691]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:12:32,855]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:12:36,975]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:12:41,440]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:12:46,778]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:12:46,879]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:12:57,064]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:13:00,275]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:13:00,656]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:13:04,512]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:13:13,804]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:13:18,318]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:13:22,602]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:13:44,098]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:13:54,067]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:14:01,486]\u001b[0m Trial 1156 finished with value: 8.330383378017205 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006827026911778456, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38981171141607923, 'dropout_rate_Layer_2': 0.250929650801605, 'dropout_rate_Layer_3': 0.1799528835446522, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000525093387555929, 'l1_Layer_2': 8.494947537574458e-05, 'l1_Layer_3': 0.0003750587594363721, 'n_units_Layer_1': 165, 'n_units_Layer_2': 255, 'n_units_Layer_3': 125}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.33 | sMAPE for Validation Set is: 47.13% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 40.28 | sMAPE for Test Set is: 46.20% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:14:04,144]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:14:13,691]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:14:14,605]\u001b[0m Trial 1155 finished with value: 8.286894862508486 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006754788922453616, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3999886688881853, 'dropout_rate_Layer_2': 0.2063719703517661, 'dropout_rate_Layer_3': 0.18514113486649011, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005173841508389498, 'l1_Layer_2': 8.07525053987784e-05, 'l1_Layer_3': 6.116028539642751e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 220, 'n_units_Layer_3': 125}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.29 | sMAPE for Validation Set is: 46.06% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 41.14 | sMAPE for Test Set is: 47.51% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:14:20,820]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:14:25,368]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:14:28,966]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:14:38,542]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:14:39,578]\u001b[0m Trial 1161 finished with value: 8.397538254870796 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006881412389380753, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37713065730750644, 'dropout_rate_Layer_2': 0.20870716471450015, 'dropout_rate_Layer_3': 0.007238091917280302, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004382258138186456, 'l1_Layer_2': 0.0001083641192122695, 'l1_Layer_3': 3.541903804287403e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 245, 'n_units_Layer_3': 115}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.40 | sMAPE for Validation Set is: 46.10% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 43.36 | sMAPE for Test Set is: 51.44% | rMAE for Test Set is: 1.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:14:44,999]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:14:48,598]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:14:53,538]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:15:02,530]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:15:07,111]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:15:11,897]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:15:12,108]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:15:19,378]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:15:28,628]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:15:33,734]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:15:33,995]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:15:39,129]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:15:43,666]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.42 | sMAPE for Validation Set is: 45.79% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 40.69 | sMAPE for Test Set is: 46.75% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:15:47,006]\u001b[0m Trial 1167 finished with value: 8.41799108057052 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006813827307792207, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38013769171258743, 'dropout_rate_Layer_2': 0.2543451024847067, 'dropout_rate_Layer_3': 0.27417595137504525, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006065052381960214, 'l1_Layer_2': 7.359599770587166e-05, 'l1_Layer_3': 0.0007037920161784289, 'n_units_Layer_1': 140, 'n_units_Layer_2': 255, 'n_units_Layer_3': 115}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:15:51,207]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:15:55,379]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:15:57,848]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:16:03,300]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:16:11,434]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:16:13,870]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.15 | sMAPE for Validation Set is: 45.74% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 23.10 | sMAPE for Test Set is: 27.99% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:16:17,104]\u001b[0m Trial 1180 finished with value: 8.154316484564943 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009262595602503215, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33110578480764497, 'dropout_rate_Layer_2': 0.29243297939922047, 'dropout_rate_Layer_3': 0.07402370817121756, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4644759069342402e-05, 'l1_Layer_2': 0.0001306291915626552, 'l1_Layer_3': 0.0004305137972052264, 'n_units_Layer_1': 80, 'n_units_Layer_2': 150, 'n_units_Layer_3': 140}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:16:22,853]\u001b[0m Trial 1184 finished with value: 9.339310760215797 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010186183380835592, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.031442919686029906, 'dropout_rate_Layer_2': 0.011151575098086982, 'dropout_rate_Layer_3': 0.34636451967480447, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7660381277334243e-05, 'l1_Layer_2': 7.087482826367681e-05, 'l1_Layer_3': 0.06161296505897777, 'n_units_Layer_1': 295, 'n_units_Layer_2': 170, 'n_units_Layer_3': 95}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.34 | sMAPE for Validation Set is: 48.58% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 27.44 | sMAPE for Test Set is: 30.40% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:16:23,189]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:16:28,421]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:16:31,373]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:16:37,635]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:16:45,140]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:16:58,316]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:16:59,863]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:17:06,319]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:17:10,603]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:17:13,462]\u001b[0m Trial 1195 finished with value: 8.156707149560294 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013359038412765086, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2071945020904633, 'dropout_rate_Layer_2': 0.1358553017191, 'dropout_rate_Layer_3': 0.3771190385157178, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.373963815182119e-05, 'l1_Layer_2': 0.0007067766318563868, 'l1_Layer_3': 0.0006310377655152869, 'n_units_Layer_1': 140, 'n_units_Layer_2': 135, 'n_units_Layer_3': 110}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.16 | sMAPE for Validation Set is: 47.42% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 22.22 | sMAPE for Test Set is: 27.23% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:17:28,231]\u001b[0m Trial 1189 finished with value: 8.578122857271131 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005975832280020474, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3711782030415189, 'dropout_rate_Layer_2': 0.2331743251524766, 'dropout_rate_Layer_3': 0.18492582570007146, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00041041661854452114, 'l1_Layer_2': 0.00023126417759998793, 'l1_Layer_3': 0.00016872855503679822, 'n_units_Layer_1': 145, 'n_units_Layer_2': 250, 'n_units_Layer_3': 125}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.58 | sMAPE for Validation Set is: 46.38% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 41.36 | sMAPE for Test Set is: 47.87% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:17:32,819]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:17:35,895]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:17:38,353]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:17:38,972]\u001b[0m Trial 1199 finished with value: 8.139441708334088 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011038172085667045, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2982538746533513, 'dropout_rate_Layer_2': 0.3805726901458608, 'dropout_rate_Layer_3': 0.035107490429239815, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7117049919045116e-05, 'l1_Layer_2': 0.0001246062579435754, 'l1_Layer_3': 0.0004667412807531174, 'n_units_Layer_1': 60, 'n_units_Layer_2': 130, 'n_units_Layer_3': 140}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.14 | sMAPE for Validation Set is: 46.15% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 24.46 | sMAPE for Test Set is: 29.73% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:17:48,371]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:17:52,532]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:17:53,459]\u001b[0m Trial 1204 finished with value: 8.998672988619502 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013788375039740744, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.048705756331074095, 'dropout_rate_Layer_2': 0.02030529315903415, 'dropout_rate_Layer_3': 0.3512880894800254, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3288023601236243e-05, 'l1_Layer_2': 4.432538987931582e-05, 'l1_Layer_3': 0.00018490382550150755, 'n_units_Layer_1': 265, 'n_units_Layer_2': 180, 'n_units_Layer_3': 55}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.00 | sMAPE for Validation Set is: 49.30% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 30.71 | sMAPE for Test Set is: 32.60% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:17:58,005]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:18:05,293]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:18:07,609]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:18:10,817]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:18:11,470]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:18:18,650]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:18:19,512]\u001b[0m Trial 1206 finished with value: 9.490141476356222 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020295958196006447, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04484309098912961, 'dropout_rate_Layer_2': 0.019348370461065172, 'dropout_rate_Layer_3': 0.3652971631525873, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3523242681346165e-05, 'l1_Layer_2': 4.586671317171452e-05, 'l1_Layer_3': 0.04055956333584042, 'n_units_Layer_1': 265, 'n_units_Layer_2': 180, 'n_units_Layer_3': 50}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.49 | sMAPE for Validation Set is: 49.29% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 30.31 | sMAPE for Test Set is: 31.14% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:18:26,121]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:18:29,356]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:18:33,246]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:18:33,911]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:18:39,635]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:18:42,431]\u001b[0m Trial 1215 finished with value: 8.763682627470173 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012192893632613224, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04058421077612311, 'dropout_rate_Layer_2': 0.07120184644550581, 'dropout_rate_Layer_3': 0.32605617431365647, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.2441075140323912e-05, 'l1_Layer_2': 2.7660372525489324e-05, 'l1_Layer_3': 0.00012293843465634828, 'n_units_Layer_1': 255, 'n_units_Layer_2': 195, 'n_units_Layer_3': 65}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.76 | sMAPE for Validation Set is: 48.15% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 30.87 | sMAPE for Test Set is: 31.40% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:18:42,666]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:18:47,251]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:18:50,633]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:18:55,110]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:18:55,770]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:18:56,603]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:19:04,995]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:19:10,535]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:19:15,447]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:19:19,619]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:19:29,570]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:19:33,293]\u001b[0m Trial 1230 finished with value: 8.947455229835937 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011140154323673226, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09047802536641361, 'dropout_rate_Layer_2': 0.05244743569329223, 'dropout_rate_Layer_3': 0.3060860462319107, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.1256298709523416e-05, 'l1_Layer_2': 2.64755513346396e-05, 'l1_Layer_3': 0.00010786776644187054, 'n_units_Layer_1': 255, 'n_units_Layer_2': 195, 'n_units_Layer_3': 65}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.95 | sMAPE for Validation Set is: 47.85% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 26.23 | sMAPE for Test Set is: 30.03% | rMAE for Test Set is: 0.78\n",
      "MAE for Validation Set is: 8.98 | sMAPE for Validation Set is: 48.98% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 31.01 | sMAPE for Test Set is: 31.84% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:19:34,953]\u001b[0m Trial 1228 finished with value: 8.983743170537297 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012084060902752519, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02426703942865921, 'dropout_rate_Layer_2': 0.03725205728757114, 'dropout_rate_Layer_3': 0.32382921468698145, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.2004233320557656e-05, 'l1_Layer_2': 2.915391368983687e-05, 'l1_Layer_3': 0.0001225790045723726, 'n_units_Layer_1': 255, 'n_units_Layer_2': 195, 'n_units_Layer_3': 65}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.34 | sMAPE for Validation Set is: 48.96% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 27.67 | sMAPE for Test Set is: 30.62% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:19:39,071]\u001b[0m Trial 1231 finished with value: 9.338819947869846 and parameters: {'n_hidden': 3, 'learning_rate': 0.001157053014705286, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09180794423220312, 'dropout_rate_Layer_2': 0.05457032034661732, 'dropout_rate_Layer_3': 0.30464449922119, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.0816526247138143e-05, 'l1_Layer_2': 3.025364406309101e-05, 'l1_Layer_3': 0.00015373715294890707, 'n_units_Layer_1': 255, 'n_units_Layer_2': 190, 'n_units_Layer_3': 65}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:19:39,159]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:19:44,289]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:19:47,638]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:19:48,281]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:19:50,128]\u001b[0m Trial 1234 finished with value: 9.649758878803521 and parameters: {'n_hidden': 3, 'learning_rate': 0.001172285849638101, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.021576826591104218, 'dropout_rate_Layer_2': 0.06840662124253316, 'dropout_rate_Layer_3': 0.3179218076244837, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.1100631304386755e-05, 'l1_Layer_2': 3.060799620312855e-05, 'l1_Layer_3': 0.00013592957157634598, 'n_units_Layer_1': 255, 'n_units_Layer_2': 190, 'n_units_Layer_3': 65}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.65 | sMAPE for Validation Set is: 49.96% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 26.67 | sMAPE for Test Set is: 32.58% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:19:59,404]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:20:00,134]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:20:06,830]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:20:41,768]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:20:46,471]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:20:49,080]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:20:53,959]\u001b[0m Trial 1241 finished with value: 8.394375087684478 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006509162232418578, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3904877838194223, 'dropout_rate_Layer_2': 0.21267492651401587, 'dropout_rate_Layer_3': 0.03235987103309134, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00043822765154923494, 'l1_Layer_2': 0.00016037522517018136, 'l1_Layer_3': 2.7422761258191723e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 240, 'n_units_Layer_3': 125}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.39 | sMAPE for Validation Set is: 46.60% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 42.33 | sMAPE for Test Set is: 49.51% | rMAE for Test Set is: 1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:20:56,274]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:20:58,131]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:21:03,144]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:21:07,781]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:21:12,239]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:21:18,675]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:21:18,787]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:21:28,026]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:21:32,477]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:21:34,719]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:21:46,159]\u001b[0m Trial 1251 finished with value: 9.225311166869622 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009584686455449864, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.029969634064555224, 'dropout_rate_Layer_2': 0.03528164005479761, 'dropout_rate_Layer_3': 0.3262388306664886, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.188119071541802e-05, 'l1_Layer_2': 1.5139782810103442e-05, 'l1_Layer_3': 0.0002304747767627282, 'n_units_Layer_1': 230, 'n_units_Layer_2': 210, 'n_units_Layer_3': 60}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.23 | sMAPE for Validation Set is: 49.72% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 26.81 | sMAPE for Test Set is: 29.46% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:21:50,523]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:21:54,799]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:22:19,672]\u001b[0m Trial 1262 finished with value: 9.29133599103023 and parameters: {'n_hidden': 3, 'learning_rate': 0.001445132609241887, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03724680789631777, 'dropout_rate_Layer_2': 0.0843411145958527, 'dropout_rate_Layer_3': 0.33520080761625826, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.1196349217509894e-05, 'l1_Layer_2': 2.5369605445787337e-05, 'l1_Layer_3': 7.554524922296759e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 200, 'n_units_Layer_3': 70}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.29 | sMAPE for Validation Set is: 48.36% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 26.60 | sMAPE for Test Set is: 29.31% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:22:24,339]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:22:32,617]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:22:33,157]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:22:40,024]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:22:40,775]\u001b[0m Trial 1259 finished with value: 8.493531589792765 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005463936147212629, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2808491588902646, 'dropout_rate_Layer_2': 0.22023817674055457, 'dropout_rate_Layer_3': 0.015692706446570753, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005708700524474389, 'l1_Layer_2': 0.00020891215268433982, 'l1_Layer_3': 0.00013073220992658238, 'n_units_Layer_1': 140, 'n_units_Layer_2': 265, 'n_units_Layer_3': 105}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.49 | sMAPE for Validation Set is: 46.72% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 42.74 | sMAPE for Test Set is: 50.26% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:22:41,533]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:22:46,397]\u001b[0m Trial 1242 finished with value: 8.418536719174204 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006528425502104462, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39121339179771586, 'dropout_rate_Layer_2': 0.21522380696386684, 'dropout_rate_Layer_3': 0.029507874885199258, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004216741164294184, 'l1_Layer_2': 0.00014804943459713647, 'l1_Layer_3': 2.7078184871220577e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 270, 'n_units_Layer_3': 125}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.42 | sMAPE for Validation Set is: 46.05% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 41.26 | sMAPE for Test Set is: 47.64% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:22:52,214]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:22:55,135]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:22:56,140]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:23:00,085]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:23:05,366]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:23:07,600]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:23:11,932]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:23:13,918]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:23:22,862]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:23:23,792]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:23:24,030]\u001b[0m Trial 1275 finished with value: 8.29528452035396 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012739517128940716, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30860446244299267, 'dropout_rate_Layer_2': 0.38207007236512897, 'dropout_rate_Layer_3': 0.06229468733669378, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.1896711349751225e-05, 'l1_Layer_2': 0.00023980847489732976, 'l1_Layer_3': 0.0002265948092963442, 'n_units_Layer_1': 205, 'n_units_Layer_2': 140, 'n_units_Layer_3': 135}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.30 | sMAPE for Validation Set is: 46.66% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 24.18 | sMAPE for Test Set is: 29.22% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:23:24,564]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:23:33,271]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:23:33,480]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:23:39,181]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:23:41,592]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:23:43,946]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:23:50,459]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:23:56,517]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:24:01,619]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:24:09,580]\u001b[0m Trial 1288 finished with value: 8.123229038633454 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008103599818073599, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32195837953996725, 'dropout_rate_Layer_2': 0.36001180653353765, 'dropout_rate_Layer_3': 0.050188479915996245, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.3922864826161797e-05, 'l1_Layer_2': 0.000318505053899451, 'l1_Layer_3': 0.0001417537915511075, 'n_units_Layer_1': 215, 'n_units_Layer_2': 155, 'n_units_Layer_3': 125}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.12 | sMAPE for Validation Set is: 47.06% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 25.15 | sMAPE for Test Set is: 31.15% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:24:13,915]\u001b[0m Trial 1285 finished with value: 9.401658665147112 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008319555131302127, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07429436829939488, 'dropout_rate_Layer_2': 0.04540061777022653, 'dropout_rate_Layer_3': 0.3389114063662238, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.599297178478582e-05, 'l1_Layer_2': 4.137588750919389e-05, 'l1_Layer_3': 0.00012274920344578134, 'n_units_Layer_1': 270, 'n_units_Layer_2': 195, 'n_units_Layer_3': 60}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.40 | sMAPE for Validation Set is: 49.49% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 24.12 | sMAPE for Test Set is: 29.68% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:24:23,682]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:24:26,145]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:24:32,854]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:24:33,995]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:24:38,628]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:24:41,021]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:24:45,396]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:24:48,822]\u001b[0m Trial 1290 finished with value: 8.82517427008063 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017660262474019685, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07476718215172073, 'dropout_rate_Layer_2': 0.0734299743381057, 'dropout_rate_Layer_3': 0.34188865701590443, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.547411631793825e-05, 'l1_Layer_2': 3.895790533198168e-05, 'l1_Layer_3': 9.856418495874503e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 200, 'n_units_Layer_3': 80}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.83 | sMAPE for Validation Set is: 48.23% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 28.96 | sMAPE for Test Set is: 31.03% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:24:51,714]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:25:00,274]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:25:10,359]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:25:15,494]\u001b[0m Trial 1300 finished with value: 8.456035956840688 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012879276645351777, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10398586825448697, 'dropout_rate_Layer_2': 0.05523046332971355, 'dropout_rate_Layer_3': 0.29956450671150364, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.320157868568259e-05, 'l1_Layer_2': 1.0296464546541653e-05, 'l1_Layer_3': 9.369638786644208e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 205, 'n_units_Layer_3': 85}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.46 | sMAPE for Validation Set is: 48.19% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 23.04 | sMAPE for Test Set is: 28.84% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:25:16,744]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:25:22,368]\u001b[0m Trial 1284 finished with value: 8.41291365294528 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005037791881076953, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39288805604870397, 'dropout_rate_Layer_2': 0.22748709897026087, 'dropout_rate_Layer_3': 0.13533226934167292, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006674279204630303, 'l1_Layer_2': 7.929196859132291e-05, 'l1_Layer_3': 2.9840123994300286e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 280, 'n_units_Layer_3': 120}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.41 | sMAPE for Validation Set is: 46.11% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 41.50 | sMAPE for Test Set is: 48.18% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:25:27,304]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:25:28,113]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:25:35,353]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:25:39,951]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.28 | sMAPE for Validation Set is: 46.65% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 23.13 | sMAPE for Test Set is: 29.08% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:25:42,920]\u001b[0m Trial 1299 finished with value: 8.28488006347927 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017434389225698466, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05608735516288767, 'dropout_rate_Layer_2': 0.028638811736126476, 'dropout_rate_Layer_3': 0.299126338973246, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.328807681038415e-05, 'l1_Layer_2': 2.11564027277001e-05, 'l1_Layer_3': 4.794092355582962e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 165, 'n_units_Layer_3': 55}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:25:47,118]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:25:51,052]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:25:51,583]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:25:57,263]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:25:57,467]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:26:04,330]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:26:08,263]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:26:10,952]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:26:14,713]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:26:16,253]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:26:17,362]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:26:21,118]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:26:26,689]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:26:27,521]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:26:30,676]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:26:30,945]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:26:40,654]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:26:40,791]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:26:41,637]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:26:48,392]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:27:00,468]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:27:04,514]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.29 | sMAPE for Validation Set is: 47.43% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 22.93 | sMAPE for Test Set is: 28.33% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:27:08,031]\u001b[0m Trial 1331 finished with value: 8.28877853447843 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007464255039118416, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30047107339843815, 'dropout_rate_Layer_2': 0.34339578884153654, 'dropout_rate_Layer_3': 0.04790101261746076, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5858446094255522e-05, 'l1_Layer_2': 4.0493304468366684e-05, 'l1_Layer_3': 0.0001804822942434239, 'n_units_Layer_1': 225, 'n_units_Layer_2': 135, 'n_units_Layer_3': 140}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:27:11,475]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:27:16,534]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:27:22,794]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:27:27,968]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:27:31,886]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:27:37,080]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:27:57,499]\u001b[0m Trial 1337 finished with value: 13.95065391534329 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017990911664789023, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10103539420659809, 'dropout_rate_Layer_2': 0.06829816669314467, 'dropout_rate_Layer_3': 0.30233080173165755, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 6.147781484956199e-05, 'l1_Layer_2': 1.2439761342119883e-05, 'l1_Layer_3': 4.468212711539433e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 215, 'n_units_Layer_3': 80}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.95 | sMAPE for Validation Set is: 64.79% | rMAE for Validation Set is: 1.07\n",
      "MAE for Test Set is: 70.58 | sMAPE for Test Set is: 114.12% | rMAE for Test Set is: 2.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:28:30,879]\u001b[0m Trial 1329 finished with value: 8.298010381707297 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005525778592928303, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3697023977929506, 'dropout_rate_Layer_2': 0.2089126114420086, 'dropout_rate_Layer_3': 0.04010654757950445, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007634277122317333, 'l1_Layer_2': 0.00010282955053712919, 'l1_Layer_3': 0.00010185458294845778, 'n_units_Layer_1': 135, 'n_units_Layer_2': 250, 'n_units_Layer_3': 120}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.30 | sMAPE for Validation Set is: 47.06% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 40.18 | sMAPE for Test Set is: 46.01% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:28:50,786]\u001b[0m Trial 1341 finished with value: 8.397725020256603 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010785879269309964, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11552641605393145, 'dropout_rate_Layer_2': 0.07849884212093858, 'dropout_rate_Layer_3': 0.2836373123272876, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.47816063878602e-05, 'l1_Layer_2': 2.280584061649485e-05, 'l1_Layer_3': 0.00010078076966456892, 'n_units_Layer_1': 245, 'n_units_Layer_2': 205, 'n_units_Layer_3': 70}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.40 | sMAPE for Validation Set is: 47.94% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 22.97 | sMAPE for Test Set is: 28.36% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:29:02,744]\u001b[0m Trial 1342 finished with value: 8.301943561225894 and parameters: {'n_hidden': 3, 'learning_rate': 0.001270197810412634, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08577927218550804, 'dropout_rate_Layer_2': 0.09330528609778461, 'dropout_rate_Layer_3': 0.27056662652003155, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.5718432508791794e-05, 'l1_Layer_2': 2.1659367158528902e-05, 'l1_Layer_3': 7.346473583663487e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 205, 'n_units_Layer_3': 70}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.30 | sMAPE for Validation Set is: 49.16% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 23.37 | sMAPE for Test Set is: 29.83% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:29:06,240]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:29:08,895]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:29:13,636]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:29:25,095]\u001b[0m Trial 1340 finished with value: 8.622641751120211 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007825452170803283, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3806731078118369, 'dropout_rate_Layer_2': 0.2661083721279048, 'dropout_rate_Layer_3': 0.18777658772154834, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008712923611751482, 'l1_Layer_2': 0.00012843757978936958, 'l1_Layer_3': 2.441873210229519e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 255, 'n_units_Layer_3': 145}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.62 | sMAPE for Validation Set is: 46.50% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 42.86 | sMAPE for Test Set is: 50.33% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:29:37,586]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:29:41,950]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:29:46,837]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:29:47,631]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:29:54,836]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:30:00,372]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:30:01,166]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:30:01,486]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:30:11,827]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:30:54,275]\u001b[0m Trial 1355 finished with value: 8.749456263366765 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017895328850946175, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38060996343495695, 'dropout_rate_Layer_2': 0.29485353886846355, 'dropout_rate_Layer_3': 0.0002421356207177039, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007802097544022174, 'l1_Layer_2': 6.708019937112882e-05, 'l1_Layer_3': 6.385383398684493e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 250, 'n_units_Layer_3': 100}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.75 | sMAPE for Validation Set is: 47.51% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 42.01 | sMAPE for Test Set is: 49.04% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:31:02,052]\u001b[0m Trial 1343 finished with value: 8.488347778314017 and parameters: {'n_hidden': 3, 'learning_rate': 0.000502820148955991, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36005678430910043, 'dropout_rate_Layer_2': 0.19534315230175797, 'dropout_rate_Layer_3': 0.03912478553764189, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006564422882752016, 'l1_Layer_2': 8.371335749809648e-05, 'l1_Layer_3': 0.00013176197230456568, 'n_units_Layer_1': 145, 'n_units_Layer_2': 255, 'n_units_Layer_3': 115}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.49 | sMAPE for Validation Set is: 47.12% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 41.06 | sMAPE for Test Set is: 47.59% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:31:10,878]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:31:22,945]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:31:29,419]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:31:41,299]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:31:45,762]\u001b[0m Trial 1359 finished with value: 8.460488334999747 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005940704925075167, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3725574795431315, 'dropout_rate_Layer_2': 0.2496885374105206, 'dropout_rate_Layer_3': 0.015332649983076194, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017518551000915585, 'l1_Layer_2': 0.00010712220306272552, 'l1_Layer_3': 0.00017575585467762507, 'n_units_Layer_1': 155, 'n_units_Layer_2': 265, 'n_units_Layer_3': 110}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.46 | sMAPE for Validation Set is: 46.49% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 42.09 | sMAPE for Test Set is: 49.07% | rMAE for Test Set is: 1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:31:54,897]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:31:59,988]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:32:03,457]\u001b[0m Trial 1357 finished with value: 8.437381917503053 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005461851900767102, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3744397213714916, 'dropout_rate_Layer_2': 0.24859275006206621, 'dropout_rate_Layer_3': 0.017845442793199873, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007822152985797944, 'l1_Layer_2': 7.203681807984681e-05, 'l1_Layer_3': 6.309129792052811e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 265, 'n_units_Layer_3': 115}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.44 | sMAPE for Validation Set is: 46.44% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 40.92 | sMAPE for Test Set is: 47.51% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:32:06,091]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:32:09,954]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:32:10,385]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:32:21,295]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:32:29,832]\u001b[0m Trial 1354 finished with value: 8.354552549331162 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005945515698798342, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3783202554940299, 'dropout_rate_Layer_2': 0.2972932511447812, 'dropout_rate_Layer_3': 0.01741843379299294, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007838923190169669, 'l1_Layer_2': 6.907290189920886e-05, 'l1_Layer_3': 5.2435723489854684e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 245, 'n_units_Layer_3': 100}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.35 | sMAPE for Validation Set is: 46.67% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 41.90 | sMAPE for Test Set is: 48.73% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:32:38,598]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:33:09,973]\u001b[0m Trial 1363 finished with value: 8.374385242796846 and parameters: {'n_hidden': 3, 'learning_rate': 0.000620544380857018, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37410404583181134, 'dropout_rate_Layer_2': 0.2146848317884568, 'dropout_rate_Layer_3': 0.025885748854316652, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007976188635778579, 'l1_Layer_2': 9.997200874038512e-05, 'l1_Layer_3': 5.1612772477722095e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 235, 'n_units_Layer_3': 150}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.37 | sMAPE for Validation Set is: 46.05% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 42.67 | sMAPE for Test Set is: 50.05% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:33:17,917]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:33:22,243]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:33:31,375]\u001b[0m Trial 1373 finished with value: 8.44981635177783 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015383338887259678, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11491713616289978, 'dropout_rate_Layer_2': 0.07331745992473962, 'dropout_rate_Layer_3': 0.27776524330733593, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.730594343728236e-05, 'l1_Layer_2': 1.2395598861197879e-05, 'l1_Layer_3': 9.046409799763722e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 200, 'n_units_Layer_3': 70}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.45 | sMAPE for Validation Set is: 46.87% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 21.95 | sMAPE for Test Set is: 26.77% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:33:37,954]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:33:47,321]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:33:47,837]\u001b[0m Trial 1371 finished with value: 8.295034642786673 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010712191794560292, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10931500955293992, 'dropout_rate_Layer_2': 0.07555987242916692, 'dropout_rate_Layer_3': 0.26633432861949363, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.916341109596562e-05, 'l1_Layer_2': 1.0295011778222742e-05, 'l1_Layer_3': 9.857463393313877e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 205, 'n_units_Layer_3': 70}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.30 | sMAPE for Validation Set is: 46.41% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 26.14 | sMAPE for Test Set is: 33.06% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:33:59,345]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:34:08,294]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:34:13,374]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:34:14,139]\u001b[0m Trial 1369 finished with value: 8.276607325858778 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014792646927067094, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12923758261854282, 'dropout_rate_Layer_2': 0.07575273012866215, 'dropout_rate_Layer_3': 0.2658094783015113, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.464220544818633e-05, 'l1_Layer_2': 2.098900757890074e-05, 'l1_Layer_3': 9.771218462426825e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 205, 'n_units_Layer_3': 70}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.28 | sMAPE for Validation Set is: 49.19% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 21.30 | sMAPE for Test Set is: 26.46% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:34:21,067]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:34:23,417]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:34:30,439]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:34:34,341]\u001b[0m Trial 1376 finished with value: 8.393077951074615 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010898437724835921, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11463576193627592, 'dropout_rate_Layer_2': 0.092807210923901, 'dropout_rate_Layer_3': 0.2636170661195469, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.109181099437657e-05, 'l1_Layer_2': 2.3663275472777717e-05, 'l1_Layer_3': 9.597256587878573e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 200, 'n_units_Layer_3': 70}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.39 | sMAPE for Validation Set is: 46.83% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 23.40 | sMAPE for Test Set is: 29.53% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:34:37,443]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:34:40,532]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:34:47,197]\u001b[0m Trial 1386 finished with value: 8.18223435156919 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005487294066807249, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3160293872680476, 'dropout_rate_Layer_2': 0.35032300371333347, 'dropout_rate_Layer_3': 0.057174016239192604, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.799744440849129e-05, 'l1_Layer_2': 0.0002976667213758166, 'l1_Layer_3': 8.784785170309091e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 160, 'n_units_Layer_3': 120}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.18 | sMAPE for Validation Set is: 47.05% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 23.42 | sMAPE for Test Set is: 28.33% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:34:50,158]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:34:56,060]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:35:01,829]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:35:06,268]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:35:12,028]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:35:20,694]\u001b[0m Trial 1380 finished with value: 8.436092340188964 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010827370805138268, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1469143035077168, 'dropout_rate_Layer_2': 0.07596019757846459, 'dropout_rate_Layer_3': 0.26672468114759895, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.806718219024219e-05, 'l1_Layer_2': 1.0719395097529455e-05, 'l1_Layer_3': 9.570283472081988e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 200, 'n_units_Layer_3': 70}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:35:20,794]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.44 | sMAPE for Validation Set is: 46.86% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 25.30 | sMAPE for Test Set is: 31.88% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:35:32,991]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:35:38,434]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:36:30,295]\u001b[0m Trial 1389 finished with value: 8.363752363308322 and parameters: {'n_hidden': 3, 'learning_rate': 0.000500385503796704, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.383558871674308, 'dropout_rate_Layer_2': 0.20977467515525444, 'dropout_rate_Layer_3': 0.04588056778898246, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005889277103445921, 'l1_Layer_2': 0.0002087159373455148, 'l1_Layer_3': 3.194621800936313e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 240, 'n_units_Layer_3': 185}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.36 | sMAPE for Validation Set is: 49.24% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 40.71 | sMAPE for Test Set is: 47.16% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:36:33,903]\u001b[0m Trial 1391 finished with value: 8.338201658597757 and parameters: {'n_hidden': 3, 'learning_rate': 0.000664880116357262, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3798867524216565, 'dropout_rate_Layer_2': 0.2219199637156607, 'dropout_rate_Layer_3': 0.057273569881194794, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007587227761174991, 'l1_Layer_2': 0.00020471473935105265, 'l1_Layer_3': 6.914170659446083e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 240, 'n_units_Layer_3': 120}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.34 | sMAPE for Validation Set is: 46.61% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 41.33 | sMAPE for Test Set is: 47.98% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:36:37,169]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:36:41,283]\u001b[0m Trial 1399 finished with value: 8.280946531675708 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010900862176970274, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14558203880597106, 'dropout_rate_Layer_2': 0.09392165880056773, 'dropout_rate_Layer_3': 0.26368371666307705, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.13578000843183e-05, 'l1_Layer_2': 1.0202980092954675e-05, 'l1_Layer_3': 9.101605974474077e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 205, 'n_units_Layer_3': 80}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.28 | sMAPE for Validation Set is: 46.22% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 24.87 | sMAPE for Test Set is: 31.49% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:36:43,734]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:36:44,633]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:36:47,746]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:36:55,162]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:36:59,156]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:37:06,724]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:37:14,480]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:37:16,907]\u001b[0m Trial 1400 finished with value: 8.221232033230246 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010829997312675984, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13873645711820184, 'dropout_rate_Layer_2': 0.0957467118556207, 'dropout_rate_Layer_3': 0.25077003270485015, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010245185871207336, 'l1_Layer_2': 1.1269839011063248e-05, 'l1_Layer_3': 9.836171907549358e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 205, 'n_units_Layer_3': 80}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.22 | sMAPE for Validation Set is: 45.94% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 22.30 | sMAPE for Test Set is: 27.62% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:37:32,812]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:37:38,570]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:37:46,597]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:37:52,735]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:38:02,415]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:38:22,424]\u001b[0m Trial 1408 finished with value: 8.319975057122823 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010508328789638356, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14165855499158886, 'dropout_rate_Layer_2': 0.09365576516087429, 'dropout_rate_Layer_3': 0.24671448846389382, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.025614670050705e-05, 'l1_Layer_2': 1.0260661526974641e-05, 'l1_Layer_3': 2.6788399038941235e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 205, 'n_units_Layer_3': 80}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.32 | sMAPE for Validation Set is: 46.07% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 27.45 | sMAPE for Test Set is: 35.49% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:38:44,036]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:39:13,451]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:39:30,057]\u001b[0m Trial 1406 finished with value: 8.561002566054698 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006867776070365188, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3773021701202943, 'dropout_rate_Layer_2': 0.22011801930408098, 'dropout_rate_Layer_3': 0.15588111816742606, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007301571920372555, 'l1_Layer_2': 0.0001768084053782532, 'l1_Layer_3': 8.645912676995377e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 155, 'n_units_Layer_3': 155}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.56 | sMAPE for Validation Set is: 47.22% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 42.81 | sMAPE for Test Set is: 50.64% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:39:37,657]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:39:44,240]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:39:49,537]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:39:59,632]\u001b[0m Trial 1419 finished with value: 8.274440089386983 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010433659363350864, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14382965987086674, 'dropout_rate_Layer_2': 0.1118238031683802, 'dropout_rate_Layer_3': 0.24836312077568481, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010438324610431743, 'l1_Layer_2': 1.013245955482724e-05, 'l1_Layer_3': 2.275242760069902e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 220, 'n_units_Layer_3': 100}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.27 | sMAPE for Validation Set is: 47.24% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 25.02 | sMAPE for Test Set is: 32.19% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:40:03,784]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:40:09,094]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:40:25,462]\u001b[0m Trial 1417 finished with value: 8.167054266846405 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005514569386846579, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3912808611458221, 'dropout_rate_Layer_2': 0.21623994958736037, 'dropout_rate_Layer_3': 0.20200870261701476, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009536229111846821, 'l1_Layer_2': 0.0002615519785021498, 'l1_Layer_3': 4.9531292956473856e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 245, 'n_units_Layer_3': 120}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.17 | sMAPE for Validation Set is: 45.48% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 41.12 | sMAPE for Test Set is: 47.65% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:40:30,179]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:40:36,586]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:40:42,111]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:40:47,757]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:40:51,287]\u001b[0m Trial 1424 finished with value: 8.171899906556911 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005017383953490576, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3951860235579489, 'dropout_rate_Layer_2': 0.21318235845076025, 'dropout_rate_Layer_3': 0.037737023968916907, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000592197973782823, 'l1_Layer_2': 8.74022855090587e-05, 'l1_Layer_3': 7.075773905480889e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 245, 'n_units_Layer_3': 110}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.17 | sMAPE for Validation Set is: 46.56% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 22.18 | sMAPE for Test Set is: 27.22% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:40:55,635]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:40:55,959]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:41:04,177]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:41:11,826]\u001b[0m Trial 1427 finished with value: 8.144949197817523 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006007765058041232, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37114554947859374, 'dropout_rate_Layer_2': 0.20651551397908305, 'dropout_rate_Layer_3': 0.19177685244353726, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005617940944144696, 'l1_Layer_2': 8.627737129389654e-05, 'l1_Layer_3': 0.00011013689479044582, 'n_units_Layer_1': 125, 'n_units_Layer_2': 275, 'n_units_Layer_3': 130}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.14 | sMAPE for Validation Set is: 45.78% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 22.45 | sMAPE for Test Set is: 27.04% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:41:19,164]\u001b[0m Trial 1435 finished with value: 8.266918352145941 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006294259812562961, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29926872576449337, 'dropout_rate_Layer_2': 0.3313958506875199, 'dropout_rate_Layer_3': 0.039980360140293145, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.029210115874652e-05, 'l1_Layer_2': 5.7787006595501544e-05, 'l1_Layer_3': 0.00019655257254454128, 'n_units_Layer_1': 255, 'n_units_Layer_2': 160, 'n_units_Layer_3': 115}. Best is trial 702 with value: 8.07295418478348.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.27 | sMAPE for Validation Set is: 46.28% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 24.68 | sMAPE for Test Set is: 30.02% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:41:24,246]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:41:37,628]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:41:47,357]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:41:56,455]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:42:00,447]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:42:06,312]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:42:19,976]\u001b[0m Trial 1436 finished with value: 7.97517376623944 and parameters: {'n_hidden': 3, 'learning_rate': 0.000556943034950437, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3991043558373655, 'dropout_rate_Layer_2': 0.21114365437831717, 'dropout_rate_Layer_3': 0.22296942710500423, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005240879923719263, 'l1_Layer_2': 0.00024733511751860775, 'l1_Layer_3': 0.00010938539356546956, 'n_units_Layer_1': 125, 'n_units_Layer_2': 250, 'n_units_Layer_3': 110}. Best is trial 1436 with value: 7.97517376623944.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.98 | sMAPE for Validation Set is: 45.28% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 23.35 | sMAPE for Test Set is: 28.59% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:42:24,194]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:42:25,933]\u001b[0m Trial 1426 finished with value: 7.9164403190369015 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005962798961633229, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36958318946026103, 'dropout_rate_Layer_2': 0.2138637780478502, 'dropout_rate_Layer_3': 0.03831977944613168, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005142520936528831, 'l1_Layer_2': 8.011882764143453e-05, 'l1_Layer_3': 0.00010887548682695125, 'n_units_Layer_1': 125, 'n_units_Layer_2': 245, 'n_units_Layer_3': 130}. Best is trial 1426 with value: 7.9164403190369015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.92 | sMAPE for Validation Set is: 44.37% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 22.96 | sMAPE for Test Set is: 28.01% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:42:30,921]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:42:38,469]\u001b[0m Trial 1440 finished with value: 8.121140193287196 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006290889780902121, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39946801975254687, 'dropout_rate_Layer_2': 0.20543259850441578, 'dropout_rate_Layer_3': 0.19094690365459435, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005554843420000981, 'l1_Layer_2': 7.994268695630106e-05, 'l1_Layer_3': 0.00015609779939601307, 'n_units_Layer_1': 125, 'n_units_Layer_2': 175, 'n_units_Layer_3': 110}. Best is trial 1426 with value: 7.9164403190369015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.12 | sMAPE for Validation Set is: 45.81% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 22.47 | sMAPE for Test Set is: 27.36% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:42:42,357]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:42:53,960]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:42:59,209]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:42:59,752]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:43:00,713]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:43:06,435]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:43:10,325]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:43:11,565]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:43:18,540]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:43:23,368]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:43:27,912]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:43:30,810]\u001b[0m Trial 1444 finished with value: 8.388637249715204 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009441446287498294, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14346731798062637, 'dropout_rate_Layer_2': 0.11169317253745983, 'dropout_rate_Layer_3': 0.24585645208083987, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.4580711423959e-05, 'l1_Layer_2': 1.1313400009230705e-05, 'l1_Layer_3': 2.4152681435856278e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 220, 'n_units_Layer_3': 100}. Best is trial 1426 with value: 7.9164403190369015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.39 | sMAPE for Validation Set is: 46.27% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 25.58 | sMAPE for Test Set is: 32.00% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:43:31,844]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:43:36,859]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:43:37,260]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:43:44,831]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:43:45,118]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:43:50,954]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:43:51,923]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:43:58,530]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:44:03,605]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:44:06,282]\u001b[0m Trial 1465 finished with value: 8.309158492237243 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008253123778919438, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3177585416590238, 'dropout_rate_Layer_2': 0.35840569444481074, 'dropout_rate_Layer_3': 0.06610566550522641, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4491731128497524e-05, 'l1_Layer_2': 0.0003785789606614492, 'l1_Layer_3': 6.626741037043847e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 150, 'n_units_Layer_3': 135}. Best is trial 1426 with value: 7.9164403190369015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.31 | sMAPE for Validation Set is: 47.06% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 26.42 | sMAPE for Test Set is: 32.46% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:44:11,000]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:44:14,193]\u001b[0m Trial 1455 finished with value: 8.045251515058172 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007544112331070616, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39352098557318144, 'dropout_rate_Layer_2': 0.19737581635504317, 'dropout_rate_Layer_3': 0.19223517439203888, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005101503460712165, 'l1_Layer_2': 8.138501034783555e-05, 'l1_Layer_3': 0.00015879864423974614, 'n_units_Layer_1': 125, 'n_units_Layer_2': 195, 'n_units_Layer_3': 105}. Best is trial 1426 with value: 7.9164403190369015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.05 | sMAPE for Validation Set is: 45.53% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 22.11 | sMAPE for Test Set is: 27.07% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:44:17,175]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:44:18,904]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:44:24,920]\u001b[0m Trial 1469 finished with value: 8.251138311396168 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008205083166086772, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3307146417490134, 'dropout_rate_Layer_2': 0.3569045629245014, 'dropout_rate_Layer_3': 0.06598247218136007, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4859366060675685e-05, 'l1_Layer_2': 0.00038997540133411533, 'l1_Layer_3': 6.484299389524757e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 150, 'n_units_Layer_3': 135}. Best is trial 1426 with value: 7.9164403190369015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.25 | sMAPE for Validation Set is: 46.66% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 23.64 | sMAPE for Test Set is: 28.56% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:44:31,040]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:44:36,234]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:44:42,425]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:44:46,834]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:44:51,431]\u001b[0m Trial 1474 finished with value: 8.220122255180117 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008460169391597033, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39314227933820856, 'dropout_rate_Layer_2': 0.1981820489597212, 'dropout_rate_Layer_3': 0.20775818676303653, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004122451611707132, 'l1_Layer_2': 7.827670549801761e-05, 'l1_Layer_3': 0.00020148829276611858, 'n_units_Layer_1': 125, 'n_units_Layer_2': 195, 'n_units_Layer_3': 100}. Best is trial 1426 with value: 7.9164403190369015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.22 | sMAPE for Validation Set is: 45.59% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 23.10 | sMAPE for Test Set is: 27.85% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:44:57,219]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:44:58,449]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.27 | sMAPE for Validation Set is: 46.21% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 23.25 | sMAPE for Test Set is: 28.09% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:45:00,595]\u001b[0m Trial 1473 finished with value: 8.27246901225399 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005996805326350954, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39230223126567026, 'dropout_rate_Layer_2': 0.20090265160465173, 'dropout_rate_Layer_3': 0.20499659205546317, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00042002741039085743, 'l1_Layer_2': 6.049648826126552e-05, 'l1_Layer_3': 0.0002133611912427888, 'n_units_Layer_1': 125, 'n_units_Layer_2': 265, 'n_units_Layer_3': 100}. Best is trial 1426 with value: 7.9164403190369015.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:45:07,335]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:45:07,615]\u001b[0m Trial 1475 finished with value: 8.270236569614312 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008085677456165168, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39310355396020613, 'dropout_rate_Layer_2': 0.20013544667079194, 'dropout_rate_Layer_3': 0.18972797571764322, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003935514145888977, 'l1_Layer_2': 5.6873943191479254e-05, 'l1_Layer_3': 0.00018019708914844085, 'n_units_Layer_1': 125, 'n_units_Layer_2': 185, 'n_units_Layer_3': 100}. Best is trial 1426 with value: 7.9164403190369015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.27 | sMAPE for Validation Set is: 46.43% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 22.32 | sMAPE for Test Set is: 27.25% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:45:13,157]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:45:17,543]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:45:20,448]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:45:25,627]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:45:30,933]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:45:31,195]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:45:44,205]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:45:47,468]\u001b[0m Trial 1484 finished with value: 8.057541809502986 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008097171895209862, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3993525482354253, 'dropout_rate_Layer_2': 0.19123178866582127, 'dropout_rate_Layer_3': 0.21568221143755323, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00038575759123572566, 'l1_Layer_2': 4.984789596064888e-05, 'l1_Layer_3': 0.00017904949183498512, 'n_units_Layer_1': 125, 'n_units_Layer_2': 200, 'n_units_Layer_3': 95}. Best is trial 1426 with value: 7.9164403190369015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.06 | sMAPE for Validation Set is: 45.22% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 24.67 | sMAPE for Test Set is: 30.62% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:46:19,711]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:46:36,236]\u001b[0m Trial 1495 finished with value: 8.273933075291685 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010374942589694036, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3063395571035122, 'dropout_rate_Layer_2': 0.3206291902319969, 'dropout_rate_Layer_3': 0.05350813369791705, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.741374499668912e-05, 'l1_Layer_2': 0.0005598731830750651, 'l1_Layer_3': 8.889752937275757e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 140, 'n_units_Layer_3': 145}. Best is trial 1426 with value: 7.9164403190369015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.27 | sMAPE for Validation Set is: 46.90% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 25.04 | sMAPE for Test Set is: 30.66% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:46:41,057]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:46:41,081]\u001b[0m Trial 1491 finished with value: 8.106402581942406 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007894354672628482, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3886254998797753, 'dropout_rate_Layer_2': 0.2086661971819028, 'dropout_rate_Layer_3': 0.20810562841657984, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00047629396287236385, 'l1_Layer_2': 4.9291910024448646e-05, 'l1_Layer_3': 0.00021193098246199285, 'n_units_Layer_1': 125, 'n_units_Layer_2': 180, 'n_units_Layer_3': 105}. Best is trial 1426 with value: 7.9164403190369015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.11 | sMAPE for Validation Set is: 44.62% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 23.11 | sMAPE for Test Set is: 28.05% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:46:48,630]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:46:48,758]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:46:52,814]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 07:46:54,580]\u001b[0m Trial 1494 finished with value: 8.224109321042079 and parameters: {'n_hidden': 3, 'learning_rate': 0.001050778355956121, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14550606292460147, 'dropout_rate_Layer_2': 0.11725609017383762, 'dropout_rate_Layer_3': 0.2492353305355086, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011529846837175492, 'l1_Layer_2': 1.0446186242719041e-05, 'l1_Layer_3': 2.0268370291922565e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 235, 'n_units_Layer_3': 85}. Best is trial 1426 with value: 7.9164403190369015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.22 | sMAPE for Validation Set is: 45.85% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 28.60 | sMAPE for Test Set is: 37.27% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 07:47:04,996]\u001b[0m Trial 1493 finished with value: 8.183491239054346 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009348403122714765, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14606681202742705, 'dropout_rate_Layer_2': 0.11445023037803326, 'dropout_rate_Layer_3': 0.2476018460511934, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011436724469395947, 'l1_Layer_2': 1.0500640805621457e-05, 'l1_Layer_3': 2.728539847788452e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 230, 'n_units_Layer_3': 100}. Best is trial 1426 with value: 7.9164403190369015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.18 | sMAPE for Validation Set is: 46.79% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 21.02 | sMAPE for Test Set is: 26.04% | rMAE for Test Set is: 0.62\n",
      "for 2021-01-01, MAE is:5.25 & sMAPE is:10.79% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :5.25 & 10.79% & 0.37\n",
      "for 2021-01-02, MAE is:9.61 & sMAPE is:20.03% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :7.43 & 15.41% & 0.33\n",
      "for 2021-01-03, MAE is:15.67 & sMAPE is:44.14% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :10.18 & 24.99% & 0.34\n",
      "for 2021-01-04, MAE is:9.65 & sMAPE is:22.36% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :10.05 & 24.33% & 0.50\n",
      "for 2021-01-05, MAE is:9.36 & sMAPE is:18.91% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :9.91 & 23.25% & 0.65\n",
      "for 2021-01-06, MAE is:4.17 & sMAPE is:9.20% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :8.95 & 20.91% & 0.65\n",
      "for 2021-01-07, MAE is:26.87 & sMAPE is:46.60% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :11.51 & 24.58% & 0.72\n",
      "for 2021-01-08, MAE is:20.20 & sMAPE is:25.96% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :12.60 & 24.75% & 0.71\n",
      "for 2021-01-09, MAE is:2.28 & sMAPE is:3.86% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :11.45 & 22.43% & 0.67\n",
      "for 2021-01-10, MAE is:3.66 & sMAPE is:7.84% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :10.67 & 20.97% & 0.62\n",
      "for 2021-01-11, MAE is:6.80 & sMAPE is:16.46% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :10.32 & 20.56% & 0.62\n",
      "for 2021-01-12, MAE is:7.09 & sMAPE is:18.59% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :10.05 & 20.40% & 0.67\n",
      "for 2021-01-13, MAE is:4.36 & sMAPE is:11.23% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :9.61 & 19.69% & 0.68\n",
      "for 2021-01-14, MAE is:21.33 & sMAPE is:31.99% & rMAE is:4.82 ||| daily mean of MAE & sMAPE & rMAE till now are :10.45 & 20.57% & 0.97\n",
      "for 2021-01-15, MAE is:9.76 & sMAPE is:13.15% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :10.40 & 20.07% & 0.98\n",
      "for 2021-01-16, MAE is:5.13 & sMAPE is:8.72% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :10.07 & 19.36% & 1.00\n",
      "for 2021-01-17, MAE is:5.51 & sMAPE is:10.27% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :9.81 & 18.83% & 0.97\n",
      "for 2021-01-18, MAE is:6.14 & sMAPE is:10.88% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :9.60 & 18.39% & 0.94\n",
      "for 2021-01-19, MAE is:4.13 & sMAPE is:9.12% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :9.31 & 17.90% & 0.93\n",
      "for 2021-01-20, MAE is:7.06 & sMAPE is:18.31% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :9.20 & 17.92% & 0.93\n",
      "for 2021-01-21, MAE is:10.26 & sMAPE is:41.42% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :9.25 & 19.04% & 0.90\n",
      "for 2021-01-22, MAE is:3.98 & sMAPE is:16.38% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :9.01 & 18.92% & 0.86\n",
      "for 2021-01-23, MAE is:24.55 & sMAPE is:63.42% & rMAE is:3.79 ||| daily mean of MAE & sMAPE & rMAE till now are :9.69 & 20.85% & 0.99\n",
      "for 2021-01-24, MAE is:4.48 & sMAPE is:8.79% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :9.47 & 20.35% & 0.99\n",
      "for 2021-01-25, MAE is:8.46 & sMAPE is:13.88% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :9.43 & 20.09% & 1.00\n",
      "for 2021-01-26, MAE is:12.90 & sMAPE is:23.14% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :9.56 & 20.21% & 0.99\n",
      "for 2021-01-27, MAE is:9.30 & sMAPE is:17.00% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :9.55 & 20.09% & 0.97\n",
      "for 2021-01-28, MAE is:5.48 & sMAPE is:9.66% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :9.41 & 19.72% & 0.94\n",
      "for 2021-01-29, MAE is:4.73 & sMAPE is:9.65% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :9.25 & 19.37% & 0.92\n",
      "for 2021-01-30, MAE is:5.28 & sMAPE is:10.59% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :9.11 & 19.08% & 0.94\n",
      "for 2021-01-31, MAE is:3.64 & sMAPE is:7.21% & rMAE is:2.27 ||| daily mean of MAE & sMAPE & rMAE till now are :8.94 & 18.70% & 0.98\n",
      "for 2021-02-01, MAE is:4.77 & sMAPE is:8.49% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :8.81 & 18.38% & 0.97\n",
      "for 2021-02-02, MAE is:4.15 & sMAPE is:7.52% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :8.67 & 18.05% & 0.96\n",
      "for 2021-02-03, MAE is:3.20 & sMAPE is:7.68% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :8.51 & 17.74% & 0.94\n",
      "for 2021-02-04, MAE is:12.20 & sMAPE is:25.25% & rMAE is:1.83 ||| daily mean of MAE & sMAPE & rMAE till now are :8.61 & 17.96% & 0.97\n",
      "for 2021-02-05, MAE is:2.28 & sMAPE is:4.51% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :8.44 & 17.58% & 0.96\n",
      "for 2021-02-06, MAE is:6.74 & sMAPE is:18.69% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :8.39 & 17.61% & 0.95\n",
      "for 2021-02-07, MAE is:12.95 & sMAPE is:96.00% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :8.51 & 19.68% & 0.94\n",
      "for 2021-02-08, MAE is:12.59 & sMAPE is:42.22% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :8.61 & 20.25% & 0.94\n",
      "for 2021-02-09, MAE is:18.74 & sMAPE is:33.87% & rMAE is:2.02 ||| daily mean of MAE & sMAPE & rMAE till now are :8.87 & 20.59% & 0.96\n",
      "for 2021-02-10, MAE is:14.38 & sMAPE is:19.76% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :9.00 & 20.57% & 0.95\n",
      "for 2021-02-11, MAE is:16.21 & sMAPE is:18.84% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :9.17 & 20.53% & 0.94\n",
      "for 2021-02-12, MAE is:4.23 & sMAPE is:6.70% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :9.06 & 20.21% & 0.93\n",
      "for 2021-02-13, MAE is:5.15 & sMAPE is:9.36% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :8.97 & 19.96% & 0.92\n",
      "for 2021-02-14, MAE is:4.26 & sMAPE is:9.40% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :8.87 & 19.73% & 0.90\n",
      "for 2021-02-15, MAE is:3.14 & sMAPE is:6.36% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :8.74 & 19.44% & 0.89\n",
      "for 2021-02-16, MAE is:5.02 & sMAPE is:9.34% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :8.66 & 19.22% & 0.88\n",
      "for 2021-02-17, MAE is:4.32 & sMAPE is:8.36% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :8.57 & 19.00% & 0.86\n",
      "for 2021-02-18, MAE is:10.43 & sMAPE is:19.78% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :8.61 & 19.01% & 0.85\n",
      "for 2021-02-19, MAE is:6.55 & sMAPE is:14.88% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :8.57 & 18.93% & 0.84\n",
      "for 2021-02-20, MAE is:9.44 & sMAPE is:25.30% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :8.59 & 19.06% & 0.84\n",
      "for 2021-02-21, MAE is:8.45 & sMAPE is:27.41% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :8.58 & 19.22% & 0.83\n",
      "for 2021-02-22, MAE is:7.14 & sMAPE is:14.76% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :8.56 & 19.13% & 0.84\n",
      "for 2021-02-23, MAE is:5.89 & sMAPE is:13.15% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :8.51 & 19.02% & 0.84\n",
      "for 2021-02-24, MAE is:9.28 & sMAPE is:27.52% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :8.52 & 19.18% & 0.84\n",
      "for 2021-02-25, MAE is:3.34 & sMAPE is:9.38% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :8.43 & 19.00% & 0.83\n",
      "for 2021-02-26, MAE is:4.87 & sMAPE is:14.85% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :8.37 & 18.93% & 0.82\n",
      "for 2021-02-27, MAE is:12.82 & sMAPE is:32.45% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :8.44 & 19.16% & 0.82\n",
      "for 2021-02-28, MAE is:7.13 & sMAPE is:17.02% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :8.42 & 19.13% & 0.82\n",
      "for 2021-03-01, MAE is:6.76 & sMAPE is:13.70% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :8.39 & 19.04% & 0.83\n",
      "for 2021-03-02, MAE is:9.48 & sMAPE is:18.50% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :8.41 & 19.03% & 0.84\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-03-03, MAE is:6.78 & sMAPE is:12.75% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :8.38 & 18.93% & 0.83\n",
      "for 2021-03-04, MAE is:9.26 & sMAPE is:18.70% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :8.40 & 18.92% & 0.82\n",
      "for 2021-03-05, MAE is:5.46 & sMAPE is:10.20% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :8.35 & 18.79% & 0.81\n",
      "for 2021-03-06, MAE is:8.96 & sMAPE is:25.88% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :8.36 & 18.89% & 0.81\n",
      "for 2021-03-07, MAE is:10.97 & sMAPE is:30.24% & rMAE is:1.95 ||| daily mean of MAE & sMAPE & rMAE till now are :8.40 & 19.07% & 0.83\n",
      "for 2021-03-08, MAE is:11.72 & sMAPE is:18.92% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :8.45 & 19.06% & 0.83\n",
      "for 2021-03-09, MAE is:6.33 & sMAPE is:9.72% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :8.42 & 18.93% & 0.83\n",
      "for 2021-03-10, MAE is:11.08 & sMAPE is:22.98% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :8.46 & 18.99% & 0.84\n",
      "for 2021-03-11, MAE is:6.73 & sMAPE is:45.78% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :8.43 & 19.37% & 0.83\n",
      "for 2021-03-12, MAE is:13.40 & sMAPE is:66.91% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :8.50 & 20.04% & 0.83\n",
      "for 2021-03-13, MAE is:14.64 & sMAPE is:79.92% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :8.59 & 20.87% & 0.82\n",
      "for 2021-03-14, MAE is:15.37 & sMAPE is:93.54% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :8.68 & 21.86% & 0.82\n",
      "for 2021-03-15, MAE is:7.33 & sMAPE is:17.48% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :8.66 & 21.81% & 0.82\n",
      "for 2021-03-16, MAE is:4.86 & sMAPE is:8.51% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :8.61 & 21.63% & 0.82\n",
      "for 2021-03-17, MAE is:6.50 & sMAPE is:10.93% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :8.58 & 21.49% & 0.82\n",
      "for 2021-03-18, MAE is:5.25 & sMAPE is:7.73% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :8.54 & 21.31% & 0.81\n",
      "for 2021-03-19, MAE is:8.59 & sMAPE is:15.52% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :8.54 & 21.23% & 0.80\n",
      "for 2021-03-20, MAE is:8.27 & sMAPE is:21.95% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :8.54 & 21.24% & 0.79\n",
      "for 2021-03-21, MAE is:9.69 & sMAPE is:27.87% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :8.55 & 21.33% & 0.79\n",
      "for 2021-03-22, MAE is:9.50 & sMAPE is:17.57% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :8.56 & 21.28% & 0.79\n",
      "for 2021-03-23, MAE is:7.57 & sMAPE is:13.25% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :8.55 & 21.18% & 0.80\n",
      "for 2021-03-24, MAE is:10.06 & sMAPE is:18.61% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :8.57 & 21.15% & 0.81\n",
      "for 2021-03-25, MAE is:9.36 & sMAPE is:16.16% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :8.58 & 21.09% & 0.81\n",
      "for 2021-03-26, MAE is:9.82 & sMAPE is:21.38% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :8.59 & 21.10% & 0.81\n",
      "for 2021-03-27, MAE is:17.07 & sMAPE is:64.13% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :8.69 & 21.60% & 0.81\n",
      "for 2021-03-28, MAE is:18.51 & sMAPE is:70.34% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :8.81 & 22.16% & 0.81\n",
      "for 2021-03-29, MAE is:9.48 & sMAPE is:29.62% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :8.81 & 22.24% & 0.80\n",
      "for 2021-03-30, MAE is:7.41 & sMAPE is:17.16% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :8.80 & 22.18% & 0.80\n",
      "for 2021-03-31, MAE is:8.72 & sMAPE is:14.89% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :8.80 & 22.10% & 0.80\n",
      "for 2021-04-01, MAE is:8.73 & sMAPE is:18.32% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :8.80 & 22.06% & 0.80\n",
      "for 2021-04-02, MAE is:18.32 & sMAPE is:54.76% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :8.90 & 22.42% & 0.81\n",
      "for 2021-04-03, MAE is:8.86 & sMAPE is:25.54% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :8.90 & 22.45% & 0.81\n",
      "for 2021-04-04, MAE is:21.09 & sMAPE is:84.24% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :9.03 & 23.11% & 0.81\n",
      "for 2021-04-05, MAE is:25.02 & sMAPE is:162.68% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :9.20 & 24.58% & 0.81\n",
      "for 2021-04-06, MAE is:11.18 & sMAPE is:65.44% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :9.22 & 25.00% & 0.81\n",
      "for 2021-04-07, MAE is:7.79 & sMAPE is:15.89% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :9.20 & 24.91% & 0.81\n",
      "for 2021-04-08, MAE is:12.27 & sMAPE is:28.27% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :9.23 & 24.94% & 0.81\n",
      "for 2021-04-09, MAE is:4.66 & sMAPE is:17.57% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :9.19 & 24.87% & 0.80\n",
      "for 2021-04-10, MAE is:22.29 & sMAPE is:51.43% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :9.32 & 25.13% & 0.81\n",
      "for 2021-04-11, MAE is:5.86 & sMAPE is:11.59% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :9.28 & 25.00% & 0.80\n",
      "for 2021-04-12, MAE is:4.78 & sMAPE is:11.45% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :9.24 & 24.87% & 0.80\n",
      "for 2021-04-13, MAE is:7.90 & sMAPE is:15.84% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :9.23 & 24.78% & 0.79\n",
      "for 2021-04-14, MAE is:22.01 & sMAPE is:34.74% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :9.35 & 24.87% & 0.80\n",
      "for 2021-04-15, MAE is:11.13 & sMAPE is:17.04% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :9.37 & 24.80% & 0.79\n",
      "for 2021-04-16, MAE is:7.92 & sMAPE is:14.06% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :9.35 & 24.70% & 0.79\n",
      "for 2021-04-17, MAE is:15.92 & sMAPE is:30.32% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :9.42 & 24.75% & 0.80\n",
      "for 2021-04-18, MAE is:6.42 & sMAPE is:10.45% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :9.39 & 24.62% & 0.79\n",
      "for 2021-04-19, MAE is:15.62 & sMAPE is:21.73% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :9.44 & 24.59% & 0.79\n",
      "for 2021-04-20, MAE is:15.94 & sMAPE is:22.58% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :9.50 & 24.57% & 0.79\n",
      "for 2021-04-21, MAE is:24.36 & sMAPE is:43.19% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :9.64 & 24.74% & 0.79\n",
      "for 2021-04-22, MAE is:12.28 & sMAPE is:45.69% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :9.66 & 24.93% & 0.79\n",
      "for 2021-04-23, MAE is:7.02 & sMAPE is:15.68% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :9.64 & 24.85% & 0.79\n",
      "for 2021-04-24, MAE is:8.77 & sMAPE is:20.32% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :9.63 & 24.81% & 0.79\n",
      "for 2021-04-25, MAE is:18.10 & sMAPE is:57.76% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :9.70 & 25.09% & 0.79\n",
      "for 2021-04-26, MAE is:8.89 & sMAPE is:14.64% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :9.70 & 25.00% & 0.79\n",
      "for 2021-04-27, MAE is:10.50 & sMAPE is:17.21% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :9.70 & 24.94% & 0.79\n",
      "for 2021-04-28, MAE is:8.77 & sMAPE is:14.64% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :9.70 & 24.85% & 0.79\n",
      "for 2021-04-29, MAE is:4.18 & sMAPE is:7.22% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :9.65 & 24.70% & 0.78\n",
      "for 2021-04-30, MAE is:25.32 & sMAPE is:45.31% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :9.78 & 24.87% & 0.78\n",
      "for 2021-05-01, MAE is:6.26 & sMAPE is:10.78% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :9.75 & 24.76% & 0.78\n",
      "for 2021-05-02, MAE is:7.24 & sMAPE is:19.48% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :9.73 & 24.71% & 0.78\n",
      "for 2021-05-03, MAE is:14.94 & sMAPE is:26.27% & rMAE is:4.76 ||| daily mean of MAE & sMAPE & rMAE till now are :9.77 & 24.73% & 0.82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-05-04, MAE is:22.43 & sMAPE is:71.26% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :9.87 & 25.10% & 0.81\n",
      "for 2021-05-05, MAE is:17.49 & sMAPE is:56.03% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :9.94 & 25.35% & 0.81\n",
      "for 2021-05-06, MAE is:18.82 & sMAPE is:32.57% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :10.01 & 25.41% & 0.82\n",
      "for 2021-05-07, MAE is:8.43 & sMAPE is:12.19% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :9.99 & 25.30% & 0.82\n",
      "for 2021-05-08, MAE is:10.28 & sMAPE is:22.08% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :10.00 & 25.28% & 0.82\n",
      "for 2021-05-09, MAE is:36.28 & sMAPE is:144.26% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :10.20 & 26.20% & 0.82\n",
      "for 2021-05-10, MAE is:10.37 & sMAPE is:18.76% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :10.20 & 26.14% & 0.83\n",
      "for 2021-05-11, MAE is:15.72 & sMAPE is:24.22% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :10.24 & 26.13% & 0.82\n",
      "for 2021-05-12, MAE is:3.46 & sMAPE is:5.09% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :10.19 & 25.97% & 0.82\n",
      "for 2021-05-13, MAE is:7.89 & sMAPE is:12.30% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :10.17 & 25.87% & 0.82\n",
      "for 2021-05-14, MAE is:6.42 & sMAPE is:8.95% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :10.15 & 25.74% & 0.82\n",
      "for 2021-05-15, MAE is:6.18 & sMAPE is:10.16% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :10.12 & 25.62% & 0.82\n",
      "for 2021-05-16, MAE is:22.11 & sMAPE is:59.10% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :10.21 & 25.87% & 0.81\n",
      "for 2021-05-17, MAE is:8.08 & sMAPE is:10.90% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :10.19 & 25.76% & 0.81\n",
      "for 2021-05-18, MAE is:6.15 & sMAPE is:8.29% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :10.16 & 25.63% & 0.82\n",
      "for 2021-05-19, MAE is:7.09 & sMAPE is:9.00% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :10.14 & 25.51% & 0.82\n",
      "for 2021-05-20, MAE is:10.39 & sMAPE is:16.38% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :10.14 & 25.45% & 0.82\n",
      "for 2021-05-21, MAE is:23.76 & sMAPE is:67.00% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :10.24 & 25.74% & 0.82\n",
      "for 2021-05-22, MAE is:24.95 & sMAPE is:145.88% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :10.34 & 26.59% & 0.82\n",
      "for 2021-05-23, MAE is:21.56 & sMAPE is:97.06% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :10.42 & 27.08% & 0.82\n",
      "for 2021-05-24, MAE is:16.02 & sMAPE is:41.05% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :10.46 & 27.18% & 0.82\n",
      "for 2021-05-25, MAE is:8.65 & sMAPE is:15.07% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :10.45 & 27.10% & 0.82\n",
      "for 2021-05-26, MAE is:7.90 & sMAPE is:12.43% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :10.43 & 27.00% & 0.82\n",
      "for 2021-05-27, MAE is:14.63 & sMAPE is:22.22% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :10.46 & 26.96% & 0.82\n",
      "for 2021-05-28, MAE is:6.71 & sMAPE is:9.14% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :10.43 & 26.84% & 0.82\n",
      "for 2021-05-29, MAE is:10.05 & sMAPE is:22.07% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :10.43 & 26.81% & 0.81\n",
      "for 2021-05-30, MAE is:21.65 & sMAPE is:59.90% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :10.50 & 27.03% & 0.81\n",
      "for 2021-05-31, MAE is:11.18 & sMAPE is:17.72% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :10.51 & 26.97% & 0.81\n",
      "for 2021-06-01, MAE is:7.49 & sMAPE is:11.01% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :10.49 & 26.86% & 0.81\n",
      "for 2021-06-02, MAE is:7.97 & sMAPE is:12.19% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :10.47 & 26.77% & 0.82\n",
      "for 2021-06-03, MAE is:6.48 & sMAPE is:10.66% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :10.45 & 26.66% & 0.81\n",
      "for 2021-06-04, MAE is:13.48 & sMAPE is:20.98% & rMAE is:2.72 ||| daily mean of MAE & sMAPE & rMAE till now are :10.47 & 26.63% & 0.83\n",
      "for 2021-06-05, MAE is:4.25 & sMAPE is:6.71% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :10.43 & 26.50% & 0.82\n",
      "for 2021-06-06, MAE is:5.11 & sMAPE is:8.41% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :10.39 & 26.38% & 0.82\n",
      "for 2021-06-07, MAE is:10.43 & sMAPE is:14.17% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :10.39 & 26.31% & 0.82\n",
      "for 2021-06-08, MAE is:6.01 & sMAPE is:7.70% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :10.36 & 26.19% & 0.82\n",
      "for 2021-06-09, MAE is:5.50 & sMAPE is:7.00% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :10.33 & 26.07% & 0.82\n",
      "for 2021-06-10, MAE is:9.31 & sMAPE is:12.15% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :10.33 & 25.98% & 0.82\n",
      "for 2021-06-11, MAE is:6.01 & sMAPE is:7.65% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :10.30 & 25.87% & 0.82\n",
      "for 2021-06-12, MAE is:30.45 & sMAPE is:69.77% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :10.42 & 26.14% & 0.82\n",
      "for 2021-06-13, MAE is:32.47 & sMAPE is:132.26% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :10.56 & 26.79% & 0.82\n",
      "for 2021-06-14, MAE is:11.96 & sMAPE is:17.01% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :10.57 & 26.73% & 0.82\n",
      "for 2021-06-15, MAE is:6.83 & sMAPE is:8.34% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :10.54 & 26.62% & 0.82\n",
      "for 2021-06-16, MAE is:8.72 & sMAPE is:10.01% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :10.53 & 26.52% & 0.82\n",
      "for 2021-06-17, MAE is:11.99 & sMAPE is:15.27% & rMAE is:1.78 ||| daily mean of MAE & sMAPE & rMAE till now are :10.54 & 26.45% & 0.83\n",
      "for 2021-06-18, MAE is:7.07 & sMAPE is:8.81% & rMAE is:1.78 ||| daily mean of MAE & sMAPE & rMAE till now are :10.52 & 26.35% & 0.83\n",
      "for 2021-06-19, MAE is:10.18 & sMAPE is:14.81% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :10.52 & 26.28% & 0.83\n",
      "for 2021-06-20, MAE is:13.43 & sMAPE is:24.58% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :10.54 & 26.27% & 0.83\n",
      "for 2021-06-21, MAE is:7.26 & sMAPE is:9.30% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :10.52 & 26.17% & 0.83\n",
      "for 2021-06-22, MAE is:5.20 & sMAPE is:6.06% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :10.49 & 26.05% & 0.83\n",
      "for 2021-06-23, MAE is:9.82 & sMAPE is:9.88% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :10.48 & 25.96% & 0.83\n",
      "for 2021-06-24, MAE is:6.81 & sMAPE is:6.83% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :10.46 & 25.85% & 0.83\n",
      "for 2021-06-25, MAE is:6.57 & sMAPE is:7.19% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :10.44 & 25.75% & 0.83\n",
      "for 2021-06-26, MAE is:7.21 & sMAPE is:9.00% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :10.42 & 25.65% & 0.83\n",
      "for 2021-06-27, MAE is:14.31 & sMAPE is:24.10% & rMAE is:2.06 ||| daily mean of MAE & sMAPE & rMAE till now are :10.44 & 25.64% & 0.84\n",
      "for 2021-06-28, MAE is:6.85 & sMAPE is:7.49% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :10.42 & 25.54% & 0.84\n",
      "for 2021-06-29, MAE is:5.16 & sMAPE is:5.89% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :10.39 & 25.43% & 0.84\n",
      "for 2021-06-30, MAE is:4.78 & sMAPE is:5.32% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :10.36 & 25.32% & 0.83\n",
      "for 2021-07-01, MAE is:5.09 & sMAPE is:5.68% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :10.33 & 25.21% & 0.83\n",
      "for 2021-07-02, MAE is:10.94 & sMAPE is:11.81% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :10.34 & 25.14% & 0.84\n",
      "for 2021-07-03, MAE is:11.95 & sMAPE is:14.02% & rMAE is:2.00 ||| daily mean of MAE & sMAPE & rMAE till now are :10.35 & 25.08% & 0.84\n",
      "for 2021-07-04, MAE is:8.29 & sMAPE is:9.76% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :10.34 & 25.00% & 0.84\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-07-05, MAE is:5.76 & sMAPE is:6.13% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :10.31 & 24.89% & 0.84\n",
      "for 2021-07-06, MAE is:15.17 & sMAPE is:18.36% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :10.34 & 24.86% & 0.84\n",
      "for 2021-07-07, MAE is:13.51 & sMAPE is:14.28% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :10.35 & 24.80% & 0.84\n",
      "for 2021-07-08, MAE is:13.23 & sMAPE is:11.97% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :10.37 & 24.74% & 0.84\n",
      "for 2021-07-09, MAE is:7.11 & sMAPE is:7.60% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :10.35 & 24.65% & 0.85\n",
      "for 2021-07-10, MAE is:8.03 & sMAPE is:9.76% & rMAE is:2.16 ||| daily mean of MAE & sMAPE & rMAE till now are :10.34 & 24.57% & 0.85\n",
      "for 2021-07-11, MAE is:8.71 & sMAPE is:10.79% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :10.33 & 24.50% & 0.86\n",
      "for 2021-07-12, MAE is:6.32 & sMAPE is:6.76% & rMAE is:2.01 ||| daily mean of MAE & sMAPE & rMAE till now are :10.31 & 24.40% & 0.86\n",
      "for 2021-07-13, MAE is:7.05 & sMAPE is:7.69% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :10.29 & 24.32% & 0.86\n",
      "for 2021-07-14, MAE is:7.11 & sMAPE is:8.15% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :10.28 & 24.23% & 0.86\n",
      "for 2021-07-15, MAE is:11.26 & sMAPE is:13.54% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :10.28 & 24.18% & 0.86\n",
      "for 2021-07-16, MAE is:5.35 & sMAPE is:6.40% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :10.26 & 24.09% & 0.86\n",
      "for 2021-07-17, MAE is:18.96 & sMAPE is:31.43% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :10.30 & 24.13% & 0.86\n",
      "for 2021-07-18, MAE is:19.69 & sMAPE is:54.49% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :10.35 & 24.28% & 0.85\n",
      "for 2021-07-19, MAE is:22.58 & sMAPE is:28.98% & rMAE is:3.59 ||| daily mean of MAE & sMAPE & rMAE till now are :10.41 & 24.30% & 0.87\n",
      "for 2021-07-20, MAE is:19.19 & sMAPE is:24.48% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :10.45 & 24.30% & 0.87\n",
      "for 2021-07-21, MAE is:8.31 & sMAPE is:9.31% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :10.44 & 24.23% & 0.87\n",
      "for 2021-07-22, MAE is:6.37 & sMAPE is:7.29% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :10.42 & 24.15% & 0.87\n",
      "for 2021-07-23, MAE is:11.32 & sMAPE is:13.21% & rMAE is:2.84 ||| daily mean of MAE & sMAPE & rMAE till now are :10.43 & 24.09% & 0.88\n",
      "for 2021-07-24, MAE is:5.95 & sMAPE is:8.02% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :10.41 & 24.01% & 0.88\n",
      "for 2021-07-25, MAE is:9.67 & sMAPE is:14.60% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :10.40 & 23.97% & 0.87\n",
      "for 2021-07-26, MAE is:5.70 & sMAPE is:6.51% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :10.38 & 23.88% & 0.88\n",
      "for 2021-07-27, MAE is:7.27 & sMAPE is:8.17% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :10.36 & 23.81% & 0.87\n",
      "for 2021-07-28, MAE is:10.83 & sMAPE is:13.75% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :10.37 & 23.76% & 0.87\n",
      "for 2021-07-29, MAE is:29.64 & sMAPE is:72.26% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :10.46 & 23.99% & 0.87\n",
      "for 2021-07-30, MAE is:10.54 & sMAPE is:17.12% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :10.46 & 23.96% & 0.87\n",
      "for 2021-07-31, MAE is:26.48 & sMAPE is:60.34% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :10.53 & 24.13% & 0.87\n",
      "for 2021-08-01, MAE is:7.52 & sMAPE is:14.87% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :10.52 & 24.09% & 0.87\n",
      "for 2021-08-02, MAE is:13.16 & sMAPE is:15.80% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :10.53 & 24.05% & 0.87\n",
      "for 2021-08-03, MAE is:8.02 & sMAPE is:7.98% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :10.52 & 23.97% & 0.87\n",
      "for 2021-08-04, MAE is:9.26 & sMAPE is:9.39% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :10.51 & 23.91% & 0.87\n",
      "for 2021-08-05, MAE is:17.84 & sMAPE is:19.95% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :10.55 & 23.89% & 0.87\n",
      "for 2021-08-06, MAE is:6.99 & sMAPE is:9.91% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :10.53 & 23.82% & 0.86\n",
      "for 2021-08-07, MAE is:11.47 & sMAPE is:20.30% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :10.54 & 23.81% & 0.86\n",
      "for 2021-08-08, MAE is:42.01 & sMAPE is:142.34% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :10.68 & 24.35% & 0.86\n",
      "for 2021-08-09, MAE is:14.54 & sMAPE is:21.33% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :10.70 & 24.33% & 0.86\n",
      "for 2021-08-10, MAE is:9.62 & sMAPE is:10.06% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :10.69 & 24.27% & 0.87\n",
      "for 2021-08-11, MAE is:13.03 & sMAPE is:12.80% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :10.70 & 24.22% & 0.87\n",
      "for 2021-08-12, MAE is:12.46 & sMAPE is:11.65% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :10.71 & 24.16% & 0.87\n",
      "for 2021-08-13, MAE is:9.63 & sMAPE is:10.21% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :10.71 & 24.10% & 0.87\n",
      "for 2021-08-14, MAE is:21.74 & sMAPE is:39.02% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :10.75 & 24.16% & 0.87\n",
      "for 2021-08-15, MAE is:13.83 & sMAPE is:25.59% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :10.77 & 24.17% & 0.87\n",
      "for 2021-08-16, MAE is:11.52 & sMAPE is:14.62% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :10.77 & 24.13% & 0.86\n",
      "for 2021-08-17, MAE is:8.14 & sMAPE is:12.77% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :10.76 & 24.08% & 0.86\n",
      "for 2021-08-18, MAE is:6.77 & sMAPE is:8.98% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :10.74 & 24.01% & 0.86\n",
      "for 2021-08-19, MAE is:16.88 & sMAPE is:18.68% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :10.77 & 23.99% & 0.86\n",
      "for 2021-08-20, MAE is:9.27 & sMAPE is:9.23% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :10.76 & 23.93% & 0.86\n",
      "for 2021-08-21, MAE is:8.71 & sMAPE is:9.39% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :10.75 & 23.86% & 0.86\n",
      "for 2021-08-22, MAE is:6.96 & sMAPE is:8.84% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :10.74 & 23.80% & 0.86\n",
      "for 2021-08-23, MAE is:12.20 & sMAPE is:13.43% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :10.74 & 23.76% & 0.86\n",
      "for 2021-08-24, MAE is:11.21 & sMAPE is:11.81% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :10.75 & 23.71% & 0.85\n",
      "for 2021-08-25, MAE is:7.99 & sMAPE is:9.75% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :10.73 & 23.65% & 0.85\n",
      "for 2021-08-26, MAE is:11.15 & sMAPE is:12.72% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :10.74 & 23.60% & 0.85\n",
      "for 2021-08-27, MAE is:12.77 & sMAPE is:14.92% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :10.74 & 23.56% & 0.85\n",
      "for 2021-08-28, MAE is:5.71 & sMAPE is:6.77% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :10.72 & 23.49% & 0.85\n",
      "for 2021-08-29, MAE is:5.40 & sMAPE is:6.42% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :10.70 & 23.42% & 0.86\n",
      "for 2021-08-30, MAE is:18.69 & sMAPE is:17.96% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :10.73 & 23.40% & 0.86\n",
      "for 2021-08-31, MAE is:15.96 & sMAPE is:15.19% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :10.76 & 23.37% & 0.86\n",
      "for 2021-09-01, MAE is:16.13 & sMAPE is:14.84% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :10.78 & 23.33% & 0.86\n",
      "for 2021-09-02, MAE is:19.57 & sMAPE is:17.40% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :10.81 & 23.31% & 0.86\n",
      "for 2021-09-03, MAE is:17.14 & sMAPE is:15.98% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :10.84 & 23.28% & 0.86\n",
      "for 2021-09-04, MAE is:11.36 & sMAPE is:10.63% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :10.84 & 23.23% & 0.86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-09-05, MAE is:16.04 & sMAPE is:16.69% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :10.86 & 23.20% & 0.86\n",
      "for 2021-09-06, MAE is:24.61 & sMAPE is:19.97% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :10.92 & 23.19% & 0.86\n",
      "for 2021-09-07, MAE is:14.92 & sMAPE is:11.79% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :10.93 & 23.14% & 0.86\n",
      "for 2021-09-08, MAE is:14.66 & sMAPE is:11.91% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :10.95 & 23.10% & 0.86\n",
      "for 2021-09-09, MAE is:19.31 & sMAPE is:15.34% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :10.98 & 23.07% & 0.86\n",
      "for 2021-09-10, MAE is:14.60 & sMAPE is:10.80% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :11.00 & 23.02% & 0.86\n",
      "for 2021-09-11, MAE is:11.46 & sMAPE is:8.97% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :11.00 & 22.96% & 0.86\n",
      "for 2021-09-12, MAE is:20.79 & sMAPE is:19.07% & rMAE is:2.68 ||| daily mean of MAE & sMAPE & rMAE till now are :11.04 & 22.95% & 0.86\n",
      "for 2021-09-13, MAE is:29.49 & sMAPE is:22.23% & rMAE is:2.20 ||| daily mean of MAE & sMAPE & rMAE till now are :11.11 & 22.95% & 0.87\n",
      "for 2021-09-14, MAE is:17.30 & sMAPE is:11.94% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :11.13 & 22.90% & 0.87\n",
      "for 2021-09-15, MAE is:40.53 & sMAPE is:26.83% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :11.25 & 22.92% & 0.87\n",
      "for 2021-09-16, MAE is:18.73 & sMAPE is:11.89% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :11.28 & 22.88% & 0.87\n",
      "for 2021-09-17, MAE is:18.63 & sMAPE is:12.82% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :11.30 & 22.84% & 0.87\n",
      "for 2021-09-18, MAE is:16.55 & sMAPE is:12.45% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :11.32 & 22.80% & 0.87\n",
      "for 2021-09-19, MAE is:24.70 & sMAPE is:24.30% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :11.37 & 22.80% & 0.87\n",
      "for 2021-09-20, MAE is:40.98 & sMAPE is:30.11% & rMAE is:3.03 ||| daily mean of MAE & sMAPE & rMAE till now are :11.49 & 22.83% & 0.88\n",
      "for 2021-09-21, MAE is:23.77 & sMAPE is:16.49% & rMAE is:1.94 ||| daily mean of MAE & sMAPE & rMAE till now are :11.53 & 22.81% & 0.89\n",
      "for 2021-09-22, MAE is:25.46 & sMAPE is:18.37% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :11.59 & 22.79% & 0.89\n",
      "for 2021-09-23, MAE is:38.85 & sMAPE is:53.11% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :11.69 & 22.90% & 0.88\n",
      "for 2021-09-24, MAE is:22.47 & sMAPE is:25.34% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :11.73 & 22.91% & 0.88\n",
      "for 2021-09-25, MAE is:43.46 & sMAPE is:38.98% & rMAE is:1.98 ||| daily mean of MAE & sMAPE & rMAE till now are :11.85 & 22.97% & 0.89\n",
      "for 2021-09-26, MAE is:24.27 & sMAPE is:19.23% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :11.89 & 22.96% & 0.89\n",
      "for 2021-09-27, MAE is:26.88 & sMAPE is:20.91% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :11.95 & 22.95% & 0.89\n",
      "for 2021-09-28, MAE is:42.39 & sMAPE is:29.16% & rMAE is:2.76 ||| daily mean of MAE & sMAPE & rMAE till now are :12.06 & 22.97% & 0.89\n",
      "for 2021-09-29, MAE is:33.00 & sMAPE is:25.11% & rMAE is:1.79 ||| daily mean of MAE & sMAPE & rMAE till now are :12.14 & 22.98% & 0.90\n",
      "for 2021-09-30, MAE is:16.22 & sMAPE is:16.85% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :12.15 & 22.96% & 0.90\n",
      "for 2021-10-01, MAE is:11.62 & sMAPE is:16.70% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :12.15 & 22.94% & 0.89\n",
      "for 2021-10-02, MAE is:33.60 & sMAPE is:36.95% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :12.23 & 22.99% & 0.89\n",
      "for 2021-10-03, MAE is:40.96 & sMAPE is:134.71% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :12.33 & 23.39% & 0.89\n",
      "for 2021-10-04, MAE is:43.20 & sMAPE is:30.76% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :12.45 & 23.42% & 0.89\n",
      "for 2021-10-05, MAE is:39.47 & sMAPE is:25.09% & rMAE is:2.12 ||| daily mean of MAE & sMAPE & rMAE till now are :12.54 & 23.42% & 0.90\n",
      "for 2021-10-06, MAE is:77.50 & sMAPE is:48.32% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :12.78 & 23.51% & 0.90\n",
      "for 2021-10-07, MAE is:122.82 & sMAPE is:50.22% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :13.17 & 23.61% & 0.90\n",
      "for 2021-10-08, MAE is:60.17 & sMAPE is:27.27% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :13.34 & 23.62% & 0.90\n",
      "for 2021-10-09, MAE is:34.79 & sMAPE is:24.99% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :13.41 & 23.63% & 0.90\n",
      "for 2021-10-10, MAE is:37.62 & sMAPE is:27.87% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :13.50 & 23.64% & 0.89\n",
      "for 2021-10-11, MAE is:42.55 & sMAPE is:33.10% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :13.60 & 23.68% & 0.90\n",
      "for 2021-10-12, MAE is:35.83 & sMAPE is:22.42% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :13.68 & 23.67% & 0.90\n",
      "for 2021-10-13, MAE is:23.52 & sMAPE is:12.44% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :13.71 & 23.63% & 0.90\n",
      "for 2021-10-14, MAE is:62.75 & sMAPE is:47.92% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :13.88 & 23.72% & 0.90\n",
      "for 2021-10-15, MAE is:14.53 & sMAPE is:22.60% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :13.88 & 23.71% & 0.89\n",
      "for 2021-10-16, MAE is:14.07 & sMAPE is:14.88% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :13.89 & 23.68% & 0.89\n",
      "for 2021-10-17, MAE is:27.10 & sMAPE is:18.06% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :13.93 & 23.66% & 0.89\n",
      "for 2021-10-18, MAE is:47.77 & sMAPE is:26.92% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :14.05 & 23.67% & 0.89\n",
      "for 2021-10-19, MAE is:33.80 & sMAPE is:23.73% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :14.11 & 23.67% & 0.89\n",
      "for 2021-10-20, MAE is:47.45 & sMAPE is:76.02% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :14.23 & 23.85% & 0.89\n",
      "for 2021-10-21, MAE is:20.30 & sMAPE is:41.53% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :14.25 & 23.91% & 0.89\n",
      "for 2021-10-22, MAE is:30.33 & sMAPE is:63.68% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :14.30 & 24.05% & 0.89\n",
      "for 2021-10-23, MAE is:90.52 & sMAPE is:109.45% & rMAE is:1.85 ||| daily mean of MAE & sMAPE & rMAE till now are :14.56 & 24.34% & 0.89\n",
      "for 2021-10-24, MAE is:52.57 & sMAPE is:46.41% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :14.69 & 24.41% & 0.89\n",
      "for 2021-10-25, MAE is:12.76 & sMAPE is:10.82% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :14.68 & 24.36% & 0.89\n",
      "for 2021-10-26, MAE is:39.16 & sMAPE is:25.84% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :14.76 & 24.37% & 0.89\n",
      "for 2021-10-27, MAE is:59.19 & sMAPE is:103.49% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :14.91 & 24.63% & 0.89\n",
      "for 2021-10-28, MAE is:30.62 & sMAPE is:61.96% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :14.96 & 24.76% & 0.90\n",
      "for 2021-10-29, MAE is:17.40 & sMAPE is:24.56% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :14.97 & 24.76% & 0.89\n",
      "for 2021-10-30, MAE is:12.87 & sMAPE is:15.81% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :14.97 & 24.73% & 0.89\n",
      "for 2021-10-31, MAE is:10.64 & sMAPE is:21.53% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :14.95 & 24.72% & 0.89\n",
      "for 2021-11-01, MAE is:28.56 & sMAPE is:49.47% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :15.00 & 24.80% & 0.89\n",
      "for 2021-11-02, MAE is:111.80 & sMAPE is:74.51% & rMAE is:1.85 ||| daily mean of MAE & sMAPE & rMAE till now are :15.31 & 24.96% & 0.89\n",
      "for 2021-11-03, MAE is:23.26 & sMAPE is:12.09% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :15.34 & 24.92% & 0.89\n",
      "for 2021-11-04, MAE is:23.64 & sMAPE is:15.13% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :15.37 & 24.89% & 0.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-11-05, MAE is:30.75 & sMAPE is:29.71% & rMAE is:3.10 ||| daily mean of MAE & sMAPE & rMAE till now are :15.42 & 24.90% & 0.90\n",
      "for 2021-11-06, MAE is:9.05 & sMAPE is:15.40% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :15.39 & 24.87% & 0.90\n",
      "for 2021-11-07, MAE is:29.22 & sMAPE is:99.27% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :15.44 & 25.11% & 0.90\n",
      "for 2021-11-08, MAE is:100.57 & sMAPE is:69.17% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :15.71 & 25.25% & 0.90\n",
      "for 2021-11-09, MAE is:75.97 & sMAPE is:61.17% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :15.90 & 25.37% & 0.89\n",
      "for 2021-11-10, MAE is:68.41 & sMAPE is:47.03% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :16.07 & 25.44% & 0.90\n",
      "for 2021-11-11, MAE is:30.47 & sMAPE is:17.40% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :16.12 & 25.41% & 0.90\n",
      "for 2021-11-12, MAE is:35.12 & sMAPE is:25.08% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :16.18 & 25.41% & 0.90\n",
      "for 2021-11-13, MAE is:62.35 & sMAPE is:48.17% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :16.32 & 25.48% & 0.90\n",
      "for 2021-11-14, MAE is:24.51 & sMAPE is:17.52% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :16.35 & 25.46% & 0.89\n",
      "for 2021-11-15, MAE is:86.76 & sMAPE is:45.56% & rMAE is:2.02 ||| daily mean of MAE & sMAPE & rMAE till now are :16.57 & 25.52% & 0.90\n",
      "for 2021-11-16, MAE is:57.94 & sMAPE is:25.63% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :16.70 & 25.52% & 0.90\n",
      "for 2021-11-17, MAE is:80.25 & sMAPE is:59.46% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :16.90 & 25.63% & 0.90\n",
      "for 2021-11-18, MAE is:18.01 & sMAPE is:21.74% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :16.90 & 25.61% & 0.89\n",
      "for 2021-11-19, MAE is:14.30 & sMAPE is:32.91% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :16.89 & 25.64% & 0.89\n",
      "for 2021-11-20, MAE is:11.19 & sMAPE is:14.64% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :16.87 & 25.60% & 0.89\n",
      "for 2021-11-21, MAE is:5.72 & sMAPE is:5.98% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :16.84 & 25.54% & 0.89\n",
      "for 2021-11-22, MAE is:58.37 & sMAPE is:37.69% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :16.97 & 25.58% & 0.89\n",
      "for 2021-11-23, MAE is:37.42 & sMAPE is:27.04% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :17.03 & 25.58% & 0.88\n",
      "for 2021-11-24, MAE is:113.29 & sMAPE is:62.84% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :17.32 & 25.70% & 0.88\n",
      "for 2021-11-25, MAE is:19.83 & sMAPE is:16.58% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :17.33 & 25.67% & 0.88\n",
      "for 2021-11-26, MAE is:58.05 & sMAPE is:37.43% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :17.46 & 25.70% & 0.88\n",
      "for 2021-11-27, MAE is:75.26 & sMAPE is:50.18% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :17.63 & 25.78% & 0.88\n",
      "for 2021-11-28, MAE is:55.61 & sMAPE is:32.54% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :17.74 & 25.80% & 0.88\n",
      "for 2021-11-29, MAE is:95.75 & sMAPE is:37.86% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :17.98 & 25.84% & 0.88\n",
      "for 2021-11-30, MAE is:64.74 & sMAPE is:45.68% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :18.12 & 25.89% & 0.88\n",
      "for 2021-12-01, MAE is:67.14 & sMAPE is:52.44% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :18.26 & 25.97% & 0.88\n",
      "for 2021-12-02, MAE is:96.72 & sMAPE is:65.95% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :18.50 & 26.09% & 0.88\n",
      "for 2021-12-03, MAE is:24.66 & sMAPE is:15.27% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :18.52 & 26.06% & 0.88\n",
      "for 2021-12-04, MAE is:68.98 & sMAPE is:42.69% & rMAE is:2.01 ||| daily mean of MAE & sMAPE & rMAE till now are :18.67 & 26.11% & 0.89\n",
      "for 2021-12-05, MAE is:29.17 & sMAPE is:23.85% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :18.70 & 26.10% & 0.88\n",
      "for 2021-12-06, MAE is:82.40 & sMAPE is:35.78% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :18.88 & 26.13% & 0.89\n",
      "for 2021-12-07, MAE is:33.46 & sMAPE is:18.46% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :18.93 & 26.11% & 0.88\n",
      "for 2021-12-08, MAE is:25.87 & sMAPE is:20.51% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :18.95 & 26.09% & 0.88\n",
      "for 2021-12-09, MAE is:112.12 & sMAPE is:48.12% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :19.22 & 26.16% & 0.89\n",
      "for 2021-12-10, MAE is:57.51 & sMAPE is:26.40% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :19.33 & 26.16% & 0.88\n",
      "for 2021-12-11, MAE is:37.61 & sMAPE is:17.09% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :19.38 & 26.13% & 0.88\n",
      "for 2021-12-12, MAE is:47.92 & sMAPE is:26.86% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :19.47 & 26.13% & 0.88\n",
      "for 2021-12-13, MAE is:53.08 & sMAPE is:25.07% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :19.56 & 26.13% & 0.89\n",
      "for 2021-12-14, MAE is:85.53 & sMAPE is:38.09% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :19.75 & 26.16% & 0.89\n",
      "for 2021-12-15, MAE is:33.41 & sMAPE is:25.30% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :19.79 & 26.16% & 0.89\n",
      "for 2021-12-16, MAE is:23.47 & sMAPE is:12.18% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :19.80 & 26.12% & 0.89\n",
      "for 2021-12-17, MAE is:55.38 & sMAPE is:26.70% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :19.90 & 26.12% & 0.89\n",
      "for 2021-12-18, MAE is:39.18 & sMAPE is:31.86% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :19.96 & 26.14% & 0.89\n",
      "for 2021-12-19, MAE is:51.64 & sMAPE is:67.74% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :20.05 & 26.26% & 0.89\n",
      "for 2021-12-20, MAE is:157.17 & sMAPE is:55.65% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :20.43 & 26.34% & 0.89\n",
      "for 2021-12-21, MAE is:145.84 & sMAPE is:38.39% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :20.79 & 26.38% & 0.89\n",
      "for 2021-12-22, MAE is:101.78 & sMAPE is:26.74% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :21.02 & 26.38% & 0.89\n",
      "for 2021-12-23, MAE is:54.83 & sMAPE is:21.37% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :21.11 & 26.36% & 0.89\n",
      "for 2021-12-24, MAE is:40.96 & sMAPE is:24.79% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :21.17 & 26.36% & 0.89\n",
      "for 2021-12-25, MAE is:30.33 & sMAPE is:15.91% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :21.19 & 26.33% & 0.88\n",
      "for 2021-12-26, MAE is:22.72 & sMAPE is:13.54% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :21.20 & 26.29% & 0.88\n",
      "for 2021-12-27, MAE is:36.01 & sMAPE is:26.10% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :21.24 & 26.29% & 0.88\n",
      "for 2021-12-28, MAE is:72.20 & sMAPE is:54.89% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :21.38 & 26.37% & 0.88\n",
      "for 2021-12-29, MAE is:26.30 & sMAPE is:18.15% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :21.39 & 26.35% & 0.88\n",
      "for 2021-12-30, MAE is:58.64 & sMAPE is:62.89% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :21.49 & 26.45% & 0.87\n",
      "for 2021-12-31, MAE is:43.84 & sMAPE is:76.03% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :21.55 & 26.59% & 0.87\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 11:52:55,947]\u001b[0m A new study created in RDB with name: DK_1_2022\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:53:09,505]\u001b[0m Trial 2 finished with value: 58.22309847065412 and parameters: {'n_hidden': 4, 'learning_rate': 0.054052756884580055, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3700433395341212, 'dropout_rate_Layer_2': 0.10685501558832865, 'dropout_rate_Layer_3': 0.29999435129921537, 'dropout_rate_Layer_4': 0.08924623167913062, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0029401491692550947, 'l1_Layer_2': 0.0011929174972149519, 'l1_Layer_3': 0.00011083345586358385, 'l1_Layer_4': 0.0038185117960925384, 'n_units_Layer_1': 70, 'n_units_Layer_2': 145, 'n_units_Layer_3': 230, 'n_units_Layer_4': 145}. Best is trial 2 with value: 58.22309847065412.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 58.22 | sMAPE for Validation Set is: 81.40% | rMAE for Validation Set is: 1.72\n",
      "MAE for Test Set is: 188.80 | sMAPE for Test Set is: 132.04% | rMAE for Test Set is: 2.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 11:53:09,801]\u001b[0m Trial 1 pruned. Trial was pruned at epoch 35.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:53:16,302]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:53:20,142]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:53:25,578]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:53:26,573]\u001b[0m Trial 5 finished with value: 45.69118335218625 and parameters: {'n_hidden': 3, 'learning_rate': 0.05086482263721535, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3192808500825644, 'dropout_rate_Layer_2': 0.25442042602306025, 'dropout_rate_Layer_3': 0.10526056653924908, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00779033249641051, 'l1_Layer_2': 1.9333508855688383e-05, 'l1_Layer_3': 0.0007134010450723206, 'n_units_Layer_1': 130, 'n_units_Layer_2': 280, 'n_units_Layer_3': 175}. Best is trial 5 with value: 45.69118335218625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.69 | sMAPE for Validation Set is: 55.12% | rMAE for Validation Set is: 1.35\n",
      "MAE for Test Set is: 173.96 | sMAPE for Test Set is: 111.92% | rMAE for Test Set is: 1.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 11:53:32,856]\u001b[0m Trial 0 finished with value: 23.223218747725923 and parameters: {'n_hidden': 4, 'learning_rate': 0.0020888465192593505, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2525518157817806, 'dropout_rate_Layer_2': 0.21252267912928124, 'dropout_rate_Layer_3': 0.2959137055242482, 'dropout_rate_Layer_4': 0.29086296394233585, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00025699147209663547, 'l1_Layer_2': 0.002894547731934491, 'l1_Layer_3': 0.002540011966083484, 'l1_Layer_4': 1.681622674505343e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 70, 'n_units_Layer_3': 290, 'n_units_Layer_4': 170}. Best is trial 0 with value: 23.223218747725923.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.22 | sMAPE for Validation Set is: 28.73% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 60.33 | sMAPE for Test Set is: 36.47% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 11:53:34,318]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:53:38,819]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:53:40,240]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:53:43,960]\u001b[0m Trial 3 finished with value: 38.16055305484731 and parameters: {'n_hidden': 3, 'learning_rate': 0.002104935791055953, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.004652810891906123, 'dropout_rate_Layer_2': 0.23015846911989138, 'dropout_rate_Layer_3': 0.2895469077670564, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.789104215752702e-05, 'l1_Layer_2': 1.467005420559642e-05, 'l1_Layer_3': 3.4203621897900044e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 130, 'n_units_Layer_3': 90}. Best is trial 0 with value: 23.223218747725923.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 38.16 | sMAPE for Validation Set is: 43.71% | rMAE for Validation Set is: 1.13\n",
      "MAE for Test Set is: 160.78 | sMAPE for Test Set is: 97.58% | rMAE for Test Set is: 1.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 11:53:45,987]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:53:46,303]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:53:51,208]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:53:53,800]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:53:55,889]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:53:59,360]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:54:02,232]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:54:05,346]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:54:05,858]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:54:11,143]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:54:12,485]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:54:14,738]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:54:18,010]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:54:23,885]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:54:24,371]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:54:24,818]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:54:34,124]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:54:38,460]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:54:38,664]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:54:45,741]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:54:45,990]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:54:50,907]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:54:51,468]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:54:55,656]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:55:00,270]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:55:03,074]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:55:03,221]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:55:10,681]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:55:14,595]\u001b[0m Trial 28 finished with value: 22.172239923128643 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015981695990623418, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3493617569504744, 'dropout_rate_Layer_2': 0.24420514387691458, 'dropout_rate_Layer_3': 0.2781382980293632, 'dropout_rate_Layer_4': 0.02961193180270474, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.021804393292037576, 'l1_Layer_2': 4.937362031777748e-05, 'l1_Layer_3': 7.150535168303819e-05, 'l1_Layer_4': 0.00020300376394206, 'n_units_Layer_1': 50, 'n_units_Layer_2': 150, 'n_units_Layer_3': 100, 'n_units_Layer_4': 50}. Best is trial 28 with value: 22.172239923128643.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.17 | sMAPE for Validation Set is: 26.70% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 55.06 | sMAPE for Test Set is: 34.16% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 11:55:21,215]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:55:22,968]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:55:25,905]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:55:27,323]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:55:28,569]\u001b[0m Trial 40 finished with value: 21.74415189679553 and parameters: {'n_hidden': 3, 'learning_rate': 0.005649414566503785, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3281316459554902, 'dropout_rate_Layer_2': 0.16100944978535447, 'dropout_rate_Layer_3': 0.28614237178528856, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.2975803694125136e-05, 'l1_Layer_2': 0.007471593913152936, 'l1_Layer_3': 0.006794168358759991, 'n_units_Layer_1': 265, 'n_units_Layer_2': 75, 'n_units_Layer_3': 135}. Best is trial 40 with value: 21.74415189679553.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.74 | sMAPE for Validation Set is: 26.50% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 58.90 | sMAPE for Test Set is: 35.13% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 11:55:31,534]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:55:36,147]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:55:38,081]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:55:42,299]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:55:42,378]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:55:47,872]\u001b[0m Trial 15 finished with value: 44.53556418754092 and parameters: {'n_hidden': 3, 'learning_rate': 0.00066488985445761, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.109983669234059, 'dropout_rate_Layer_2': 0.24001174507903833, 'dropout_rate_Layer_3': 0.08063447633509871, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0029477161609047994, 'l1_Layer_2': 0.0598688061068274, 'l1_Layer_3': 0.014744137997120647, 'n_units_Layer_1': 50, 'n_units_Layer_2': 260, 'n_units_Layer_3': 250}. Best is trial 40 with value: 21.74415189679553.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.54 | sMAPE for Validation Set is: 52.73% | rMAE for Validation Set is: 1.32\n",
      "MAE for Test Set is: 173.17 | sMAPE for Test Set is: 110.96% | rMAE for Test Set is: 1.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 11:55:48,215]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:55:49,689]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:55:54,743]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:55:55,484]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:55:56,462]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:56:00,302]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:56:02,226]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:56:05,940]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:56:06,166]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:56:11,074]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:56:15,466]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:56:19,560]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:56:23,114]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:56:30,694]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:56:34,016]\u001b[0m Trial 58 finished with value: 22.38797394697671 and parameters: {'n_hidden': 3, 'learning_rate': 0.07615874726375542, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.398049178105483, 'dropout_rate_Layer_2': 0.3489041821927096, 'dropout_rate_Layer_3': 0.14565085790439714, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1913361582919475e-05, 'l1_Layer_2': 1.1445295073518812e-05, 'l1_Layer_3': 0.0008829393232838837, 'n_units_Layer_1': 105, 'n_units_Layer_2': 230, 'n_units_Layer_3': 195}. Best is trial 40 with value: 21.74415189679553.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.39 | sMAPE for Validation Set is: 27.64% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 61.37 | sMAPE for Test Set is: 35.84% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 11:56:37,990]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:56:38,361]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:56:44,644]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:56:48,293]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:56:49,794]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:56:55,949]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:57:01,102]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:57:01,528]\u001b[0m Trial 65 finished with value: 24.175726749830407 and parameters: {'n_hidden': 4, 'learning_rate': 0.001817426991575077, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36291360432979697, 'dropout_rate_Layer_2': 0.3746345086105145, 'dropout_rate_Layer_3': 0.39994724948570165, 'dropout_rate_Layer_4': 0.004459924485377503, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0003459284742866178, 'l1_Layer_2': 1.2004285899762305e-05, 'l1_Layer_3': 1.5434617443396028e-05, 'l1_Layer_4': 0.0009683939435269038, 'n_units_Layer_1': 115, 'n_units_Layer_2': 140, 'n_units_Layer_3': 60, 'n_units_Layer_4': 65}. Best is trial 40 with value: 21.74415189679553.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.18 | sMAPE for Validation Set is: 29.56% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 60.31 | sMAPE for Test Set is: 36.34% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 11:57:01,856]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:57:06,567]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:57:09,522]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:57:12,512]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:57:16,541]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:57:42,846]\u001b[0m Trial 82 finished with value: 22.171252998634202 and parameters: {'n_hidden': 3, 'learning_rate': 0.004105724858300137, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33766389979743466, 'dropout_rate_Layer_2': 0.28555802064021163, 'dropout_rate_Layer_3': 0.008770912442808143, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0027187084656349427, 'l1_Layer_2': 1.0914473942528573e-05, 'l1_Layer_3': 0.00041296183295867506, 'n_units_Layer_1': 135, 'n_units_Layer_2': 215, 'n_units_Layer_3': 195}. Best is trial 40 with value: 21.74415189679553.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.17 | sMAPE for Validation Set is: 27.57% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 59.35 | sMAPE for Test Set is: 35.22% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 11:57:47,769]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:57:51,345]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:57:55,873]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:57:58,255]\u001b[0m Trial 78 finished with value: 23.86108822446074 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015624279391814589, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.392765352111413, 'dropout_rate_Layer_2': 0.3740990190997417, 'dropout_rate_Layer_3': 0.39021342694292294, 'dropout_rate_Layer_4': 0.00020825858101856248, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00025797455904700466, 'l1_Layer_2': 1.0038419373756767e-05, 'l1_Layer_3': 1.0966501682799476e-05, 'l1_Layer_4': 0.0011494484099677025, 'n_units_Layer_1': 110, 'n_units_Layer_2': 140, 'n_units_Layer_3': 55, 'n_units_Layer_4': 50}. Best is trial 40 with value: 21.74415189679553.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.86 | sMAPE for Validation Set is: 28.93% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 59.27 | sMAPE for Test Set is: 35.95% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 11:58:02,815]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:58:09,008]\u001b[0m Trial 63 finished with value: 21.453693407021422 and parameters: {'n_hidden': 4, 'learning_rate': 0.001943717542007493, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3999192581912044, 'dropout_rate_Layer_2': 0.3591579318825762, 'dropout_rate_Layer_3': 0.3936537346999191, 'dropout_rate_Layer_4': 0.011119368564203144, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000430231678142531, 'l1_Layer_2': 1.644815203337657e-05, 'l1_Layer_3': 1.1607735514766682e-05, 'l1_Layer_4': 0.000993167482304614, 'n_units_Layer_1': 115, 'n_units_Layer_2': 150, 'n_units_Layer_3': 50, 'n_units_Layer_4': 55}. Best is trial 63 with value: 21.453693407021422.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.45 | sMAPE for Validation Set is: 26.25% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 55.86 | sMAPE for Test Set is: 34.23% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 11:58:19,992]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:58:24,529]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:58:27,773]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:58:30,649]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:58:32,986]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:58:37,206]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:58:41,253]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:58:45,545]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:58:45,853]\u001b[0m Trial 86 finished with value: 24.608692781938526 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017231492155178017, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38185262740681886, 'dropout_rate_Layer_2': 0.3628079046161196, 'dropout_rate_Layer_3': 0.3882797328799282, 'dropout_rate_Layer_4': 0.0061365254774389255, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00024103319625916114, 'l1_Layer_2': 1.1122679774345644e-05, 'l1_Layer_3': 1.1030436150805235e-05, 'l1_Layer_4': 0.0008472447042381594, 'n_units_Layer_1': 110, 'n_units_Layer_2': 140, 'n_units_Layer_3': 50, 'n_units_Layer_4': 50}. Best is trial 63 with value: 21.453693407021422.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.61 | sMAPE for Validation Set is: 29.51% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 61.71 | sMAPE for Test Set is: 36.69% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 11:58:51,543]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:58:55,989]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:58:59,438]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:59:04,232]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:59:06,468]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:59:06,595]\u001b[0m Trial 93 finished with value: 22.75091806100956 and parameters: {'n_hidden': 4, 'learning_rate': 0.00158450514657612, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29510121540244216, 'dropout_rate_Layer_2': 0.30568604066571214, 'dropout_rate_Layer_3': 0.24408922060395183, 'dropout_rate_Layer_4': 0.057611162199093104, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.09295089377894694, 'l1_Layer_2': 5.981314462486576e-05, 'l1_Layer_3': 6.57216434250116e-05, 'l1_Layer_4': 0.0011256032372585524, 'n_units_Layer_1': 85, 'n_units_Layer_2': 150, 'n_units_Layer_3': 100, 'n_units_Layer_4': 130}. Best is trial 63 with value: 21.453693407021422.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.75 | sMAPE for Validation Set is: 27.33% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 56.88 | sMAPE for Test Set is: 34.93% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 11:59:08,792]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:59:13,364]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:59:20,271]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:59:20,593]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:59:25,276]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:59:30,273]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:59:30,828]\u001b[0m Trial 104 finished with value: 22.11148480453527 and parameters: {'n_hidden': 4, 'learning_rate': 0.014273092657401482, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2948476148068526, 'dropout_rate_Layer_2': 0.28610653362747024, 'dropout_rate_Layer_3': 0.3086580856492318, 'dropout_rate_Layer_4': 0.2688389982499742, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000969494349232771, 'l1_Layer_2': 4.84882864915184e-05, 'l1_Layer_3': 4.4346522204845255e-05, 'l1_Layer_4': 1.3537459675957893e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 110, 'n_units_Layer_3': 200, 'n_units_Layer_4': 105}. Best is trial 63 with value: 21.453693407021422.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.11 | sMAPE for Validation Set is: 26.89% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 54.11 | sMAPE for Test Set is: 33.76% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 11:59:31,120]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:59:33,926]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:59:37,730]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:59:41,503]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:59:44,668]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:59:45,623]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:59:52,540]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:59:53,423]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:59:55,469]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 11:59:55,971]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:00:01,394]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:00:02,021]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:00:03,586]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:00:06,733]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:00:10,747]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:00:10,986]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:00:14,065]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:00:16,042]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:00:22,326]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:00:24,887]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:00:28,370]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:00:28,934]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:00:33,276]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:00:35,668]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:00:38,957]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:00:41,676]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:00:45,076]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:00:45,709]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:00:45,884]\u001b[0m Trial 131 finished with value: 21.765810486639904 and parameters: {'n_hidden': 3, 'learning_rate': 0.014923406036900762, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38605800215253533, 'dropout_rate_Layer_2': 0.22170207696196964, 'dropout_rate_Layer_3': 0.1385753078800513, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012802558922907778, 'l1_Layer_2': 0.006470496050403312, 'l1_Layer_3': 0.0001331554914847556, 'n_units_Layer_1': 150, 'n_units_Layer_2': 95, 'n_units_Layer_3': 105}. Best is trial 63 with value: 21.453693407021422.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.77 | sMAPE for Validation Set is: 26.69% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 56.86 | sMAPE for Test Set is: 34.73% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:00:50,237]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:00:55,805]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:00:56,998]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:01:01,153]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:01:04,975]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:01:08,926]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:01:12,234]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:01:16,170]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.24 | sMAPE for Validation Set is: 26.39% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 53.81 | sMAPE for Test Set is: 33.25% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:01:19,204]\u001b[0m Trial 134 finished with value: 21.244762753179398 and parameters: {'n_hidden': 4, 'learning_rate': 0.003046367336595817, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32909226637573435, 'dropout_rate_Layer_2': 0.3312330316794784, 'dropout_rate_Layer_3': 0.2974301726169575, 'dropout_rate_Layer_4': 0.3617872545673452, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.013595243211653467, 'l1_Layer_2': 3.133059239907679e-05, 'l1_Layer_3': 0.00011347717182293363, 'l1_Layer_4': 0.00015554562607543302, 'n_units_Layer_1': 70, 'n_units_Layer_2': 115, 'n_units_Layer_3': 80, 'n_units_Layer_4': 75}. Best is trial 134 with value: 21.244762753179398.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:01:19,937]\u001b[0m Trial 143 finished with value: 22.235848261801674 and parameters: {'n_hidden': 3, 'learning_rate': 0.013502401386668623, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3881918821162305, 'dropout_rate_Layer_2': 0.22890701603611469, 'dropout_rate_Layer_3': 0.15304732304011878, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.122946826685658e-05, 'l1_Layer_2': 0.012898277122648844, 'l1_Layer_3': 0.0038510078190195462, 'n_units_Layer_1': 170, 'n_units_Layer_2': 95, 'n_units_Layer_3': 100}. Best is trial 134 with value: 21.244762753179398.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.24 | sMAPE for Validation Set is: 28.31% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 54.84 | sMAPE for Test Set is: 34.38% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:01:20,616]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:01:25,694]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:01:25,777]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:01:27,725]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:01:32,975]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:01:33,915]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:01:36,400]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:01:36,728]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:01:43,475]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:01:45,195]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:01:50,699]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:01:51,116]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:01:57,441]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:02:00,288]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:02:01,295]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:02:09,409]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:02:17,317]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:02:17,785]\u001b[0m Trial 158 finished with value: 22.091582675970244 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010383421890163304, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3935177565812108, 'dropout_rate_Layer_2': 0.32856540137205287, 'dropout_rate_Layer_3': 0.3628186065339667, 'dropout_rate_Layer_4': 0.36660817746606117, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0006534029855660756, 'l1_Layer_2': 2.125843291387311e-05, 'l1_Layer_3': 0.0004502885366760038, 'l1_Layer_4': 3.6966538865184047e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 170, 'n_units_Layer_3': 215, 'n_units_Layer_4': 120}. Best is trial 134 with value: 21.244762753179398.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.09 | sMAPE for Validation Set is: 26.93% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 55.85 | sMAPE for Test Set is: 34.38% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:02:24,589]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:02:24,935]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:02:29,844]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:02:31,212]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:02:34,117]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:02:36,301]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.81 | sMAPE for Validation Set is: 26.62% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 57.55 | sMAPE for Test Set is: 34.66% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:02:39,395]\u001b[0m Trial 165 finished with value: 21.813154580482117 and parameters: {'n_hidden': 4, 'learning_rate': 0.0026585426903816614, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31225482954398964, 'dropout_rate_Layer_2': 0.3265535099666746, 'dropout_rate_Layer_3': 0.3538910095346721, 'dropout_rate_Layer_4': 0.33889319462830075, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005656306286911225, 'l1_Layer_2': 1.87357397325207e-05, 'l1_Layer_3': 3.1467173214814625e-05, 'l1_Layer_4': 4.0357506928167385e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 165, 'n_units_Layer_3': 210, 'n_units_Layer_4': 120}. Best is trial 134 with value: 21.244762753179398.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:02:42,743]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:02:44,289]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:02:48,905]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:02:51,862]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:02:56,221]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:02:56,830]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:03:02,130]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:03:02,471]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:03:03,376]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:03:09,600]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:03:15,003]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:03:19,220]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:03:21,633]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:03:25,897]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:03:26,156]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:03:36,378]\u001b[0m Trial 183 finished with value: 21.262472239726083 and parameters: {'n_hidden': 3, 'learning_rate': 0.004131972591272071, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3780810219972903, 'dropout_rate_Layer_2': 0.049576229003672395, 'dropout_rate_Layer_3': 0.3319457290567136, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.02421779119825015, 'l1_Layer_2': 0.0005246011642450164, 'l1_Layer_3': 0.00038648344005435176, 'n_units_Layer_1': 185, 'n_units_Layer_2': 230, 'n_units_Layer_3': 230}. Best is trial 134 with value: 21.244762753179398.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.26 | sMAPE for Validation Set is: 26.04% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 55.09 | sMAPE for Test Set is: 33.92% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:03:36,799]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:03:37,335]\u001b[0m Trial 164 finished with value: 20.85384245369909 and parameters: {'n_hidden': 4, 'learning_rate': 0.0026186040052745252, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39832740911297426, 'dropout_rate_Layer_2': 0.3314435241509201, 'dropout_rate_Layer_3': 0.3613648710024018, 'dropout_rate_Layer_4': 0.33080286730162956, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0013306442815628752, 'l1_Layer_2': 2.2179907921376446e-05, 'l1_Layer_3': 0.0006535987320766164, 'l1_Layer_4': 3.338051395938456e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 165, 'n_units_Layer_3': 215, 'n_units_Layer_4': 130}. Best is trial 164 with value: 20.85384245369909.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.85 | sMAPE for Validation Set is: 25.59% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 53.12 | sMAPE for Test Set is: 32.77% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:03:45,720]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:03:47,288]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:03:48,403]\u001b[0m Trial 189 finished with value: 20.55248338290433 and parameters: {'n_hidden': 3, 'learning_rate': 0.0042225922244005214, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35409366938030934, 'dropout_rate_Layer_2': 0.23030496465450329, 'dropout_rate_Layer_3': 0.3993667003661531, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007345182589328352, 'l1_Layer_2': 0.0028785370709758385, 'l1_Layer_3': 0.00040317886488431957, 'n_units_Layer_1': 85, 'n_units_Layer_2': 235, 'n_units_Layer_3': 175}. Best is trial 189 with value: 20.55248338290433.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.55 | sMAPE for Validation Set is: 25.46% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 51.07 | sMAPE for Test Set is: 32.20% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:03:53,252]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:03:54,651]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:03:59,523]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:04:02,562]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:04:04,611]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:04:05,659]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:04:08,113]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:04:11,553]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:04:22,654]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:04:25,812]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:04:28,960]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:04:30,656]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:04:34,526]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:04:36,195]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:04:37,503]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:04:42,529]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:04:44,769]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.99 | sMAPE for Validation Set is: 25.83% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 53.29 | sMAPE for Test Set is: 33.23% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:04:48,729]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:04:48,843]\u001b[0m Trial 202 finished with value: 20.993371662887117 and parameters: {'n_hidden': 3, 'learning_rate': 0.0038565016382168856, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3373398127716335, 'dropout_rate_Layer_2': 0.19396687724457617, 'dropout_rate_Layer_3': 0.3758209461243762, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0116926938707134, 'l1_Layer_2': 0.0021862709510238323, 'l1_Layer_3': 0.000159801429238036, 'n_units_Layer_1': 85, 'n_units_Layer_2': 225, 'n_units_Layer_3': 175}. Best is trial 189 with value: 20.55248338290433.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:04:48,915]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:04:57,061]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:05:03,754]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:05:04,010]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:05:11,169]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:05:15,466]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:05:18,341]\u001b[0m Trial 217 finished with value: 20.84363887718936 and parameters: {'n_hidden': 3, 'learning_rate': 0.00457031894046293, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07724941528713813, 'dropout_rate_Layer_2': 0.15353642633791617, 'dropout_rate_Layer_3': 0.14763641721527532, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.473503912535308e-05, 'l1_Layer_2': 0.0013008662316703577, 'l1_Layer_3': 1.2007239047986276e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 210, 'n_units_Layer_3': 155}. Best is trial 189 with value: 20.55248338290433.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.84 | sMAPE for Validation Set is: 25.54% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 52.89 | sMAPE for Test Set is: 33.01% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:05:21,989]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:05:22,374]\u001b[0m Trial 219 finished with value: 20.794440365352667 and parameters: {'n_hidden': 3, 'learning_rate': 0.006530853506352579, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35804207953534695, 'dropout_rate_Layer_2': 0.1389184779849023, 'dropout_rate_Layer_3': 0.30909700836876747, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0013919032378419, 'l1_Layer_2': 1.0116823749635277e-05, 'l1_Layer_3': 2.719469437136525e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 95, 'n_units_Layer_3': 155}. Best is trial 189 with value: 20.55248338290433.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.79 | sMAPE for Validation Set is: 25.31% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 51.68 | sMAPE for Test Set is: 33.00% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:05:28,120]\u001b[0m Trial 213 finished with value: 20.89630393425846 and parameters: {'n_hidden': 3, 'learning_rate': 0.0038367644614259082, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29963896114775945, 'dropout_rate_Layer_2': 0.11412734372143178, 'dropout_rate_Layer_3': 0.35730739278397633, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0023726152331391675, 'l1_Layer_2': 0.0018151973854862772, 'l1_Layer_3': 0.004202100163537093, 'n_units_Layer_1': 65, 'n_units_Layer_2': 205, 'n_units_Layer_3': 195}. Best is trial 189 with value: 20.55248338290433.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.90 | sMAPE for Validation Set is: 25.87% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 53.18 | sMAPE for Test Set is: 33.26% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:05:28,499]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:05:40,337]\u001b[0m Trial 222 finished with value: 21.021725867806865 and parameters: {'n_hidden': 3, 'learning_rate': 0.003564692439154737, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30586037505691555, 'dropout_rate_Layer_2': 0.18135025494471968, 'dropout_rate_Layer_3': 0.35869652271889835, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00669795162081917, 'l1_Layer_2': 0.00248878193274389, 'l1_Layer_3': 0.00014807964915116074, 'n_units_Layer_1': 105, 'n_units_Layer_2': 210, 'n_units_Layer_3': 160}. Best is trial 189 with value: 20.55248338290433.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.02 | sMAPE for Validation Set is: 26.09% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 54.37 | sMAPE for Test Set is: 33.63% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:05:41,128]\u001b[0m Trial 225 finished with value: 21.564156968482603 and parameters: {'n_hidden': 3, 'learning_rate': 0.004448826774709789, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03714215530309344, 'dropout_rate_Layer_2': 0.14127794237248736, 'dropout_rate_Layer_3': 0.12455157911814449, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.111677152041522e-05, 'l1_Layer_2': 2.6773318065206364e-05, 'l1_Layer_3': 1.1330149761650028e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 205, 'n_units_Layer_3': 170}. Best is trial 189 with value: 20.55248338290433.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.56 | sMAPE for Validation Set is: 25.88% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 55.48 | sMAPE for Test Set is: 33.98% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:05:41,514]\u001b[0m Trial 226 finished with value: 21.510127594852804 and parameters: {'n_hidden': 3, 'learning_rate': 0.00599117927955311, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.045927081224148965, 'dropout_rate_Layer_2': 0.14701057599776055, 'dropout_rate_Layer_3': 0.11190269491455887, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0016356819808419504, 'l1_Layer_2': 1.246802995699931e-05, 'l1_Layer_3': 1.0291452978118579e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 205, 'n_units_Layer_3': 165}. Best is trial 189 with value: 20.55248338290433.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.51 | sMAPE for Validation Set is: 26.24% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 54.31 | sMAPE for Test Set is: 33.67% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:05:50,051]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:05:50,375]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:06:00,338]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:06:00,815]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:06:05,063]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:06:10,496]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:06:14,436]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:06:14,947]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:06:18,277]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:06:22,214]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:06:25,106]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:06:29,283]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:06:33,716]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:06:37,337]\u001b[0m Trial 237 finished with value: 21.353006203132967 and parameters: {'n_hidden': 3, 'learning_rate': 0.006447486958078564, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28820035715104064, 'dropout_rate_Layer_2': 0.1475821055704464, 'dropout_rate_Layer_3': 0.3827126223446419, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.5090216932183525e-05, 'l1_Layer_2': 0.0031477160138623124, 'l1_Layer_3': 0.0005151187819495775, 'n_units_Layer_1': 75, 'n_units_Layer_2': 215, 'n_units_Layer_3': 215}. Best is trial 189 with value: 20.55248338290433.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:06:37,387]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.35 | sMAPE for Validation Set is: 26.27% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 51.96 | sMAPE for Test Set is: 32.45% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:06:42,790]\u001b[0m Trial 239 finished with value: 21.181483350288214 and parameters: {'n_hidden': 3, 'learning_rate': 0.007111189415599104, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3494986313276822, 'dropout_rate_Layer_2': 0.14260463929632566, 'dropout_rate_Layer_3': 0.3858381044023024, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0758579881537405e-05, 'l1_Layer_2': 0.0030572468460374333, 'l1_Layer_3': 0.00047776305801309593, 'n_units_Layer_1': 90, 'n_units_Layer_2': 215, 'n_units_Layer_3': 215}. Best is trial 189 with value: 20.55248338290433.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.18 | sMAPE for Validation Set is: 26.66% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 50.94 | sMAPE for Test Set is: 32.19% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:06:45,722]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:06:50,303]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:06:55,047]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:06:55,735]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:06:58,250]\u001b[0m Trial 243 finished with value: 20.735927921380412 and parameters: {'n_hidden': 3, 'learning_rate': 0.005250987939137694, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.039455865318357076, 'dropout_rate_Layer_2': 0.14350139769459852, 'dropout_rate_Layer_3': 0.10787641506390518, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003234912071366458, 'l1_Layer_2': 1.188245972481059e-05, 'l1_Layer_3': 1.430863128794417e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 225, 'n_units_Layer_3': 170}. Best is trial 189 with value: 20.55248338290433.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.74 | sMAPE for Validation Set is: 25.50% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 51.88 | sMAPE for Test Set is: 32.89% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:07:06,431]\u001b[0m Trial 245 finished with value: 20.93061258540695 and parameters: {'n_hidden': 3, 'learning_rate': 0.00514607772465323, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03990051309762915, 'dropout_rate_Layer_2': 0.12848948637348867, 'dropout_rate_Layer_3': 0.05981953597604435, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0015948978664044665, 'l1_Layer_2': 1.3321647710064042e-05, 'l1_Layer_3': 1.2714454748082105e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 220, 'n_units_Layer_3': 170}. Best is trial 189 with value: 20.55248338290433.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.93 | sMAPE for Validation Set is: 25.47% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 55.55 | sMAPE for Test Set is: 33.62% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:07:08,255]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:07:13,474]\u001b[0m Trial 250 finished with value: 20.90716693572825 and parameters: {'n_hidden': 3, 'learning_rate': 0.00696521311488568, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.045497185955982095, 'dropout_rate_Layer_2': 0.12225564005226741, 'dropout_rate_Layer_3': 0.0714019863114454, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0031860727751931604, 'l1_Layer_2': 1.0417193639187623e-05, 'l1_Layer_3': 1.7211351719416306e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 225, 'n_units_Layer_3': 155}. Best is trial 189 with value: 20.55248338290433.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.91 | sMAPE for Validation Set is: 25.78% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 53.51 | sMAPE for Test Set is: 33.18% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:07:16,233]\u001b[0m Trial 248 finished with value: 20.570214153267372 and parameters: {'n_hidden': 3, 'learning_rate': 0.005332302924477207, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0422376274702692, 'dropout_rate_Layer_2': 0.1292801935906339, 'dropout_rate_Layer_3': 0.07367257927292833, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018479644665196481, 'l1_Layer_2': 1.1770147443255834e-05, 'l1_Layer_3': 1.2931626851779995e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 215, 'n_units_Layer_3': 165}. Best is trial 189 with value: 20.55248338290433.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.57 | sMAPE for Validation Set is: 25.23% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 53.69 | sMAPE for Test Set is: 33.19% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:07:21,312]\u001b[0m Trial 252 finished with value: 20.487778201885728 and parameters: {'n_hidden': 3, 'learning_rate': 0.0073682096948230694, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0455006182230788, 'dropout_rate_Layer_2': 0.1262070709432606, 'dropout_rate_Layer_3': 0.12259058522424565, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004499527644228238, 'l1_Layer_2': 1.1141476556707903e-05, 'l1_Layer_3': 1.764373003873582e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 220, 'n_units_Layer_3': 155}. Best is trial 252 with value: 20.487778201885728.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.49 | sMAPE for Validation Set is: 25.24% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 50.99 | sMAPE for Test Set is: 32.45% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:07:25,434]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:07:25,996]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.02 | sMAPE for Validation Set is: 25.94% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 54.74 | sMAPE for Test Set is: 33.62% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:07:29,793]\u001b[0m Trial 253 finished with value: 21.01893013224033 and parameters: {'n_hidden': 3, 'learning_rate': 0.008255547129174787, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04656531782593572, 'dropout_rate_Layer_2': 0.1256515348123777, 'dropout_rate_Layer_3': 0.04908199179237966, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005334365220148016, 'l1_Layer_2': 1.859912215864736e-05, 'l1_Layer_3': 2.4444091883821334e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 220, 'n_units_Layer_3': 155}. Best is trial 252 with value: 20.487778201885728.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:07:31,792]\u001b[0m Trial 254 finished with value: 20.76956675958589 and parameters: {'n_hidden': 3, 'learning_rate': 0.007357782318937315, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04190620931151183, 'dropout_rate_Layer_2': 0.12676741901921834, 'dropout_rate_Layer_3': 0.052384104013532856, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003953179624739056, 'l1_Layer_2': 2.807631607167531e-05, 'l1_Layer_3': 1.678777603797425e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 220, 'n_units_Layer_3': 155}. Best is trial 252 with value: 20.487778201885728.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.77 | sMAPE for Validation Set is: 25.56% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 53.16 | sMAPE for Test Set is: 32.99% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:07:32,514]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:07:39,347]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:07:41,001]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:07:46,280]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:07:49,977]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.66 | sMAPE for Validation Set is: 25.13% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 52.97 | sMAPE for Test Set is: 32.96% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:07:52,886]\u001b[0m Trial 258 finished with value: 20.656962208068567 and parameters: {'n_hidden': 3, 'learning_rate': 0.007473865199547672, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.018308741715226222, 'dropout_rate_Layer_2': 0.12358585475924692, 'dropout_rate_Layer_3': 0.03649076508857306, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00624673720453748, 'l1_Layer_2': 1.9343959755383353e-05, 'l1_Layer_3': 1.8534214368944646e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 220, 'n_units_Layer_3': 145}. Best is trial 252 with value: 20.487778201885728.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:07:57,214]\u001b[0m Trial 261 finished with value: 21.207141386550237 and parameters: {'n_hidden': 3, 'learning_rate': 0.006577156425489221, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3131833763443025, 'dropout_rate_Layer_2': 0.09678764122946687, 'dropout_rate_Layer_3': 0.3648769909544437, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.969951102229584e-05, 'l1_Layer_2': 0.0023545188299855004, 'l1_Layer_3': 0.0001576113805250405, 'n_units_Layer_1': 70, 'n_units_Layer_2': 190, 'n_units_Layer_3': 215}. Best is trial 252 with value: 20.487778201885728.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.21 | sMAPE for Validation Set is: 26.48% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 53.26 | sMAPE for Test Set is: 32.88% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:08:01,267]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:08:01,715]\u001b[0m Trial 264 finished with value: 20.71822406481542 and parameters: {'n_hidden': 3, 'learning_rate': 0.009347205447375538, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06646748458042473, 'dropout_rate_Layer_2': 0.09880845269537121, 'dropout_rate_Layer_3': 0.05963095043201499, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0032487807566784718, 'l1_Layer_2': 1.9681519170667567e-05, 'l1_Layer_3': 1.436922078626362e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 220, 'n_units_Layer_3': 160}. Best is trial 252 with value: 20.487778201885728.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.72 | sMAPE for Validation Set is: 25.24% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 52.52 | sMAPE for Test Set is: 32.75% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:08:01,903]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:08:10,036]\u001b[0m Trial 263 finished with value: 20.855331378182886 and parameters: {'n_hidden': 3, 'learning_rate': 0.004887747965282931, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07255173894472385, 'dropout_rate_Layer_2': 0.12138275614573046, 'dropout_rate_Layer_3': 0.06877310953578591, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00888127184108387, 'l1_Layer_2': 2.0326173026167892e-05, 'l1_Layer_3': 3.279213910378209e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 220, 'n_units_Layer_3': 160}. Best is trial 252 with value: 20.487778201885728.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.86 | sMAPE for Validation Set is: 25.55% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 54.30 | sMAPE for Test Set is: 33.47% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:08:10,769]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:08:20,297]\u001b[0m Trial 267 finished with value: 20.745694620302938 and parameters: {'n_hidden': 3, 'learning_rate': 0.004905015669776661, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06481987710754916, 'dropout_rate_Layer_2': 0.0935165356957546, 'dropout_rate_Layer_3': 0.03742835404808581, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.010029436035709936, 'l1_Layer_2': 2.2825238288118647e-05, 'l1_Layer_3': 1.4704201293313925e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 215, 'n_units_Layer_3': 160}. Best is trial 252 with value: 20.487778201885728.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.75 | sMAPE for Validation Set is: 25.57% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 51.31 | sMAPE for Test Set is: 32.41% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:08:24,245]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:08:27,168]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:08:30,763]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:08:33,421]\u001b[0m Trial 271 finished with value: 20.767022193441623 and parameters: {'n_hidden': 3, 'learning_rate': 0.0045475690426850365, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09092900381812408, 'dropout_rate_Layer_2': 0.09783232939359117, 'dropout_rate_Layer_3': 0.07082622188285696, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008728237954952785, 'l1_Layer_2': 4.606549788610262e-05, 'l1_Layer_3': 1.4716817543151672e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 215, 'n_units_Layer_3': 150}. Best is trial 252 with value: 20.487778201885728.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.77 | sMAPE for Validation Set is: 25.62% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 52.20 | sMAPE for Test Set is: 32.84% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:08:36,826]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:08:40,791]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:08:44,153]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:08:47,647]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:08:51,655]\u001b[0m Trial 270 finished with value: 21.52167750172997 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012963212595329097, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39757404686624337, 'dropout_rate_Layer_2': 0.32208926439999175, 'dropout_rate_Layer_3': 0.37199581120945246, 'dropout_rate_Layer_4': 0.3582946312784778, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0004739105157654011, 'l1_Layer_2': 2.513529250240776e-05, 'l1_Layer_3': 0.0005755481323990449, 'l1_Layer_4': 4.020212200333482e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 175, 'n_units_Layer_3': 215, 'n_units_Layer_4': 115}. Best is trial 252 with value: 20.487778201885728.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.52 | sMAPE for Validation Set is: 26.10% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 56.37 | sMAPE for Test Set is: 34.17% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:08:52,667]\u001b[0m Trial 274 finished with value: 21.910879089934426 and parameters: {'n_hidden': 4, 'learning_rate': 0.0021873819528179022, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37785634160841197, 'dropout_rate_Layer_2': 0.3748836327840619, 'dropout_rate_Layer_3': 0.3968157093228152, 'dropout_rate_Layer_4': 0.3339820980562809, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0007141571462560024, 'l1_Layer_2': 1.8054758590697244e-05, 'l1_Layer_3': 0.0003732586777824436, 'l1_Layer_4': 6.184368223317704e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 150, 'n_units_Layer_3': 195, 'n_units_Layer_4': 115}. Best is trial 252 with value: 20.487778201885728.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.91 | sMAPE for Validation Set is: 27.14% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 54.10 | sMAPE for Test Set is: 33.75% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:08:59,093]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:09:03,266]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:09:04,317]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:09:09,600]\u001b[0m Trial 280 finished with value: 21.81323768329798 and parameters: {'n_hidden': 3, 'learning_rate': 0.005025539450737182, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04971979659656148, 'dropout_rate_Layer_2': 0.12029080059330513, 'dropout_rate_Layer_3': 0.04545714897833272, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.016775431131168642, 'l1_Layer_2': 2.273097563352927e-05, 'l1_Layer_3': 0.09235883200682023, 'n_units_Layer_1': 80, 'n_units_Layer_2': 220, 'n_units_Layer_3': 160}. Best is trial 252 with value: 20.487778201885728.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.81 | sMAPE for Validation Set is: 26.54% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 56.12 | sMAPE for Test Set is: 34.42% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:09:11,250]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:09:16,002]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.85 | sMAPE for Validation Set is: 26.47% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 50.53 | sMAPE for Test Set is: 32.30% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:09:17,924]\u001b[0m Trial 281 finished with value: 20.85461065341474 and parameters: {'n_hidden': 3, 'learning_rate': 0.002909344889134688, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.322914203668905, 'dropout_rate_Layer_2': 0.08965345114003836, 'dropout_rate_Layer_3': 0.371830640334023, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.06800023389555e-05, 'l1_Layer_2': 0.00670889034917873, 'l1_Layer_3': 0.0002129210051358893, 'n_units_Layer_1': 65, 'n_units_Layer_2': 180, 'n_units_Layer_3': 230}. Best is trial 252 with value: 20.487778201885728.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:09:20,753]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:09:24,196]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:09:28,229]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:09:28,367]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:09:34,095]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:09:34,437]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:09:34,591]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:09:41,371]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:09:43,934]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:09:46,811]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:09:50,995]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:09:53,255]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:09:57,038]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:10:02,135]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:10:02,163]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:10:02,334]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.70 | sMAPE for Validation Set is: 25.45% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 52.28 | sMAPE for Test Set is: 32.88% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:10:07,370]\u001b[0m Trial 300 finished with value: 20.695249734093576 and parameters: {'n_hidden': 3, 'learning_rate': 0.0057225884285413975, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05527672420470646, 'dropout_rate_Layer_2': 0.11607088980743918, 'dropout_rate_Layer_3': 0.06511871326997887, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.017980419148448706, 'l1_Layer_2': 1.8618109515284896e-05, 'l1_Layer_3': 2.16097062837254e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 225, 'n_units_Layer_3': 170}. Best is trial 252 with value: 20.487778201885728.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:10:11,898]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:10:12,030]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:10:12,416]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:10:20,989]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:10:22,210]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:10:31,505]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:10:32,395]\u001b[0m Trial 307 finished with value: 20.99758233473732 and parameters: {'n_hidden': 3, 'learning_rate': 0.0050767185512699195, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05144131926423558, 'dropout_rate_Layer_2': 0.10795547222111096, 'dropout_rate_Layer_3': 0.06375486020202707, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.030755265119352428, 'l1_Layer_2': 1.6880804667565897e-05, 'l1_Layer_3': 1.2941363711375701e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 220, 'n_units_Layer_3': 160}. Best is trial 252 with value: 20.487778201885728.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.00 | sMAPE for Validation Set is: 25.91% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 53.04 | sMAPE for Test Set is: 33.23% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:10:37,382]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:10:41,556]\u001b[0m Trial 311 finished with value: 21.008733543306313 and parameters: {'n_hidden': 3, 'learning_rate': 0.007249559481591847, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03625159467441416, 'dropout_rate_Layer_2': 0.12681105455959932, 'dropout_rate_Layer_3': 0.052356395179757265, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.02147204390284092, 'l1_Layer_2': 1.2604218828822382e-05, 'l1_Layer_3': 1.3778297179654599e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 205, 'n_units_Layer_3': 175}. Best is trial 252 with value: 20.487778201885728.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:10:41,624]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.01 | sMAPE for Validation Set is: 25.87% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 53.73 | sMAPE for Test Set is: 33.44% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:10:43,043]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:10:50,527]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:10:52,121]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:10:56,330]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:10:59,866]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:11:03,545]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:11:07,263]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:11:10,288]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:11:12,780]\u001b[0m Trial 318 finished with value: 21.42816853098363 and parameters: {'n_hidden': 3, 'learning_rate': 0.007089647421355503, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08510890072561125, 'dropout_rate_Layer_2': 0.1320305016936021, 'dropout_rate_Layer_3': 0.02785174888446268, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.044125771583331044, 'l1_Layer_2': 1.6289679095729716e-05, 'l1_Layer_3': 1.7614383588024352e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 230, 'n_units_Layer_3': 175}. Best is trial 252 with value: 20.487778201885728.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.43 | sMAPE for Validation Set is: 26.13% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 53.72 | sMAPE for Test Set is: 33.56% | rMAE for Test Set is: 0.59\n",
      "MAE for Validation Set is: 21.02 | sMAPE for Validation Set is: 26.04% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 51.62 | sMAPE for Test Set is: 32.59% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:11:14,618]\u001b[0m Trial 313 finished with value: 21.01794195584967 and parameters: {'n_hidden': 4, 'learning_rate': 0.001801678775519028, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06985571240470836, 'dropout_rate_Layer_2': 0.3637362966109428, 'dropout_rate_Layer_3': 0.3663774387779463, 'dropout_rate_Layer_4': 0.32774023812894115, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003728961788080502, 'l1_Layer_2': 2.7056729287826533e-05, 'l1_Layer_3': 0.00017510523404782122, 'l1_Layer_4': 1.8126927199096627e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 160, 'n_units_Layer_3': 170, 'n_units_Layer_4': 50}. Best is trial 252 with value: 20.487778201885728.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:11:17,360]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:11:18,178]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:11:18,985]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:11:24,335]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:11:27,137]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:11:29,484]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:11:33,712]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:11:35,042]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:11:38,811]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:11:42,331]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:11:42,763]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:11:46,511]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:11:47,853]\u001b[0m Trial 323 finished with value: 22.094229419471166 and parameters: {'n_hidden': 4, 'learning_rate': 0.002283470793125737, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23064485575743265, 'dropout_rate_Layer_2': 0.36453512080759026, 'dropout_rate_Layer_3': 0.32677872152854714, 'dropout_rate_Layer_4': 0.15119249659153564, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 7.852859755202779e-05, 'l1_Layer_2': 0.03329803567987192, 'l1_Layer_3': 8.64321202225138e-05, 'l1_Layer_4': 0.0023354129332195687, 'n_units_Layer_1': 75, 'n_units_Layer_2': 175, 'n_units_Layer_3': 240, 'n_units_Layer_4': 195}. Best is trial 252 with value: 20.487778201885728.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.09 | sMAPE for Validation Set is: 27.20% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 56.09 | sMAPE for Test Set is: 34.51% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:11:48,352]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:11:48,804]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:11:54,948]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:12:00,270]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:12:00,946]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:12:06,353]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:12:11,777]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:12:12,113]\u001b[0m Trial 340 finished with value: 20.726617120594284 and parameters: {'n_hidden': 3, 'learning_rate': 0.004922368360910625, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03492022749064, 'dropout_rate_Layer_2': 0.12085576690290137, 'dropout_rate_Layer_3': 0.04650725867255114, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.007027693761861017, 'l1_Layer_2': 2.608504812865718e-05, 'l1_Layer_3': 1.1023272869661143e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 205, 'n_units_Layer_3': 175}. Best is trial 252 with value: 20.487778201885728.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.73 | sMAPE for Validation Set is: 25.79% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 52.68 | sMAPE for Test Set is: 32.87% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:12:18,112]\u001b[0m Trial 342 finished with value: 20.787689499411062 and parameters: {'n_hidden': 3, 'learning_rate': 0.004559472461089989, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03708346626685164, 'dropout_rate_Layer_2': 0.13667045413840487, 'dropout_rate_Layer_3': 0.0828268211766882, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0020007847957982466, 'l1_Layer_2': 1.6041521861187423e-05, 'l1_Layer_3': 1.0010638690617837e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 225, 'n_units_Layer_3': 165}. Best is trial 252 with value: 20.487778201885728.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.79 | sMAPE for Validation Set is: 25.31% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 52.68 | sMAPE for Test Set is: 33.04% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:12:19,744]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:12:21,005]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:12:24,135]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:12:28,570]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:12:28,622]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:12:29,112]\u001b[0m Trial 344 finished with value: 20.578802136442516 and parameters: {'n_hidden': 3, 'learning_rate': 0.004976149919750284, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.011368999058208932, 'dropout_rate_Layer_2': 0.13489841959499524, 'dropout_rate_Layer_3': 0.09538527511855982, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006341073781991424, 'l1_Layer_2': 1.590296755108974e-05, 'l1_Layer_3': 2.2125662546882164e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 225, 'n_units_Layer_3': 165}. Best is trial 252 with value: 20.487778201885728.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.58 | sMAPE for Validation Set is: 25.21% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 51.85 | sMAPE for Test Set is: 32.59% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:12:37,302]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:12:38,758]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:12:40,420]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:12:46,402]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:12:46,993]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:12:49,556]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:12:50,180]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:12:52,698]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:12:59,852]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:13:02,468]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:13:05,171]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:13:07,464]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:13:08,009]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:13:14,738]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:13:15,408]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:13:20,316]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:13:22,533]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:13:25,030]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.80 | sMAPE for Validation Set is: 25.68% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 51.69 | sMAPE for Test Set is: 32.66% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:13:27,630]\u001b[0m Trial 362 finished with value: 20.79794601361179 and parameters: {'n_hidden': 3, 'learning_rate': 0.004122372048861913, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26430346600808524, 'dropout_rate_Layer_2': 0.19197100881701445, 'dropout_rate_Layer_3': 0.20855248021604048, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001546945922285354, 'l1_Layer_2': 0.012987455548289712, 'l1_Layer_3': 0.0005970917639645857, 'n_units_Layer_1': 155, 'n_units_Layer_2': 230, 'n_units_Layer_3': 165}. Best is trial 252 with value: 20.487778201885728.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:13:29,765]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:13:30,564]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:13:37,621]\u001b[0m Trial 366 finished with value: 20.46432499630713 and parameters: {'n_hidden': 3, 'learning_rate': 0.006009322403418325, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2664958314728017, 'dropout_rate_Layer_2': 0.07210771264111826, 'dropout_rate_Layer_3': 0.34426651977539846, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3375503977123995e-05, 'l1_Layer_2': 0.0010602981164007728, 'l1_Layer_3': 0.0012119157040604443, 'n_units_Layer_1': 155, 'n_units_Layer_2': 205, 'n_units_Layer_3': 165}. Best is trial 366 with value: 20.46432499630713.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.46 | sMAPE for Validation Set is: 25.28% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 52.65 | sMAPE for Test Set is: 32.58% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:13:40,475]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:13:49,837]\u001b[0m Trial 374 finished with value: 20.389877426955067 and parameters: {'n_hidden': 3, 'learning_rate': 0.00519153223131122, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06317160063305025, 'dropout_rate_Layer_2': 0.15418062934370502, 'dropout_rate_Layer_3': 0.06777385652964758, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.023708352979822295, 'l1_Layer_2': 1.7922133534527676e-05, 'l1_Layer_3': 3.242452752494443e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 225, 'n_units_Layer_3': 180}. Best is trial 374 with value: 20.389877426955067.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.39 | sMAPE for Validation Set is: 24.95% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 50.96 | sMAPE for Test Set is: 32.11% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:13:53,425]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:13:53,954]\u001b[0m Trial 377 finished with value: 20.528927271557034 and parameters: {'n_hidden': 3, 'learning_rate': 0.005081844623193167, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0065421316284197395, 'dropout_rate_Layer_2': 0.15416961474666072, 'dropout_rate_Layer_3': 0.06715078678894655, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.013882209538023616, 'l1_Layer_2': 1.828417956612326e-05, 'l1_Layer_3': 3.212038826245506e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 255, 'n_units_Layer_3': 180}. Best is trial 374 with value: 20.389877426955067.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:13:53,984]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.53 | sMAPE for Validation Set is: 25.22% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 51.73 | sMAPE for Test Set is: 32.69% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:14:01,367]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:14:05,085]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:14:09,563]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:14:11,890]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:14:15,394]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:14:17,819]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:14:21,257]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:14:22,283]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:14:26,547]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.43 | sMAPE for Validation Set is: 25.21% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 52.76 | sMAPE for Test Set is: 32.73% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:14:28,474]\u001b[0m Trial 383 finished with value: 20.428336861508743 and parameters: {'n_hidden': 3, 'learning_rate': 0.0059645633656018595, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0027961951616919927, 'dropout_rate_Layer_2': 0.14206505901086788, 'dropout_rate_Layer_3': 0.07710000587686261, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.011167311012945507, 'l1_Layer_2': 0.0010180135875894729, 'l1_Layer_3': 3.238405143547383e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 260, 'n_units_Layer_3': 170}. Best is trial 374 with value: 20.389877426955067.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:14:32,304]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:14:34,835]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:14:39,701]\u001b[0m Trial 373 finished with value: 20.645427226081242 and parameters: {'n_hidden': 4, 'learning_rate': 0.0032333473668933487, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.029986058066927113, 'dropout_rate_Layer_2': 0.3636011794422689, 'dropout_rate_Layer_3': 0.3846562163828066, 'dropout_rate_Layer_4': 0.3287685047964945, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.004077206163745711, 'l1_Layer_2': 4.1103520431801945e-05, 'l1_Layer_3': 0.00025409296288611425, 'l1_Layer_4': 1.720877870092559e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 125, 'n_units_Layer_3': 215, 'n_units_Layer_4': 50}. Best is trial 374 with value: 20.389877426955067.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.65 | sMAPE for Validation Set is: 25.65% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 49.97 | sMAPE for Test Set is: 32.13% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:14:47,145]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:14:51,042]\u001b[0m Trial 393 finished with value: 20.789156959323243 and parameters: {'n_hidden': 3, 'learning_rate': 0.006943167344209781, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2645162569616217, 'dropout_rate_Layer_2': 0.2071334425374287, 'dropout_rate_Layer_3': 0.29903419283608246, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2628431940699208e-05, 'l1_Layer_2': 0.028461766569896765, 'l1_Layer_3': 0.00014829833336327627, 'n_units_Layer_1': 160, 'n_units_Layer_2': 215, 'n_units_Layer_3': 165}. Best is trial 374 with value: 20.389877426955067.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.79 | sMAPE for Validation Set is: 25.66% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 51.43 | sMAPE for Test Set is: 32.88% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:14:52,256]\u001b[0m Trial 392 finished with value: 20.508100035297137 and parameters: {'n_hidden': 3, 'learning_rate': 0.004626512991563632, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0035362268621961512, 'dropout_rate_Layer_2': 0.12239991172955636, 'dropout_rate_Layer_3': 0.07419811391024048, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.010626714034242927, 'l1_Layer_2': 0.0009148178534432954, 'l1_Layer_3': 2.8113431132022803e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 260, 'n_units_Layer_3': 160}. Best is trial 374 with value: 20.389877426955067.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.51 | sMAPE for Validation Set is: 25.35% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 50.38 | sMAPE for Test Set is: 32.06% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:14:56,713]\u001b[0m Trial 394 finished with value: 20.626744097166 and parameters: {'n_hidden': 3, 'learning_rate': 0.006520329602123203, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0003592906198537499, 'dropout_rate_Layer_2': 0.13715144987642464, 'dropout_rate_Layer_3': 0.07663546912373709, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.009642925887022593, 'l1_Layer_2': 0.000574114068415311, 'l1_Layer_3': 2.2307278103429295e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 225, 'n_units_Layer_3': 160}. Best is trial 374 with value: 20.389877426955067.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.63 | sMAPE for Validation Set is: 25.62% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 50.85 | sMAPE for Test Set is: 32.26% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:14:57,655]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:15:09,410]\u001b[0m Trial 399 finished with value: 20.642562103231526 and parameters: {'n_hidden': 3, 'learning_rate': 0.005602041153627673, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00046808654975173496, 'dropout_rate_Layer_2': 0.1385066183681381, 'dropout_rate_Layer_3': 0.07489811975272326, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.012108254454351356, 'l1_Layer_2': 0.0008964231847826778, 'l1_Layer_3': 2.144271274920617e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 260, 'n_units_Layer_3': 165}. Best is trial 374 with value: 20.389877426955067.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.64 | sMAPE for Validation Set is: 25.30% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 52.42 | sMAPE for Test Set is: 32.57% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:15:12,392]\u001b[0m Trial 396 finished with value: 20.478547981429145 and parameters: {'n_hidden': 3, 'learning_rate': 0.005651774907906941, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0002796513788806687, 'dropout_rate_Layer_2': 0.12319654043552627, 'dropout_rate_Layer_3': 0.07608605788017367, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01150834234260163, 'l1_Layer_2': 0.0011968347920963765, 'l1_Layer_3': 2.3763397741391766e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 185, 'n_units_Layer_3': 160}. Best is trial 374 with value: 20.389877426955067.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.48 | sMAPE for Validation Set is: 24.92% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 50.61 | sMAPE for Test Set is: 32.05% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:15:14,942]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:15:17,259]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:15:21,193]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:15:33,519]\u001b[0m Trial 395 finished with value: 20.900697367926107 and parameters: {'n_hidden': 4, 'learning_rate': 0.0032027447577540253, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.040759137894428574, 'dropout_rate_Layer_2': 0.34603179967496545, 'dropout_rate_Layer_3': 0.3536851448268312, 'dropout_rate_Layer_4': 0.2860191267255918, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0038571816146865585, 'l1_Layer_2': 6.794857295065923e-05, 'l1_Layer_3': 0.0005159744179876716, 'l1_Layer_4': 1.8123137212375335e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 130, 'n_units_Layer_3': 220, 'n_units_Layer_4': 50}. Best is trial 374 with value: 20.389877426955067.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.90 | sMAPE for Validation Set is: 25.94% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 53.01 | sMAPE for Test Set is: 33.28% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:15:37,012]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:15:37,460]\u001b[0m Trial 404 finished with value: 20.721583426318357 and parameters: {'n_hidden': 3, 'learning_rate': 0.006389847475429945, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008885104343592173, 'dropout_rate_Layer_2': 0.1381381826527124, 'dropout_rate_Layer_3': 0.07417880478113896, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008544493947079864, 'l1_Layer_2': 0.0009725802237770744, 'l1_Layer_3': 2.039542664608596e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 270, 'n_units_Layer_3': 155}. Best is trial 374 with value: 20.389877426955067.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.72 | sMAPE for Validation Set is: 25.66% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 52.04 | sMAPE for Test Set is: 32.70% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:15:42,667]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:15:46,997]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.82 | sMAPE for Validation Set is: 26.58% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 54.18 | sMAPE for Test Set is: 33.90% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:15:48,759]\u001b[0m Trial 403 finished with value: 21.822440029003104 and parameters: {'n_hidden': 4, 'learning_rate': 0.0044144718824502445, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.030092873551931253, 'dropout_rate_Layer_2': 0.29693969740960985, 'dropout_rate_Layer_3': 0.35334631792188187, 'dropout_rate_Layer_4': 0.28178323872241917, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.003947552039764942, 'l1_Layer_2': 2.5788600198069153e-05, 'l1_Layer_3': 7.223706836713455e-05, 'l1_Layer_4': 1.933485694065554e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 130, 'n_units_Layer_3': 220, 'n_units_Layer_4': 50}. Best is trial 374 with value: 20.389877426955067.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:15:52,084]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:15:55,315]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:16:02,224]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:16:02,763]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:16:04,985]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:16:08,114]\u001b[0m Trial 398 finished with value: 20.850878287387292 and parameters: {'n_hidden': 4, 'learning_rate': 0.0032940616116772, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.030787021067646463, 'dropout_rate_Layer_2': 0.3446310163807095, 'dropout_rate_Layer_3': 0.35239127283255556, 'dropout_rate_Layer_4': 0.28667527360399153, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.008466015530133247, 'l1_Layer_2': 1.4719662539439597e-05, 'l1_Layer_3': 7.975030869001761e-05, 'l1_Layer_4': 1.9921115812107064e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 125, 'n_units_Layer_3': 225, 'n_units_Layer_4': 50}. Best is trial 374 with value: 20.389877426955067.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.85 | sMAPE for Validation Set is: 25.65% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 52.05 | sMAPE for Test Set is: 32.96% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:16:10,885]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:16:18,956]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:16:24,582]\u001b[0m Trial 417 finished with value: 20.765584097290397 and parameters: {'n_hidden': 3, 'learning_rate': 0.005620694619438193, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0009981875867025331, 'dropout_rate_Layer_2': 0.13405199741286555, 'dropout_rate_Layer_3': 0.07360200576996793, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008401142037095, 'l1_Layer_2': 0.000434011182430793, 'l1_Layer_3': 3.848977984832417e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 260, 'n_units_Layer_3': 150}. Best is trial 374 with value: 20.389877426955067.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.77 | sMAPE for Validation Set is: 25.70% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 51.79 | sMAPE for Test Set is: 32.59% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:16:25,350]\u001b[0m Trial 413 finished with value: 20.604531934463335 and parameters: {'n_hidden': 3, 'learning_rate': 0.004551914296023872, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.017394630423136177, 'dropout_rate_Layer_2': 0.138296255082834, 'dropout_rate_Layer_3': 0.07226786042047237, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.014540633643372438, 'l1_Layer_2': 0.0011272229933961138, 'l1_Layer_3': 3.4925498893172076e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 270, 'n_units_Layer_3': 150}. Best is trial 374 with value: 20.389877426955067.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.60 | sMAPE for Validation Set is: 25.23% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 51.83 | sMAPE for Test Set is: 32.43% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:16:30,342]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:16:31,096]\u001b[0m Trial 415 finished with value: 21.38410832077209 and parameters: {'n_hidden': 3, 'learning_rate': 0.007611438446751726, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24937933067652154, 'dropout_rate_Layer_2': 0.06160465434620136, 'dropout_rate_Layer_3': 0.35218633975938246, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0022134998686966587, 'l1_Layer_2': 0.00197430567484867, 'l1_Layer_3': 0.012126945642328378, 'n_units_Layer_1': 180, 'n_units_Layer_2': 230, 'n_units_Layer_3': 180}. Best is trial 374 with value: 20.389877426955067.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.38 | sMAPE for Validation Set is: 26.35% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 55.27 | sMAPE for Test Set is: 34.06% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:16:36,767]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:16:41,699]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:16:41,769]\u001b[0m Trial 418 finished with value: 20.547380647068806 and parameters: {'n_hidden': 3, 'learning_rate': 0.005585326507631852, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008334237657151605, 'dropout_rate_Layer_2': 0.1350132589310619, 'dropout_rate_Layer_3': 0.06941722868495469, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008262026128439041, 'l1_Layer_2': 0.000679016141371599, 'l1_Layer_3': 3.8717436381261905e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 255, 'n_units_Layer_3': 150}. Best is trial 374 with value: 20.389877426955067.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.55 | sMAPE for Validation Set is: 25.16% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 50.97 | sMAPE for Test Set is: 31.96% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:16:47,181]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:16:47,358]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:16:52,749]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:16:52,929]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:17:00,000]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:17:00,737]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:17:00,747]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:17:08,513]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:17:08,679]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:17:08,937]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:17:16,668]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:17:19,224]\u001b[0m Trial 428 finished with value: 21.77206024874522 and parameters: {'n_hidden': 3, 'learning_rate': 0.0052676123948045515, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3623307568916381, 'dropout_rate_Layer_2': 0.11879518040506674, 'dropout_rate_Layer_3': 0.3786863340348819, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005523225489337904, 'l1_Layer_2': 0.007847766060027043, 'l1_Layer_3': 0.0033135975648721006, 'n_units_Layer_1': 100, 'n_units_Layer_2': 185, 'n_units_Layer_3': 170}. Best is trial 374 with value: 20.389877426955067.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.77 | sMAPE for Validation Set is: 26.55% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 54.76 | sMAPE for Test Set is: 33.97% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:17:19,584]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:17:20,585]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:17:27,828]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:17:28,060]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:17:34,732]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:17:35,360]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:17:40,654]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:17:41,106]\u001b[0m Trial 437 finished with value: 20.18817663755941 and parameters: {'n_hidden': 3, 'learning_rate': 0.004896844762333623, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.009323875150248608, 'dropout_rate_Layer_2': 0.14995819426664142, 'dropout_rate_Layer_3': 0.0920591803144379, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.014178426825475604, 'l1_Layer_2': 0.0005098049297807819, 'l1_Layer_3': 2.3774944461485937e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 270, 'n_units_Layer_3': 140}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.19 | sMAPE for Validation Set is: 24.96% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 50.63 | sMAPE for Test Set is: 32.03% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:17:41,350]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:17:42,312]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:17:49,085]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:17:53,275]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:17:54,910]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:17:58,378]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:18:00,942]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:18:03,420]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:18:05,249]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:18:09,009]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:18:09,844]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:18:14,969]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:18:15,273]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:18:30,810]\u001b[0m Trial 448 finished with value: 21.229189256005668 and parameters: {'n_hidden': 4, 'learning_rate': 0.0029965077451499225, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.043356363643469, 'dropout_rate_Layer_2': 0.35317332518371186, 'dropout_rate_Layer_3': 0.37504727636429525, 'dropout_rate_Layer_4': 0.2998677266419264, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.01001592036007851, 'l1_Layer_2': 1.4204487184900437e-05, 'l1_Layer_3': 0.0002979699026601038, 'l1_Layer_4': 3.017554389249129e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 115, 'n_units_Layer_3': 245, 'n_units_Layer_4': 50}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.23 | sMAPE for Validation Set is: 26.02% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 52.50 | sMAPE for Test Set is: 33.09% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:18:34,249]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:18:34,489]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:18:40,652]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:18:40,776]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.71 | sMAPE for Validation Set is: 25.58% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 49.71 | sMAPE for Test Set is: 31.93% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:18:43,253]\u001b[0m Trial 446 finished with value: 20.710971538032677 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019236613664579247, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.037254578181756086, 'dropout_rate_Layer_2': 0.31849000236559444, 'dropout_rate_Layer_3': 0.37691827771381287, 'dropout_rate_Layer_4': 0.30033725807893946, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00851446034540757, 'l1_Layer_2': 3.9427833991576374e-05, 'l1_Layer_3': 0.0009462473897628918, 'l1_Layer_4': 3.1077969537010315e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 115, 'n_units_Layer_3': 250, 'n_units_Layer_4': 50}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:18:48,790]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:18:50,611]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:18:55,364]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:18:56,196]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:19:01,915]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:19:02,979]\u001b[0m Trial 457 finished with value: 21.21308945495878 and parameters: {'n_hidden': 4, 'learning_rate': 0.0031523337789945605, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05012956509943586, 'dropout_rate_Layer_2': 0.35377563438452575, 'dropout_rate_Layer_3': 0.37285716172203853, 'dropout_rate_Layer_4': 0.30299683267823946, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.008064990388563882, 'l1_Layer_2': 1.4012426827045658e-05, 'l1_Layer_3': 0.00027718870114989296, 'l1_Layer_4': 2.859777203244694e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 80, 'n_units_Layer_3': 255, 'n_units_Layer_4': 60}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.21 | sMAPE for Validation Set is: 26.32% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 52.82 | sMAPE for Test Set is: 33.04% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:19:07,198]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:19:08,388]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:19:09,575]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:19:16,624]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:19:17,281]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:19:20,805]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:19:24,656]\u001b[0m Trial 468 finished with value: 20.605567080659352 and parameters: {'n_hidden': 3, 'learning_rate': 0.003155204741609969, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2834541184163921, 'dropout_rate_Layer_2': 0.22977293794851378, 'dropout_rate_Layer_3': 0.23965893943927397, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0019012276124368865, 'l1_Layer_2': 0.004459658146945133, 'l1_Layer_3': 0.0008124713793318858, 'n_units_Layer_1': 160, 'n_units_Layer_2': 235, 'n_units_Layer_3': 165}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.61 | sMAPE for Validation Set is: 25.55% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 52.51 | sMAPE for Test Set is: 32.99% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:19:25,176]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:19:25,767]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:19:32,138]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:19:33,252]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:19:33,572]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:19:33,937]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:19:39,073]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:19:39,530]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:19:45,878]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:19:46,083]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:19:48,668]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:19:49,451]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:19:57,485]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:19:58,177]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:19:58,368]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:20:04,668]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:20:06,221]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:20:07,316]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:20:07,810]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:20:08,279]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:20:17,419]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:20:17,807]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:20:17,939]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:20:23,375]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:20:26,001]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:20:27,748]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:20:31,057]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:20:34,413]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:20:34,822]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:20:40,444]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:20:43,691]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:20:44,276]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:20:44,508]\u001b[0m Trial 501 finished with value: 22.69479501734455 and parameters: {'n_hidden': 4, 'learning_rate': 0.012751696751447637, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09070326235291923, 'dropout_rate_Layer_2': 0.35682085503209654, 'dropout_rate_Layer_3': 0.38491810704065815, 'dropout_rate_Layer_4': 0.30340916554230934, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.011545195674699735, 'l1_Layer_2': 2.2247941698527285e-05, 'l1_Layer_3': 0.0002515827904731639, 'l1_Layer_4': 5.1302616799356406e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 90, 'n_units_Layer_3': 245, 'n_units_Layer_4': 75}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.69 | sMAPE for Validation Set is: 27.69% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 57.09 | sMAPE for Test Set is: 34.99% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:20:49,668]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:20:50,663]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:20:52,940]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:20:53,052]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:20:59,920]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:21:02,780]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:21:04,780]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:21:22,014]\u001b[0m Trial 513 finished with value: 21.11471373625974 and parameters: {'n_hidden': 4, 'learning_rate': 0.0031788548656201524, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03254917737268647, 'dropout_rate_Layer_2': 0.29926850774809644, 'dropout_rate_Layer_3': 0.3726143838487897, 'dropout_rate_Layer_4': 0.3226190077729266, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.03226997365108373, 'l1_Layer_2': 8.17157693456417e-05, 'l1_Layer_3': 0.00011888087673514451, 'l1_Layer_4': 1.9168743088475647e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 115, 'n_units_Layer_3': 255, 'n_units_Layer_4': 60}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.11 | sMAPE for Validation Set is: 26.17% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 50.64 | sMAPE for Test Set is: 32.31% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:21:26,176]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:21:28,788]\u001b[0m Trial 512 finished with value: 21.336581094907093 and parameters: {'n_hidden': 4, 'learning_rate': 0.0032194773220263094, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.055704907632946124, 'dropout_rate_Layer_2': 0.3019392081121116, 'dropout_rate_Layer_3': 0.34484832836190166, 'dropout_rate_Layer_4': 0.31896084155417, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.02600123727283364, 'l1_Layer_2': 3.3793075466588965e-05, 'l1_Layer_3': 0.00012211642264538155, 'l1_Layer_4': 2.1006521062911275e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 75, 'n_units_Layer_3': 255, 'n_units_Layer_4': 60}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.34 | sMAPE for Validation Set is: 26.81% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 52.23 | sMAPE for Test Set is: 32.93% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:21:31,447]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:21:36,325]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:21:41,049]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:21:41,354]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:21:41,429]\u001b[0m Trial 516 finished with value: 21.206845426461772 and parameters: {'n_hidden': 4, 'learning_rate': 0.0031795349421007636, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03285823947694228, 'dropout_rate_Layer_2': 0.36971849717344096, 'dropout_rate_Layer_3': 0.3439953808336257, 'dropout_rate_Layer_4': 0.32648837616587867, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.015056934796701905, 'l1_Layer_2': 8.055371338273572e-05, 'l1_Layer_3': 0.00012821011725010242, 'l1_Layer_4': 2.0208262789619987e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 115, 'n_units_Layer_3': 290, 'n_units_Layer_4': 60}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.21 | sMAPE for Validation Set is: 26.36% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 53.10 | sMAPE for Test Set is: 33.05% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:21:41,900]\u001b[0m Trial 517 finished with value: 20.99093252227959 and parameters: {'n_hidden': 4, 'learning_rate': 0.0030519250926313, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05423657221591083, 'dropout_rate_Layer_2': 0.28341716291707125, 'dropout_rate_Layer_3': 0.34414630953822917, 'dropout_rate_Layer_4': 0.3233786746019913, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.015498863401141306, 'l1_Layer_2': 3.472910906667056e-05, 'l1_Layer_3': 0.00011589766817925576, 'l1_Layer_4': 2.0744128056980804e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 115, 'n_units_Layer_3': 285, 'n_units_Layer_4': 60}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.99 | sMAPE for Validation Set is: 25.70% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 50.40 | sMAPE for Test Set is: 32.10% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:21:49,222]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:21:50,008]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:21:51,064]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:21:52,215]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:21:57,835]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:21:58,178]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:22:06,329]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:22:07,320]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:22:08,710]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:22:10,924]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:22:15,350]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:22:17,651]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:22:24,918]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:22:25,287]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:22:30,613]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:22:31,543]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:22:32,148]\u001b[0m Trial 529 finished with value: 21.27675277281962 and parameters: {'n_hidden': 3, 'learning_rate': 0.005208570187188102, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3829024876677797, 'dropout_rate_Layer_2': 0.1227998605337881, 'dropout_rate_Layer_3': 0.37017715063198475, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004344128985988656, 'l1_Layer_2': 0.007006749839329929, 'l1_Layer_3': 0.006660027940166665, 'n_units_Layer_1': 90, 'n_units_Layer_2': 175, 'n_units_Layer_3': 170}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.28 | sMAPE for Validation Set is: 26.01% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 55.09 | sMAPE for Test Set is: 33.78% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:22:34,953]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:22:42,619]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:22:43,137]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:22:43,347]\u001b[0m Trial 537 finished with value: 21.35206357235793 and parameters: {'n_hidden': 3, 'learning_rate': 0.006508583825755026, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3800683369907363, 'dropout_rate_Layer_2': 0.09484397024761254, 'dropout_rate_Layer_3': 0.38189119071319877, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0024203937430521964, 'l1_Layer_2': 0.011162972693202712, 'l1_Layer_3': 0.0021313026592417396, 'n_units_Layer_1': 80, 'n_units_Layer_2': 165, 'n_units_Layer_3': 155}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:22:43,410]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.35 | sMAPE for Validation Set is: 26.08% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 53.56 | sMAPE for Test Set is: 33.33% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:22:51,048]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:22:55,429]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:23:00,463]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:23:01,799]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:23:05,625]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.66 | sMAPE for Validation Set is: 25.58% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 51.99 | sMAPE for Test Set is: 32.50% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:23:08,024]\u001b[0m Trial 545 finished with value: 20.661867401337933 and parameters: {'n_hidden': 3, 'learning_rate': 0.005218458825687831, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00022529503010695028, 'dropout_rate_Layer_2': 0.11251424089819459, 'dropout_rate_Layer_3': 0.03565721541517191, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.009012293564130263, 'l1_Layer_2': 0.000593668945110115, 'l1_Layer_3': 3.209733073491366e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 215, 'n_units_Layer_3': 165}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:23:11,221]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:23:12,000]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:23:18,626]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:23:23,404]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:23:30,551]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:23:38,435]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:23:47,604]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:23:51,250]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:23:55,348]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:23:59,451]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:24:02,937]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:24:06,312]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:24:09,119]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:24:11,977]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:24:14,216]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:24:15,669]\u001b[0m Trial 558 finished with value: 21.132037934299067 and parameters: {'n_hidden': 4, 'learning_rate': 0.0025482977807869396, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.034427089628282954, 'dropout_rate_Layer_2': 0.1779643524016059, 'dropout_rate_Layer_3': 0.15108652350707363, 'dropout_rate_Layer_4': 0.34135513235572923, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.02588612870280516, 'l1_Layer_2': 9.074811813142416e-05, 'l1_Layer_3': 0.0008920799405705909, 'l1_Layer_4': 1.4549125911865819e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 105, 'n_units_Layer_3': 280, 'n_units_Layer_4': 55}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.13 | sMAPE for Validation Set is: 26.12% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 52.24 | sMAPE for Test Set is: 32.74% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:24:17,742]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:24:21,328]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:24:24,517]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:24:25,241]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:24:31,380]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:24:34,760]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:24:35,428]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:24:39,749]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:24:40,331]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:24:47,017]\u001b[0m Trial 560 finished with value: 20.757397378427804 and parameters: {'n_hidden': 4, 'learning_rate': 0.0020839212666568657, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0003545575193613093, 'dropout_rate_Layer_2': 0.1752878453290506, 'dropout_rate_Layer_3': 0.1213513896427016, 'dropout_rate_Layer_4': 0.34328160418275105, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.029773755087378204, 'l1_Layer_2': 5.322145933491134e-05, 'l1_Layer_3': 0.0004769583987952687, 'l1_Layer_4': 3.5345081555508306e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 145, 'n_units_Layer_3': 265, 'n_units_Layer_4': 60}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.76 | sMAPE for Validation Set is: 25.99% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 50.99 | sMAPE for Test Set is: 32.12% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:24:49,793]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:24:50,426]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:24:53,054]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:24:55,088]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:24:55,182]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:24:56,754]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:25:04,564]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:25:05,027]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:25:07,172]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:25:11,961]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:25:16,801]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:25:21,105]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:25:22,123]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:25:30,332]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:25:34,508]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:25:38,685]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:25:41,554]\u001b[0m Trial 589 finished with value: 20.881295942275663 and parameters: {'n_hidden': 3, 'learning_rate': 0.008650403572355143, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3216609326131653, 'dropout_rate_Layer_2': 0.1463831259431368, 'dropout_rate_Layer_3': 0.37893851512068627, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0033533482779659635, 'l1_Layer_2': 0.0011016074829665187, 'l1_Layer_3': 0.0007891471564468798, 'n_units_Layer_1': 75, 'n_units_Layer_2': 200, 'n_units_Layer_3': 185}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.88 | sMAPE for Validation Set is: 25.76% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 52.89 | sMAPE for Test Set is: 32.89% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:25:45,724]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:25:46,676]\u001b[0m Trial 592 finished with value: 21.130857537316654 and parameters: {'n_hidden': 4, 'learning_rate': 0.002179887809911616, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02495048268060575, 'dropout_rate_Layer_2': 0.22439801854003974, 'dropout_rate_Layer_3': 0.08774170000679431, 'dropout_rate_Layer_4': 0.32331027294291187, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.01510332558434488, 'l1_Layer_2': 4.678654345639046e-05, 'l1_Layer_3': 5.563067602866032e-05, 'l1_Layer_4': 1.8699860012779075e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 115, 'n_units_Layer_3': 160, 'n_units_Layer_4': 60}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.13 | sMAPE for Validation Set is: 26.40% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 51.91 | sMAPE for Test Set is: 32.84% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:25:51,593]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:25:53,875]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:25:57,231]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:26:00,807]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:26:01,053]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:26:01,636]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:26:07,551]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:26:08,992]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:26:09,761]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:26:14,242]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:26:16,691]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:26:19,346]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:26:22,266]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:26:24,040]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:26:28,655]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.92 | sMAPE for Validation Set is: 25.75% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 52.33 | sMAPE for Test Set is: 32.48% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:26:29,627]\u001b[0m Trial 595 finished with value: 20.92121133148115 and parameters: {'n_hidden': 4, 'learning_rate': 0.003539679947546168, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.025422141681346218, 'dropout_rate_Layer_2': 0.17523596165977062, 'dropout_rate_Layer_3': 0.10951723684627951, 'dropout_rate_Layer_4': 0.28966014489766523, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.006441165607839541, 'l1_Layer_2': 9.423518635017406e-05, 'l1_Layer_3': 4.980275746367326e-05, 'l1_Layer_4': 2.3623729275315173e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 115, 'n_units_Layer_3': 270, 'n_units_Layer_4': 65}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:26:33,054]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:26:33,671]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:26:35,689]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:26:35,996]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:26:40,393]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:26:40,959]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:26:45,478]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:26:51,021]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:26:52,057]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:26:52,608]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:27:00,144]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:27:00,450]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:27:00,697]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:27:08,992]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:27:09,350]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:27:09,453]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:27:16,064]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:27:16,584]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:27:21,437]\u001b[0m Trial 622 finished with value: 20.622729974989564 and parameters: {'n_hidden': 3, 'learning_rate': 0.005638822501246886, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28872717619343347, 'dropout_rate_Layer_2': 0.0649321178673617, 'dropout_rate_Layer_3': 0.3594960403768551, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0028484740053762517, 'l1_Layer_2': 0.002250335287627697, 'l1_Layer_3': 0.0003017728684765224, 'n_units_Layer_1': 95, 'n_units_Layer_2': 215, 'n_units_Layer_3': 185}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.62 | sMAPE for Validation Set is: 25.57% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 50.43 | sMAPE for Test Set is: 32.13% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:27:23,690]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:27:27,547]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:27:35,703]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:27:38,874]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:27:40,759]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.87 | sMAPE for Validation Set is: 25.93% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 52.22 | sMAPE for Test Set is: 32.90% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:27:43,842]\u001b[0m Trial 630 finished with value: 20.869045068107727 and parameters: {'n_hidden': 4, 'learning_rate': 0.003544878433146095, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.023506304326510595, 'dropout_rate_Layer_2': 0.22304342491687965, 'dropout_rate_Layer_3': 0.10426533588273591, 'dropout_rate_Layer_4': 0.278631778753109, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00491343787181343, 'l1_Layer_2': 3.5302442349764947e-05, 'l1_Layer_3': 3.829378279467621e-05, 'l1_Layer_4': 3.4572128104547864e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 135, 'n_units_Layer_3': 155, 'n_units_Layer_4': 50}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:27:44,024]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:27:49,662]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:27:52,788]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:27:53,634]\u001b[0m Trial 632 finished with value: 20.725872245545272 and parameters: {'n_hidden': 4, 'learning_rate': 0.003543639361368087, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.023642999067017487, 'dropout_rate_Layer_2': 0.23358312394934055, 'dropout_rate_Layer_3': 0.10747239727196735, 'dropout_rate_Layer_4': 0.291806049642175, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.009003464391396807, 'l1_Layer_2': 3.0097181855846872e-05, 'l1_Layer_3': 5.130180239319958e-05, 'l1_Layer_4': 5.983895194451959e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 135, 'n_units_Layer_3': 175, 'n_units_Layer_4': 50}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.73 | sMAPE for Validation Set is: 25.82% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 52.59 | sMAPE for Test Set is: 32.66% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:27:54,126]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:27:54,444]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:27:58,630]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:28:01,144]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:28:03,073]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:28:08,608]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:28:10,401]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:28:11,522]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:28:20,268]\u001b[0m Trial 646 finished with value: 20.480286450430444 and parameters: {'n_hidden': 3, 'learning_rate': 0.006223161437996153, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.033233775881789974, 'dropout_rate_Layer_2': 0.13316091045827733, 'dropout_rate_Layer_3': 0.02614199943867694, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.016062882726216015, 'l1_Layer_2': 1.9440167956479803e-05, 'l1_Layer_3': 1.7510707606294685e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 225, 'n_units_Layer_3': 165}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.48 | sMAPE for Validation Set is: 25.21% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 51.60 | sMAPE for Test Set is: 32.56% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:28:24,172]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:28:24,499]\u001b[0m Trial 651 finished with value: 20.915268622665653 and parameters: {'n_hidden': 3, 'learning_rate': 0.0075449530565179, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20913342569343715, 'dropout_rate_Layer_2': 0.12337186673848306, 'dropout_rate_Layer_3': 0.08225535464611168, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.010777840253012552, 'l1_Layer_2': 0.00045693571433256646, 'l1_Layer_3': 1.7475453378228543e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 230, 'n_units_Layer_3': 155}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.92 | sMAPE for Validation Set is: 25.93% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 52.15 | sMAPE for Test Set is: 32.98% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:28:27,451]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:28:30,163]\u001b[0m Trial 650 finished with value: 20.3555607960788 and parameters: {'n_hidden': 3, 'learning_rate': 0.008183380213586236, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2623362681895808, 'dropout_rate_Layer_2': 0.057713667453387574, 'dropout_rate_Layer_3': 0.3561549636015374, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0014815186309372157, 'l1_Layer_2': 0.0021523308800042045, 'l1_Layer_3': 0.00020580363035372617, 'n_units_Layer_1': 90, 'n_units_Layer_2': 235, 'n_units_Layer_3': 175}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.36 | sMAPE for Validation Set is: 25.10% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 50.03 | sMAPE for Test Set is: 32.29% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:28:30,381]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:28:30,717]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:28:34,183]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:28:41,527]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:28:43,165]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:28:43,409]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:28:44,137]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:28:48,517]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:28:54,261]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:28:55,186]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:28:55,212]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:28:55,920]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:29:03,725]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:29:05,008]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:29:06,188]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:29:06,729]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:29:16,487]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:29:17,204]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:29:22,328]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:29:22,602]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:29:28,028]\u001b[0m Trial 670 finished with value: 20.578228562366586 and parameters: {'n_hidden': 3, 'learning_rate': 0.00561710219964679, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.037940087813078546, 'dropout_rate_Layer_2': 0.09884181735788383, 'dropout_rate_Layer_3': 0.051897370227648926, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.010673170605653247, 'l1_Layer_2': 1.7223138859961226e-05, 'l1_Layer_3': 4.1456353278511314e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 200, 'n_units_Layer_3': 155}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.58 | sMAPE for Validation Set is: 25.13% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 52.64 | sMAPE for Test Set is: 33.01% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:29:30,403]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:29:31,191]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:29:33,405]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:29:37,139]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:29:38,839]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:29:40,456]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:29:44,822]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:29:46,056]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:29:48,196]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:29:54,284]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:29:56,659]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:30:00,829]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:30:01,373]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:30:06,992]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:30:07,347]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.33 | sMAPE for Validation Set is: 24.72% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 50.43 | sMAPE for Test Set is: 32.03% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:30:12,321]\u001b[0m Trial 685 finished with value: 20.3267988961147 and parameters: {'n_hidden': 3, 'learning_rate': 0.006152105259499196, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007346726987198684, 'dropout_rate_Layer_2': 0.11360699585185119, 'dropout_rate_Layer_3': 0.09097558279742932, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.009116649856257158, 'l1_Layer_2': 0.0008202965651712162, 'l1_Layer_3': 4.337689671472087e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 205, 'n_units_Layer_3': 170}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:30:16,505]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:30:17,272]\u001b[0m Trial 687 finished with value: 20.65310425198056 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019949881338297546, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05239317928153232, 'dropout_rate_Layer_2': 0.14484022194384485, 'dropout_rate_Layer_3': 0.07957715265973399, 'dropout_rate_Layer_4': 0.2748228876022027, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.005703752422897603, 'l1_Layer_2': 3.485597307547381e-05, 'l1_Layer_3': 4.2154495877635025e-05, 'l1_Layer_4': 4.315107980601296e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 125, 'n_units_Layer_3': 265, 'n_units_Layer_4': 55}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.65 | sMAPE for Validation Set is: 25.66% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 50.11 | sMAPE for Test Set is: 32.28% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:30:20,084]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:30:24,718]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:30:25,434]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:30:25,630]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:30:33,460]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:30:34,179]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:30:34,412]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:30:36,849]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:30:37,952]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:30:44,247]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:30:46,837]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:30:47,098]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:30:47,777]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:30:50,863]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:30:54,355]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:30:56,522]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:30:57,028]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:31:05,660]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:31:06,711]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:31:07,117]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:31:11,574]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:31:11,647]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:31:13,877]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:31:20,459]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:31:21,004]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:31:21,844]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:31:27,629]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:31:28,170]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:31:33,998]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:31:38,036]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:31:41,472]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:31:45,654]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:31:49,022]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:31:49,664]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:31:50,190]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.50 | sMAPE for Validation Set is: 25.29% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 50.91 | sMAPE for Test Set is: 32.44% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:31:54,224]\u001b[0m Trial 722 finished with value: 20.498030911015842 and parameters: {'n_hidden': 3, 'learning_rate': 0.003397397155121296, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2823464838590533, 'dropout_rate_Layer_2': 0.06552900420657547, 'dropout_rate_Layer_3': 0.3913921380767588, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0016324446845236778, 'l1_Layer_2': 0.002756345695413561, 'l1_Layer_3': 0.00026410007289244525, 'n_units_Layer_1': 150, 'n_units_Layer_2': 235, 'n_units_Layer_3': 160}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:32:01,604]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:32:04,967]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:32:05,832]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:32:06,046]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:32:08,258]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:32:09,700]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:32:18,374]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:32:22,216]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:32:22,364]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:32:22,974]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:32:23,495]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:32:31,417]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:32:35,056]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:32:35,974]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:32:41,254]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:32:44,027]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:32:51,050]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:32:51,598]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:32:51,818]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:32:52,111]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:33:00,720]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:33:01,877]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:33:07,135]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:33:10,320]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:33:13,604]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:33:14,034]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:33:18,978]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:33:22,166]\u001b[0m Trial 750 finished with value: 20.9475205855707 and parameters: {'n_hidden': 4, 'learning_rate': 0.0046635412233911, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.042500379817756805, 'dropout_rate_Layer_2': 0.1507400672849096, 'dropout_rate_Layer_3': 0.10507434954841274, 'dropout_rate_Layer_4': 0.3082534351637997, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.001701388969900826, 'l1_Layer_2': 3.512418136981528e-05, 'l1_Layer_3': 7.504354107270443e-05, 'l1_Layer_4': 3.383785648523037e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 145, 'n_units_Layer_3': 150, 'n_units_Layer_4': 55}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.95 | sMAPE for Validation Set is: 25.78% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 51.00 | sMAPE for Test Set is: 32.74% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:33:22,990]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:33:25,767]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:33:28,298]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:33:28,873]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:33:31,669]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:33:36,061]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:33:38,305]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:33:41,151]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:33:43,762]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:33:44,672]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:33:52,012]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:33:52,356]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:33:52,740]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:33:52,899]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:34:02,942]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:34:04,771]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:34:11,128]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:34:15,245]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:34:19,308]\u001b[0m Trial 774 finished with value: 20.682088685512987 and parameters: {'n_hidden': 3, 'learning_rate': 0.0051757610517434265, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27584740229797905, 'dropout_rate_Layer_2': 0.049810376877965745, 'dropout_rate_Layer_3': 0.32916174216922595, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018871605431200371, 'l1_Layer_2': 0.006912917682617497, 'l1_Layer_3': 1.073234996854804e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 200, 'n_units_Layer_3': 185}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.68 | sMAPE for Validation Set is: 25.65% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 49.73 | sMAPE for Test Set is: 31.81% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:34:20,432]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:34:22,728]\u001b[0m Trial 772 finished with value: 20.451304845636784 and parameters: {'n_hidden': 3, 'learning_rate': 0.005037936647595163, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17357157076328134, 'dropout_rate_Layer_2': 0.054866229954435984, 'dropout_rate_Layer_3': 0.3597502820365759, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.979763275431415e-05, 'l1_Layer_2': 0.01670335882001945, 'l1_Layer_3': 0.0010943004683192513, 'n_units_Layer_1': 185, 'n_units_Layer_2': 200, 'n_units_Layer_3': 185}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.45 | sMAPE for Validation Set is: 25.57% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 51.26 | sMAPE for Test Set is: 32.25% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:34:27,851]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:34:31,506]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:34:34,393]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:34:35,596]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:34:39,477]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:34:40,368]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:34:41,187]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:34:47,160]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:34:48,044]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:34:48,436]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:34:49,250]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:34:56,294]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:34:58,075]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:34:59,041]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:34:59,327]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:35:08,850]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:35:12,403]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:35:13,631]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:35:13,722]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:35:19,901]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:35:21,747]\u001b[0m Trial 793 finished with value: 20.806009426412192 and parameters: {'n_hidden': 3, 'learning_rate': 0.0060363889968851284, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2911752236345987, 'dropout_rate_Layer_2': 0.07260634966489841, 'dropout_rate_Layer_3': 0.3595027234263847, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.6246387764906843e-05, 'l1_Layer_2': 0.02239661601483064, 'l1_Layer_3': 1.3034586794180318e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 205, 'n_units_Layer_3': 175}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.81 | sMAPE for Validation Set is: 25.95% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 51.22 | sMAPE for Test Set is: 32.88% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:35:22,193]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:35:24,637]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:35:24,803]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:35:33,255]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:35:34,479]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:35:35,106]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:35:43,165]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:35:44,755]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:35:48,628]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:35:51,357]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:35:54,122]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:35:57,478]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:35:57,779]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:35:58,509]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:36:07,135]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:36:07,856]\u001b[0m Trial 808 finished with value: 21.002245764661325 and parameters: {'n_hidden': 4, 'learning_rate': 0.0051998441505326076, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015719002178852335, 'dropout_rate_Layer_2': 0.14162819594649062, 'dropout_rate_Layer_3': 0.13866824923674237, 'dropout_rate_Layer_4': 0.25774691201715616, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.012304719601907394, 'l1_Layer_2': 1.772268982420709e-05, 'l1_Layer_3': 0.000378465298582698, 'l1_Layer_4': 8.077904354286968e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 135, 'n_units_Layer_3': 220, 'n_units_Layer_4': 155}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.00 | sMAPE for Validation Set is: 25.70% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 53.56 | sMAPE for Test Set is: 33.44% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:36:10,477]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:36:14,357]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:36:17,037]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:36:18,917]\u001b[0m Trial 814 finished with value: 20.95218336152773 and parameters: {'n_hidden': 3, 'learning_rate': 0.007326135262598809, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009017201583378437, 'dropout_rate_Layer_2': 0.12944934629902208, 'dropout_rate_Layer_3': 0.023091183006414377, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005809178720490471, 'l1_Layer_2': 0.0008684912581521279, 'l1_Layer_3': 2.550321383938504e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 205, 'n_units_Layer_3': 150}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.95 | sMAPE for Validation Set is: 26.26% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 51.35 | sMAPE for Test Set is: 32.62% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:36:20,955]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:36:22,051]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:36:30,683]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:36:31,495]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:36:37,405]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:36:41,064]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:36:44,641]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:36:48,566]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:36:52,260]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:36:56,287]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.79 | sMAPE for Validation Set is: 25.47% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 53.41 | sMAPE for Test Set is: 33.15% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:36:58,747]\u001b[0m Trial 825 finished with value: 20.78643491444641 and parameters: {'n_hidden': 3, 'learning_rate': 0.0062185431585226525, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04785071766956206, 'dropout_rate_Layer_2': 0.12067597902862014, 'dropout_rate_Layer_3': 0.07295440724522764, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00899573323554996, 'l1_Layer_2': 0.0005088846302089965, 'l1_Layer_3': 2.0179892740312994e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 235, 'n_units_Layer_3': 175}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:37:01,701]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:37:05,814]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:37:08,879]\u001b[0m Trial 821 finished with value: 20.705077162987696 and parameters: {'n_hidden': 3, 'learning_rate': 0.007110866512273904, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008436741174452695, 'dropout_rate_Layer_2': 0.2413380539189033, 'dropout_rate_Layer_3': 0.1356780020847444, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0052956113809152, 'l1_Layer_2': 1.2567806668122311e-05, 'l1_Layer_3': 0.000689379436042476, 'n_units_Layer_1': 110, 'n_units_Layer_2': 110, 'n_units_Layer_3': 240}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.71 | sMAPE for Validation Set is: 25.48% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 53.14 | sMAPE for Test Set is: 33.15% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:37:09,819]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:37:15,756]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:37:19,400]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:37:23,085]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:37:23,976]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:37:27,835]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:37:31,334]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:37:32,469]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:37:37,181]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:37:37,934]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:37:42,741]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:37:43,363]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:37:48,593]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:37:49,478]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:37:54,482]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:37:57,975]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:37:58,800]\u001b[0m Trial 833 finished with value: 20.85494144120918 and parameters: {'n_hidden': 3, 'learning_rate': 0.004167977619101411, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015075093359327194, 'dropout_rate_Layer_2': 0.241637311467709, 'dropout_rate_Layer_3': 0.13727196416865997, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005385952059930997, 'l1_Layer_2': 2.233063084674496e-05, 'l1_Layer_3': 0.0004719920568292485, 'n_units_Layer_1': 100, 'n_units_Layer_2': 110, 'n_units_Layer_3': 240}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.85 | sMAPE for Validation Set is: 25.61% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 52.23 | sMAPE for Test Set is: 32.84% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:37:59,796]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:38:06,523]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:38:06,948]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:38:07,571]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:38:14,511]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:38:15,188]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:38:16,051]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:38:18,171]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:38:23,680]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:38:28,565]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:38:28,635]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:38:30,394]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:38:30,424]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:38:38,870]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:38:40,584]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:38:45,153]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:38:45,421]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:38:50,216]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:38:51,598]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:38:55,213]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:38:58,839]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:39:02,375]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:39:04,756]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:39:08,160]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:39:08,463]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:39:15,099]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:39:19,296]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:39:19,919]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:39:26,952]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:39:27,976]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:39:34,067]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:39:40,251]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:39:44,176]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:39:49,049]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:39:51,572]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:39:55,133]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:39:56,713]\u001b[0m Trial 874 finished with value: 20.845999894297545 and parameters: {'n_hidden': 3, 'learning_rate': 0.004239528733009468, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03863718655424214, 'dropout_rate_Layer_2': 0.2479455209339159, 'dropout_rate_Layer_3': 0.15872649846684317, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006397867966678946, 'l1_Layer_2': 1.005332455353749e-05, 'l1_Layer_3': 0.0006536637087679071, 'n_units_Layer_1': 105, 'n_units_Layer_2': 100, 'n_units_Layer_3': 250}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.85 | sMAPE for Validation Set is: 25.83% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 51.94 | sMAPE for Test Set is: 32.62% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:39:56,785]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:39:59,527]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:40:05,114]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:40:08,717]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:40:12,010]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:40:15,982]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:40:18,435]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:40:18,960]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:40:20,012]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:40:26,924]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:40:31,591]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:40:36,921]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:40:40,742]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:40:42,645]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:40:46,997]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:40:48,616]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:40:52,491]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:40:54,331]\u001b[0m Trial 898 finished with value: 20.654040585683045 and parameters: {'n_hidden': 3, 'learning_rate': 0.006491133588652787, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29247643634046805, 'dropout_rate_Layer_2': 0.07241130115833502, 'dropout_rate_Layer_3': 0.3601968229189484, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002042420047689358, 'l1_Layer_2': 0.008383558940308067, 'l1_Layer_3': 0.0011087339349287245, 'n_units_Layer_1': 85, 'n_units_Layer_2': 155, 'n_units_Layer_3': 165}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.65 | sMAPE for Validation Set is: 25.53% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 52.69 | sMAPE for Test Set is: 32.97% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:40:59,547]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:41:00,670]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:41:06,098]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:41:06,331]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:41:06,528]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:41:15,785]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:41:16,408]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:41:16,608]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:41:27,078]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:41:27,239]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:41:34,125]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:41:34,458]\u001b[0m Trial 877 finished with value: 20.965900711345054 and parameters: {'n_hidden': 3, 'learning_rate': 0.00241144920935367, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02418266387012082, 'dropout_rate_Layer_2': 0.2435845469164009, 'dropout_rate_Layer_3': 0.16023107573383355, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002812742755867097, 'l1_Layer_2': 3.9380215337702516e-05, 'l1_Layer_3': 0.000647856649260671, 'n_units_Layer_1': 210, 'n_units_Layer_2': 120, 'n_units_Layer_3': 230}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.97 | sMAPE for Validation Set is: 25.84% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 54.41 | sMAPE for Test Set is: 33.27% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:41:34,733]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:41:34,925]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:41:46,523]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:41:47,274]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:41:52,823]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:41:57,409]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:42:02,060]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:42:06,604]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:42:11,357]\u001b[0m Trial 919 finished with value: 20.681216587637945 and parameters: {'n_hidden': 3, 'learning_rate': 0.005975876581029943, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3106028698086352, 'dropout_rate_Layer_2': 0.06600853689182891, 'dropout_rate_Layer_3': 0.3836810873860841, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001729747736504089, 'l1_Layer_2': 0.008569232757290502, 'l1_Layer_3': 0.0012854458092712753, 'n_units_Layer_1': 80, 'n_units_Layer_2': 225, 'n_units_Layer_3': 175}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.68 | sMAPE for Validation Set is: 25.70% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 51.26 | sMAPE for Test Set is: 32.49% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:42:15,639]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:42:19,150]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:42:22,782]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:42:26,657]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:42:27,389]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:42:33,409]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:42:35,778]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:42:41,995]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:42:46,573]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:42:50,570]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:42:54,811]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:42:57,687]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:43:02,327]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:43:03,275]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:43:10,025]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:43:10,424]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:43:10,699]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:43:19,278]\u001b[0m Trial 939 finished with value: 20.53047496660462 and parameters: {'n_hidden': 3, 'learning_rate': 0.006021726262563255, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.019903233239177545, 'dropout_rate_Layer_2': 0.15091103883150764, 'dropout_rate_Layer_3': 0.017086584690372834, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.013030167646235415, 'l1_Layer_2': 0.0007423675559103588, 'l1_Layer_3': 2.2746944363476526e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 220, 'n_units_Layer_3': 150}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.53 | sMAPE for Validation Set is: 25.29% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 50.37 | sMAPE for Test Set is: 31.94% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:43:20,628]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:43:24,425]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:43:26,832]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:43:28,571]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:43:29,418]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:43:29,996]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:43:35,695]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:43:42,478]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:43:46,528]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:43:49,025]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:43:51,399]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:43:53,665]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:43:55,209]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:43:55,715]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:43:57,457]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:44:07,665]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:44:08,065]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:44:09,312]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:44:12,554]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:44:17,536]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:44:21,181]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:44:24,998]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:44:27,327]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:44:35,076]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:44:38,442]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:44:41,640]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:44:43,463]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:44:47,950]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:44:49,407]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:44:57,031]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:44:57,802]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:44:58,675]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:44:59,455]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:45:05,111]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:45:08,757]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:45:10,854]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:45:14,690]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:45:21,915]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:45:25,598]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:45:26,030]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:45:33,095]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:45:37,114]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:45:37,306]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:45:43,356]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:45:45,555]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:45:45,979]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:45:49,037]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:45:55,820]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:45:56,726]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:46:01,719]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:46:06,542]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:46:09,264]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:46:10,222]\u001b[0m Trial 984 finished with value: 20.83850549369329 and parameters: {'n_hidden': 3, 'learning_rate': 0.002390647455675998, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2877509697215914, 'dropout_rate_Layer_2': 0.1894337341326291, 'dropout_rate_Layer_3': 0.13428694181709494, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004532595637655854, 'l1_Layer_2': 1.2943086038726832e-05, 'l1_Layer_3': 0.00048027983297461654, 'n_units_Layer_1': 105, 'n_units_Layer_2': 100, 'n_units_Layer_3': 235}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.84 | sMAPE for Validation Set is: 25.56% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 52.73 | sMAPE for Test Set is: 32.74% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:46:11,302]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:46:19,118]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:46:19,888]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:46:21,551]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:46:29,904]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:46:33,273]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:46:37,934]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:46:42,900]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:46:49,201]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:46:52,944]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:46:57,257]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:47:01,531]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:47:05,786]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:47:05,986]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:47:13,347]\u001b[0m Trial 1000 finished with value: 20.635634590482805 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015975813565880866, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25221807774155747, 'dropout_rate_Layer_2': 0.180328610336581, 'dropout_rate_Layer_3': 0.11618567861076873, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004651141817074767, 'l1_Layer_2': 1.6590852454891346e-05, 'l1_Layer_3': 0.0007784251815936239, 'n_units_Layer_1': 120, 'n_units_Layer_2': 120, 'n_units_Layer_3': 220}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.64 | sMAPE for Validation Set is: 25.35% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 52.64 | sMAPE for Test Set is: 32.87% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:47:13,692]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:47:21,049]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:47:21,663]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:47:25,657]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:47:28,274]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:47:31,943]\u001b[0m Trial 1010 finished with value: 20.844429834190915 and parameters: {'n_hidden': 3, 'learning_rate': 0.002900998896416758, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31860870623413773, 'dropout_rate_Layer_2': 0.09206796401951405, 'dropout_rate_Layer_3': 0.37637953928447454, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.493463523436011e-05, 'l1_Layer_2': 0.002584745221995019, 'l1_Layer_3': 0.0005514937875623986, 'n_units_Layer_1': 195, 'n_units_Layer_2': 175, 'n_units_Layer_3': 185}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.84 | sMAPE for Validation Set is: 25.67% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 52.30 | sMAPE for Test Set is: 32.79% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:47:34,452]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:47:38,161]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:47:40,844]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:47:41,474]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:47:41,690]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:47:52,382]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:47:54,775]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:47:55,622]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:47:55,841]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:47:57,091]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:48:05,123]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:48:07,815]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:48:08,735]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:48:09,002]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:48:16,266]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:48:16,496]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:48:20,730]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:48:21,753]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:48:30,093]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:48:33,704]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:48:34,198]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:48:34,935]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:48:46,896]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:48:47,185]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:48:47,248]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:48:52,352]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:48:56,616]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:48:58,455]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:48:59,042]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:49:08,432]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:49:09,042]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:49:14,581]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:49:22,486]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:49:26,801]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:49:27,674]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:49:35,102]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:49:35,310]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:49:41,537]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:49:45,516]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:49:49,071]\u001b[0m Trial 1048 finished with value: 21.133943201345662 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016268320944413815, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03347319603366543, 'dropout_rate_Layer_2': 0.18189761474851646, 'dropout_rate_Layer_3': 0.08511109850288688, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004018853488287357, 'l1_Layer_2': 1.3443976968498617e-05, 'l1_Layer_3': 0.00043870246494380065, 'n_units_Layer_1': 130, 'n_units_Layer_2': 130, 'n_units_Layer_3': 140}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.13 | sMAPE for Validation Set is: 26.34% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 51.99 | sMAPE for Test Set is: 32.81% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:49:49,497]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:49:51,142]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:49:56,939]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:50:00,523]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:50:04,845]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:50:06,570]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:50:09,434]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:50:11,478]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:50:15,400]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:50:18,731]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:50:22,435]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:50:24,539]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:50:30,156]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:50:34,553]\u001b[0m Trial 1053 finished with value: 21.24654208230129 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020173236397167515, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2557122590931701, 'dropout_rate_Layer_2': 0.1836519639996734, 'dropout_rate_Layer_3': 0.09067039599155016, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008513226412653094, 'l1_Layer_2': 1.3631703727660813e-05, 'l1_Layer_3': 0.0004626773463827523, 'n_units_Layer_1': 130, 'n_units_Layer_2': 130, 'n_units_Layer_3': 235}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.25 | sMAPE for Validation Set is: 25.92% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 53.38 | sMAPE for Test Set is: 32.80% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:50:38,459]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:50:39,457]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:50:44,150]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:50:48,769]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:50:54,086]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:50:58,146]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:51:04,206]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:51:09,108]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:51:09,484]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:51:15,597]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:51:20,097]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:51:23,886]\u001b[0m Trial 1073 finished with value: 20.99568375560824 and parameters: {'n_hidden': 3, 'learning_rate': 0.002966072359444946, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17635611773784665, 'dropout_rate_Layer_2': 0.17172878502270156, 'dropout_rate_Layer_3': 0.1276291480861031, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0025344447949238666, 'l1_Layer_2': 5.9174869235349267e-05, 'l1_Layer_3': 0.0006878046641854542, 'n_units_Layer_1': 110, 'n_units_Layer_2': 105, 'n_units_Layer_3': 240}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.00 | sMAPE for Validation Set is: 25.33% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 51.28 | sMAPE for Test Set is: 32.28% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:51:27,971]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:51:35,058]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:51:40,497]\u001b[0m Trial 1071 finished with value: 21.178965245829115 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028453156045334044, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2680632206581299, 'dropout_rate_Layer_2': 0.23044456432613153, 'dropout_rate_Layer_3': 0.09365705468849916, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0025445562080564535, 'l1_Layer_2': 3.306632247275376e-05, 'l1_Layer_3': 0.0005734599921489899, 'n_units_Layer_1': 200, 'n_units_Layer_2': 105, 'n_units_Layer_3': 235}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.18 | sMAPE for Validation Set is: 26.41% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 54.07 | sMAPE for Test Set is: 33.17% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:51:52,571]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:51:52,805]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:51:53,455]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:51:54,794]\u001b[0m Trial 1086 finished with value: 20.494198706272147 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032324288036651326, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.021676845182353438, 'dropout_rate_Layer_2': 0.2291591147793747, 'dropout_rate_Layer_3': 0.18132965881247692, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0031765223924663183, 'l1_Layer_2': 0.0075673727040173385, 'l1_Layer_3': 0.0003118442838689062, 'n_units_Layer_1': 115, 'n_units_Layer_2': 105, 'n_units_Layer_3': 225}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.49 | sMAPE for Validation Set is: 25.15% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 54.40 | sMAPE for Test Set is: 33.28% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:52:03,820]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:52:06,550]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:52:11,304]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:52:13,875]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:52:15,050]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:52:16,515]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:52:19,307]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:52:23,327]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:52:23,664]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:52:26,856]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:52:28,715]\u001b[0m Trial 1093 finished with value: 20.419742875836192 and parameters: {'n_hidden': 3, 'learning_rate': 0.007008508652408703, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 2.545931144506356e-05, 'dropout_rate_Layer_2': 0.1652791716757166, 'dropout_rate_Layer_3': 0.09223885166263547, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.010154280621097736, 'l1_Layer_2': 0.0007131564223312773, 'l1_Layer_3': 1.2056934523661507e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 230, 'n_units_Layer_3': 140}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.42 | sMAPE for Validation Set is: 24.97% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 50.43 | sMAPE for Test Set is: 31.95% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:52:35,293]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:52:39,483]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:52:39,886]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:52:43,578]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:52:44,519]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:52:50,319]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:52:51,128]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:53:01,948]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:53:05,892]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:53:09,027]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:53:10,629]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:53:12,472]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:53:13,335]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:53:19,234]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:53:23,391]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:53:23,956]\u001b[0m Trial 1109 finished with value: 20.724030222981558 and parameters: {'n_hidden': 3, 'learning_rate': 0.007821291534319784, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.005690763164151492, 'dropout_rate_Layer_2': 0.1731963336110016, 'dropout_rate_Layer_3': 0.10173374572319789, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.025090363198937565, 'l1_Layer_2': 0.00045134004656892607, 'l1_Layer_3': 3.662640659245716e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 270, 'n_units_Layer_3': 190}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.72 | sMAPE for Validation Set is: 25.55% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 52.25 | sMAPE for Test Set is: 32.70% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:53:30,252]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:53:36,594]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:53:41,595]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:53:42,753]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:53:46,698]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:53:48,925]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:53:49,368]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:53:56,248]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:53:56,621]\u001b[0m Trial 1119 finished with value: 20.766519271999986 and parameters: {'n_hidden': 3, 'learning_rate': 0.0043187922424573815, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01548965418468702, 'dropout_rate_Layer_2': 0.20844970256515855, 'dropout_rate_Layer_3': 0.10892237709421851, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003352875323269825, 'l1_Layer_2': 0.0003125846829816743, 'l1_Layer_3': 0.00023929808164727687, 'n_units_Layer_1': 105, 'n_units_Layer_2': 100, 'n_units_Layer_3': 230}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.77 | sMAPE for Validation Set is: 25.75% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 52.21 | sMAPE for Test Set is: 32.46% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:53:57,435]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:54:01,740]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:54:03,960]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:54:04,660]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:54:12,343]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:54:15,130]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:54:15,434]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:54:18,716]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:54:18,988]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:54:23,420]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:54:28,047]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:54:33,218]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:54:33,594]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:54:35,824]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:54:39,836]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:54:43,476]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:54:48,759]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:54:49,254]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:54:51,016]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:54:58,089]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:55:01,439]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:55:02,794]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:55:06,396]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:55:12,116]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:55:12,463]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:55:13,128]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:55:15,591]\u001b[0m Trial 1139 finished with value: 20.38889561678583 and parameters: {'n_hidden': 3, 'learning_rate': 0.003866131207782057, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04016760898124476, 'dropout_rate_Layer_2': 0.22422953436133986, 'dropout_rate_Layer_3': 0.1929290719305118, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0016045069281322138, 'l1_Layer_2': 0.0020069418631590966, 'l1_Layer_3': 0.00021003837803698936, 'n_units_Layer_1': 115, 'n_units_Layer_2': 110, 'n_units_Layer_3': 220}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.39 | sMAPE for Validation Set is: 25.22% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 50.32 | sMAPE for Test Set is: 31.62% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:55:21,001]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:55:21,292]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:55:22,187]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:55:30,638]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:55:33,271]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:55:33,656]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:55:34,428]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:55:44,244]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:55:44,672]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:55:46,025]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:55:54,507]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:55:54,830]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:55:55,611]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:56:02,239]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:56:04,377]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:56:05,892]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:56:09,938]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:56:11,742]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:56:14,601]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:56:18,952]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:56:22,860]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:56:23,724]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:56:23,953]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:56:30,281]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:56:33,674]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:56:34,373]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:56:38,066]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:56:46,213]\u001b[0m Trial 1162 finished with value: 20.359057076681037 and parameters: {'n_hidden': 3, 'learning_rate': 0.0038463477640788427, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16430811294188827, 'dropout_rate_Layer_2': 0.19343165580323152, 'dropout_rate_Layer_3': 0.20609524494471765, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001904057851239438, 'l1_Layer_2': 0.012388401380263255, 'l1_Layer_3': 0.0002047175549559107, 'n_units_Layer_1': 105, 'n_units_Layer_2': 95, 'n_units_Layer_3': 220}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.36 | sMAPE for Validation Set is: 25.14% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 49.97 | sMAPE for Test Set is: 31.87% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 12:56:46,558]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:56:46,883]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:56:54,988]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:56:57,049]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:56:57,407]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:57:00,580]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:57:01,708]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:57:08,441]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:57:10,955]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:57:14,858]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:57:18,960]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:57:19,302]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:57:20,545]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:57:21,096]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:57:25,929]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:57:28,154]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:57:30,476]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:57:33,081]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:57:35,660]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:57:38,502]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:57:40,967]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:57:43,171]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:57:44,332]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:57:54,059]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:57:54,251]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:57:55,058]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:58:01,835]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:58:05,413]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:58:06,829]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:58:08,312]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:58:15,572]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:58:19,360]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:58:20,429]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:58:20,989]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:58:21,206]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:58:24,826]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:58:35,075]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:58:35,723]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:58:36,274]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:58:44,766]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:58:45,564]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:58:50,039]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:58:53,135]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:58:53,236]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:58:53,918]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:58:57,194]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:59:04,392]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:59:07,313]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:59:07,406]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:59:07,957]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:59:11,770]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:59:19,706]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:59:19,864]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:59:22,141]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:59:23,611]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:59:31,739]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:59:31,879]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:59:33,102]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:59:40,636]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:59:45,514]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:59:45,644]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:59:51,904]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:59:52,009]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:59:55,835]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 12:59:59,353]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:00:00,458]\u001b[0m Trial 1238 finished with value: 20.735912881190554 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033004016457803117, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20797010209304154, 'dropout_rate_Layer_2': 0.22095773284703785, 'dropout_rate_Layer_3': 0.19147210323694894, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004761119949054051, 'l1_Layer_2': 0.00756006813916336, 'l1_Layer_3': 0.0002869944427127219, 'n_units_Layer_1': 110, 'n_units_Layer_2': 95, 'n_units_Layer_3': 225}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.74 | sMAPE for Validation Set is: 25.55% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 50.87 | sMAPE for Test Set is: 32.11% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 13:00:01,203]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:00:03,203]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:00:04,013]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:00:13,193]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:00:13,289]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:00:13,541]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:00:22,906]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:00:23,265]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:00:23,442]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:00:23,626]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:00:32,388]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:00:33,652]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:00:38,558]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:00:40,683]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:00:43,725]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:00:47,975]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:00:52,236]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:00:56,215]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:00:59,362]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:01:03,260]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:01:08,905]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:01:12,862]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:01:15,784]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:01:18,270]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:01:22,054]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:01:28,762]\u001b[0m Trial 1259 finished with value: 20.575848888702676 and parameters: {'n_hidden': 3, 'learning_rate': 0.003100561684120421, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.018862493640564623, 'dropout_rate_Layer_2': 0.20636985557763698, 'dropout_rate_Layer_3': 0.18513708054435574, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0036684057891777323, 'l1_Layer_2': 0.010166942002930219, 'l1_Layer_3': 0.0002299615603390548, 'n_units_Layer_1': 105, 'n_units_Layer_2': 95, 'n_units_Layer_3': 240}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.58 | sMAPE for Validation Set is: 25.85% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 51.62 | sMAPE for Test Set is: 32.47% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 13:01:32,617]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:01:32,797]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:01:39,432]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:01:41,927]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:01:42,889]\u001b[0m Trial 1261 finished with value: 20.879076250070078 and parameters: {'n_hidden': 3, 'learning_rate': 0.003067129686689379, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2115630088019848, 'dropout_rate_Layer_2': 0.20535301723958788, 'dropout_rate_Layer_3': 0.17837957958646042, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0037315486544088512, 'l1_Layer_2': 0.010021284819737655, 'l1_Layer_3': 0.0004050693444213745, 'n_units_Layer_1': 105, 'n_units_Layer_2': 100, 'n_units_Layer_3': 240}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.88 | sMAPE for Validation Set is: 25.93% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 53.64 | sMAPE for Test Set is: 33.22% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 13:01:52,831]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:01:56,538]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:01:59,510]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:02:03,676]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:02:07,828]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:02:08,273]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:02:08,632]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:02:13,558]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:02:18,034]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:02:19,439]\u001b[0m Trial 1275 finished with value: 20.69331957792215 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021875601753566835, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21570328359240182, 'dropout_rate_Layer_2': 0.23300195521483744, 'dropout_rate_Layer_3': 0.18026929787032867, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005275668559178687, 'l1_Layer_2': 0.007186011296581665, 'l1_Layer_3': 0.00021685848497323453, 'n_units_Layer_1': 115, 'n_units_Layer_2': 100, 'n_units_Layer_3': 235}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:02:19,555]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.69 | sMAPE for Validation Set is: 25.51% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 51.14 | sMAPE for Test Set is: 32.53% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 13:02:27,618]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:02:33,525]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:02:34,110]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:02:36,495]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:02:42,371]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:02:44,559]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:02:47,700]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:02:50,903]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:02:51,012]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:02:52,238]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:02:59,764]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:02:59,839]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:03:01,208]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:03:09,222]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:03:09,721]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:03:12,845]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:03:13,673]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:03:16,790]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:03:22,792]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:03:26,121]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:03:26,747]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:03:32,320]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:03:35,379]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:03:36,310]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:03:39,620]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:03:44,580]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:03:44,772]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:03:50,106]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:03:53,097]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:03:56,966]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:04:00,959]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:04:04,740]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:04:05,888]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:04:05,940]\u001b[0m Trial 1317 finished with value: 20.932396229680915 and parameters: {'n_hidden': 3, 'learning_rate': 0.008645969352701994, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0070934089205365765, 'dropout_rate_Layer_2': 0.12067047309553103, 'dropout_rate_Layer_3': 0.26654087587478675, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00857953631046793, 'l1_Layer_2': 0.0006885951803927752, 'l1_Layer_3': 4.543833618580587e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 200, 'n_units_Layer_3': 160}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.93 | sMAPE for Validation Set is: 25.92% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 52.76 | sMAPE for Test Set is: 33.01% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 13:04:14,018]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:04:15,265]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:04:17,037]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:04:23,247]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:04:26,922]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:04:27,367]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:04:31,750]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:04:33,916]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:04:36,874]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:04:40,622]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:04:45,891]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:04:51,817]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:04:52,452]\u001b[0m Trial 1319 finished with value: 20.76337260121296 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034652980522610058, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1903720831204604, 'dropout_rate_Layer_2': 0.2352186284364521, 'dropout_rate_Layer_3': 0.1844242598254671, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002333057875648711, 'l1_Layer_2': 0.01290245306205241, 'l1_Layer_3': 0.0002862411516140552, 'n_units_Layer_1': 105, 'n_units_Layer_2': 95, 'n_units_Layer_3': 245}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.76 | sMAPE for Validation Set is: 25.50% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 50.01 | sMAPE for Test Set is: 32.11% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 13:04:52,707]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:04:53,621]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:05:02,469]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:05:04,769]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:05:06,246]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:05:07,505]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:05:07,886]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:05:16,228]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:05:18,659]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:05:22,514]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:05:26,628]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:05:30,055]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:05:30,925]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:05:31,625]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:05:36,350]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:05:40,501]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:05:43,965]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:05:45,435]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:05:45,473]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:05:49,067]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:05:55,919]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:05:58,546]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:05:59,180]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:06:01,937]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:06:10,433]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:06:12,432]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:06:16,899]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:06:17,609]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:06:22,484]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:06:25,675]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:06:32,912]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:06:33,324]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:06:33,431]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:06:41,871]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:06:46,952]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:06:47,296]\u001b[0m Trial 1370 finished with value: 20.682350121035036 and parameters: {'n_hidden': 3, 'learning_rate': 0.00968686254496669, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 2.5952405442994375e-05, 'dropout_rate_Layer_2': 0.13345133723609381, 'dropout_rate_Layer_3': 0.01640092927154741, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.007934036070606667, 'l1_Layer_2': 0.0010242281297872073, 'l1_Layer_3': 1.8855919389710954e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 225, 'n_units_Layer_3': 155}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.68 | sMAPE for Validation Set is: 25.54% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 53.20 | sMAPE for Test Set is: 33.00% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 13:06:49,028]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:06:52,239]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:06:55,391]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:07:00,931]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:07:03,311]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:07:04,972]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:07:07,621]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:07:09,851]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:07:11,383]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:07:16,604]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:07:18,370]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:07:24,752]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:07:28,527]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:07:30,845]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:07:31,803]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:07:33,803]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:07:40,388]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:07:43,562]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:07:44,374]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:07:45,180]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:07:49,902]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:07:51,178]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:07:52,501]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:08:00,946]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:08:04,241]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:08:07,495]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:08:09,898]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:08:11,159]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:08:17,448]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:08:19,153]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:08:22,572]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:08:25,500]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:08:27,013]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:08:30,975]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:08:34,677]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:08:35,484]\u001b[0m Trial 1396 finished with value: 20.59397257175741 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015820559552865308, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.000815012284560726, 'dropout_rate_Layer_2': 0.1856485166088779, 'dropout_rate_Layer_3': 0.18325391076184736, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001282821756232455, 'l1_Layer_2': 0.0007331263370928575, 'l1_Layer_3': 0.00038843609860230214, 'n_units_Layer_1': 100, 'n_units_Layer_2': 95, 'n_units_Layer_3': 210}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.59 | sMAPE for Validation Set is: 25.61% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 50.41 | sMAPE for Test Set is: 31.66% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 13:08:36,692]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:08:45,809]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:08:47,021]\u001b[0m Trial 1403 finished with value: 20.59092123862307 and parameters: {'n_hidden': 3, 'learning_rate': 0.008174032489404508, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.018033865413296504, 'dropout_rate_Layer_2': 0.14601473511167393, 'dropout_rate_Layer_3': 0.01865448735704433, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.011635917544979715, 'l1_Layer_2': 0.0011219843233263329, 'l1_Layer_3': 1.595942255334554e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 255, 'n_units_Layer_3': 155}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.59 | sMAPE for Validation Set is: 25.27% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 51.60 | sMAPE for Test Set is: 32.21% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 13:08:52,282]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:08:54,957]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:08:59,533]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:09:03,797]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:09:08,324]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:09:08,845]\u001b[0m Trial 1412 finished with value: 20.49560809774106 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028382585736167407, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17313805031375384, 'dropout_rate_Layer_2': 0.18991611701255293, 'dropout_rate_Layer_3': 0.3921310437342069, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001630942995921823, 'l1_Layer_2': 0.0014372304324034683, 'l1_Layer_3': 9.878569461866696e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 200, 'n_units_Layer_3': 160}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.50 | sMAPE for Validation Set is: 25.58% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 50.53 | sMAPE for Test Set is: 32.19% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 13:09:16,015]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:09:17,408]\u001b[0m Trial 1413 finished with value: 20.547487159416885 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015155696507946766, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0007011852749915434, 'dropout_rate_Layer_2': 0.210440165668312, 'dropout_rate_Layer_3': 0.18419329736162413, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009461524868379403, 'l1_Layer_2': 0.0012202950653362966, 'l1_Layer_3': 0.0004719868024618552, 'n_units_Layer_1': 80, 'n_units_Layer_2': 95, 'n_units_Layer_3': 210}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.55 | sMAPE for Validation Set is: 25.23% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 51.15 | sMAPE for Test Set is: 32.01% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 13:09:22,786]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:09:26,024]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:09:29,057]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:09:29,298]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:09:30,670]\u001b[0m Trial 1416 finished with value: 20.553454702761808 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016398506271304816, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0006063329553841375, 'dropout_rate_Layer_2': 0.1854675320663762, 'dropout_rate_Layer_3': 0.1865189006919209, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000992806877837466, 'l1_Layer_2': 0.009957293185260549, 'l1_Layer_3': 0.0005174256125410939, 'n_units_Layer_1': 80, 'n_units_Layer_2': 100, 'n_units_Layer_3': 210}. Best is trial 437 with value: 20.18817663755941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.55 | sMAPE for Validation Set is: 25.50% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 50.53 | sMAPE for Test Set is: 32.28% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 13:09:38,433]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:09:39,121]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:09:39,877]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:09:49,203]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:09:50,086]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:09:52,738]\u001b[0m Trial 1425 finished with value: 20.132926830319718 and parameters: {'n_hidden': 3, 'learning_rate': 0.009645682265707767, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.013717767680142254, 'dropout_rate_Layer_2': 0.14158517540082452, 'dropout_rate_Layer_3': 0.00275776405554325, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.014700532808101697, 'l1_Layer_2': 0.001027790036622435, 'l1_Layer_3': 1.4792747178439498e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 260, 'n_units_Layer_3': 65}. Best is trial 1425 with value: 20.132926830319718.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.13 | sMAPE for Validation Set is: 24.87% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 49.55 | sMAPE for Test Set is: 31.70% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 13:09:55,089]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:09:58,430]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:10:02,018]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:10:09,993]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:10:14,859]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:10:19,212]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:10:23,565]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:10:23,911]\u001b[0m Trial 1435 finished with value: 20.984862241662857 and parameters: {'n_hidden': 3, 'learning_rate': 0.004473887289856688, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15477506965369173, 'dropout_rate_Layer_2': 0.22294502488980178, 'dropout_rate_Layer_3': 0.38081995593384754, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0021663636324250665, 'l1_Layer_2': 0.001836903308917304, 'l1_Layer_3': 1.631770984667287e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 190, 'n_units_Layer_3': 175}. Best is trial 1425 with value: 20.132926830319718.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.98 | sMAPE for Validation Set is: 26.32% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 50.99 | sMAPE for Test Set is: 32.44% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 13:10:27,024]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:10:31,487]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:10:33,638]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:10:39,692]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:10:41,170]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:10:43,017]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:10:44,879]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:10:45,911]\u001b[0m Trial 1433 finished with value: 20.17711256955187 and parameters: {'n_hidden': 3, 'learning_rate': 0.00144374487854089, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.009320809275980889, 'dropout_rate_Layer_2': 0.1864908147960722, 'dropout_rate_Layer_3': 0.19767482999613512, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009706800656855306, 'l1_Layer_2': 0.0018140978876925895, 'l1_Layer_3': 0.0007076794322380545, 'n_units_Layer_1': 85, 'n_units_Layer_2': 95, 'n_units_Layer_3': 205}. Best is trial 1425 with value: 20.132926830319718.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.18 | sMAPE for Validation Set is: 25.32% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 49.56 | sMAPE for Test Set is: 31.83% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 13:10:48,810]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:10:58,782]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:11:02,493]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:11:03,834]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:11:03,835]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:11:09,403]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:11:12,543]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:11:15,613]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:11:16,096]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:11:18,541]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:11:27,931]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:11:27,995]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:11:28,483]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:11:38,457]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:11:38,620]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:11:42,405]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:11:46,465]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:11:52,078]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:11:52,772]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:11:52,889]\u001b[0m Trial 1457 finished with value: 20.261552353640067 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013496462121446592, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.005087610291894424, 'dropout_rate_Layer_2': 0.19842722194098927, 'dropout_rate_Layer_3': 0.18757189930792142, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000998493241187136, 'l1_Layer_2': 0.0006585303389386618, 'l1_Layer_3': 0.0010780226171638342, 'n_units_Layer_1': 75, 'n_units_Layer_2': 100, 'n_units_Layer_3': 215}. Best is trial 1425 with value: 20.132926830319718.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.26 | sMAPE for Validation Set is: 25.44% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 49.50 | sMAPE for Test Set is: 31.62% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 13:11:53,722]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:11:58,338]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:12:06,111]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:12:06,234]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:12:06,890]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:12:15,653]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:12:16,060]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:12:18,085]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:12:19,108]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:12:26,428]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:12:30,813]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:12:32,339]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:12:38,511]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:12:40,995]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:12:42,337]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:12:47,008]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:12:49,458]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:12:56,676]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:13:01,097]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:13:06,296]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:13:10,961]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:13:11,839]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:13:16,957]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:13:21,703]\u001b[0m Trial 1477 finished with value: 20.380736977297058 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012505875762061879, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00687122627469966, 'dropout_rate_Layer_2': 0.1889390947204736, 'dropout_rate_Layer_3': 0.20258355926001534, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007498020024792373, 'l1_Layer_2': 0.002623662137876366, 'l1_Layer_3': 0.001361167069487016, 'n_units_Layer_1': 80, 'n_units_Layer_2': 90, 'n_units_Layer_3': 215}. Best is trial 1425 with value: 20.132926830319718.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.38 | sMAPE for Validation Set is: 25.42% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 50.30 | sMAPE for Test Set is: 31.73% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 13:13:22,425]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:13:29,149]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:13:35,000]\u001b[0m Trial 1485 finished with value: 20.11348515058585 and parameters: {'n_hidden': 3, 'learning_rate': 0.001174459090812308, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00636372260989677, 'dropout_rate_Layer_2': 0.2025880216324538, 'dropout_rate_Layer_3': 0.20258060548303333, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0012369590461803798, 'l1_Layer_2': 0.0007911567141880044, 'l1_Layer_3': 0.0011877363509649385, 'n_units_Layer_1': 80, 'n_units_Layer_2': 90, 'n_units_Layer_3': 215}. Best is trial 1485 with value: 20.11348515058585.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.11 | sMAPE for Validation Set is: 25.03% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 49.66 | sMAPE for Test Set is: 31.34% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 13:13:40,959]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:13:45,591]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:13:48,840]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:13:50,918]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.21 | sMAPE for Validation Set is: 25.36% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 50.47 | sMAPE for Test Set is: 31.76% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 13:14:00,604]\u001b[0m Trial 1494 finished with value: 20.20806524534576 and parameters: {'n_hidden': 3, 'learning_rate': 0.001361389776622741, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008698009657640865, 'dropout_rate_Layer_2': 0.1885538450618219, 'dropout_rate_Layer_3': 0.18495160262157173, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007895610222382714, 'l1_Layer_2': 0.0018474286139781196, 'l1_Layer_3': 0.0020793132091375707, 'n_units_Layer_1': 80, 'n_units_Layer_2': 85, 'n_units_Layer_3': 210}. Best is trial 1485 with value: 20.11348515058585.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 13:14:02,494]\u001b[0m Trial 1496 finished with value: 20.234018960973625 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014204258187763528, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.005356475517590331, 'dropout_rate_Layer_2': 0.18727631924220156, 'dropout_rate_Layer_3': 0.20208895967455714, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007738515096249954, 'l1_Layer_2': 0.0026936242775308867, 'l1_Layer_3': 0.0010223084306684338, 'n_units_Layer_1': 80, 'n_units_Layer_2': 85, 'n_units_Layer_3': 210}. Best is trial 1485 with value: 20.11348515058585.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.23 | sMAPE for Validation Set is: 25.10% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 50.41 | sMAPE for Test Set is: 31.63% | rMAE for Test Set is: 0.55\n",
      "for 2022-01-01, MAE is:29.67 & sMAPE is:35.78% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :29.67 & 35.78% & 0.26\n",
      "for 2022-01-02, MAE is:37.89 & sMAPE is:53.97% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :33.78 & 44.87% & 0.29\n",
      "for 2022-01-03, MAE is:26.72 & sMAPE is:52.13% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :31.43 & 47.29% & 0.32\n",
      "for 2022-01-04, MAE is:42.54 & sMAPE is:34.50% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :34.20 & 44.09% & 0.55\n",
      "for 2022-01-05, MAE is:14.51 & sMAPE is:15.99% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :30.27 & 38.47% & 0.50\n",
      "for 2022-01-06, MAE is:85.73 & sMAPE is:54.71% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :39.51 & 41.18% & 0.54\n",
      "for 2022-01-07, MAE is:24.39 & sMAPE is:15.38% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :37.35 & 37.49% & 0.49\n",
      "for 2022-01-08, MAE is:20.34 & sMAPE is:14.93% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :35.22 & 34.67% & 0.47\n",
      "for 2022-01-09, MAE is:41.23 & sMAPE is:33.32% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :35.89 & 34.52% & 0.48\n",
      "for 2022-01-10, MAE is:83.43 & sMAPE is:36.64% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :40.64 & 34.73% & 0.48\n",
      "for 2022-01-11, MAE is:24.13 & sMAPE is:13.86% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :39.14 & 32.84% & 0.54\n",
      "for 2022-01-12, MAE is:33.12 & sMAPE is:25.20% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :38.64 & 32.20% & 0.57\n",
      "for 2022-01-13, MAE is:70.77 & sMAPE is:132.77% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :41.11 & 39.94% & 0.56\n",
      "for 2022-01-14, MAE is:50.18 & sMAPE is:62.13% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :41.76 & 41.52% & 0.57\n",
      "for 2022-01-15, MAE is:44.48 & sMAPE is:28.81% & rMAE is:1.78 ||| daily mean of MAE & sMAPE & rMAE till now are :41.94 & 40.67% & 0.65\n",
      "for 2022-01-16, MAE is:49.21 & sMAPE is:48.75% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :42.40 & 41.18% & 0.65\n",
      "for 2022-01-17, MAE is:37.72 & sMAPE is:57.75% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :42.12 & 42.15% & 0.62\n",
      "for 2022-01-18, MAE is:41.14 & sMAPE is:26.59% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :42.07 & 41.29% & 0.68\n",
      "for 2022-01-19, MAE is:55.80 & sMAPE is:80.53% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :42.79 & 43.35% & 0.68\n",
      "for 2022-01-20, MAE is:51.61 & sMAPE is:97.29% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :43.23 & 46.05% & 0.69\n",
      "for 2022-01-21, MAE is:39.98 & sMAPE is:35.35% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :43.08 & 45.54% & 0.70\n",
      "for 2022-01-22, MAE is:28.20 & sMAPE is:18.05% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :42.40 & 44.29% & 0.74\n",
      "for 2022-01-23, MAE is:12.37 & sMAPE is:9.46% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :41.09 & 42.78% & 0.72\n",
      "for 2022-01-24, MAE is:9.00 & sMAPE is:6.96% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :39.76 & 41.28% & 0.70\n",
      "for 2022-01-25, MAE is:37.59 & sMAPE is:20.45% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :39.67 & 40.45% & 0.71\n",
      "for 2022-01-26, MAE is:36.51 & sMAPE is:33.27% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :39.55 & 40.17% & 0.70\n",
      "for 2022-01-27, MAE is:28.93 & sMAPE is:72.43% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :39.16 & 41.37% & 0.70\n",
      "for 2022-01-28, MAE is:81.02 & sMAPE is:91.46% & rMAE is:1.99 ||| daily mean of MAE & sMAPE & rMAE till now are :40.65 & 43.16% & 0.75\n",
      "for 2022-01-29, MAE is:40.39 & sMAPE is:52.91% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :40.64 & 43.50% & 0.74\n",
      "for 2022-01-30, MAE is:66.46 & sMAPE is:120.42% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :41.50 & 46.06% & 0.74\n",
      "for 2022-01-31, MAE is:51.69 & sMAPE is:29.20% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :41.83 & 45.52% & 0.74\n",
      "for 2022-02-01, MAE is:33.93 & sMAPE is:24.89% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :41.58 & 44.87% & 0.74\n",
      "for 2022-02-02, MAE is:71.06 & sMAPE is:70.44% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :42.48 & 45.65% & 0.75\n",
      "for 2022-02-03, MAE is:38.26 & sMAPE is:23.38% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :42.35 & 44.99% & 0.74\n",
      "for 2022-02-04, MAE is:29.91 & sMAPE is:21.89% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :42.00 & 44.33% & 0.73\n",
      "for 2022-02-05, MAE is:48.96 & sMAPE is:79.59% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :42.19 & 45.31% & 0.74\n",
      "for 2022-02-06, MAE is:42.48 & sMAPE is:105.00% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :42.20 & 46.92% & 0.76\n",
      "for 2022-02-07, MAE is:38.95 & sMAPE is:57.68% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :42.11 & 47.21% & 0.75\n",
      "for 2022-02-08, MAE is:18.06 & sMAPE is:17.02% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :41.50 & 46.43% & 0.75\n",
      "for 2022-02-09, MAE is:14.20 & sMAPE is:11.43% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :40.81 & 45.56% & 0.73\n",
      "for 2022-02-10, MAE is:16.04 & sMAPE is:13.24% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :40.21 & 44.77% & 0.72\n",
      "for 2022-02-11, MAE is:57.86 & sMAPE is:36.91% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :40.63 & 44.58% & 0.73\n",
      "for 2022-02-12, MAE is:46.67 & sMAPE is:36.30% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :40.77 & 44.39% & 0.73\n",
      "for 2022-02-13, MAE is:19.86 & sMAPE is:26.21% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :40.30 & 43.98% & 0.72\n",
      "for 2022-02-14, MAE is:22.24 & sMAPE is:34.47% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :39.89 & 43.76% & 0.73\n",
      "for 2022-02-15, MAE is:15.47 & sMAPE is:15.74% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :39.36 & 43.16% & 0.73\n",
      "for 2022-02-16, MAE is:15.84 & sMAPE is:16.02% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :38.86 & 42.58% & 0.74\n",
      "for 2022-02-17, MAE is:25.38 & sMAPE is:45.56% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :38.58 & 42.64% & 0.74\n",
      "for 2022-02-18, MAE is:33.65 & sMAPE is:37.16% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :38.48 & 42.53% & 0.73\n",
      "for 2022-02-19, MAE is:55.98 & sMAPE is:116.32% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :38.83 & 44.00% & 0.73\n",
      "for 2022-02-20, MAE is:29.67 & sMAPE is:46.75% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :38.65 & 44.06% & 0.74\n",
      "for 2022-02-21, MAE is:41.89 & sMAPE is:79.18% & rMAE is:2.74 ||| daily mean of MAE & sMAPE & rMAE till now are :38.71 & 44.73% & 0.77\n",
      "for 2022-02-22, MAE is:37.32 & sMAPE is:32.74% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :38.69 & 44.51% & 0.79\n",
      "for 2022-02-23, MAE is:27.90 & sMAPE is:29.80% & rMAE is:2.28 ||| daily mean of MAE & sMAPE & rMAE till now are :38.49 & 44.23% & 0.82\n",
      "for 2022-02-24, MAE is:21.94 & sMAPE is:21.55% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :38.19 & 43.82% & 0.81\n",
      "for 2022-02-25, MAE is:15.01 & sMAPE is:13.57% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :37.77 & 43.28% & 0.81\n",
      "for 2022-02-26, MAE is:118.36 & sMAPE is:69.54% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :39.19 & 43.74% & 0.81\n",
      "for 2022-02-27, MAE is:29.42 & sMAPE is:16.56% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :39.02 & 43.27% & 0.80\n",
      "for 2022-02-28, MAE is:38.85 & sMAPE is:20.74% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :39.02 & 42.89% & 0.79\n",
      "for 2022-03-01, MAE is:106.11 & sMAPE is:54.30% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :40.13 & 43.08% & 0.79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-03-02, MAE is:60.48 & sMAPE is:23.56% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :40.47 & 42.76% & 0.79\n",
      "for 2022-03-03, MAE is:108.40 & sMAPE is:37.56% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :41.56 & 42.68% & 0.78\n",
      "for 2022-03-04, MAE is:66.98 & sMAPE is:20.38% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :41.97 & 42.32% & 0.77\n",
      "for 2022-03-05, MAE is:42.07 & sMAPE is:12.72% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :41.97 & 41.86% & 0.77\n",
      "for 2022-03-06, MAE is:54.55 & sMAPE is:16.70% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :42.16 & 41.47% & 0.76\n",
      "for 2022-03-07, MAE is:60.48 & sMAPE is:15.95% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :42.44 & 41.09% & 0.75\n",
      "for 2022-03-08, MAE is:162.63 & sMAPE is:39.92% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :44.23 & 41.07% & 0.75\n",
      "for 2022-03-09, MAE is:78.18 & sMAPE is:18.22% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :44.73 & 40.73% & 0.75\n",
      "for 2022-03-10, MAE is:136.34 & sMAPE is:46.09% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :46.06 & 40.81% & 0.76\n",
      "for 2022-03-11, MAE is:111.31 & sMAPE is:94.38% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :46.99 & 41.58% & 0.75\n",
      "for 2022-03-12, MAE is:39.10 & sMAPE is:34.84% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :46.88 & 41.48% & 0.75\n",
      "for 2022-03-13, MAE is:65.55 & sMAPE is:58.81% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :47.14 & 41.72% & 0.74\n",
      "for 2022-03-14, MAE is:52.88 & sMAPE is:20.70% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :47.22 & 41.44% & 0.74\n",
      "for 2022-03-15, MAE is:42.94 & sMAPE is:14.62% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :47.16 & 41.07% & 0.73\n",
      "for 2022-03-16, MAE is:60.00 & sMAPE is:24.99% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :47.33 & 40.86% & 0.72\n",
      "for 2022-03-17, MAE is:23.85 & sMAPE is:14.18% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :47.02 & 40.51% & 0.72\n",
      "for 2022-03-18, MAE is:49.41 & sMAPE is:24.55% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :47.05 & 40.30% & 0.71\n",
      "for 2022-03-19, MAE is:63.60 & sMAPE is:52.58% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :47.27 & 40.46% & 0.71\n",
      "for 2022-03-20, MAE is:46.04 & sMAPE is:90.21% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :47.25 & 41.09% & 0.71\n",
      "for 2022-03-21, MAE is:71.39 & sMAPE is:43.16% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :47.55 & 41.11% & 0.72\n",
      "for 2022-03-22, MAE is:43.94 & sMAPE is:19.49% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :47.51 & 40.85% & 0.72\n",
      "for 2022-03-23, MAE is:39.51 & sMAPE is:16.64% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :47.41 & 40.55% & 0.72\n",
      "for 2022-03-24, MAE is:36.54 & sMAPE is:15.34% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :47.28 & 40.25% & 0.72\n",
      "for 2022-03-25, MAE is:41.33 & sMAPE is:18.69% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :47.21 & 39.99% & 0.73\n",
      "for 2022-03-26, MAE is:44.91 & sMAPE is:27.48% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :47.18 & 39.84% & 0.72\n",
      "for 2022-03-27, MAE is:31.02 & sMAPE is:18.29% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :46.99 & 39.59% & 0.72\n",
      "for 2022-03-28, MAE is:72.55 & sMAPE is:56.59% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :47.29 & 39.79% & 0.72\n",
      "for 2022-03-29, MAE is:71.08 & sMAPE is:40.76% & rMAE is:2.26 ||| daily mean of MAE & sMAPE & rMAE till now are :47.56 & 39.80% & 0.74\n",
      "for 2022-03-30, MAE is:49.91 & sMAPE is:22.14% & rMAE is:1.95 ||| daily mean of MAE & sMAPE & rMAE till now are :47.58 & 39.60% & 0.75\n",
      "for 2022-03-31, MAE is:23.91 & sMAPE is:10.78% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :47.32 & 39.28% & 0.75\n",
      "for 2022-04-01, MAE is:19.67 & sMAPE is:11.69% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :47.02 & 38.98% & 0.75\n",
      "for 2022-04-02, MAE is:23.91 & sMAPE is:14.19% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :46.77 & 38.71% & 0.74\n",
      "for 2022-04-03, MAE is:25.52 & sMAPE is:15.71% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :46.54 & 38.46% & 0.75\n",
      "for 2022-04-04, MAE is:79.50 & sMAPE is:72.69% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :46.89 & 38.82% & 0.75\n",
      "for 2022-04-05, MAE is:79.80 & sMAPE is:64.66% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :47.23 & 39.10% & 0.76\n",
      "for 2022-04-06, MAE is:47.35 & sMAPE is:36.16% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :47.24 & 39.07% & 0.76\n",
      "for 2022-04-07, MAE is:36.04 & sMAPE is:39.04% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :47.12 & 39.07% & 0.75\n",
      "for 2022-04-08, MAE is:65.27 & sMAPE is:88.14% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :47.31 & 39.57% & 0.75\n",
      "for 2022-04-09, MAE is:84.07 & sMAPE is:96.62% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :47.68 & 40.14% & 0.75\n",
      "for 2022-04-10, MAE is:52.04 & sMAPE is:95.37% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :47.72 & 40.70% & 0.75\n",
      "for 2022-04-11, MAE is:77.77 & sMAPE is:42.23% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :48.02 & 40.71% & 0.75\n",
      "for 2022-04-12, MAE is:35.84 & sMAPE is:19.98% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :47.90 & 40.51% & 0.75\n",
      "for 2022-04-13, MAE is:67.12 & sMAPE is:37.11% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :48.09 & 40.47% & 0.75\n",
      "for 2022-04-14, MAE is:23.78 & sMAPE is:10.90% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :47.85 & 40.19% & 0.74\n",
      "for 2022-04-15, MAE is:13.47 & sMAPE is:7.11% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :47.52 & 39.87% & 0.74\n",
      "for 2022-04-16, MAE is:32.62 & sMAPE is:27.80% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :47.38 & 39.76% & 0.73\n",
      "for 2022-04-17, MAE is:37.14 & sMAPE is:46.40% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :47.29 & 39.82% & 0.73\n",
      "for 2022-04-18, MAE is:48.04 & sMAPE is:39.27% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :47.29 & 39.82% & 0.73\n",
      "for 2022-04-19, MAE is:37.41 & sMAPE is:18.78% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :47.20 & 39.62% & 0.74\n",
      "for 2022-04-20, MAE is:23.97 & sMAPE is:12.38% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :46.99 & 39.38% & 0.74\n",
      "for 2022-04-21, MAE is:16.47 & sMAPE is:8.14% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :46.72 & 39.10% & 0.74\n",
      "for 2022-04-22, MAE is:31.31 & sMAPE is:19.89% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :46.58 & 38.92% & 0.74\n",
      "for 2022-04-23, MAE is:44.95 & sMAPE is:57.45% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :46.57 & 39.09% & 0.74\n",
      "for 2022-04-24, MAE is:29.63 & sMAPE is:26.82% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :46.42 & 38.98% & 0.74\n",
      "for 2022-04-25, MAE is:56.62 & sMAPE is:29.37% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :46.51 & 38.90% & 0.74\n",
      "for 2022-04-26, MAE is:24.33 & sMAPE is:10.82% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :46.31 & 38.65% & 0.74\n",
      "for 2022-04-27, MAE is:17.53 & sMAPE is:8.13% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :46.07 & 38.39% & 0.75\n",
      "for 2022-04-28, MAE is:37.48 & sMAPE is:17.82% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :46.00 & 38.22% & 0.75\n",
      "for 2022-04-29, MAE is:21.17 & sMAPE is:9.66% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :45.79 & 37.98% & 0.75\n",
      "for 2022-04-30, MAE is:18.24 & sMAPE is:9.51% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :45.56 & 37.74% & 0.74\n",
      "for 2022-05-01, MAE is:14.54 & sMAPE is:7.69% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :45.30 & 37.49% & 0.74\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-05-02, MAE is:20.80 & sMAPE is:9.56% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :45.10 & 37.27% & 0.74\n",
      "for 2022-05-03, MAE is:25.40 & sMAPE is:12.27% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :44.94 & 37.06% & 0.75\n",
      "for 2022-05-04, MAE is:21.70 & sMAPE is:9.73% & rMAE is:2.22 ||| daily mean of MAE & sMAPE & rMAE till now are :44.75 & 36.84% & 0.76\n",
      "for 2022-05-05, MAE is:26.57 & sMAPE is:12.41% & rMAE is:2.56 ||| daily mean of MAE & sMAPE & rMAE till now are :44.61 & 36.65% & 0.77\n",
      "for 2022-05-06, MAE is:15.67 & sMAPE is:7.04% & rMAE is:2.01 ||| daily mean of MAE & sMAPE & rMAE till now are :44.38 & 36.41% & 0.78\n",
      "for 2022-05-07, MAE is:12.53 & sMAPE is:6.17% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :44.13 & 36.17% & 0.79\n",
      "for 2022-05-08, MAE is:29.32 & sMAPE is:19.35% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :44.01 & 36.04% & 0.79\n",
      "for 2022-05-09, MAE is:23.27 & sMAPE is:11.03% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :43.85 & 35.85% & 0.80\n",
      "for 2022-05-10, MAE is:29.22 & sMAPE is:18.69% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :43.74 & 35.72% & 0.80\n",
      "for 2022-05-11, MAE is:45.71 & sMAPE is:37.90% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :43.75 & 35.73% & 0.80\n",
      "for 2022-05-12, MAE is:29.33 & sMAPE is:19.44% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :43.64 & 35.61% & 0.79\n",
      "for 2022-05-13, MAE is:45.24 & sMAPE is:36.38% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :43.66 & 35.61% & 0.79\n",
      "for 2022-05-14, MAE is:50.19 & sMAPE is:42.96% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :43.70 & 35.67% & 0.79\n",
      "for 2022-05-15, MAE is:39.92 & sMAPE is:33.50% & rMAE is:1.67 ||| daily mean of MAE & sMAPE & rMAE till now are :43.68 & 35.65% & 0.80\n",
      "for 2022-05-16, MAE is:20.88 & sMAPE is:10.13% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :43.51 & 35.47% & 0.80\n",
      "for 2022-05-17, MAE is:38.23 & sMAPE is:18.33% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :43.47 & 35.34% & 0.80\n",
      "for 2022-05-18, MAE is:24.28 & sMAPE is:12.89% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :43.33 & 35.18% & 0.80\n",
      "for 2022-05-19, MAE is:23.28 & sMAPE is:11.51% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :43.19 & 35.01% & 0.80\n",
      "for 2022-05-20, MAE is:20.01 & sMAPE is:10.27% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :43.02 & 34.83% & 0.79\n",
      "for 2022-05-21, MAE is:56.13 & sMAPE is:49.68% & rMAE is:1.62 ||| daily mean of MAE & sMAPE & rMAE till now are :43.11 & 34.94% & 0.80\n",
      "for 2022-05-22, MAE is:16.13 & sMAPE is:10.18% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :42.92 & 34.76% & 0.80\n",
      "for 2022-05-23, MAE is:24.73 & sMAPE is:13.35% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :42.80 & 34.61% & 0.80\n",
      "for 2022-05-24, MAE is:33.66 & sMAPE is:32.44% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :42.73 & 34.60% & 0.80\n",
      "for 2022-05-25, MAE is:24.48 & sMAPE is:15.14% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :42.61 & 34.46% & 0.79\n",
      "for 2022-05-26, MAE is:78.44 & sMAPE is:111.49% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :42.85 & 34.99% & 0.79\n",
      "for 2022-05-27, MAE is:82.18 & sMAPE is:110.56% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :43.12 & 35.50% & 0.79\n",
      "for 2022-05-28, MAE is:42.42 & sMAPE is:145.98% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :43.12 & 36.25% & 0.79\n",
      "for 2022-05-29, MAE is:43.17 & sMAPE is:32.58% & rMAE is:2.11 ||| daily mean of MAE & sMAPE & rMAE till now are :43.12 & 36.23% & 0.80\n",
      "for 2022-05-30, MAE is:49.18 & sMAPE is:24.49% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :43.16 & 36.15% & 0.80\n",
      "for 2022-05-31, MAE is:16.71 & sMAPE is:8.05% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :42.98 & 35.96% & 0.80\n",
      "for 2022-06-01, MAE is:20.19 & sMAPE is:9.94% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :42.83 & 35.79% & 0.79\n",
      "for 2022-06-02, MAE is:26.50 & sMAPE is:14.02% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :42.73 & 35.65% & 0.79\n",
      "for 2022-06-03, MAE is:27.39 & sMAPE is:17.12% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :42.63 & 35.53% & 0.79\n",
      "for 2022-06-04, MAE is:27.26 & sMAPE is:18.61% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :42.53 & 35.42% & 0.78\n",
      "for 2022-06-05, MAE is:17.81 & sMAPE is:12.23% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :42.37 & 35.27% & 0.78\n",
      "for 2022-06-06, MAE is:72.64 & sMAPE is:81.31% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :42.56 & 35.56% & 0.78\n",
      "for 2022-06-07, MAE is:13.86 & sMAPE is:7.76% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :42.38 & 35.39% & 0.78\n",
      "for 2022-06-08, MAE is:15.43 & sMAPE is:8.18% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :42.21 & 35.22% & 0.78\n",
      "for 2022-06-09, MAE is:10.92 & sMAPE is:5.88% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :42.01 & 35.03% & 0.78\n",
      "for 2022-06-10, MAE is:15.03 & sMAPE is:8.47% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :41.85 & 34.87% & 0.78\n",
      "for 2022-06-11, MAE is:42.75 & sMAPE is:40.32% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :41.85 & 34.90% & 0.78\n",
      "for 2022-06-12, MAE is:46.69 & sMAPE is:52.91% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :41.88 & 35.01% & 0.79\n",
      "for 2022-06-13, MAE is:21.04 & sMAPE is:13.86% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :41.75 & 34.88% & 0.78\n",
      "for 2022-06-14, MAE is:33.33 & sMAPE is:19.46% & rMAE is:2.21 ||| daily mean of MAE & sMAPE & rMAE till now are :41.70 & 34.79% & 0.79\n",
      "for 2022-06-15, MAE is:30.85 & sMAPE is:14.66% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :41.64 & 34.67% & 0.79\n",
      "for 2022-06-16, MAE is:33.15 & sMAPE is:18.41% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :41.59 & 34.57% & 0.79\n",
      "for 2022-06-17, MAE is:51.11 & sMAPE is:21.27% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :41.64 & 34.49% & 0.79\n",
      "for 2022-06-18, MAE is:45.60 & sMAPE is:25.08% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :41.67 & 34.44% & 0.79\n",
      "for 2022-06-19, MAE is:70.33 & sMAPE is:45.56% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :41.84 & 34.50% & 0.80\n",
      "for 2022-06-20, MAE is:39.72 & sMAPE is:13.80% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :41.82 & 34.38% & 0.80\n",
      "for 2022-06-21, MAE is:96.99 & sMAPE is:38.15% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :42.14 & 34.40% & 0.80\n",
      "for 2022-06-22, MAE is:41.79 & sMAPE is:12.43% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :42.14 & 34.28% & 0.79\n",
      "for 2022-06-23, MAE is:39.67 & sMAPE is:13.33% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :42.13 & 34.16% & 0.79\n",
      "for 2022-06-24, MAE is:36.03 & sMAPE is:15.06% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :42.09 & 34.05% & 0.79\n",
      "for 2022-06-25, MAE is:33.38 & sMAPE is:14.05% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :42.04 & 33.93% & 0.79\n",
      "for 2022-06-26, MAE is:57.71 & sMAPE is:32.14% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :42.13 & 33.92% & 0.79\n",
      "for 2022-06-27, MAE is:24.90 & sMAPE is:7.86% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :42.04 & 33.78% & 0.79\n",
      "for 2022-06-28, MAE is:43.85 & sMAPE is:13.23% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :42.05 & 33.66% & 0.79\n",
      "for 2022-06-29, MAE is:30.10 & sMAPE is:9.59% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :41.98 & 33.53% & 0.79\n",
      "for 2022-06-30, MAE is:50.27 & sMAPE is:15.74% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :42.03 & 33.43% & 0.80\n",
      "for 2022-07-01, MAE is:28.34 & sMAPE is:9.09% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :41.95 & 33.30% & 0.80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-07-02, MAE is:67.63 & sMAPE is:34.16% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :42.09 & 33.30% & 0.80\n",
      "for 2022-07-03, MAE is:66.40 & sMAPE is:36.43% & rMAE is:3.34 ||| daily mean of MAE & sMAPE & rMAE till now are :42.22 & 33.32% & 0.81\n",
      "for 2022-07-04, MAE is:57.45 & sMAPE is:21.89% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :42.30 & 33.26% & 0.81\n",
      "for 2022-07-05, MAE is:30.11 & sMAPE is:11.08% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :42.24 & 33.14% & 0.81\n",
      "for 2022-07-06, MAE is:52.02 & sMAPE is:19.87% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :42.29 & 33.07% & 0.81\n",
      "for 2022-07-07, MAE is:20.06 & sMAPE is:10.47% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :42.17 & 32.95% & 0.81\n",
      "for 2022-07-08, MAE is:19.89 & sMAPE is:9.93% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :42.06 & 32.82% & 0.80\n",
      "for 2022-07-09, MAE is:98.25 & sMAPE is:76.91% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :42.35 & 33.06% & 0.80\n",
      "for 2022-07-10, MAE is:95.68 & sMAPE is:86.36% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :42.63 & 33.33% & 0.81\n",
      "for 2022-07-11, MAE is:74.38 & sMAPE is:21.70% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :42.80 & 33.27% & 0.80\n",
      "for 2022-07-12, MAE is:53.66 & sMAPE is:14.72% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :42.85 & 33.18% & 0.80\n",
      "for 2022-07-13, MAE is:102.85 & sMAPE is:38.60% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :43.16 & 33.21% & 0.81\n",
      "for 2022-07-14, MAE is:75.10 & sMAPE is:29.85% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :43.32 & 33.19% & 0.81\n",
      "for 2022-07-15, MAE is:64.86 & sMAPE is:30.63% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :43.43 & 33.18% & 0.81\n",
      "for 2022-07-16, MAE is:107.94 & sMAPE is:82.94% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :43.76 & 33.43% & 0.82\n",
      "for 2022-07-17, MAE is:79.14 & sMAPE is:39.72% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :43.94 & 33.46% & 0.82\n",
      "for 2022-07-18, MAE is:73.44 & sMAPE is:18.36% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :44.09 & 33.38% & 0.82\n",
      "for 2022-07-19, MAE is:58.98 & sMAPE is:14.51% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :44.16 & 33.29% & 0.82\n",
      "for 2022-07-20, MAE is:39.54 & sMAPE is:15.05% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :44.14 & 33.20% & 0.82\n",
      "for 2022-07-21, MAE is:127.62 & sMAPE is:40.63% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :44.55 & 33.24% & 0.82\n",
      "for 2022-07-22, MAE is:34.98 & sMAPE is:10.91% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :44.51 & 33.13% & 0.82\n",
      "for 2022-07-23, MAE is:30.69 & sMAPE is:10.43% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :44.44 & 33.01% & 0.81\n",
      "for 2022-07-24, MAE is:91.30 & sMAPE is:43.07% & rMAE is:1.79 ||| daily mean of MAE & sMAPE & rMAE till now are :44.67 & 33.06% & 0.82\n",
      "for 2022-07-25, MAE is:93.89 & sMAPE is:33.19% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :44.91 & 33.06% & 0.82\n",
      "for 2022-07-26, MAE is:141.13 & sMAPE is:60.11% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :45.37 & 33.19% & 0.82\n",
      "for 2022-07-27, MAE is:87.46 & sMAPE is:38.07% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :45.57 & 33.22% & 0.82\n",
      "for 2022-07-28, MAE is:111.74 & sMAPE is:27.85% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :45.89 & 33.19% & 0.82\n",
      "for 2022-07-29, MAE is:27.20 & sMAPE is:6.28% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :45.80 & 33.06% & 0.82\n",
      "for 2022-07-30, MAE is:59.98 & sMAPE is:16.80% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :45.87 & 32.99% & 0.82\n",
      "for 2022-07-31, MAE is:53.19 & sMAPE is:17.27% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :45.90 & 32.91% & 0.82\n",
      "for 2022-08-01, MAE is:43.36 & sMAPE is:12.47% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :45.89 & 32.82% & 0.81\n",
      "for 2022-08-02, MAE is:82.53 & sMAPE is:25.88% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :46.06 & 32.78% & 0.81\n",
      "for 2022-08-03, MAE is:69.13 & sMAPE is:22.41% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :46.17 & 32.74% & 0.81\n",
      "for 2022-08-04, MAE is:59.30 & sMAPE is:16.93% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :46.23 & 32.66% & 0.81\n",
      "for 2022-08-05, MAE is:60.38 & sMAPE is:17.10% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :46.30 & 32.59% & 0.81\n",
      "for 2022-08-06, MAE is:52.10 & sMAPE is:22.14% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :46.32 & 32.54% & 0.81\n",
      "for 2022-08-07, MAE is:99.91 & sMAPE is:47.83% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :46.57 & 32.61% & 0.81\n",
      "for 2022-08-08, MAE is:47.27 & sMAPE is:13.02% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :46.57 & 32.52% & 0.81\n",
      "for 2022-08-09, MAE is:37.62 & sMAPE is:10.97% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :46.53 & 32.43% & 0.81\n",
      "for 2022-08-10, MAE is:38.76 & sMAPE is:11.51% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :46.49 & 32.33% & 0.81\n",
      "for 2022-08-11, MAE is:48.57 & sMAPE is:13.23% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :46.50 & 32.25% & 0.81\n",
      "for 2022-08-12, MAE is:80.16 & sMAPE is:19.91% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :46.65 & 32.19% & 0.81\n",
      "for 2022-08-13, MAE is:53.66 & sMAPE is:15.52% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :46.69 & 32.12% & 0.81\n",
      "for 2022-08-14, MAE is:70.43 & sMAPE is:26.18% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :46.79 & 32.09% & 0.81\n",
      "for 2022-08-15, MAE is:46.87 & sMAPE is:11.55% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :46.79 & 32.00% & 0.81\n",
      "for 2022-08-16, MAE is:83.64 & sMAPE is:18.14% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :46.95 & 31.94% & 0.81\n",
      "for 2022-08-17, MAE is:64.76 & sMAPE is:12.36% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :47.03 & 31.85% & 0.80\n",
      "for 2022-08-18, MAE is:81.94 & sMAPE is:15.95% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :47.18 & 31.79% & 0.80\n",
      "for 2022-08-19, MAE is:28.94 & sMAPE is:5.89% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :47.10 & 31.67% & 0.80\n",
      "for 2022-08-20, MAE is:46.88 & sMAPE is:10.84% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :47.10 & 31.58% & 0.80\n",
      "for 2022-08-21, MAE is:110.41 & sMAPE is:34.38% & rMAE is:1.85 ||| daily mean of MAE & sMAPE & rMAE till now are :47.37 & 31.60% & 0.80\n",
      "for 2022-08-22, MAE is:48.99 & sMAPE is:9.15% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :47.38 & 31.50% & 0.80\n",
      "for 2022-08-23, MAE is:92.57 & sMAPE is:16.39% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :47.57 & 31.44% & 0.80\n",
      "for 2022-08-24, MAE is:73.84 & sMAPE is:12.23% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :47.68 & 31.35% & 0.80\n",
      "for 2022-08-25, MAE is:66.58 & sMAPE is:11.30% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :47.76 & 31.27% & 0.81\n",
      "for 2022-08-26, MAE is:115.13 & sMAPE is:17.98% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :48.05 & 31.21% & 0.80\n",
      "for 2022-08-27, MAE is:40.22 & sMAPE is:6.95% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :48.01 & 31.11% & 0.80\n",
      "for 2022-08-28, MAE is:146.87 & sMAPE is:44.46% & rMAE is:1.77 ||| daily mean of MAE & sMAPE & rMAE till now are :48.43 & 31.17% & 0.81\n",
      "for 2022-08-29, MAE is:100.69 & sMAPE is:15.72% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :48.64 & 31.10% & 0.81\n",
      "for 2022-08-30, MAE is:63.52 & sMAPE is:9.79% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :48.70 & 31.02% & 0.81\n",
      "for 2022-08-31, MAE is:42.49 & sMAPE is:7.15% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :48.68 & 30.92% & 0.81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-09-01, MAE is:54.96 & sMAPE is:9.79% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :48.70 & 30.83% & 0.81\n",
      "for 2022-09-02, MAE is:129.52 & sMAPE is:28.77% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :49.03 & 30.82% & 0.81\n",
      "for 2022-09-03, MAE is:90.76 & sMAPE is:35.80% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :49.20 & 30.84% & 0.81\n",
      "for 2022-09-04, MAE is:127.03 & sMAPE is:52.82% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :49.52 & 30.93% & 0.81\n",
      "for 2022-09-05, MAE is:106.32 & sMAPE is:30.66% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :49.75 & 30.93% & 0.81\n",
      "for 2022-09-06, MAE is:89.78 & sMAPE is:22.07% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :49.91 & 30.89% & 0.80\n",
      "for 2022-09-07, MAE is:40.53 & sMAPE is:8.85% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :49.87 & 30.81% & 0.80\n",
      "for 2022-09-08, MAE is:43.55 & sMAPE is:10.25% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :49.85 & 30.72% & 0.80\n",
      "for 2022-09-09, MAE is:47.78 & sMAPE is:14.80% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :49.84 & 30.66% & 0.80\n",
      "for 2022-09-10, MAE is:53.90 & sMAPE is:14.19% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :49.85 & 30.60% & 0.80\n",
      "for 2022-09-11, MAE is:34.36 & sMAPE is:9.11% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :49.79 & 30.51% & 0.80\n",
      "for 2022-09-12, MAE is:47.61 & sMAPE is:11.83% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :49.78 & 30.44% & 0.80\n",
      "for 2022-09-13, MAE is:36.15 & sMAPE is:9.93% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :49.73 & 30.36% & 0.79\n",
      "for 2022-09-14, MAE is:67.03 & sMAPE is:16.55% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :49.80 & 30.30% & 0.80\n",
      "for 2022-09-15, MAE is:44.95 & sMAPE is:12.90% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :49.78 & 30.24% & 0.80\n",
      "for 2022-09-16, MAE is:132.13 & sMAPE is:61.51% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :50.10 & 30.36% & 0.80\n",
      "for 2022-09-17, MAE is:118.82 & sMAPE is:97.18% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :50.36 & 30.61% & 0.79\n",
      "for 2022-09-18, MAE is:55.14 & sMAPE is:69.04% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :50.38 & 30.76% & 0.79\n",
      "for 2022-09-19, MAE is:112.46 & sMAPE is:47.22% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :50.62 & 30.82% & 0.79\n",
      "for 2022-09-20, MAE is:59.89 & sMAPE is:16.54% & rMAE is:1.94 ||| daily mean of MAE & sMAPE & rMAE till now are :50.65 & 30.77% & 0.80\n",
      "for 2022-09-21, MAE is:57.40 & sMAPE is:14.82% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :50.68 & 30.71% & 0.80\n",
      "for 2022-09-22, MAE is:69.58 & sMAPE is:18.16% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :50.75 & 30.66% & 0.80\n",
      "for 2022-09-23, MAE is:36.19 & sMAPE is:9.88% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :50.69 & 30.58% & 0.80\n",
      "for 2022-09-24, MAE is:60.02 & sMAPE is:18.59% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :50.73 & 30.54% & 0.79\n",
      "for 2022-09-25, MAE is:35.02 & sMAPE is:12.55% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :50.67 & 30.47% & 0.79\n",
      "for 2022-09-26, MAE is:66.49 & sMAPE is:28.65% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :50.73 & 30.47% & 0.79\n",
      "for 2022-09-27, MAE is:51.20 & sMAPE is:18.17% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :50.73 & 30.42% & 0.79\n",
      "for 2022-09-28, MAE is:76.96 & sMAPE is:20.32% & rMAE is:2.29 ||| daily mean of MAE & sMAPE & rMAE till now are :50.83 & 30.38% & 0.80\n",
      "for 2022-09-29, MAE is:59.34 & sMAPE is:14.17% & rMAE is:2.61 ||| daily mean of MAE & sMAPE & rMAE till now are :50.86 & 30.32% & 0.81\n",
      "for 2022-09-30, MAE is:95.74 & sMAPE is:31.20% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :51.02 & 30.33% & 0.81\n",
      "for 2022-10-01, MAE is:93.53 & sMAPE is:84.22% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :51.18 & 30.52% & 0.81\n",
      "for 2022-10-02, MAE is:56.52 & sMAPE is:47.36% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :51.20 & 30.58% & 0.80\n",
      "for 2022-10-03, MAE is:85.14 & sMAPE is:43.39% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :51.32 & 30.63% & 0.81\n",
      "for 2022-10-04, MAE is:95.30 & sMAPE is:39.01% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :51.48 & 30.66% & 0.81\n",
      "for 2022-10-05, MAE is:125.98 & sMAPE is:120.23% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :51.75 & 30.98% & 0.81\n",
      "for 2022-10-06, MAE is:68.87 & sMAPE is:137.86% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :51.81 & 31.37% & 0.80\n",
      "for 2022-10-07, MAE is:55.36 & sMAPE is:115.61% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :51.82 & 31.67% & 0.80\n",
      "for 2022-10-08, MAE is:8.63 & sMAPE is:17.78% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :51.67 & 31.62% & 0.80\n",
      "for 2022-10-09, MAE is:61.52 & sMAPE is:60.19% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :51.70 & 31.72% & 0.80\n",
      "for 2022-10-10, MAE is:43.95 & sMAPE is:29.61% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :51.68 & 31.71% & 0.80\n",
      "for 2022-10-11, MAE is:103.58 & sMAPE is:46.52% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :51.86 & 31.76% & 0.80\n",
      "for 2022-10-12, MAE is:50.96 & sMAPE is:16.38% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :51.86 & 31.71% & 0.80\n",
      "for 2022-10-13, MAE is:47.13 & sMAPE is:19.31% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :51.84 & 31.67% & 0.80\n",
      "for 2022-10-14, MAE is:61.74 & sMAPE is:25.65% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :51.87 & 31.65% & 0.80\n",
      "for 2022-10-15, MAE is:17.63 & sMAPE is:11.00% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :51.75 & 31.57% & 0.79\n",
      "for 2022-10-16, MAE is:36.87 & sMAPE is:42.19% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :51.70 & 31.61% & 0.79\n",
      "for 2022-10-17, MAE is:24.08 & sMAPE is:15.25% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :51.61 & 31.55% & 0.79\n",
      "for 2022-10-18, MAE is:21.33 & sMAPE is:12.35% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :51.50 & 31.49% & 0.79\n",
      "for 2022-10-19, MAE is:22.32 & sMAPE is:12.87% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :51.40 & 31.42% & 0.79\n",
      "for 2022-10-20, MAE is:18.49 & sMAPE is:14.25% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :51.29 & 31.37% & 0.79\n",
      "for 2022-10-21, MAE is:22.55 & sMAPE is:14.68% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :51.19 & 31.31% & 0.79\n",
      "for 2022-10-22, MAE is:9.24 & sMAPE is:6.68% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :51.05 & 31.23% & 0.79\n",
      "for 2022-10-23, MAE is:20.55 & sMAPE is:19.70% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :50.95 & 31.19% & 0.78\n",
      "for 2022-10-24, MAE is:13.02 & sMAPE is:18.21% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :50.82 & 31.14% & 0.78\n",
      "for 2022-10-25, MAE is:22.34 & sMAPE is:22.80% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :50.73 & 31.11% & 0.78\n",
      "for 2022-10-26, MAE is:16.19 & sMAPE is:13.50% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :50.61 & 31.06% & 0.78\n",
      "for 2022-10-27, MAE is:26.99 & sMAPE is:23.67% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :50.53 & 31.03% & 0.78\n",
      "for 2022-10-28, MAE is:11.57 & sMAPE is:10.77% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :50.40 & 30.96% & 0.78\n",
      "for 2022-10-29, MAE is:22.02 & sMAPE is:24.01% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :50.31 & 30.94% & 0.78\n",
      "for 2022-10-30, MAE is:33.88 & sMAPE is:32.69% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :50.25 & 30.95% & 0.78\n",
      "for 2022-10-31, MAE is:36.98 & sMAPE is:28.27% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :50.21 & 30.94% & 0.78\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-11-01, MAE is:38.54 & sMAPE is:47.73% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :50.17 & 30.99% & 0.78\n",
      "for 2022-11-02, MAE is:26.01 & sMAPE is:40.55% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :50.09 & 31.02% & 0.78\n",
      "for 2022-11-03, MAE is:13.32 & sMAPE is:17.05% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :49.97 & 30.98% & 0.78\n",
      "for 2022-11-04, MAE is:35.87 & sMAPE is:31.70% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :49.93 & 30.98% & 0.78\n",
      "for 2022-11-05, MAE is:60.38 & sMAPE is:61.94% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :49.96 & 31.08% & 0.78\n",
      "for 2022-11-06, MAE is:6.25 & sMAPE is:17.22% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :49.82 & 31.04% & 0.78\n",
      "for 2022-11-07, MAE is:16.64 & sMAPE is:56.61% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :49.71 & 31.12% & 0.78\n",
      "for 2022-11-08, MAE is:17.87 & sMAPE is:31.79% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :49.61 & 31.12% & 0.78\n",
      "for 2022-11-09, MAE is:43.48 & sMAPE is:50.40% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :49.59 & 31.18% & 0.78\n",
      "for 2022-11-10, MAE is:73.19 & sMAPE is:86.77% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :49.67 & 31.36% & 0.78\n",
      "for 2022-11-11, MAE is:18.04 & sMAPE is:168.71% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :49.57 & 31.80% & 0.78\n",
      "for 2022-11-12, MAE is:122.02 & sMAPE is:158.47% & rMAE is:1.83 ||| daily mean of MAE & sMAPE & rMAE till now are :49.80 & 32.20% & 0.78\n",
      "for 2022-11-13, MAE is:31.90 & sMAPE is:24.35% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :49.74 & 32.17% & 0.78\n",
      "for 2022-11-14, MAE is:53.84 & sMAPE is:41.69% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :49.75 & 32.20% & 0.78\n",
      "for 2022-11-15, MAE is:63.78 & sMAPE is:67.89% & rMAE is:1.95 ||| daily mean of MAE & sMAPE & rMAE till now are :49.80 & 32.31% & 0.78\n",
      "for 2022-11-16, MAE is:12.41 & sMAPE is:33.80% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :49.68 & 32.32% & 0.78\n",
      "for 2022-11-17, MAE is:14.20 & sMAPE is:35.77% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :49.57 & 32.33% & 0.78\n",
      "for 2022-11-18, MAE is:80.74 & sMAPE is:118.86% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :49.67 & 32.60% & 0.78\n",
      "for 2022-11-19, MAE is:86.87 & sMAPE is:55.34% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :49.78 & 32.67% & 0.78\n",
      "for 2022-11-20, MAE is:35.89 & sMAPE is:18.23% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :49.74 & 32.62% & 0.78\n",
      "for 2022-11-21, MAE is:72.18 & sMAPE is:29.57% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :49.81 & 32.61% & 0.78\n",
      "for 2022-11-22, MAE is:24.61 & sMAPE is:15.56% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :49.73 & 32.56% & 0.78\n",
      "for 2022-11-23, MAE is:18.58 & sMAPE is:12.70% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :49.63 & 32.50% & 0.78\n",
      "for 2022-11-24, MAE is:121.75 & sMAPE is:65.73% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :49.85 & 32.60% & 0.78\n",
      "for 2022-11-25, MAE is:81.40 & sMAPE is:35.95% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :49.95 & 32.61% & 0.78\n",
      "for 2022-11-26, MAE is:25.97 & sMAPE is:11.24% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :49.88 & 32.55% & 0.78\n",
      "for 2022-11-27, MAE is:36.24 & sMAPE is:23.13% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :49.84 & 32.52% & 0.77\n",
      "for 2022-11-28, MAE is:37.51 & sMAPE is:22.00% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :49.80 & 32.49% & 0.77\n",
      "for 2022-11-29, MAE is:182.18 & sMAPE is:64.43% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :50.20 & 32.58% & 0.77\n",
      "for 2022-11-30, MAE is:129.98 & sMAPE is:37.58% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :50.44 & 32.60% & 0.77\n",
      "for 2022-12-01, MAE is:106.00 & sMAPE is:30.28% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :50.60 & 32.59% & 0.77\n",
      "for 2022-12-02, MAE is:53.12 & sMAPE is:16.18% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :50.61 & 32.54% & 0.77\n",
      "for 2022-12-03, MAE is:30.78 & sMAPE is:12.74% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :50.55 & 32.48% & 0.77\n",
      "for 2022-12-04, MAE is:42.64 & sMAPE is:17.21% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :50.53 & 32.44% & 0.77\n",
      "for 2022-12-05, MAE is:70.71 & sMAPE is:23.76% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :50.59 & 32.41% & 0.77\n",
      "for 2022-12-06, MAE is:77.23 & sMAPE is:21.56% & rMAE is:1.98 ||| daily mean of MAE & sMAPE & rMAE till now are :50.66 & 32.38% & 0.78\n",
      "for 2022-12-07, MAE is:45.38 & sMAPE is:13.97% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :50.65 & 32.33% & 0.78\n",
      "for 2022-12-08, MAE is:84.26 & sMAPE is:23.87% & rMAE is:7.38 ||| daily mean of MAE & sMAPE & rMAE till now are :50.75 & 32.30% & 0.80\n",
      "for 2022-12-09, MAE is:103.28 & sMAPE is:28.07% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :50.90 & 32.29% & 0.80\n",
      "for 2022-12-10, MAE is:63.67 & sMAPE is:19.09% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :50.94 & 32.25% & 0.80\n",
      "for 2022-12-11, MAE is:46.00 & sMAPE is:15.21% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :50.92 & 32.20% & 0.80\n",
      "for 2022-12-12, MAE is:122.75 & sMAPE is:30.36% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :51.13 & 32.20% & 0.80\n",
      "for 2022-12-13, MAE is:110.99 & sMAPE is:25.78% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :51.30 & 32.18% & 0.80\n",
      "for 2022-12-14, MAE is:135.97 & sMAPE is:33.56% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :51.55 & 32.18% & 0.80\n",
      "for 2022-12-15, MAE is:44.17 & sMAPE is:11.25% & rMAE is:2.42 ||| daily mean of MAE & sMAPE & rMAE till now are :51.53 & 32.12% & 0.81\n",
      "for 2022-12-16, MAE is:82.70 & sMAPE is:20.79% & rMAE is:2.98 ||| daily mean of MAE & sMAPE & rMAE till now are :51.61 & 32.09% & 0.81\n",
      "for 2022-12-17, MAE is:54.17 & sMAPE is:19.73% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :51.62 & 32.06% & 0.81\n",
      "for 2022-12-18, MAE is:37.86 & sMAPE is:18.28% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :51.58 & 32.02% & 0.81\n",
      "for 2022-12-19, MAE is:26.71 & sMAPE is:14.85% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :51.51 & 31.97% & 0.81\n",
      "for 2022-12-20, MAE is:21.07 & sMAPE is:13.67% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :51.43 & 31.92% & 0.81\n",
      "for 2022-12-21, MAE is:29.40 & sMAPE is:14.29% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :51.36 & 31.87% & 0.80\n",
      "for 2022-12-22, MAE is:15.80 & sMAPE is:8.51% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :51.26 & 31.80% & 0.80\n",
      "for 2022-12-23, MAE is:25.12 & sMAPE is:13.84% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :51.19 & 31.75% & 0.80\n",
      "for 2022-12-24, MAE is:25.01 & sMAPE is:27.26% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :51.12 & 31.74% & 0.80\n",
      "for 2022-12-25, MAE is:17.26 & sMAPE is:15.12% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :51.02 & 31.69% & 0.80\n",
      "for 2022-12-26, MAE is:73.25 & sMAPE is:97.39% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :51.09 & 31.87% & 0.80\n",
      "for 2022-12-27, MAE is:42.78 & sMAPE is:58.98% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :51.06 & 31.95% & 0.79\n",
      "for 2022-12-28, MAE is:44.12 & sMAPE is:75.11% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :51.04 & 32.07% & 0.79\n",
      "for 2022-12-29, MAE is:36.89 & sMAPE is:136.94% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :51.00 & 32.36% & 0.79\n",
      "for 2022-12-30, MAE is:29.81 & sMAPE is:102.39% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :50.95 & 32.55% & 0.79\n",
      "for 2022-12-31, MAE is:12.08 & sMAPE is:118.13% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :50.84 & 32.78% & 0.79\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:05:53,019]\u001b[0m A new study created in RDB with name: DK_1_2023\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:06:12,740]\u001b[0m Trial 2 finished with value: 179.7043703721578 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013785173024050382, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.014566881882370897, 'dropout_rate_Layer_2': 0.2765470572985355, 'dropout_rate_Layer_3': 0.2765796758050802, 'dropout_rate_Layer_4': 0.04452536097137423, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.004652776271375621, 'l1_Layer_2': 0.014589080929282645, 'l1_Layer_3': 3.9888772860372625e-05, 'l1_Layer_4': 0.08920566756369039, 'n_units_Layer_1': 250, 'n_units_Layer_2': 205, 'n_units_Layer_3': 115, 'n_units_Layer_4': 220}. Best is trial 2 with value: 179.7043703721578.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 179.70 | sMAPE for Validation Set is: 119.35% | rMAE for Validation Set is: 1.96\n",
      "MAE for Test Set is: 59.45 | sMAPE for Test Set is: 80.91% | rMAE for Test Set is: 1.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:06:18,662]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:06:22,299]\u001b[0m Trial 1 finished with value: 86.86944243411112 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012157388243379497, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24195903583046552, 'dropout_rate_Layer_2': 0.35433760145497617, 'dropout_rate_Layer_3': 0.14670917671248304, 'dropout_rate_Layer_4': 0.02538210685699878, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0009603650942304589, 'l1_Layer_2': 2.70544865958685e-05, 'l1_Layer_3': 0.0009205984367082163, 'l1_Layer_4': 5.4617622324047826e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 190, 'n_units_Layer_3': 240, 'n_units_Layer_4': 230}. Best is trial 1 with value: 86.86944243411112.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 86.87 | sMAPE for Validation Set is: 46.24% | rMAE for Validation Set is: 0.95\n",
      "MAE for Test Set is: 29.93 | sMAPE for Test Set is: 39.02% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:06:22,722]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:06:30,378]\u001b[0m Trial 0 finished with value: 111.75278140932933 and parameters: {'n_hidden': 3, 'learning_rate': 0.000718717224602876, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.016506104606844298, 'dropout_rate_Layer_2': 0.06190560443997431, 'dropout_rate_Layer_3': 0.3048145483184488, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005519890483342546, 'l1_Layer_2': 0.010747382258200147, 'l1_Layer_3': 0.05936493291187666, 'n_units_Layer_1': 80, 'n_units_Layer_2': 240, 'n_units_Layer_3': 150}. Best is trial 1 with value: 86.86944243411112.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 111.75 | sMAPE for Validation Set is: 58.90% | rMAE for Validation Set is: 1.22\n",
      "MAE for Test Set is: 33.28 | sMAPE for Test Set is: 45.18% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:06:30,840]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:06:33,084]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:06:37,339]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:06:37,507]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:06:40,620]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:06:45,976]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:06:48,309]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:06:49,549]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:06:52,685]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:06:54,634]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:06:55,113]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:06:58,084]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:06:59,719]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:07:01,649]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:07:02,243]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:07:03,784]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:07:07,038]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:07:09,941]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:07:18,309]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:07:21,582]\u001b[0m Trial 22 finished with value: 171.22532531692107 and parameters: {'n_hidden': 4, 'learning_rate': 0.006245474202075582, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06660637359353015, 'dropout_rate_Layer_2': 0.10546552351990589, 'dropout_rate_Layer_3': 0.3749400454165578, 'dropout_rate_Layer_4': 0.0922368523513618, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0001345547456198236, 'l1_Layer_2': 0.006451765079249363, 'l1_Layer_3': 0.09781857326941303, 'l1_Layer_4': 0.005866206613635463, 'n_units_Layer_1': 300, 'n_units_Layer_2': 135, 'n_units_Layer_3': 235, 'n_units_Layer_4': 100}. Best is trial 1 with value: 86.86944243411112.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 171.23 | sMAPE for Validation Set is: 109.11% | rMAE for Validation Set is: 1.87\n",
      "MAE for Test Set is: 51.51 | sMAPE for Test Set is: 67.07% | rMAE for Test Set is: 1.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:07:24,731]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:07:24,849]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:07:31,317]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:07:33,174]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:07:34,532]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:07:36,610]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:07:37,199]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:07:41,755]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:07:45,498]\u001b[0m Trial 27 finished with value: 67.84143563568036 and parameters: {'n_hidden': 4, 'learning_rate': 0.012512932700872496, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.003269037361714844, 'dropout_rate_Layer_2': 0.07875929030509897, 'dropout_rate_Layer_3': 0.10162600593551088, 'dropout_rate_Layer_4': 0.0869125336250503, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.563468614297018e-05, 'l1_Layer_2': 1.1447841113184706e-05, 'l1_Layer_3': 1.2928882753637246e-05, 'l1_Layer_4': 7.343810105605884e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 125, 'n_units_Layer_3': 55, 'n_units_Layer_4': 150}. Best is trial 27 with value: 67.84143563568036.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:07:45,556]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 67.84 | sMAPE for Validation Set is: 38.30% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 30.43 | sMAPE for Test Set is: 34.93% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:07:51,277]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:07:57,126]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:08:00,002]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:08:03,446]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:08:06,545]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:08:09,704]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:08:10,113]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:08:17,203]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:08:20,691]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:08:25,679]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:08:31,070]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:08:36,197]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:08:40,983]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:08:45,989]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:08:48,490]\u001b[0m Trial 43 finished with value: 83.14596035607035 and parameters: {'n_hidden': 4, 'learning_rate': 0.01146348386668892, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03408261724690411, 'dropout_rate_Layer_2': 0.38632028141376984, 'dropout_rate_Layer_3': 0.0742914955871604, 'dropout_rate_Layer_4': 0.28764982640483416, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.001520033687755948, 'l1_Layer_2': 0.03741497161386774, 'l1_Layer_3': 0.05899069704030689, 'l1_Layer_4': 0.002586985873004058, 'n_units_Layer_1': 55, 'n_units_Layer_2': 140, 'n_units_Layer_3': 190, 'n_units_Layer_4': 140}. Best is trial 27 with value: 67.84143563568036.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 83.15 | sMAPE for Validation Set is: 44.47% | rMAE for Validation Set is: 0.91\n",
      "MAE for Test Set is: 39.88 | sMAPE for Test Set is: 40.40% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:08:55,929]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:09:04,548]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:09:08,705]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:09:16,669]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:09:24,826]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:09:44,731]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:09:54,496]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:10:00,013]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:10:01,759]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:10:05,949]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:10:09,562]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:10:13,569]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:10:16,231]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:10:20,074]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:10:22,048]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:10:29,584]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:10:36,545]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:10:46,491]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:10:48,573]\u001b[0m Trial 68 finished with value: 47.69821631621105 and parameters: {'n_hidden': 3, 'learning_rate': 0.008730857259819055, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.012568635065195776, 'dropout_rate_Layer_2': 0.007919782180385707, 'dropout_rate_Layer_3': 0.1666870168856619, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00024472027131840695, 'l1_Layer_2': 0.0002264856461182135, 'l1_Layer_3': 0.0053338825423056725, 'n_units_Layer_1': 115, 'n_units_Layer_2': 215, 'n_units_Layer_3': 160}. Best is trial 68 with value: 47.69821631621105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.70 | sMAPE for Validation Set is: 31.57% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 23.17 | sMAPE for Test Set is: 31.91% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:10:56,177]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:11:01,158]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:11:20,344]\u001b[0m Trial 3 finished with value: 88.23447082172781 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007853900031675866, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1037828183156841, 'dropout_rate_Layer_2': 0.26826598969019205, 'dropout_rate_Layer_3': 0.3983871461577775, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.013420155682956668, 'l1_Layer_2': 0.003930569618578024, 'l1_Layer_3': 2.3402867072160694e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 280, 'n_units_Layer_3': 55}. Best is trial 68 with value: 47.69821631621105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 88.23 | sMAPE for Validation Set is: 46.24% | rMAE for Validation Set is: 0.96\n",
      "MAE for Test Set is: 23.91 | sMAPE for Test Set is: 31.95% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:11:42,669]\u001b[0m Trial 71 finished with value: 53.489699084239305 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012009083285994273, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27891019680420037, 'dropout_rate_Layer_2': 0.35108141093744055, 'dropout_rate_Layer_3': 0.16061870377387186, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006831290460562847, 'l1_Layer_2': 0.05329885300908997, 'l1_Layer_3': 0.0006345113215237002, 'n_units_Layer_1': 300, 'n_units_Layer_2': 240, 'n_units_Layer_3': 220}. Best is trial 68 with value: 47.69821631621105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.49 | sMAPE for Validation Set is: 33.84% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 25.44 | sMAPE for Test Set is: 33.72% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:11:55,707]\u001b[0m Trial 74 finished with value: 48.82432612754141 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011016451342935295, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23488409743429492, 'dropout_rate_Layer_2': 0.39769593086230687, 'dropout_rate_Layer_3': 0.16839006050233227, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.007350937216305905, 'l1_Layer_2': 0.015875483352965916, 'l1_Layer_3': 3.8442842319016676e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 255, 'n_units_Layer_3': 205}. Best is trial 68 with value: 47.69821631621105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 48.82 | sMAPE for Validation Set is: 31.76% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 22.47 | sMAPE for Test Set is: 30.49% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:11:56,254]\u001b[0m Trial 69 finished with value: 82.75526527469604 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011719806578017824, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2374848191494441, 'dropout_rate_Layer_2': 0.3461569776971989, 'dropout_rate_Layer_3': 0.16542822505749158, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018992607185111708, 'l1_Layer_2': 0.0036089647966307233, 'l1_Layer_3': 1.032481039295832e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 245, 'n_units_Layer_3': 205}. Best is trial 68 with value: 47.69821631621105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 82.76 | sMAPE for Validation Set is: 44.16% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 22.84 | sMAPE for Test Set is: 30.24% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:12:07,717]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:12:15,290]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:12:19,343]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:12:19,642]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:12:22,997]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:12:26,893]\u001b[0m Trial 75 finished with value: 47.74893214277437 and parameters: {'n_hidden': 3, 'learning_rate': 0.001087525599478563, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0688832232090672, 'dropout_rate_Layer_2': 0.3429120784290539, 'dropout_rate_Layer_3': 0.16436131684378869, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006918896321303745, 'l1_Layer_2': 0.016061289215363768, 'l1_Layer_3': 0.0006465492685328954, 'n_units_Layer_1': 300, 'n_units_Layer_2': 215, 'n_units_Layer_3': 210}. Best is trial 68 with value: 47.69821631621105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.75 | sMAPE for Validation Set is: 31.50% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 22.26 | sMAPE for Test Set is: 30.70% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:12:27,560]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:12:29,230]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:12:30,046]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:12:42,787]\u001b[0m Trial 84 finished with value: 88.09429614793434 and parameters: {'n_hidden': 4, 'learning_rate': 0.02846913454076576, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31023957247955225, 'dropout_rate_Layer_2': 0.17486702538261908, 'dropout_rate_Layer_3': 0.10831959885194174, 'dropout_rate_Layer_4': 0.03340740598045483, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.3952936232025831e-05, 'l1_Layer_2': 0.0001736368972086313, 'l1_Layer_3': 0.0938176137341298, 'l1_Layer_4': 1.035968005513395e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 205, 'n_units_Layer_3': 230, 'n_units_Layer_4': 210}. Best is trial 68 with value: 47.69821631621105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 88.09 | sMAPE for Validation Set is: 45.90% | rMAE for Validation Set is: 0.96\n",
      "MAE for Test Set is: 28.43 | sMAPE for Test Set is: 34.21% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:12:44,338]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:12:48,568]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:12:53,293]\u001b[0m Trial 87 finished with value: 50.010970394423786 and parameters: {'n_hidden': 3, 'learning_rate': 0.01887645470194691, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.026622631396971075, 'dropout_rate_Layer_2': 0.006569189720829805, 'dropout_rate_Layer_3': 0.3124518722339017, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003665718443499277, 'l1_Layer_2': 1.000440837312783e-05, 'l1_Layer_3': 0.04928513425354505, 'n_units_Layer_1': 80, 'n_units_Layer_2': 285, 'n_units_Layer_3': 255}. Best is trial 68 with value: 47.69821631621105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.01 | sMAPE for Validation Set is: 32.46% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 23.44 | sMAPE for Test Set is: 31.54% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:13:00,638]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:13:01,515]\u001b[0m Trial 89 finished with value: 52.71766766668477 and parameters: {'n_hidden': 4, 'learning_rate': 0.0029622406123128962, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1756107776082582, 'dropout_rate_Layer_2': 0.2182563550279945, 'dropout_rate_Layer_3': 0.036633484713875064, 'dropout_rate_Layer_4': 0.08931892222688265, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00011100163174700453, 'l1_Layer_2': 0.00020547849219444174, 'l1_Layer_3': 0.01190267733831251, 'l1_Layer_4': 1.2183169009294607e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 255, 'n_units_Layer_3': 270, 'n_units_Layer_4': 210}. Best is trial 68 with value: 47.69821631621105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.72 | sMAPE for Validation Set is: 33.01% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 24.63 | sMAPE for Test Set is: 31.72% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:13:06,874]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:13:09,078]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:13:16,474]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:13:20,645]\u001b[0m Trial 93 finished with value: 51.846265435174416 and parameters: {'n_hidden': 4, 'learning_rate': 0.0033454926618752667, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1808360265110634, 'dropout_rate_Layer_2': 0.32766821860173206, 'dropout_rate_Layer_3': 0.02182702620295736, 'dropout_rate_Layer_4': 0.11260534222339516, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00011758882372252448, 'l1_Layer_2': 0.000529875142200437, 'l1_Layer_3': 0.010209732670206318, 'l1_Layer_4': 5.807278046093868e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 270, 'n_units_Layer_3': 270, 'n_units_Layer_4': 300}. Best is trial 68 with value: 47.69821631621105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.85 | sMAPE for Validation Set is: 32.86% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 22.17 | sMAPE for Test Set is: 30.00% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:13:23,687]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:13:28,251]\u001b[0m Trial 94 finished with value: 48.587928094044194 and parameters: {'n_hidden': 3, 'learning_rate': 0.01105719108044696, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2895024551775597, 'dropout_rate_Layer_2': 0.18461728971857097, 'dropout_rate_Layer_3': 0.05751423350070609, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012807198530448313, 'l1_Layer_2': 0.0002752796553805337, 'l1_Layer_3': 0.03281502709326982, 'n_units_Layer_1': 155, 'n_units_Layer_2': 195, 'n_units_Layer_3': 100}. Best is trial 68 with value: 47.69821631621105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 48.59 | sMAPE for Validation Set is: 32.47% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 24.91 | sMAPE for Test Set is: 34.08% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:13:32,092]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:13:39,058]\u001b[0m Trial 98 finished with value: 53.965465843957226 and parameters: {'n_hidden': 3, 'learning_rate': 0.004299579907680247, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16740962507510587, 'dropout_rate_Layer_2': 0.2333996347291389, 'dropout_rate_Layer_3': 0.054390696694101716, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011121679605617821, 'l1_Layer_2': 0.003785923611286954, 'l1_Layer_3': 0.015001993715594115, 'n_units_Layer_1': 90, 'n_units_Layer_2': 265, 'n_units_Layer_3': 300}. Best is trial 68 with value: 47.69821631621105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.97 | sMAPE for Validation Set is: 33.64% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 22.71 | sMAPE for Test Set is: 30.18% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:13:41,445]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:13:44,410]\u001b[0m Trial 96 finished with value: 50.81990804042673 and parameters: {'n_hidden': 4, 'learning_rate': 0.0032456913506469765, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21099628312947774, 'dropout_rate_Layer_2': 0.22680383618097721, 'dropout_rate_Layer_3': 0.031065518040601148, 'dropout_rate_Layer_4': 0.09641061468623192, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0014459781802896986, 'l1_Layer_2': 6.647035431375206e-05, 'l1_Layer_3': 0.013119208630538155, 'l1_Layer_4': 1.2023962963090943e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 245, 'n_units_Layer_3': 300, 'n_units_Layer_4': 220}. Best is trial 68 with value: 47.69821631621105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.82 | sMAPE for Validation Set is: 32.35% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 22.88 | sMAPE for Test Set is: 30.21% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:13:44,703]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:13:49,731]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:13:49,885]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:13:50,777]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:13:56,594]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:13:57,852]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:14:01,789]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:14:02,307]\u001b[0m Trial 90 finished with value: 45.540389431089274 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010199887247223215, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.058986984805216996, 'dropout_rate_Layer_2': 0.3988942472602565, 'dropout_rate_Layer_3': 0.19270109220682113, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006707943775950311, 'l1_Layer_2': 0.00392367035799785, 'l1_Layer_3': 0.0001803529935850489, 'n_units_Layer_1': 80, 'n_units_Layer_2': 235, 'n_units_Layer_3': 250}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.54 | sMAPE for Validation Set is: 30.46% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 20.69 | sMAPE for Test Set is: 29.07% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:14:02,935]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:14:05,141]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:14:08,388]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:14:11,895]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:14:14,166]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:14:16,354]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:14:21,749]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:14:24,907]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:14:57,999]\u001b[0m Trial 118 finished with value: 49.254373355084816 and parameters: {'n_hidden': 3, 'learning_rate': 0.00308589254289714, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19072846353480974, 'dropout_rate_Layer_2': 0.37493742346940645, 'dropout_rate_Layer_3': 0.2391974258464798, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.013609573668221487, 'l1_Layer_2': 0.0017372401965623683, 'l1_Layer_3': 0.00020851411544475237, 'n_units_Layer_1': 65, 'n_units_Layer_2': 235, 'n_units_Layer_3': 255}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.25 | sMAPE for Validation Set is: 31.78% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 22.02 | sMAPE for Test Set is: 30.17% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:15:09,355]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:15:14,016]\u001b[0m Trial 120 finished with value: 95.02824110793888 and parameters: {'n_hidden': 3, 'learning_rate': 0.03271430087395666, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05355148829685055, 'dropout_rate_Layer_2': 0.12468138418331254, 'dropout_rate_Layer_3': 0.09006487517890381, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018911115409565396, 'l1_Layer_2': 0.050453872017844834, 'l1_Layer_3': 0.0014529949571818004, 'n_units_Layer_1': 300, 'n_units_Layer_2': 200, 'n_units_Layer_3': 170}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 95.03 | sMAPE for Validation Set is: 48.82% | rMAE for Validation Set is: 1.04\n",
      "MAE for Test Set is: 34.15 | sMAPE for Test Set is: 37.70% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:15:18,537]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:15:21,045]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:15:29,604]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:15:38,654]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:15:40,807]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:15:47,981]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:15:49,501]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:15:52,350]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:15:53,020]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:15:56,908]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:15:57,060]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:16:00,580]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:16:04,411]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:16:10,045]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:16:13,293]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:16:29,513]\u001b[0m Trial 132 finished with value: 51.50602457491601 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017371937463728476, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.018508887315742517, 'dropout_rate_Layer_2': 0.13114076922460144, 'dropout_rate_Layer_3': 0.05828795356629188, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00805313034511505, 'l1_Layer_2': 0.0003042232525133248, 'l1_Layer_3': 0.0015049284974238877, 'n_units_Layer_1': 185, 'n_units_Layer_2': 235, 'n_units_Layer_3': 260}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.51 | sMAPE for Validation Set is: 32.40% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 29.51 | sMAPE for Test Set is: 35.03% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:16:32,036]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:16:34,220]\u001b[0m Trial 133 finished with value: 51.18050562930395 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017662085452650243, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02503477421833969, 'dropout_rate_Layer_2': 0.2984672220136406, 'dropout_rate_Layer_3': 3.1385337671146346e-05, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.010999530423269174, 'l1_Layer_2': 0.000348429610338879, 'l1_Layer_3': 0.02744965941930623, 'n_units_Layer_1': 190, 'n_units_Layer_2': 240, 'n_units_Layer_3': 260}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.18 | sMAPE for Validation Set is: 32.90% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 24.72 | sMAPE for Test Set is: 32.66% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:16:36,321]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:16:38,845]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:16:42,072]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:16:44,464]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:16:46,710]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:16:49,041]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:16:52,087]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:16:54,893]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:16:55,469]\u001b[0m Trial 137 finished with value: 51.67657504788878 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022268939518088476, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006840319780671289, 'dropout_rate_Layer_2': 0.13452543832183833, 'dropout_rate_Layer_3': 0.0018407855804580542, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.012684863668364839, 'l1_Layer_2': 0.00034213011001604473, 'l1_Layer_3': 0.0287106828843586, 'n_units_Layer_1': 185, 'n_units_Layer_2': 230, 'n_units_Layer_3': 285}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.68 | sMAPE for Validation Set is: 32.98% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 24.30 | sMAPE for Test Set is: 31.65% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:16:59,719]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:17:05,257]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:17:06,046]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:17:11,076]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:17:17,754]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:17:22,830]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:17:25,848]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:17:28,064]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:17:31,754]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:17:35,877]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:17:38,189]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:17:39,136]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:17:44,977]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:17:49,160]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:17:54,818]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:17:56,688]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:17:58,686]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:18:00,608]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:18:03,565]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:18:24,055]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:18:29,197]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:18:33,532]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:18:37,426]\u001b[0m Trial 167 finished with value: 52.35065983224515 and parameters: {'n_hidden': 3, 'learning_rate': 0.00181164153909832, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05162616218340682, 'dropout_rate_Layer_2': 0.13039123405700181, 'dropout_rate_Layer_3': 0.060597398766299396, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004563460767257872, 'l1_Layer_2': 0.002043838664238451, 'l1_Layer_3': 0.01956005755743414, 'n_units_Layer_1': 245, 'n_units_Layer_2': 240, 'n_units_Layer_3': 300}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.35 | sMAPE for Validation Set is: 33.37% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 24.89 | sMAPE for Test Set is: 32.80% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:18:40,173]\u001b[0m Trial 168 finished with value: 52.22422067926251 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016294860503067833, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05467417830314951, 'dropout_rate_Layer_2': 0.2583897943687471, 'dropout_rate_Layer_3': 0.058381123989606515, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004423988584888092, 'l1_Layer_2': 0.0016840527703424963, 'l1_Layer_3': 0.09275029727599912, 'n_units_Layer_1': 250, 'n_units_Layer_2': 235, 'n_units_Layer_3': 300}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.22 | sMAPE for Validation Set is: 33.35% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 25.93 | sMAPE for Test Set is: 32.70% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:18:43,932]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:18:44,607]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:18:53,662]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:18:55,895]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:19:03,653]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:19:06,832]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:19:20,779]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:19:25,674]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:19:26,185]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:19:33,211]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:19:47,449]\u001b[0m Trial 171 finished with value: 48.47631160380371 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005882270048818332, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09337323673479606, 'dropout_rate_Layer_2': 0.37928406370043133, 'dropout_rate_Layer_3': 0.23301795763894292, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005991373464244217, 'l1_Layer_2': 0.0018670612785813855, 'l1_Layer_3': 0.0009208484924812283, 'n_units_Layer_1': 165, 'n_units_Layer_2': 235, 'n_units_Layer_3': 275}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 48.48 | sMAPE for Validation Set is: 31.63% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 22.72 | sMAPE for Test Set is: 31.31% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:19:50,390]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:19:53,180]\u001b[0m Trial 183 finished with value: 49.59881381319889 and parameters: {'n_hidden': 3, 'learning_rate': 0.014899710625985869, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3694673200204425, 'dropout_rate_Layer_2': 0.12443031597428256, 'dropout_rate_Layer_3': 0.030566441691115668, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003457683652430459, 'l1_Layer_2': 0.0007791753213979524, 'l1_Layer_3': 0.011741253922405333, 'n_units_Layer_1': 170, 'n_units_Layer_2': 205, 'n_units_Layer_3': 250}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.60 | sMAPE for Validation Set is: 31.85% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 25.29 | sMAPE for Test Set is: 35.13% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:19:53,853]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:19:59,105]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:19:59,500]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:20:05,823]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:20:06,164]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:20:06,469]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:20:14,338]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:20:16,377]\u001b[0m Trial 184 finished with value: 49.34783643666925 and parameters: {'n_hidden': 3, 'learning_rate': 0.015798348902007757, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3624265284255866, 'dropout_rate_Layer_2': 0.12746485844575306, 'dropout_rate_Layer_3': 0.03298818851571833, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003395229725473529, 'l1_Layer_2': 0.0007854650678499396, 'l1_Layer_3': 0.017505096412109265, 'n_units_Layer_1': 115, 'n_units_Layer_2': 165, 'n_units_Layer_3': 275}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.35 | sMAPE for Validation Set is: 31.67% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 23.99 | sMAPE for Test Set is: 33.44% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:20:17,233]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:20:20,371]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:20:22,406]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:20:44,723]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:20:49,972]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:20:52,415]\u001b[0m Trial 196 finished with value: 50.692472958928825 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010475305534544935, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2608868105721712, 'dropout_rate_Layer_2': 0.01040880245829176, 'dropout_rate_Layer_3': 0.1462044017852919, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008257156010268554, 'l1_Layer_2': 0.007715363543419109, 'l1_Layer_3': 0.0010587192650910093, 'n_units_Layer_1': 140, 'n_units_Layer_2': 190, 'n_units_Layer_3': 245}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.69 | sMAPE for Validation Set is: 32.32% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 23.69 | sMAPE for Test Set is: 30.70% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:20:55,802]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:20:58,387]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:21:02,358]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:21:10,067]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:21:16,659]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:21:20,296]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:21:20,615]\u001b[0m Trial 193 finished with value: 49.15941778616311 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009886050123253587, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08970300928835814, 'dropout_rate_Layer_2': 0.36469608821202876, 'dropout_rate_Layer_3': 0.24913948909413935, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01990332358155954, 'l1_Layer_2': 0.0032820252118655477, 'l1_Layer_3': 1.003812740075889e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 250, 'n_units_Layer_3': 275}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.16 | sMAPE for Validation Set is: 31.79% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 21.82 | sMAPE for Test Set is: 30.02% | rMAE for Test Set is: 0.59\n",
      "MAE for Validation Set is: 48.27 | sMAPE for Validation Set is: 31.55% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 22.99 | sMAPE for Test Set is: 31.81% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:21:20,774]\u001b[0m Trial 195 finished with value: 48.26514447724812 and parameters: {'n_hidden': 3, 'learning_rate': 0.000982344462957637, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0384416320043145, 'dropout_rate_Layer_2': 0.3346367596484682, 'dropout_rate_Layer_3': 0.2942214369972554, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.007149265203864405, 'l1_Layer_2': 0.00284842858399057, 'l1_Layer_3': 0.00014656624363050284, 'n_units_Layer_1': 155, 'n_units_Layer_2': 260, 'n_units_Layer_3': 235}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:21:27,094]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:21:32,165]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:21:36,896]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:21:40,553]\u001b[0m Trial 202 finished with value: 50.74913406743241 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008760840270410172, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2601978287476345, 'dropout_rate_Layer_2': 0.005483816703808945, 'dropout_rate_Layer_3': 0.1422523641210384, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008833495795161833, 'l1_Layer_2': 0.0072237621882142306, 'l1_Layer_3': 0.000811168037354153, 'n_units_Layer_1': 135, 'n_units_Layer_2': 160, 'n_units_Layer_3': 240}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.75 | sMAPE for Validation Set is: 32.45% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 23.04 | sMAPE for Test Set is: 30.28% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:21:43,807]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:21:56,961]\u001b[0m Trial 210 finished with value: 48.26280443606902 and parameters: {'n_hidden': 3, 'learning_rate': 0.008050333391393208, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0021071959060127345, 'dropout_rate_Layer_2': 0.16605379655620015, 'dropout_rate_Layer_3': 0.12311849591841886, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006669139718300418, 'l1_Layer_2': 0.005439637087366726, 'l1_Layer_3': 0.019313290409304018, 'n_units_Layer_1': 75, 'n_units_Layer_2': 105, 'n_units_Layer_3': 245}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 48.26 | sMAPE for Validation Set is: 31.79% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 25.05 | sMAPE for Test Set is: 34.44% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:22:02,338]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:22:02,843]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:22:07,162]\u001b[0m Trial 207 finished with value: 48.62945435829073 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013120915744105983, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.040252979079509144, 'dropout_rate_Layer_2': 0.3924268239821298, 'dropout_rate_Layer_3': 0.2894201803693101, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.009815456794955713, 'l1_Layer_2': 0.005350383175828878, 'l1_Layer_3': 1.4561900250537772e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 275, 'n_units_Layer_3': 250}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 48.63 | sMAPE for Validation Set is: 31.92% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 23.25 | sMAPE for Test Set is: 32.10% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:22:08,576]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:22:12,546]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:22:13,240]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:22:18,137]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:22:18,837]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:22:19,672]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:22:25,502]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:22:30,634]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:22:31,412]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:22:40,952]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:22:44,104]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:22:49,249]\u001b[0m Trial 224 finished with value: 50.11877766293909 and parameters: {'n_hidden': 3, 'learning_rate': 0.017433835530268286, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.026848612479254606, 'dropout_rate_Layer_2': 0.1484080545486567, 'dropout_rate_Layer_3': 0.1691428359191178, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001008768819019819, 'l1_Layer_2': 0.000581048716868166, 'l1_Layer_3': 0.003972045365264841, 'n_units_Layer_1': 70, 'n_units_Layer_2': 100, 'n_units_Layer_3': 230}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.12 | sMAPE for Validation Set is: 31.95% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.07 | sMAPE for Test Set is: 33.28% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:22:51,731]\u001b[0m Trial 225 finished with value: 51.02680594351788 and parameters: {'n_hidden': 3, 'learning_rate': 0.013790679907491958, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03178164343257761, 'dropout_rate_Layer_2': 0.17645587186476375, 'dropout_rate_Layer_3': 0.07178557098072932, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015065840499732926, 'l1_Layer_2': 0.0006319316684341155, 'l1_Layer_3': 0.004900806020634009, 'n_units_Layer_1': 60, 'n_units_Layer_2': 105, 'n_units_Layer_3': 255}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.03 | sMAPE for Validation Set is: 32.08% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 23.38 | sMAPE for Test Set is: 32.09% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:22:54,812]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:22:57,807]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:22:59,452]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:23:00,249]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:23:05,656]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:23:10,998]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:23:15,147]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:23:21,742]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:23:24,512]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:23:30,661]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:23:31,335]\u001b[0m Trial 233 finished with value: 49.55926002039922 and parameters: {'n_hidden': 3, 'learning_rate': 0.005477836402885369, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32983072438421907, 'dropout_rate_Layer_2': 0.1339097607677236, 'dropout_rate_Layer_3': 0.1836893518646154, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003228471783966946, 'l1_Layer_2': 0.00030055466778378017, 'l1_Layer_3': 0.009450354767917432, 'n_units_Layer_1': 75, 'n_units_Layer_2': 90, 'n_units_Layer_3': 275}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.56 | sMAPE for Validation Set is: 32.59% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 26.72 | sMAPE for Test Set is: 36.44% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:23:37,703]\u001b[0m Trial 232 finished with value: 97.40662802213176 and parameters: {'n_hidden': 3, 'learning_rate': 0.0077824744336988895, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07510028750874076, 'dropout_rate_Layer_2': 0.25327897104135144, 'dropout_rate_Layer_3': 0.14226002177626076, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00017516237199044789, 'l1_Layer_2': 0.07798858587729088, 'l1_Layer_3': 0.00018190504183152918, 'n_units_Layer_1': 50, 'n_units_Layer_2': 135, 'n_units_Layer_3': 240}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 97.41 | sMAPE for Validation Set is: 51.04% | rMAE for Validation Set is: 1.06\n",
      "MAE for Test Set is: 27.89 | sMAPE for Test Set is: 33.23% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:23:38,508]\u001b[0m Trial 228 finished with value: 92.32720661764039 and parameters: {'n_hidden': 3, 'learning_rate': 0.0068486069274003416, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07488641653431473, 'dropout_rate_Layer_2': 0.2790147151070557, 'dropout_rate_Layer_3': 0.147026021090713, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00022485693525722158, 'l1_Layer_2': 0.07593697984340846, 'l1_Layer_3': 9.011012207756562e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 150, 'n_units_Layer_3': 240}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 92.33 | sMAPE for Validation Set is: 48.29% | rMAE for Validation Set is: 1.01\n",
      "MAE for Test Set is: 31.97 | sMAPE for Test Set is: 35.54% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:23:43,514]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:23:48,733]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:23:49,020]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:23:49,539]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:23:59,446]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:24:00,887]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:24:08,356]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:24:11,173]\u001b[0m Trial 241 finished with value: 49.42226553481828 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008022532778494309, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2577472964774043, 'dropout_rate_Layer_2': 0.005394600976113267, 'dropout_rate_Layer_3': 0.28204434097604036, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016590726289232212, 'l1_Layer_2': 0.007658581809592021, 'l1_Layer_3': 0.00018432463525297835, 'n_units_Layer_1': 135, 'n_units_Layer_2': 195, 'n_units_Layer_3': 200}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.42 | sMAPE for Validation Set is: 31.92% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 22.21 | sMAPE for Test Set is: 29.59% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:24:15,051]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:24:15,276]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:24:20,153]\u001b[0m Trial 249 finished with value: 50.82719781813813 and parameters: {'n_hidden': 3, 'learning_rate': 0.005215099125661292, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36434323973062743, 'dropout_rate_Layer_2': 0.11341787610436176, 'dropout_rate_Layer_3': 0.14835829862608108, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005621838435576806, 'l1_Layer_2': 0.0009967797546028986, 'l1_Layer_3': 0.007597747919161792, 'n_units_Layer_1': 100, 'n_units_Layer_2': 55, 'n_units_Layer_3': 275}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.83 | sMAPE for Validation Set is: 33.00% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 27.66 | sMAPE for Test Set is: 37.34% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:24:25,865]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:24:28,758]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:24:33,035]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:24:35,696]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:24:38,739]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:24:42,774]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:24:45,191]\u001b[0m Trial 245 finished with value: 49.62265186738258 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007968311739820913, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.268479890845833, 'dropout_rate_Layer_2': 0.006433975658260751, 'dropout_rate_Layer_3': 0.30615019701560775, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001465576148594275, 'l1_Layer_2': 0.011604262826329804, 'l1_Layer_3': 0.0005306613866773365, 'n_units_Layer_1': 140, 'n_units_Layer_2': 185, 'n_units_Layer_3': 200}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.62 | sMAPE for Validation Set is: 31.79% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 24.21 | sMAPE for Test Set is: 31.33% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:25:00,847]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:25:05,731]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:25:12,213]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:25:18,067]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 48.74 | sMAPE for Validation Set is: 32.37% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 26.52 | sMAPE for Test Set is: 35.80% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:25:28,113]\u001b[0m Trial 263 finished with value: 48.73934669809481 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032680542086064566, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.019392140683029455, 'dropout_rate_Layer_2': 0.12785994978894916, 'dropout_rate_Layer_3': 0.12894740801249205, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002444263595754472, 'l1_Layer_2': 0.0001666276266472072, 'l1_Layer_3': 0.003009571901429033, 'n_units_Layer_1': 70, 'n_units_Layer_2': 90, 'n_units_Layer_3': 290}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:25:35,538]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:25:39,067]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:25:42,794]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:25:49,549]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:25:52,898]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:25:55,057]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:25:56,333]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:26:06,035]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:26:16,741]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:26:21,505]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:26:26,139]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:26:35,521]\u001b[0m Trial 258 finished with value: 46.422830976393605 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009086512027031848, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08319846346310948, 'dropout_rate_Layer_2': 0.36080711663798837, 'dropout_rate_Layer_3': 0.18852751221416833, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006647566742691931, 'l1_Layer_2': 0.016941793205754847, 'l1_Layer_3': 0.0005309117193185599, 'n_units_Layer_1': 90, 'n_units_Layer_2': 240, 'n_units_Layer_3': 145}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.42 | sMAPE for Validation Set is: 30.82% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 21.33 | sMAPE for Test Set is: 29.55% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:26:41,294]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:26:44,077]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:26:48,652]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:26:52,645]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:26:57,099]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:27:01,095]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:27:12,200]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:27:15,090]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:27:17,928]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:27:21,517]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:27:26,367]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:27:26,824]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:27:31,497]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:27:31,939]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:27:38,938]\u001b[0m Trial 285 finished with value: 100.28225300530926 and parameters: {'n_hidden': 3, 'learning_rate': 0.013472078489743711, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11560906517162958, 'dropout_rate_Layer_2': 0.16565755284363784, 'dropout_rate_Layer_3': 0.38105096754254086, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.998259579676921e-05, 'l1_Layer_2': 0.0016121110067891977, 'l1_Layer_3': 0.02864121399636697, 'n_units_Layer_1': 130, 'n_units_Layer_2': 240, 'n_units_Layer_3': 260}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 100.28 | sMAPE for Validation Set is: 52.17% | rMAE for Validation Set is: 1.09\n",
      "MAE for Test Set is: 29.91 | sMAPE for Test Set is: 34.19% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:27:43,177]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:27:47,692]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:27:48,549]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:27:56,207]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:28:01,411]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:28:02,112]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:28:05,927]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:28:16,234]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:28:19,365]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:28:27,945]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:28:31,243]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:28:31,919]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:28:44,959]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:28:50,058]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:28:54,119]\u001b[0m Trial 295 finished with value: 88.4090407619882 and parameters: {'n_hidden': 4, 'learning_rate': 0.0036970527243831704, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18729471706357703, 'dropout_rate_Layer_2': 0.06926908045096286, 'dropout_rate_Layer_3': 0.24919892896638962, 'dropout_rate_Layer_4': 0.2514301801993235, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0015069956069252684, 'l1_Layer_2': 0.00011820048037121783, 'l1_Layer_3': 0.005206432180347679, 'l1_Layer_4': 0.09704684104861923, 'n_units_Layer_1': 215, 'n_units_Layer_2': 170, 'n_units_Layer_3': 105, 'n_units_Layer_4': 50}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 88.41 | sMAPE for Validation Set is: 47.12% | rMAE for Validation Set is: 0.96\n",
      "MAE for Test Set is: 25.95 | sMAPE for Test Set is: 34.84% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:28:57,285]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:28:59,727]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:29:03,089]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:29:13,061]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:29:16,628]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:29:21,992]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:29:28,300]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:29:28,997]\u001b[0m Trial 305 finished with value: 53.22487152629503 and parameters: {'n_hidden': 4, 'learning_rate': 0.003871901371471679, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0356898039076051, 'dropout_rate_Layer_2': 0.2799740218414837, 'dropout_rate_Layer_3': 0.2601684332920745, 'dropout_rate_Layer_4': 0.25277969636768566, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0006561543045868854, 'l1_Layer_2': 4.262289189430563e-05, 'l1_Layer_3': 0.004778698394748233, 'l1_Layer_4': 0.04723745594264431, 'n_units_Layer_1': 105, 'n_units_Layer_2': 115, 'n_units_Layer_3': 270, 'n_units_Layer_4': 65}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.22 | sMAPE for Validation Set is: 33.78% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 26.15 | sMAPE for Test Set is: 33.02% | rMAE for Test Set is: 0.71\n",
      "MAE for Validation Set is: 53.33 | sMAPE for Validation Set is: 33.23% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 24.84 | sMAPE for Test Set is: 32.34% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:29:33,396]\u001b[0m Trial 300 finished with value: 53.32986352977361 and parameters: {'n_hidden': 4, 'learning_rate': 0.004163004047564701, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03325214632439874, 'dropout_rate_Layer_2': 0.2824502946782194, 'dropout_rate_Layer_3': 0.001930024785819981, 'dropout_rate_Layer_4': 0.2518505104644092, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005273455873445009, 'l1_Layer_2': 6.0500873406539394e-05, 'l1_Layer_3': 0.005356993492542395, 'l1_Layer_4': 0.062047007883845914, 'n_units_Layer_1': 205, 'n_units_Layer_2': 105, 'n_units_Layer_3': 270, 'n_units_Layer_4': 50}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:29:36,593]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:29:37,200]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:29:38,130]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:29:43,864]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:29:45,537]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:29:52,808]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:29:55,406]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:30:14,762]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:30:16,717]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:30:18,367]\u001b[0m Trial 322 finished with value: 47.01649900057462 and parameters: {'n_hidden': 3, 'learning_rate': 0.001726496292136857, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09299759191542495, 'dropout_rate_Layer_2': 0.13395815906328865, 'dropout_rate_Layer_3': 0.21175487658246295, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00024146154577016718, 'l1_Layer_2': 0.0002945213761421451, 'l1_Layer_3': 0.010100663687668175, 'n_units_Layer_1': 80, 'n_units_Layer_2': 150, 'n_units_Layer_3': 220}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.02 | sMAPE for Validation Set is: 30.74% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 22.39 | sMAPE for Test Set is: 31.15% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:30:26,797]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:30:28,185]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:30:32,062]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:30:34,605]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:30:37,891]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:30:41,942]\u001b[0m Trial 319 finished with value: 48.04014845674708 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012622135410755406, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24176887068995176, 'dropout_rate_Layer_2': 0.3987301054033703, 'dropout_rate_Layer_3': 0.17255728259361325, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01821069207356886, 'l1_Layer_2': 0.002382814598888549, 'l1_Layer_3': 1.2529300047920993e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 240, 'n_units_Layer_3': 210}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 48.04 | sMAPE for Validation Set is: 31.57% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 22.22 | sMAPE for Test Set is: 30.69% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:30:42,699]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:30:49,745]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:30:56,265]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:31:05,051]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:31:14,747]\u001b[0m Trial 332 finished with value: 52.20821898023704 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015831172842194052, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.032943670757586724, 'dropout_rate_Layer_2': 0.284021716103011, 'dropout_rate_Layer_3': 0.29063367550751973, 'dropout_rate_Layer_4': 0.17152388233019394, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0004868568751999729, 'l1_Layer_2': 5.1106164347705436e-05, 'l1_Layer_3': 0.0006209989472115389, 'l1_Layer_4': 0.022980549951811632, 'n_units_Layer_1': 205, 'n_units_Layer_2': 105, 'n_units_Layer_3': 270, 'n_units_Layer_4': 90}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.21 | sMAPE for Validation Set is: 33.20% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 26.01 | sMAPE for Test Set is: 32.38% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:31:22,544]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:31:29,341]\u001b[0m Trial 326 finished with value: 46.82192964900139 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012134781320230993, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22510144745841115, 'dropout_rate_Layer_2': 0.38877007000724195, 'dropout_rate_Layer_3': 0.15372854250930096, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0035062556397912024, 'l1_Layer_2': 0.005070500971397348, 'l1_Layer_3': 2.784269635214022e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 280, 'n_units_Layer_3': 230}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.82 | sMAPE for Validation Set is: 31.10% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 21.66 | sMAPE for Test Set is: 30.24% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:31:35,600]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:31:39,199]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:31:43,199]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:31:43,886]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:31:49,950]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:31:50,159]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:31:50,500]\u001b[0m Trial 337 finished with value: 53.11154940721931 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017264391572245229, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0329906853041993, 'dropout_rate_Layer_2': 0.28367516804639153, 'dropout_rate_Layer_3': 0.30245164331492186, 'dropout_rate_Layer_4': 0.18127929083386501, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005550038251401092, 'l1_Layer_2': 5.103782223433012e-05, 'l1_Layer_3': 0.0005820152038071085, 'l1_Layer_4': 0.021826552534482745, 'n_units_Layer_1': 210, 'n_units_Layer_2': 105, 'n_units_Layer_3': 270, 'n_units_Layer_4': 85}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.11 | sMAPE for Validation Set is: 33.50% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 25.05 | sMAPE for Test Set is: 32.48% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:31:57,275]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:32:17,375]\u001b[0m Trial 339 finished with value: 48.56714720898486 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015766982450017887, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23713164416616297, 'dropout_rate_Layer_2': 0.3539230637912705, 'dropout_rate_Layer_3': 0.15596850438333984, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0134694677665897, 'l1_Layer_2': 0.001734489366075537, 'l1_Layer_3': 1.576382326470163e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 245, 'n_units_Layer_3': 215}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 48.57 | sMAPE for Validation Set is: 31.84% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 23.12 | sMAPE for Test Set is: 31.51% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:32:23,338]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:32:28,241]\u001b[0m Trial 346 finished with value: 53.69371675801954 and parameters: {'n_hidden': 4, 'learning_rate': 0.001908703797157805, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10056814788074722, 'dropout_rate_Layer_2': 0.24528225289434424, 'dropout_rate_Layer_3': 0.29835990302143306, 'dropout_rate_Layer_4': 0.1522238371567909, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00034078074364750306, 'l1_Layer_2': 1.8350999966071185e-05, 'l1_Layer_3': 0.000540186152153553, 'l1_Layer_4': 0.014985932579908675, 'n_units_Layer_1': 225, 'n_units_Layer_2': 65, 'n_units_Layer_3': 280, 'n_units_Layer_4': 95}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.69 | sMAPE for Validation Set is: 33.81% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 25.19 | sMAPE for Test Set is: 33.58% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:32:32,571]\u001b[0m Trial 347 finished with value: 53.12542250048515 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018717893653154335, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09924209954116446, 'dropout_rate_Layer_2': 0.2463223277221497, 'dropout_rate_Layer_3': 0.2987727239294063, 'dropout_rate_Layer_4': 0.15441029203476342, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 9.699465972134715e-05, 'l1_Layer_2': 2.033439279179587e-05, 'l1_Layer_3': 0.00047987514072585496, 'l1_Layer_4': 0.015686750800823084, 'n_units_Layer_1': 215, 'n_units_Layer_2': 50, 'n_units_Layer_3': 215, 'n_units_Layer_4': 95}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.13 | sMAPE for Validation Set is: 33.48% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 24.92 | sMAPE for Test Set is: 32.51% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:32:32,826]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:32:35,157]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:32:41,871]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:32:47,756]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:32:56,261]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:32:58,223]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:33:01,728]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:33:02,039]\u001b[0m Trial 348 finished with value: 52.51685902487634 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016318253677103198, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10178427823863374, 'dropout_rate_Layer_2': 0.322587573573466, 'dropout_rate_Layer_3': 0.3492040760594596, 'dropout_rate_Layer_4': 0.0035313953860620084, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0001139245587526366, 'l1_Layer_2': 1.0765390002889847e-05, 'l1_Layer_3': 0.00040400476074770205, 'l1_Layer_4': 0.015412014879954208, 'n_units_Layer_1': 210, 'n_units_Layer_2': 60, 'n_units_Layer_3': 280, 'n_units_Layer_4': 100}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.52 | sMAPE for Validation Set is: 33.19% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 25.29 | sMAPE for Test Set is: 32.68% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:33:07,944]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:33:11,851]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:33:12,477]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:33:14,860]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:33:17,451]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:33:17,648]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:33:23,236]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:33:25,546]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:33:26,353]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:33:28,916]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:33:31,975]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:33:34,011]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:33:37,257]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:33:38,227]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:33:39,401]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:33:45,259]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:33:51,266]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:33:56,694]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:34:00,978]\u001b[0m Trial 374 finished with value: 52.63768903361574 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026292173100889633, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21678736145790703, 'dropout_rate_Layer_2': 0.29030393568180546, 'dropout_rate_Layer_3': 0.2664080817896369, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.016935692491724455, 'l1_Layer_2': 0.010643326917198208, 'l1_Layer_3': 0.002077731096532234, 'n_units_Layer_1': 230, 'n_units_Layer_2': 155, 'n_units_Layer_3': 285}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.64 | sMAPE for Validation Set is: 33.39% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 24.69 | sMAPE for Test Set is: 32.13% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:34:06,132]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:34:08,932]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:34:09,845]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:34:15,725]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:34:31,255]\u001b[0m Trial 381 finished with value: 47.11061433262492 and parameters: {'n_hidden': 3, 'learning_rate': 0.004749615425009415, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.011604120489910257, 'dropout_rate_Layer_2': 0.15316592301337714, 'dropout_rate_Layer_3': 0.013228302389288682, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007039237541234397, 'l1_Layer_2': 0.0002727422852805644, 'l1_Layer_3': 0.006459820255748312, 'n_units_Layer_1': 75, 'n_units_Layer_2': 125, 'n_units_Layer_3': 295}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.11 | sMAPE for Validation Set is: 31.25% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 23.20 | sMAPE for Test Set is: 32.44% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:34:34,971]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:34:37,445]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:34:41,803]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:34:44,781]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:34:53,929]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:34:58,560]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:34:59,130]\u001b[0m Trial 368 finished with value: 46.28899633523139 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008681118428704563, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.032634592936666, 'dropout_rate_Layer_2': 0.1970732402255465, 'dropout_rate_Layer_3': 0.16673736512866982, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.010652160198917661, 'l1_Layer_2': 0.011968590110898512, 'l1_Layer_3': 1.4432908449938696e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 245, 'n_units_Layer_3': 265}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.29 | sMAPE for Validation Set is: 30.76% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 21.23 | sMAPE for Test Set is: 29.65% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:35:03,184]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:35:03,836]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:35:03,924]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:35:08,865]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:35:10,433]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:35:13,416]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:35:13,579]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:35:14,722]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:35:21,978]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:35:22,959]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:35:24,302]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:35:25,101]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:35:32,371]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:35:34,795]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:35:36,687]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:35:38,079]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:35:39,388]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:35:46,454]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:35:52,332]\u001b[0m Trial 405 finished with value: 49.09618097280546 and parameters: {'n_hidden': 3, 'learning_rate': 0.008473022620217267, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3486675695249042, 'dropout_rate_Layer_2': 0.1366385260027189, 'dropout_rate_Layer_3': 0.04238338483382586, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00024563493027470736, 'l1_Layer_2': 0.0008432214429720196, 'l1_Layer_3': 0.0064981313437257, 'n_units_Layer_1': 65, 'n_units_Layer_2': 125, 'n_units_Layer_3': 295}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.10 | sMAPE for Validation Set is: 31.85% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 24.31 | sMAPE for Test Set is: 33.20% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:35:56,785]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:36:19,362]\u001b[0m Trial 407 finished with value: 53.398082773232595 and parameters: {'n_hidden': 4, 'learning_rate': 0.001351692219803961, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05087499007030755, 'dropout_rate_Layer_2': 0.3010146360905497, 'dropout_rate_Layer_3': 0.2885080286070835, 'dropout_rate_Layer_4': 0.027611860266713195, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 9.61824812376031e-05, 'l1_Layer_2': 1.1456686753644785e-05, 'l1_Layer_3': 0.0008868424177674839, 'l1_Layer_4': 0.021880244400978785, 'n_units_Layer_1': 240, 'n_units_Layer_2': 80, 'n_units_Layer_3': 275, 'n_units_Layer_4': 80}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.40 | sMAPE for Validation Set is: 33.65% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 24.99 | sMAPE for Test Set is: 33.15% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:36:22,984]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:36:23,377]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:36:28,927]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:36:32,509]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:37:39,685]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:37:47,575]\u001b[0m Trial 416 finished with value: 47.34247661156237 and parameters: {'n_hidden': 3, 'learning_rate': 0.000726562254473306, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0820427747786442, 'dropout_rate_Layer_2': 0.38971093486282143, 'dropout_rate_Layer_3': 0.25587415863427365, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005658657347938468, 'l1_Layer_2': 0.0026839911474125034, 'l1_Layer_3': 0.00036320993569609203, 'n_units_Layer_1': 175, 'n_units_Layer_2': 230, 'n_units_Layer_3': 205}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.34 | sMAPE for Validation Set is: 31.36% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 21.94 | sMAPE for Test Set is: 30.57% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:37:53,918]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:37:57,581]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:38:00,552]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:38:01,873]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:38:03,301]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:38:03,716]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:38:08,069]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:38:10,030]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:38:10,658]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:38:15,323]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:38:16,171]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:38:16,674]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:38:20,588]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:38:25,073]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:38:25,736]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:38:42,607]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:38:42,846]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:38:47,360]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:38:47,848]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.18 | sMAPE for Validation Set is: 31.01% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 21.08 | sMAPE for Test Set is: 29.69% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:38:52,177]\u001b[0m Trial 430 finished with value: 46.17546934435328 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020365782652604666, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18968335215179483, 'dropout_rate_Layer_2': 0.015933759847411393, 'dropout_rate_Layer_3': 0.15544350644971838, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00619501151445849, 'l1_Layer_2': 0.000470571749879214, 'l1_Layer_3': 0.00025576370101297455, 'n_units_Layer_1': 120, 'n_units_Layer_2': 175, 'n_units_Layer_3': 230}. Best is trial 90 with value: 45.540389431089274.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:38:52,358]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:38:53,561]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:38:58,856]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:39:01,791]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:39:04,486]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:39:05,023]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:39:07,278]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:39:11,371]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:39:15,106]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:39:18,482]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:39:21,308]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:39:36,504]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:39:39,680]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:39:41,833]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:39:45,422]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:39:48,975]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:39:49,716]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:39:55,046]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:39:55,497]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:40:02,519]\u001b[0m Trial 444 finished with value: 45.21091898386815 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011027508641734973, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19283299396188197, 'dropout_rate_Layer_2': 0.011879727957779501, 'dropout_rate_Layer_3': 0.15983966674088027, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002897565142901893, 'l1_Layer_2': 0.0005360510631913101, 'l1_Layer_3': 0.00034070951496082585, 'n_units_Layer_1': 115, 'n_units_Layer_2': 205, 'n_units_Layer_3': 235}. Best is trial 444 with value: 45.21091898386815.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.21 | sMAPE for Validation Set is: 30.47% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 20.50 | sMAPE for Test Set is: 29.18% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:40:04,969]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:40:05,687]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:40:11,591]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:40:13,652]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:40:16,861]\u001b[0m Trial 449 finished with value: 82.37075882997925 and parameters: {'n_hidden': 4, 'learning_rate': 0.002674333482647096, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3924421690013157, 'dropout_rate_Layer_2': 0.22231366391083104, 'dropout_rate_Layer_3': 0.23625829427280318, 'dropout_rate_Layer_4': 0.11296337141365771, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00013620064746052758, 'l1_Layer_2': 7.593799781378536e-05, 'l1_Layer_3': 0.0008071908683580973, 'l1_Layer_4': 0.022398653174201012, 'n_units_Layer_1': 260, 'n_units_Layer_2': 150, 'n_units_Layer_3': 285, 'n_units_Layer_4': 115}. Best is trial 444 with value: 45.21091898386815.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 82.37 | sMAPE for Validation Set is: 43.54% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 27.74 | sMAPE for Test Set is: 33.23% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:40:17,658]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:40:24,164]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:40:25,734]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:40:30,974]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:40:34,778]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:40:44,398]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:40:49,367]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:40:54,505]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:40:54,603]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:41:01,627]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:41:06,248]\u001b[0m Trial 462 finished with value: 47.468536468524654 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013581153309199852, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24603021468097422, 'dropout_rate_Layer_2': 0.3780730678183306, 'dropout_rate_Layer_3': 0.25476840591645933, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00691606551456328, 'l1_Layer_2': 0.004930515359111247, 'l1_Layer_3': 0.0002634675602780571, 'n_units_Layer_1': 135, 'n_units_Layer_2': 245, 'n_units_Layer_3': 215}. Best is trial 444 with value: 45.21091898386815.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.47 | sMAPE for Validation Set is: 31.43% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 22.63 | sMAPE for Test Set is: 31.23% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:41:06,956]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:41:07,137]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:41:12,561]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:41:14,745]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:41:16,846]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:41:17,294]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:41:20,037]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:41:23,875]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:41:24,072]\u001b[0m Trial 467 finished with value: 45.096161900018394 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011422271479720508, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.160763099503895, 'dropout_rate_Layer_2': 0.0023720481986848826, 'dropout_rate_Layer_3': 0.1597198503771237, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0020080706194783265, 'l1_Layer_2': 0.00012384832837514196, 'l1_Layer_3': 0.000166319788650841, 'n_units_Layer_1': 120, 'n_units_Layer_2': 190, 'n_units_Layer_3': 210}. Best is trial 467 with value: 45.096161900018394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.10 | sMAPE for Validation Set is: 30.45% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 20.41 | sMAPE for Test Set is: 28.97% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:41:31,033]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:41:31,667]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:41:35,135]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:41:36,071]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:41:36,956]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:41:41,501]\u001b[0m Trial 479 finished with value: 49.15048608417201 and parameters: {'n_hidden': 3, 'learning_rate': 0.005393970284473846, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34256486000114783, 'dropout_rate_Layer_2': 0.11192824176264365, 'dropout_rate_Layer_3': 0.15338018892580108, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005774026059296466, 'l1_Layer_2': 0.000954982722593527, 'l1_Layer_3': 0.006321477245291688, 'n_units_Layer_1': 100, 'n_units_Layer_2': 80, 'n_units_Layer_3': 285}. Best is trial 467 with value: 45.096161900018394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.15 | sMAPE for Validation Set is: 31.92% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 25.53 | sMAPE for Test Set is: 34.84% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:41:41,914]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:41:45,746]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:41:50,454]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:41:50,962]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:41:56,660]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:41:58,713]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:42:02,452]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:42:04,570]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:42:07,208]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:42:07,891]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:42:09,576]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:42:13,370]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:42:15,013]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:42:16,042]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:42:18,453]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:42:20,765]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:42:24,563]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:42:27,178]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:42:30,286]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:42:31,242]\u001b[0m Trial 487 finished with value: 60.66241983054514 and parameters: {'n_hidden': 4, 'learning_rate': 0.005168859226731908, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08609607080812465, 'dropout_rate_Layer_2': 0.19575751446643855, 'dropout_rate_Layer_3': 0.28612445165701156, 'dropout_rate_Layer_4': 0.19351711721046266, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00026841511151917994, 'l1_Layer_2': 2.173049532845759e-05, 'l1_Layer_3': 0.00033279013238806765, 'l1_Layer_4': 0.006562872771591059, 'n_units_Layer_1': 225, 'n_units_Layer_2': 270, 'n_units_Layer_3': 225, 'n_units_Layer_4': 75}. Best is trial 467 with value: 45.096161900018394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 60.66 | sMAPE for Validation Set is: 37.01% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 29.79 | sMAPE for Test Set is: 39.75% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:42:31,441]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:42:36,102]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:42:37,157]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:42:39,328]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:42:43,614]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:42:47,427]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:42:47,714]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:42:48,327]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:42:48,841]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:42:57,505]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:42:57,883]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:42:57,929]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:43:07,294]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:43:11,721]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:43:17,308]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:43:22,454]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:43:26,620]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:43:35,364]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:43:39,577]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:43:44,177]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:43:48,543]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:43:52,860]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:43:55,477]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:43:58,610]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:44:02,976]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:44:06,137]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:44:10,419]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:44:16,997]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:44:20,893]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:44:25,043]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:44:27,433]\u001b[0m Trial 532 finished with value: 46.435492308681454 and parameters: {'n_hidden': 3, 'learning_rate': 0.002068379978719566, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2571764172370064, 'dropout_rate_Layer_2': 0.030720971183336054, 'dropout_rate_Layer_3': 0.15500676347111209, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001586055510425259, 'l1_Layer_2': 4.3765982535985784e-05, 'l1_Layer_3': 6.054444125735202e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 190, 'n_units_Layer_3': 215}. Best is trial 467 with value: 45.096161900018394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.44 | sMAPE for Validation Set is: 31.23% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 21.63 | sMAPE for Test Set is: 29.97% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:44:31,379]\u001b[0m Trial 525 finished with value: 48.45944468206701 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011499921627635304, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33027948422638903, 'dropout_rate_Layer_2': 0.014944010727991092, 'dropout_rate_Layer_3': 0.16876436188552546, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01475335036334685, 'l1_Layer_2': 0.0025370860385924426, 'l1_Layer_3': 1.0013051527176413e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 255, 'n_units_Layer_3': 270}. Best is trial 467 with value: 45.096161900018394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 48.46 | sMAPE for Validation Set is: 31.46% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 21.48 | sMAPE for Test Set is: 29.55% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:44:32,027]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:44:37,786]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:44:38,783]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:44:45,464]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:44:45,620]\u001b[0m Trial 540 finished with value: 49.744926889310115 and parameters: {'n_hidden': 3, 'learning_rate': 0.007470984908193407, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01821134968999885, 'dropout_rate_Layer_2': 0.13678919950644938, 'dropout_rate_Layer_3': 0.04397394672826435, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00018188426087520089, 'l1_Layer_2': 0.0008090231478253869, 'l1_Layer_3': 0.005181242950329494, 'n_units_Layer_1': 75, 'n_units_Layer_2': 110, 'n_units_Layer_3': 290}. Best is trial 467 with value: 45.096161900018394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.74 | sMAPE for Validation Set is: 32.19% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 25.40 | sMAPE for Test Set is: 34.27% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:44:52,018]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:44:52,136]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:44:53,330]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:44:57,265]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:45:00,238]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:45:01,377]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:45:03,501]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:45:08,339]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:45:10,092]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:45:10,411]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:45:12,852]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:45:17,407]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:45:17,876]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:45:25,028]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:45:26,067]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:45:30,220]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:45:31,966]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:45:35,612]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:45:37,978]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:45:41,390]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:45:43,778]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:45:47,025]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:45:49,623]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:45:52,961]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:45:53,218]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:45:53,806]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:46:02,130]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:46:02,714]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:46:08,899]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:46:09,202]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:46:15,621]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:46:16,468]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:46:22,682]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:46:29,027]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:46:32,617]\u001b[0m Trial 518 finished with value: 80.8155717905096 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008263693542906343, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.018768032675266444, 'dropout_rate_Layer_2': 0.23434400295828445, 'dropout_rate_Layer_3': 0.33112345045809544, 'dropout_rate_Layer_4': 0.3154530177488557, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0011380200716985143, 'l1_Layer_2': 0.0001772785178537765, 'l1_Layer_3': 0.0920363993068912, 'l1_Layer_4': 0.009362376168249285, 'n_units_Layer_1': 180, 'n_units_Layer_2': 100, 'n_units_Layer_3': 200, 'n_units_Layer_4': 150}. Best is trial 467 with value: 45.096161900018394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 80.82 | sMAPE for Validation Set is: 43.23% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 26.29 | sMAPE for Test Set is: 34.25% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:46:37,631]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:46:40,253]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:46:46,424]\u001b[0m Trial 578 finished with value: 47.20758260564375 and parameters: {'n_hidden': 3, 'learning_rate': 0.004597396665896182, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.029715480246084912, 'dropout_rate_Layer_2': 0.02866768628398651, 'dropout_rate_Layer_3': 0.029140385555049456, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004666065757840544, 'l1_Layer_2': 0.0003368608258957502, 'l1_Layer_3': 0.014840388527138617, 'n_units_Layer_1': 115, 'n_units_Layer_2': 150, 'n_units_Layer_3': 270}. Best is trial 467 with value: 45.096161900018394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.21 | sMAPE for Validation Set is: 31.15% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 23.76 | sMAPE for Test Set is: 32.86% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:46:47,224]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:46:52,888]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:46:55,408]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:46:56,058]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:47:01,106]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:47:06,665]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:47:10,706]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:47:15,267]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:47:19,085]\u001b[0m Trial 586 finished with value: 47.37041270838739 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034143781461950674, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.001547519648252919, 'dropout_rate_Layer_2': 0.009181983327256775, 'dropout_rate_Layer_3': 0.008195880699485198, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005237710298198711, 'l1_Layer_2': 0.0003489818390023084, 'l1_Layer_3': 0.009183821013269464, 'n_units_Layer_1': 115, 'n_units_Layer_2': 150, 'n_units_Layer_3': 265}. Best is trial 467 with value: 45.096161900018394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.37 | sMAPE for Validation Set is: 30.76% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 22.12 | sMAPE for Test Set is: 30.27% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:47:20,425]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:47:31,895]\u001b[0m Trial 571 finished with value: 71.4565252246082 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007173487888086615, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.019053326727801436, 'dropout_rate_Layer_2': 0.2574796063126002, 'dropout_rate_Layer_3': 0.32666540973107616, 'dropout_rate_Layer_4': 6.529992621042216e-05, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0009951629648802796, 'l1_Layer_2': 0.00021773731780871795, 'l1_Layer_3': 0.09798725480876797, 'l1_Layer_4': 0.009292159544535272, 'n_units_Layer_1': 180, 'n_units_Layer_2': 100, 'n_units_Layer_3': 255, 'n_units_Layer_4': 140}. Best is trial 467 with value: 45.096161900018394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 71.46 | sMAPE for Validation Set is: 38.91% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 24.76 | sMAPE for Test Set is: 31.96% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:47:36,181]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:47:40,307]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:47:44,436]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:47:50,289]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:47:54,579]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:47:57,940]\u001b[0m Trial 598 finished with value: 112.13773936752945 and parameters: {'n_hidden': 4, 'learning_rate': 0.05264238960365555, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.052143863893772, 'dropout_rate_Layer_2': 0.37803753736958884, 'dropout_rate_Layer_3': 0.3088778791616573, 'dropout_rate_Layer_4': 0.04739491584105949, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 7.240423260638365e-05, 'l1_Layer_2': 4.9662574284852196e-05, 'l1_Layer_3': 4.114493275752533e-05, 'l1_Layer_4': 0.0012765797497320346, 'n_units_Layer_1': 200, 'n_units_Layer_2': 205, 'n_units_Layer_3': 160, 'n_units_Layer_4': 80}. Best is trial 467 with value: 45.096161900018394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 112.14 | sMAPE for Validation Set is: 58.27% | rMAE for Validation Set is: 1.22\n",
      "MAE for Test Set is: 31.99 | sMAPE for Test Set is: 36.55% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:48:02,401]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:48:02,721]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:48:09,133]\u001b[0m Trial 594 finished with value: 55.29165677004908 and parameters: {'n_hidden': 4, 'learning_rate': 0.04251545449875713, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05015234132331034, 'dropout_rate_Layer_2': 0.26182951703247626, 'dropout_rate_Layer_3': 0.3167524255959749, 'dropout_rate_Layer_4': 0.04458739767689682, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 7.58632298542963e-05, 'l1_Layer_2': 1.7580685623052982e-05, 'l1_Layer_3': 5.0375572345610065e-05, 'l1_Layer_4': 0.003077325961916393, 'n_units_Layer_1': 195, 'n_units_Layer_2': 205, 'n_units_Layer_3': 165, 'n_units_Layer_4': 90}. Best is trial 467 with value: 45.096161900018394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.29 | sMAPE for Validation Set is: 34.02% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 25.12 | sMAPE for Test Set is: 31.57% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:48:13,787]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:48:17,328]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:48:18,388]\u001b[0m Trial 589 finished with value: 55.54304519348748 and parameters: {'n_hidden': 4, 'learning_rate': 0.04667474571589739, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05568731885343639, 'dropout_rate_Layer_2': 0.2677617076020846, 'dropout_rate_Layer_3': 0.31555712055464663, 'dropout_rate_Layer_4': 0.2133716100311806, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 7.851106403003343e-05, 'l1_Layer_2': 1.7812937863003985e-05, 'l1_Layer_3': 2.8166819894979025e-05, 'l1_Layer_4': 0.004740782037853672, 'n_units_Layer_1': 195, 'n_units_Layer_2': 205, 'n_units_Layer_3': 230, 'n_units_Layer_4': 85}. Best is trial 467 with value: 45.096161900018394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.54 | sMAPE for Validation Set is: 33.80% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 25.90 | sMAPE for Test Set is: 32.48% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:48:22,504]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:48:22,791]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:48:25,051]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:48:29,773]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:48:50,520]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:48:51,521]\u001b[0m Trial 603 finished with value: 53.50744010750808 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013563010263763836, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27492713091839455, 'dropout_rate_Layer_2': 0.3005444592968963, 'dropout_rate_Layer_3': 0.39742278461427977, 'dropout_rate_Layer_4': 0.17276328216789774, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0032675115689835095, 'l1_Layer_2': 1.4819459953914994e-05, 'l1_Layer_3': 0.00028808943234605116, 'l1_Layer_4': 0.0035094581514725914, 'n_units_Layer_1': 160, 'n_units_Layer_2': 50, 'n_units_Layer_3': 285, 'n_units_Layer_4': 105}. Best is trial 467 with value: 45.096161900018394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.51 | sMAPE for Validation Set is: 33.67% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 24.72 | sMAPE for Test Set is: 32.11% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:48:55,865]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:49:02,507]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:49:06,125]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:49:23,154]\u001b[0m Trial 610 finished with value: 53.3371140706295 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013095247129781499, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09446994843631296, 'dropout_rate_Layer_2': 0.2952239266311177, 'dropout_rate_Layer_3': 0.2813156206179512, 'dropout_rate_Layer_4': 0.16102636650270674, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0001907754477866786, 'l1_Layer_2': 3.12172031391167e-05, 'l1_Layer_3': 0.0005258060830372542, 'l1_Layer_4': 0.01563484015740626, 'n_units_Layer_1': 225, 'n_units_Layer_2': 55, 'n_units_Layer_3': 285, 'n_units_Layer_4': 110}. Best is trial 467 with value: 45.096161900018394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.34 | sMAPE for Validation Set is: 33.57% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 24.66 | sMAPE for Test Set is: 33.02% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:49:27,063]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:49:33,610]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:49:37,325]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:49:46,979]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:49:52,363]\u001b[0m Trial 616 finished with value: 54.44554055945167 and parameters: {'n_hidden': 4, 'learning_rate': 0.0021117432328916935, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16717026835319174, 'dropout_rate_Layer_2': 0.2190424270961337, 'dropout_rate_Layer_3': 0.2769642867521645, 'dropout_rate_Layer_4': 0.1525263859967929, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005158736995923196, 'l1_Layer_2': 2.9056401296897474e-05, 'l1_Layer_3': 0.0005387447445437213, 'l1_Layer_4': 0.015088385879420742, 'n_units_Layer_1': 215, 'n_units_Layer_2': 50, 'n_units_Layer_3': 265, 'n_units_Layer_4': 110}. Best is trial 467 with value: 45.096161900018394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.45 | sMAPE for Validation Set is: 34.32% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 26.13 | sMAPE for Test Set is: 33.53% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:50:00,167]\u001b[0m Trial 611 finished with value: 53.14870294918117 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013812710695491003, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16738661672609934, 'dropout_rate_Layer_2': 0.22021078278179854, 'dropout_rate_Layer_3': 0.2840225304872353, 'dropout_rate_Layer_4': 0.1616007998647755, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0004632144882334898, 'l1_Layer_2': 2.9227191952658117e-05, 'l1_Layer_3': 0.000653190653996115, 'l1_Layer_4': 0.015547003545695413, 'n_units_Layer_1': 215, 'n_units_Layer_2': 55, 'n_units_Layer_3': 285, 'n_units_Layer_4': 110}. Best is trial 467 with value: 45.096161900018394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.15 | sMAPE for Validation Set is: 33.23% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 25.69 | sMAPE for Test Set is: 32.54% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:50:09,314]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:50:12,323]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:50:14,806]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:50:18,812]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:50:20,689]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:50:24,822]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:50:28,670]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:50:29,465]\u001b[0m Trial 613 finished with value: 53.275782244898096 and parameters: {'n_hidden': 4, 'learning_rate': 0.0021660421464450887, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16237935818908344, 'dropout_rate_Layer_2': 0.22443091138636911, 'dropout_rate_Layer_3': 0.3442952264241984, 'dropout_rate_Layer_4': 0.150407584627657, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00043982071723021353, 'l1_Layer_2': 4.0561617921437244e-05, 'l1_Layer_3': 0.000592221490358195, 'l1_Layer_4': 0.01576258023920151, 'n_units_Layer_1': 215, 'n_units_Layer_2': 50, 'n_units_Layer_3': 205, 'n_units_Layer_4': 110}. Best is trial 467 with value: 45.096161900018394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.28 | sMAPE for Validation Set is: 33.34% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 27.15 | sMAPE for Test Set is: 33.57% | rMAE for Test Set is: 0.74\n",
      "MAE for Validation Set is: 52.54 | sMAPE for Validation Set is: 33.28% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 24.19 | sMAPE for Test Set is: 32.49% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:50:29,547]\u001b[0m Trial 621 finished with value: 52.54142531146772 and parameters: {'n_hidden': 4, 'learning_rate': 0.0021624396658720406, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12193147729664092, 'dropout_rate_Layer_2': 0.0010442805222030558, 'dropout_rate_Layer_3': 0.34314918401189165, 'dropout_rate_Layer_4': 0.11234694509274185, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0008323756945324663, 'l1_Layer_2': 2.66946090911092e-05, 'l1_Layer_3': 0.0007176420077855127, 'l1_Layer_4': 0.03434457220439355, 'n_units_Layer_1': 220, 'n_units_Layer_2': 70, 'n_units_Layer_3': 200, 'n_units_Layer_4': 100}. Best is trial 467 with value: 45.096161900018394.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:50:36,394]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:50:40,015]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:50:43,024]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:50:44,915]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:50:46,961]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:50:49,139]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:50:49,480]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:50:50,050]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:50:51,849]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:50:58,164]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:51:02,194]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:51:02,261]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:51:03,702]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:51:08,884]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:51:12,630]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:51:17,633]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:51:17,756]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:51:20,459]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:51:24,923]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:51:27,706]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:51:30,734]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:51:31,453]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:51:31,470]\u001b[0m Trial 638 finished with value: 45.858185132805204 and parameters: {'n_hidden': 3, 'learning_rate': 0.002425696811435662, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23149581883570855, 'dropout_rate_Layer_2': 0.22649615004287182, 'dropout_rate_Layer_3': 0.3614293355739869, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010086718763593627, 'l1_Layer_2': 0.0008975909309315797, 'l1_Layer_3': 0.0002581438631295847, 'n_units_Layer_1': 105, 'n_units_Layer_2': 190, 'n_units_Layer_3': 215}. Best is trial 467 with value: 45.096161900018394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.86 | sMAPE for Validation Set is: 30.77% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 21.97 | sMAPE for Test Set is: 29.65% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:51:31,828]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:51:40,710]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:51:40,904]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:51:41,847]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:51:49,242]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:51:50,116]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:51:50,213]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:51:51,193]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:51:57,928]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:52:01,592]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:52:02,406]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:52:04,861]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:52:09,058]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:52:11,937]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:52:12,401]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:52:14,073]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:52:16,253]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:52:18,307]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:52:19,462]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:52:25,948]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:52:26,216]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:52:26,723]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:52:33,410]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:52:34,250]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:52:36,636]\u001b[0m Trial 664 finished with value: 46.68307843894266 and parameters: {'n_hidden': 3, 'learning_rate': 0.0041113973248347885, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2748388823021203, 'dropout_rate_Layer_2': 0.2594180108219391, 'dropout_rate_Layer_3': 0.354692305686597, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006170921334977919, 'l1_Layer_2': 0.0007441220104840501, 'l1_Layer_3': 0.00022836657417351985, 'n_units_Layer_1': 120, 'n_units_Layer_2': 190, 'n_units_Layer_3': 220}. Best is trial 467 with value: 45.096161900018394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.68 | sMAPE for Validation Set is: 31.23% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 21.79 | sMAPE for Test Set is: 30.39% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:52:42,766]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:52:43,062]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:52:49,445]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:52:51,537]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:52:51,876]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:52:57,369]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:53:00,794]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:53:04,147]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:53:04,328]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:53:05,547]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:53:05,863]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:53:13,131]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:53:13,771]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:53:14,323]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:53:14,370]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:53:18,027]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:53:21,430]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:53:23,782]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:53:23,912]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:53:26,013]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:53:31,069]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:53:34,425]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:53:36,920]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:53:38,898]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:53:39,430]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:53:40,428]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:53:42,990]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:53:44,383]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:53:48,656]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:53:50,402]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:53:52,587]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:53:55,959]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:53:57,046]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:53:57,198]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:54:00,397]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:54:05,488]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:54:06,169]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:54:09,752]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:54:13,060]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:54:15,644]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:54:16,153]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:54:17,022]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:54:21,881]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:54:23,901]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:54:26,811]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:54:31,195]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:55:02,705]\u001b[0m Trial 722 finished with value: 54.010397753950826 and parameters: {'n_hidden': 4, 'learning_rate': 0.001664263019298933, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0915669415283234, 'dropout_rate_Layer_2': 0.03789792222220547, 'dropout_rate_Layer_3': 0.30844970087207135, 'dropout_rate_Layer_4': 0.08351574850307289, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0001259627581437549, 'l1_Layer_2': 2.340678453577029e-05, 'l1_Layer_3': 0.0003682095080905413, 'l1_Layer_4': 0.036993056057277277, 'n_units_Layer_1': 205, 'n_units_Layer_2': 65, 'n_units_Layer_3': 175, 'n_units_Layer_4': 95}. Best is trial 467 with value: 45.096161900018394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.01 | sMAPE for Validation Set is: 34.03% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 26.39 | sMAPE for Test Set is: 33.61% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:55:04,904]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:55:11,041]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:55:16,673]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:55:21,153]\u001b[0m Trial 726 finished with value: 53.462278209869204 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016542118832489393, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08824010395567855, 'dropout_rate_Layer_2': 0.09827352058862954, 'dropout_rate_Layer_3': 0.3070089290969233, 'dropout_rate_Layer_4': 0.1806059555959127, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0001233059527147872, 'l1_Layer_2': 2.033274552014186e-05, 'l1_Layer_3': 0.0003730204096737549, 'l1_Layer_4': 0.031040181063824376, 'n_units_Layer_1': 170, 'n_units_Layer_2': 65, 'n_units_Layer_3': 220, 'n_units_Layer_4': 95}. Best is trial 467 with value: 45.096161900018394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.46 | sMAPE for Validation Set is: 33.58% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 26.39 | sMAPE for Test Set is: 33.39% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:55:23,527]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:55:33,710]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:55:37,533]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:55:40,150]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.94 | sMAPE for Validation Set is: 33.45% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 25.37 | sMAPE for Test Set is: 32.62% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:55:40,708]\u001b[0m Trial 727 finished with value: 52.94093014249589 and parameters: {'n_hidden': 4, 'learning_rate': 0.0025549466410148673, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13660028054843873, 'dropout_rate_Layer_2': 0.09985128639871033, 'dropout_rate_Layer_3': 0.3312014673223914, 'dropout_rate_Layer_4': 0.22650068091218592, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00033224649725944317, 'l1_Layer_2': 5.165966822254923e-05, 'l1_Layer_3': 0.0010995674855502117, 'l1_Layer_4': 0.009064698928857012, 'n_units_Layer_1': 170, 'n_units_Layer_2': 90, 'n_units_Layer_3': 200, 'n_units_Layer_4': 70}. Best is trial 467 with value: 45.096161900018394.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:55:46,423]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:55:49,469]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:55:50,223]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:55:51,946]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:55:58,222]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:56:02,685]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:56:03,136]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:56:08,847]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:56:09,581]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:56:14,249]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:56:19,085]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:56:21,438]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:56:21,936]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:56:27,954]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:56:31,093]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:56:35,425]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:56:35,573]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:56:36,711]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:56:42,018]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:56:45,907]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:56:50,212]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:56:51,527]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:56:51,621]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:56:57,799]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:57:02,046]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:57:02,317]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:57:07,109]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:57:10,342]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:57:13,861]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:57:14,728]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:57:14,962]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:57:23,261]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:57:29,041]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:57:29,219]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:57:35,027]\u001b[0m Trial 756 finished with value: 54.32400668461229 and parameters: {'n_hidden': 4, 'learning_rate': 0.002546854841843832, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1450065557329989, 'dropout_rate_Layer_2': 0.13133036250088595, 'dropout_rate_Layer_3': 0.3331777690620463, 'dropout_rate_Layer_4': 0.2292965248092191, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0003375979677614489, 'l1_Layer_2': 5.742360600094494e-05, 'l1_Layer_3': 0.001096724518129792, 'l1_Layer_4': 1.2139665118184384e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 90, 'n_units_Layer_3': 180, 'n_units_Layer_4': 70}. Best is trial 467 with value: 45.096161900018394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.32 | sMAPE for Validation Set is: 33.77% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 27.24 | sMAPE for Test Set is: 33.91% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:57:38,559]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:57:43,212]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:57:47,044]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:57:49,867]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:58:07,564]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:58:09,682]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:58:13,227]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:58:18,858]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:58:19,583]\u001b[0m Trial 775 finished with value: 47.40834538017142 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026037552963288145, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12206046245943102, 'dropout_rate_Layer_2': 0.13128375583452415, 'dropout_rate_Layer_3': 0.1516204120514327, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00021421651769670013, 'l1_Layer_2': 0.0003122432635107133, 'l1_Layer_3': 0.004128511208639549, 'n_units_Layer_1': 125, 'n_units_Layer_2': 215, 'n_units_Layer_3': 265}. Best is trial 467 with value: 45.096161900018394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.41 | sMAPE for Validation Set is: 31.22% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 22.65 | sMAPE for Test Set is: 31.15% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:58:19,748]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:58:26,141]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:58:28,090]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:58:30,943]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:58:32,575]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:58:33,866]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:58:34,192]\u001b[0m Trial 770 finished with value: 51.35730855157478 and parameters: {'n_hidden': 4, 'learning_rate': 0.002714633038199086, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13758963874840568, 'dropout_rate_Layer_2': 0.05483804003759357, 'dropout_rate_Layer_3': 0.33011997424100786, 'dropout_rate_Layer_4': 0.22367313116195606, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0006836829771612116, 'l1_Layer_2': 5.564834485786007e-05, 'l1_Layer_3': 1.0933144368222297e-05, 'l1_Layer_4': 5.4582898574703584e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 90, 'n_units_Layer_3': 200, 'n_units_Layer_4': 65}. Best is trial 467 with value: 45.096161900018394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.36 | sMAPE for Validation Set is: 32.84% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 24.47 | sMAPE for Test Set is: 32.05% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 15:58:38,537]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:58:45,306]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:58:45,547]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:58:47,662]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:58:53,355]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:58:54,367]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:59:00,643]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:59:04,692]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:59:05,732]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:59:11,535]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:59:13,541]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:59:14,284]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:59:20,481]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:59:24,378]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:59:26,612]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:59:27,035]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:59:31,140]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:59:31,940]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:59:32,757]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:59:36,690]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:59:38,341]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:59:40,727]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:59:43,358]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:59:45,652]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:59:47,568]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:59:51,315]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:59:51,679]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:59:53,997]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 15:59:55,028]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:00:03,154]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:00:03,560]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:00:04,145]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:00:04,916]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:00:13,664]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:00:14,197]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:00:19,000]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:00:22,597]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:00:23,622]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:00:28,899]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:00:29,552]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:00:32,825]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:00:35,427]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:00:36,099]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:00:40,959]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:00:42,845]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:00:43,933]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:00:46,432]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:00:49,007]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:00:51,343]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:00:55,873]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:00:57,386]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:01:00,834]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:01:01,869]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:01:05,432]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:01:06,021]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:01:11,214]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:01:14,294]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:01:18,992]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:01:22,958]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:01:25,474]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:01:28,849]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:01:33,198]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:01:33,434]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:01:34,431]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:01:41,722]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:01:47,744]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:01:47,894]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:01:53,827]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:01:54,066]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:01:59,097]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:02:04,149]\u001b[0m Trial 822 finished with value: 44.74884458529493 and parameters: {'n_hidden': 3, 'learning_rate': 0.001205078042027478, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08308025108974795, 'dropout_rate_Layer_2': 0.0001286935365810843, 'dropout_rate_Layer_3': 0.1682090838220031, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006890855277250013, 'l1_Layer_2': 0.0027879015309120146, 'l1_Layer_3': 1.0115914188983251e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 220, 'n_units_Layer_3': 210}. Best is trial 822 with value: 44.74884458529493.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.75 | sMAPE for Validation Set is: 29.96% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 20.67 | sMAPE for Test Set is: 29.32% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:02:08,028]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:02:12,457]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:02:16,379]\u001b[0m Trial 849 finished with value: 53.829698484604364 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012362360628538035, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06781701823729414, 'dropout_rate_Layer_2': 0.004259908119289859, 'dropout_rate_Layer_3': 0.35916171097206173, 'dropout_rate_Layer_4': 0.21295629674820513, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0019871171879186074, 'l1_Layer_2': 5.41557860001085e-05, 'l1_Layer_3': 8.917695609034207e-05, 'l1_Layer_4': 9.942526828196673e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 110, 'n_units_Layer_3': 295, 'n_units_Layer_4': 50}. Best is trial 822 with value: 44.74884458529493.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.83 | sMAPE for Validation Set is: 33.94% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 24.79 | sMAPE for Test Set is: 32.84% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:02:16,965]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:02:22,900]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:02:24,934]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:02:28,051]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:02:31,518]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:02:34,848]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:02:38,783]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:02:39,252]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:02:41,818]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:02:45,403]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:02:49,178]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:02:50,262]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:02:54,084]\u001b[0m Trial 857 finished with value: 53.70517157243395 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010541386584598665, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11209971981208867, 'dropout_rate_Layer_2': 0.006220154523786643, 'dropout_rate_Layer_3': 0.35983555454533594, 'dropout_rate_Layer_4': 0.20994972934238532, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0019509404799641385, 'l1_Layer_2': 0.00017728796716489666, 'l1_Layer_3': 8.446239824898024e-05, 'l1_Layer_4': 0.00012829214910063436, 'n_units_Layer_1': 85, 'n_units_Layer_2': 110, 'n_units_Layer_3': 265, 'n_units_Layer_4': 60}. Best is trial 822 with value: 44.74884458529493.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.71 | sMAPE for Validation Set is: 33.90% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 25.28 | sMAPE for Test Set is: 32.78% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:02:56,607]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:02:56,910]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:02:57,793]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:03:04,286]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:03:07,041]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:03:08,203]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:03:13,536]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:03:14,098]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:03:19,299]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:03:23,694]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:03:24,025]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:03:29,864]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:03:30,898]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:03:50,880]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:03:54,517]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:03:59,349]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:04:01,295]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:04:05,846]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:04:06,329]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:04:14,907]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:04:20,730]\u001b[0m Trial 884 finished with value: 48.4031590163705 and parameters: {'n_hidden': 3, 'learning_rate': 0.001117918802887091, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3490583476647596, 'dropout_rate_Layer_2': 0.37819761782759426, 'dropout_rate_Layer_3': 0.20480680652675193, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008691623847872075, 'l1_Layer_2': 0.0014020925477296305, 'l1_Layer_3': 8.074102838431346e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 225, 'n_units_Layer_3': 250}. Best is trial 822 with value: 44.74884458529493.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 48.40 | sMAPE for Validation Set is: 31.88% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 23.00 | sMAPE for Test Set is: 31.48% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:04:23,953]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:04:24,460]\u001b[0m Trial 883 finished with value: 54.44334021785185 and parameters: {'n_hidden': 4, 'learning_rate': 0.003208286321250701, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04056273223727062, 'dropout_rate_Layer_2': 0.34152893547080954, 'dropout_rate_Layer_3': 0.3892240482780086, 'dropout_rate_Layer_4': 0.2804431102134171, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003310724222111138, 'l1_Layer_2': 0.000310090645860057, 'l1_Layer_3': 0.0018096276697230536, 'l1_Layer_4': 0.07544297404166758, 'n_units_Layer_1': 60, 'n_units_Layer_2': 70, 'n_units_Layer_3': 250, 'n_units_Layer_4': 85}. Best is trial 822 with value: 44.74884458529493.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.44 | sMAPE for Validation Set is: 33.77% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 26.70 | sMAPE for Test Set is: 32.83% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:04:24,859]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.15 | sMAPE for Validation Set is: 33.45% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 24.21 | sMAPE for Test Set is: 32.03% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:04:31,059]\u001b[0m Trial 893 finished with value: 53.146651435240244 and parameters: {'n_hidden': 4, 'learning_rate': 0.0092126035110643, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03679695023361276, 'dropout_rate_Layer_2': 0.14743722288452035, 'dropout_rate_Layer_3': 0.27103195495639093, 'dropout_rate_Layer_4': 0.1309830903102113, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0001806146831894384, 'l1_Layer_2': 3.5878108065417954e-05, 'l1_Layer_3': 0.001892307307192077, 'l1_Layer_4': 0.07396445816665312, 'n_units_Layer_1': 205, 'n_units_Layer_2': 80, 'n_units_Layer_3': 245, 'n_units_Layer_4': 85}. Best is trial 822 with value: 44.74884458529493.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:04:31,355]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:04:37,747]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:04:38,212]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:04:44,353]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:04:50,824]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:04:55,677]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:05:00,053]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:05:06,877]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:05:14,940]\u001b[0m Trial 898 finished with value: 45.48875092790431 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008176539075815581, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29490622455158405, 'dropout_rate_Layer_2': 0.01673866706684917, 'dropout_rate_Layer_3': 0.016687915425338366, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009450472260604815, 'l1_Layer_2': 0.00023877573181836653, 'l1_Layer_3': 0.00024995433986028313, 'n_units_Layer_1': 180, 'n_units_Layer_2': 215, 'n_units_Layer_3': 215}. Best is trial 822 with value: 44.74884458529493.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.49 | sMAPE for Validation Set is: 30.65% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 20.87 | sMAPE for Test Set is: 29.47% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:05:17,710]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:05:20,693]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:05:23,679]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:05:26,492]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:05:36,425]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:05:42,982]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:05:42,986]\u001b[0m Trial 897 finished with value: 44.794960406798886 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009576210512820075, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0009360688609393875, 'dropout_rate_Layer_2': 0.01348556688079057, 'dropout_rate_Layer_3': 0.02164562663094501, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00206683991484331, 'l1_Layer_2': 0.0006581236122042768, 'l1_Layer_3': 0.0002388596977570763, 'n_units_Layer_1': 120, 'n_units_Layer_2': 165, 'n_units_Layer_3': 280}. Best is trial 822 with value: 44.74884458529493.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.79 | sMAPE for Validation Set is: 30.33% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 23.34 | sMAPE for Test Set is: 30.86% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:05:43,967]\u001b[0m Trial 902 finished with value: 45.54542200098823 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010076195109674413, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0014477923239031264, 'dropout_rate_Layer_2': 0.3392379813455966, 'dropout_rate_Layer_3': 0.16489317454305896, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003248131876702597, 'l1_Layer_2': 0.0006758278496214162, 'l1_Layer_3': 0.00028148767764123005, 'n_units_Layer_1': 180, 'n_units_Layer_2': 165, 'n_units_Layer_3': 240}. Best is trial 822 with value: 44.74884458529493.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.55 | sMAPE for Validation Set is: 30.56% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 20.68 | sMAPE for Test Set is: 29.38% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:05:52,480]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:05:52,842]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:05:53,743]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.56 | sMAPE for Validation Set is: 31.10% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 20.79 | sMAPE for Test Set is: 29.59% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:05:59,435]\u001b[0m Trial 911 finished with value: 46.55892030017829 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007994463922470934, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.294795149338128, 'dropout_rate_Layer_2': 0.053945280477895, 'dropout_rate_Layer_3': 0.17247241850755513, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005348417120206384, 'l1_Layer_2': 0.00011057087883735206, 'l1_Layer_3': 0.0002641801926797071, 'n_units_Layer_1': 120, 'n_units_Layer_2': 215, 'n_units_Layer_3': 190}. Best is trial 822 with value: 44.74884458529493.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:06:05,291]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:06:05,383]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:06:09,785]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:06:11,725]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:06:14,653]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:06:25,097]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:06:29,964]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:06:36,709]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:06:36,817]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:06:39,689]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:06:40,878]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:06:50,230]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:06:54,341]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:06:54,645]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:06:54,868]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:07:02,341]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:07:04,521]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:07:06,446]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:07:07,677]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:07:16,112]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:07:18,383]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:07:19,314]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:07:21,328]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:07:24,727]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:07:29,062]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:07:30,008]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:07:31,671]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:07:34,598]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:07:39,441]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:07:39,902]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:07:45,360]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:07:47,923]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:07:52,513]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:07:52,575]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:07:59,916]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:08:03,338]\u001b[0m Trial 937 finished with value: 44.95704903757883 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009820176299300287, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.005166069509722419, 'dropout_rate_Layer_2': 0.011253965488920962, 'dropout_rate_Layer_3': 0.16528610818054068, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005501474531890272, 'l1_Layer_2': 0.0002456386958571881, 'l1_Layer_3': 0.0002990107096694842, 'n_units_Layer_1': 115, 'n_units_Layer_2': 165, 'n_units_Layer_3': 190}. Best is trial 822 with value: 44.74884458529493.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.96 | sMAPE for Validation Set is: 30.27% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 20.79 | sMAPE for Test Set is: 30.11% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:08:05,477]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:08:09,399]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:08:10,060]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:08:12,667]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:08:17,017]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:08:19,377]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:08:20,099]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:08:24,904]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:08:27,196]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:08:31,063]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:08:35,322]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:08:35,695]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:08:41,694]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:08:46,458]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:08:49,205]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:08:54,268]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:08:54,954]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:09:00,733]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:09:07,334]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:09:07,357]\u001b[0m Trial 958 finished with value: 44.866689912537446 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007973127210712585, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.001080287133422943, 'dropout_rate_Layer_2': 0.05040330517807855, 'dropout_rate_Layer_3': 0.18356756109146546, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006420012687419056, 'l1_Layer_2': 0.00014357257694406787, 'l1_Layer_3': 0.0002145372528809187, 'n_units_Layer_1': 100, 'n_units_Layer_2': 160, 'n_units_Layer_3': 190}. Best is trial 822 with value: 44.74884458529493.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.87 | sMAPE for Validation Set is: 30.18% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 21.14 | sMAPE for Test Set is: 29.15% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:09:11,042]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:09:15,347]\u001b[0m Trial 961 finished with value: 44.73287015452294 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008325191279078626, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0031633168804997966, 'dropout_rate_Layer_2': 0.0431402879588619, 'dropout_rate_Layer_3': 0.1692973148909809, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004378294387837009, 'l1_Layer_2': 0.00024166405309952396, 'l1_Layer_3': 0.0002040702733263924, 'n_units_Layer_1': 100, 'n_units_Layer_2': 150, 'n_units_Layer_3': 190}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.73 | sMAPE for Validation Set is: 30.13% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 20.56 | sMAPE for Test Set is: 29.17% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:09:18,400]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:09:18,524]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:09:19,251]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:09:27,565]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:09:31,822]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:09:32,368]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:09:39,025]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:09:39,605]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:09:41,098]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:09:45,493]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:10:02,641]\u001b[0m Trial 979 finished with value: 45.01022966946581 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007058560619589959, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.004553022471194754, 'dropout_rate_Layer_2': 0.055573495745054685, 'dropout_rate_Layer_3': 0.19396701349625886, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00033177174389534584, 'l1_Layer_2': 0.00016047299825726764, 'l1_Layer_3': 0.0001859993166541317, 'n_units_Layer_1': 100, 'n_units_Layer_2': 160, 'n_units_Layer_3': 175}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.01 | sMAPE for Validation Set is: 30.36% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 20.84 | sMAPE for Test Set is: 30.25% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:10:05,748]\u001b[0m Trial 988 finished with value: 48.608712027280056 and parameters: {'n_hidden': 3, 'learning_rate': 0.004349398904457522, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008955341504450744, 'dropout_rate_Layer_2': 0.13071125826660504, 'dropout_rate_Layer_3': 0.0430323002698754, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003842933076802285, 'l1_Layer_2': 0.00032268328197367096, 'l1_Layer_3': 0.019471131766441226, 'n_units_Layer_1': 120, 'n_units_Layer_2': 145, 'n_units_Layer_3': 265}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 48.61 | sMAPE for Validation Set is: 31.67% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 24.55 | sMAPE for Test Set is: 33.99% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:10:06,203]\u001b[0m Trial 987 finished with value: 47.72228208940886 and parameters: {'n_hidden': 3, 'learning_rate': 0.004424025072853598, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009548105912075314, 'dropout_rate_Layer_2': 0.0033883860283837573, 'dropout_rate_Layer_3': 0.005110458290893323, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004041929124911493, 'l1_Layer_2': 0.016096153810634777, 'l1_Layer_3': 0.03289136657521683, 'n_units_Layer_1': 130, 'n_units_Layer_2': 130, 'n_units_Layer_3': 265}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.72 | sMAPE for Validation Set is: 31.22% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 23.63 | sMAPE for Test Set is: 33.04% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:10:13,069]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:10:16,323]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:10:22,895]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:10:25,605]\u001b[0m Trial 986 finished with value: 45.111315745615876 and parameters: {'n_hidden': 3, 'learning_rate': 0.000982100262166831, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0018100085710229601, 'dropout_rate_Layer_2': 0.0644277242134229, 'dropout_rate_Layer_3': 0.18186680881036965, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003308792456669388, 'l1_Layer_2': 0.0001667601814239992, 'l1_Layer_3': 0.0001726088737569726, 'n_units_Layer_1': 85, 'n_units_Layer_2': 150, 'n_units_Layer_3': 170}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.11 | sMAPE for Validation Set is: 30.44% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 20.70 | sMAPE for Test Set is: 29.07% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:10:31,115]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.13 | sMAPE for Validation Set is: 30.80% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 23.77 | sMAPE for Test Set is: 33.26% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:10:34,285]\u001b[0m Trial 990 finished with value: 46.13298970994642 and parameters: {'n_hidden': 3, 'learning_rate': 0.004801265147280223, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008830428025347597, 'dropout_rate_Layer_2': 0.006030689027520625, 'dropout_rate_Layer_3': 0.0067421670776550285, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004093928207976214, 'l1_Layer_2': 0.002624623594284198, 'l1_Layer_3': 0.034361908857027744, 'n_units_Layer_1': 120, 'n_units_Layer_2': 140, 'n_units_Layer_3': 260}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:10:40,565]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:10:42,927]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:10:47,859]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:10:48,013]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:10:48,298]\u001b[0m Trial 992 finished with value: 48.3962210234184 and parameters: {'n_hidden': 3, 'learning_rate': 0.004107454952936096, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009072017049570825, 'dropout_rate_Layer_2': 0.017671938459444397, 'dropout_rate_Layer_3': 0.043013262030860686, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005267071023597866, 'l1_Layer_2': 0.015235451057734077, 'l1_Layer_3': 0.05221653397633406, 'n_units_Layer_1': 120, 'n_units_Layer_2': 145, 'n_units_Layer_3': 260}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 48.40 | sMAPE for Validation Set is: 31.69% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 23.84 | sMAPE for Test Set is: 33.18% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:10:56,918]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:10:59,599]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:11:03,027]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:11:05,389]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:11:06,727]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:11:11,383]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:11:13,128]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:11:15,155]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:11:19,316]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:11:20,416]\u001b[0m Trial 994 finished with value: 45.29325649302306 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007009837575665447, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0037671582353350215, 'dropout_rate_Layer_2': 0.05826572231237173, 'dropout_rate_Layer_3': 0.1924252653823088, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00030697160762752844, 'l1_Layer_2': 0.0001664015611147665, 'l1_Layer_3': 0.000170355213958756, 'n_units_Layer_1': 85, 'n_units_Layer_2': 155, 'n_units_Layer_3': 155}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.29 | sMAPE for Validation Set is: 30.47% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 21.07 | sMAPE for Test Set is: 30.86% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:11:21,859]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:11:26,143]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:11:28,166]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:11:32,281]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:11:36,010]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:11:40,068]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:11:57,567]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:11:58,613]\u001b[0m Trial 1015 finished with value: 45.9592740021782 and parameters: {'n_hidden': 3, 'learning_rate': 0.000961110867153543, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0009917299093173504, 'dropout_rate_Layer_2': 0.06002965423339288, 'dropout_rate_Layer_3': 0.19818826735440678, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003798253370778099, 'l1_Layer_2': 0.00017714325516174822, 'l1_Layer_3': 0.00016061990808198306, 'n_units_Layer_1': 80, 'n_units_Layer_2': 160, 'n_units_Layer_3': 150}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.96 | sMAPE for Validation Set is: 30.77% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 20.85 | sMAPE for Test Set is: 29.50% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:12:05,320]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:12:06,335]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:12:08,797]\u001b[0m Trial 1011 finished with value: 44.90220452739462 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010238030176317927, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0008808241380062732, 'dropout_rate_Layer_2': 0.05624831398274929, 'dropout_rate_Layer_3': 0.2089545331537161, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004494398659375148, 'l1_Layer_2': 0.00022173408404903711, 'l1_Layer_3': 0.00016033758261340422, 'n_units_Layer_1': 75, 'n_units_Layer_2': 160, 'n_units_Layer_3': 155}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.90 | sMAPE for Validation Set is: 30.29% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 20.90 | sMAPE for Test Set is: 29.54% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:12:14,662]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:12:19,663]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:12:23,076]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:12:25,412]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:12:25,794]\u001b[0m Trial 1018 finished with value: 54.0455747380603 and parameters: {'n_hidden': 4, 'learning_rate': 0.001961491660963876, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10359845259604253, 'dropout_rate_Layer_2': 0.24087565647352419, 'dropout_rate_Layer_3': 0.3196584810020202, 'dropout_rate_Layer_4': 0.1769301298122967, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00023572772260638754, 'l1_Layer_2': 6.808471553536378e-05, 'l1_Layer_3': 0.0008660247508333489, 'l1_Layer_4': 0.048414982321731824, 'n_units_Layer_1': 185, 'n_units_Layer_2': 60, 'n_units_Layer_3': 210, 'n_units_Layer_4': 100}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.05 | sMAPE for Validation Set is: 33.77% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 24.70 | sMAPE for Test Set is: 32.05% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:12:32,410]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:12:32,570]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:12:38,870]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:12:41,800]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:12:46,144]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:12:46,298]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:12:52,826]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:13:08,458]\u001b[0m Trial 1026 finished with value: 45.044296421236886 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011033366389567314, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0017739387313174407, 'dropout_rate_Layer_2': 0.09024377165832811, 'dropout_rate_Layer_3': 0.22780409369718496, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00043785760143445643, 'l1_Layer_2': 0.00024356050663773603, 'l1_Layer_3': 8.753720793840876e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 150, 'n_units_Layer_3': 145}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.04 | sMAPE for Validation Set is: 30.31% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 20.67 | sMAPE for Test Set is: 30.18% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:13:23,131]\u001b[0m Trial 1023 finished with value: 51.679356792303885 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019288695251878899, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10212532918368988, 'dropout_rate_Layer_2': 0.27196432400591425, 'dropout_rate_Layer_3': 0.2907348800291053, 'dropout_rate_Layer_4': 0.1419111472679019, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00022538156436898723, 'l1_Layer_2': 6.334747525832719e-05, 'l1_Layer_3': 0.0007383363869748778, 'l1_Layer_4': 0.0017311327516472358, 'n_units_Layer_1': 190, 'n_units_Layer_2': 60, 'n_units_Layer_3': 210, 'n_units_Layer_4': 75}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.68 | sMAPE for Validation Set is: 32.73% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 24.05 | sMAPE for Test Set is: 31.35% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:13:25,904]\u001b[0m Trial 1034 finished with value: 53.087377284842944 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015988601928944867, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17896932261744367, 'dropout_rate_Layer_2': 0.27486861969048637, 'dropout_rate_Layer_3': 0.29217892925851424, 'dropout_rate_Layer_4': 0.14236711975749852, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.748625475221441e-05, 'l1_Layer_2': 4.713462705451598e-05, 'l1_Layer_3': 0.00026480170476060583, 'l1_Layer_4': 0.011710890687440374, 'n_units_Layer_1': 210, 'n_units_Layer_2': 70, 'n_units_Layer_3': 220, 'n_units_Layer_4': 75}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.09 | sMAPE for Validation Set is: 33.65% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 25.29 | sMAPE for Test Set is: 32.94% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:13:26,967]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:13:34,830]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:13:39,150]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:14:10,310]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:14:14,232]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:14:14,793]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:14:22,556]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:14:22,634]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.98 | sMAPE for Validation Set is: 30.28% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 20.61 | sMAPE for Test Set is: 29.35% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:14:26,402]\u001b[0m Trial 1041 finished with value: 44.977125979484846 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009989778685135628, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0004138927008830866, 'dropout_rate_Layer_2': 0.08479917778618422, 'dropout_rate_Layer_3': 0.2270809906605393, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00032418379796856224, 'l1_Layer_2': 0.0002015381673380534, 'l1_Layer_3': 8.986151744092107e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 130, 'n_units_Layer_3': 160}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:14:29,138]\u001b[0m Trial 1035 finished with value: 47.35287590803492 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008320247665731444, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.020913588660414578, 'dropout_rate_Layer_2': 0.36710674869882515, 'dropout_rate_Layer_3': 0.2505326418701544, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00101972578350091, 'l1_Layer_2': 0.0010948509161255936, 'l1_Layer_3': 1.3334984842532719e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 205, 'n_units_Layer_3': 260}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.35 | sMAPE for Validation Set is: 31.60% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 24.02 | sMAPE for Test Set is: 33.43% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:14:30,552]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:14:30,660]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:14:37,032]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:14:42,094]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:14:45,534]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:14:46,807]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:14:52,459]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:15:04,409]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:15:09,959]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:15:11,162]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:15:33,701]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:15:37,393]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:15:41,186]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:15:49,807]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:15:53,124]\u001b[0m Trial 1057 finished with value: 45.19695501261458 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010025345545413413, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01138112419779664, 'dropout_rate_Layer_2': 0.08088100426727482, 'dropout_rate_Layer_3': 0.24272018400083303, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003101558513226172, 'l1_Layer_2': 0.00014017760746642906, 'l1_Layer_3': 7.958606605396993e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 130, 'n_units_Layer_3': 160}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.20 | sMAPE for Validation Set is: 30.48% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 20.37 | sMAPE for Test Set is: 29.14% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:15:55,871]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:15:57,072]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:16:03,921]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:16:08,165]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:16:13,931]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:16:20,677]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:16:25,051]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:16:28,729]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:16:44,159]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:16:48,323]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:16:48,670]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:17:06,476]\u001b[0m Trial 1071 finished with value: 45.206427707121094 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011311887511568223, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.011440447816962667, 'dropout_rate_Layer_2': 0.08307815529798843, 'dropout_rate_Layer_3': 0.2286778186437616, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00031118684585502266, 'l1_Layer_2': 0.0002086514715184942, 'l1_Layer_3': 4.9252519180624404e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 130, 'n_units_Layer_3': 160}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.21 | sMAPE for Validation Set is: 30.45% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 20.91 | sMAPE for Test Set is: 29.43% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:17:19,494]\u001b[0m Trial 1064 finished with value: 46.83546398445617 and parameters: {'n_hidden': 3, 'learning_rate': 0.001243138035029143, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00034085520297374994, 'dropout_rate_Layer_2': 0.0640551029467379, 'dropout_rate_Layer_3': 0.2880944786221421, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005380193090750497, 'l1_Layer_2': 0.004988083211248421, 'l1_Layer_3': 1.155601540794259e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 285, 'n_units_Layer_3': 260}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.84 | sMAPE for Validation Set is: 31.27% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 21.70 | sMAPE for Test Set is: 29.86% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:17:31,456]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:17:32,366]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:17:37,323]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:17:47,811]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:17:50,620]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:17:50,984]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:17:56,951]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:18:01,383]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:18:24,336]\u001b[0m Trial 1079 finished with value: 52.68856168664146 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015012214351329796, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15632385074390362, 'dropout_rate_Layer_2': 0.31197846433293575, 'dropout_rate_Layer_3': 0.10384675726986314, 'dropout_rate_Layer_4': 0.36895650497451526, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.567695080577048e-05, 'l1_Layer_2': 4.2553338743184745e-05, 'l1_Layer_3': 0.0007177019430188677, 'l1_Layer_4': 0.011317697858777214, 'n_units_Layer_1': 205, 'n_units_Layer_2': 85, 'n_units_Layer_3': 220, 'n_units_Layer_4': 75}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.69 | sMAPE for Validation Set is: 33.69% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 25.90 | sMAPE for Test Set is: 33.20% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:18:34,284]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:18:37,282]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:18:40,134]\u001b[0m Trial 1082 finished with value: 45.09998835796112 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012515369827085449, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.023630649476421482, 'dropout_rate_Layer_2': 0.09854408826059163, 'dropout_rate_Layer_3': 0.22710433283355372, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00032034234267335805, 'l1_Layer_2': 0.00022231059900078905, 'l1_Layer_3': 6.554564970591763e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 130, 'n_units_Layer_3': 155}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.10 | sMAPE for Validation Set is: 30.35% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 20.80 | sMAPE for Test Set is: 30.16% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:18:40,270]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:19:32,887]\u001b[0m Trial 1085 finished with value: 46.653660227280085 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009633249183958303, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.010923489589222964, 'dropout_rate_Layer_2': 0.08448726292580727, 'dropout_rate_Layer_3': 0.29390745489895465, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0015442042654495425, 'l1_Layer_2': 0.005607068542304974, 'l1_Layer_3': 1.1567074350777316e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 190, 'n_units_Layer_3': 255}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.65 | sMAPE for Validation Set is: 31.04% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 21.21 | sMAPE for Test Set is: 29.88% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:19:39,155]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:19:45,199]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:19:51,269]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:19:56,833]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:20:44,394]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:20:44,680]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:20:48,197]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:20:55,591]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:20:56,195]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:21:03,419]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:21:08,375]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:21:09,334]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:21:09,684]\u001b[0m Trial 1094 finished with value: 55.49648250963879 and parameters: {'n_hidden': 4, 'learning_rate': 0.00224325327517386, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15300186155437456, 'dropout_rate_Layer_2': 0.31515702261491, 'dropout_rate_Layer_3': 0.09111692665785645, 'dropout_rate_Layer_4': 0.32657179948949655, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.313057919564218e-05, 'l1_Layer_2': 3.568477872782762e-05, 'l1_Layer_3': 0.000757119580944554, 'l1_Layer_4': 0.001276764922795567, 'n_units_Layer_1': 170, 'n_units_Layer_2': 95, 'n_units_Layer_3': 180, 'n_units_Layer_4': 75}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.50 | sMAPE for Validation Set is: 34.35% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 25.84 | sMAPE for Test Set is: 32.66% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:21:19,215]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:21:22,156]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:21:27,104]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:21:27,373]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:21:28,485]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:21:35,922]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:21:38,713]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:21:41,275]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:21:41,500]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:21:42,163]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:21:48,156]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:21:48,562]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:21:48,936]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:21:57,323]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:21:59,857]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:22:00,194]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:22:02,781]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:22:06,915]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:22:10,432]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:22:12,777]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:22:13,079]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:22:19,981]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:22:22,375]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:22:27,019]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:22:29,191]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:22:34,519]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:22:34,749]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:22:40,765]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:22:44,030]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:22:45,446]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:22:49,722]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:22:51,119]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:22:56,671]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:22:57,840]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:23:04,459]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:23:06,813]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:23:10,796]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:23:17,642]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:23:22,486]\u001b[0m Trial 1095 finished with value: 53.67459695419232 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014573933504962097, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2036805685949233, 'dropout_rate_Layer_2': 0.3318342335475736, 'dropout_rate_Layer_3': 0.19605259654190577, 'dropout_rate_Layer_4': 0.3202952241936939, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.743915439525807e-05, 'l1_Layer_2': 2.707516541622999e-05, 'l1_Layer_3': 0.0012634053272895331, 'l1_Layer_4': 0.0015490363737358296, 'n_units_Layer_1': 225, 'n_units_Layer_2': 95, 'n_units_Layer_3': 175, 'n_units_Layer_4': 75}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.67 | sMAPE for Validation Set is: 33.56% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 24.62 | sMAPE for Test Set is: 33.65% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:23:23,597]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:23:29,246]\u001b[0m Trial 1137 finished with value: 47.76435039724108 and parameters: {'n_hidden': 3, 'learning_rate': 0.006602297205098705, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3462590793152795, 'dropout_rate_Layer_2': 0.01166238305873505, 'dropout_rate_Layer_3': 0.02859087123553737, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00021892603935694808, 'l1_Layer_2': 0.0002466173417050811, 'l1_Layer_3': 0.006952702245752307, 'n_units_Layer_1': 170, 'n_units_Layer_2': 220, 'n_units_Layer_3': 265}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.76 | sMAPE for Validation Set is: 31.20% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 23.07 | sMAPE for Test Set is: 32.33% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:23:31,659]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:23:34,748]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:23:39,601]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:23:39,751]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:23:42,327]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:23:44,351]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:23:47,303]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:23:47,528]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:23:54,223]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:23:58,104]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:24:02,431]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:24:03,043]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:24:03,701]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:24:04,687]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:24:13,935]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:24:14,120]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:24:14,514]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:24:18,414]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:24:24,167]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:24:25,309]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:24:30,506]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:24:30,697]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:24:31,663]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:24:33,472]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:24:41,774]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:24:45,954]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:24:48,999]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:24:50,586]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:24:55,460]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:24:56,576]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:24:57,222]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:25:05,340]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:25:07,704]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:25:13,276]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:25:17,190]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:25:20,440]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:25:22,827]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:25:27,971]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:25:30,231]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:25:34,323]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.41 | sMAPE for Validation Set is: 31.46% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 22.98 | sMAPE for Test Set is: 31.61% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:25:36,969]\u001b[0m Trial 1168 finished with value: 47.40511519783993 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011713955759220843, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22123596916527602, 'dropout_rate_Layer_2': 0.021491607666291088, 'dropout_rate_Layer_3': 0.1490030048682599, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006609759296738846, 'l1_Layer_2': 0.0025050504089757595, 'l1_Layer_3': 1.747851527905798e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 255, 'n_units_Layer_3': 265}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:25:38,529]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:25:42,509]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:25:48,470]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:25:48,598]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:25:49,484]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:25:50,206]\u001b[0m Trial 1173 finished with value: 53.13426692688265 and parameters: {'n_hidden': 4, 'learning_rate': 0.0028933524970252552, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19519302222159787, 'dropout_rate_Layer_2': 0.26513976095409353, 'dropout_rate_Layer_3': 0.2926470183983786, 'dropout_rate_Layer_4': 0.3584510326887528, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.631392732257368e-05, 'l1_Layer_2': 4.864833051010297e-05, 'l1_Layer_3': 0.0002266903625609852, 'l1_Layer_4': 0.010926820763018418, 'n_units_Layer_1': 210, 'n_units_Layer_2': 60, 'n_units_Layer_3': 220, 'n_units_Layer_4': 50}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.13 | sMAPE for Validation Set is: 33.62% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 24.82 | sMAPE for Test Set is: 32.05% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:26:01,285]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:26:01,654]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:26:02,138]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:26:10,387]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:26:11,358]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:26:18,185]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:26:22,622]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:26:27,041]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:26:31,304]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:26:34,262]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:26:38,539]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:26:40,917]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:26:45,190]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:26:45,874]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:26:46,480]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:26:51,619]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:26:56,045]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:26:57,256]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:26:59,246]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:27:02,244]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:27:08,206]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:27:09,291]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:27:15,332]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:27:17,848]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:27:24,770]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:27:50,064]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:27:56,383]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:28:00,949]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:28:08,558]\u001b[0m Trial 1216 finished with value: 45.55976591577548 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008884594425723368, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01857866780049552, 'dropout_rate_Layer_2': 0.05733970640589754, 'dropout_rate_Layer_3': 0.21798374145332167, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004936861976213002, 'l1_Layer_2': 0.00018574362625454788, 'l1_Layer_3': 9.843581922998217e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 155, 'n_units_Layer_3': 175}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.56 | sMAPE for Validation Set is: 30.60% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 21.21 | sMAPE for Test Set is: 30.54% | rMAE for Test Set is: 0.58\n",
      "MAE for Validation Set is: 44.92 | sMAPE for Validation Set is: 30.25% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 21.74 | sMAPE for Test Set is: 29.63% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:28:08,600]\u001b[0m Trial 1209 finished with value: 44.91818778063248 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008752027757356057, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0003405614227651036, 'dropout_rate_Layer_2': 0.056857980124470235, 'dropout_rate_Layer_3': 0.21618963212513248, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005081635357684616, 'l1_Layer_2': 0.00037180193623713697, 'l1_Layer_3': 0.0003257351645735132, 'n_units_Layer_1': 70, 'n_units_Layer_2': 100, 'n_units_Layer_3': 175}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:28:09,385]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:28:18,551]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:28:19,534]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:28:24,576]\u001b[0m Trial 1203 finished with value: 52.568222245140014 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011403410521832948, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1614198270589038, 'dropout_rate_Layer_2': 0.27209091338603786, 'dropout_rate_Layer_3': 0.1150652392786843, 'dropout_rate_Layer_4': 0.10749511665872317, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 9.233130397922662e-05, 'l1_Layer_2': 6.768273842161485e-05, 'l1_Layer_3': 0.0006437612645120828, 'l1_Layer_4': 0.008623269002237205, 'n_units_Layer_1': 190, 'n_units_Layer_2': 245, 'n_units_Layer_3': 230, 'n_units_Layer_4': 90}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.57 | sMAPE for Validation Set is: 33.15% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 27.34 | sMAPE for Test Set is: 34.72% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:28:27,893]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:28:30,760]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:28:34,801]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:28:36,843]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:28:40,575]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:28:44,483]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:28:48,494]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:28:53,138]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:28:53,733]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:28:55,134]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:29:04,413]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:29:05,368]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:29:06,112]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:29:10,621]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:29:11,682]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:29:18,099]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:29:20,286]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:29:20,780]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:29:20,992]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:29:29,548]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:29:30,674]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:29:35,773]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:29:38,710]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:29:39,589]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:29:40,206]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:29:41,025]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:29:49,819]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:29:53,188]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:29:56,843]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:29:59,775]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:30:03,297]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:30:04,805]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:30:11,159]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:30:11,973]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:30:17,058]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:30:20,855]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:30:24,917]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:30:28,971]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:30:33,368]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:30:38,092]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:30:40,283]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:30:43,387]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:30:45,716]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:30:50,035]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:30:53,490]\u001b[0m Trial 1253 finished with value: 54.54948641611433 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018914430771772397, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08461623843970156, 'dropout_rate_Layer_2': 0.016381855310127563, 'dropout_rate_Layer_3': 0.11664072532818724, 'dropout_rate_Layer_4': 0.10289627291862542, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 9.883313638275594e-05, 'l1_Layer_2': 6.038276173727294e-05, 'l1_Layer_3': 0.0007319938472953762, 'l1_Layer_4': 0.007256646401746006, 'n_units_Layer_1': 175, 'n_units_Layer_2': 285, 'n_units_Layer_3': 230, 'n_units_Layer_4': 90}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.55 | sMAPE for Validation Set is: 34.07% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 25.52 | sMAPE for Test Set is: 32.28% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:30:54,702]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:30:59,009]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:31:03,557]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:31:04,102]\u001b[0m Trial 1257 finished with value: 53.07924071140753 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010506737696255165, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16145886476267451, 'dropout_rate_Layer_2': 0.013702387531295924, 'dropout_rate_Layer_3': 0.14369013010293627, 'dropout_rate_Layer_4': 0.09594651252691579, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 9.217590013885037e-05, 'l1_Layer_2': 6.414296020213111e-05, 'l1_Layer_3': 0.0006302570764933579, 'l1_Layer_4': 0.006483730235588954, 'n_units_Layer_1': 175, 'n_units_Layer_2': 250, 'n_units_Layer_3': 230, 'n_units_Layer_4': 90}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.08 | sMAPE for Validation Set is: 33.82% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 25.24 | sMAPE for Test Set is: 33.22% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:31:07,061]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:31:09,281]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:31:13,830]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:31:15,584]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:31:24,902]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:31:25,790]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:31:30,351]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:31:30,961]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:31:37,366]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:31:39,276]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:31:43,268]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:31:46,052]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:31:48,756]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:31:57,152]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:32:02,044]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:32:05,399]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:32:05,601]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:32:12,766]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:32:12,981]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:32:18,273]\u001b[0m Trial 1280 finished with value: 45.1322708978916 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009850501149037145, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015996798766696983, 'dropout_rate_Layer_2': 0.06438394498778194, 'dropout_rate_Layer_3': 0.16701820303938067, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004148295644425837, 'l1_Layer_2': 0.0002242774250182987, 'l1_Layer_3': 0.0002949816188711437, 'n_units_Layer_1': 80, 'n_units_Layer_2': 165, 'n_units_Layer_3': 160}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.13 | sMAPE for Validation Set is: 30.43% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 20.61 | sMAPE for Test Set is: 29.19% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:32:21,370]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:32:25,562]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:32:26,822]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:32:28,751]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:32:32,427]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:32:37,514]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:32:38,293]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:32:40,407]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:32:59,104]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:33:00,435]\u001b[0m Trial 1302 finished with value: 47.480547722632444 and parameters: {'n_hidden': 3, 'learning_rate': 0.006224108712439902, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3559812527747799, 'dropout_rate_Layer_2': 0.12736515698723222, 'dropout_rate_Layer_3': 0.017368549972782102, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005157026451584774, 'l1_Layer_2': 0.0001885574035023555, 'l1_Layer_3': 0.004182956042539718, 'n_units_Layer_1': 155, 'n_units_Layer_2': 145, 'n_units_Layer_3': 295}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.48 | sMAPE for Validation Set is: 31.46% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 22.48 | sMAPE for Test Set is: 30.74% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:33:05,043]\u001b[0m Trial 1293 finished with value: 45.04405036376259 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009642633528907878, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0002090367069294909, 'dropout_rate_Layer_2': 0.0619983571616816, 'dropout_rate_Layer_3': 0.1641024863431504, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00041794333936898744, 'l1_Layer_2': 0.0001577113693145625, 'l1_Layer_3': 0.0003070555364595514, 'n_units_Layer_1': 80, 'n_units_Layer_2': 165, 'n_units_Layer_3': 160}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.04 | sMAPE for Validation Set is: 30.33% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 20.80 | sMAPE for Test Set is: 30.09% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:33:05,595]\u001b[0m Trial 1300 finished with value: 45.74906272863487 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013352215763569105, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01733363880767174, 'dropout_rate_Layer_2': 0.06344041038162393, 'dropout_rate_Layer_3': 0.17949776769992556, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000161632731556818, 'l1_Layer_2': 0.00021975658044946685, 'l1_Layer_3': 0.0003301183407174789, 'n_units_Layer_1': 80, 'n_units_Layer_2': 160, 'n_units_Layer_3': 160}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.75 | sMAPE for Validation Set is: 30.71% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 20.59 | sMAPE for Test Set is: 29.59% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:33:05,871]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:33:14,237]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:33:31,744]\u001b[0m Trial 1304 finished with value: 48.19795106470807 and parameters: {'n_hidden': 4, 'learning_rate': 0.0021669558327906896, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11208475430671071, 'dropout_rate_Layer_2': 0.06806628519187391, 'dropout_rate_Layer_3': 0.34856396497236347, 'dropout_rate_Layer_4': 0.030722509538415738, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005536619202503501, 'l1_Layer_2': 3.528622297699856e-05, 'l1_Layer_3': 5.720459037083228e-05, 'l1_Layer_4': 0.019897916014378455, 'n_units_Layer_1': 200, 'n_units_Layer_2': 190, 'n_units_Layer_3': 185, 'n_units_Layer_4': 60}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 48.20 | sMAPE for Validation Set is: 31.42% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 21.60 | sMAPE for Test Set is: 29.56% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:33:36,164]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:33:36,605]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:33:42,910]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:33:47,313]\u001b[0m Trial 1307 finished with value: 47.052639275183225 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011678842994355277, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1080177716277653, 'dropout_rate_Layer_2': 0.0922459340181945, 'dropout_rate_Layer_3': 0.35014978281553605, 'dropout_rate_Layer_4': 0.05134232915415545, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0006225871586546178, 'l1_Layer_2': 0.00014654695720365784, 'l1_Layer_3': 0.0014048682363053812, 'l1_Layer_4': 0.0007947196032237062, 'n_units_Layer_1': 200, 'n_units_Layer_2': 295, 'n_units_Layer_3': 255, 'n_units_Layer_4': 60}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.05 | sMAPE for Validation Set is: 31.05% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 24.93 | sMAPE for Test Set is: 31.74% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:33:53,274]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:33:57,140]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:34:03,184]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.55 | sMAPE for Validation Set is: 31.11% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 22.79 | sMAPE for Test Set is: 30.76% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:34:04,152]\u001b[0m Trial 1305 finished with value: 46.54761387423665 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006183808172781084, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10890219347299601, 'dropout_rate_Layer_2': 0.3063058096464806, 'dropout_rate_Layer_3': 0.12874056501767095, 'dropout_rate_Layer_4': 0.05295957165388243, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005706550876300176, 'l1_Layer_2': 0.00013035123114176332, 'l1_Layer_3': 0.0014413942489187915, 'l1_Layer_4': 0.004412079218290891, 'n_units_Layer_1': 200, 'n_units_Layer_2': 85, 'n_units_Layer_3': 185, 'n_units_Layer_4': 60}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:34:10,648]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:34:11,255]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:34:17,502]\u001b[0m Trial 1311 finished with value: 48.868660657967496 and parameters: {'n_hidden': 4, 'learning_rate': 0.001149493204181298, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10684609476734931, 'dropout_rate_Layer_2': 0.30585968859246154, 'dropout_rate_Layer_3': 0.3525690884541011, 'dropout_rate_Layer_4': 0.04579922015556592, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0013191867251042236, 'l1_Layer_2': 1.3379722428011083e-05, 'l1_Layer_3': 6.415390143870955e-05, 'l1_Layer_4': 0.018982324136139806, 'n_units_Layer_1': 200, 'n_units_Layer_2': 300, 'n_units_Layer_3': 185, 'n_units_Layer_4': 60}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 48.87 | sMAPE for Validation Set is: 31.53% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 21.67 | sMAPE for Test Set is: 29.79% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:34:17,621]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:34:20,432]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:34:23,984]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:34:25,425]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:34:26,099]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:34:33,524]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:34:35,114]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:34:36,786]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:34:39,145]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:34:40,294]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:34:49,116]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:34:51,957]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:34:55,459]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:34:58,800]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:35:03,651]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:35:05,114]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:35:10,482]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:35:11,903]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:35:17,081]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:35:18,890]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:35:24,438]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:35:30,373]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:35:30,959]\u001b[0m Trial 1330 finished with value: 49.24616832416651 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006378382086453444, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10238134816722806, 'dropout_rate_Layer_2': 0.3347350554483036, 'dropout_rate_Layer_3': 0.33935769470659993, 'dropout_rate_Layer_4': 0.02317256195111976, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0013030427700353657, 'l1_Layer_2': 1.378395483120931e-05, 'l1_Layer_3': 1.6659451760185376e-05, 'l1_Layer_4': 0.00047317536673012505, 'n_units_Layer_1': 200, 'n_units_Layer_2': 290, 'n_units_Layer_3': 185, 'n_units_Layer_4': 55}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.25 | sMAPE for Validation Set is: 32.01% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 25.22 | sMAPE for Test Set is: 32.42% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:35:42,351]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:35:46,718]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:35:50,630]\u001b[0m Trial 1331 finished with value: 46.58845877129022 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015830177200137673, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01932492109803076, 'dropout_rate_Layer_2': 0.374195602930582, 'dropout_rate_Layer_3': 0.23624187845326775, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003980499147720259, 'l1_Layer_2': 0.0014771068413696369, 'l1_Layer_3': 1.1535272981473998e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 245, 'n_units_Layer_3': 140}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.59 | sMAPE for Validation Set is: 30.94% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 21.30 | sMAPE for Test Set is: 30.16% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:35:52,021]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:36:08,524]\u001b[0m Trial 1343 finished with value: 48.10764523884882 and parameters: {'n_hidden': 4, 'learning_rate': 0.000653895901679447, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09951894940310264, 'dropout_rate_Layer_2': 0.3358305186620571, 'dropout_rate_Layer_3': 0.32406453801318436, 'dropout_rate_Layer_4': 0.023024377661802528, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.001393650495115106, 'l1_Layer_2': 1.3582890692674943e-05, 'l1_Layer_3': 1.5419875178741668e-05, 'l1_Layer_4': 0.0004699351441684658, 'n_units_Layer_1': 200, 'n_units_Layer_2': 280, 'n_units_Layer_3': 160, 'n_units_Layer_4': 55}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 48.11 | sMAPE for Validation Set is: 31.36% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 25.13 | sMAPE for Test Set is: 32.06% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:36:09,173]\u001b[0m Trial 1339 finished with value: 45.28875448596808 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012965730010518154, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03221554496025667, 'dropout_rate_Layer_2': 0.09592124062187193, 'dropout_rate_Layer_3': 0.21370138699351038, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.311845156000227e-05, 'l1_Layer_2': 0.0004126241593081999, 'l1_Layer_3': 6.511647688051207e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 150, 'n_units_Layer_3': 140}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.29 | sMAPE for Validation Set is: 30.48% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 20.92 | sMAPE for Test Set is: 29.79% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:36:15,512]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:36:18,627]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:36:19,136]\u001b[0m Trial 1347 finished with value: 46.73480754974889 and parameters: {'n_hidden': 3, 'learning_rate': 0.004459977029419032, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006547178548465205, 'dropout_rate_Layer_2': 0.16037931427486365, 'dropout_rate_Layer_3': 0.017254265556886812, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00034543602877866176, 'l1_Layer_2': 0.0002768719089965872, 'l1_Layer_3': 0.008907083602635046, 'n_units_Layer_1': 75, 'n_units_Layer_2': 135, 'n_units_Layer_3': 265}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.73 | sMAPE for Validation Set is: 30.58% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 24.39 | sMAPE for Test Set is: 34.17% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:36:24,794]\u001b[0m Trial 1346 finished with value: 47.86398788458309 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020295205171065077, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04334303164126993, 'dropout_rate_Layer_2': 0.374201059616618, 'dropout_rate_Layer_3': 0.23388340712269706, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023794501158285546, 'l1_Layer_2': 0.0011837213314704312, 'l1_Layer_3': 1.3653162801658793e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 255, 'n_units_Layer_3': 220}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.86 | sMAPE for Validation Set is: 31.26% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 23.00 | sMAPE for Test Set is: 31.92% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:36:25,510]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:36:29,894]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:36:32,776]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:36:38,524]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:36:38,896]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:36:44,858]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:36:49,936]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:36:50,538]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:36:52,243]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:36:59,328]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:37:00,929]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:37:02,649]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:37:09,421]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:37:23,839]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:37:28,790]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:37:33,176]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:37:37,720]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:37:44,719]\u001b[0m Trial 1360 finished with value: 46.35345435083773 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019834581529990275, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.046241613717930403, 'dropout_rate_Layer_2': 0.37592974683997243, 'dropout_rate_Layer_3': 0.22861922569040685, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00024004637633398356, 'l1_Layer_2': 0.0009561641231951884, 'l1_Layer_3': 1.888800212085083e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 260, 'n_units_Layer_3': 225}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.35 | sMAPE for Validation Set is: 31.18% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 25.24 | sMAPE for Test Set is: 36.21% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:37:46,809]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:37:51,560]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:37:52,324]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:37:52,977]\u001b[0m Trial 1364 finished with value: 46.69025380023476 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027413794763498107, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05552141737584944, 'dropout_rate_Layer_2': 0.37975050549047346, 'dropout_rate_Layer_3': 0.23256773413719767, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00026511802729011554, 'l1_Layer_2': 0.0007906488807056358, 'l1_Layer_3': 1.5029490296796418e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 250, 'n_units_Layer_3': 220}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.69 | sMAPE for Validation Set is: 30.66% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 22.76 | sMAPE for Test Set is: 32.45% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:37:53,833]\u001b[0m Trial 1366 finished with value: 45.23068607882789 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010486638135671284, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 1.5580268087587459e-06, 'dropout_rate_Layer_2': 0.07255150680618488, 'dropout_rate_Layer_3': 0.22321504215171067, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.98180568906552e-05, 'l1_Layer_2': 0.0002038957086432941, 'l1_Layer_3': 6.941478464764927e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 165, 'n_units_Layer_3': 175}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.23 | sMAPE for Validation Set is: 30.47% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 21.27 | sMAPE for Test Set is: 29.99% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:38:01,128]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:38:03,676]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:38:05,936]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:38:12,984]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:38:13,408]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:38:13,925]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:38:25,578]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:38:26,155]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:38:32,401]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:38:32,821]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:38:38,423]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:38:49,282]\u001b[0m Trial 1377 finished with value: 47.24922593123378 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018149138374073056, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04500443705785351, 'dropout_rate_Layer_2': 0.37938202691421286, 'dropout_rate_Layer_3': 0.21991480141259578, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00018159159298425473, 'l1_Layer_2': 0.000526905918627317, 'l1_Layer_3': 2.495313429125349e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 260, 'n_units_Layer_3': 225}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.25 | sMAPE for Validation Set is: 31.24% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 23.46 | sMAPE for Test Set is: 33.20% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:38:50,316]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:39:00,057]\u001b[0m Trial 1380 finished with value: 45.078878326578625 and parameters: {'n_hidden': 3, 'learning_rate': 0.001171322066499686, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01348302838614303, 'dropout_rate_Layer_2': 0.0702544961661429, 'dropout_rate_Layer_3': 0.22456106652561367, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011269134590955795, 'l1_Layer_2': 0.000211875467979997, 'l1_Layer_3': 7.260132642537412e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 160, 'n_units_Layer_3': 175}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.08 | sMAPE for Validation Set is: 30.25% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 20.91 | sMAPE for Test Set is: 30.33% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:39:02,417]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:39:07,206]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:39:09,484]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:39:16,517]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:39:18,913]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:39:24,952]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:39:25,847]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:39:28,586]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:39:38,515]\u001b[0m Trial 1392 finished with value: 45.98275437193266 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011666041646845498, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.014592632467201414, 'dropout_rate_Layer_2': 0.07021023649495885, 'dropout_rate_Layer_3': 0.23099482614148906, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012512861596652668, 'l1_Layer_2': 0.00019305653603039047, 'l1_Layer_3': 4.8135895999668997e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 170, 'n_units_Layer_3': 170}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.98 | sMAPE for Validation Set is: 30.72% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 21.80 | sMAPE for Test Set is: 30.19% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:39:53,599]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:39:59,933]\u001b[0m Trial 1397 finished with value: 47.894290033861914 and parameters: {'n_hidden': 3, 'learning_rate': 0.005609380895023187, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37626704160281443, 'dropout_rate_Layer_2': 0.1427828011048866, 'dropout_rate_Layer_3': 0.1812043031973923, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015291600022805682, 'l1_Layer_2': 0.00018587878149772002, 'l1_Layer_3': 0.009012466668572888, 'n_units_Layer_1': 70, 'n_units_Layer_2': 220, 'n_units_Layer_3': 245}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.89 | sMAPE for Validation Set is: 31.50% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 23.87 | sMAPE for Test Set is: 33.06% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:40:05,992]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:40:12,224]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:40:13,260]\u001b[0m Trial 1399 finished with value: 47.67633319172211 and parameters: {'n_hidden': 3, 'learning_rate': 0.001754698418473658, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.055320824835930364, 'dropout_rate_Layer_2': 0.374275153596353, 'dropout_rate_Layer_3': 0.2063758946171461, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022847025889739643, 'l1_Layer_2': 0.0002909615534542305, 'l1_Layer_3': 1.729185658323746e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 260, 'n_units_Layer_3': 215}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.68 | sMAPE for Validation Set is: 31.36% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 23.40 | sMAPE for Test Set is: 32.50% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:40:19,119]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:40:21,704]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:40:29,182]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:40:30,085]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:40:35,533]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:40:54,922]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:41:01,364]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:41:07,903]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:41:12,864]\u001b[0m Trial 1396 finished with value: 45.26990129601537 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005067577800903692, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10677652562162941, 'dropout_rate_Layer_2': 0.34841688235593726, 'dropout_rate_Layer_3': 0.325724598608618, 'dropout_rate_Layer_4': 0.03137188813930284, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002692232912962668, 'l1_Layer_2': 1.7966712557405845e-05, 'l1_Layer_3': 4.847477502774437e-05, 'l1_Layer_4': 0.0005055453435024135, 'n_units_Layer_1': 180, 'n_units_Layer_2': 295, 'n_units_Layer_3': 185, 'n_units_Layer_4': 50}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.27 | sMAPE for Validation Set is: 30.32% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 21.28 | sMAPE for Test Set is: 29.51% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:41:13,831]\u001b[0m Trial 1409 finished with value: 46.130370962572044 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009142050602485261, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10969083391045044, 'dropout_rate_Layer_2': 0.3064543963533147, 'dropout_rate_Layer_3': 0.3294305262996205, 'dropout_rate_Layer_4': 0.03520422342514068, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.001100687708651319, 'l1_Layer_2': 1.785334436790872e-05, 'l1_Layer_3': 1.0594253910690612e-05, 'l1_Layer_4': 0.0005131559277353657, 'n_units_Layer_1': 180, 'n_units_Layer_2': 295, 'n_units_Layer_3': 185, 'n_units_Layer_4': 50}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.13 | sMAPE for Validation Set is: 30.80% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 21.19 | sMAPE for Test Set is: 29.70% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:41:21,209]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:41:29,380]\u001b[0m Trial 1405 finished with value: 45.50920529906969 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008724000454074089, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10909387819293814, 'dropout_rate_Layer_2': 0.3449195843558541, 'dropout_rate_Layer_3': 0.33665696922254085, 'dropout_rate_Layer_4': 0.039348079105951006, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0006698234881740474, 'l1_Layer_2': 0.0010370783284735904, 'l1_Layer_3': 5.0825546721606276e-05, 'l1_Layer_4': 0.0006067500129077887, 'n_units_Layer_1': 180, 'n_units_Layer_2': 295, 'n_units_Layer_3': 185, 'n_units_Layer_4': 50}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.51 | sMAPE for Validation Set is: 30.48% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 21.01 | sMAPE for Test Set is: 29.40% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:41:29,911]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:41:36,512]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:41:40,817]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:41:43,224]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:41:58,956]\u001b[0m Trial 1412 finished with value: 45.985416690215494 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009017705841399925, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10852858771348214, 'dropout_rate_Layer_2': 0.34994821753875843, 'dropout_rate_Layer_3': 0.3276810103185438, 'dropout_rate_Layer_4': 0.03396267546251514, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002810138175985341, 'l1_Layer_2': 1.796848743658904e-05, 'l1_Layer_3': 5.488856155799779e-05, 'l1_Layer_4': 0.0007821907958449837, 'n_units_Layer_1': 180, 'n_units_Layer_2': 295, 'n_units_Layer_3': 185, 'n_units_Layer_4': 50}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.99 | sMAPE for Validation Set is: 30.58% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 21.08 | sMAPE for Test Set is: 29.32% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:42:03,953]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:42:04,909]\u001b[0m Trial 1419 finished with value: 46.12127639533282 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010934704914791914, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008084205868474376, 'dropout_rate_Layer_2': 0.05117718242992843, 'dropout_rate_Layer_3': 0.24484609134049284, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004885160619520837, 'l1_Layer_2': 0.00017622925359335855, 'l1_Layer_3': 0.00012879793217685263, 'n_units_Layer_1': 60, 'n_units_Layer_2': 165, 'n_units_Layer_3': 165}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.12 | sMAPE for Validation Set is: 30.85% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 21.21 | sMAPE for Test Set is: 29.81% | rMAE for Test Set is: 0.58\n",
      "MAE for Validation Set is: 48.07 | sMAPE for Validation Set is: 31.53% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 23.61 | sMAPE for Test Set is: 32.45% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:42:07,703]\u001b[0m Trial 1418 finished with value: 48.066281747049345 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016776183824508783, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.047636660434730416, 'dropout_rate_Layer_2': 0.3783842323144511, 'dropout_rate_Layer_3': 0.23284061537933504, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020909745749046253, 'l1_Layer_2': 0.0005768084437405929, 'l1_Layer_3': 1.3991503417949222e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 255, 'n_units_Layer_3': 215}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:42:11,037]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:42:13,989]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:42:16,143]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:42:18,564]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:42:25,048]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:42:25,209]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:42:32,858]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:42:33,091]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:42:39,656]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:42:44,361]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:42:48,312]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:42:51,721]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:42:55,181]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:42:58,828]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:43:10,666]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:43:17,527]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:43:21,360]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:43:26,754]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:43:36,227]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:43:47,545]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:43:55,394]\u001b[0m Trial 1425 finished with value: 45.67849133696914 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005039172620556058, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10883017544519467, 'dropout_rate_Layer_2': 0.34900563968653237, 'dropout_rate_Layer_3': 0.3499587837648401, 'dropout_rate_Layer_4': 0.030664564548573796, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0029596598015415162, 'l1_Layer_2': 0.0013765336116056653, 'l1_Layer_3': 5.849664411531834e-05, 'l1_Layer_4': 0.0005742248620527687, 'n_units_Layer_1': 165, 'n_units_Layer_2': 295, 'n_units_Layer_3': 185, 'n_units_Layer_4': 50}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.68 | sMAPE for Validation Set is: 30.54% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 21.02 | sMAPE for Test Set is: 29.81% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:44:02,334]\u001b[0m Trial 1436 finished with value: 46.084501967343954 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008893215132685813, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10908476837806685, 'dropout_rate_Layer_2': 0.399796906594546, 'dropout_rate_Layer_3': 0.3541127723554847, 'dropout_rate_Layer_4': 0.03499626741343482, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0028549800320929754, 'l1_Layer_2': 1.228812778188209e-05, 'l1_Layer_3': 6.03774611504354e-05, 'l1_Layer_4': 0.0005378886600974444, 'n_units_Layer_1': 180, 'n_units_Layer_2': 295, 'n_units_Layer_3': 170, 'n_units_Layer_4': 50}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.08 | sMAPE for Validation Set is: 30.88% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 21.34 | sMAPE for Test Set is: 30.44% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:44:06,169]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:44:06,210]\u001b[0m Trial 1440 finished with value: 46.58969247431117 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018050721450428304, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.053322502304875626, 'dropout_rate_Layer_2': 0.3629173334624323, 'dropout_rate_Layer_3': 0.24312609156637932, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00039311141162289335, 'l1_Layer_2': 0.0006037153384240625, 'l1_Layer_3': 1.5343071614488233e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 255, 'n_units_Layer_3': 215}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.59 | sMAPE for Validation Set is: 31.07% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 22.92 | sMAPE for Test Set is: 32.28% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:44:06,480]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:44:15,747]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:44:20,395]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:44:24,008]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:44:24,909]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:44:31,247]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:44:31,600]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:44:39,952]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:44:42,896]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:44:46,844]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:44:50,361]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:44:57,166]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:45:01,909]\u001b[0m Trial 1454 finished with value: 46.471069598772885 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012480572059584824, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.000366160813236675, 'dropout_rate_Layer_2': 0.08311991744074239, 'dropout_rate_Layer_3': 0.21476240589236376, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.641569337704013e-05, 'l1_Layer_2': 0.00035711785947495453, 'l1_Layer_3': 5.861359740699371e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 70, 'n_units_Layer_3': 145}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.47 | sMAPE for Validation Set is: 30.98% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 22.36 | sMAPE for Test Set is: 30.13% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:45:20,211]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:45:21,055]\u001b[0m Trial 1460 finished with value: 45.94356822011968 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013153750846387861, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02989716354494075, 'dropout_rate_Layer_2': 0.08391490612548037, 'dropout_rate_Layer_3': 0.21281503983944267, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.910755261516099e-05, 'l1_Layer_2': 0.0003517310095227566, 'l1_Layer_3': 6.346006499434462e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 150, 'n_units_Layer_3': 145}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.94 | sMAPE for Validation Set is: 30.74% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 20.97 | sMAPE for Test Set is: 29.87% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:45:28,721]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:45:30,019]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:45:43,737]\u001b[0m Trial 1451 finished with value: 45.51080208123867 and parameters: {'n_hidden': 4, 'learning_rate': 0.000515543686963279, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09210521188533385, 'dropout_rate_Layer_2': 0.395061269262855, 'dropout_rate_Layer_3': 0.35141719742412314, 'dropout_rate_Layer_4': 0.03360463645015998, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0026425472490390466, 'l1_Layer_2': 0.00043814907858847143, 'l1_Layer_3': 5.9669794117990835e-05, 'l1_Layer_4': 0.0007135937063060927, 'n_units_Layer_1': 180, 'n_units_Layer_2': 295, 'n_units_Layer_3': 185, 'n_units_Layer_4': 50}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.51 | sMAPE for Validation Set is: 30.58% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 20.87 | sMAPE for Test Set is: 29.77% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:45:48,311]\u001b[0m Trial 1461 finished with value: 46.455160962277034 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016968151293582842, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.038001401541230884, 'dropout_rate_Layer_2': 0.38606489335847055, 'dropout_rate_Layer_3': 0.23697859627555443, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00021155562856331665, 'l1_Layer_2': 0.0004870048903892967, 'l1_Layer_3': 1.2340156748877159e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 250, 'n_units_Layer_3': 235}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.46 | sMAPE for Validation Set is: 31.00% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 22.15 | sMAPE for Test Set is: 31.45% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:45:51,715]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:45:55,496]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:45:56,507]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:46:04,044]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:46:07,688]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:46:11,866]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:46:12,829]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:46:19,089]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:46:22,035]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:46:23,930]\u001b[0m Trial 1464 finished with value: 46.976742876495884 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016242072290385216, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0577184054356376, 'dropout_rate_Layer_2': 0.3758234512707677, 'dropout_rate_Layer_3': 0.2393384720262547, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014368640084495745, 'l1_Layer_2': 0.000744751727921724, 'l1_Layer_3': 1.6809182386784652e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 260, 'n_units_Layer_3': 235}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.98 | sMAPE for Validation Set is: 31.85% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 22.55 | sMAPE for Test Set is: 31.93% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:46:25,784]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:46:34,254]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:46:35,511]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:46:36,068]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:46:44,826]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:46:46,439]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:47:06,519]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:47:12,279]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:47:13,313]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:47:18,985]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:47:26,100]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:47:26,402]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:47:32,387]\u001b[0m Trial 1479 finished with value: 47.82194827190991 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016173940341096369, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06011198310301633, 'dropout_rate_Layer_2': 0.3731015924718828, 'dropout_rate_Layer_3': 0.2262944210074248, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015116202208505073, 'l1_Layer_2': 0.0006919896776707859, 'l1_Layer_3': 2.2263781325906904e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 265, 'n_units_Layer_3': 240}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.82 | sMAPE for Validation Set is: 31.16% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 21.90 | sMAPE for Test Set is: 30.59% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:47:36,883]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:47:41,430]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:47:48,108]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:47:51,864]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:48:00,939]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:48:05,542]\u001b[0m Trial 1488 finished with value: 45.737859058498884 and parameters: {'n_hidden': 3, 'learning_rate': 0.001030663954880638, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0004637472748755238, 'dropout_rate_Layer_2': 0.09140973314155786, 'dropout_rate_Layer_3': 0.2328855872349297, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00027299061278561736, 'l1_Layer_2': 0.00013280503310681826, 'l1_Layer_3': 0.00023787251819355363, 'n_units_Layer_1': 105, 'n_units_Layer_2': 155, 'n_units_Layer_3': 160}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.74 | sMAPE for Validation Set is: 30.89% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 21.78 | sMAPE for Test Set is: 30.16% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:48:06,970]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:48:15,647]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:48:27,592]\u001b[0m Trial 1491 finished with value: 44.853286175349346 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010302186195190147, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.045287882058965036, 'dropout_rate_Layer_2': 0.1098935116998645, 'dropout_rate_Layer_3': 0.18655180974480504, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.837350306511916e-05, 'l1_Layer_2': 0.00013484973501116758, 'l1_Layer_3': 0.00022277504168468268, 'n_units_Layer_1': 105, 'n_units_Layer_2': 115, 'n_units_Layer_3': 160}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.85 | sMAPE for Validation Set is: 30.21% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 20.92 | sMAPE for Test Set is: 29.24% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:48:32,335]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 16:48:38,274]\u001b[0m Trial 1493 finished with value: 47.50719613574515 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016997848893650531, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04789518923314488, 'dropout_rate_Layer_2': 0.3641531484596549, 'dropout_rate_Layer_3': 0.22268351174953277, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015764090306259632, 'l1_Layer_2': 0.0005637154071958847, 'l1_Layer_3': 1.5712260876681583e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 265, 'n_units_Layer_3': 235}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.51 | sMAPE for Validation Set is: 31.42% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 23.22 | sMAPE for Test Set is: 32.70% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:48:45,693]\u001b[0m Trial 1496 finished with value: 47.408309866760476 and parameters: {'n_hidden': 3, 'learning_rate': 0.001707980567463752, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.056711959698407484, 'dropout_rate_Layer_2': 0.3639588386385562, 'dropout_rate_Layer_3': 0.23459359068542268, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.704910137518458e-05, 'l1_Layer_2': 0.0006174662577127942, 'l1_Layer_3': 2.1696273925190026e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 270, 'n_units_Layer_3': 230}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.41 | sMAPE for Validation Set is: 31.42% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 22.12 | sMAPE for Test Set is: 31.21% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 16:48:48,546]\u001b[0m Trial 1498 finished with value: 47.35912053241312 and parameters: {'n_hidden': 3, 'learning_rate': 0.00171005175536367, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.059644705705124895, 'dropout_rate_Layer_2': 0.36342853610818615, 'dropout_rate_Layer_3': 0.2356721300974086, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.115051180976722e-05, 'l1_Layer_2': 0.000611179185187181, 'l1_Layer_3': 2.104910142896202e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 270, 'n_units_Layer_3': 230}. Best is trial 961 with value: 44.73287015452294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.36 | sMAPE for Validation Set is: 30.79% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 22.05 | sMAPE for Test Set is: 31.14% | rMAE for Test Set is: 0.60\n",
      "for 2023-01-01, MAE is:17.27 & sMAPE is:129.57% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :17.27 & 129.57% & 0.19\n",
      "for 2023-01-02, MAE is:71.09 & sMAPE is:77.27% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :44.18 & 103.42% & 0.52\n",
      "for 2023-01-03, MAE is:31.59 & sMAPE is:24.86% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :39.99 & 77.23% & 0.54\n",
      "for 2023-01-04, MAE is:43.19 & sMAPE is:64.87% & rMAE is:1.91 ||| daily mean of MAE & sMAPE & rMAE till now are :40.79 & 74.14% & 0.88\n",
      "for 2023-01-05, MAE is:77.16 & sMAPE is:119.34% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :48.06 & 83.18% & 0.87\n",
      "for 2023-01-06, MAE is:12.35 & sMAPE is:10.45% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :42.11 & 71.06% & 0.75\n",
      "for 2023-01-07, MAE is:13.44 & sMAPE is:15.69% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :38.01 & 63.15% & 0.67\n",
      "for 2023-01-08, MAE is:35.64 & sMAPE is:73.30% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :37.72 & 64.42% & 0.67\n",
      "for 2023-01-09, MAE is:32.73 & sMAPE is:27.12% & rMAE is:3.34 ||| daily mean of MAE & sMAPE & rMAE till now are :37.16 & 60.27% & 0.97\n",
      "for 2023-01-10, MAE is:21.44 & sMAPE is:19.01% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :35.59 & 56.15% & 0.96\n",
      "for 2023-01-11, MAE is:29.51 & sMAPE is:64.28% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :35.04 & 56.89% & 0.94\n",
      "for 2023-01-12, MAE is:17.36 & sMAPE is:44.63% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :33.57 & 55.87% & 0.90\n",
      "for 2023-01-13, MAE is:12.96 & sMAPE is:34.52% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :31.98 & 54.22% & 0.85\n",
      "for 2023-01-14, MAE is:33.44 & sMAPE is:71.98% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :32.08 & 55.49% & 0.83\n",
      "for 2023-01-15, MAE is:9.31 & sMAPE is:119.05% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :30.57 & 59.73% & 0.79\n",
      "for 2023-01-16, MAE is:71.99 & sMAPE is:82.74% & rMAE is:6.27 ||| daily mean of MAE & sMAPE & rMAE till now are :33.16 & 61.17% & 1.13\n",
      "for 2023-01-17, MAE is:17.82 & sMAPE is:14.80% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :32.25 & 58.44% & 1.11\n",
      "for 2023-01-18, MAE is:20.04 & sMAPE is:16.69% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :31.57 & 56.12% & 1.07\n",
      "for 2023-01-19, MAE is:39.43 & sMAPE is:30.70% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :31.99 & 54.78% & 1.05\n",
      "for 2023-01-20, MAE is:45.05 & sMAPE is:28.32% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :32.64 & 53.46% & 1.01\n",
      "for 2023-01-21, MAE is:20.52 & sMAPE is:15.03% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :32.06 & 51.63% & 0.97\n",
      "for 2023-01-22, MAE is:44.27 & sMAPE is:33.90% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :32.62 & 50.82% & 0.95\n",
      "for 2023-01-23, MAE is:43.74 & sMAPE is:23.28% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :33.10 & 49.63% & 0.93\n",
      "for 2023-01-24, MAE is:45.29 & sMAPE is:24.60% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :33.61 & 48.58% & 0.92\n",
      "for 2023-01-25, MAE is:11.52 & sMAPE is:8.08% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :32.73 & 46.96% & 0.92\n",
      "for 2023-01-26, MAE is:29.37 & sMAPE is:20.77% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :32.60 & 45.96% & 0.93\n",
      "for 2023-01-27, MAE is:37.37 & sMAPE is:24.96% & rMAE is:2.59 ||| daily mean of MAE & sMAPE & rMAE till now are :32.77 & 45.18% & 0.99\n",
      "for 2023-01-28, MAE is:20.39 & sMAPE is:16.18% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :32.33 & 44.14% & 0.98\n",
      "for 2023-01-29, MAE is:13.75 & sMAPE is:14.10% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :31.69 & 43.11% & 0.96\n",
      "for 2023-01-30, MAE is:32.67 & sMAPE is:51.82% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :31.72 & 43.40% & 0.93\n",
      "for 2023-01-31, MAE is:17.19 & sMAPE is:21.77% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :31.26 & 42.70% & 0.91\n",
      "for 2023-02-01, MAE is:14.89 & sMAPE is:17.01% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :30.74 & 41.90% & 0.89\n",
      "for 2023-02-02, MAE is:49.81 & sMAPE is:42.14% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :31.32 & 41.90% & 0.91\n",
      "for 2023-02-03, MAE is:10.32 & sMAPE is:10.02% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :30.70 & 40.97% & 0.89\n",
      "for 2023-02-04, MAE is:57.23 & sMAPE is:49.04% & rMAE is:1.67 ||| daily mean of MAE & sMAPE & rMAE till now are :31.46 & 41.20% & 0.91\n",
      "for 2023-02-05, MAE is:19.23 & sMAPE is:18.92% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :31.12 & 40.58% & 0.92\n",
      "for 2023-02-06, MAE is:49.34 & sMAPE is:33.39% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :31.61 & 40.38% & 0.91\n",
      "for 2023-02-07, MAE is:27.07 & sMAPE is:16.15% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :31.49 & 39.75% & 0.89\n",
      "for 2023-02-08, MAE is:39.79 & sMAPE is:28.26% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :31.71 & 39.45% & 0.89\n",
      "for 2023-02-09, MAE is:10.80 & sMAPE is:11.31% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :31.18 & 38.75% & 0.88\n",
      "for 2023-02-10, MAE is:23.83 & sMAPE is:24.31% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :31.01 & 38.40% & 0.88\n",
      "for 2023-02-11, MAE is:38.24 & sMAPE is:58.41% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :31.18 & 38.87% & 0.87\n",
      "for 2023-02-12, MAE is:26.28 & sMAPE is:23.73% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :31.06 & 38.52% & 0.89\n",
      "for 2023-02-13, MAE is:32.38 & sMAPE is:21.83% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :31.09 & 38.14% & 0.90\n",
      "for 2023-02-14, MAE is:15.90 & sMAPE is:10.18% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :30.76 & 37.52% & 0.90\n",
      "for 2023-02-15, MAE is:20.75 & sMAPE is:15.35% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :30.54 & 37.04% & 0.90\n",
      "for 2023-02-16, MAE is:23.11 & sMAPE is:18.38% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :30.38 & 36.64% & 0.89\n",
      "for 2023-02-17, MAE is:32.05 & sMAPE is:38.52% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :30.42 & 36.68% & 0.90\n",
      "for 2023-02-18, MAE is:42.57 & sMAPE is:61.88% & rMAE is:2.67 ||| daily mean of MAE & sMAPE & rMAE till now are :30.66 & 37.20% & 0.94\n",
      "for 2023-02-19, MAE is:10.95 & sMAPE is:10.80% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :30.27 & 36.67% & 0.93\n",
      "for 2023-02-20, MAE is:26.87 & sMAPE is:43.29% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :30.20 & 36.80% & 0.92\n",
      "for 2023-02-21, MAE is:28.99 & sMAPE is:27.01% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :30.18 & 36.61% & 0.91\n",
      "for 2023-02-22, MAE is:14.87 & sMAPE is:10.69% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :29.89 & 36.12% & 0.92\n",
      "for 2023-02-23, MAE is:18.10 & sMAPE is:14.37% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :29.67 & 35.72% & 0.92\n",
      "for 2023-02-24, MAE is:10.41 & sMAPE is:10.51% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :29.32 & 35.26% & 0.91\n",
      "for 2023-02-25, MAE is:11.53 & sMAPE is:16.45% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :29.00 & 34.92% & 0.90\n",
      "for 2023-02-26, MAE is:30.71 & sMAPE is:31.55% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :29.03 & 34.86% & 0.91\n",
      "for 2023-02-27, MAE is:22.10 & sMAPE is:15.68% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :28.91 & 34.53% & 0.90\n",
      "for 2023-02-28, MAE is:16.00 & sMAPE is:10.77% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :28.70 & 34.13% & 0.89\n",
      "for 2023-03-01, MAE is:18.31 & sMAPE is:12.47% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :28.52 & 33.77% & 0.91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2023-03-02, MAE is:15.86 & sMAPE is:11.18% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :28.31 & 33.40% & 0.91\n",
      "for 2023-03-03, MAE is:25.85 & sMAPE is:21.16% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :28.28 & 33.20% & 0.91\n",
      "for 2023-03-04, MAE is:49.43 & sMAPE is:63.73% & rMAE is:1.95 ||| daily mean of MAE & sMAPE & rMAE till now are :28.61 & 33.69% & 0.92\n",
      "for 2023-03-05, MAE is:20.04 & sMAPE is:17.91% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :28.48 & 33.44% & 0.94\n",
      "for 2023-03-06, MAE is:31.29 & sMAPE is:22.11% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :28.52 & 33.27% & 0.94\n",
      "for 2023-03-07, MAE is:16.38 & sMAPE is:15.05% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :28.34 & 32.99% & 0.93\n",
      "for 2023-03-08, MAE is:22.70 & sMAPE is:17.55% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :28.25 & 32.76% & 0.94\n",
      "for 2023-03-09, MAE is:17.52 & sMAPE is:14.61% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :28.09 & 32.49% & 0.94\n",
      "for 2023-03-10, MAE is:20.53 & sMAPE is:19.30% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :27.98 & 32.30% & 0.94\n",
      "for 2023-03-11, MAE is:14.90 & sMAPE is:17.18% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :27.80 & 32.08% & 0.94\n",
      "for 2023-03-12, MAE is:15.47 & sMAPE is:18.41% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :27.62 & 31.89% & 0.93\n",
      "for 2023-03-13, MAE is:42.07 & sMAPE is:90.08% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :27.82 & 32.70% & 0.92\n",
      "for 2023-03-14, MAE is:28.06 & sMAPE is:66.69% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :27.83 & 33.17% & 0.92\n",
      "for 2023-03-15, MAE is:31.39 & sMAPE is:33.89% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :27.88 & 33.18% & 0.92\n",
      "for 2023-03-16, MAE is:15.75 & sMAPE is:16.02% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :27.71 & 32.95% & 0.92\n",
      "for 2023-03-17, MAE is:17.47 & sMAPE is:20.29% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :27.58 & 32.78% & 0.91\n",
      "for 2023-03-18, MAE is:19.94 & sMAPE is:19.28% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :27.48 & 32.60% & 0.91\n",
      "for 2023-03-19, MAE is:16.03 & sMAPE is:15.00% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :27.33 & 32.38% & 0.91\n",
      "for 2023-03-20, MAE is:11.21 & sMAPE is:9.23% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :27.13 & 32.09% & 0.90\n",
      "for 2023-03-21, MAE is:16.82 & sMAPE is:14.82% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :27.00 & 31.87% & 0.90\n",
      "for 2023-03-22, MAE is:15.16 & sMAPE is:25.93% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :26.85 & 31.80% & 0.89\n",
      "for 2023-03-23, MAE is:13.58 & sMAPE is:22.49% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :26.69 & 31.68% & 0.88\n",
      "for 2023-03-24, MAE is:25.14 & sMAPE is:54.76% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :26.67 & 31.96% & 0.88\n",
      "for 2023-03-25, MAE is:44.56 & sMAPE is:138.09% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :26.89 & 33.22% & 0.88\n",
      "for 2023-03-26, MAE is:42.29 & sMAPE is:88.87% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :27.07 & 33.88% & 0.88\n",
      "for 2023-03-27, MAE is:16.08 & sMAPE is:18.83% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :26.94 & 33.70% & 0.87\n",
      "for 2023-03-28, MAE is:40.08 & sMAPE is:42.39% & rMAE is:1.94 ||| daily mean of MAE & sMAPE & rMAE till now are :27.09 & 33.80% & 0.89\n",
      "for 2023-03-29, MAE is:22.98 & sMAPE is:21.75% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :27.04 & 33.67% & 0.88\n",
      "for 2023-03-30, MAE is:21.16 & sMAPE is:34.51% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :26.98 & 33.68% & 0.88\n",
      "for 2023-03-31, MAE is:22.96 & sMAPE is:25.09% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :26.93 & 33.58% & 0.88\n",
      "for 2023-04-01, MAE is:8.38 & sMAPE is:15.13% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :26.73 & 33.38% & 0.87\n",
      "for 2023-04-02, MAE is:19.72 & sMAPE is:31.35% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :26.65 & 33.36% & 0.87\n",
      "for 2023-04-03, MAE is:26.83 & sMAPE is:26.29% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :26.66 & 33.28% & 0.87\n",
      "for 2023-04-04, MAE is:17.55 & sMAPE is:14.04% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :26.56 & 33.08% & 0.87\n",
      "for 2023-04-05, MAE is:18.32 & sMAPE is:12.99% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :26.47 & 32.86% & 0.87\n",
      "for 2023-04-06, MAE is:18.90 & sMAPE is:17.21% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :26.39 & 32.70% & 0.87\n",
      "for 2023-04-07, MAE is:12.38 & sMAPE is:12.40% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :26.25 & 32.49% & 0.86\n",
      "for 2023-04-08, MAE is:10.32 & sMAPE is:10.38% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :26.09 & 32.27% & 0.86\n",
      "for 2023-04-09, MAE is:17.23 & sMAPE is:18.66% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :26.00 & 32.13% & 0.85\n",
      "for 2023-04-10, MAE is:33.54 & sMAPE is:87.56% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :26.07 & 32.68% & 0.85\n",
      "for 2023-04-11, MAE is:47.56 & sMAPE is:131.33% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :26.28 & 33.66% & 0.85\n",
      "for 2023-04-12, MAE is:13.88 & sMAPE is:13.96% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :26.16 & 33.47% & 0.84\n",
      "for 2023-04-13, MAE is:30.39 & sMAPE is:34.68% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :26.20 & 33.48% & 0.84\n",
      "for 2023-04-14, MAE is:30.95 & sMAPE is:27.68% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :26.25 & 33.42% & 0.85\n",
      "for 2023-04-15, MAE is:32.70 & sMAPE is:40.41% & rMAE is:3.40 ||| daily mean of MAE & sMAPE & rMAE till now are :26.31 & 33.49% & 0.87\n",
      "for 2023-04-16, MAE is:15.61 & sMAPE is:17.14% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :26.21 & 33.34% & 0.87\n",
      "for 2023-04-17, MAE is:34.42 & sMAPE is:33.28% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :26.29 & 33.33% & 0.87\n",
      "for 2023-04-18, MAE is:18.97 & sMAPE is:20.04% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :26.22 & 33.21% & 0.86\n",
      "for 2023-04-19, MAE is:25.23 & sMAPE is:44.82% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :26.21 & 33.32% & 0.86\n",
      "for 2023-04-20, MAE is:17.17 & sMAPE is:25.59% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :26.13 & 33.25% & 0.86\n",
      "for 2023-04-21, MAE is:23.21 & sMAPE is:43.44% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :26.10 & 33.34% & 0.86\n",
      "for 2023-04-22, MAE is:16.68 & sMAPE is:33.04% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :26.02 & 33.34% & 0.86\n",
      "for 2023-04-23, MAE is:27.72 & sMAPE is:45.11% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :26.03 & 33.44% & 0.86\n",
      "for 2023-04-24, MAE is:14.73 & sMAPE is:13.74% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :25.93 & 33.27% & 0.86\n",
      "for 2023-04-25, MAE is:20.27 & sMAPE is:36.00% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :25.88 & 33.29% & 0.86\n",
      "for 2023-04-26, MAE is:20.54 & sMAPE is:29.98% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :25.84 & 33.26% & 0.86\n",
      "for 2023-04-27, MAE is:43.36 & sMAPE is:54.49% & rMAE is:2.14 ||| daily mean of MAE & sMAPE & rMAE till now are :25.99 & 33.45% & 0.87\n",
      "for 2023-04-28, MAE is:26.08 & sMAPE is:30.45% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :25.99 & 33.42% & 0.88\n",
      "for 2023-04-29, MAE is:38.98 & sMAPE is:55.88% & rMAE is:2.01 ||| daily mean of MAE & sMAPE & rMAE till now are :26.10 & 33.61% & 0.89\n",
      "for 2023-04-30, MAE is:28.04 & sMAPE is:64.62% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :26.11 & 33.87% & 0.89\n",
      "for 2023-05-01, MAE is:23.30 & sMAPE is:26.93% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :26.09 & 33.81% & 0.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2023-05-02, MAE is:22.05 & sMAPE is:24.43% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :26.06 & 33.73% & 0.89\n",
      "for 2023-05-03, MAE is:20.32 & sMAPE is:23.30% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :26.01 & 33.65% & 0.89\n",
      "for 2023-05-04, MAE is:14.17 & sMAPE is:15.43% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :25.92 & 33.50% & 0.89\n",
      "for 2023-05-05, MAE is:19.87 & sMAPE is:49.50% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :25.87 & 33.63% & 0.89\n",
      "for 2023-05-06, MAE is:28.69 & sMAPE is:53.92% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :25.89 & 33.79% & 0.89\n",
      "for 2023-05-07, MAE is:25.39 & sMAPE is:64.55% & rMAE is:2.42 ||| daily mean of MAE & sMAPE & rMAE till now are :25.89 & 34.03% & 0.90\n",
      "for 2023-05-08, MAE is:28.01 & sMAPE is:42.84% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :25.90 & 34.10% & 0.91\n",
      "for 2023-05-09, MAE is:15.70 & sMAPE is:21.22% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :25.82 & 34.00% & 0.91\n",
      "for 2023-05-10, MAE is:26.31 & sMAPE is:34.86% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :25.83 & 34.01% & 0.91\n",
      "for 2023-05-11, MAE is:28.41 & sMAPE is:28.30% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :25.85 & 33.96% & 0.92\n",
      "for 2023-05-12, MAE is:18.06 & sMAPE is:19.29% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :25.79 & 33.85% & 0.91\n",
      "for 2023-05-13, MAE is:18.62 & sMAPE is:40.80% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :25.73 & 33.91% & 0.91\n",
      "for 2023-05-14, MAE is:25.06 & sMAPE is:57.68% & rMAE is:2.11 ||| daily mean of MAE & sMAPE & rMAE till now are :25.73 & 34.08% & 0.92\n",
      "for 2023-05-15, MAE is:32.03 & sMAPE is:33.62% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :25.78 & 34.08% & 0.92\n",
      "for 2023-05-16, MAE is:22.43 & sMAPE is:38.23% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :25.75 & 34.11% & 0.92\n",
      "for 2023-05-17, MAE is:31.67 & sMAPE is:104.37% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :25.79 & 34.62% & 0.92\n",
      "for 2023-05-18, MAE is:17.12 & sMAPE is:22.94% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :25.73 & 34.54% & 0.92\n",
      "for 2023-05-19, MAE is:18.80 & sMAPE is:25.49% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :25.68 & 34.47% & 0.92\n",
      "for 2023-05-20, MAE is:18.12 & sMAPE is:69.55% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :25.63 & 34.72% & 0.92\n",
      "for 2023-05-21, MAE is:20.17 & sMAPE is:96.18% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :25.59 & 35.16% & 0.92\n",
      "for 2023-05-22, MAE is:31.02 & sMAPE is:44.21% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :25.63 & 35.22% & 0.92\n",
      "for 2023-05-23, MAE is:15.78 & sMAPE is:37.25% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :25.56 & 35.24% & 0.92\n",
      "for 2023-05-24, MAE is:48.26 & sMAPE is:73.43% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :25.72 & 35.50% & 0.92\n",
      "for 2023-05-25, MAE is:17.35 & sMAPE is:45.65% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :25.66 & 35.57% & 0.92\n",
      "for 2023-05-26, MAE is:27.53 & sMAPE is:75.57% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :25.67 & 35.85% & 0.92\n",
      "for 2023-05-27, MAE is:25.58 & sMAPE is:81.36% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :25.67 & 36.16% & 0.92\n",
      "for 2023-05-28, MAE is:34.25 & sMAPE is:89.41% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :25.73 & 36.52% & 0.92\n",
      "for 2023-05-29, MAE is:33.67 & sMAPE is:87.22% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :25.78 & 36.86% & 0.92\n",
      "for 2023-05-30, MAE is:35.54 & sMAPE is:57.09% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :25.85 & 36.99% & 0.92\n",
      "for 2023-05-31, MAE is:29.98 & sMAPE is:58.31% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :25.87 & 37.13% & 0.92\n",
      "for 2023-06-01, MAE is:42.58 & sMAPE is:110.86% & rMAE is:2.46 ||| daily mean of MAE & sMAPE & rMAE till now are :25.98 & 37.62% & 0.93\n",
      "for 2023-06-02, MAE is:14.54 & sMAPE is:19.92% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :25.91 & 37.50% & 0.93\n",
      "for 2023-06-03, MAE is:20.28 & sMAPE is:81.82% & rMAE is:2.45 ||| daily mean of MAE & sMAPE & rMAE till now are :25.87 & 37.79% & 0.94\n",
      "for 2023-06-04, MAE is:27.05 & sMAPE is:91.58% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :25.88 & 38.14% & 0.94\n",
      "for 2023-06-05, MAE is:43.60 & sMAPE is:77.58% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :25.99 & 38.39% & 0.94\n",
      "for 2023-06-06, MAE is:21.34 & sMAPE is:23.69% & rMAE is:2.12 ||| daily mean of MAE & sMAPE & rMAE till now are :25.96 & 38.30% & 0.94\n",
      "for 2023-06-07, MAE is:19.72 & sMAPE is:21.62% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :25.92 & 38.19% & 0.94\n",
      "for 2023-06-08, MAE is:14.87 & sMAPE is:20.13% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :25.85 & 38.08% & 0.94\n",
      "for 2023-06-09, MAE is:12.87 & sMAPE is:17.35% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :25.77 & 37.95% & 0.94\n",
      "for 2023-06-10, MAE is:25.89 & sMAPE is:82.65% & rMAE is:3.59 ||| daily mean of MAE & sMAPE & rMAE till now are :25.77 & 38.22% & 0.96\n",
      "for 2023-06-11, MAE is:31.23 & sMAPE is:103.45% & rMAE is:2.34 ||| daily mean of MAE & sMAPE & rMAE till now are :25.81 & 38.63% & 0.97\n",
      "for 2023-06-12, MAE is:43.44 & sMAPE is:61.57% & rMAE is:4.77 ||| daily mean of MAE & sMAPE & rMAE till now are :25.92 & 38.77% & 0.99\n",
      "for 2023-06-13, MAE is:14.35 & sMAPE is:17.83% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :25.85 & 38.64% & 0.99\n",
      "for 2023-06-14, MAE is:24.09 & sMAPE is:27.14% & rMAE is:4.21 ||| daily mean of MAE & sMAPE & rMAE till now are :25.84 & 38.57% & 1.01\n",
      "for 2023-06-15, MAE is:42.29 & sMAPE is:41.85% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :25.93 & 38.59% & 1.01\n",
      "for 2023-06-16, MAE is:15.49 & sMAPE is:12.29% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :25.87 & 38.43% & 1.01\n",
      "for 2023-06-17, MAE is:16.70 & sMAPE is:18.59% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :25.82 & 38.31% & 1.01\n",
      "for 2023-06-18, MAE is:18.22 & sMAPE is:24.37% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :25.77 & 38.23% & 1.00\n",
      "for 2023-06-19, MAE is:21.89 & sMAPE is:19.40% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :25.75 & 38.12% & 1.00\n",
      "for 2023-06-20, MAE is:15.77 & sMAPE is:13.42% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :25.69 & 37.98% & 1.00\n",
      "for 2023-06-21, MAE is:20.59 & sMAPE is:17.34% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :25.66 & 37.86% & 1.00\n",
      "for 2023-06-22, MAE is:13.22 & sMAPE is:10.99% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :25.59 & 37.70% & 1.00\n",
      "for 2023-06-23, MAE is:15.18 & sMAPE is:16.32% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :25.53 & 37.58% & 1.00\n",
      "for 2023-06-24, MAE is:25.43 & sMAPE is:48.88% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :25.53 & 37.64% & 1.00\n",
      "for 2023-06-25, MAE is:31.33 & sMAPE is:75.46% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :25.56 & 37.86% & 1.00\n",
      "for 2023-06-26, MAE is:27.83 & sMAPE is:27.97% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :25.57 & 37.80% & 1.00\n",
      "for 2023-06-27, MAE is:56.57 & sMAPE is:128.45% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :25.75 & 38.31% & 1.00\n",
      "for 2023-06-28, MAE is:28.26 & sMAPE is:29.95% & rMAE is:2.26 ||| daily mean of MAE & sMAPE & rMAE till now are :25.76 & 38.27% & 1.01\n",
      "for 2023-06-29, MAE is:29.06 & sMAPE is:28.86% & rMAE is:2.69 ||| daily mean of MAE & sMAPE & rMAE till now are :25.78 & 38.21% & 1.02\n",
      "for 2023-06-30, MAE is:11.49 & sMAPE is:10.94% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :25.70 & 38.06% & 1.02\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:35:41,541]\u001b[0m A new study created in RDB with name: DK_2_2018\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:35:56,127]\u001b[0m Trial 0 finished with value: 5.349662614521368 and parameters: {'n_hidden': 3, 'learning_rate': 0.013370166978461872, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3980986010078696, 'dropout_rate_Layer_2': 0.20832401047288418, 'dropout_rate_Layer_3': 0.023353477676138868, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.5097927454870166e-05, 'l1_Layer_2': 0.0001665117851153464, 'l1_Layer_3': 0.00017470611223332369, 'n_units_Layer_1': 260, 'n_units_Layer_2': 205, 'n_units_Layer_3': 175}. Best is trial 0 with value: 5.349662614521368.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:35:56,200]\u001b[0m Trial 3 pruned. Trial was pruned at epoch 10.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.35 | sMAPE for Validation Set is: 18.38% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.89 | sMAPE for Test Set is: 26.17% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:35:56,412]\u001b[0m Trial 2 pruned. Trial was pruned at epoch 29.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:36:04,705]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:36:05,896]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:36:10,361]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:36:13,509]\u001b[0m Trial 1 finished with value: 5.167182065985501 and parameters: {'n_hidden': 4, 'learning_rate': 0.0023688876972356066, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2540629029320416, 'dropout_rate_Layer_2': 0.10334960493494494, 'dropout_rate_Layer_3': 0.12846092942525464, 'dropout_rate_Layer_4': 0.09437903061033004, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 2.5028818307743447e-05, 'l1_Layer_2': 0.0012321071466172768, 'l1_Layer_3': 2.8538941181306932e-05, 'l1_Layer_4': 4.719712794598612e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 195, 'n_units_Layer_3': 120, 'n_units_Layer_4': 90}. Best is trial 1 with value: 5.167182065985501.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.17 | sMAPE for Validation Set is: 17.97% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.65 | sMAPE for Test Set is: 27.92% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:36:15,236]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:36:19,101]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:36:21,369]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.37 | sMAPE for Validation Set is: 24.98% | rMAE for Validation Set is: 0.92\n",
      "MAE for Test Set is: 19.83 | sMAPE for Test Set is: 51.21% | rMAE for Test Set is: 1.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:36:24,419]\u001b[0m Trial 5 finished with value: 7.370569289729581 and parameters: {'n_hidden': 4, 'learning_rate': 0.0234318234676427, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2049005991101367, 'dropout_rate_Layer_2': 0.013769085733754773, 'dropout_rate_Layer_3': 0.39862909811357716, 'dropout_rate_Layer_4': 0.26961924739187143, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.01647065483296926, 'l1_Layer_2': 0.0016052309490505695, 'l1_Layer_3': 0.0008358016176213567, 'l1_Layer_4': 2.5142170188827103e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 155, 'n_units_Layer_3': 70, 'n_units_Layer_4': 265}. Best is trial 1 with value: 5.167182065985501.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:36:25,221]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:36:30,924]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:36:33,684]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:36:36,674]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:36:37,026]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:36:37,450]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:36:42,510]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:36:44,395]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:36:44,811]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:36:45,336]\u001b[0m Trial 8 finished with value: 5.935687567412966 and parameters: {'n_hidden': 3, 'learning_rate': 0.04727521424796431, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15928264005889667, 'dropout_rate_Layer_2': 0.012069489781463006, 'dropout_rate_Layer_3': 0.2030915410497671, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.06460067343603879, 'l1_Layer_2': 0.00253997598593876, 'l1_Layer_3': 3.105210413080149e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 275, 'n_units_Layer_3': 220}. Best is trial 1 with value: 5.167182065985501.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.94 | sMAPE for Validation Set is: 20.12% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 10.19 | sMAPE for Test Set is: 24.40% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:36:48,774]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:36:55,775]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:36:55,915]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:37:01,267]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:37:05,024]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:37:08,507]\u001b[0m Trial 26 finished with value: 6.647022718699508 and parameters: {'n_hidden': 3, 'learning_rate': 0.025830826178140545, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3303955501510891, 'dropout_rate_Layer_2': 0.23219061178817807, 'dropout_rate_Layer_3': 0.2941151291815913, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 3.816850051659772e-05, 'l1_Layer_2': 0.000360559661458332, 'l1_Layer_3': 0.06912874942852891, 'n_units_Layer_1': 275, 'n_units_Layer_2': 155, 'n_units_Layer_3': 245}. Best is trial 1 with value: 5.167182065985501.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.65 | sMAPE for Validation Set is: 21.77% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 14.64 | sMAPE for Test Set is: 35.21% | rMAE for Test Set is: 1.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:37:10,262]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:37:16,336]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:37:20,358]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:37:24,406]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:37:44,977]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:37:45,154]\u001b[0m Trial 23 finished with value: 5.679849410634245 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009471955955203632, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30291518152231367, 'dropout_rate_Layer_2': 0.340804442326832, 'dropout_rate_Layer_3': 0.3281639876836313, 'dropout_rate_Layer_4': 0.1464452237223035, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.6303000405625213e-05, 'l1_Layer_2': 0.00011230719039413848, 'l1_Layer_3': 0.03667422808388833, 'l1_Layer_4': 0.027832815625863143, 'n_units_Layer_1': 185, 'n_units_Layer_2': 215, 'n_units_Layer_3': 160, 'n_units_Layer_4': 60}. Best is trial 1 with value: 5.167182065985501.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.68 | sMAPE for Validation Set is: 19.48% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 15.05 | sMAPE for Test Set is: 36.54% | rMAE for Test Set is: 1.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:37:50,243]\u001b[0m Trial 30 finished with value: 5.4779535911469495 and parameters: {'n_hidden': 3, 'learning_rate': 0.008808564147252205, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.004997036777058295, 'dropout_rate_Layer_2': 0.1546415280098081, 'dropout_rate_Layer_3': 0.13788027939863076, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 1.6451698144697214e-05, 'l1_Layer_2': 0.01762431504620386, 'l1_Layer_3': 0.0027269858034554085, 'n_units_Layer_1': 295, 'n_units_Layer_2': 125, 'n_units_Layer_3': 165}. Best is trial 1 with value: 5.167182065985501.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.48 | sMAPE for Validation Set is: 19.10% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 12.72 | sMAPE for Test Set is: 31.33% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:37:53,498]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:37:56,510]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:37:56,993]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:38:01,539]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:38:01,827]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:38:08,339]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:38:12,269]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:38:15,317]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:38:19,195]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:38:23,808]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:38:23,906]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:38:30,942]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:38:36,029]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:38:41,191]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:38:41,245]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:38:47,911]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:38:51,272]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:38:53,984]\u001b[0m Trial 52 finished with value: 7.147759459422731 and parameters: {'n_hidden': 4, 'learning_rate': 0.026704290918250613, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25498453018430073, 'dropout_rate_Layer_2': 0.3191582953176844, 'dropout_rate_Layer_3': 0.3614633151877327, 'dropout_rate_Layer_4': 0.08622571785626532, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00017221898435635277, 'l1_Layer_2': 9.499013244763963e-05, 'l1_Layer_3': 2.160914905683066e-05, 'l1_Layer_4': 9.743766944586724e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 125, 'n_units_Layer_3': 70, 'n_units_Layer_4': 125}. Best is trial 1 with value: 5.167182065985501.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.15 | sMAPE for Validation Set is: 23.65% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 16.17 | sMAPE for Test Set is: 40.34% | rMAE for Test Set is: 1.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:38:56,956]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:39:00,139]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:39:04,038]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:39:07,730]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:39:10,673]\u001b[0m Trial 34 finished with value: 5.452935599312881 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014344033684286575, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24627774222599152, 'dropout_rate_Layer_2': 0.03485816599530356, 'dropout_rate_Layer_3': 0.28439204986083866, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0747563243550215, 'l1_Layer_2': 0.00012390616697097854, 'l1_Layer_3': 0.01030252048275851, 'n_units_Layer_1': 260, 'n_units_Layer_2': 70, 'n_units_Layer_3': 195}. Best is trial 1 with value: 5.167182065985501.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.45 | sMAPE for Validation Set is: 18.67% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.94 | sMAPE for Test Set is: 26.02% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:39:13,791]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:39:16,849]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:39:20,795]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:39:22,615]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:39:27,998]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:39:29,777]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:39:34,044]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:39:37,058]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:39:41,639]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:39:42,144]\u001b[0m Trial 42 finished with value: 5.193662348329412 and parameters: {'n_hidden': 3, 'learning_rate': 0.012506555685305653, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3194680356293118, 'dropout_rate_Layer_2': 0.15869192493469844, 'dropout_rate_Layer_3': 0.04264779180589726, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008956269136990592, 'l1_Layer_2': 0.0010188831280817643, 'l1_Layer_3': 2.600564650427352e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 235, 'n_units_Layer_3': 165}. Best is trial 1 with value: 5.167182065985501.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.19 | sMAPE for Validation Set is: 18.12% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 7.16 | sMAPE for Test Set is: 17.69% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:39:46,704]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:39:47,184]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:39:52,044]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:39:52,656]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:39:53,927]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:39:59,405]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:40:00,693]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:40:04,429]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:40:06,604]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:40:07,783]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:40:16,142]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:40:22,623]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:40:28,384]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:40:32,072]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:40:34,419]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:40:37,463]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:40:42,541]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:40:45,800]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.31 | sMAPE for Validation Set is: 18.56% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.47 | sMAPE for Test Set is: 24.99% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:40:49,529]\u001b[0m Trial 81 finished with value: 5.311484351249159 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014018674909861862, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11729645753533734, 'dropout_rate_Layer_2': 0.25308284151691396, 'dropout_rate_Layer_3': 0.29516537293565087, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0040888242546751035, 'l1_Layer_2': 0.00046221212061421294, 'l1_Layer_3': 0.00039735061213347903, 'n_units_Layer_1': 110, 'n_units_Layer_2': 120, 'n_units_Layer_3': 95}. Best is trial 1 with value: 5.167182065985501.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:40:49,613]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:40:52,626]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:40:56,876]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:40:58,248]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:41:01,549]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:41:04,018]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:41:05,547]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:41:13,690]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:41:17,031]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:41:17,391]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:41:17,897]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:41:18,037]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:41:24,769]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:41:25,396]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:41:29,776]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:41:30,362]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:41:33,197]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:41:36,201]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:41:37,957]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:41:42,185]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:41:44,078]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:41:46,882]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:41:47,187]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:41:52,715]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:41:52,919]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:41:58,942]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:42:02,094]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:42:05,104]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:42:12,019]\u001b[0m Trial 104 finished with value: 5.179132331292834 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008160420132160997, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3559134035097215, 'dropout_rate_Layer_2': 0.22174371530024897, 'dropout_rate_Layer_3': 0.04865528221227314, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.592748364268525e-05, 'l1_Layer_2': 0.00010017933008544978, 'l1_Layer_3': 3.782835667608764e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 295, 'n_units_Layer_3': 215}. Best is trial 1 with value: 5.167182065985501.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.18 | sMAPE for Validation Set is: 18.07% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.10 | sMAPE for Test Set is: 17.85% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:42:12,683]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:42:22,099]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:42:23,095]\u001b[0m Trial 113 finished with value: 5.187594047272007 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032604536367531745, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3868972276790149, 'dropout_rate_Layer_2': 0.0814297398347366, 'dropout_rate_Layer_3': 0.3080154363618133, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005753925097983156, 'l1_Layer_2': 3.5973979887958605e-05, 'l1_Layer_3': 0.00010784271573621997, 'n_units_Layer_1': 115, 'n_units_Layer_2': 255, 'n_units_Layer_3': 160}. Best is trial 1 with value: 5.167182065985501.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.19 | sMAPE for Validation Set is: 18.00% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 7.63 | sMAPE for Test Set is: 18.64% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:42:25,979]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:42:33,207]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:42:33,490]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:42:34,122]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:42:43,237]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:42:47,781]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:42:47,909]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:42:48,614]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:42:55,385]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:42:55,912]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:42:57,832]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:43:01,733]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:43:05,760]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:43:10,495]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:43:14,996]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:43:20,336]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:43:24,137]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:43:28,337]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:43:28,805]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:43:33,976]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:43:37,344]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:43:40,367]\u001b[0m Trial 128 finished with value: 5.020234724204411 and parameters: {'n_hidden': 3, 'learning_rate': 0.000599151430582577, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0257797590076983, 'dropout_rate_Layer_2': 0.13352163734538353, 'dropout_rate_Layer_3': 0.0739797542048474, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.192477559772637e-05, 'l1_Layer_2': 0.00029548194323881296, 'l1_Layer_3': 4.22312635836303e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 145, 'n_units_Layer_3': 245}. Best is trial 128 with value: 5.020234724204411.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.02 | sMAPE for Validation Set is: 17.68% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.85 | sMAPE for Test Set is: 17.04% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:43:44,622]\u001b[0m Trial 131 finished with value: 5.07451799529863 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006314031440469359, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.018247530239340448, 'dropout_rate_Layer_2': 0.13067102302024647, 'dropout_rate_Layer_3': 0.05178505350936728, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.712450937933413e-05, 'l1_Layer_2': 0.00019953429785851383, 'l1_Layer_3': 4.250498138886127e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 150, 'n_units_Layer_3': 255}. Best is trial 128 with value: 5.020234724204411.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.07 | sMAPE for Validation Set is: 17.77% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 7.14 | sMAPE for Test Set is: 17.43% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:43:47,621]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:43:50,553]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:43:53,685]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:43:54,312]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:43:54,742]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:44:01,059]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:44:03,050]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:44:03,732]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:44:08,861]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:44:13,604]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:44:19,528]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:44:21,276]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:44:26,626]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:44:28,485]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:44:31,732]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:44:32,734]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:44:33,018]\u001b[0m Trial 143 finished with value: 5.235287504071992 and parameters: {'n_hidden': 3, 'learning_rate': 0.006162654519839897, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33015015064377, 'dropout_rate_Layer_2': 0.07530093140361649, 'dropout_rate_Layer_3': 0.11572103406457548, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.02250085521797825, 'l1_Layer_2': 0.004338293832612644, 'l1_Layer_3': 0.00010441573310327794, 'n_units_Layer_1': 85, 'n_units_Layer_2': 95, 'n_units_Layer_3': 230}. Best is trial 128 with value: 5.020234724204411.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.24 | sMAPE for Validation Set is: 18.37% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 9.86 | sMAPE for Test Set is: 24.04% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:44:39,282]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:44:42,897]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:44:43,331]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:44:47,183]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:44:49,552]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:44:53,684]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:44:54,269]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:45:00,006]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:45:04,467]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:45:05,108]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:45:15,666]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:45:20,141]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:45:23,347]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:45:32,278]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:45:33,012]\u001b[0m Trial 159 finished with value: 5.31721995704445 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009830910419527464, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19480995519130465, 'dropout_rate_Layer_2': 0.1388601724355507, 'dropout_rate_Layer_3': 0.2111447313993231, 'dropout_rate_Layer_4': 0.17323672807563317, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0070754521335133595, 'l1_Layer_2': 5.477843801625251e-05, 'l1_Layer_3': 0.016565975036339643, 'l1_Layer_4': 0.0018912814107110466, 'n_units_Layer_1': 125, 'n_units_Layer_2': 260, 'n_units_Layer_3': 145, 'n_units_Layer_4': 165}. Best is trial 128 with value: 5.020234724204411.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.32 | sMAPE for Validation Set is: 18.35% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 11.78 | sMAPE for Test Set is: 28.02% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:45:35,271]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:45:37,563]\u001b[0m Trial 163 finished with value: 5.336059059159939 and parameters: {'n_hidden': 3, 'learning_rate': 0.00656952856337602, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3692729023671838, 'dropout_rate_Layer_2': 0.1580951905452096, 'dropout_rate_Layer_3': 0.05533464579966507, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003431460555266395, 'l1_Layer_2': 0.008779305094788612, 'l1_Layer_3': 0.0024546251711815713, 'n_units_Layer_1': 60, 'n_units_Layer_2': 95, 'n_units_Layer_3': 140}. Best is trial 128 with value: 5.020234724204411.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.34 | sMAPE for Validation Set is: 18.49% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 11.13 | sMAPE for Test Set is: 26.55% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:45:41,302]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:45:48,070]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:45:49,657]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:45:54,946]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:46:02,812]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:46:06,009]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:46:13,451]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:46:17,453]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:46:22,173]\u001b[0m Trial 182 finished with value: 4.97353985190291 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010704520106961575, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07585630678618316, 'dropout_rate_Layer_2': 0.07268128814028274, 'dropout_rate_Layer_3': 0.053697649700328934, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.1696683321354974e-05, 'l1_Layer_2': 0.0001081202055262724, 'l1_Layer_3': 2.7278734570398156e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 230, 'n_units_Layer_3': 180}. Best is trial 182 with value: 4.97353985190291.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.97 | sMAPE for Validation Set is: 17.52% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.76 | sMAPE for Test Set is: 16.83% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:46:25,382]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:46:25,605]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:46:32,628]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:46:34,579]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:46:40,132]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:46:40,279]\u001b[0m Trial 175 finished with value: 5.455776801557737 and parameters: {'n_hidden': 4, 'learning_rate': 0.004862370870482689, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1343596305559105, 'dropout_rate_Layer_2': 0.0013571604546050858, 'dropout_rate_Layer_3': 0.15802938939079428, 'dropout_rate_Layer_4': 0.2678373631431916, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.08823252765419089, 'l1_Layer_2': 0.00047421012373112975, 'l1_Layer_3': 0.0027672803478203884, 'l1_Layer_4': 0.0003453138483072965, 'n_units_Layer_1': 125, 'n_units_Layer_2': 110, 'n_units_Layer_3': 200, 'n_units_Layer_4': 225}. Best is trial 182 with value: 4.97353985190291.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.46 | sMAPE for Validation Set is: 19.03% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 8.05 | sMAPE for Test Set is: 20.04% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:46:46,308]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:46:46,691]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:46:56,633]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:46:56,677]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:47:01,566]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:47:01,824]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:47:07,647]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:47:10,205]\u001b[0m Trial 194 finished with value: 4.955370919061774 and parameters: {'n_hidden': 3, 'learning_rate': 0.001116732277690205, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009397641427205936, 'dropout_rate_Layer_2': 0.09171295278136032, 'dropout_rate_Layer_3': 0.0537931207374122, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.6323989781505992e-05, 'l1_Layer_2': 4.19127735249147e-05, 'l1_Layer_3': 4.2066971896640776e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 130, 'n_units_Layer_3': 190}. Best is trial 194 with value: 4.955370919061774.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.96 | sMAPE for Validation Set is: 17.20% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.61 | sMAPE for Test Set is: 16.44% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:47:12,714]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:47:15,315]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:47:21,067]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:47:27,586]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:47:31,885]\u001b[0m Trial 197 finished with value: 4.887844302132692 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008287316841969869, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19509969363493615, 'dropout_rate_Layer_2': 0.03238755258113574, 'dropout_rate_Layer_3': 0.053452251251065855, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.734004027998437e-05, 'l1_Layer_2': 4.456730486964936e-05, 'l1_Layer_3': 4.2452231322783214e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 230, 'n_units_Layer_3': 185}. Best is trial 197 with value: 4.887844302132692.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.89 | sMAPE for Validation Set is: 17.32% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.91 | sMAPE for Test Set is: 16.97% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:47:36,833]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:47:40,962]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:47:41,713]\u001b[0m Trial 198 finished with value: 5.386598258582352 and parameters: {'n_hidden': 4, 'learning_rate': 0.006637066527388567, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15831009932205412, 'dropout_rate_Layer_2': 0.07086477986831066, 'dropout_rate_Layer_3': 0.3905030050172467, 'dropout_rate_Layer_4': 0.10979459207178988, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.008295045587831213, 'l1_Layer_2': 0.0056305306799534684, 'l1_Layer_3': 0.010969486713833115, 'l1_Layer_4': 0.00017578334940434584, 'n_units_Layer_1': 205, 'n_units_Layer_2': 215, 'n_units_Layer_3': 100, 'n_units_Layer_4': 125}. Best is trial 197 with value: 4.887844302132692.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.39 | sMAPE for Validation Set is: 18.71% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 12.92 | sMAPE for Test Set is: 31.15% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:47:47,477]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:47:48,220]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:47:53,498]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:47:53,705]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:47:54,256]\u001b[0m Trial 204 finished with value: 4.863438105580694 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008880205621462166, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008518525995377061, 'dropout_rate_Layer_2': 0.07496749892367463, 'dropout_rate_Layer_3': 0.04517570069461702, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.769509595004169e-05, 'l1_Layer_2': 2.782318512085031e-05, 'l1_Layer_3': 3.972679455612178e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 250, 'n_units_Layer_3': 190}. Best is trial 204 with value: 4.863438105580694.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.86 | sMAPE for Validation Set is: 16.91% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.60 | sMAPE for Test Set is: 16.20% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:48:01,026]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:48:01,229]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:48:06,138]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:48:08,297]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:48:18,164]\u001b[0m Trial 205 finished with value: 4.866539147725292 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006049910126248307, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17758349829241474, 'dropout_rate_Layer_2': 0.048438500242664564, 'dropout_rate_Layer_3': 0.08325596430890948, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.3353497235312755e-05, 'l1_Layer_2': 4.4746436706626734e-05, 'l1_Layer_3': 4.128961238172792e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 135, 'n_units_Layer_3': 175}. Best is trial 204 with value: 4.863438105580694.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.87 | sMAPE for Validation Set is: 17.07% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.55 | sMAPE for Test Set is: 16.38% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:48:23,068]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:48:36,422]\u001b[0m Trial 217 finished with value: 5.224702523385126 and parameters: {'n_hidden': 3, 'learning_rate': 0.0054701582840278795, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34146862252795646, 'dropout_rate_Layer_2': 0.14411163054945106, 'dropout_rate_Layer_3': 0.07515641284819986, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004097133886121296, 'l1_Layer_2': 0.004314664673716324, 'l1_Layer_3': 0.0001765429280714512, 'n_units_Layer_1': 65, 'n_units_Layer_2': 95, 'n_units_Layer_3': 200}. Best is trial 204 with value: 4.863438105580694.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.22 | sMAPE for Validation Set is: 18.04% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 12.04 | sMAPE for Test Set is: 28.85% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:48:46,369]\u001b[0m Trial 218 finished with value: 5.206898732975653 and parameters: {'n_hidden': 3, 'learning_rate': 0.005833928582584277, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2868097769467799, 'dropout_rate_Layer_2': 0.14237646689206568, 'dropout_rate_Layer_3': 0.05504444914277425, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00042625077696797144, 'l1_Layer_2': 0.0009834198754416074, 'l1_Layer_3': 0.00026329243321583233, 'n_units_Layer_1': 60, 'n_units_Layer_2': 110, 'n_units_Layer_3': 145}. Best is trial 204 with value: 4.863438105580694.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.21 | sMAPE for Validation Set is: 18.08% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 11.47 | sMAPE for Test Set is: 27.50% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:48:49,382]\u001b[0m Trial 219 finished with value: 5.1258127436047385 and parameters: {'n_hidden': 3, 'learning_rate': 0.005777085068441138, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26821961824172114, 'dropout_rate_Layer_2': 0.1409963998133117, 'dropout_rate_Layer_3': 0.05688069571757049, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003521804047099601, 'l1_Layer_2': 0.0038441904789026115, 'l1_Layer_3': 0.0003048466373678601, 'n_units_Layer_1': 65, 'n_units_Layer_2': 105, 'n_units_Layer_3': 150}. Best is trial 204 with value: 4.863438105580694.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.13 | sMAPE for Validation Set is: 17.79% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.94 | sMAPE for Test Set is: 28.66% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:48:56,700]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:49:00,157]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:49:03,802]\u001b[0m Trial 220 finished with value: 4.927732951856137 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008936406259853155, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1682026391701979, 'dropout_rate_Layer_2': 0.0358319552496355, 'dropout_rate_Layer_3': 0.08984951533873356, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.56402215383127e-05, 'l1_Layer_2': 2.572110163689366e-05, 'l1_Layer_3': 3.7911856510711284e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 135, 'n_units_Layer_3': 165}. Best is trial 204 with value: 4.863438105580694.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.93 | sMAPE for Validation Set is: 17.24% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.66 | sMAPE for Test Set is: 16.37% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:49:12,761]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:49:16,519]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:49:21,275]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:49:23,417]\u001b[0m Trial 221 finished with value: 4.850417187808696 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008962884154493661, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14411290317841788, 'dropout_rate_Layer_2': 0.030063195025070752, 'dropout_rate_Layer_3': 0.0868263325038564, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010016869895718502, 'l1_Layer_2': 2.7968138066565044e-05, 'l1_Layer_3': 3.746520522294508e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 135, 'n_units_Layer_3': 165}. Best is trial 221 with value: 4.850417187808696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.85 | sMAPE for Validation Set is: 17.15% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.40 | sMAPE for Test Set is: 16.00% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:49:26,876]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:49:30,539]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:49:31,275]\u001b[0m Trial 225 finished with value: 4.9407878794672335 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006640763795024617, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28086089147641335, 'dropout_rate_Layer_2': 0.01603393889691291, 'dropout_rate_Layer_3': 0.06295741515785962, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.4683530359172735e-05, 'l1_Layer_2': 6.448419671909058e-05, 'l1_Layer_3': 7.031487676743119e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 135, 'n_units_Layer_3': 180}. Best is trial 221 with value: 4.850417187808696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.94 | sMAPE for Validation Set is: 17.27% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.67 | sMAPE for Test Set is: 16.66% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:49:33,887]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:49:39,052]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:49:47,236]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:49:51,930]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:49:56,142]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:50:02,840]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:50:09,900]\u001b[0m Trial 233 finished with value: 4.9429046028174355 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008148362290069886, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14754767943352484, 'dropout_rate_Layer_2': 0.012703332645258456, 'dropout_rate_Layer_3': 0.06623986668643984, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.862719295635784e-05, 'l1_Layer_2': 2.6491102672051373e-05, 'l1_Layer_3': 7.815316631979367e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 115, 'n_units_Layer_3': 170}. Best is trial 221 with value: 4.850417187808696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.94 | sMAPE for Validation Set is: 17.34% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.70 | sMAPE for Test Set is: 16.58% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:50:14,403]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:50:22,358]\u001b[0m Trial 238 finished with value: 4.950856457768317 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007909408964053945, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28346942493084154, 'dropout_rate_Layer_2': 0.03803577938452482, 'dropout_rate_Layer_3': 0.0622536088988941, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011751185778238929, 'l1_Layer_2': 1.9651089243869875e-05, 'l1_Layer_3': 8.276428243702774e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 145, 'n_units_Layer_3': 175}. Best is trial 221 with value: 4.850417187808696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.95 | sMAPE for Validation Set is: 17.27% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.77 | sMAPE for Test Set is: 17.01% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:50:27,155]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:50:52,481]\u001b[0m Trial 241 finished with value: 4.807586198566027 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007819992205594655, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1365128251459291, 'dropout_rate_Layer_2': 0.016646946483223783, 'dropout_rate_Layer_3': 0.0857551205222352, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.390416814698635e-05, 'l1_Layer_2': 2.77218918094116e-05, 'l1_Layer_3': 6.779220362858665e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 135, 'n_units_Layer_3': 155}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.81 | sMAPE for Validation Set is: 17.02% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.69 | sMAPE for Test Set is: 16.50% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:51:16,418]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:51:20,919]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:51:26,316]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:51:30,982]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:52:02,814]\u001b[0m Trial 248 finished with value: 4.941497963095497 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009747519179804572, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13636899905967353, 'dropout_rate_Layer_2': 0.022160259888072475, 'dropout_rate_Layer_3': 0.07649807017504917, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.459356323794571e-05, 'l1_Layer_2': 1.3370200995573337e-05, 'l1_Layer_3': 4.078920829890418e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 125, 'n_units_Layer_3': 185}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.94 | sMAPE for Validation Set is: 17.38% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.63 | sMAPE for Test Set is: 16.57% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:52:11,284]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:53:01,279]\u001b[0m Trial 250 finished with value: 4.848502508698992 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007012152664005862, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1311628846042558, 'dropout_rate_Layer_2': 0.019706413853271734, 'dropout_rate_Layer_3': 0.07586521219295624, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001834724767152354, 'l1_Layer_2': 1.2906104365528482e-05, 'l1_Layer_3': 4.257159517905463e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 115, 'n_units_Layer_3': 185}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.85 | sMAPE for Validation Set is: 16.93% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.46 | sMAPE for Test Set is: 16.07% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:53:06,901]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:53:11,663]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:53:51,101]\u001b[0m Trial 253 finished with value: 5.404562307832628 and parameters: {'n_hidden': 4, 'learning_rate': 0.006828103809125374, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03610492637275832, 'dropout_rate_Layer_2': 0.19534569609499003, 'dropout_rate_Layer_3': 0.35400599243920716, 'dropout_rate_Layer_4': 0.3115395522393072, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.02117197400814508, 'l1_Layer_2': 0.006299003930634084, 'l1_Layer_3': 0.0029901908885089615, 'l1_Layer_4': 0.00024251464896905736, 'n_units_Layer_1': 235, 'n_units_Layer_2': 200, 'n_units_Layer_3': 80, 'n_units_Layer_4': 250}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.40 | sMAPE for Validation Set is: 18.76% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 11.10 | sMAPE for Test Set is: 26.69% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:54:14,258]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:54:21,951]\u001b[0m Trial 236 finished with value: 5.133259741869275 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006531992170159645, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02716965221620149, 'dropout_rate_Layer_2': 0.09374546164274139, 'dropout_rate_Layer_3': 0.12241600068258537, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.022800628188714013, 'l1_Layer_2': 0.0015319358665537453, 'l1_Layer_3': 0.01920721770116542, 'n_units_Layer_1': 200, 'n_units_Layer_2': 185, 'n_units_Layer_3': 230}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.13 | sMAPE for Validation Set is: 18.00% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 9.36 | sMAPE for Test Set is: 22.78% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:54:25,534]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:54:26,495]\u001b[0m Trial 254 finished with value: 5.220743633226754 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025685974858965237, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18667973652146228, 'dropout_rate_Layer_2': 0.05019517998309525, 'dropout_rate_Layer_3': 0.04089620598146387, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014524438284270474, 'l1_Layer_2': 0.0012628715525136074, 'l1_Layer_3': 0.0009695440517535057, 'n_units_Layer_1': 75, 'n_units_Layer_2': 105, 'n_units_Layer_3': 155}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.22 | sMAPE for Validation Set is: 18.31% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.81 | sMAPE for Test Set is: 25.99% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:54:33,541]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:54:36,839]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:54:37,395]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:54:50,146]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:54:50,554]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:54:54,622]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:55:00,162]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:55:00,327]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:55:06,646]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:55:06,795]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:55:12,482]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:55:17,411]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:55:23,372]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:55:27,678]\u001b[0m Trial 261 finished with value: 5.207794465241707 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024463343303428317, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1842210587381533, 'dropout_rate_Layer_2': 0.054918814218571615, 'dropout_rate_Layer_3': 0.03962125721413318, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001191061379213033, 'l1_Layer_2': 0.0008409038852278106, 'l1_Layer_3': 0.0010035254906832069, 'n_units_Layer_1': 50, 'n_units_Layer_2': 145, 'n_units_Layer_3': 160}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.21 | sMAPE for Validation Set is: 18.13% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 11.20 | sMAPE for Test Set is: 26.78% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:55:32,979]\u001b[0m Trial 264 finished with value: 4.923050215702012 and parameters: {'n_hidden': 3, 'learning_rate': 0.000989746225242783, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14979209509978572, 'dropout_rate_Layer_2': 0.05177584011090139, 'dropout_rate_Layer_3': 0.1128224989540368, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012176082183252277, 'l1_Layer_2': 1.889255011426273e-05, 'l1_Layer_3': 5.6169106001454444e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 145, 'n_units_Layer_3': 155}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.92 | sMAPE for Validation Set is: 16.96% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.93 | sMAPE for Test Set is: 16.65% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:55:37,689]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:55:42,142]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:55:44,531]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:55:47,380]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:55:52,749]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:55:57,639]\u001b[0m Trial 271 finished with value: 4.850072963612963 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008176143443163235, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11542374420486162, 'dropout_rate_Layer_2': 0.028857723938705716, 'dropout_rate_Layer_3': 0.06496254434939454, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.932800808843216e-05, 'l1_Layer_2': 5.1148723886653784e-05, 'l1_Layer_3': 3.7879314471284903e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 105, 'n_units_Layer_3': 195}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.85 | sMAPE for Validation Set is: 17.15% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.60 | sMAPE for Test Set is: 16.58% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:55:59,592]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:56:16,367]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:56:27,652]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:56:36,415]\u001b[0m Trial 279 finished with value: 5.379998237947956 and parameters: {'n_hidden': 4, 'learning_rate': 0.005146164883031106, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11452646909885714, 'dropout_rate_Layer_2': 0.23692763494584193, 'dropout_rate_Layer_3': 0.3656309374492693, 'dropout_rate_Layer_4': 0.23790845713155578, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0005025529383526812, 'l1_Layer_2': 0.017382120599551482, 'l1_Layer_3': 0.004536172589430031, 'l1_Layer_4': 2.1171518706685573e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 105, 'n_units_Layer_3': 125, 'n_units_Layer_4': 280}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.38 | sMAPE for Validation Set is: 18.83% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.54 | sMAPE for Test Set is: 25.64% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:56:43,456]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:56:43,528]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.26 | sMAPE for Validation Set is: 18.23% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 11.80 | sMAPE for Test Set is: 28.38% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:56:43,534]\u001b[0m Trial 281 finished with value: 5.263585375372036 and parameters: {'n_hidden': 3, 'learning_rate': 0.002939399084754664, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18093577261105284, 'dropout_rate_Layer_2': 0.04570055395614973, 'dropout_rate_Layer_3': 0.046255140685055623, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 8.719548769821476e-05, 'l1_Layer_2': 0.0002632111942891411, 'l1_Layer_3': 0.001023401475237821, 'n_units_Layer_1': 50, 'n_units_Layer_2': 145, 'n_units_Layer_3': 160}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:56:50,884]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:56:54,440]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:56:55,025]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.19 | sMAPE for Validation Set is: 18.06% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 11.52 | sMAPE for Test Set is: 27.81% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:56:57,949]\u001b[0m Trial 272 finished with value: 5.192941780312324 and parameters: {'n_hidden': 4, 'learning_rate': 0.005718268668232126, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10399463561445503, 'dropout_rate_Layer_2': 0.18926558549630149, 'dropout_rate_Layer_3': 0.3728540338924265, 'dropout_rate_Layer_4': 0.2313791247167707, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0005366458501519606, 'l1_Layer_2': 0.014380445095928538, 'l1_Layer_3': 0.010461044354330212, 'l1_Layer_4': 0.0013868446682104593, 'n_units_Layer_1': 255, 'n_units_Layer_2': 105, 'n_units_Layer_3': 95, 'n_units_Layer_4': 280}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:56:58,896]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:57:04,146]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:57:08,363]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:57:10,364]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:57:15,093]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:57:18,424]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:57:18,688]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:57:24,704]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:57:24,806]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:57:30,142]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:57:38,270]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:57:44,833]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:57:48,278]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:57:54,009]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:58:05,391]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:58:09,359]\u001b[0m Trial 286 finished with value: 5.423515967721158 and parameters: {'n_hidden': 4, 'learning_rate': 0.004577242269712622, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07856064720329617, 'dropout_rate_Layer_2': 0.2945977465446102, 'dropout_rate_Layer_3': 0.04905403145411441, 'dropout_rate_Layer_4': 0.2868449133545721, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 6.0089574994603946e-05, 'l1_Layer_2': 0.009374219580305777, 'l1_Layer_3': 0.018190891320049404, 'l1_Layer_4': 8.410799280684143e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 80, 'n_units_Layer_3': 145, 'n_units_Layer_4': 285}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.42 | sMAPE for Validation Set is: 18.78% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 11.13 | sMAPE for Test Set is: 26.49% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:58:15,143]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:58:27,238]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:58:29,428]\u001b[0m Trial 289 finished with value: 5.260239685454182 and parameters: {'n_hidden': 4, 'learning_rate': 0.0030505487718504878, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1704317088654952, 'dropout_rate_Layer_2': 0.29072144782555587, 'dropout_rate_Layer_3': 0.0035225499275577735, 'dropout_rate_Layer_4': 0.2934463517035053, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 4.499037508277661e-05, 'l1_Layer_2': 0.009194579754586046, 'l1_Layer_3': 2.2549530818590594e-05, 'l1_Layer_4': 9.1550807755988e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 85, 'n_units_Layer_3': 140, 'n_units_Layer_4': 195}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.26 | sMAPE for Validation Set is: 18.55% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 11.61 | sMAPE for Test Set is: 27.87% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:58:34,051]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:58:51,809]\u001b[0m Trial 303 finished with value: 5.294196862484047 and parameters: {'n_hidden': 4, 'learning_rate': 0.002102596799675604, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.167831175585011, 'dropout_rate_Layer_2': 0.0003522708539169389, 'dropout_rate_Layer_3': 0.0035104620693298325, 'dropout_rate_Layer_4': 0.14306987928021855, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000171756354807879, 'l1_Layer_2': 0.0012619315579990083, 'l1_Layer_3': 0.00394878158509586, 'l1_Layer_4': 1.2466774125997163e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 200, 'n_units_Layer_3': 120, 'n_units_Layer_4': 50}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.29 | sMAPE for Validation Set is: 18.32% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.83 | sMAPE for Test Set is: 25.89% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:58:58,760]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:59:03,598]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:59:41,917]\u001b[0m Trial 308 finished with value: 5.364510937900295 and parameters: {'n_hidden': 4, 'learning_rate': 0.004659566688725509, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06651140577774639, 'dropout_rate_Layer_2': 0.3787027925961574, 'dropout_rate_Layer_3': 0.05636553222778735, 'dropout_rate_Layer_4': 0.29944409089801105, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00015300750562468197, 'l1_Layer_2': 0.01074167173172488, 'l1_Layer_3': 0.04374517490158878, 'l1_Layer_4': 8.860980517351699e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 50, 'n_units_Layer_3': 110, 'n_units_Layer_4': 285}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.36 | sMAPE for Validation Set is: 18.44% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 11.35 | sMAPE for Test Set is: 27.16% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 17:59:45,945]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:59:52,803]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 17:59:57,757]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:00:02,315]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:00:16,325]\u001b[0m Trial 310 finished with value: 5.241173652135239 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017691543292198634, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17820281116281111, 'dropout_rate_Layer_2': 0.3823831058983116, 'dropout_rate_Layer_3': 0.051993265419955796, 'dropout_rate_Layer_4': 0.29055232494720545, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 2.1078478038223166e-05, 'l1_Layer_2': 0.009982211597004874, 'l1_Layer_3': 2.870697721931562e-05, 'l1_Layer_4': 9.542270587030568e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 50, 'n_units_Layer_3': 130, 'n_units_Layer_4': 280}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.24 | sMAPE for Validation Set is: 18.24% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 11.29 | sMAPE for Test Set is: 26.76% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:00:19,353]\u001b[0m Trial 313 finished with value: 5.193218521309299 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019355246946090754, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16528021708204177, 'dropout_rate_Layer_2': 0.3257988967469685, 'dropout_rate_Layer_3': 0.051355146267351756, 'dropout_rate_Layer_4': 0.29277078521259914, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 6.31737759440134e-05, 'l1_Layer_2': 0.00961109284378504, 'l1_Layer_3': 2.0343456046853352e-05, 'l1_Layer_4': 0.00010231175750777735, 'n_units_Layer_1': 190, 'n_units_Layer_2': 60, 'n_units_Layer_3': 130, 'n_units_Layer_4': 280}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.19 | sMAPE for Validation Set is: 18.13% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 11.07 | sMAPE for Test Set is: 26.48% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:00:28,355]\u001b[0m Trial 318 finished with value: 5.150430955704809 and parameters: {'n_hidden': 3, 'learning_rate': 0.0042882042273250055, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24829637699469287, 'dropout_rate_Layer_2': 0.06480104378285068, 'dropout_rate_Layer_3': 0.16992018125764927, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.621835311057731e-05, 'l1_Layer_2': 0.0006895223634273703, 'l1_Layer_3': 0.0007485613406483624, 'n_units_Layer_1': 95, 'n_units_Layer_2': 165, 'n_units_Layer_3': 185}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.15 | sMAPE for Validation Set is: 17.91% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.27 | sMAPE for Test Set is: 27.12% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:00:36,380]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:00:42,688]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:00:45,701]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:01:07,414]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:01:10,824]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:01:18,814]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:01:35,225]\u001b[0m Trial 316 finished with value: 5.392555709644404 and parameters: {'n_hidden': 4, 'learning_rate': 0.002355148528987649, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16841725997100987, 'dropout_rate_Layer_2': 0.36957870722525293, 'dropout_rate_Layer_3': 0.013446432988612471, 'dropout_rate_Layer_4': 0.29214354532541026, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00014871719167398783, 'l1_Layer_2': 0.004084903843698654, 'l1_Layer_3': 0.09866902556418702, 'l1_Layer_4': 0.00041509023491631726, 'n_units_Layer_1': 260, 'n_units_Layer_2': 60, 'n_units_Layer_3': 110, 'n_units_Layer_4': 250}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.39 | sMAPE for Validation Set is: 18.63% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.91 | sMAPE for Test Set is: 26.33% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:01:39,131]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:01:45,664]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:01:49,389]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:01:52,147]\u001b[0m Trial 327 finished with value: 5.120686190115007 and parameters: {'n_hidden': 3, 'learning_rate': 0.004698807514758562, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2289667073387448, 'dropout_rate_Layer_2': 0.06340374366646179, 'dropout_rate_Layer_3': 0.0850601848634828, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014193725249765898, 'l1_Layer_2': 0.0007581141160746042, 'l1_Layer_3': 0.0007436766018969985, 'n_units_Layer_1': 85, 'n_units_Layer_2': 110, 'n_units_Layer_3': 185}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.12 | sMAPE for Validation Set is: 17.79% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 12.01 | sMAPE for Test Set is: 28.69% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:01:56,628]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:01:58,919]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:02:05,823]\u001b[0m Trial 320 finished with value: 5.193844348021283 and parameters: {'n_hidden': 4, 'learning_rate': 0.001453664427751735, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1691706131186936, 'dropout_rate_Layer_2': 0.39524503889082374, 'dropout_rate_Layer_3': 0.011955395733857958, 'dropout_rate_Layer_4': 0.2949550241345323, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 2.5031489995998652e-05, 'l1_Layer_2': 0.011959911251707391, 'l1_Layer_3': 2.6626900215797185e-05, 'l1_Layer_4': 3.687003465571446e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 50, 'n_units_Layer_3': 130, 'n_units_Layer_4': 295}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.19 | sMAPE for Validation Set is: 18.14% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 11.02 | sMAPE for Test Set is: 26.50% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:02:18,295]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:02:24,019]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:02:37,547]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:02:41,148]\u001b[0m Trial 324 finished with value: 5.225991887879772 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016723324769451445, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1838064328076949, 'dropout_rate_Layer_2': 0.3765621821112054, 'dropout_rate_Layer_3': 0.004153351641623941, 'dropout_rate_Layer_4': 0.29520026888872475, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 2.2305614519802084e-05, 'l1_Layer_2': 0.011271555715087308, 'l1_Layer_3': 2.0463665678093804e-05, 'l1_Layer_4': 2.829289632624869e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 50, 'n_units_Layer_3': 130, 'n_units_Layer_4': 300}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.23 | sMAPE for Validation Set is: 18.22% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.92 | sMAPE for Test Set is: 26.14% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:02:44,761]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:02:54,633]\u001b[0m Trial 334 finished with value: 4.893768373057038 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006456798424880966, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13650259119028046, 'dropout_rate_Layer_2': 0.024174765176041148, 'dropout_rate_Layer_3': 0.041501476408073376, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.530085563052006e-05, 'l1_Layer_2': 0.00011587169348999322, 'l1_Layer_3': 7.3719235638384e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 130, 'n_units_Layer_3': 150}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.89 | sMAPE for Validation Set is: 17.40% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.85 | sMAPE for Test Set is: 16.71% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:02:56,588]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:03:06,255]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:03:06,694]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:03:17,769]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:03:29,063]\u001b[0m Trial 343 finished with value: 5.175241037387422 and parameters: {'n_hidden': 3, 'learning_rate': 0.004524362271687633, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23006193789351911, 'dropout_rate_Layer_2': 0.0655096974833167, 'dropout_rate_Layer_3': 0.09704773003455347, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.0213740174809514e-05, 'l1_Layer_2': 0.0007421202844911877, 'l1_Layer_3': 0.0003430848140056528, 'n_units_Layer_1': 180, 'n_units_Layer_2': 135, 'n_units_Layer_3': 180}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.18 | sMAPE for Validation Set is: 17.86% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 12.63 | sMAPE for Test Set is: 30.27% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:03:51,674]\u001b[0m Trial 338 finished with value: 5.130094981690804 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017276554962139526, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1953316432430374, 'dropout_rate_Layer_2': 0.318031653797044, 'dropout_rate_Layer_3': 0.01850372077421345, 'dropout_rate_Layer_4': 0.37210352512361744, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 4.049669290469043e-05, 'l1_Layer_2': 0.012045624111419607, 'l1_Layer_3': 6.353979958552697e-05, 'l1_Layer_4': 5.2172806706232625e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 70, 'n_units_Layer_3': 115, 'n_units_Layer_4': 300}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.13 | sMAPE for Validation Set is: 17.87% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 12.04 | sMAPE for Test Set is: 28.85% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:03:56,979]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:03:57,736]\u001b[0m Trial 346 finished with value: 5.110764921830354 and parameters: {'n_hidden': 3, 'learning_rate': 0.00445874059599569, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23261784130338162, 'dropout_rate_Layer_2': 0.09413213628767927, 'dropout_rate_Layer_3': 0.09006279931548863, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.251962557959802e-05, 'l1_Layer_2': 0.00042232590197227815, 'l1_Layer_3': 0.0006389201660065468, 'n_units_Layer_1': 190, 'n_units_Layer_2': 130, 'n_units_Layer_3': 190}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.11 | sMAPE for Validation Set is: 17.85% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.86 | sMAPE for Test Set is: 28.57% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:04:02,266]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:04:06,134]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:04:06,990]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:04:09,517]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:04:13,268]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:04:17,802]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:04:19,850]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:04:24,011]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:04:34,531]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:04:46,664]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:04:57,310]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:05:05,617]\u001b[0m Trial 348 finished with value: 4.83222324737124 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005688270342942715, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13403416097756515, 'dropout_rate_Layer_2': 0.02958207858366214, 'dropout_rate_Layer_3': 0.05306712289998451, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.212236403456764e-05, 'l1_Layer_2': 9.016956040674869e-05, 'l1_Layer_3': 7.798988943982468e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 135, 'n_units_Layer_3': 160}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.83 | sMAPE for Validation Set is: 17.37% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.61 | sMAPE for Test Set is: 16.32% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:05:09,118]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:05:14,543]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:05:18,851]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:05:24,204]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:05:28,724]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:05:29,415]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:05:35,224]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:05:39,781]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:05:41,887]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:05:45,132]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:05:46,906]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:05:52,616]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:05:55,948]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:05:59,260]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:06:10,095]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:06:14,547]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:06:19,216]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:06:22,965]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:06:25,721]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:06:29,349]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:06:32,378]\u001b[0m Trial 353 finished with value: 5.197815919945804 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011268931875937451, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13241416912066595, 'dropout_rate_Layer_2': 0.371798980295422, 'dropout_rate_Layer_3': 0.0016558326082065696, 'dropout_rate_Layer_4': 0.2726807648020264, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.6357697655584422e-05, 'l1_Layer_2': 0.013757579987978726, 'l1_Layer_3': 2.0423172925844265e-05, 'l1_Layer_4': 5.618975757705888e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 60, 'n_units_Layer_3': 130, 'n_units_Layer_4': 290}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:06:32,415]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.20 | sMAPE for Validation Set is: 18.10% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.27 | sMAPE for Test Set is: 24.58% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:06:32,739]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:06:33,882]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:06:39,600]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:06:42,713]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:06:43,297]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:06:43,491]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:06:47,354]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:06:47,581]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:06:53,619]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:06:54,593]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:06:58,120]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:06:59,089]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:07:00,948]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:07:13,733]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:07:18,880]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:07:23,696]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:07:46,118]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:07:50,876]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:07:56,996]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:08:01,946]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:08:07,499]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:08:19,957]\u001b[0m Trial 397 finished with value: 5.328392139972922 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019420828973177185, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16014156841013927, 'dropout_rate_Layer_2': 0.13603489106263233, 'dropout_rate_Layer_3': 0.19286151250292402, 'dropout_rate_Layer_4': 0.3232535845637823, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.002665353886652492, 'l1_Layer_2': 0.026728547129028547, 'l1_Layer_3': 0.0014475173455358863, 'l1_Layer_4': 0.0007727710277021543, 'n_units_Layer_1': 210, 'n_units_Layer_2': 75, 'n_units_Layer_3': 210, 'n_units_Layer_4': 195}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.33 | sMAPE for Validation Set is: 18.44% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.87 | sMAPE for Test Set is: 25.85% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:08:25,233]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:08:29,560]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:08:42,357]\u001b[0m Trial 404 finished with value: 5.021274745912748 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030224361466042104, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24156073507721756, 'dropout_rate_Layer_2': 0.1091474824419594, 'dropout_rate_Layer_3': 0.12461233086978948, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00024604024069499464, 'l1_Layer_2': 0.00032593932442313774, 'l1_Layer_3': 0.0007284352189759903, 'n_units_Layer_1': 190, 'n_units_Layer_2': 160, 'n_units_Layer_3': 165}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.02 | sMAPE for Validation Set is: 17.50% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 13.28 | sMAPE for Test Set is: 31.88% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:08:46,064]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:08:49,036]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:08:52,656]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:08:56,566]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:09:00,576]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:10:07,641]\u001b[0m Trial 396 finished with value: 5.283430223100901 and parameters: {'n_hidden': 4, 'learning_rate': 0.002181473203717257, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16293139545672738, 'dropout_rate_Layer_2': 0.1439132779227134, 'dropout_rate_Layer_3': 0.06954334628883585, 'dropout_rate_Layer_4': 0.325860602650903, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.002148023846871158, 'l1_Layer_2': 0.0186318305102464, 'l1_Layer_3': 0.04644555670734909, 'l1_Layer_4': 0.012636684306850162, 'n_units_Layer_1': 150, 'n_units_Layer_2': 170, 'n_units_Layer_3': 210, 'n_units_Layer_4': 195}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.28 | sMAPE for Validation Set is: 18.25% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 12.01 | sMAPE for Test Set is: 28.74% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:10:11,910]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:10:40,118]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:10:45,643]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:10:58,438]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.27 | sMAPE for Validation Set is: 18.50% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.49 | sMAPE for Test Set is: 22.90% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:11:00,283]\u001b[0m Trial 409 finished with value: 5.26697159361129 and parameters: {'n_hidden': 4, 'learning_rate': 0.002109407253172717, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16329212880639357, 'dropout_rate_Layer_2': 0.1469056115325238, 'dropout_rate_Layer_3': 0.18824997972416838, 'dropout_rate_Layer_4': 0.32529760692463333, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00038815692850080805, 'l1_Layer_2': 0.030061829160299557, 'l1_Layer_3': 0.00033677101612946027, 'l1_Layer_4': 0.0006071353454225296, 'n_units_Layer_1': 205, 'n_units_Layer_2': 80, 'n_units_Layer_3': 215, 'n_units_Layer_4': 200}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:11:02,385]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:11:05,013]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:11:10,504]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:11:15,887]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:11:21,259]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:11:24,156]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:11:24,365]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:11:28,983]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:11:45,724]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:11:47,970]\u001b[0m Trial 413 finished with value: 5.227654391271886 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008133526019578276, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1767744677492493, 'dropout_rate_Layer_2': 0.14531435482546087, 'dropout_rate_Layer_3': 0.19814464142462435, 'dropout_rate_Layer_4': 0.33377792027476016, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0019702730603796607, 'l1_Layer_2': 0.027015586414917036, 'l1_Layer_3': 0.0004944867226792716, 'l1_Layer_4': 0.0007760659140491528, 'n_units_Layer_1': 205, 'n_units_Layer_2': 70, 'n_units_Layer_3': 215, 'n_units_Layer_4': 190}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.23 | sMAPE for Validation Set is: 18.19% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 9.77 | sMAPE for Test Set is: 23.30% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:11:49,191]\u001b[0m Trial 394 finished with value: 5.254803079768488 and parameters: {'n_hidden': 4, 'learning_rate': 0.002020754270634797, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16084154492087116, 'dropout_rate_Layer_2': 0.1348356838001046, 'dropout_rate_Layer_3': 0.05495414059225155, 'dropout_rate_Layer_4': 0.31884557256564156, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0027815111673362082, 'l1_Layer_2': 0.031685726653308065, 'l1_Layer_3': 0.0003075943134736105, 'l1_Layer_4': 0.010852100049451387, 'n_units_Layer_1': 205, 'n_units_Layer_2': 165, 'n_units_Layer_3': 215, 'n_units_Layer_4': 195}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.25 | sMAPE for Validation Set is: 18.40% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.28 | sMAPE for Test Set is: 24.81% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:11:50,385]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:11:54,198]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:11:57,753]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:11:57,971]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:11:59,535]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:12:09,798]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:12:11,726]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:12:17,143]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:12:21,466]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:12:24,597]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:12:24,858]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:12:31,075]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:12:32,706]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:12:41,385]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:12:44,362]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:12:45,780]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:12:50,841]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:12:53,828]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:13:00,230]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:13:03,785]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:13:20,362]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:13:24,615]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:13:27,585]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:13:30,037]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:13:32,979]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:13:41,425]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:13:45,782]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:13:46,316]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:13:50,743]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:13:55,038]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:13:59,960]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:14:00,679]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:14:04,767]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:14:23,871]\u001b[0m Trial 450 finished with value: 10.264281394455573 and parameters: {'n_hidden': 4, 'learning_rate': 0.07972484425423018, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06819317099392426, 'dropout_rate_Layer_2': 0.23757459865995645, 'dropout_rate_Layer_3': 0.002612522294570978, 'dropout_rate_Layer_4': 0.2850336116147075, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 7.483186865763873e-05, 'l1_Layer_2': 0.006450335097445679, 'l1_Layer_3': 6.598578935173377e-05, 'l1_Layer_4': 0.00013479884291207216, 'n_units_Layer_1': 225, 'n_units_Layer_2': 115, 'n_units_Layer_3': 255, 'n_units_Layer_4': 270}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.26 | sMAPE for Validation Set is: 40.03% | rMAE for Validation Set is: 1.28\n",
      "MAE for Test Set is: 12.12 | sMAPE for Test Set is: 31.41% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:14:27,358]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:14:42,060]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:14:44,748]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:14:45,317]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:14:49,712]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:14:54,214]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:14:59,785]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:15:00,308]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:15:04,742]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:15:07,744]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:15:14,666]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:15:17,997]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:15:22,930]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:15:25,350]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:15:32,153]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:15:36,079]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:15:39,903]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:15:45,723]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:16:01,317]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:16:07,325]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:16:08,957]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:16:19,124]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:16:24,076]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:16:28,881]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:16:34,135]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:16:39,601]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:16:41,489]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:16:45,399]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:16:50,137]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:16:50,217]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:17:06,445]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:17:10,352]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:17:13,646]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:17:24,045]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:18:05,684]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:18:14,800]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:18:17,259]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:18:20,783]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:18:21,031]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:18:26,988]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:18:27,181]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:18:35,065]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:18:35,498]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:18:42,531]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:18:44,716]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:18:47,278]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:18:51,449]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:18:55,922]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:19:01,852]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:19:06,462]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:19:08,700]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:19:29,465]\u001b[0m Trial 482 finished with value: 5.113482867534545 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007067649476947586, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.036682530218004314, 'dropout_rate_Layer_2': 0.1810123932567899, 'dropout_rate_Layer_3': 0.10635569114814789, 'dropout_rate_Layer_4': 0.30742768752527405, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0015662866477941968, 'l1_Layer_2': 0.009819267124026311, 'l1_Layer_3': 0.0006966615851156986, 'l1_Layer_4': 0.0002483393110811941, 'n_units_Layer_1': 200, 'n_units_Layer_2': 145, 'n_units_Layer_3': 285, 'n_units_Layer_4': 210}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.11 | sMAPE for Validation Set is: 17.92% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.51 | sMAPE for Test Set is: 25.08% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:19:32,173]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:19:34,633]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:19:41,302]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:19:44,717]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:19:50,394]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:19:54,065]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:19:59,190]\u001b[0m Trial 515 finished with value: 5.143135663159955 and parameters: {'n_hidden': 3, 'learning_rate': 0.00942116474469832, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20152065018053955, 'dropout_rate_Layer_2': 0.1089151270421138, 'dropout_rate_Layer_3': 0.2254057550022684, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.9795078609315236e-05, 'l1_Layer_2': 0.0015747048033394407, 'l1_Layer_3': 0.0022016727391771314, 'n_units_Layer_1': 160, 'n_units_Layer_2': 80, 'n_units_Layer_3': 105}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.14 | sMAPE for Validation Set is: 17.87% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.88 | sMAPE for Test Set is: 28.60% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:19:59,703]\u001b[0m Trial 517 finished with value: 5.09956564859971 and parameters: {'n_hidden': 3, 'learning_rate': 0.009418980675179307, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20135891741257506, 'dropout_rate_Layer_2': 0.10891017473375744, 'dropout_rate_Layer_3': 0.06916647697115272, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.205121944514258e-05, 'l1_Layer_2': 0.0017984650800221538, 'l1_Layer_3': 0.00016009849575070198, 'n_units_Layer_1': 300, 'n_units_Layer_2': 75, 'n_units_Layer_3': 180}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.10 | sMAPE for Validation Set is: 17.78% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 12.06 | sMAPE for Test Set is: 29.26% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:20:06,134]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:20:09,559]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:20:15,825]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:20:18,555]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:20:24,015]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:20:24,453]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:20:30,194]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:20:35,752]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:20:37,435]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:20:38,592]\u001b[0m Trial 514 finished with value: 5.441670673477361 and parameters: {'n_hidden': 4, 'learning_rate': 0.0050994039683333265, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19194624830419652, 'dropout_rate_Layer_2': 0.246376688225112, 'dropout_rate_Layer_3': 0.06346776699147684, 'dropout_rate_Layer_4': 0.06722170280300917, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 3.7706166084740634e-05, 'l1_Layer_2': 0.001970246160759108, 'l1_Layer_3': 0.03581227423822674, 'l1_Layer_4': 0.00020608546893093047, 'n_units_Layer_1': 195, 'n_units_Layer_2': 235, 'n_units_Layer_3': 100, 'n_units_Layer_4': 190}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.44 | sMAPE for Validation Set is: 18.85% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 12.33 | sMAPE for Test Set is: 29.47% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:20:39,505]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:20:48,788]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:20:54,057]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:20:54,719]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:21:01,101]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:21:02,892]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:21:05,547]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:21:07,926]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:21:11,257]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:21:15,349]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:21:17,674]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:21:21,924]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:21:25,444]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:21:26,870]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:21:29,343]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:21:34,381]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:21:36,655]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:21:39,591]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:21:42,597]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:21:43,199]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:21:51,286]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:22:02,010]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:22:02,698]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:22:09,229]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:22:12,505]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:22:14,845]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:22:15,909]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:22:18,664]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:22:19,253]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:22:24,369]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:22:28,331]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:22:32,667]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:22:33,585]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:22:39,161]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:22:39,662]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:22:43,061]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:22:47,176]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:22:51,367]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:22:51,676]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:22:57,437]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:23:02,595]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:23:02,910]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:23:07,449]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:23:11,157]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:23:11,719]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:23:18,878]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:23:22,645]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:23:31,217]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:23:43,981]\u001b[0m Trial 576 finished with value: 5.27650437494674 and parameters: {'n_hidden': 4, 'learning_rate': 0.0026847509097875496, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05298554037170415, 'dropout_rate_Layer_2': 0.22282858702244435, 'dropout_rate_Layer_3': 0.3717556357123892, 'dropout_rate_Layer_4': 0.278249391317606, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0054931043358490556, 'l1_Layer_2': 0.01194324681307862, 'l1_Layer_3': 0.006225201802003339, 'l1_Layer_4': 0.00013575133110673354, 'n_units_Layer_1': 240, 'n_units_Layer_2': 210, 'n_units_Layer_3': 80, 'n_units_Layer_4': 265}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.28 | sMAPE for Validation Set is: 18.46% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.45 | sMAPE for Test Set is: 24.98% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:23:47,617]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:23:47,950]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:23:48,125]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:23:54,257]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:23:57,407]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:23:57,538]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:23:58,764]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:24:10,360]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:24:11,714]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:24:16,063]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:24:20,932]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:24:26,976]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:24:27,693]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:24:44,096]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:24:44,925]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:24:54,228]\u001b[0m Trial 591 finished with value: 5.04399902647878 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021855076757934942, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22467155582983925, 'dropout_rate_Layer_2': 0.14582783580905812, 'dropout_rate_Layer_3': 0.07781342555250878, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.929382020675082e-05, 'l1_Layer_2': 0.002991160508023108, 'l1_Layer_3': 6.747087635700751e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 110, 'n_units_Layer_3': 50}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.04 | sMAPE for Validation Set is: 17.56% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 11.72 | sMAPE for Test Set is: 28.11% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:25:01,973]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:25:08,777]\u001b[0m Trial 595 finished with value: 5.2605114034012495 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015663461039480636, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10907282302362517, 'dropout_rate_Layer_2': 0.15788103050971752, 'dropout_rate_Layer_3': 0.10419489654822156, 'dropout_rate_Layer_4': 0.2690765926479439, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0003118497609432879, 'l1_Layer_2': 0.014884808112206101, 'l1_Layer_3': 0.0007746975102510853, 'l1_Layer_4': 0.0004787468959596824, 'n_units_Layer_1': 240, 'n_units_Layer_2': 185, 'n_units_Layer_3': 225, 'n_units_Layer_4': 120}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.26 | sMAPE for Validation Set is: 18.42% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 12.86 | sMAPE for Test Set is: 31.37% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:25:12,167]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:25:16,532]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:25:20,596]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:25:23,740]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:25:29,958]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:25:33,510]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:25:33,534]\u001b[0m Trial 599 finished with value: 4.930412773739692 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022813484169631236, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20835614327887597, 'dropout_rate_Layer_2': 0.1882470327240125, 'dropout_rate_Layer_3': 0.06687732566775344, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.344711141940936e-05, 'l1_Layer_2': 0.001106642660712508, 'l1_Layer_3': 1.5348035930239008e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 115, 'n_units_Layer_3': 170}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.93 | sMAPE for Validation Set is: 17.16% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 9.74 | sMAPE for Test Set is: 23.41% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:25:39,324]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:25:43,599]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:25:44,231]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:26:08,063]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:26:18,199]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:26:20,147]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:26:23,468]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:26:24,175]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:26:28,993]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:26:29,497]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:26:37,418]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:26:42,275]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:26:56,075]\u001b[0m Trial 598 finished with value: 5.42122390604996 and parameters: {'n_hidden': 4, 'learning_rate': 0.005786064695061402, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19219620224868028, 'dropout_rate_Layer_2': 0.1181226341873188, 'dropout_rate_Layer_3': 0.06579357924938337, 'dropout_rate_Layer_4': 0.31866074421412155, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00213870024400541, 'l1_Layer_2': 0.018758779374446678, 'l1_Layer_3': 0.001670059735239858, 'l1_Layer_4': 0.030486617136493043, 'n_units_Layer_1': 165, 'n_units_Layer_2': 200, 'n_units_Layer_3': 195, 'n_units_Layer_4': 200}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.42 | sMAPE for Validation Set is: 18.59% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 13.87 | sMAPE for Test Set is: 33.52% | rMAE for Test Set is: 1.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:27:01,846]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:27:05,024]\u001b[0m Trial 617 finished with value: 5.313557784588422 and parameters: {'n_hidden': 4, 'learning_rate': 0.001267058294522282, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2728223332257494, 'dropout_rate_Layer_2': 0.2302112573488349, 'dropout_rate_Layer_3': 0.04951619147415012, 'dropout_rate_Layer_4': 0.15827344513296315, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.6281195235672175e-05, 'l1_Layer_2': 0.008222450004834916, 'l1_Layer_3': 1.5589948802928446e-05, 'l1_Layer_4': 9.793528522021679e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 115, 'n_units_Layer_3': 140, 'n_units_Layer_4': 115}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.31 | sMAPE for Validation Set is: 18.46% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 11.68 | sMAPE for Test Set is: 28.41% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:27:05,322]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:27:05,729]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:27:05,834]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:27:15,379]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:27:15,846]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:27:16,937]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:27:20,890]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:27:24,219]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:27:25,735]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:27:27,612]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:27:32,779]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:27:37,728]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:27:51,456]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:28:01,526]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:28:07,128]\u001b[0m Trial 625 finished with value: 5.275694826632684 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008605284993712866, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1413411236683484, 'dropout_rate_Layer_2': 0.1726050084302641, 'dropout_rate_Layer_3': 0.08077297006858873, 'dropout_rate_Layer_4': 0.34641805574878554, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00019041626035597924, 'l1_Layer_2': 0.010367351651030601, 'l1_Layer_3': 3.617067289858057e-05, 'l1_Layer_4': 0.00012714849619345218, 'n_units_Layer_1': 200, 'n_units_Layer_2': 160, 'n_units_Layer_3': 250, 'n_units_Layer_4': 90}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.28 | sMAPE for Validation Set is: 18.46% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 11.60 | sMAPE for Test Set is: 28.32% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:28:09,317]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:28:10,085]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:28:11,785]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:28:19,636]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:28:22,338]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:28:23,854]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:28:28,820]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:28:29,616]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:28:31,014]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:28:34,437]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:28:38,995]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:28:41,339]\u001b[0m Trial 631 finished with value: 5.2677418459127745 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008429349466005837, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14411588179900967, 'dropout_rate_Layer_2': 0.07845548471519469, 'dropout_rate_Layer_3': 0.08463894317150358, 'dropout_rate_Layer_4': 0.3465611582246595, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00014988806737450155, 'l1_Layer_2': 0.011071068221471083, 'l1_Layer_3': 0.0005779321462715372, 'l1_Layer_4': 0.0001383802213601539, 'n_units_Layer_1': 205, 'n_units_Layer_2': 165, 'n_units_Layer_3': 245, 'n_units_Layer_4': 80}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:28:41,428]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.27 | sMAPE for Validation Set is: 18.49% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 12.33 | sMAPE for Test Set is: 30.15% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:28:42,164]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:28:48,293]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:28:48,531]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:28:53,650]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:28:55,755]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:28:58,839]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:29:03,960]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:29:04,369]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:29:09,125]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:29:10,630]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:29:22,240]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:29:31,049]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:29:40,743]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:29:40,766]\u001b[0m Trial 653 finished with value: 5.256937141675967 and parameters: {'n_hidden': 4, 'learning_rate': 0.0027552998243757223, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07050299080230232, 'dropout_rate_Layer_2': 0.13311875281724433, 'dropout_rate_Layer_3': 0.10716493785299519, 'dropout_rate_Layer_4': 0.10014850946976687, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0009258650302329254, 'l1_Layer_2': 0.030247758867988063, 'l1_Layer_3': 0.00018933641102930786, 'l1_Layer_4': 0.00297352235832437, 'n_units_Layer_1': 175, 'n_units_Layer_2': 180, 'n_units_Layer_3': 220, 'n_units_Layer_4': 165}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.26 | sMAPE for Validation Set is: 18.42% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 11.20 | sMAPE for Test Set is: 26.69% | rMAE for Test Set is: 1.06\n",
      "MAE for Validation Set is: 4.99 | sMAPE for Validation Set is: 17.53% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.56 | sMAPE for Test Set is: 25.35% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:29:45,446]\u001b[0m Trial 661 finished with value: 4.986413153836182 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022275578156663346, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19073735076995965, 'dropout_rate_Layer_2': 0.09943065765354453, 'dropout_rate_Layer_3': 0.23282737816193355, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.066594963319334e-05, 'l1_Layer_2': 0.0009636551077305658, 'l1_Layer_3': 7.52234050942734e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 140, 'n_units_Layer_3': 165}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:29:51,285]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:29:51,497]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:29:57,467]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:30:02,035]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:30:05,461]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:30:08,906]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:30:14,401]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:30:20,019]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:30:27,047]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:30:29,519]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:30:33,545]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:30:37,292]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:30:40,672]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:30:48,007]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:30:48,536]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:30:53,373]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:30:55,635]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:30:55,861]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:31:03,955]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:31:08,392]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:31:10,829]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:31:14,912]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:31:17,155]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:31:26,176]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:31:26,412]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:31:32,767]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:31:36,974]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:31:40,981]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:31:45,312]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:31:53,118]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:31:54,979]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:31:59,506]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:32:03,372]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:32:04,353]\u001b[0m Trial 682 finished with value: 5.145548773258093 and parameters: {'n_hidden': 4, 'learning_rate': 0.0020629911381241746, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04891763455690973, 'dropout_rate_Layer_2': 0.15742970827427458, 'dropout_rate_Layer_3': 0.009704674033929281, 'dropout_rate_Layer_4': 0.28129477940278835, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00012285069888388135, 'l1_Layer_2': 0.012693548295387847, 'l1_Layer_3': 0.0062856059367699686, 'l1_Layer_4': 0.00015340417479027486, 'n_units_Layer_1': 150, 'n_units_Layer_2': 75, 'n_units_Layer_3': 155, 'n_units_Layer_4': 290}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.15 | sMAPE for Validation Set is: 17.94% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.17 | sMAPE for Test Set is: 24.63% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:32:10,380]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:32:14,178]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:32:14,632]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:32:15,477]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:32:20,182]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:32:22,445]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:32:23,302]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:32:23,779]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:32:28,253]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:32:30,995]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:32:34,579]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:32:40,723]\u001b[0m Trial 690 finished with value: 5.311006996755938 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006324095206642185, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0899556991209974, 'dropout_rate_Layer_2': 0.11927507789400084, 'dropout_rate_Layer_3': 0.05096292815348385, 'dropout_rate_Layer_4': 0.27352617285520564, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00032424943808195865, 'l1_Layer_2': 0.023999827623157378, 'l1_Layer_3': 0.0002877029668394726, 'l1_Layer_4': 0.0005669616199502511, 'n_units_Layer_1': 185, 'n_units_Layer_2': 180, 'n_units_Layer_3': 220, 'n_units_Layer_4': 185}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.31 | sMAPE for Validation Set is: 18.52% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.78 | sMAPE for Test Set is: 23.67% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:32:46,424]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:32:55,041]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:32:59,078]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:33:03,696]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:33:07,287]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:33:08,482]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:33:12,914]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:33:13,714]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:33:18,143]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:33:21,568]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:33:26,060]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:33:29,458]\u001b[0m Trial 709 finished with value: 5.168520516334744 and parameters: {'n_hidden': 4, 'learning_rate': 0.002169767950122787, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14771439983816959, 'dropout_rate_Layer_2': 0.14488057904645313, 'dropout_rate_Layer_3': 0.006262254940120561, 'dropout_rate_Layer_4': 0.288126331304127, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 9.851463917714073e-05, 'l1_Layer_2': 0.01310646957396614, 'l1_Layer_3': 1.581487772348029e-05, 'l1_Layer_4': 0.000144801244520596, 'n_units_Layer_1': 155, 'n_units_Layer_2': 50, 'n_units_Layer_3': 145, 'n_units_Layer_4': 285}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.17 | sMAPE for Validation Set is: 18.13% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.71 | sMAPE for Test Set is: 25.43% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:33:32,475]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:33:35,721]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:33:36,700]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:33:42,105]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:33:48,499]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:33:52,318]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:33:55,915]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:34:00,266]\u001b[0m Trial 725 finished with value: 5.278167066658454 and parameters: {'n_hidden': 4, 'learning_rate': 0.004383113107387496, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10122480207823614, 'dropout_rate_Layer_2': 0.13139146158723639, 'dropout_rate_Layer_3': 0.12705404684134364, 'dropout_rate_Layer_4': 0.193313832186926, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0006618652692774775, 'l1_Layer_2': 0.03210981009708843, 'l1_Layer_3': 0.0006396593258821265, 'l1_Layer_4': 0.00021642574269783635, 'n_units_Layer_1': 155, 'n_units_Layer_2': 85, 'n_units_Layer_3': 200, 'n_units_Layer_4': 205}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.28 | sMAPE for Validation Set is: 18.55% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.33 | sMAPE for Test Set is: 22.79% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:34:04,339]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:34:10,186]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:34:10,518]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:34:18,789]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:34:27,729]\u001b[0m Trial 712 finished with value: 4.894424445247295 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005152978589039073, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19138920189644634, 'dropout_rate_Layer_2': 0.10080144127761054, 'dropout_rate_Layer_3': 0.24511599070646098, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00021084290439059514, 'l1_Layer_2': 0.0009498909966547595, 'l1_Layer_3': 6.212998090898505e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 140, 'n_units_Layer_3': 165}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.89 | sMAPE for Validation Set is: 17.19% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 8.79 | sMAPE for Test Set is: 20.96% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:34:31,456]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:34:49,431]\u001b[0m Trial 732 finished with value: 5.274337293899705 and parameters: {'n_hidden': 4, 'learning_rate': 0.0027161234983938292, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08034510536422432, 'dropout_rate_Layer_2': 0.21856539834488328, 'dropout_rate_Layer_3': 0.14417058168121388, 'dropout_rate_Layer_4': 0.056165151650358985, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0008768681461759839, 'l1_Layer_2': 0.025393599291678, 'l1_Layer_3': 0.00018337294381880878, 'l1_Layer_4': 0.001333492150361531, 'n_units_Layer_1': 230, 'n_units_Layer_2': 230, 'n_units_Layer_3': 215, 'n_units_Layer_4': 235}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.27 | sMAPE for Validation Set is: 18.45% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.30 | sMAPE for Test Set is: 24.64% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:34:57,811]\u001b[0m Trial 736 finished with value: 5.268193901324406 and parameters: {'n_hidden': 4, 'learning_rate': 0.0026766579936698, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1796585463493392, 'dropout_rate_Layer_2': 0.22277030242182125, 'dropout_rate_Layer_3': 0.1531176037509431, 'dropout_rate_Layer_4': 0.06537823536286697, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0014689521477307228, 'l1_Layer_2': 0.02667072255930451, 'l1_Layer_3': 0.00011339795768847794, 'l1_Layer_4': 0.0013619957330578243, 'n_units_Layer_1': 215, 'n_units_Layer_2': 100, 'n_units_Layer_3': 215, 'n_units_Layer_4': 230}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.27 | sMAPE for Validation Set is: 18.41% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.36 | sMAPE for Test Set is: 24.71% | rMAE for Test Set is: 0.98\n",
      "MAE for Validation Set is: 5.34 | sMAPE for Validation Set is: 18.58% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 12.94 | sMAPE for Test Set is: 31.15% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:34:59,827]\u001b[0m Trial 735 finished with value: 5.340340153766967 and parameters: {'n_hidden': 4, 'learning_rate': 0.002750705380228962, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20294934353127983, 'dropout_rate_Layer_2': 0.221839154564542, 'dropout_rate_Layer_3': 0.1488719711015172, 'dropout_rate_Layer_4': 0.3726948669202057, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0013055617879920525, 'l1_Layer_2': 0.005575758138168762, 'l1_Layer_3': 0.00011400674131560083, 'l1_Layer_4': 0.0032529132266827794, 'n_units_Layer_1': 215, 'n_units_Layer_2': 100, 'n_units_Layer_3': 215, 'n_units_Layer_4': 235}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:35:07,691]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:35:11,480]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:35:11,923]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:35:20,845]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:35:49,146]\u001b[0m Trial 738 finished with value: 5.147591694182192 and parameters: {'n_hidden': 4, 'learning_rate': 0.001981099923050053, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15861173923957378, 'dropout_rate_Layer_2': 0.10699021434069916, 'dropout_rate_Layer_3': 0.04224705296715077, 'dropout_rate_Layer_4': 0.27107498363438254, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00016071207144055584, 'l1_Layer_2': 0.009919065242773716, 'l1_Layer_3': 1.5728455694106533e-05, 'l1_Layer_4': 2.973830061060014e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 60, 'n_units_Layer_3': 140, 'n_units_Layer_4': 285}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.15 | sMAPE for Validation Set is: 18.06% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.12 | sMAPE for Test Set is: 26.60% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:35:50,563]\u001b[0m Trial 739 finished with value: 4.815856287199693 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005780429974826962, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16864913864599512, 'dropout_rate_Layer_2': 0.0741014520989487, 'dropout_rate_Layer_3': 0.09241436808959538, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002633416736088841, 'l1_Layer_2': 0.0002825483112115435, 'l1_Layer_3': 3.5004083066362015e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 155, 'n_units_Layer_3': 145}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.82 | sMAPE for Validation Set is: 16.82% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 8.54 | sMAPE for Test Set is: 20.44% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:35:54,661]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:35:58,017]\u001b[0m Trial 743 finished with value: 4.90858225033936 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007422376962468357, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06287685177271582, 'dropout_rate_Layer_2': 0.16620661691499172, 'dropout_rate_Layer_3': 0.09553254436993087, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00021514634644706463, 'l1_Layer_2': 0.00030760434608409514, 'l1_Layer_3': 3.383966555626226e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 150, 'n_units_Layer_3': 290}. Best is trial 241 with value: 4.807586198566027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.91 | sMAPE for Validation Set is: 17.31% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 9.65 | sMAPE for Test Set is: 23.18% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:36:02,890]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:36:08,752]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:36:13,320]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:36:18,754]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:36:24,951]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:36:44,025]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:36:45,281]\u001b[0m Trial 748 finished with value: 4.786526648923894 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005558018458874619, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.053391743248218604, 'dropout_rate_Layer_2': 0.07262567419442363, 'dropout_rate_Layer_3': 0.09022368726561228, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022257865843898345, 'l1_Layer_2': 0.00026609054566125167, 'l1_Layer_3': 3.736704386273433e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 130, 'n_units_Layer_3': 165}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.79 | sMAPE for Validation Set is: 16.90% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 8.22 | sMAPE for Test Set is: 19.77% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:36:51,142]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:36:58,719]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:37:11,544]\u001b[0m Trial 750 finished with value: 4.874168700497022 and parameters: {'n_hidden': 3, 'learning_rate': 0.000509324831536602, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05073752154578781, 'dropout_rate_Layer_2': 0.08887326959444332, 'dropout_rate_Layer_3': 0.09341637793972692, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002292782867564698, 'l1_Layer_2': 0.00034580473496021184, 'l1_Layer_3': 3.635646554343499e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 150, 'n_units_Layer_3': 290}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.87 | sMAPE for Validation Set is: 17.18% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 9.74 | sMAPE for Test Set is: 23.27% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:37:15,347]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:37:20,975]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:37:29,522]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:37:39,030]\u001b[0m Trial 757 finished with value: 4.860088854391594 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005645331305056246, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03777678505720693, 'dropout_rate_Layer_2': 0.1811694459359185, 'dropout_rate_Layer_3': 0.09547024479105756, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002308092453366585, 'l1_Layer_2': 0.00025879180135920704, 'l1_Layer_3': 3.731337641611311e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 150, 'n_units_Layer_3': 245}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.86 | sMAPE for Validation Set is: 17.22% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 9.27 | sMAPE for Test Set is: 22.25% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:37:39,273]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:37:45,840]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:37:48,244]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:37:50,290]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:37:52,979]\u001b[0m Trial 758 finished with value: 4.827625736557017 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005108300974196063, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07226754464163627, 'dropout_rate_Layer_2': 0.07616158264558992, 'dropout_rate_Layer_3': 0.09361805190322081, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022998153293997834, 'l1_Layer_2': 0.00011826249252813442, 'l1_Layer_3': 3.605106060364052e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 160, 'n_units_Layer_3': 295}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.83 | sMAPE for Validation Set is: 17.08% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 8.47 | sMAPE for Test Set is: 20.53% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:37:53,126]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:37:54,861]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:38:00,594]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:38:01,045]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:38:07,169]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:38:07,770]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:38:08,412]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:38:14,181]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:38:17,380]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:38:22,363]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:38:24,225]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:38:27,542]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:38:32,147]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:38:33,027]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:38:38,606]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:38:48,615]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:38:59,218]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:39:13,676]\u001b[0m Trial 772 finished with value: 4.861071976689931 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005051351415494536, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.058223051917454166, 'dropout_rate_Layer_2': 0.21657299989650672, 'dropout_rate_Layer_3': 0.10423928991010925, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023296195398718066, 'l1_Layer_2': 0.00025407409268615386, 'l1_Layer_3': 3.477535442490559e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 160, 'n_units_Layer_3': 290}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.86 | sMAPE for Validation Set is: 17.24% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 9.26 | sMAPE for Test Set is: 22.22% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:39:17,533]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:39:22,315]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:39:25,665]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:39:34,018]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:39:42,646]\u001b[0m Trial 782 finished with value: 4.846954800615181 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005495888925728077, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05693973764939735, 'dropout_rate_Layer_2': 0.08630464880404766, 'dropout_rate_Layer_3': 0.10370302460140823, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020710135340040067, 'l1_Layer_2': 0.0001623741705483952, 'l1_Layer_3': 3.859484469740231e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 160, 'n_units_Layer_3': 280}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.85 | sMAPE for Validation Set is: 17.07% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 9.08 | sMAPE for Test Set is: 21.70% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:39:44,853]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:39:48,169]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:39:53,302]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:39:56,670]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:40:05,227]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:40:11,544]\u001b[0m Trial 785 finished with value: 4.915227762935216 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005216233550527426, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04928178493212465, 'dropout_rate_Layer_2': 0.2206750726903772, 'dropout_rate_Layer_3': 0.10215206165630353, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000254073587745975, 'l1_Layer_2': 0.00024726123963458743, 'l1_Layer_3': 4.304722996262684e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 160, 'n_units_Layer_3': 290}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.92 | sMAPE for Validation Set is: 17.37% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 8.89 | sMAPE for Test Set is: 21.42% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:40:15,362]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:40:30,594]\u001b[0m Trial 786 finished with value: 4.826597318375133 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005281795306277556, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05146301930584568, 'dropout_rate_Layer_2': 0.22005467707589665, 'dropout_rate_Layer_3': 0.10274013337498725, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005123121277502696, 'l1_Layer_2': 0.00010794405712396784, 'l1_Layer_3': 3.5426250670347526e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 150, 'n_units_Layer_3': 290}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.83 | sMAPE for Validation Set is: 17.10% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 9.07 | sMAPE for Test Set is: 21.79% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:40:34,454]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:40:37,799]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:40:41,631]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:40:45,510]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:40:50,380]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:40:53,520]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:40:56,910]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:40:59,254]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:41:00,533]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:41:06,327]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:41:11,647]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:41:11,798]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:41:20,312]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:41:24,377]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:41:31,056]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:41:35,004]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:41:36,120]\u001b[0m Trial 795 finished with value: 4.940318236486082 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005119180717841123, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05097543316999095, 'dropout_rate_Layer_2': 0.21802085102055047, 'dropout_rate_Layer_3': 0.1030731598525434, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005417400732104663, 'l1_Layer_2': 0.00011821434452456624, 'l1_Layer_3': 3.642286704100264e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 175, 'n_units_Layer_3': 285}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.94 | sMAPE for Validation Set is: 17.50% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 10.27 | sMAPE for Test Set is: 24.97% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:41:41,183]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:41:48,047]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:41:51,951]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:41:54,931]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:42:00,400]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:42:00,570]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:42:07,389]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:42:21,082]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:42:26,301]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:42:30,447]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:42:30,721]\u001b[0m Trial 810 finished with value: 4.878744144527662 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006006458685920693, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.062300633585643896, 'dropout_rate_Layer_2': 0.2596479852556415, 'dropout_rate_Layer_3': 0.11557669529402118, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004879445179908425, 'l1_Layer_2': 5.446068236524443e-05, 'l1_Layer_3': 3.0580241859150595e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 175, 'n_units_Layer_3': 285}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.88 | sMAPE for Validation Set is: 16.98% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 9.86 | sMAPE for Test Set is: 23.73% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:42:41,313]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:42:44,972]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:42:55,472]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:43:37,717]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:43:42,073]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:43:46,245]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:44:04,429]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:44:08,560]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:44:12,379]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:44:16,690]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:44:20,729]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:44:24,693]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:44:28,459]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:45:05,396]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:45:17,581]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:46:01,574]\u001b[0m Trial 830 finished with value: 5.360597017641619 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010077353100179324, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24504806689045697, 'dropout_rate_Layer_2': 0.0694163031580896, 'dropout_rate_Layer_3': 0.10277514650254307, 'dropout_rate_Layer_4': 0.30604856011628523, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0005161453740117723, 'l1_Layer_2': 0.01612813040877756, 'l1_Layer_3': 0.00023840826072385384, 'l1_Layer_4': 0.004763180044783157, 'n_units_Layer_1': 195, 'n_units_Layer_2': 70, 'n_units_Layer_3': 180, 'n_units_Layer_4': 160}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.36 | sMAPE for Validation Set is: 18.29% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 13.65 | sMAPE for Test Set is: 32.95% | rMAE for Test Set is: 1.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:46:09,621]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:46:10,606]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:46:14,464]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:46:16,846]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:46:18,223]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:46:21,835]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:46:26,198]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:46:30,484]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:46:31,453]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.10 | sMAPE for Validation Set is: 17.90% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.66 | sMAPE for Test Set is: 16.75% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:46:35,047]\u001b[0m Trial 840 finished with value: 5.099810183354597 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010008210781357828, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11365107766684368, 'dropout_rate_Layer_2': 0.06842624985712357, 'dropout_rate_Layer_3': 0.05848758942371808, 'dropout_rate_Layer_4': 0.3068191907651624, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0005581480986528767, 'l1_Layer_2': 0.001615575144781266, 'l1_Layer_3': 0.0009812632100227867, 'l1_Layer_4': 0.018934403461674302, 'n_units_Layer_1': 195, 'n_units_Layer_2': 70, 'n_units_Layer_3': 185, 'n_units_Layer_4': 110}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:46:39,210]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:46:44,023]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:46:48,600]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:46:53,485]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:46:54,035]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:46:59,611]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:47:01,909]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:47:04,744]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:47:05,834]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:47:09,983]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:47:10,533]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:47:14,613]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:47:17,500]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:47:23,995]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:47:28,800]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:47:29,276]\u001b[0m Trial 852 finished with value: 5.311305815247851 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014344533293825458, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15226771843679152, 'dropout_rate_Layer_2': 0.09333642136129613, 'dropout_rate_Layer_3': 0.08295288754719674, 'dropout_rate_Layer_4': 0.33459985457218316, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 8.733633242364851e-05, 'l1_Layer_2': 0.010477378443714106, 'l1_Layer_3': 0.000501227400317321, 'l1_Layer_4': 0.0002028121320282185, 'n_units_Layer_1': 205, 'n_units_Layer_2': 165, 'n_units_Layer_3': 245, 'n_units_Layer_4': 85}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.31 | sMAPE for Validation Set is: 18.49% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 11.03 | sMAPE for Test Set is: 26.53% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:47:34,176]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:47:34,362]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:47:40,487]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:47:40,700]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:47:47,818]\u001b[0m Trial 858 finished with value: 4.851232451443011 and parameters: {'n_hidden': 3, 'learning_rate': 0.000715331835027187, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03712780706666306, 'dropout_rate_Layer_2': 0.2439322852620841, 'dropout_rate_Layer_3': 0.1333678380324279, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00039251905553109863, 'l1_Layer_2': 2.1586733580003657e-05, 'l1_Layer_3': 3.091407534399825e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 160, 'n_units_Layer_3': 270}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.85 | sMAPE for Validation Set is: 17.12% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 7.86 | sMAPE for Test Set is: 19.07% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:47:48,591]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:47:52,939]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:47:53,666]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:47:58,318]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:47:58,936]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:48:01,681]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:48:06,375]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:48:06,739]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:48:12,335]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:48:13,153]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:48:17,433]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:48:18,665]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:48:24,628]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:48:28,900]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:48:32,455]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:48:40,807]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:48:46,098]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:48:49,948]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:48:50,409]\u001b[0m Trial 872 finished with value: 4.973363603849651 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012184735187094184, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01844052263010447, 'dropout_rate_Layer_2': 0.012987237574698392, 'dropout_rate_Layer_3': 0.05747046134556405, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008242587534827232, 'l1_Layer_2': 0.0014954303445847109, 'l1_Layer_3': 0.0021886604665144476, 'n_units_Layer_1': 225, 'n_units_Layer_2': 75, 'n_units_Layer_3': 160}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.97 | sMAPE for Validation Set is: 17.44% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.51 | sMAPE for Test Set is: 16.30% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:49:00,574]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:49:00,649]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:49:06,132]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:49:07,009]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:49:11,636]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:49:15,137]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:49:20,984]\u001b[0m Trial 878 finished with value: 4.824812884475738 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011186417422801573, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05863322972501117, 'dropout_rate_Layer_2': 0.18190851419268012, 'dropout_rate_Layer_3': 0.07053924326687044, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0020612493511765807, 'l1_Layer_2': 0.0009822889747547472, 'l1_Layer_3': 0.000346681622110688, 'n_units_Layer_1': 255, 'n_units_Layer_2': 175, 'n_units_Layer_3': 205}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.82 | sMAPE for Validation Set is: 17.01% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.35 | sMAPE for Test Set is: 15.83% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:49:33,317]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:49:33,804]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:49:37,889]\u001b[0m Trial 885 finished with value: 4.806944673332894 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007055766446942192, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17023238455084344, 'dropout_rate_Layer_2': 0.1184620304580571, 'dropout_rate_Layer_3': 0.055160699299478505, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018831090222617454, 'l1_Layer_2': 0.001241923518455935, 'l1_Layer_3': 0.00038847413256409645, 'n_units_Layer_1': 170, 'n_units_Layer_2': 175, 'n_units_Layer_3': 205}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.81 | sMAPE for Validation Set is: 16.97% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.36 | sMAPE for Test Set is: 15.97% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:49:47,501]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:49:48,462]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:49:52,391]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:49:55,520]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:49:56,296]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:50:00,812]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:50:05,131]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:50:16,131]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:50:39,431]\u001b[0m Trial 906 finished with value: 4.877720997700922 and parameters: {'n_hidden': 3, 'learning_rate': 0.000567906095570958, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03854827997579281, 'dropout_rate_Layer_2': 0.24204196441979461, 'dropout_rate_Layer_3': 0.09489156975703598, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002537381598068008, 'l1_Layer_2': 0.00019507896304149912, 'l1_Layer_3': 3.211704537235546e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 150, 'n_units_Layer_3': 290}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.88 | sMAPE for Validation Set is: 17.30% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 8.24 | sMAPE for Test Set is: 20.08% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:50:55,958]\u001b[0m Trial 911 finished with value: 4.891390595883409 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005700270052189165, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.040122168535530855, 'dropout_rate_Layer_2': 0.23752651698871657, 'dropout_rate_Layer_3': 0.09481113385247718, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003038916024853576, 'l1_Layer_2': 2.7317985250739138e-05, 'l1_Layer_3': 3.260033967679067e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 170, 'n_units_Layer_3': 280}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.89 | sMAPE for Validation Set is: 17.26% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 7.38 | sMAPE for Test Set is: 18.21% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:51:04,081]\u001b[0m Trial 900 finished with value: 5.009143146205576 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007327396106300663, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.011762076283081511, 'dropout_rate_Layer_2': 0.046235926031038974, 'dropout_rate_Layer_3': 0.06091389754095025, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001847285497014185, 'l1_Layer_2': 0.0012569761274097203, 'l1_Layer_3': 0.0020565295743386223, 'n_units_Layer_1': 250, 'n_units_Layer_2': 55, 'n_units_Layer_3': 130}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.01 | sMAPE for Validation Set is: 17.59% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.52 | sMAPE for Test Set is: 16.38% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:51:11,082]\u001b[0m Trial 910 finished with value: 4.985519959983491 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007171548415535284, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0247842626162241, 'dropout_rate_Layer_2': 0.006652649082561096, 'dropout_rate_Layer_3': 0.060883079265527176, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0019196723761255917, 'l1_Layer_2': 0.0010119119666507589, 'l1_Layer_3': 0.001861427724676611, 'n_units_Layer_1': 225, 'n_units_Layer_2': 145, 'n_units_Layer_3': 170}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.99 | sMAPE for Validation Set is: 17.50% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.60 | sMAPE for Test Set is: 16.55% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:51:14,140]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:51:19,979]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:51:21,037]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:51:24,773]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:51:29,338]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:51:29,948]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:51:37,361]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:51:40,952]\u001b[0m Trial 912 finished with value: 4.9068553900518905 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005746062470975736, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.039484610156517164, 'dropout_rate_Layer_2': 0.29153296030630943, 'dropout_rate_Layer_3': 0.11214441257095982, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00031636631837891373, 'l1_Layer_2': 0.0001914746872882946, 'l1_Layer_3': 3.0193479860143585e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 170, 'n_units_Layer_3': 280}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.91 | sMAPE for Validation Set is: 17.24% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 7.76 | sMAPE for Test Set is: 18.87% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:51:47,947]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:52:12,215]\u001b[0m Trial 922 finished with value: 4.894279839006883 and parameters: {'n_hidden': 3, 'learning_rate': 0.000581225330686857, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04212409131689095, 'dropout_rate_Layer_2': 0.2347209815227831, 'dropout_rate_Layer_3': 0.08912608380373363, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00028811465682775187, 'l1_Layer_2': 2.5459389239665298e-05, 'l1_Layer_3': 3.051343382137993e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 170, 'n_units_Layer_3': 280}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.89 | sMAPE for Validation Set is: 17.30% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 7.66 | sMAPE for Test Set is: 18.75% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:52:26,481]\u001b[0m Trial 913 finished with value: 5.30853184755066 and parameters: {'n_hidden': 4, 'learning_rate': 0.001379557015105017, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16940357028723305, 'dropout_rate_Layer_2': 0.30038785698479115, 'dropout_rate_Layer_3': 0.11530323963957428, 'dropout_rate_Layer_4': 0.31298685718213604, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 4.9530605160479686e-05, 'l1_Layer_2': 0.0005687130719745356, 'l1_Layer_3': 0.0038872142201727506, 'l1_Layer_4': 0.00013731728924670523, 'n_units_Layer_1': 200, 'n_units_Layer_2': 55, 'n_units_Layer_3': 145, 'n_units_Layer_4': 265}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.31 | sMAPE for Validation Set is: 18.58% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.85 | sMAPE for Test Set is: 26.10% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:52:37,772]\u001b[0m Trial 920 finished with value: 4.990157517080909 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007480186562150023, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00723266135718955, 'dropout_rate_Layer_2': 0.009917384101808098, 'dropout_rate_Layer_3': 0.017991624014088006, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0022697965408226715, 'l1_Layer_2': 0.0012458380208885385, 'l1_Layer_3': 0.001815223920347567, 'n_units_Layer_1': 260, 'n_units_Layer_2': 50, 'n_units_Layer_3': 130}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.99 | sMAPE for Validation Set is: 17.65% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.55 | sMAPE for Test Set is: 16.52% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:52:42,486]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:52:47,639]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:52:50,796]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:52:51,943]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:53:01,813]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:53:02,730]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:53:08,325]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:53:12,947]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:53:17,315]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:53:20,447]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:53:21,613]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:53:28,604]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:53:32,551]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:53:59,864]\u001b[0m Trial 926 finished with value: 5.37868894105961 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017762655961284382, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14846216000207563, 'dropout_rate_Layer_2': 0.29628431934056254, 'dropout_rate_Layer_3': 0.11953193098680646, 'dropout_rate_Layer_4': 0.2897202208282316, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 5.21697503541977e-05, 'l1_Layer_2': 0.018015780852198446, 'l1_Layer_3': 0.006588051108020893, 'l1_Layer_4': 0.00014081844800628037, 'n_units_Layer_1': 255, 'n_units_Layer_2': 55, 'n_units_Layer_3': 140, 'n_units_Layer_4': 275}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.38 | sMAPE for Validation Set is: 18.76% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 11.60 | sMAPE for Test Set is: 27.91% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:54:04,389]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:54:08,011]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:54:13,175]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:54:17,164]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:54:27,728]\u001b[0m Trial 940 finished with value: 4.924045464407577 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006747486117636001, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015396854249696588, 'dropout_rate_Layer_2': 0.2583718493026806, 'dropout_rate_Layer_3': 0.07798732186195334, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00026227198798247167, 'l1_Layer_2': 0.0001727215024261894, 'l1_Layer_3': 4.0939186790789374e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 165, 'n_units_Layer_3': 295}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.92 | sMAPE for Validation Set is: 17.33% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 8.45 | sMAPE for Test Set is: 20.34% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:54:31,872]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:54:34,397]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:54:42,907]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:54:47,310]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:54:51,741]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:55:02,503]\u001b[0m Trial 939 finished with value: 5.012198004323775 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007202817733025997, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.005648766960316534, 'dropout_rate_Layer_2': 0.014198571588155713, 'dropout_rate_Layer_3': 0.015083920907163317, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002316098044528021, 'l1_Layer_2': 0.0013605778176618234, 'l1_Layer_3': 0.0038465047142712855, 'n_units_Layer_1': 260, 'n_units_Layer_2': 60, 'n_units_Layer_3': 110}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.01 | sMAPE for Validation Set is: 17.69% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.55 | sMAPE for Test Set is: 16.53% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:55:11,466]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:55:15,611]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:55:21,614]\u001b[0m Trial 945 finished with value: 4.840361075442375 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006716942266966636, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02128016652257276, 'dropout_rate_Layer_2': 0.2028093611668449, 'dropout_rate_Layer_3': 0.07807309660259489, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00026905319974497333, 'l1_Layer_2': 0.00017126033188687344, 'l1_Layer_3': 3.820059433921597e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 165, 'n_units_Layer_3': 295}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.84 | sMAPE for Validation Set is: 17.11% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 8.03 | sMAPE for Test Set is: 19.49% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:55:24,601]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:55:26,108]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:55:26,677]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:55:33,200]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:55:58,870]\u001b[0m Trial 951 finished with value: 5.011795597758208 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005832508329067013, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006373356201860962, 'dropout_rate_Layer_2': 0.018783885366014347, 'dropout_rate_Layer_3': 0.06286891585618122, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0023577921527023105, 'l1_Layer_2': 0.001470884921576755, 'l1_Layer_3': 0.004907528426857488, 'n_units_Layer_1': 285, 'n_units_Layer_2': 60, 'n_units_Layer_3': 135}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.01 | sMAPE for Validation Set is: 17.72% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.57 | sMAPE for Test Set is: 16.51% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:56:10,606]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:56:15,566]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:56:19,572]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:56:23,227]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:56:31,894]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:56:43,302]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:56:47,287]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:57:05,136]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:57:05,966]\u001b[0m Trial 959 finished with value: 5.337945511205682 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013400179217638638, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.107882720901882, 'dropout_rate_Layer_2': 0.3046076778882294, 'dropout_rate_Layer_3': 0.11568081447288528, 'dropout_rate_Layer_4': 0.28386918085194496, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 4.920521590650887e-05, 'l1_Layer_2': 0.00028887283188622166, 'l1_Layer_3': 0.0070223936638597545, 'l1_Layer_4': 0.00010372424106657009, 'n_units_Layer_1': 190, 'n_units_Layer_2': 65, 'n_units_Layer_3': 130, 'n_units_Layer_4': 280}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.34 | sMAPE for Validation Set is: 18.54% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 11.04 | sMAPE for Test Set is: 26.32% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:57:11,802]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:57:12,243]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:57:17,723]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:57:18,072]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:57:19,374]\u001b[0m Trial 957 finished with value: 4.9675785367870695 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006587139204673337, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0034258421424126495, 'dropout_rate_Layer_2': 0.22348205133759572, 'dropout_rate_Layer_3': 0.08141615615022389, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017876385980823098, 'l1_Layer_2': 0.00023489777043602333, 'l1_Layer_3': 5.3813676076460896e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 155, 'n_units_Layer_3': 290}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.97 | sMAPE for Validation Set is: 17.55% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 9.33 | sMAPE for Test Set is: 22.32% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:57:25,686]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:57:29,916]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:57:34,300]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:57:41,645]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:57:44,587]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:57:45,122]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:57:51,622]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:58:07,253]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:58:23,286]\u001b[0m Trial 965 finished with value: 4.946601750643325 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005040633494102426, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008691211555485367, 'dropout_rate_Layer_2': 0.01981561792693167, 'dropout_rate_Layer_3': 0.015889849321965535, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0019488492679545775, 'l1_Layer_2': 0.0004221618883213892, 'l1_Layer_3': 0.005063717123350962, 'n_units_Layer_1': 290, 'n_units_Layer_2': 60, 'n_units_Layer_3': 110}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.95 | sMAPE for Validation Set is: 17.48% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.45 | sMAPE for Test Set is: 16.23% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:58:26,335]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:58:32,456]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:58:36,069]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:58:53,052]\u001b[0m Trial 979 finished with value: 4.986681232656695 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005058575836661077, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.001558505904769858, 'dropout_rate_Layer_2': 0.020214160240370815, 'dropout_rate_Layer_3': 0.018771218700628117, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002259313051977576, 'l1_Layer_2': 0.00047272662872626807, 'l1_Layer_3': 0.005660355284446624, 'n_units_Layer_1': 285, 'n_units_Layer_2': 60, 'n_units_Layer_3': 115}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.99 | sMAPE for Validation Set is: 17.67% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.55 | sMAPE for Test Set is: 16.56% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:58:56,110]\u001b[0m Trial 981 finished with value: 4.861164937216921 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005650141983190573, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07645315044052951, 'dropout_rate_Layer_2': 0.19977553798466083, 'dropout_rate_Layer_3': 0.09299730528908792, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014748492976319428, 'l1_Layer_2': 3.386582270907285e-05, 'l1_Layer_3': 1.0247807198514351e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 165, 'n_units_Layer_3': 300}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.86 | sMAPE for Validation Set is: 17.23% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 7.46 | sMAPE for Test Set is: 18.27% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:58:57,295]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:59:00,869]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:59:03,834]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:59:08,425]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:59:11,624]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:59:11,880]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:59:18,190]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:59:21,603]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:59:24,858]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:59:25,912]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:59:32,145]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:59:36,117]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:59:39,989]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:59:44,085]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:59:47,752]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:59:53,396]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:59:55,135]\u001b[0m Trial 986 finished with value: 4.842788165738907 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005531005246820412, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07201520926812266, 'dropout_rate_Layer_2': 0.07408467016541226, 'dropout_rate_Layer_3': 0.09457017945117346, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00045289971844312583, 'l1_Layer_2': 6.637705574678134e-05, 'l1_Layer_3': 3.9563119931785105e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 165, 'n_units_Layer_3': 300}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.84 | sMAPE for Validation Set is: 17.04% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 7.47 | sMAPE for Test Set is: 18.18% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 18:59:57,331]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 18:59:59,467]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:00:04,314]\u001b[0m Trial 985 finished with value: 4.903612699170338 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006094172844604282, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0024055822193949986, 'dropout_rate_Layer_2': 0.01587996730830961, 'dropout_rate_Layer_3': 0.019470960398384717, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0020815309788468506, 'l1_Layer_2': 0.0004279144310230512, 'l1_Layer_3': 0.0057493619819285685, 'n_units_Layer_1': 285, 'n_units_Layer_2': 50, 'n_units_Layer_3': 115}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.90 | sMAPE for Validation Set is: 17.26% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.50 | sMAPE for Test Set is: 16.34% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:00:07,580]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:00:08,926]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:00:11,494]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:00:14,096]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:00:14,139]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:00:16,721]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:00:25,637]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:00:30,278]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:00:33,026]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:00:37,783]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:00:44,066]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:00:49,986]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:01:18,970]\u001b[0m Trial 1011 finished with value: 5.036337074414868 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005177076670690176, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.019117775482543037, 'dropout_rate_Layer_2': 0.03805884190425034, 'dropout_rate_Layer_3': 0.0007999830575418365, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005533449987871684, 'l1_Layer_2': 0.0004171552302913561, 'l1_Layer_3': 0.008189725310211813, 'n_units_Layer_1': 290, 'n_units_Layer_2': 50, 'n_units_Layer_3': 115}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.04 | sMAPE for Validation Set is: 17.82% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.86 | sMAPE for Test Set is: 17.32% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:01:39,271]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:01:43,933]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:01:48,712]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:01:52,747]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:01:54,036]\u001b[0m Trial 1020 finished with value: 4.957629398975793 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005263792535605672, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.025258539035894555, 'dropout_rate_Layer_2': 0.024740258335609583, 'dropout_rate_Layer_3': 0.02093061138345103, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0053041010359890905, 'l1_Layer_2': 0.0002702381513988716, 'l1_Layer_3': 0.002669174896153563, 'n_units_Layer_1': 290, 'n_units_Layer_2': 50, 'n_units_Layer_3': 95}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.96 | sMAPE for Validation Set is: 17.49% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.52 | sMAPE for Test Set is: 16.41% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:01:59,131]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:02:00,003]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:02:05,040]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:02:19,484]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:02:22,208]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:02:22,511]\u001b[0m Trial 1023 finished with value: 4.900845223651919 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010647159146632472, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.027034814989988325, 'dropout_rate_Layer_2': 0.08641389094573736, 'dropout_rate_Layer_3': 0.06366336922485182, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00039893744823398826, 'l1_Layer_2': 0.0002668085131178187, 'l1_Layer_3': 9.789759652228913e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 150, 'n_units_Layer_3': 275}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.90 | sMAPE for Validation Set is: 17.27% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 8.30 | sMAPE for Test Set is: 20.03% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:02:29,204]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:02:29,707]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:02:35,851]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:02:36,234]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:02:36,630]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:02:44,625]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:02:47,154]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:02:50,744]\u001b[0m Trial 1028 finished with value: 4.884741187155302 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010970610784986922, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.018029669507951412, 'dropout_rate_Layer_2': 0.05623763965781345, 'dropout_rate_Layer_3': 0.049218446851186815, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001282399815354672, 'l1_Layer_2': 0.0002842448432328357, 'l1_Layer_3': 1.0376736668167456e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 150, 'n_units_Layer_3': 275}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.88 | sMAPE for Validation Set is: 17.14% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 7.56 | sMAPE for Test Set is: 18.35% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:02:52,182]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:02:56,491]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:02:57,178]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:02:58,204]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:03:08,018]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:03:13,668]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:03:28,968]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:03:33,645]\u001b[0m Trial 1042 finished with value: 4.864963100682424 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006997078749380535, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.016101966333344903, 'dropout_rate_Layer_2': 0.06043660912518806, 'dropout_rate_Layer_3': 0.02338855809340269, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.356040028644611e-05, 'l1_Layer_2': 0.00013671058282867875, 'l1_Layer_3': 4.4740661654596125e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 145, 'n_units_Layer_3': 180}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.86 | sMAPE for Validation Set is: 17.01% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.49 | sMAPE for Test Set is: 16.29% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:03:41,594]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:04:13,941]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:04:18,256]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:04:23,910]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:04:24,008]\u001b[0m Trial 1045 finished with value: 4.8880280023807705 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005028487008747466, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06931795216599232, 'dropout_rate_Layer_2': 0.2589862771958275, 'dropout_rate_Layer_3': 0.10780431550347766, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005453881425331879, 'l1_Layer_2': 8.124639346348602e-05, 'l1_Layer_3': 3.87934219581437e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 175, 'n_units_Layer_3': 285}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.89 | sMAPE for Validation Set is: 17.06% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 9.34 | sMAPE for Test Set is: 22.30% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:04:27,083]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:04:35,494]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:04:39,950]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:04:51,016]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:04:51,882]\u001b[0m Trial 1043 finished with value: 4.9763432031894865 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006488178812332695, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.000687736022816686, 'dropout_rate_Layer_2': 0.0016741823536706515, 'dropout_rate_Layer_3': 0.03747534916093205, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0017314726207287878, 'l1_Layer_2': 0.0008202089569345488, 'l1_Layer_3': 0.005548217099112633, 'n_units_Layer_1': 275, 'n_units_Layer_2': 55, 'n_units_Layer_3': 80}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.98 | sMAPE for Validation Set is: 17.45% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.48 | sMAPE for Test Set is: 16.32% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:05:00,008]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:05:01,760]\u001b[0m Trial 1053 finished with value: 4.820252555916347 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007466939888024181, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007482307945476592, 'dropout_rate_Layer_2': 0.06335508305248816, 'dropout_rate_Layer_3': 0.03272973785582858, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.9031985017537493e-05, 'l1_Layer_2': 0.0001282351516846901, 'l1_Layer_3': 5.4133507856631306e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 160, 'n_units_Layer_3': 285}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.82 | sMAPE for Validation Set is: 16.89% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.49 | sMAPE for Test Set is: 16.46% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:05:08,519]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:05:09,693]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:05:21,473]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:05:29,923]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:05:34,727]\u001b[0m Trial 1055 finished with value: 4.805434646155595 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006319303207586787, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05389699659711588, 'dropout_rate_Layer_2': 0.06915696886665615, 'dropout_rate_Layer_3': 0.11902258564401233, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000428530530702883, 'l1_Layer_2': 0.0002110252821107749, 'l1_Layer_3': 2.6974202090555065e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 165, 'n_units_Layer_3': 285}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.81 | sMAPE for Validation Set is: 17.00% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 7.67 | sMAPE for Test Set is: 18.62% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:05:38,921]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:05:43,685]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:05:47,629]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:05:48,298]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:05:55,514]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:06:01,658]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:06:05,372]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:06:10,505]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:06:17,921]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:06:22,336]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:06:30,465]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:06:45,283]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:06:56,568]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:07:00,847]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:07:10,308]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:07:14,593]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:07:18,544]\u001b[0m Trial 1077 finished with value: 4.910445755359681 and parameters: {'n_hidden': 3, 'learning_rate': 0.001570146538945414, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11026593483560762, 'dropout_rate_Layer_2': 0.06065729554734792, 'dropout_rate_Layer_3': 0.040880370229403974, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.6061616900649975e-05, 'l1_Layer_2': 0.0001809154445578766, 'l1_Layer_3': 4.758900867144793e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 155, 'n_units_Layer_3': 190}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.91 | sMAPE for Validation Set is: 17.11% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.41 | sMAPE for Test Set is: 16.14% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:07:22,073]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:07:22,531]\u001b[0m Trial 1062 finished with value: 5.2911694222544385 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013039606323963684, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07265241642977223, 'dropout_rate_Layer_2': 0.2829223279912495, 'dropout_rate_Layer_3': 0.014316812468984823, 'dropout_rate_Layer_4': 0.2702517113017539, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.003919944062154475, 'l1_Layer_2': 0.011784250658635042, 'l1_Layer_3': 0.005328320971580999, 'l1_Layer_4': 7.117081318787603e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 255, 'n_units_Layer_3': 155, 'n_units_Layer_4': 270}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.29 | sMAPE for Validation Set is: 18.43% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.06 | sMAPE for Test Set is: 21.88% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:07:29,446]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:07:29,706]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:07:36,899]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:07:39,588]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:07:46,112]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:07:50,248]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:07:53,753]\u001b[0m Trial 1078 finished with value: 4.820890491131478 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007907772203634383, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35244909349833625, 'dropout_rate_Layer_2': 0.05623610847367441, 'dropout_rate_Layer_3': 0.03869493696603063, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.763030736085216e-05, 'l1_Layer_2': 0.00018026630065111276, 'l1_Layer_3': 4.7520159333509656e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 155, 'n_units_Layer_3': 190}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.82 | sMAPE for Validation Set is: 16.96% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.42 | sMAPE for Test Set is: 16.16% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:07:54,311]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:08:07,044]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:08:14,415]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:08:19,141]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:08:26,084]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:08:29,868]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:08:35,120]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:08:39,978]\u001b[0m Trial 1085 finished with value: 4.997711160306297 and parameters: {'n_hidden': 3, 'learning_rate': 0.001126616574697593, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05283737596628498, 'dropout_rate_Layer_2': 0.023262340915355176, 'dropout_rate_Layer_3': 0.023669308324578926, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005131557178046609, 'l1_Layer_2': 0.0008078387812256991, 'l1_Layer_3': 0.002686874188551422, 'n_units_Layer_1': 290, 'n_units_Layer_2': 55, 'n_units_Layer_3': 65}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.00 | sMAPE for Validation Set is: 17.71% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.56 | sMAPE for Test Set is: 16.59% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:08:44,555]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:08:47,123]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:08:56,374]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:09:25,954]\u001b[0m Trial 1101 finished with value: 4.88822227747275 and parameters: {'n_hidden': 3, 'learning_rate': 0.00103951037373662, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34852363624609617, 'dropout_rate_Layer_2': 0.06022835277352567, 'dropout_rate_Layer_3': 0.04449364464955407, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.3159726240602872e-05, 'l1_Layer_2': 0.00014157022576745206, 'l1_Layer_3': 3.924537630312654e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 160, 'n_units_Layer_3': 190}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.89 | sMAPE for Validation Set is: 17.04% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.72 | sMAPE for Test Set is: 16.58% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:09:47,961]\u001b[0m Trial 1095 finished with value: 5.307827737966286 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011854066902449133, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06787474750880296, 'dropout_rate_Layer_2': 0.280495859900719, 'dropout_rate_Layer_3': 0.0034958907633349523, 'dropout_rate_Layer_4': 0.25194827908693773, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 4.042275712061526e-05, 'l1_Layer_2': 0.012228393449813881, 'l1_Layer_3': 0.004459498140956497, 'l1_Layer_4': 9.115022856488014e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 50, 'n_units_Layer_3': 95, 'n_units_Layer_4': 270}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.31 | sMAPE for Validation Set is: 18.53% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.39 | sMAPE for Test Set is: 22.52% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:09:53,199]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:09:58,263]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:10:02,095]\u001b[0m Trial 1102 finished with value: 4.808747668985549 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005845970362442413, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05969563916325178, 'dropout_rate_Layer_2': 0.28266654348189624, 'dropout_rate_Layer_3': 0.08602893656723432, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005148875429233571, 'l1_Layer_2': 0.0002241155189177106, 'l1_Layer_3': 3.6084019419673743e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 180, 'n_units_Layer_3': 285}. Best is trial 748 with value: 4.786526648923894.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.81 | sMAPE for Validation Set is: 16.97% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 7.67 | sMAPE for Test Set is: 18.67% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:10:02,574]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:10:10,954]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:10:15,258]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:10:15,639]\u001b[0m Trial 1103 finished with value: 4.776370605918505 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005870231227685463, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05922907141701905, 'dropout_rate_Layer_2': 0.19435583442302962, 'dropout_rate_Layer_3': 0.08485984638318116, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005177873090532457, 'l1_Layer_2': 6.88602605764123e-05, 'l1_Layer_3': 3.5872614207593746e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 180, 'n_units_Layer_3': 285}. Best is trial 1103 with value: 4.776370605918505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.78 | sMAPE for Validation Set is: 16.88% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 7.49 | sMAPE for Test Set is: 18.31% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:10:21,593]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:10:24,348]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:10:24,524]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:10:29,436]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:10:46,432]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:10:54,471]\u001b[0m Trial 1114 finished with value: 4.839256852458143 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008529257943066142, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.001402081503425549, 'dropout_rate_Layer_2': 0.06397015669566783, 'dropout_rate_Layer_3': 0.054793807716352026, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.910700022717898e-05, 'l1_Layer_2': 0.00012973813914688464, 'l1_Layer_3': 4.2046230954653165e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 150, 'n_units_Layer_3': 130}. Best is trial 1103 with value: 4.776370605918505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.84 | sMAPE for Validation Set is: 17.04% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.61 | sMAPE for Test Set is: 16.68% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:11:02,339]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:11:11,825]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:11:14,812]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:11:14,823]\u001b[0m Trial 1109 finished with value: 5.058068977380155 and parameters: {'n_hidden': 3, 'learning_rate': 0.000898326711512498, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02894473675582361, 'dropout_rate_Layer_2': 0.02895055108391347, 'dropout_rate_Layer_3': 0.04588672095477228, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0017602694255699784, 'l1_Layer_2': 0.0002664637226251846, 'l1_Layer_3': 0.005787157439526553, 'n_units_Layer_1': 280, 'n_units_Layer_2': 85, 'n_units_Layer_3': 145}. Best is trial 1103 with value: 4.776370605918505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.06 | sMAPE for Validation Set is: 17.89% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.62 | sMAPE for Test Set is: 16.77% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:11:23,112]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:11:28,079]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:11:33,159]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:11:35,150]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:11:40,802]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:11:46,542]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:11:50,450]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:11:55,629]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:11:58,850]\u001b[0m Trial 1119 finished with value: 4.85229422142136 and parameters: {'n_hidden': 3, 'learning_rate': 0.00095349851061367, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01050625830458295, 'dropout_rate_Layer_2': 0.06400876879723358, 'dropout_rate_Layer_3': 0.04787374062514205, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.7125604090236186e-05, 'l1_Layer_2': 0.00013217860057320512, 'l1_Layer_3': 6.6621719630581e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 150, 'n_units_Layer_3': 135}. Best is trial 1103 with value: 4.776370605918505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.85 | sMAPE for Validation Set is: 17.15% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.66 | sMAPE for Test Set is: 16.75% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:12:09,504]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:12:14,777]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:12:17,989]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:12:20,822]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:12:26,133]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:12:34,450]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:12:56,840]\u001b[0m Trial 1124 finished with value: 4.797336509178915 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009114510858058237, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08132341734340211, 'dropout_rate_Layer_2': 0.19662535786451554, 'dropout_rate_Layer_3': 0.07621017786301942, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001037544452332591, 'l1_Layer_2': 7.331773208619985e-05, 'l1_Layer_3': 3.691557257595784e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 180, 'n_units_Layer_3': 280}. Best is trial 1103 with value: 4.776370605918505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.80 | sMAPE for Validation Set is: 16.92% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 7.17 | sMAPE for Test Set is: 17.43% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:13:06,088]\u001b[0m Trial 1116 finished with value: 5.278021545038322 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016733296683533244, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04319333320065244, 'dropout_rate_Layer_2': 0.3001626663676553, 'dropout_rate_Layer_3': 0.018328362160921763, 'dropout_rate_Layer_4': 0.26113972962221216, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 2.9616915174792844e-05, 'l1_Layer_2': 0.009292177345868794, 'l1_Layer_3': 0.005773763266287574, 'l1_Layer_4': 8.529078608638684e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 285, 'n_units_Layer_3': 105, 'n_units_Layer_4': 270}. Best is trial 1103 with value: 4.776370605918505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.28 | sMAPE for Validation Set is: 18.45% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.53 | sMAPE for Test Set is: 23.21% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:13:08,924]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:13:23,683]\u001b[0m Trial 1137 finished with value: 4.895425855670214 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010090805172168137, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0006344400767135314, 'dropout_rate_Layer_2': 0.042950163142062917, 'dropout_rate_Layer_3': 0.040286147500606245, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.927225382323016e-05, 'l1_Layer_2': 1.597346283927193e-05, 'l1_Layer_3': 5.536076777114021e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 160, 'n_units_Layer_3': 125}. Best is trial 1103 with value: 4.776370605918505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.90 | sMAPE for Validation Set is: 17.09% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.61 | sMAPE for Test Set is: 16.54% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:13:28,138]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:13:33,144]\u001b[0m Trial 1138 finished with value: 4.845859807731457 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010196176063223025, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0010621675982091616, 'dropout_rate_Layer_2': 0.04269540576749603, 'dropout_rate_Layer_3': 0.038012439588159225, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.0019517324524767e-05, 'l1_Layer_2': 1.7136703713869142e-05, 'l1_Layer_3': 5.5868076775140174e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 160, 'n_units_Layer_3': 120}. Best is trial 1103 with value: 4.776370605918505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.85 | sMAPE for Validation Set is: 16.99% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.52 | sMAPE for Test Set is: 16.40% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:13:42,797]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:13:46,560]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:13:52,063]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:13:52,624]\u001b[0m Trial 1141 finished with value: 4.912402451213734 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010748806618729597, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.005514180248452604, 'dropout_rate_Layer_2': 0.05240196612029149, 'dropout_rate_Layer_3': 0.02536260492399555, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.7502002664902535e-05, 'l1_Layer_2': 1.608050367726948e-05, 'l1_Layer_3': 6.115247186999509e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 170, 'n_units_Layer_3': 125}. Best is trial 1103 with value: 4.776370605918505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.91 | sMAPE for Validation Set is: 17.21% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.66 | sMAPE for Test Set is: 16.64% | rMAE for Test Set is: 0.63\n",
      "MAE for Validation Set is: 5.24 | sMAPE for Validation Set is: 18.33% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 9.90 | sMAPE for Test Set is: 23.70% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:13:57,580]\u001b[0m Trial 1136 finished with value: 5.239617499483809 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012929254611714024, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05691711399799881, 'dropout_rate_Layer_2': 0.29232519841137955, 'dropout_rate_Layer_3': 0.049629481706147616, 'dropout_rate_Layer_4': 0.22830205604280132, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.004752040182223128, 'l1_Layer_2': 0.00635531452810339, 'l1_Layer_3': 0.005750836439560595, 'l1_Layer_4': 9.727828739458973e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 65, 'n_units_Layer_3': 285, 'n_units_Layer_4': 270}. Best is trial 1103 with value: 4.776370605918505.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:14:01,337]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:14:17,879]\u001b[0m Trial 1139 finished with value: 4.928976556647438 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006754487816588336, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0009905717973090443, 'dropout_rate_Layer_2': 0.01719661464100894, 'dropout_rate_Layer_3': 0.07318239567906101, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001119747295396589, 'l1_Layer_2': 0.0004900484797413702, 'l1_Layer_3': 0.0029496409172015668, 'n_units_Layer_1': 270, 'n_units_Layer_2': 50, 'n_units_Layer_3': 105}. Best is trial 1103 with value: 4.776370605918505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.93 | sMAPE for Validation Set is: 17.38% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.47 | sMAPE for Test Set is: 16.30% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:14:21,165]\u001b[0m Trial 1145 finished with value: 4.790945701216326 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010916459275423839, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007031596089926162, 'dropout_rate_Layer_2': 0.043442137241815226, 'dropout_rate_Layer_3': 0.014770921063689435, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.748855111964083e-05, 'l1_Layer_2': 1.3878339375597439e-05, 'l1_Layer_3': 8.668630980702101e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 175, 'n_units_Layer_3': 125}. Best is trial 1103 with value: 4.776370605918505.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:14:21,194]\u001b[0m Trial 1147 finished with value: 5.238871536875904 and parameters: {'n_hidden': 3, 'learning_rate': 0.016835417927663278, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01475112738856213, 'dropout_rate_Layer_2': 0.05775644491159821, 'dropout_rate_Layer_3': 0.07371623840319864, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011951174755083528, 'l1_Layer_2': 0.000528862742068916, 'l1_Layer_3': 0.003096267515868572, 'n_units_Layer_1': 270, 'n_units_Layer_2': 50, 'n_units_Layer_3': 105}. Best is trial 1103 with value: 4.776370605918505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.79 | sMAPE for Validation Set is: 16.72% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.56 | sMAPE for Test Set is: 16.49% | rMAE for Test Set is: 0.62\n",
      "MAE for Validation Set is: 5.24 | sMAPE for Validation Set is: 18.34% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.97 | sMAPE for Test Set is: 17.46% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:14:39,152]\u001b[0m Trial 1149 finished with value: 4.856828210571958 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008714356156469258, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008344351272610316, 'dropout_rate_Layer_2': 0.04110808948955119, 'dropout_rate_Layer_3': 0.02688194848204626, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.6074534958657598e-05, 'l1_Layer_2': 1.2623637102664574e-05, 'l1_Layer_3': 6.205019812827414e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 170, 'n_units_Layer_3': 130}. Best is trial 1103 with value: 4.776370605918505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.86 | sMAPE for Validation Set is: 17.05% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.52 | sMAPE for Test Set is: 16.50% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:14:43,922]\u001b[0m Trial 1151 finished with value: 4.870001715174782 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011293653925958443, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.001227192032707279, 'dropout_rate_Layer_2': 0.041392158050445466, 'dropout_rate_Layer_3': 0.01643747206367782, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.5747348094944413e-05, 'l1_Layer_2': 1.4709251081839538e-05, 'l1_Layer_3': 6.69018587623982e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 175, 'n_units_Layer_3': 125}. Best is trial 1103 with value: 4.776370605918505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.87 | sMAPE for Validation Set is: 16.97% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.55 | sMAPE for Test Set is: 16.39% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:14:52,250]\u001b[0m Trial 1148 finished with value: 4.966337796287261 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006706048046858611, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014866281746679682, 'dropout_rate_Layer_2': 0.05635627645365796, 'dropout_rate_Layer_3': 0.029052987071780126, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0024445096314110928, 'l1_Layer_2': 0.0005047344565727015, 'l1_Layer_3': 0.0030365710005701486, 'n_units_Layer_1': 265, 'n_units_Layer_2': 50, 'n_units_Layer_3': 105}. Best is trial 1103 with value: 4.776370605918505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.97 | sMAPE for Validation Set is: 17.62% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.61 | sMAPE for Test Set is: 16.69% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:14:55,054]\u001b[0m Trial 1150 finished with value: 4.788666743826281 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011933714836123075, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008953009667141302, 'dropout_rate_Layer_2': 0.04177688190153207, 'dropout_rate_Layer_3': 0.007415115162294532, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4977258873616864e-05, 'l1_Layer_2': 1.3987651188816401e-05, 'l1_Layer_3': 6.461271721331497e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 175, 'n_units_Layer_3': 120}. Best is trial 1103 with value: 4.776370605918505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.79 | sMAPE for Validation Set is: 16.96% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.56 | sMAPE for Test Set is: 16.29% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:14:58,840]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:15:05,817]\u001b[0m Trial 1152 finished with value: 4.818433571957759 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012392529085011178, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0007211851079155998, 'dropout_rate_Layer_2': 0.0438878847527322, 'dropout_rate_Layer_3': 0.010520875113099779, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3422241735968577e-05, 'l1_Layer_2': 1.190066190038693e-05, 'l1_Layer_3': 6.131309301300013e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 175, 'n_units_Layer_3': 125}. Best is trial 1103 with value: 4.776370605918505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.82 | sMAPE for Validation Set is: 16.99% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.35 | sMAPE for Test Set is: 16.04% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:15:07,049]\u001b[0m Trial 1153 finished with value: 4.858784547265987 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012110754240567101, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008669678093795367, 'dropout_rate_Layer_2': 0.04346552587057973, 'dropout_rate_Layer_3': 0.005037811371102978, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3882720298807885e-05, 'l1_Layer_2': 1.1181997157838927e-05, 'l1_Layer_3': 6.925708875207002e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 175, 'n_units_Layer_3': 120}. Best is trial 1103 with value: 4.776370605918505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.86 | sMAPE for Validation Set is: 16.97% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.50 | sMAPE for Test Set is: 16.39% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:15:13,282]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:15:27,408]\u001b[0m Trial 1156 finished with value: 4.799858008768111 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012003064537074327, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01194053400927228, 'dropout_rate_Layer_2': 0.04392611531644362, 'dropout_rate_Layer_3': 0.0033928936643934943, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2087229172106183e-05, 'l1_Layer_2': 1.1058590021393788e-05, 'l1_Layer_3': 6.47235071235605e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 175, 'n_units_Layer_3': 125}. Best is trial 1103 with value: 4.776370605918505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.80 | sMAPE for Validation Set is: 16.76% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.39 | sMAPE for Test Set is: 16.05% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:15:28,221]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:15:38,395]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:15:42,027]\u001b[0m Trial 1159 finished with value: 4.856471846602316 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013198037834537416, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0001382621723372765, 'dropout_rate_Layer_2': 0.043464347428184474, 'dropout_rate_Layer_3': 0.003993248779070056, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1786809248220696e-05, 'l1_Layer_2': 1.494705905690003e-05, 'l1_Layer_3': 7.281765299080173e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 175, 'n_units_Layer_3': 125}. Best is trial 1103 with value: 4.776370605918505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.86 | sMAPE for Validation Set is: 17.20% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.59 | sMAPE for Test Set is: 16.44% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:15:46,718]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:15:47,370]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:15:53,116]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:15:57,315]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:16:06,285]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:16:06,916]\u001b[0m Trial 1163 finished with value: 4.874567555420628 and parameters: {'n_hidden': 3, 'learning_rate': 0.001400006280499162, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.010724211986697306, 'dropout_rate_Layer_2': 0.04070691817340767, 'dropout_rate_Layer_3': 0.003030237764179121, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0351869490065633e-05, 'l1_Layer_2': 1.0229848179142735e-05, 'l1_Layer_3': 8.210809421050818e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 180, 'n_units_Layer_3': 115}. Best is trial 1103 with value: 4.776370605918505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.87 | sMAPE for Validation Set is: 17.26% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.66 | sMAPE for Test Set is: 16.58% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:16:14,668]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:16:15,037]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:16:21,307]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:16:21,811]\u001b[0m Trial 1155 finished with value: 4.952614713024965 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006411311939871267, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0005255636685053428, 'dropout_rate_Layer_2': 0.021631766392108596, 'dropout_rate_Layer_3': 0.029993455548230272, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0017351123841690592, 'l1_Layer_2': 0.0004218294097994335, 'l1_Layer_3': 0.004192595396149716, 'n_units_Layer_1': 280, 'n_units_Layer_2': 75, 'n_units_Layer_3': 100}. Best is trial 1103 with value: 4.776370605918505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.95 | sMAPE for Validation Set is: 17.42% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.49 | sMAPE for Test Set is: 16.37% | rMAE for Test Set is: 0.61\n",
      "MAE for Validation Set is: 4.91 | sMAPE for Validation Set is: 17.06% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.54 | sMAPE for Test Set is: 16.16% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:16:25,296]\u001b[0m Trial 1165 finished with value: 4.909647792675281 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013495750290601486, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.002371799073233428, 'dropout_rate_Layer_2': 0.041372664549330224, 'dropout_rate_Layer_3': 0.01411540957852744, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3428024770255136e-05, 'l1_Layer_2': 1.1974750619892396e-05, 'l1_Layer_3': 8.781505813537538e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 180, 'n_units_Layer_3': 130}. Best is trial 1103 with value: 4.776370605918505.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:16:32,628]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:16:38,294]\u001b[0m Trial 1171 finished with value: 4.902786520959106 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013367855156065196, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.013933300324770677, 'dropout_rate_Layer_2': 0.03653375400938545, 'dropout_rate_Layer_3': 0.0012920642205491092, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1822301580852776e-05, 'l1_Layer_2': 1.014826329638092e-05, 'l1_Layer_3': 0.00010407790569131668, 'n_units_Layer_1': 300, 'n_units_Layer_2': 180, 'n_units_Layer_3': 110}. Best is trial 1103 with value: 4.776370605918505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.90 | sMAPE for Validation Set is: 17.14% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.52 | sMAPE for Test Set is: 16.40% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:16:42,811]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:16:51,822]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:17:22,165]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:17:22,721]\u001b[0m Trial 1174 finished with value: 4.990755538025687 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006583318408399225, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.031009535579756775, 'dropout_rate_Layer_2': 0.0505670452096266, 'dropout_rate_Layer_3': 0.032165587269928145, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0015841413245796406, 'l1_Layer_2': 0.0006343632196370914, 'l1_Layer_3': 0.004221015131485928, 'n_units_Layer_1': 265, 'n_units_Layer_2': 75, 'n_units_Layer_3': 75}. Best is trial 1103 with value: 4.776370605918505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.99 | sMAPE for Validation Set is: 17.61% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.67 | sMAPE for Test Set is: 16.77% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:17:33,265]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:17:41,897]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:17:44,946]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:17:46,655]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:17:47,877]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:17:53,034]\u001b[0m Trial 1173 finished with value: 5.319037319712578 and parameters: {'n_hidden': 4, 'learning_rate': 0.0023908593966744597, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16333552260718945, 'dropout_rate_Layer_2': 0.31469562298301335, 'dropout_rate_Layer_3': 0.009150638517934488, 'dropout_rate_Layer_4': 0.3841630559499129, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0063137204146777245, 'l1_Layer_2': 0.011468186793309278, 'l1_Layer_3': 1.5104420151307322e-05, 'l1_Layer_4': 9.762663461204629e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 70, 'n_units_Layer_3': 95, 'n_units_Layer_4': 265}. Best is trial 1103 with value: 4.776370605918505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.32 | sMAPE for Validation Set is: 18.55% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.01 | sMAPE for Test Set is: 24.05% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:17:57,994]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:18:03,711]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:18:06,882]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:18:10,330]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:18:13,571]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:18:31,024]\u001b[0m Trial 1190 finished with value: 4.769812800572783 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012196858813779726, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00924104171877618, 'dropout_rate_Layer_2': 0.03626734814040334, 'dropout_rate_Layer_3': 0.007777956909509261, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4783813331533847e-05, 'l1_Layer_2': 1.4156208993633678e-05, 'l1_Layer_3': 0.00010657496104895296, 'n_units_Layer_1': 300, 'n_units_Layer_2': 175, 'n_units_Layer_3': 115}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.77 | sMAPE for Validation Set is: 16.76% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.46 | sMAPE for Test Set is: 16.37% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:18:50,957]\u001b[0m Trial 1187 finished with value: 5.012076656852175 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008858527625959325, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.023190635929609398, 'dropout_rate_Layer_2': 0.03433727704149474, 'dropout_rate_Layer_3': 0.05364451171066817, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007631520903152068, 'l1_Layer_2': 0.00037456433620226565, 'l1_Layer_3': 0.0032703792860127273, 'n_units_Layer_1': 280, 'n_units_Layer_2': 55, 'n_units_Layer_3': 95}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.01 | sMAPE for Validation Set is: 17.61% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.53 | sMAPE for Test Set is: 16.36% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:18:56,814]\u001b[0m Trial 1185 finished with value: 4.996744240356446 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008702949235022561, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06131162469000763, 'dropout_rate_Layer_2': 0.030472844500820946, 'dropout_rate_Layer_3': 0.053409712566390315, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007773200497011094, 'l1_Layer_2': 0.0009226644688553252, 'l1_Layer_3': 0.0033239465167948833, 'n_units_Layer_1': 275, 'n_units_Layer_2': 55, 'n_units_Layer_3': 65}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.00 | sMAPE for Validation Set is: 17.56% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.69 | sMAPE for Test Set is: 16.54% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:18:59,906]\u001b[0m Trial 1191 finished with value: 5.027302908583283 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009023796466036179, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06141007161039367, 'dropout_rate_Layer_2': 0.028541655993007294, 'dropout_rate_Layer_3': 0.041325579409361095, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007822941626212898, 'l1_Layer_2': 0.0004033460203134206, 'l1_Layer_3': 0.0030867797817908933, 'n_units_Layer_1': 280, 'n_units_Layer_2': 55, 'n_units_Layer_3': 95}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.03 | sMAPE for Validation Set is: 17.72% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.67 | sMAPE for Test Set is: 16.72% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:19:04,588]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:19:09,744]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:19:15,285]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:19:22,849]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:19:26,744]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:19:26,945]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:19:32,982]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:19:41,236]\u001b[0m Trial 1197 finished with value: 4.8966337018693125 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011828828684663877, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00816971853421886, 'dropout_rate_Layer_2': 0.05647795736448753, 'dropout_rate_Layer_3': 7.026512587949771e-06, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.5243467692036164e-05, 'l1_Layer_2': 1.3906076478335233e-05, 'l1_Layer_3': 0.00011237537124311952, 'n_units_Layer_1': 300, 'n_units_Layer_2': 185, 'n_units_Layer_3': 115}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.90 | sMAPE for Validation Set is: 17.34% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.66 | sMAPE for Test Set is: 16.68% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:19:45,952]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:19:46,272]\u001b[0m Trial 1192 finished with value: 4.952182967539884 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009274016322392606, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.017316920529900273, 'dropout_rate_Layer_2': 0.029038774290395062, 'dropout_rate_Layer_3': 0.009452709855979978, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0010701094440876521, 'l1_Layer_2': 0.00038681148492587396, 'l1_Layer_3': 0.003123414201722475, 'n_units_Layer_1': 280, 'n_units_Layer_2': 55, 'n_units_Layer_3': 95}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.95 | sMAPE for Validation Set is: 17.40% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.57 | sMAPE for Test Set is: 16.52% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:19:49,888]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:19:54,097]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:19:58,332]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:20:02,167]\u001b[0m Trial 1204 finished with value: 6.4742773199428285 and parameters: {'n_hidden': 3, 'learning_rate': 0.04196816589035605, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01224617057955402, 'dropout_rate_Layer_2': 0.01569208476298982, 'dropout_rate_Layer_3': 0.026313910966121172, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0015085108233347363, 'l1_Layer_2': 0.0002650358455496766, 'l1_Layer_3': 0.0014176280300759246, 'n_units_Layer_1': 270, 'n_units_Layer_2': 65, 'n_units_Layer_3': 105}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.47 | sMAPE for Validation Set is: 23.45% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 8.55 | sMAPE for Test Set is: 21.79% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:20:02,562]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:20:21,630]\u001b[0m Trial 1209 finished with value: 4.870274997083556 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014572963444016644, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00034538644215630163, 'dropout_rate_Layer_2': 0.03276025566474702, 'dropout_rate_Layer_3': 0.017634239015757287, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.6892159595743553e-05, 'l1_Layer_2': 1.0386350856547234e-05, 'l1_Layer_3': 6.253576058728294e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 170, 'n_units_Layer_3': 105}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.87 | sMAPE for Validation Set is: 17.11% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.76 | sMAPE for Test Set is: 17.10% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:20:25,716]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:20:30,961]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:20:31,735]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:20:38,059]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:20:42,439]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:20:43,927]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:20:50,660]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:20:54,452]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:20:54,743]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:21:03,260]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:21:04,371]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:21:15,109]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:21:32,933]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:21:38,686]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:21:42,155]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:21:47,446]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:21:51,031]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:21:52,158]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:21:58,747]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:22:01,683]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:22:04,347]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:22:13,545]\u001b[0m Trial 1221 finished with value: 4.829758449297822 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005639810626668841, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.057102678012008586, 'dropout_rate_Layer_2': 0.06689098294141275, 'dropout_rate_Layer_3': 0.10215470066313871, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003885410367315805, 'l1_Layer_2': 3.2789588241932094e-05, 'l1_Layer_3': 3.5267673552681226e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 165, 'n_units_Layer_3': 295}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.83 | sMAPE for Validation Set is: 17.07% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 8.73 | sMAPE for Test Set is: 20.96% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:22:18,271]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:22:24,896]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:22:29,445]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:22:39,066]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:22:47,156]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:22:48,502]\u001b[0m Trial 1233 finished with value: 4.8142997138161965 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010942291231594288, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02751379529867123, 'dropout_rate_Layer_2': 0.04738654401987374, 'dropout_rate_Layer_3': 0.00671890136562097, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.77212805004364e-05, 'l1_Layer_2': 1.2261717157607085e-05, 'l1_Layer_3': 5.7683331238267795e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 170, 'n_units_Layer_3': 135}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.81 | sMAPE for Validation Set is: 16.81% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.39 | sMAPE for Test Set is: 15.92% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:22:51,825]\u001b[0m Trial 1234 finished with value: 4.857471678885744 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011165869154366054, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.030334568562321727, 'dropout_rate_Layer_2': 0.04801328165467644, 'dropout_rate_Layer_3': 0.008516690818710409, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.7001984513791917e-05, 'l1_Layer_2': 1.6082225231859818e-05, 'l1_Layer_3': 5.60225937824713e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 185, 'n_units_Layer_3': 110}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.86 | sMAPE for Validation Set is: 17.07% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.58 | sMAPE for Test Set is: 16.59% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:23:04,097]\u001b[0m Trial 1236 finished with value: 4.904608984455827 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011419097482765045, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02882891853283933, 'dropout_rate_Layer_2': 0.053152256971395376, 'dropout_rate_Layer_3': 0.005809847598228245, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1535079713175148e-05, 'l1_Layer_2': 1.5726378874486148e-05, 'l1_Layer_3': 0.00011837255674560373, 'n_units_Layer_1': 300, 'n_units_Layer_2': 185, 'n_units_Layer_3': 120}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.90 | sMAPE for Validation Set is: 17.13% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.45 | sMAPE for Test Set is: 16.19% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:23:08,023]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:23:14,103]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:23:19,397]\u001b[0m Trial 1239 finished with value: 4.87704005220787 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012038738946303117, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.029925317212919182, 'dropout_rate_Layer_2': 0.054195247773039246, 'dropout_rate_Layer_3': 0.021409583760664725, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.8965417793463463e-05, 'l1_Layer_2': 1.6141974830672128e-05, 'l1_Layer_3': 5.454323557710003e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 170, 'n_units_Layer_3': 135}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.88 | sMAPE for Validation Set is: 17.15% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.57 | sMAPE for Test Set is: 16.66% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:23:23,530]\u001b[0m Trial 1240 finished with value: 4.839797111626583 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011251927972115434, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.030992089598117827, 'dropout_rate_Layer_2': 0.054525996257860775, 'dropout_rate_Layer_3': 0.021086325647047214, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.8521535003180647e-05, 'l1_Layer_2': 1.6923728902759785e-05, 'l1_Layer_3': 5.719469068501984e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 170, 'n_units_Layer_3': 130}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.84 | sMAPE for Validation Set is: 17.04% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.51 | sMAPE for Test Set is: 16.37% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:23:27,864]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:23:32,057]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:23:36,405]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:23:37,417]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:23:41,599]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:23:42,679]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:23:50,797]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:24:01,033]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:24:15,121]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:24:19,531]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:24:24,535]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:24:31,605]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:24:35,418]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:24:43,892]\u001b[0m Trial 1248 finished with value: 5.029824772763312 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007013024434183076, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.000909385443408078, 'dropout_rate_Layer_2': 0.005388380198210547, 'dropout_rate_Layer_3': 0.07070175646425764, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0019755259140188898, 'l1_Layer_2': 0.0007915585839808756, 'l1_Layer_3': 0.009102234233161277, 'n_units_Layer_1': 295, 'n_units_Layer_2': 65, 'n_units_Layer_3': 120}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.03 | sMAPE for Validation Set is: 17.77% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.59 | sMAPE for Test Set is: 16.60% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:24:48,718]\u001b[0m Trial 1250 finished with value: 5.019703613450575 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007942715147888142, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.026407761911682544, 'dropout_rate_Layer_2': 0.008697851334394144, 'dropout_rate_Layer_3': 0.03601378800237617, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018179315881889633, 'l1_Layer_2': 0.0008056694246586972, 'l1_Layer_3': 0.008839493107633874, 'n_units_Layer_1': 285, 'n_units_Layer_2': 65, 'n_units_Layer_3': 120}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:24:48,789]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.02 | sMAPE for Validation Set is: 17.77% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.61 | sMAPE for Test Set is: 16.73% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:24:56,527]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:25:00,941]\u001b[0m Trial 1257 finished with value: 4.8903595572957 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012518605898712357, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.046862243965612504, 'dropout_rate_Layer_2': 0.04689972598957792, 'dropout_rate_Layer_3': 9.539700362900345e-05, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.6638164369586957e-05, 'l1_Layer_2': 1.337029033181799e-05, 'l1_Layer_3': 8.713698425182609e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 175, 'n_units_Layer_3': 130}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.89 | sMAPE for Validation Set is: 17.17% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.84 | sMAPE for Test Set is: 16.70% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:25:03,331]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:25:07,855]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:25:09,409]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:25:15,662]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:25:25,268]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:25:29,207]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:25:31,085]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:25:34,286]\u001b[0m Trial 1258 finished with value: 5.314351691384999 and parameters: {'n_hidden': 4, 'learning_rate': 0.00207713486126485, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06028875285883418, 'dropout_rate_Layer_2': 0.2849915679188402, 'dropout_rate_Layer_3': 0.014124848268935716, 'dropout_rate_Layer_4': 0.23047900274693603, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 3.433434149084533e-05, 'l1_Layer_2': 0.014190261417093132, 'l1_Layer_3': 0.009254016842974784, 'l1_Layer_4': 9.50037586577351e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 265, 'n_units_Layer_3': 105, 'n_units_Layer_4': 285}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.31 | sMAPE for Validation Set is: 18.51% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.16 | sMAPE for Test Set is: 24.70% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:25:38,104]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:25:42,557]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:25:47,154]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:25:50,094]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:25:50,702]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:25:58,862]\u001b[0m Trial 1263 finished with value: 5.136709865926032 and parameters: {'n_hidden': 4, 'learning_rate': 0.0020580440423993303, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05910591697668317, 'dropout_rate_Layer_2': 0.2587633448992804, 'dropout_rate_Layer_3': 0.011645939546349118, 'dropout_rate_Layer_4': 0.2841390183041508, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 3.445138271048146e-05, 'l1_Layer_2': 0.00044489164127938164, 'l1_Layer_3': 0.009885867937382482, 'l1_Layer_4': 1.9098071129098667e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 70, 'n_units_Layer_3': 130, 'n_units_Layer_4': 285}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.14 | sMAPE for Validation Set is: 18.02% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.91 | sMAPE for Test Set is: 26.30% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:26:05,184]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:26:07,452]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:26:12,420]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:26:16,719]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:26:22,766]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:26:28,401]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:26:34,248]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:26:41,410]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.18 | sMAPE for Validation Set is: 18.10% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.30 | sMAPE for Test Set is: 27.20% | rMAE for Test Set is: 1.07\n",
      "MAE for Validation Set is: 5.19 | sMAPE for Validation Set is: 18.12% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.63 | sMAPE for Test Set is: 25.62% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:26:44,767]\u001b[0m Trial 1278 finished with value: 5.178367094368687 and parameters: {'n_hidden': 4, 'learning_rate': 0.002212607823040816, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05980691046451023, 'dropout_rate_Layer_2': 0.2615005063284056, 'dropout_rate_Layer_3': 0.01746064778769137, 'dropout_rate_Layer_4': 0.23031947979862882, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 3.85049848229798e-05, 'l1_Layer_2': 0.00032205194370186655, 'l1_Layer_3': 0.007877003087918135, 'l1_Layer_4': 2.231733793944255e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 280, 'n_units_Layer_3': 125, 'n_units_Layer_4': 280}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:26:44,777]\u001b[0m Trial 1277 finished with value: 5.189467069727527 and parameters: {'n_hidden': 4, 'learning_rate': 0.001962672883629878, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.049349413269952735, 'dropout_rate_Layer_2': 0.28516129111696975, 'dropout_rate_Layer_3': 0.01935660114461521, 'dropout_rate_Layer_4': 0.2507101973328585, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 3.42716865102179e-05, 'l1_Layer_2': 0.00028586438842374666, 'l1_Layer_3': 0.009024877954245301, 'l1_Layer_4': 2.2366058014088253e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 290, 'n_units_Layer_3': 125, 'n_units_Layer_4': 280}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:26:59,070]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:27:05,052]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:27:10,298]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:27:13,514]\u001b[0m Trial 1276 finished with value: 4.876546059190339 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005577270443455839, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.022173207827679706, 'dropout_rate_Layer_2': 0.20537138825375859, 'dropout_rate_Layer_3': 0.09758766215199613, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003020370480663524, 'l1_Layer_2': 1.9685386504469152e-05, 'l1_Layer_3': 6.953556552252584e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 160, 'n_units_Layer_3': 270}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.88 | sMAPE for Validation Set is: 17.16% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 8.85 | sMAPE for Test Set is: 21.16% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:27:17,573]\u001b[0m Trial 1285 finished with value: 4.816624795624838 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010605232467009338, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01677760679777904, 'dropout_rate_Layer_2': 0.029872333283742118, 'dropout_rate_Layer_3': 0.007364507819200162, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4400018805022722e-05, 'l1_Layer_2': 1.1649256109865381e-05, 'l1_Layer_3': 5.748070873460039e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 185, 'n_units_Layer_3': 135}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.82 | sMAPE for Validation Set is: 16.97% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.43 | sMAPE for Test Set is: 16.20% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:27:18,154]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:27:23,213]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:27:27,334]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:27:27,860]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:27:33,590]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:27:38,900]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:27:45,060]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:27:49,199]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:28:26,859]\u001b[0m Trial 1293 finished with value: 4.820260830135874 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005030509074817274, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05009814776907378, 'dropout_rate_Layer_2': 0.07000299512041716, 'dropout_rate_Layer_3': 0.08418466058091426, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002185897540232716, 'l1_Layer_2': 0.00017066036673775827, 'l1_Layer_3': 4.09341637529505e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 165, 'n_units_Layer_3': 290}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.82 | sMAPE for Validation Set is: 17.07% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 8.95 | sMAPE for Test Set is: 21.53% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:28:34,492]\u001b[0m Trial 1295 finished with value: 4.855136667905823 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005993036942369066, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05208093675793889, 'dropout_rate_Layer_2': 0.07174117907429944, 'dropout_rate_Layer_3': 0.08447378798622371, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00021785143558930746, 'l1_Layer_2': 0.00014718873249463014, 'l1_Layer_3': 4.001886727933455e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 165, 'n_units_Layer_3': 290}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.86 | sMAPE for Validation Set is: 17.16% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 9.44 | sMAPE for Test Set is: 22.51% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:28:44,165]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:28:48,809]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.81 | sMAPE for Validation Set is: 17.04% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 8.97 | sMAPE for Test Set is: 21.52% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:28:50,804]\u001b[0m Trial 1296 finished with value: 4.814466447224997 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005035414984428303, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05220814134981472, 'dropout_rate_Layer_2': 0.07169468205611787, 'dropout_rate_Layer_3': 0.08256556337081086, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00021108376760716025, 'l1_Layer_2': 0.0001520853797791317, 'l1_Layer_3': 3.884636409330299e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 165, 'n_units_Layer_3': 290}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:28:58,259]\u001b[0m Trial 1300 finished with value: 4.815775370909737 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005005328728775225, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.049514375565974114, 'dropout_rate_Layer_2': 0.08464814558991669, 'dropout_rate_Layer_3': 0.08447507224838882, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022842516973716886, 'l1_Layer_2': 0.00016216505443467102, 'l1_Layer_3': 3.4319420914297145e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 165, 'n_units_Layer_3': 290}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.82 | sMAPE for Validation Set is: 16.98% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 8.85 | sMAPE for Test Set is: 21.17% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:29:04,912]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:29:05,307]\u001b[0m Trial 1302 finished with value: 4.841627745934706 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010819862106330525, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015200517960550115, 'dropout_rate_Layer_2': 0.03465470794005769, 'dropout_rate_Layer_3': 0.013689196975391501, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.8417012404170752e-05, 'l1_Layer_2': 1.0042934352962075e-05, 'l1_Layer_3': 5.817681296636152e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 180, 'n_units_Layer_3': 135}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.84 | sMAPE for Validation Set is: 16.96% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.54 | sMAPE for Test Set is: 16.57% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:29:30,326]\u001b[0m Trial 1305 finished with value: 4.787578881039966 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006151090397221482, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04817311365037172, 'dropout_rate_Layer_2': 0.055495308349776, 'dropout_rate_Layer_3': 0.06854155901345489, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00018842509605616854, 'l1_Layer_2': 0.00015393991418879806, 'l1_Layer_3': 4.276996689602341e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 180, 'n_units_Layer_3': 280}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.79 | sMAPE for Validation Set is: 16.88% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 8.64 | sMAPE for Test Set is: 20.70% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:29:30,783]\u001b[0m Trial 1307 finished with value: 4.8322817321787666 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012194692863669598, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03185254221225389, 'dropout_rate_Layer_2': 0.026062285606586782, 'dropout_rate_Layer_3': 0.00910849560218773, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4182202812417836e-05, 'l1_Layer_2': 1.1790420183320745e-05, 'l1_Layer_3': 7.49088469645958e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 180, 'n_units_Layer_3': 140}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.83 | sMAPE for Validation Set is: 17.16% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.54 | sMAPE for Test Set is: 16.24% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:29:31,785]\u001b[0m Trial 1308 finished with value: 4.912722262585608 and parameters: {'n_hidden': 3, 'learning_rate': 0.001180707515801858, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03845305147682378, 'dropout_rate_Layer_2': 0.026911961361427157, 'dropout_rate_Layer_3': 0.007643452273797124, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2547068643809158e-05, 'l1_Layer_2': 1.0178936925956698e-05, 'l1_Layer_3': 7.752759782067746e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 190, 'n_units_Layer_3': 140}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.91 | sMAPE for Validation Set is: 17.28% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.66 | sMAPE for Test Set is: 16.64% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:29:40,998]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:29:46,890]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:29:52,197]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:30:10,242]\u001b[0m Trial 1313 finished with value: 4.859763896218683 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013127832111554426, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.037231192116678496, 'dropout_rate_Layer_2': 0.032830321561281794, 'dropout_rate_Layer_3': 0.006889253434700029, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0002192159223838e-05, 'l1_Layer_2': 1.0030300817754823e-05, 'l1_Layer_3': 8.989585372937106e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 185, 'n_units_Layer_3': 140}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.86 | sMAPE for Validation Set is: 17.15% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.59 | sMAPE for Test Set is: 16.56% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:30:14,154]\u001b[0m Trial 1306 finished with value: 4.962965570503233 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005565857463261662, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.046802893613114814, 'dropout_rate_Layer_2': 0.013968633724466037, 'dropout_rate_Layer_3': 0.0013191704962952633, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009843271394454085, 'l1_Layer_2': 0.00047741747463690817, 'l1_Layer_3': 0.004659178247634521, 'n_units_Layer_1': 300, 'n_units_Layer_2': 50, 'n_units_Layer_3': 105}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.96 | sMAPE for Validation Set is: 17.47% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.53 | sMAPE for Test Set is: 16.53% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:30:15,746]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:30:23,066]\u001b[0m Trial 1310 finished with value: 4.829221865058612 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007664373790193856, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.060760520472647184, 'dropout_rate_Layer_2': 0.06919055906760194, 'dropout_rate_Layer_3': 0.06766986194137653, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000428120569213781, 'l1_Layer_2': 0.00016971866456319022, 'l1_Layer_3': 4.9044051707954304e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 180, 'n_units_Layer_3': 275}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.83 | sMAPE for Validation Set is: 16.97% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 8.70 | sMAPE for Test Set is: 20.76% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:30:34,871]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:30:34,966]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:30:44,283]\u001b[0m Trial 1316 finished with value: 4.931860922386165 and parameters: {'n_hidden': 3, 'learning_rate': 0.001587203351733702, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03217790595679368, 'dropout_rate_Layer_2': 0.03201188747517524, 'dropout_rate_Layer_3': 0.008028950281871637, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0331914744438399e-05, 'l1_Layer_2': 1.0142111202899896e-05, 'l1_Layer_3': 0.00014013025642791533, 'n_units_Layer_1': 275, 'n_units_Layer_2': 185, 'n_units_Layer_3': 140}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.93 | sMAPE for Validation Set is: 17.55% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 7.04 | sMAPE for Test Set is: 17.35% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:30:44,448]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:30:44,510]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:30:55,523]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:31:04,819]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:31:07,353]\u001b[0m Trial 1314 finished with value: 5.1176496436858985 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011212737624907703, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0007405389578227575, 'dropout_rate_Layer_2': 0.04805214258377337, 'dropout_rate_Layer_3': 0.056127130828796175, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002640695827786071, 'l1_Layer_2': 0.0003213012792217708, 'l1_Layer_3': 0.006577507862372146, 'n_units_Layer_1': 285, 'n_units_Layer_2': 70, 'n_units_Layer_3': 110}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.12 | sMAPE for Validation Set is: 18.15% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.58 | sMAPE for Test Set is: 16.61% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:31:11,950]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:31:13,460]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:31:19,072]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:31:27,827]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:31:28,479]\u001b[0m Trial 1323 finished with value: 4.803451120909894 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013701664155080025, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04059846566145734, 'dropout_rate_Layer_2': 0.03507322702596423, 'dropout_rate_Layer_3': 0.0002728038435289345, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.221623274192629e-05, 'l1_Layer_2': 1.2225831717394491e-05, 'l1_Layer_3': 9.543019168388892e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 195, 'n_units_Layer_3': 130}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.80 | sMAPE for Validation Set is: 16.98% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.63 | sMAPE for Test Set is: 16.69% | rMAE for Test Set is: 0.63\n",
      "MAE for Validation Set is: 4.88 | sMAPE for Validation Set is: 17.13% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.53 | sMAPE for Test Set is: 16.10% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:31:32,803]\u001b[0m Trial 1321 finished with value: 4.879904348251568 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013113833330235757, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03651599466214515, 'dropout_rate_Layer_2': 0.03449653241945421, 'dropout_rate_Layer_3': 0.015573438620300412, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1489291196068036e-05, 'l1_Layer_2': 1.1955847337996614e-05, 'l1_Layer_3': 0.0001262328419389519, 'n_units_Layer_1': 285, 'n_units_Layer_2': 195, 'n_units_Layer_3': 145}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:31:39,545]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:31:44,026]\u001b[0m Trial 1328 finished with value: 4.832173699880127 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017159847165182831, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02974198108232686, 'dropout_rate_Layer_2': 0.03507120485008645, 'dropout_rate_Layer_3': 0.01897171741513507, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.6045003122139476e-05, 'l1_Layer_2': 1.5093668317925843e-05, 'l1_Layer_3': 7.834385943594634e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 190, 'n_units_Layer_3': 125}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:31:44,123]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.83 | sMAPE for Validation Set is: 16.98% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.63 | sMAPE for Test Set is: 16.52% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:31:51,637]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:31:51,850]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:31:59,324]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:32:00,270]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:32:06,878]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:32:07,437]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:32:15,526]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:32:23,817]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:32:28,861]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:32:31,086]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:32:35,386]\u001b[0m Trial 1330 finished with value: 4.969450863247921 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009331151216428364, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04847430040961233, 'dropout_rate_Layer_2': 0.015723707167555785, 'dropout_rate_Layer_3': 0.034893668462096544, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000440307208655889, 'l1_Layer_2': 0.0004135505611399725, 'l1_Layer_3': 0.00478890473216801, 'n_units_Layer_1': 270, 'n_units_Layer_2': 55, 'n_units_Layer_3': 105}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.97 | sMAPE for Validation Set is: 17.48% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.61 | sMAPE for Test Set is: 16.59% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:32:36,870]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:32:40,196]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:32:45,752]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:32:46,448]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:32:54,300]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:33:00,944]\u001b[0m Trial 1339 finished with value: 4.899025387134633 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007566620043064146, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04567391990213884, 'dropout_rate_Layer_2': 0.03069077976328033, 'dropout_rate_Layer_3': 0.04131316302900365, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015877500506953138, 'l1_Layer_2': 0.0001102667304452477, 'l1_Layer_3': 4.8609496352861835e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 195, 'n_units_Layer_3': 280}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.90 | sMAPE for Validation Set is: 17.34% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 9.55 | sMAPE for Test Set is: 22.90% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:33:04,285]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:33:14,099]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:33:30,409]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:33:34,642]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:33:42,010]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:33:47,839]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:33:49,089]\u001b[0m Trial 1347 finished with value: 4.897832235015749 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007939771576143817, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04500485402315023, 'dropout_rate_Layer_2': 0.0700800159419943, 'dropout_rate_Layer_3': 0.04883806609560476, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00016239757195944947, 'l1_Layer_2': 0.00011295331114036944, 'l1_Layer_3': 5.084168005841296e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 200, 'n_units_Layer_3': 280}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.90 | sMAPE for Validation Set is: 17.28% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 9.38 | sMAPE for Test Set is: 22.41% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:34:07,524]\u001b[0m Trial 1358 finished with value: 4.901703796026555 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011500903237969264, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.011335999940215637, 'dropout_rate_Layer_2': 0.04295107953368831, 'dropout_rate_Layer_3': 0.00915474677455625, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3521183105077084e-05, 'l1_Layer_2': 1.4316240566706627e-05, 'l1_Layer_3': 6.041887089406898e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 190, 'n_units_Layer_3': 115}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.90 | sMAPE for Validation Set is: 17.19% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.57 | sMAPE for Test Set is: 16.47% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:34:12,688]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:34:19,238]\u001b[0m Trial 1351 finished with value: 4.9174112072840925 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005792758374832729, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28011742741067147, 'dropout_rate_Layer_2': 0.01842780659666364, 'dropout_rate_Layer_3': 0.019118670160264747, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006481822028172781, 'l1_Layer_2': 0.00029450675945621123, 'l1_Layer_3': 0.004898036156416733, 'n_units_Layer_1': 275, 'n_units_Layer_2': 50, 'n_units_Layer_3': 100}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.92 | sMAPE for Validation Set is: 17.33% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.44 | sMAPE for Test Set is: 16.14% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:34:29,414]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:34:29,588]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:34:39,029]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:34:44,071]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:34:44,291]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:34:56,341]\u001b[0m Trial 1361 finished with value: 4.81640557076463 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010828994707973605, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.019835275684410486, 'dropout_rate_Layer_2': 0.0315773369943088, 'dropout_rate_Layer_3': 0.0199750074771348, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.5134246591377459e-05, 'l1_Layer_2': 1.5977563733196008e-05, 'l1_Layer_3': 8.720146126719684e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 175, 'n_units_Layer_3': 140}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.82 | sMAPE for Validation Set is: 16.95% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.79 | sMAPE for Test Set is: 16.64% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:35:01,624]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:35:05,709]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:35:09,779]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:35:14,164]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:35:14,470]\u001b[0m Trial 1367 finished with value: 4.8706484316490615 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011018879606846707, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0071242062303395835, 'dropout_rate_Layer_2': 0.03014917844817288, 'dropout_rate_Layer_3': 0.02271318257492354, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.2194968519655027e-05, 'l1_Layer_2': 1.5552591392810932e-05, 'l1_Layer_3': 5.6403290277138056e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 185, 'n_units_Layer_3': 125}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.87 | sMAPE for Validation Set is: 17.14% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.54 | sMAPE for Test Set is: 16.39% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:35:19,480]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:35:22,499]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:35:23,487]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:35:30,953]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:35:34,566]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:35:37,313]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:35:41,568]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:35:46,631]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:35:47,131]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:35:56,697]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:36:26,910]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:36:38,228]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:36:43,620]\u001b[0m Trial 1382 finished with value: 4.839373137575732 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006081380178650018, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.053498890656276665, 'dropout_rate_Layer_2': 0.0862925062324957, 'dropout_rate_Layer_3': 0.06260016589778371, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00040733064890888113, 'l1_Layer_2': 0.00014334641385460185, 'l1_Layer_3': 3.039289505825767e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 170, 'n_units_Layer_3': 295}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.84 | sMAPE for Validation Set is: 17.08% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 8.54 | sMAPE for Test Set is: 20.42% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:36:44,035]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:36:45,488]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:36:53,053]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:36:59,038]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:37:04,986]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:37:09,120]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:37:11,747]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:37:16,207]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:37:16,586]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:37:23,514]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:37:28,074]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:37:30,566]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:37:33,059]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:37:42,210]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:37:49,266]\u001b[0m Trial 1395 finished with value: 4.793225960533658 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010454631358516836, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.027462485376302775, 'dropout_rate_Layer_2': 0.009451017485100355, 'dropout_rate_Layer_3': 0.007208681661625755, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.867397944889006e-05, 'l1_Layer_2': 1.3963707976192304e-05, 'l1_Layer_3': 6.975056322265813e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 160, 'n_units_Layer_3': 145}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.79 | sMAPE for Validation Set is: 16.82% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.39 | sMAPE for Test Set is: 16.07% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:37:56,428]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:38:00,667]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:38:04,929]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:38:28,721]\u001b[0m Trial 1398 finished with value: 5.092423682347135 and parameters: {'n_hidden': 4, 'learning_rate': 0.002092200213323427, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17969552488134014, 'dropout_rate_Layer_2': 0.28287156325566337, 'dropout_rate_Layer_3': 0.040220753207450076, 'dropout_rate_Layer_4': 0.27108435329858993, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.4827892911106594e-05, 'l1_Layer_2': 0.009448650046641664, 'l1_Layer_3': 0.003918155631905731, 'l1_Layer_4': 0.0001192857392887176, 'n_units_Layer_1': 200, 'n_units_Layer_2': 55, 'n_units_Layer_3': 100, 'n_units_Layer_4': 295}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.09 | sMAPE for Validation Set is: 17.86% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 8.54 | sMAPE for Test Set is: 20.60% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:38:32,482]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:38:33,776]\u001b[0m Trial 1399 finished with value: 4.79635143923582 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005971234693666861, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04865788208719404, 'dropout_rate_Layer_2': 0.07742462490497667, 'dropout_rate_Layer_3': 0.07397264953676438, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003474330202650012, 'l1_Layer_2': 0.00020664919778083673, 'l1_Layer_3': 2.351299621257628e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 180, 'n_units_Layer_3': 290}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.80 | sMAPE for Validation Set is: 16.95% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 8.54 | sMAPE for Test Set is: 20.52% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:38:33,936]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:38:42,715]\u001b[0m Trial 1400 finished with value: 4.7968284336911795 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005889013111200108, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08310485447568561, 'dropout_rate_Layer_2': 0.07679561717124808, 'dropout_rate_Layer_3': 0.06895542385601748, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005147164465096763, 'l1_Layer_2': 8.447750383373863e-05, 'l1_Layer_3': 2.3572653277065765e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 180, 'n_units_Layer_3': 290}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.80 | sMAPE for Validation Set is: 16.97% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 8.38 | sMAPE for Test Set is: 20.17% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:38:47,230]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:38:51,688]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:38:51,894]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:38:52,516]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:39:01,246]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:39:05,625]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:39:10,273]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:39:18,141]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:39:40,057]\u001b[0m Trial 1411 finished with value: 4.960321324548409 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009407236222110088, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27083279151262113, 'dropout_rate_Layer_2': 0.03219182218438682, 'dropout_rate_Layer_3': 0.0003359698492543684, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0010205377018750535, 'l1_Layer_2': 0.0002132205553430926, 'l1_Layer_3': 0.004600060996917612, 'n_units_Layer_1': 265, 'n_units_Layer_2': 60, 'n_units_Layer_3': 120}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.96 | sMAPE for Validation Set is: 17.51% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.41 | sMAPE for Test Set is: 16.12% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:39:43,814]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.14 | sMAPE for Validation Set is: 17.97% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.54 | sMAPE for Test Set is: 25.07% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:39:43,982]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:39:44,074]\u001b[0m Trial 1406 finished with value: 5.137680867112327 and parameters: {'n_hidden': 4, 'learning_rate': 0.0026539622573361725, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18825889135904125, 'dropout_rate_Layer_2': 0.2697087014493617, 'dropout_rate_Layer_3': 0.0379177016833019, 'dropout_rate_Layer_4': 0.2675537507992678, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.7764016288609165e-05, 'l1_Layer_2': 0.00818410481349159, 'l1_Layer_3': 0.004047343488188685, 'l1_Layer_4': 0.00011790199974311331, 'n_units_Layer_1': 205, 'n_units_Layer_2': 70, 'n_units_Layer_3': 145, 'n_units_Layer_4': 300}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:39:56,941]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:39:57,894]\u001b[0m Trial 1413 finished with value: 5.18056033577444 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017634948571268441, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1808307468943335, 'dropout_rate_Layer_2': 0.2747959273920211, 'dropout_rate_Layer_3': 0.014292347427398069, 'dropout_rate_Layer_4': 0.25528532651293734, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.441124090626143e-05, 'l1_Layer_2': 0.0002617056067025756, 'l1_Layer_3': 0.005903007488144381, 'l1_Layer_4': 0.00011293922963187035, 'n_units_Layer_1': 155, 'n_units_Layer_2': 60, 'n_units_Layer_3': 145, 'n_units_Layer_4': 295}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.18 | sMAPE for Validation Set is: 18.03% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.23 | sMAPE for Test Set is: 26.75% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:40:04,191]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:40:04,423]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:40:05,149]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:40:14,979]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:40:15,542]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:40:16,405]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:40:25,620]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:40:26,085]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:40:26,919]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:40:33,681]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:40:38,606]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:40:43,132]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:40:44,407]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:40:46,795]\u001b[0m Trial 1419 finished with value: 5.071076880669017 and parameters: {'n_hidden': 4, 'learning_rate': 0.002650709220138051, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19872272819447595, 'dropout_rate_Layer_2': 0.2727728128823505, 'dropout_rate_Layer_3': 0.035733465135178576, 'dropout_rate_Layer_4': 0.2663714423600604, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.938946469985551e-05, 'l1_Layer_2': 0.007046648816881282, 'l1_Layer_3': 0.003656964330700009, 'l1_Layer_4': 0.000133119014130211, 'n_units_Layer_1': 210, 'n_units_Layer_2': 70, 'n_units_Layer_3': 155, 'n_units_Layer_4': 300}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.07 | sMAPE for Validation Set is: 17.69% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 9.94 | sMAPE for Test Set is: 23.68% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:40:48,688]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:40:55,415]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:40:58,648]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:41:03,483]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:41:09,840]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:41:16,939]\u001b[0m Trial 1439 finished with value: 4.812641758090735 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011063469406889979, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02006244009929263, 'dropout_rate_Layer_2': 0.0417555224412349, 'dropout_rate_Layer_3': 0.01067290956860144, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.6837589277544273e-05, 'l1_Layer_2': 1.1688045541826827e-05, 'l1_Layer_3': 7.417310006516542e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 170, 'n_units_Layer_3': 125}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.81 | sMAPE for Validation Set is: 16.86% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.45 | sMAPE for Test Set is: 16.19% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:41:20,536]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:41:25,976]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:41:34,063]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:41:36,738]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:41:37,186]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:41:44,083]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:41:48,511]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:41:48,591]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:41:55,207]\u001b[0m Trial 1442 finished with value: 5.140839879782506 and parameters: {'n_hidden': 4, 'learning_rate': 0.003365461190802848, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2014971030018878, 'dropout_rate_Layer_2': 0.2663202711601877, 'dropout_rate_Layer_3': 0.04763282982560169, 'dropout_rate_Layer_4': 0.26540379121695723, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 6.753936607482603e-05, 'l1_Layer_2': 0.006708333646987452, 'l1_Layer_3': 0.003692588862352873, 'l1_Layer_4': 0.0001715483824402037, 'n_units_Layer_1': 215, 'n_units_Layer_2': 60, 'n_units_Layer_3': 150, 'n_units_Layer_4': 300}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.14 | sMAPE for Validation Set is: 18.01% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.89 | sMAPE for Test Set is: 26.08% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:41:59,870]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:42:04,996]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:42:09,221]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:42:13,315]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:42:14,775]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:42:18,734]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:42:24,112]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:42:25,827]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:42:31,570]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:42:32,574]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:42:38,104]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:42:39,231]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:42:41,778]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:42:45,862]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:42:49,153]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:42:50,426]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:42:52,455]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:42:52,864]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:43:04,331]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:43:08,576]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:43:12,879]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:43:13,950]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:43:16,908]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:43:18,467]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:43:24,155]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:43:31,888]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:43:35,421]\u001b[0m Trial 1470 finished with value: 4.809412399569953 and parameters: {'n_hidden': 3, 'learning_rate': 0.000984928496370822, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00814305393916083, 'dropout_rate_Layer_2': 0.010888139772779859, 'dropout_rate_Layer_3': 0.007263479516702817, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4678054039513001e-05, 'l1_Layer_2': 1.144156069756458e-05, 'l1_Layer_3': 0.00012672937995385157, 'n_units_Layer_1': 300, 'n_units_Layer_2': 170, 'n_units_Layer_3': 120}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.81 | sMAPE for Validation Set is: 16.99% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.44 | sMAPE for Test Set is: 16.21% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:43:36,455]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:43:47,554]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:43:51,973]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:43:52,667]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:44:00,582]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:44:04,783]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:44:09,519]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:44:13,520]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:44:13,854]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:44:20,749]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:44:21,006]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:44:26,722]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:44:32,096]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.16 | sMAPE for Validation Set is: 18.05% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.16 | sMAPE for Test Set is: 24.16% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:44:34,847]\u001b[0m Trial 1482 finished with value: 5.156860159459339 and parameters: {'n_hidden': 4, 'learning_rate': 0.0033747846819900014, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20228728762627057, 'dropout_rate_Layer_2': 0.24862539113443854, 'dropout_rate_Layer_3': 0.05467453845028186, 'dropout_rate_Layer_4': 0.24116795676458094, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.735553249498031e-05, 'l1_Layer_2': 0.008475152688970353, 'l1_Layer_3': 0.004886476335977669, 'l1_Layer_4': 2.437088539877515e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 60, 'n_units_Layer_3': 150, 'n_units_Layer_4': 295}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:44:41,952]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:44:42,849]\u001b[0m Trial 1480 finished with value: 4.928311624889656 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012192818189802645, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29236146528635537, 'dropout_rate_Layer_2': 0.025311612942363993, 'dropout_rate_Layer_3': 0.01809791528952806, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006833862328647051, 'l1_Layer_2': 0.0004959064826910302, 'l1_Layer_3': 1.1086432883482102e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 75, 'n_units_Layer_3': 95}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.93 | sMAPE for Validation Set is: 17.28% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.67 | sMAPE for Test Set is: 16.47% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:44:52,463]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:44:56,613]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:45:04,106]\u001b[0m Trial 1490 finished with value: 5.10820500433778 and parameters: {'n_hidden': 4, 'learning_rate': 0.0022947649695682242, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19274969585903112, 'dropout_rate_Layer_2': 0.275889611093891, 'dropout_rate_Layer_3': 0.056336711855839355, 'dropout_rate_Layer_4': 0.24202112073707865, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 6.130380810704041e-05, 'l1_Layer_2': 0.005017589046672261, 'l1_Layer_3': 0.00466172907626049, 'l1_Layer_4': 2.3630545135993484e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 60, 'n_units_Layer_3': 150, 'n_units_Layer_4': 295}. Best is trial 1190 with value: 4.769812800572783.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:45:04,196]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.11 | sMAPE for Validation Set is: 17.80% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 9.25 | sMAPE for Test Set is: 22.56% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 19:45:04,596]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:45:14,080]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:45:14,205]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 19:45:29,180]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-01-01, MAE is:3.45 & sMAPE is:15.78% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :3.45 & 15.78% & 0.26\n",
      "for 2018-01-02, MAE is:3.88 & sMAPE is:13.05% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :3.67 & 14.41% & 0.22\n",
      "for 2018-01-03, MAE is:7.52 & sMAPE is:48.88% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :4.95 & 25.90% & 0.49\n",
      "for 2018-01-04, MAE is:8.11 & sMAPE is:24.65% & rMAE is:2.09 ||| daily mean of MAE & sMAPE & rMAE till now are :5.74 & 25.59% & 0.89\n",
      "for 2018-01-05, MAE is:5.03 & sMAPE is:12.48% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :5.60 & 22.97% & 0.81\n",
      "for 2018-01-06, MAE is:3.06 & sMAPE is:8.85% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :5.18 & 20.61% & 0.73\n",
      "for 2018-01-07, MAE is:1.28 & sMAPE is:4.62% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :4.62 & 18.33% & 0.72\n",
      "for 2018-01-08, MAE is:3.94 & sMAPE is:11.18% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :4.53 & 17.44% & 0.67\n",
      "for 2018-01-09, MAE is:4.62 & sMAPE is:22.50% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :4.54 & 18.00% & 0.67\n",
      "for 2018-01-10, MAE is:5.88 & sMAPE is:17.23% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 17.92% & 0.64\n",
      "for 2018-01-11, MAE is:4.29 & sMAPE is:9.66% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.64 & 17.17% & 0.62\n",
      "for 2018-01-12, MAE is:3.49 & sMAPE is:10.11% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :4.55 & 16.58% & 0.61\n",
      "for 2018-01-13, MAE is:2.42 & sMAPE is:8.14% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.38 & 15.93% & 0.61\n",
      "for 2018-01-14, MAE is:1.59 & sMAPE is:5.38% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :4.18 & 15.18% & 0.64\n",
      "for 2018-01-15, MAE is:7.43 & sMAPE is:29.20% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :4.40 & 16.11% & 0.66\n",
      "for 2018-01-16, MAE is:8.28 & sMAPE is:57.48% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :4.64 & 18.70% & 0.69\n",
      "for 2018-01-17, MAE is:4.33 & sMAPE is:15.11% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :4.62 & 18.49% & 0.69\n",
      "for 2018-01-18, MAE is:1.81 & sMAPE is:5.01% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :4.47 & 17.74% & 0.66\n",
      "for 2018-01-19, MAE is:3.21 & sMAPE is:8.48% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :4.40 & 17.25% & 0.67\n",
      "for 2018-01-20, MAE is:3.91 & sMAPE is:10.34% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.38 & 16.91% & 0.67\n",
      "for 2018-01-21, MAE is:2.08 & sMAPE is:5.91% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :4.27 & 16.38% & 0.66\n",
      "for 2018-01-22, MAE is:4.81 & sMAPE is:13.58% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :4.29 & 16.26% & 0.64\n",
      "for 2018-01-23, MAE is:9.58 & sMAPE is:25.70% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :4.52 & 16.67% & 0.65\n",
      "for 2018-01-24, MAE is:3.77 & sMAPE is:18.35% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :4.49 & 16.74% & 0.64\n",
      "for 2018-01-25, MAE is:6.08 & sMAPE is:33.18% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :4.55 & 17.39% & 0.63\n",
      "for 2018-01-26, MAE is:10.93 & sMAPE is:30.67% & rMAE is:3.77 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 17.90% & 0.75\n",
      "for 2018-01-27, MAE is:4.47 & sMAPE is:20.26% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :4.79 & 17.99% & 0.75\n",
      "for 2018-01-28, MAE is:10.24 & sMAPE is:94.01% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :4.98 & 20.71% & 0.74\n",
      "for 2018-01-29, MAE is:7.13 & sMAPE is:48.77% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :5.06 & 21.67% & 0.72\n",
      "for 2018-01-30, MAE is:5.05 & sMAPE is:25.67% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :5.06 & 21.81% & 0.72\n",
      "for 2018-01-31, MAE is:5.45 & sMAPE is:17.36% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :5.07 & 21.66% & 0.72\n",
      "for 2018-02-01, MAE is:3.18 & sMAPE is:9.81% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :5.01 & 21.29% & 0.72\n",
      "for 2018-02-02, MAE is:4.04 & sMAPE is:11.23% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :4.98 & 20.99% & 0.73\n",
      "for 2018-02-03, MAE is:4.18 & sMAPE is:12.72% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :4.96 & 20.75% & 0.73\n",
      "for 2018-02-04, MAE is:2.67 & sMAPE is:8.23% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :4.89 & 20.39% & 0.71\n",
      "for 2018-02-05, MAE is:14.10 & sMAPE is:27.83% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :5.15 & 20.59% & 0.70\n",
      "for 2018-02-06, MAE is:3.51 & sMAPE is:7.15% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :5.10 & 20.23% & 0.69\n",
      "for 2018-02-07, MAE is:4.31 & sMAPE is:9.38% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :5.08 & 19.95% & 0.68\n",
      "for 2018-02-08, MAE is:5.91 & sMAPE is:12.09% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :5.10 & 19.74% & 0.67\n",
      "for 2018-02-09, MAE is:3.04 & sMAPE is:7.75% & rMAE is:2.02 ||| daily mean of MAE & sMAPE & rMAE till now are :5.05 & 19.44% & 0.70\n",
      "for 2018-02-10, MAE is:2.78 & sMAPE is:8.12% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :5.00 & 19.17% & 0.73\n",
      "for 2018-02-11, MAE is:8.01 & sMAPE is:42.03% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :5.07 & 19.71% & 0.72\n",
      "for 2018-02-12, MAE is:9.34 & sMAPE is:42.17% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :5.17 & 20.23% & 0.72\n",
      "for 2018-02-13, MAE is:5.34 & sMAPE is:15.18% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :5.17 & 20.12% & 0.71\n",
      "for 2018-02-14, MAE is:3.14 & sMAPE is:7.77% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :5.13 & 19.85% & 0.71\n",
      "for 2018-02-15, MAE is:3.56 & sMAPE is:12.88% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :5.09 & 19.69% & 0.70\n",
      "for 2018-02-16, MAE is:4.79 & sMAPE is:13.80% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :5.09 & 19.57% & 0.72\n",
      "for 2018-02-17, MAE is:6.40 & sMAPE is:17.93% & rMAE is:1.86 ||| daily mean of MAE & sMAPE & rMAE till now are :5.11 & 19.53% & 0.74\n",
      "for 2018-02-18, MAE is:3.69 & sMAPE is:10.60% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :5.08 & 19.35% & 0.73\n",
      "for 2018-02-19, MAE is:9.03 & sMAPE is:20.39% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :5.16 & 19.37% & 0.73\n",
      "for 2018-02-20, MAE is:6.31 & sMAPE is:13.49% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :5.19 & 19.26% & 0.73\n",
      "for 2018-02-21, MAE is:4.51 & sMAPE is:9.14% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :5.17 & 19.06% & 0.72\n",
      "for 2018-02-22, MAE is:6.39 & sMAPE is:14.23% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.20 & 18.97% & 0.72\n",
      "for 2018-02-23, MAE is:4.00 & sMAPE is:8.94% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :5.17 & 18.79% & 0.71\n",
      "for 2018-02-24, MAE is:1.71 & sMAPE is:4.73% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :5.11 & 18.53% & 0.71\n",
      "for 2018-02-25, MAE is:2.66 & sMAPE is:7.39% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :5.07 & 18.33% & 0.72\n",
      "for 2018-02-26, MAE is:6.33 & sMAPE is:13.48% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :5.09 & 18.25% & 0.73\n",
      "for 2018-02-27, MAE is:6.49 & sMAPE is:12.60% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :5.11 & 18.15% & 0.73\n",
      "for 2018-02-28, MAE is:6.42 & sMAPE is:12.84% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :5.14 & 18.06% & 0.75\n",
      "for 2018-03-01, MAE is:49.58 & sMAPE is:51.62% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 18.62% & 0.75\n",
      "for 2018-03-02, MAE is:11.03 & sMAPE is:16.81% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :5.96 & 18.59% & 0.75\n",
      "for 2018-03-03, MAE is:7.06 & sMAPE is:17.48% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :5.98 & 18.57% & 0.76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-03-04, MAE is:2.40 & sMAPE is:6.03% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :5.92 & 18.37% & 0.76\n",
      "for 2018-03-05, MAE is:8.08 & sMAPE is:14.75% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :5.95 & 18.31% & 0.77\n",
      "for 2018-03-06, MAE is:3.68 & sMAPE is:7.13% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :5.92 & 18.14% & 0.77\n",
      "for 2018-03-07, MAE is:4.60 & sMAPE is:10.53% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :5.90 & 18.03% & 0.77\n",
      "for 2018-03-08, MAE is:6.21 & sMAPE is:13.59% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :5.90 & 17.96% & 0.76\n",
      "for 2018-03-09, MAE is:5.25 & sMAPE is:14.03% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :5.89 & 17.90% & 0.75\n",
      "for 2018-03-10, MAE is:1.66 & sMAPE is:4.38% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :5.83 & 17.71% & 0.75\n",
      "for 2018-03-11, MAE is:2.04 & sMAPE is:6.17% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :5.78 & 17.54% & 0.74\n",
      "for 2018-03-12, MAE is:6.87 & sMAPE is:17.82% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :5.79 & 17.55% & 0.74\n",
      "for 2018-03-13, MAE is:1.88 & sMAPE is:4.36% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :5.74 & 17.36% & 0.73\n",
      "for 2018-03-14, MAE is:5.50 & sMAPE is:11.03% & rMAE is:3.30 ||| daily mean of MAE & sMAPE & rMAE till now are :5.74 & 17.28% & 0.77\n",
      "for 2018-03-15, MAE is:9.82 & sMAPE is:26.72% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :5.79 & 17.40% & 0.77\n",
      "for 2018-03-16, MAE is:6.49 & sMAPE is:24.30% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :5.80 & 17.50% & 0.77\n",
      "for 2018-03-17, MAE is:24.01 & sMAPE is:118.29% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 18.82% & 0.77\n",
      "for 2018-03-18, MAE is:14.64 & sMAPE is:78.85% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.15 & 19.60% & 0.78\n",
      "for 2018-03-19, MAE is:5.83 & sMAPE is:14.65% & rMAE is:2.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.15 & 19.54% & 0.80\n",
      "for 2018-03-20, MAE is:4.09 & sMAPE is:9.08% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.12 & 19.41% & 0.81\n",
      "for 2018-03-21, MAE is:7.95 & sMAPE is:16.09% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.15 & 19.36% & 0.82\n",
      "for 2018-03-22, MAE is:9.29 & sMAPE is:19.99% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.18 & 19.37% & 0.82\n",
      "for 2018-03-23, MAE is:7.14 & sMAPE is:15.05% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :6.20 & 19.32% & 0.81\n",
      "for 2018-03-24, MAE is:7.83 & sMAPE is:21.49% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :6.22 & 19.35% & 0.81\n",
      "for 2018-03-25, MAE is:2.48 & sMAPE is:6.60% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :6.17 & 19.19% & 0.80\n",
      "for 2018-03-26, MAE is:3.91 & sMAPE is:8.15% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.14 & 19.06% & 0.80\n",
      "for 2018-03-27, MAE is:3.40 & sMAPE is:7.11% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.11 & 18.92% & 0.80\n",
      "for 2018-03-28, MAE is:9.88 & sMAPE is:23.73% & rMAE is:3.20 ||| daily mean of MAE & sMAPE & rMAE till now are :6.16 & 18.98% & 0.82\n",
      "for 2018-03-29, MAE is:4.36 & sMAPE is:14.57% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.14 & 18.93% & 0.82\n",
      "for 2018-03-30, MAE is:2.38 & sMAPE is:5.86% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 18.78% & 0.81\n",
      "for 2018-03-31, MAE is:4.11 & sMAPE is:12.48% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 18.71% & 0.81\n",
      "for 2018-04-01, MAE is:3.12 & sMAPE is:8.40% & rMAE is:2.21 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 18.60% & 0.83\n",
      "for 2018-04-02, MAE is:1.80 & sMAPE is:4.45% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :5.99 & 18.45% & 0.82\n",
      "for 2018-04-03, MAE is:3.29 & sMAPE is:8.10% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :5.96 & 18.33% & 0.82\n",
      "for 2018-04-04, MAE is:5.22 & sMAPE is:15.72% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :5.96 & 18.31% & 0.82\n",
      "for 2018-04-05, MAE is:5.90 & sMAPE is:17.22% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :5.95 & 18.30% & 0.82\n",
      "for 2018-04-06, MAE is:3.68 & sMAPE is:9.89% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :5.93 & 18.21% & 0.82\n",
      "for 2018-04-07, MAE is:16.10 & sMAPE is:77.96% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 18.82% & 0.82\n",
      "for 2018-04-08, MAE is:10.32 & sMAPE is:31.76% & rMAE is:5.95 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 18.96% & 0.87\n",
      "for 2018-04-09, MAE is:3.91 & sMAPE is:8.98% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :6.06 & 18.86% & 0.87\n",
      "for 2018-04-10, MAE is:4.50 & sMAPE is:12.08% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 18.79% & 0.87\n",
      "for 2018-04-11, MAE is:5.43 & sMAPE is:17.20% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 18.77% & 0.87\n",
      "for 2018-04-12, MAE is:8.22 & sMAPE is:25.70% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :6.06 & 18.84% & 0.87\n",
      "for 2018-04-13, MAE is:5.25 & sMAPE is:15.10% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :6.05 & 18.80% & 0.88\n",
      "for 2018-04-14, MAE is:2.01 & sMAPE is:5.50% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :6.01 & 18.68% & 0.87\n",
      "for 2018-04-15, MAE is:2.25 & sMAPE is:6.21% & rMAE is:2.17 ||| daily mean of MAE & sMAPE & rMAE till now are :5.98 & 18.56% & 0.88\n",
      "for 2018-04-16, MAE is:5.06 & sMAPE is:11.20% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :5.97 & 18.49% & 0.89\n",
      "for 2018-04-17, MAE is:4.39 & sMAPE is:10.28% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :5.95 & 18.41% & 0.88\n",
      "for 2018-04-18, MAE is:3.17 & sMAPE is:7.52% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :5.93 & 18.31% & 0.88\n",
      "for 2018-04-19, MAE is:5.05 & sMAPE is:11.55% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :5.92 & 18.25% & 0.88\n",
      "for 2018-04-20, MAE is:2.50 & sMAPE is:6.64% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :5.89 & 18.14% & 0.88\n",
      "for 2018-04-21, MAE is:3.60 & sMAPE is:10.90% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :5.87 & 18.08% & 0.87\n",
      "for 2018-04-22, MAE is:2.71 & sMAPE is:8.29% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :5.84 & 17.99% & 0.87\n",
      "for 2018-04-23, MAE is:6.16 & sMAPE is:22.18% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :5.84 & 18.03% & 0.87\n",
      "for 2018-04-24, MAE is:7.19 & sMAPE is:19.34% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :5.85 & 18.04% & 0.87\n",
      "for 2018-04-25, MAE is:6.37 & sMAPE is:16.81% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :5.86 & 18.03% & 0.87\n",
      "for 2018-04-26, MAE is:5.86 & sMAPE is:17.21% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :5.86 & 18.02% & 0.87\n",
      "for 2018-04-27, MAE is:6.24 & sMAPE is:17.16% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :5.86 & 18.01% & 0.87\n",
      "for 2018-04-28, MAE is:3.34 & sMAPE is:10.09% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :5.84 & 17.95% & 0.87\n",
      "for 2018-04-29, MAE is:3.72 & sMAPE is:10.29% & rMAE is:2.46 ||| daily mean of MAE & sMAPE & rMAE till now are :5.82 & 17.88% & 0.89\n",
      "for 2018-04-30, MAE is:15.97 & sMAPE is:78.53% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 18.39% & 0.89\n",
      "for 2018-05-01, MAE is:7.43 & sMAPE is:42.85% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :5.92 & 18.59% & 0.88\n",
      "for 2018-05-02, MAE is:5.90 & sMAPE is:17.46% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :5.92 & 18.58% & 0.89\n",
      "for 2018-05-03, MAE is:3.11 & sMAPE is:7.73% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :5.90 & 18.49% & 0.89\n",
      "for 2018-05-04, MAE is:10.13 & sMAPE is:17.76% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :5.93 & 18.49% & 0.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-05-05, MAE is:2.85 & sMAPE is:8.67% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 18.41% & 0.89\n",
      "for 2018-05-06, MAE is:6.70 & sMAPE is:27.00% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 18.48% & 0.88\n",
      "for 2018-05-07, MAE is:7.83 & sMAPE is:23.80% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :5.93 & 18.52% & 0.88\n",
      "for 2018-05-08, MAE is:5.20 & sMAPE is:18.08% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :5.92 & 18.51% & 0.88\n",
      "for 2018-05-09, MAE is:8.27 & sMAPE is:29.79% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :5.94 & 18.60% & 0.88\n",
      "for 2018-05-10, MAE is:7.26 & sMAPE is:54.87% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :5.95 & 18.88% & 0.87\n",
      "for 2018-05-11, MAE is:22.32 & sMAPE is:85.36% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 19.39% & 0.88\n",
      "for 2018-05-12, MAE is:6.59 & sMAPE is:18.69% & rMAE is:2.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 19.38% & 0.89\n",
      "for 2018-05-13, MAE is:6.01 & sMAPE is:30.80% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 19.47% & 0.89\n",
      "for 2018-05-14, MAE is:12.23 & sMAPE is:37.67% & rMAE is:2.17 ||| daily mean of MAE & sMAPE & rMAE till now are :6.12 & 19.60% & 0.90\n",
      "for 2018-05-15, MAE is:15.78 & sMAPE is:31.60% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.20 & 19.69% & 0.90\n",
      "for 2018-05-16, MAE is:32.94 & sMAPE is:39.87% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 19.84% & 0.90\n",
      "for 2018-05-17, MAE is:10.72 & sMAPE is:35.93% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 19.96% & 0.89\n",
      "for 2018-05-18, MAE is:8.52 & sMAPE is:33.43% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.44 & 20.06% & 0.90\n",
      "for 2018-05-19, MAE is:6.85 & sMAPE is:21.80% & rMAE is:1.67 ||| daily mean of MAE & sMAPE & rMAE till now are :6.44 & 20.07% & 0.90\n",
      "for 2018-05-20, MAE is:3.77 & sMAPE is:15.08% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 20.03% & 0.90\n",
      "for 2018-05-21, MAE is:8.96 & sMAPE is:49.15% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :6.44 & 20.24% & 0.90\n",
      "for 2018-05-22, MAE is:15.60 & sMAPE is:32.47% & rMAE is:2.05 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 20.33% & 0.91\n",
      "for 2018-05-23, MAE is:13.40 & sMAPE is:22.59% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 20.34% & 0.91\n",
      "for 2018-05-24, MAE is:6.47 & sMAPE is:13.32% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 20.29% & 0.90\n",
      "for 2018-05-25, MAE is:4.71 & sMAPE is:10.46% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.54 & 20.23% & 0.90\n",
      "for 2018-05-26, MAE is:3.22 & sMAPE is:8.61% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :6.52 & 20.15% & 0.90\n",
      "for 2018-05-27, MAE is:3.41 & sMAPE is:9.54% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 20.07% & 0.90\n",
      "for 2018-05-28, MAE is:6.30 & sMAPE is:15.73% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 20.04% & 0.89\n",
      "for 2018-05-29, MAE is:4.90 & sMAPE is:10.47% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 19.98% & 0.89\n",
      "for 2018-05-30, MAE is:4.45 & sMAPE is:9.64% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 19.91% & 0.89\n",
      "for 2018-05-31, MAE is:3.30 & sMAPE is:7.43% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.45 & 19.83% & 0.88\n",
      "for 2018-06-01, MAE is:10.54 & sMAPE is:19.19% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 19.82% & 0.88\n",
      "for 2018-06-02, MAE is:2.95 & sMAPE is:6.82% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.45 & 19.74% & 0.88\n",
      "for 2018-06-03, MAE is:2.78 & sMAPE is:6.93% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.43 & 19.66% & 0.88\n",
      "for 2018-06-04, MAE is:3.19 & sMAPE is:7.25% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 19.58% & 0.88\n",
      "for 2018-06-05, MAE is:5.31 & sMAPE is:11.45% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 19.52% & 0.88\n",
      "for 2018-06-06, MAE is:4.49 & sMAPE is:8.77% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 19.46% & 0.88\n",
      "for 2018-06-07, MAE is:5.78 & sMAPE is:11.99% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 19.41% & 0.88\n",
      "for 2018-06-08, MAE is:3.32 & sMAPE is:6.84% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.37 & 19.33% & 0.88\n",
      "for 2018-06-09, MAE is:2.90 & sMAPE is:6.57% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :6.34 & 19.25% & 0.88\n",
      "for 2018-06-10, MAE is:2.22 & sMAPE is:5.14% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :6.32 & 19.16% & 0.88\n",
      "for 2018-06-11, MAE is:13.71 & sMAPE is:18.98% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.36 & 19.16% & 0.88\n",
      "for 2018-06-12, MAE is:46.54 & sMAPE is:45.33% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 19.32% & 0.88\n",
      "for 2018-06-13, MAE is:11.23 & sMAPE is:17.48% & rMAE is:1.88 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 19.31% & 0.88\n",
      "for 2018-06-14, MAE is:5.36 & sMAPE is:10.72% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :6.63 & 19.26% & 0.88\n",
      "for 2018-06-15, MAE is:5.31 & sMAPE is:10.75% & rMAE is:1.93 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 19.21% & 0.89\n",
      "for 2018-06-16, MAE is:1.65 & sMAPE is:3.75% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :6.59 & 19.11% & 0.89\n",
      "for 2018-06-17, MAE is:2.32 & sMAPE is:5.57% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :6.57 & 19.03% & 0.89\n",
      "for 2018-06-18, MAE is:5.15 & sMAPE is:10.61% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 18.98% & 0.89\n",
      "for 2018-06-19, MAE is:4.54 & sMAPE is:10.28% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 18.93% & 0.88\n",
      "for 2018-06-20, MAE is:7.85 & sMAPE is:16.08% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 18.92% & 0.88\n",
      "for 2018-06-21, MAE is:6.65 & sMAPE is:15.24% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 18.89% & 0.88\n",
      "for 2018-06-22, MAE is:7.77 & sMAPE is:33.16% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 18.98% & 0.88\n",
      "for 2018-06-23, MAE is:5.13 & sMAPE is:16.68% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 18.96% & 0.88\n",
      "for 2018-06-24, MAE is:5.43 & sMAPE is:14.82% & rMAE is:3.45 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 18.94% & 0.89\n",
      "for 2018-06-25, MAE is:8.30 & sMAPE is:15.35% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 18.92% & 0.89\n",
      "for 2018-06-26, MAE is:17.56 & sMAPE is:26.94% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 18.97% & 0.89\n",
      "for 2018-06-27, MAE is:8.98 & sMAPE is:15.58% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.63 & 18.95% & 0.89\n",
      "for 2018-06-28, MAE is:4.28 & sMAPE is:9.49% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 18.89% & 0.89\n",
      "for 2018-06-29, MAE is:4.38 & sMAPE is:10.02% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 18.84% & 0.89\n",
      "for 2018-06-30, MAE is:5.99 & sMAPE is:14.35% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :6.60 & 18.82% & 0.88\n",
      "for 2018-07-01, MAE is:2.60 & sMAPE is:6.05% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 18.75% & 0.88\n",
      "for 2018-07-02, MAE is:5.03 & sMAPE is:9.87% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.57 & 18.70% & 0.88\n",
      "for 2018-07-03, MAE is:6.62 & sMAPE is:13.13% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.57 & 18.67% & 0.88\n",
      "for 2018-07-04, MAE is:3.53 & sMAPE is:6.95% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 18.61% & 0.88\n",
      "for 2018-07-05, MAE is:3.67 & sMAPE is:6.87% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.54 & 18.54% & 0.87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-07-06, MAE is:3.04 & sMAPE is:6.27% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.52 & 18.48% & 0.87\n",
      "for 2018-07-07, MAE is:1.83 & sMAPE is:3.99% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 18.40% & 0.87\n",
      "for 2018-07-08, MAE is:2.87 & sMAPE is:6.27% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 18.34% & 0.87\n",
      "for 2018-07-09, MAE is:2.96 & sMAPE is:5.93% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 18.27% & 0.87\n",
      "for 2018-07-10, MAE is:2.62 & sMAPE is:5.15% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :6.44 & 18.20% & 0.87\n",
      "for 2018-07-11, MAE is:2.58 & sMAPE is:5.12% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 18.13% & 0.88\n",
      "for 2018-07-12, MAE is:2.57 & sMAPE is:4.98% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 18.07% & 0.88\n",
      "for 2018-07-13, MAE is:3.21 & sMAPE is:6.32% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :6.38 & 18.01% & 0.88\n",
      "for 2018-07-14, MAE is:4.09 & sMAPE is:8.37% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.37 & 17.96% & 0.88\n",
      "for 2018-07-15, MAE is:1.34 & sMAPE is:2.73% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.35 & 17.88% & 0.88\n",
      "for 2018-07-16, MAE is:3.19 & sMAPE is:6.27% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.33 & 17.82% & 0.87\n",
      "for 2018-07-17, MAE is:2.40 & sMAPE is:4.43% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 17.75% & 0.88\n",
      "for 2018-07-18, MAE is:3.28 & sMAPE is:6.45% & rMAE is:1.91 ||| daily mean of MAE & sMAPE & rMAE till now are :6.30 & 17.70% & 0.88\n",
      "for 2018-07-19, MAE is:3.45 & sMAPE is:6.71% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.28 & 17.64% & 0.89\n",
      "for 2018-07-20, MAE is:3.48 & sMAPE is:6.81% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :6.27 & 17.59% & 0.89\n",
      "for 2018-07-21, MAE is:2.59 & sMAPE is:5.13% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :6.25 & 17.53% & 0.90\n",
      "for 2018-07-22, MAE is:1.80 & sMAPE is:3.60% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :6.23 & 17.46% & 0.90\n",
      "for 2018-07-23, MAE is:8.31 & sMAPE is:13.11% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 17.44% & 0.90\n",
      "for 2018-07-24, MAE is:6.42 & sMAPE is:12.06% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 17.41% & 0.90\n",
      "for 2018-07-25, MAE is:6.81 & sMAPE is:11.88% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 17.38% & 0.90\n",
      "for 2018-07-26, MAE is:2.43 & sMAPE is:4.39% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.22 & 17.32% & 0.90\n",
      "for 2018-07-27, MAE is:5.67 & sMAPE is:9.61% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.22 & 17.28% & 0.90\n",
      "for 2018-07-28, MAE is:2.01 & sMAPE is:4.12% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.20 & 17.22% & 0.90\n",
      "for 2018-07-29, MAE is:1.49 & sMAPE is:2.97% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :6.18 & 17.15% & 0.90\n",
      "for 2018-07-30, MAE is:3.43 & sMAPE is:5.62% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.16 & 17.10% & 0.90\n",
      "for 2018-07-31, MAE is:3.95 & sMAPE is:7.27% & rMAE is:2.14 ||| daily mean of MAE & sMAPE & rMAE till now are :6.15 & 17.05% & 0.90\n",
      "for 2018-08-01, MAE is:2.72 & sMAPE is:4.58% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :6.14 & 16.99% & 0.90\n",
      "for 2018-08-02, MAE is:4.51 & sMAPE is:7.59% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :6.13 & 16.95% & 0.91\n",
      "for 2018-08-03, MAE is:13.66 & sMAPE is:19.77% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :6.17 & 16.96% & 0.91\n",
      "for 2018-08-04, MAE is:5.14 & sMAPE is:9.23% & rMAE is:2.00 ||| daily mean of MAE & sMAPE & rMAE till now are :6.16 & 16.93% & 0.91\n",
      "for 2018-08-05, MAE is:1.80 & sMAPE is:3.72% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.14 & 16.86% & 0.91\n",
      "for 2018-08-06, MAE is:5.56 & sMAPE is:8.61% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.14 & 16.83% & 0.91\n",
      "for 2018-08-07, MAE is:4.37 & sMAPE is:6.82% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :6.13 & 16.78% & 0.91\n",
      "for 2018-08-08, MAE is:7.12 & sMAPE is:11.57% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.13 & 16.76% & 0.91\n",
      "for 2018-08-09, MAE is:5.16 & sMAPE is:8.88% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :6.13 & 16.72% & 0.91\n",
      "for 2018-08-10, MAE is:6.70 & sMAPE is:18.46% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :6.13 & 16.73% & 0.91\n",
      "for 2018-08-11, MAE is:2.60 & sMAPE is:5.25% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.12 & 16.68% & 0.91\n",
      "for 2018-08-12, MAE is:5.02 & sMAPE is:10.85% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :6.11 & 16.65% & 0.91\n",
      "for 2018-08-13, MAE is:3.29 & sMAPE is:5.71% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.10 & 16.60% & 0.91\n",
      "for 2018-08-14, MAE is:2.38 & sMAPE is:4.03% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 16.55% & 0.90\n",
      "for 2018-08-15, MAE is:3.07 & sMAPE is:5.20% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 16.50% & 0.90\n",
      "for 2018-08-16, MAE is:6.47 & sMAPE is:10.77% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 16.47% & 0.90\n",
      "for 2018-08-17, MAE is:3.04 & sMAPE is:5.28% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :6.06 & 16.42% & 0.90\n",
      "for 2018-08-18, MAE is:5.32 & sMAPE is:10.58% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.05 & 16.40% & 0.90\n",
      "for 2018-08-19, MAE is:4.80 & sMAPE is:9.58% & rMAE is:2.07 ||| daily mean of MAE & sMAPE & rMAE till now are :6.05 & 16.37% & 0.91\n",
      "for 2018-08-20, MAE is:8.90 & sMAPE is:15.06% & rMAE is:1.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.06 & 16.36% & 0.91\n",
      "for 2018-08-21, MAE is:14.86 & sMAPE is:25.26% & rMAE is:2.06 ||| daily mean of MAE & sMAPE & rMAE till now are :6.10 & 16.40% & 0.92\n",
      "for 2018-08-22, MAE is:3.72 & sMAPE is:6.05% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 16.36% & 0.92\n",
      "for 2018-08-23, MAE is:5.47 & sMAPE is:8.90% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 16.33% & 0.92\n",
      "for 2018-08-24, MAE is:9.82 & sMAPE is:16.20% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.10 & 16.32% & 0.92\n",
      "for 2018-08-25, MAE is:3.62 & sMAPE is:7.19% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 16.29% & 0.92\n",
      "for 2018-08-26, MAE is:4.65 & sMAPE is:8.79% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 16.25% & 0.92\n",
      "for 2018-08-27, MAE is:7.83 & sMAPE is:16.66% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 16.26% & 0.92\n",
      "for 2018-08-28, MAE is:7.75 & sMAPE is:13.30% & rMAE is:3.08 ||| daily mean of MAE & sMAPE & rMAE till now are :6.10 & 16.24% & 0.93\n",
      "for 2018-08-29, MAE is:5.00 & sMAPE is:7.69% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :6.10 & 16.21% & 0.93\n",
      "for 2018-08-30, MAE is:3.93 & sMAPE is:6.19% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 16.17% & 0.93\n",
      "for 2018-08-31, MAE is:6.97 & sMAPE is:12.17% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 16.15% & 0.93\n",
      "for 2018-09-01, MAE is:5.27 & sMAPE is:9.01% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 16.12% & 0.92\n",
      "for 2018-09-02, MAE is:4.51 & sMAPE is:8.23% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 16.09% & 0.93\n",
      "for 2018-09-03, MAE is:4.70 & sMAPE is:8.15% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 16.06% & 0.92\n",
      "for 2018-09-04, MAE is:5.22 & sMAPE is:8.51% & rMAE is:2.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 16.03% & 0.93\n",
      "for 2018-09-05, MAE is:4.88 & sMAPE is:7.22% & rMAE is:1.86 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 15.99% & 0.93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-09-06, MAE is:4.40 & sMAPE is:6.90% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :6.06 & 15.95% & 0.93\n",
      "for 2018-09-07, MAE is:4.45 & sMAPE is:7.67% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :6.05 & 15.92% & 0.93\n",
      "for 2018-09-08, MAE is:3.10 & sMAPE is:5.98% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 15.88% & 0.93\n",
      "for 2018-09-09, MAE is:3.24 & sMAPE is:5.48% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :6.03 & 15.84% & 0.93\n",
      "for 2018-09-10, MAE is:7.18 & sMAPE is:11.75% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 15.82% & 0.93\n",
      "for 2018-09-11, MAE is:6.55 & sMAPE is:10.35% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 15.80% & 0.93\n",
      "for 2018-09-12, MAE is:7.12 & sMAPE is:12.31% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 15.79% & 0.93\n",
      "for 2018-09-13, MAE is:12.25 & sMAPE is:18.36% & rMAE is:1.96 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 15.80% & 0.93\n",
      "for 2018-09-14, MAE is:5.20 & sMAPE is:8.36% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :6.06 & 15.77% & 0.94\n",
      "for 2018-09-15, MAE is:3.40 & sMAPE is:6.14% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.05 & 15.73% & 0.94\n",
      "for 2018-09-16, MAE is:2.40 & sMAPE is:4.58% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 15.69% & 0.93\n",
      "for 2018-09-17, MAE is:9.89 & sMAPE is:15.70% & rMAE is:1.91 ||| daily mean of MAE & sMAPE & rMAE till now are :6.05 & 15.69% & 0.94\n",
      "for 2018-09-18, MAE is:4.59 & sMAPE is:7.89% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.05 & 15.66% & 0.94\n",
      "for 2018-09-19, MAE is:5.85 & sMAPE is:10.86% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :6.05 & 15.64% & 0.94\n",
      "for 2018-09-20, MAE is:9.53 & sMAPE is:18.61% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.06 & 15.65% & 0.94\n",
      "for 2018-09-21, MAE is:13.43 & sMAPE is:34.24% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 15.72% & 0.94\n",
      "for 2018-09-22, MAE is:3.95 & sMAPE is:33.20% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 15.79% & 0.93\n",
      "for 2018-09-23, MAE is:15.82 & sMAPE is:73.79% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :6.12 & 16.01% & 0.93\n",
      "for 2018-09-24, MAE is:5.66 & sMAPE is:22.83% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.11 & 16.03% & 0.93\n",
      "for 2018-09-25, MAE is:9.78 & sMAPE is:18.14% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.13 & 16.04% & 0.93\n",
      "for 2018-09-26, MAE is:19.35 & sMAPE is:55.74% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :6.18 & 16.19% & 0.93\n",
      "for 2018-09-27, MAE is:4.68 & sMAPE is:15.83% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :6.17 & 16.19% & 0.93\n",
      "for 2018-09-28, MAE is:3.14 & sMAPE is:8.79% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.16 & 16.16% & 0.93\n",
      "for 2018-09-29, MAE is:7.39 & sMAPE is:19.38% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :6.17 & 16.17% & 0.93\n",
      "for 2018-09-30, MAE is:10.85 & sMAPE is:25.06% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :6.18 & 16.20% & 0.93\n",
      "for 2018-10-01, MAE is:6.19 & sMAPE is:11.07% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.18 & 16.19% & 0.93\n",
      "for 2018-10-02, MAE is:14.82 & sMAPE is:34.83% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.21 & 16.25% & 0.93\n",
      "for 2018-10-03, MAE is:15.41 & sMAPE is:75.03% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :6.25 & 16.47% & 0.93\n",
      "for 2018-10-04, MAE is:18.83 & sMAPE is:33.24% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.29 & 16.53% & 0.93\n",
      "for 2018-10-05, MAE is:11.73 & sMAPE is:20.27% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 16.54% & 0.93\n",
      "for 2018-10-06, MAE is:6.57 & sMAPE is:11.59% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 16.52% & 0.92\n",
      "for 2018-10-07, MAE is:9.70 & sMAPE is:18.89% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.32 & 16.53% & 0.92\n",
      "for 2018-10-08, MAE is:9.29 & sMAPE is:15.06% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.34 & 16.53% & 0.92\n",
      "for 2018-10-09, MAE is:16.41 & sMAPE is:24.75% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.37 & 16.55% & 0.92\n",
      "for 2018-10-10, MAE is:8.61 & sMAPE is:14.27% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :6.38 & 16.55% & 0.92\n",
      "for 2018-10-11, MAE is:9.42 & sMAPE is:18.19% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 16.55% & 0.92\n",
      "for 2018-10-12, MAE is:6.08 & sMAPE is:10.97% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 16.53% & 0.92\n",
      "for 2018-10-13, MAE is:9.55 & sMAPE is:26.22% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 16.57% & 0.92\n",
      "for 2018-10-14, MAE is:7.95 & sMAPE is:50.45% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 16.68% & 0.92\n",
      "for 2018-10-15, MAE is:30.66 & sMAPE is:77.50% & rMAE is:2.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 16.90% & 0.92\n",
      "for 2018-10-16, MAE is:17.68 & sMAPE is:28.06% & rMAE is:1.95 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 16.93% & 0.93\n",
      "for 2018-10-17, MAE is:10.31 & sMAPE is:14.30% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :6.54 & 16.93% & 0.93\n",
      "for 2018-10-18, MAE is:7.22 & sMAPE is:11.74% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.54 & 16.91% & 0.93\n",
      "for 2018-10-19, MAE is:10.53 & sMAPE is:16.40% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 16.91% & 0.92\n",
      "for 2018-10-20, MAE is:4.66 & sMAPE is:8.41% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 16.88% & 0.92\n",
      "for 2018-10-21, MAE is:5.91 & sMAPE is:12.93% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 16.86% & 0.92\n",
      "for 2018-10-22, MAE is:8.20 & sMAPE is:20.06% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 16.87% & 0.92\n",
      "for 2018-10-23, MAE is:15.92 & sMAPE is:43.83% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.59 & 16.97% & 0.92\n",
      "for 2018-10-24, MAE is:13.99 & sMAPE is:67.53% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 17.14% & 0.92\n",
      "for 2018-10-25, MAE is:4.85 & sMAPE is:10.82% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.60 & 17.11% & 0.91\n",
      "for 2018-10-26, MAE is:8.96 & sMAPE is:16.16% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 17.11% & 0.91\n",
      "for 2018-10-27, MAE is:7.22 & sMAPE is:17.44% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 17.11% & 0.91\n",
      "for 2018-10-28, MAE is:4.68 & sMAPE is:10.38% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 17.09% & 0.91\n",
      "for 2018-10-29, MAE is:6.54 & sMAPE is:16.58% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 17.09% & 0.91\n",
      "for 2018-10-30, MAE is:4.41 & sMAPE is:12.49% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.60 & 17.07% & 0.91\n",
      "for 2018-10-31, MAE is:12.07 & sMAPE is:27.01% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 17.11% & 0.91\n",
      "for 2018-11-01, MAE is:4.53 & sMAPE is:9.46% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 17.08% & 0.91\n",
      "for 2018-11-02, MAE is:4.91 & sMAPE is:10.73% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 17.06% & 0.91\n",
      "for 2018-11-03, MAE is:10.09 & sMAPE is:20.88% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 17.07% & 0.91\n",
      "for 2018-11-04, MAE is:5.60 & sMAPE is:12.03% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 17.06% & 0.91\n",
      "for 2018-11-05, MAE is:8.13 & sMAPE is:15.11% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 17.05% & 0.91\n",
      "for 2018-11-06, MAE is:14.57 & sMAPE is:28.25% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 17.09% & 0.91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-11-07, MAE is:6.44 & sMAPE is:11.84% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 17.07% & 0.91\n",
      "for 2018-11-08, MAE is:12.46 & sMAPE is:21.02% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 17.08% & 0.91\n",
      "for 2018-11-09, MAE is:6.60 & sMAPE is:12.40% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 17.07% & 0.91\n",
      "for 2018-11-10, MAE is:2.42 & sMAPE is:5.38% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 17.03% & 0.91\n",
      "for 2018-11-11, MAE is:2.33 & sMAPE is:6.01% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 16.99% & 0.90\n",
      "for 2018-11-12, MAE is:5.93 & sMAPE is:11.68% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :6.63 & 16.98% & 0.91\n",
      "for 2018-11-13, MAE is:5.30 & sMAPE is:11.52% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.63 & 16.96% & 0.90\n",
      "for 2018-11-14, MAE is:11.75 & sMAPE is:20.89% & rMAE is:2.88 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 16.97% & 0.91\n",
      "for 2018-11-15, MAE is:9.26 & sMAPE is:16.31% & rMAE is:2.03 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 16.97% & 0.91\n",
      "for 2018-11-16, MAE is:6.34 & sMAPE is:11.73% & rMAE is:2.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 16.95% & 0.92\n",
      "for 2018-11-17, MAE is:3.49 & sMAPE is:7.05% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 16.92% & 0.92\n",
      "for 2018-11-18, MAE is:3.21 & sMAPE is:7.40% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.63 & 16.89% & 0.92\n",
      "for 2018-11-19, MAE is:5.30 & sMAPE is:10.33% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :6.63 & 16.87% & 0.92\n",
      "for 2018-11-20, MAE is:4.64 & sMAPE is:10.71% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 16.85% & 0.92\n",
      "for 2018-11-21, MAE is:4.45 & sMAPE is:8.44% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 16.83% & 0.92\n",
      "for 2018-11-22, MAE is:20.64 & sMAPE is:28.42% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 16.86% & 0.92\n",
      "for 2018-11-23, MAE is:10.82 & sMAPE is:13.43% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 16.85% & 0.92\n",
      "for 2018-11-24, MAE is:5.14 & sMAPE is:8.81% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 16.83% & 0.91\n",
      "for 2018-11-25, MAE is:3.94 & sMAPE is:7.17% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 16.80% & 0.91\n",
      "for 2018-11-26, MAE is:11.24 & sMAPE is:14.68% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 16.79% & 0.91\n",
      "for 2018-11-27, MAE is:8.26 & sMAPE is:10.80% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 16.78% & 0.91\n",
      "for 2018-11-28, MAE is:9.30 & sMAPE is:16.02% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 16.77% & 0.91\n",
      "for 2018-11-29, MAE is:8.06 & sMAPE is:18.67% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.69 & 16.78% & 0.91\n",
      "for 2018-11-30, MAE is:6.49 & sMAPE is:15.28% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :6.69 & 16.77% & 0.91\n",
      "for 2018-12-01, MAE is:2.58 & sMAPE is:6.05% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 16.74% & 0.91\n",
      "for 2018-12-02, MAE is:5.70 & sMAPE is:16.17% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 16.74% & 0.90\n",
      "for 2018-12-03, MAE is:5.61 & sMAPE is:12.44% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 16.73% & 0.90\n",
      "for 2018-12-04, MAE is:6.36 & sMAPE is:13.84% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 16.72% & 0.90\n",
      "for 2018-12-05, MAE is:13.94 & sMAPE is:26.12% & rMAE is:1.92 ||| daily mean of MAE & sMAPE & rMAE till now are :6.69 & 16.75% & 0.90\n",
      "for 2018-12-06, MAE is:4.01 & sMAPE is:7.48% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 16.72% & 0.90\n",
      "for 2018-12-07, MAE is:5.99 & sMAPE is:15.19% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 16.72% & 0.90\n",
      "for 2018-12-08, MAE is:14.59 & sMAPE is:90.09% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 16.93% & 0.90\n",
      "for 2018-12-09, MAE is:23.29 & sMAPE is:114.49% & rMAE is:2.08 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 17.21% & 0.90\n",
      "for 2018-12-10, MAE is:7.96 & sMAPE is:48.97% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 17.31% & 0.90\n",
      "for 2018-12-11, MAE is:14.02 & sMAPE is:26.39% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 17.33% & 0.90\n",
      "for 2018-12-12, MAE is:9.13 & sMAPE is:12.84% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 17.32% & 0.90\n",
      "for 2018-12-13, MAE is:6.45 & sMAPE is:9.76% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 17.30% & 0.90\n",
      "for 2018-12-14, MAE is:12.25 & sMAPE is:17.48% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 17.30% & 0.90\n",
      "for 2018-12-15, MAE is:9.14 & sMAPE is:17.95% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 17.30% & 0.90\n",
      "for 2018-12-16, MAE is:6.29 & sMAPE is:13.43% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 17.29% & 0.90\n",
      "for 2018-12-17, MAE is:15.05 & sMAPE is:24.17% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 17.31% & 0.90\n",
      "for 2018-12-18, MAE is:5.90 & sMAPE is:9.76% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 17.29% & 0.90\n",
      "for 2018-12-19, MAE is:5.06 & sMAPE is:9.88% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 17.27% & 0.89\n",
      "for 2018-12-20, MAE is:6.53 & sMAPE is:11.81% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 17.25% & 0.89\n",
      "for 2018-12-21, MAE is:5.01 & sMAPE is:8.71% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.81 & 17.23% & 0.89\n",
      "for 2018-12-22, MAE is:2.43 & sMAPE is:4.51% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 17.19% & 0.89\n",
      "for 2018-12-23, MAE is:4.43 & sMAPE is:8.70% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 17.17% & 0.89\n",
      "for 2018-12-24, MAE is:4.87 & sMAPE is:9.73% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 17.15% & 0.89\n",
      "for 2018-12-25, MAE is:20.77 & sMAPE is:85.93% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 17.34% & 0.89\n",
      "for 2018-12-26, MAE is:10.04 & sMAPE is:24.73% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.84 & 17.36% & 0.89\n",
      "for 2018-12-27, MAE is:4.71 & sMAPE is:10.14% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 17.34% & 0.89\n",
      "for 2018-12-28, MAE is:5.19 & sMAPE is:10.48% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 17.32% & 0.89\n",
      "for 2018-12-29, MAE is:4.08 & sMAPE is:10.29% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 17.30% & 0.89\n",
      "for 2018-12-30, MAE is:17.21 & sMAPE is:72.67% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 17.45% & 0.89\n",
      "for 2018-12-31, MAE is:7.25 & sMAPE is:17.44% & rMAE is:2.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 17.45% & 0.90\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 20:40:05,508]\u001b[0m A new study created in RDB with name: DK_2_2019\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:40:34,392]\u001b[0m Trial 1 finished with value: 18.249438133772525 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015567254049610746, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.018370465493410038, 'dropout_rate_Layer_2': 0.024486182136877456, 'dropout_rate_Layer_3': 0.3584463630657842, 'dropout_rate_Layer_4': 0.008008866658404524, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.06156273420190794, 'l1_Layer_2': 8.80684851569192e-05, 'l1_Layer_3': 0.03319314416151849, 'l1_Layer_4': 0.01144501426197858, 'n_units_Layer_1': 245, 'n_units_Layer_2': 220, 'n_units_Layer_3': 200, 'n_units_Layer_4': 125}. Best is trial 1 with value: 18.249438133772525.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.25 | sMAPE for Validation Set is: 45.68% | rMAE for Validation Set is: 1.73\n",
      "MAE for Test Set is: 12.06 | sMAPE for Test Set is: 34.74% | rMAE for Test Set is: 1.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 20:40:37,193]\u001b[0m Trial 2 finished with value: 12.529618520745577 and parameters: {'n_hidden': 4, 'learning_rate': 0.06697130201952632, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39508198795020916, 'dropout_rate_Layer_2': 0.0891970716079376, 'dropout_rate_Layer_3': 0.27526075451390186, 'dropout_rate_Layer_4': 0.22432113141527182, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0002823990388425277, 'l1_Layer_2': 0.08623418434027316, 'l1_Layer_3': 0.00030177073577456024, 'l1_Layer_4': 0.0008295776877218165, 'n_units_Layer_1': 65, 'n_units_Layer_2': 245, 'n_units_Layer_3': 105, 'n_units_Layer_4': 285}. Best is trial 2 with value: 12.529618520745577.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.53 | sMAPE for Validation Set is: 30.07% | rMAE for Validation Set is: 1.19\n",
      "MAE for Test Set is: 7.94 | sMAPE for Test Set is: 22.83% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 20:40:40,208]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:40:45,557]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:40:48,486]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:40:52,006]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:40:57,632]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:41:03,555]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:41:03,944]\u001b[0m Trial 3 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:41:08,819]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:41:11,633]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:41:14,595]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:41:18,965]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:41:19,296]\u001b[0m Trial 5 finished with value: 9.570710794490587 and parameters: {'n_hidden': 4, 'learning_rate': 0.04777217245742699, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0020175447571814777, 'dropout_rate_Layer_2': 0.3045781830757619, 'dropout_rate_Layer_3': 0.06995105935653467, 'dropout_rate_Layer_4': 0.029005823162649283, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 3.858456214505124e-05, 'l1_Layer_2': 0.0001459186123581552, 'l1_Layer_3': 0.0025932460921047284, 'l1_Layer_4': 1.3259474135024514e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 50, 'n_units_Layer_3': 60, 'n_units_Layer_4': 210}. Best is trial 5 with value: 9.570710794490587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.57 | sMAPE for Validation Set is: 22.77% | rMAE for Validation Set is: 0.91\n",
      "MAE for Test Set is: 7.17 | sMAPE for Test Set is: 20.37% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 20:41:27,050]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:41:30,187]\u001b[0m Trial 14 finished with value: 7.432340469289315 and parameters: {'n_hidden': 3, 'learning_rate': 0.04447164889000013, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2632134178684358, 'dropout_rate_Layer_2': 0.045874382409334086, 'dropout_rate_Layer_3': 0.21692275414074946, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002098820471892681, 'l1_Layer_2': 0.006412600579471354, 'l1_Layer_3': 0.038203723254505335, 'n_units_Layer_1': 140, 'n_units_Layer_2': 245, 'n_units_Layer_3': 60}. Best is trial 14 with value: 7.432340469289315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.43 | sMAPE for Validation Set is: 18.26% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 6.15 | sMAPE for Test Set is: 18.14% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 20:41:34,988]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:41:37,379]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:41:39,582]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:41:43,496]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:41:45,814]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:41:50,436]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:41:52,994]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:41:53,450]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:42:00,087]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:42:01,776]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:42:06,982]\u001b[0m Trial 0 finished with value: 7.3729780724406 and parameters: {'n_hidden': 4, 'learning_rate': 0.001047865286057453, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1846919842593683, 'dropout_rate_Layer_2': 0.24953892961168683, 'dropout_rate_Layer_3': 0.1520796938044872, 'dropout_rate_Layer_4': 0.3692285628218389, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.058236594360173e-05, 'l1_Layer_2': 0.00011073844041945126, 'l1_Layer_3': 4.917143453127648e-05, 'l1_Layer_4': 0.0002532773442723821, 'n_units_Layer_1': 85, 'n_units_Layer_2': 205, 'n_units_Layer_3': 140, 'n_units_Layer_4': 115}. Best is trial 0 with value: 7.3729780724406.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.37 | sMAPE for Validation Set is: 18.13% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 6.31 | sMAPE for Test Set is: 18.59% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 20:42:07,575]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:42:15,461]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:42:17,791]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:42:19,316]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:42:22,699]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:42:33,231]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:42:37,894]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:42:43,789]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:42:47,225]\u001b[0m Trial 34 finished with value: 8.610369936598522 and parameters: {'n_hidden': 3, 'learning_rate': 0.00845039577629458, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25774513586664766, 'dropout_rate_Layer_2': 0.2918354903652987, 'dropout_rate_Layer_3': 0.28405394612811546, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0042329809183864085, 'l1_Layer_2': 3.1628409552886006e-05, 'l1_Layer_3': 2.3022233601695216e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 60, 'n_units_Layer_3': 160}. Best is trial 0 with value: 7.3729780724406.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.61 | sMAPE for Validation Set is: 21.01% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 6.87 | sMAPE for Test Set is: 19.90% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 20:42:47,805]\u001b[0m Trial 28 finished with value: 13.951752671858008 and parameters: {'n_hidden': 3, 'learning_rate': 0.06868284520478372, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3044746881190541, 'dropout_rate_Layer_2': 0.2571078545397704, 'dropout_rate_Layer_3': 0.2991858808623914, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0020449163799275976, 'l1_Layer_2': 0.02547997454258814, 'l1_Layer_3': 0.0006313843920382653, 'n_units_Layer_1': 290, 'n_units_Layer_2': 65, 'n_units_Layer_3': 130}. Best is trial 0 with value: 7.3729780724406.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.95 | sMAPE for Validation Set is: 33.86% | rMAE for Validation Set is: 1.32\n",
      "MAE for Test Set is: 9.07 | sMAPE for Test Set is: 26.05% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 20:42:55,135]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:42:58,538]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:42:58,672]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:43:03,070]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:43:10,796]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:43:15,391]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:43:27,185]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:43:38,364]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:43:49,597]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:44:05,539]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:44:13,581]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:44:40,325]\u001b[0m Trial 49 finished with value: 7.914110169459543 and parameters: {'n_hidden': 3, 'learning_rate': 0.02109827526846, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38774823463442726, 'dropout_rate_Layer_2': 0.27704534125336533, 'dropout_rate_Layer_3': 0.29472068806256035, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006086912474010543, 'l1_Layer_2': 1.373306106334591e-05, 'l1_Layer_3': 0.08936021721066452, 'n_units_Layer_1': 135, 'n_units_Layer_2': 55, 'n_units_Layer_3': 120}. Best is trial 0 with value: 7.3729780724406.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.91 | sMAPE for Validation Set is: 19.53% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 6.43 | sMAPE for Test Set is: 19.05% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 20:44:42,538]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:44:47,973]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:44:53,740]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:44:55,798]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:45:01,632]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:45:04,692]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:45:13,124]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:45:20,851]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:45:31,583]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:45:39,749]\u001b[0m Trial 51 finished with value: 10.317226132298758 and parameters: {'n_hidden': 4, 'learning_rate': 0.030641756600791385, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36088943804656015, 'dropout_rate_Layer_2': 0.39509683550404434, 'dropout_rate_Layer_3': 0.29247531578971825, 'dropout_rate_Layer_4': 0.29664128220691083, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.8812503645546684e-05, 'l1_Layer_2': 7.505698843571756e-05, 'l1_Layer_3': 0.017708594615418436, 'l1_Layer_4': 0.012967141395921004, 'n_units_Layer_1': 180, 'n_units_Layer_2': 255, 'n_units_Layer_3': 55, 'n_units_Layer_4': 155}. Best is trial 0 with value: 7.3729780724406.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.32 | sMAPE for Validation Set is: 24.81% | rMAE for Validation Set is: 0.98\n",
      "MAE for Test Set is: 6.88 | sMAPE for Test Set is: 20.06% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 20:45:43,017]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:45:48,456]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:45:52,178]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:45:52,317]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:46:00,055]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:46:00,239]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:46:03,927]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:46:10,419]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:46:14,384]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:46:18,357]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:46:25,993]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:46:26,296]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:46:33,578]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:46:36,131]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:46:37,887]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:46:41,042]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:46:45,833]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:46:50,655]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:46:54,437]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:46:59,490]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:46:59,979]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:47:06,572]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:47:12,296]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:47:17,203]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:47:22,578]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:47:29,010]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:47:35,139]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:47:37,782]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:47:43,720]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:47:49,111]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:47:56,491]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:48:00,517]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:48:03,802]\u001b[0m Trial 89 finished with value: 9.697648177217948 and parameters: {'n_hidden': 3, 'learning_rate': 0.004796761982641933, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2545612393305801, 'dropout_rate_Layer_2': 0.01177662019795167, 'dropout_rate_Layer_3': 0.3814324339472774, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.9260533560240337e-05, 'l1_Layer_2': 0.00015694636047211612, 'l1_Layer_3': 8.203773227905234e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 100, 'n_units_Layer_3': 245}. Best is trial 0 with value: 7.3729780724406.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.70 | sMAPE for Validation Set is: 23.08% | rMAE for Validation Set is: 0.92\n",
      "MAE for Test Set is: 6.57 | sMAPE for Test Set is: 19.10% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 20:48:06,626]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:48:09,785]\u001b[0m Trial 82 finished with value: 9.547331979754249 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005238305036674636, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1937579089473257, 'dropout_rate_Layer_2': 0.393637963017059, 'dropout_rate_Layer_3': 0.3540682159076075, 'dropout_rate_Layer_4': 0.12161867937764051, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0008711274459921856, 'l1_Layer_2': 0.00040156968370130505, 'l1_Layer_3': 0.004984140111087265, 'l1_Layer_4': 0.00032062937884432734, 'n_units_Layer_1': 180, 'n_units_Layer_2': 245, 'n_units_Layer_3': 270, 'n_units_Layer_4': 135}. Best is trial 0 with value: 7.3729780724406.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:48:09,821]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.55 | sMAPE for Validation Set is: 23.11% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 6.57 | sMAPE for Test Set is: 19.50% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 20:48:14,174]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:48:22,116]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:48:29,852]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:48:40,967]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:48:46,265]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:48:46,490]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:48:51,779]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:48:55,842]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:48:56,021]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:49:04,761]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:49:04,946]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:49:05,503]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:49:15,613]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:49:19,927]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:49:28,746]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:49:34,777]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:49:43,538]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:49:50,863]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:49:54,316]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:49:55,475]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:50:09,126]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:50:09,753]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:50:11,967]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:50:22,915]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:50:23,215]\u001b[0m Trial 114 finished with value: 8.440131617373815 and parameters: {'n_hidden': 4, 'learning_rate': 0.04348135617065068, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08966329556456504, 'dropout_rate_Layer_2': 0.3551330935050728, 'dropout_rate_Layer_3': 0.08934454246881457, 'dropout_rate_Layer_4': 0.12069443687167468, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.2913374201255373e-05, 'l1_Layer_2': 0.00012299230473511831, 'l1_Layer_3': 0.0025505165479933123, 'l1_Layer_4': 0.00038156980270772267, 'n_units_Layer_1': 300, 'n_units_Layer_2': 50, 'n_units_Layer_3': 50, 'n_units_Layer_4': 230}. Best is trial 0 with value: 7.3729780724406.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.44 | sMAPE for Validation Set is: 20.24% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 7.07 | sMAPE for Test Set is: 19.83% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 20:50:23,532]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:50:38,958]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:50:39,276]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:50:39,365]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:50:55,993]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:51:02,579]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:51:06,259]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:51:08,563]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:51:18,547]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:51:21,992]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:51:29,639]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:51:42,587]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:51:48,323]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:52:01,081]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:52:07,685]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:52:07,875]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:52:14,851]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:52:15,094]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:52:23,914]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:52:26,120]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:52:32,642]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:52:40,368]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:52:40,907]\u001b[0m Trial 140 finished with value: 15.487108710180669 and parameters: {'n_hidden': 3, 'learning_rate': 0.04383243350409744, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23003026575298136, 'dropout_rate_Layer_2': 0.33056310613162054, 'dropout_rate_Layer_3': 0.1903294806279947, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 9.458518809397554e-05, 'l1_Layer_2': 1.5429368190494983e-05, 'l1_Layer_3': 0.0004222118317487101, 'n_units_Layer_1': 290, 'n_units_Layer_2': 180, 'n_units_Layer_3': 120}. Best is trial 0 with value: 7.3729780724406.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.49 | sMAPE for Validation Set is: 38.02% | rMAE for Validation Set is: 1.47\n",
      "MAE for Test Set is: 9.94 | sMAPE for Test Set is: 28.69% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 20:52:51,278]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:52:51,412]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:52:59,634]\u001b[0m Trial 138 finished with value: 7.110787864876858 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027746609460494237, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3834108368895073, 'dropout_rate_Layer_2': 0.18142211587994253, 'dropout_rate_Layer_3': 0.2464407043074176, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004877529009887293, 'l1_Layer_2': 0.00019265332629361418, 'l1_Layer_3': 0.019421776880318084, 'n_units_Layer_1': 185, 'n_units_Layer_2': 290, 'n_units_Layer_3': 135}. Best is trial 138 with value: 7.110787864876858.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.11 | sMAPE for Validation Set is: 17.53% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.97 | sMAPE for Test Set is: 17.65% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 20:53:03,078]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:53:15,667]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:53:24,908]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:53:32,679]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:53:37,025]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:53:49,694]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:54:05,649]\u001b[0m Trial 151 finished with value: 11.36233728620149 and parameters: {'n_hidden': 4, 'learning_rate': 0.013870244100047299, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13369816747979218, 'dropout_rate_Layer_2': 0.021131401455066607, 'dropout_rate_Layer_3': 0.38784871256633546, 'dropout_rate_Layer_4': 0.016438597671274383, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.02690840324764914, 'l1_Layer_2': 0.0009016471144964838, 'l1_Layer_3': 1.1207305554054063e-05, 'l1_Layer_4': 0.00013203380160461755, 'n_units_Layer_1': 140, 'n_units_Layer_2': 125, 'n_units_Layer_3': 300, 'n_units_Layer_4': 60}. Best is trial 138 with value: 7.110787864876858.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.36 | sMAPE for Validation Set is: 27.41% | rMAE for Validation Set is: 1.08\n",
      "MAE for Test Set is: 7.52 | sMAPE for Test Set is: 21.76% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 20:54:18,733]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:54:26,476]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:54:29,454]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:54:35,323]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:54:35,694]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:54:35,927]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:54:43,256]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:54:49,103]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:54:51,855]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:55:00,568]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:55:11,765]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:55:22,863]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:55:29,288]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:55:36,911]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:55:43,872]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:55:49,732]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:56:00,290]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:56:06,776]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:56:14,943]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:56:22,434]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:56:28,349]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:56:33,523]\u001b[0m Trial 161 finished with value: 7.4210998957694345 and parameters: {'n_hidden': 4, 'learning_rate': 0.00601352211227515, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.174453549775433, 'dropout_rate_Layer_2': 0.2384857077565021, 'dropout_rate_Layer_3': 0.26245292473149523, 'dropout_rate_Layer_4': 0.2921432882019933, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.800292603640735e-05, 'l1_Layer_2': 0.05338998699305953, 'l1_Layer_3': 0.0004032861596143567, 'l1_Layer_4': 0.0002785198766166884, 'n_units_Layer_1': 55, 'n_units_Layer_2': 285, 'n_units_Layer_3': 230, 'n_units_Layer_4': 180}. Best is trial 138 with value: 7.110787864876858.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.42 | sMAPE for Validation Set is: 18.16% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 6.24 | sMAPE for Test Set is: 18.46% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 20:56:39,267]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:56:40,335]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:56:40,458]\u001b[0m Trial 147 finished with value: 7.746738060084579 and parameters: {'n_hidden': 4, 'learning_rate': 0.002154172098540289, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25754871550414543, 'dropout_rate_Layer_2': 0.3008888853988819, 'dropout_rate_Layer_3': 0.16388127891382076, 'dropout_rate_Layer_4': 0.3683608248148934, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0014489378468406167, 'l1_Layer_2': 0.02216351682272592, 'l1_Layer_3': 1.7181580965274796e-05, 'l1_Layer_4': 0.0003945361844815592, 'n_units_Layer_1': 55, 'n_units_Layer_2': 285, 'n_units_Layer_3': 210, 'n_units_Layer_4': 220}. Best is trial 138 with value: 7.110787864876858.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.75 | sMAPE for Validation Set is: 19.00% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 6.32 | sMAPE for Test Set is: 18.77% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 20:56:47,339]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:56:51,308]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:56:53,255]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:56:56,340]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:57:04,805]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:57:08,431]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:57:19,951]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:57:23,557]\u001b[0m Trial 185 finished with value: 6.675429552613689 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018130831044994005, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21651013759239712, 'dropout_rate_Layer_2': 0.1932064726070915, 'dropout_rate_Layer_3': 0.2846753845636308, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00018126488994874633, 'l1_Layer_2': 6.629911112680865e-05, 'l1_Layer_3': 0.005078386366682622, 'n_units_Layer_1': 210, 'n_units_Layer_2': 270, 'n_units_Layer_3': 295}. Best is trial 185 with value: 6.675429552613689.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.68 | sMAPE for Validation Set is: 16.58% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.80 | sMAPE for Test Set is: 17.47% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 20:57:24,048]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:57:32,505]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:57:36,711]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:57:41,364]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:57:44,659]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:57:53,524]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:57:57,351]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:58:00,654]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:58:05,046]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:58:21,715]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:58:28,144]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:58:37,434]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:58:43,919]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:58:47,328]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:58:55,438]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:59:00,175]\u001b[0m Trial 188 finished with value: 7.436554400854269 and parameters: {'n_hidden': 4, 'learning_rate': 0.003143357108639268, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1757037490844219, 'dropout_rate_Layer_2': 0.3325165158570583, 'dropout_rate_Layer_3': 0.228846447224064, 'dropout_rate_Layer_4': 0.3383002008584527, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.8686565173070806e-05, 'l1_Layer_2': 0.05371748088916152, 'l1_Layer_3': 2.237567961388738e-05, 'l1_Layer_4': 0.0015474715149204855, 'n_units_Layer_1': 80, 'n_units_Layer_2': 230, 'n_units_Layer_3': 225, 'n_units_Layer_4': 200}. Best is trial 185 with value: 6.675429552613689.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.44 | sMAPE for Validation Set is: 18.28% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 6.19 | sMAPE for Test Set is: 18.39% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 20:59:03,111]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:59:08,063]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:59:10,479]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:59:16,955]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:59:26,341]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:59:33,185]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:59:36,247]\u001b[0m Trial 166 finished with value: 7.73588243002332 and parameters: {'n_hidden': 4, 'learning_rate': 0.0038458448920639017, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1793346630266235, 'dropout_rate_Layer_2': 0.28712717269329735, 'dropout_rate_Layer_3': 0.18307141901966154, 'dropout_rate_Layer_4': 0.39965600525283984, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 6.69754037021692e-05, 'l1_Layer_2': 0.029248621626236274, 'l1_Layer_3': 0.0060415389127617975, 'l1_Layer_4': 0.00014032881800663864, 'n_units_Layer_1': 80, 'n_units_Layer_2': 280, 'n_units_Layer_3': 215, 'n_units_Layer_4': 205}. Best is trial 185 with value: 6.675429552613689.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.74 | sMAPE for Validation Set is: 18.91% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 6.65 | sMAPE for Test Set is: 19.26% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 20:59:39,512]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:59:41,116]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:59:44,261]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:59:48,628]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 20:59:53,575]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:00:00,499]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:00:06,590]\u001b[0m Trial 216 finished with value: 6.718764293016224 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016822904401746954, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20674896383307398, 'dropout_rate_Layer_2': 0.19365896230033594, 'dropout_rate_Layer_3': 0.27635937693275514, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002368812500720228, 'l1_Layer_2': 7.684075053778188e-05, 'l1_Layer_3': 0.005439053741301305, 'n_units_Layer_1': 220, 'n_units_Layer_2': 270, 'n_units_Layer_3': 290}. Best is trial 185 with value: 6.675429552613689.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.72 | sMAPE for Validation Set is: 16.66% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.01 | sMAPE for Test Set is: 17.81% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:00:08,803]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:00:21,324]\u001b[0m Trial 206 finished with value: 7.290690984242009 and parameters: {'n_hidden': 4, 'learning_rate': 0.002215619900951452, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18304908129801786, 'dropout_rate_Layer_2': 0.03113596551009712, 'dropout_rate_Layer_3': 0.2398843721429238, 'dropout_rate_Layer_4': 0.36491445224396746, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.1941490484577137e-05, 'l1_Layer_2': 0.04441383133964741, 'l1_Layer_3': 2.5170703151168213e-05, 'l1_Layer_4': 0.0015744300025785436, 'n_units_Layer_1': 85, 'n_units_Layer_2': 245, 'n_units_Layer_3': 240, 'n_units_Layer_4': 195}. Best is trial 185 with value: 6.675429552613689.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.29 | sMAPE for Validation Set is: 18.16% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 6.07 | sMAPE for Test Set is: 18.24% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:00:36,180]\u001b[0m Trial 221 finished with value: 6.674896464902816 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018285823547658552, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19681008996260188, 'dropout_rate_Layer_2': 0.19821651191546294, 'dropout_rate_Layer_3': 0.28645043697393774, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00021385123789184602, 'l1_Layer_2': 3.7222772987542854e-05, 'l1_Layer_3': 0.00405983811021848, 'n_units_Layer_1': 220, 'n_units_Layer_2': 270, 'n_units_Layer_3': 300}. Best is trial 221 with value: 6.674896464902816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.67 | sMAPE for Validation Set is: 16.69% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.97 | sMAPE for Test Set is: 17.99% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:00:38,072]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:00:44,357]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:00:48,844]\u001b[0m Trial 219 finished with value: 7.366145454341027 and parameters: {'n_hidden': 4, 'learning_rate': 0.004084871639304138, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16435437660954666, 'dropout_rate_Layer_2': 0.3737868886439422, 'dropout_rate_Layer_3': 0.1973121407460782, 'dropout_rate_Layer_4': 0.36796388094089005, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.1810879984654586e-05, 'l1_Layer_2': 0.041409797666422846, 'l1_Layer_3': 0.0015328032885083018, 'l1_Layer_4': 0.0013309503462259635, 'n_units_Layer_1': 95, 'n_units_Layer_2': 290, 'n_units_Layer_3': 225, 'n_units_Layer_4': 150}. Best is trial 221 with value: 6.674896464902816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.37 | sMAPE for Validation Set is: 18.21% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 6.19 | sMAPE for Test Set is: 18.37% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:00:50,661]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:00:56,818]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:01:23,787]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:01:28,812]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:01:42,655]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:01:55,676]\u001b[0m Trial 225 finished with value: 7.207852823170426 and parameters: {'n_hidden': 4, 'learning_rate': 0.006466934826193982, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15542979451657649, 'dropout_rate_Layer_2': 0.359866018471566, 'dropout_rate_Layer_3': 0.19004207642104212, 'dropout_rate_Layer_4': 0.3702822941083778, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.1183851427826178e-05, 'l1_Layer_2': 0.03528941115943268, 'l1_Layer_3': 0.0003554030966948156, 'l1_Layer_4': 0.0018346571101051053, 'n_units_Layer_1': 100, 'n_units_Layer_2': 300, 'n_units_Layer_3': 255, 'n_units_Layer_4': 150}. Best is trial 221 with value: 6.674896464902816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.21 | sMAPE for Validation Set is: 17.84% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 6.01 | sMAPE for Test Set is: 17.90% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:01:59,439]\u001b[0m Trial 230 finished with value: 7.0527095370940875 and parameters: {'n_hidden': 4, 'learning_rate': 0.008126578341926009, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1549971670967087, 'dropout_rate_Layer_2': 0.3671574904853587, 'dropout_rate_Layer_3': 0.1789156713262473, 'dropout_rate_Layer_4': 0.3708279897231808, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.294470261993006e-05, 'l1_Layer_2': 0.05236207506568823, 'l1_Layer_3': 3.443829891659149e-05, 'l1_Layer_4': 0.0010261573261226386, 'n_units_Layer_1': 95, 'n_units_Layer_2': 290, 'n_units_Layer_3': 255, 'n_units_Layer_4': 135}. Best is trial 221 with value: 6.674896464902816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.05 | sMAPE for Validation Set is: 17.48% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.92 | sMAPE for Test Set is: 17.74% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:02:01,424]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:02:06,571]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:02:06,815]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:02:09,999]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:02:14,024]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:02:14,914]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.11 | sMAPE for Validation Set is: 17.41% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.13 | sMAPE for Test Set is: 18.04% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:02:19,249]\u001b[0m Trial 218 finished with value: 7.113265427628487 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005817482680369861, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16580330069653892, 'dropout_rate_Layer_2': 0.3577918106115662, 'dropout_rate_Layer_3': 0.13908251009062164, 'dropout_rate_Layer_4': 0.36242887065046353, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.1856686498976873e-05, 'l1_Layer_2': 0.042206272241539854, 'l1_Layer_3': 5.3155286439640536e-05, 'l1_Layer_4': 0.001810116594300771, 'n_units_Layer_1': 95, 'n_units_Layer_2': 290, 'n_units_Layer_3': 75, 'n_units_Layer_4': 150}. Best is trial 221 with value: 6.674896464902816.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:02:20,028]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:02:25,013]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:02:28,193]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:02:32,565]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:02:36,642]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:02:39,595]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:02:45,316]\u001b[0m Trial 241 finished with value: 6.689710307628527 and parameters: {'n_hidden': 3, 'learning_rate': 0.005703661078054497, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21881423224252736, 'dropout_rate_Layer_2': 0.21130505579423267, 'dropout_rate_Layer_3': 0.3459913953628559, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.891383571840082e-05, 'l1_Layer_2': 3.201999308136335e-05, 'l1_Layer_3': 0.0014546493623648967, 'n_units_Layer_1': 255, 'n_units_Layer_2': 220, 'n_units_Layer_3': 275}. Best is trial 221 with value: 6.674896464902816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.69 | sMAPE for Validation Set is: 16.73% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.07 | sMAPE for Test Set is: 18.42% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:02:51,693]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:02:55,744]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:02:56,120]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:02:56,667]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:03:01,350]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:03:03,581]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:03:10,718]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:03:16,526]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:03:21,526]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:03:31,995]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:03:37,309]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:03:42,665]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:03:47,148]\u001b[0m Trial 250 finished with value: 8.140298699142768 and parameters: {'n_hidden': 4, 'learning_rate': 0.04556552808474573, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04157360436689729, 'dropout_rate_Layer_2': 0.2907685890469197, 'dropout_rate_Layer_3': 0.33608637263496277, 'dropout_rate_Layer_4': 0.152271201683971, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.0333030426822955e-05, 'l1_Layer_2': 0.000382476213607831, 'l1_Layer_3': 0.0002669329889655497, 'l1_Layer_4': 0.01818489078613863, 'n_units_Layer_1': 300, 'n_units_Layer_2': 80, 'n_units_Layer_3': 120, 'n_units_Layer_4': 170}. Best is trial 221 with value: 6.674896464902816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.14 | sMAPE for Validation Set is: 19.23% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 6.73 | sMAPE for Test Set is: 19.28% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:03:54,046]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:04:01,869]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:04:02,214]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:04:24,312]\u001b[0m Trial 249 finished with value: 7.030778231753982 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010166855148783585, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12608113623901637, 'dropout_rate_Layer_2': 0.3596698751471149, 'dropout_rate_Layer_3': 0.15948867943341916, 'dropout_rate_Layer_4': 0.35393259996211063, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.0161246418996522e-05, 'l1_Layer_2': 0.03204455057926281, 'l1_Layer_3': 0.00029301653381013905, 'l1_Layer_4': 0.003245782077133758, 'n_units_Layer_1': 115, 'n_units_Layer_2': 290, 'n_units_Layer_3': 275, 'n_units_Layer_4': 140}. Best is trial 221 with value: 6.674896464902816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.03 | sMAPE for Validation Set is: 17.33% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.96 | sMAPE for Test Set is: 17.69% | rMAE for Test Set is: 0.73\n",
      "MAE for Validation Set is: 7.07 | sMAPE for Validation Set is: 17.37% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.88 | sMAPE for Test Set is: 17.45% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:04:26,460]\u001b[0m Trial 255 finished with value: 7.067765878627642 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012067474063181386, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15308109126325234, 'dropout_rate_Layer_2': 0.3894750149948144, 'dropout_rate_Layer_3': 0.20449924158348834, 'dropout_rate_Layer_4': 0.36893099751998565, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 8.915684184672785e-05, 'l1_Layer_2': 0.03659695479221225, 'l1_Layer_3': 0.010704887052682242, 'l1_Layer_4': 0.0013136927632533453, 'n_units_Layer_1': 100, 'n_units_Layer_2': 285, 'n_units_Layer_3': 240, 'n_units_Layer_4': 160}. Best is trial 221 with value: 6.674896464902816.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:04:32,040]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:04:34,084]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:04:42,422]\u001b[0m Trial 262 finished with value: 7.099123030081807 and parameters: {'n_hidden': 4, 'learning_rate': 0.001547065570611771, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20027861605043026, 'dropout_rate_Layer_2': 0.34225982973078745, 'dropout_rate_Layer_3': 0.17706595024313324, 'dropout_rate_Layer_4': 0.34379528840260803, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.4987003431533846e-05, 'l1_Layer_2': 0.05684364707588599, 'l1_Layer_3': 1.8790009680200924e-05, 'l1_Layer_4': 0.006644113922952696, 'n_units_Layer_1': 90, 'n_units_Layer_2': 300, 'n_units_Layer_3': 255, 'n_units_Layer_4': 130}. Best is trial 221 with value: 6.674896464902816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.10 | sMAPE for Validation Set is: 17.45% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.01 | sMAPE for Test Set is: 17.78% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:04:50,019]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:04:53,944]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:04:54,582]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:05:02,306]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:05:09,353]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:05:09,824]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:05:15,829]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:05:19,467]\u001b[0m Trial 266 finished with value: 10.488947573072195 and parameters: {'n_hidden': 3, 'learning_rate': 0.003386467532583731, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20433611593523815, 'dropout_rate_Layer_2': 0.3399477248671802, 'dropout_rate_Layer_3': 0.24747336390852073, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00040953884482587433, 'l1_Layer_2': 2.6518634852352023e-05, 'l1_Layer_3': 0.08946818962519255, 'n_units_Layer_1': 210, 'n_units_Layer_2': 105, 'n_units_Layer_3': 255}. Best is trial 221 with value: 6.674896464902816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.49 | sMAPE for Validation Set is: 25.20% | rMAE for Validation Set is: 0.99\n",
      "MAE for Test Set is: 6.87 | sMAPE for Test Set is: 20.21% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:05:26,002]\u001b[0m Trial 265 finished with value: 7.06652566757948 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011880792023912863, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1217934499462089, 'dropout_rate_Layer_2': 0.3471718227201472, 'dropout_rate_Layer_3': 0.14831710407746274, 'dropout_rate_Layer_4': 0.34573499658029266, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.4748140087266757e-05, 'l1_Layer_2': 0.01765660483840757, 'l1_Layer_3': 0.008979494281502954, 'l1_Layer_4': 0.001693395386167594, 'n_units_Layer_1': 125, 'n_units_Layer_2': 300, 'n_units_Layer_3': 255, 'n_units_Layer_4': 145}. Best is trial 221 with value: 6.674896464902816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.07 | sMAPE for Validation Set is: 17.35% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.97 | sMAPE for Test Set is: 17.65% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:05:29,040]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:05:36,718]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:05:39,452]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:05:42,482]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:05:48,111]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:05:53,027]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:05:58,503]\u001b[0m Trial 274 finished with value: 10.512729320437327 and parameters: {'n_hidden': 3, 'learning_rate': 0.008745093614685855, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1912131508627298, 'dropout_rate_Layer_2': 0.3339059395889781, 'dropout_rate_Layer_3': 0.24431078528477737, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004167443517983838, 'l1_Layer_2': 3.1063038620610864e-05, 'l1_Layer_3': 0.0871126920259873, 'n_units_Layer_1': 245, 'n_units_Layer_2': 180, 'n_units_Layer_3': 250}. Best is trial 221 with value: 6.674896464902816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.51 | sMAPE for Validation Set is: 25.15% | rMAE for Validation Set is: 1.00\n",
      "MAE for Test Set is: 6.84 | sMAPE for Test Set is: 19.89% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:06:02,848]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:06:03,465]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:06:12,312]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:06:14,169]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:06:17,740]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:06:18,016]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:06:22,632]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:06:29,302]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:06:33,356]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:06:33,497]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:06:36,563]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:06:43,250]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:06:46,787]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:06:46,934]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:06:55,683]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:07:01,924]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:07:02,075]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:07:07,239]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:07:11,858]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:07:12,789]\u001b[0m Trial 290 finished with value: 7.046819152192697 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012294153063239677, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10302850607099602, 'dropout_rate_Layer_2': 0.34574096831470164, 'dropout_rate_Layer_3': 0.01756479069849262, 'dropout_rate_Layer_4': 0.3485611277970422, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 8.770074086773004e-05, 'l1_Layer_2': 0.050841842697992815, 'l1_Layer_3': 0.0048277216793457724, 'l1_Layer_4': 0.00558703720336438, 'n_units_Layer_1': 110, 'n_units_Layer_2': 285, 'n_units_Layer_3': 240, 'n_units_Layer_4': 150}. Best is trial 221 with value: 6.674896464902816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.05 | sMAPE for Validation Set is: 17.34% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.95 | sMAPE for Test Set is: 17.62% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:07:33,036]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:07:34,970]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:07:40,674]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:07:48,292]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.92 | sMAPE for Validation Set is: 19.36% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 6.73 | sMAPE for Test Set is: 19.42% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:07:52,218]\u001b[0m Trial 300 finished with value: 7.916376660753673 and parameters: {'n_hidden': 4, 'learning_rate': 0.04674307680788484, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.046247632789929896, 'dropout_rate_Layer_2': 0.3792103013099947, 'dropout_rate_Layer_3': 0.284438192836385, 'dropout_rate_Layer_4': 0.1868402720056005, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0031478477551351966, 'l1_Layer_2': 2.3133376509571998e-05, 'l1_Layer_3': 0.0002692819505422293, 'l1_Layer_4': 0.015436265143634526, 'n_units_Layer_1': 300, 'n_units_Layer_2': 300, 'n_units_Layer_3': 70, 'n_units_Layer_4': 135}. Best is trial 221 with value: 6.674896464902816.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:07:53,140]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:08:03,206]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:08:10,608]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:08:16,171]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:08:22,482]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:08:26,992]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:08:28,853]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:08:33,836]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:08:40,935]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:08:52,830]\u001b[0m Trial 309 finished with value: 7.109542348193943 and parameters: {'n_hidden': 4, 'learning_rate': 0.0021965198138026686, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19111459291688704, 'dropout_rate_Layer_2': 0.3492365275837819, 'dropout_rate_Layer_3': 0.21161064652904588, 'dropout_rate_Layer_4': 0.36709036540707335, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.2742965561045651e-05, 'l1_Layer_2': 0.03180592441837997, 'l1_Layer_3': 0.006057176784367966, 'l1_Layer_4': 0.0007183614758304425, 'n_units_Layer_1': 105, 'n_units_Layer_2': 275, 'n_units_Layer_3': 225, 'n_units_Layer_4': 195}. Best is trial 221 with value: 6.674896464902816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.11 | sMAPE for Validation Set is: 17.55% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.93 | sMAPE for Test Set is: 17.62% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:08:58,649]\u001b[0m Trial 303 finished with value: 7.811823306638657 and parameters: {'n_hidden': 4, 'learning_rate': 0.002607249011348933, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.013014228395068134, 'dropout_rate_Layer_2': 0.05431618534439122, 'dropout_rate_Layer_3': 0.3736547898832861, 'dropout_rate_Layer_4': 0.23766547443044117, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.014972723898387e-05, 'l1_Layer_2': 0.0021367346013043127, 'l1_Layer_3': 0.00667494322618407, 'l1_Layer_4': 0.00018228657807726936, 'n_units_Layer_1': 115, 'n_units_Layer_2': 215, 'n_units_Layer_3': 280, 'n_units_Layer_4': 295}. Best is trial 221 with value: 6.674896464902816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.81 | sMAPE for Validation Set is: 19.27% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 6.87 | sMAPE for Test Set is: 20.03% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:09:03,084]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:09:17,615]\u001b[0m Trial 315 finished with value: 6.981559616320626 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013347894542509607, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09127432810280796, 'dropout_rate_Layer_2': 0.015568566603653302, 'dropout_rate_Layer_3': 0.013562757293787135, 'dropout_rate_Layer_4': 0.3353801693941304, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.633442811239703e-05, 'l1_Layer_2': 0.038412725095964044, 'l1_Layer_3': 0.00676419741956713, 'l1_Layer_4': 0.0013874114132363688, 'n_units_Layer_1': 130, 'n_units_Layer_2': 290, 'n_units_Layer_3': 265, 'n_units_Layer_4': 145}. Best is trial 221 with value: 6.674896464902816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.98 | sMAPE for Validation Set is: 17.24% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.83 | sMAPE for Test Set is: 17.42% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:09:21,490]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:09:28,106]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:09:36,880]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:09:42,827]\u001b[0m Trial 320 finished with value: 6.988210970658386 and parameters: {'n_hidden': 4, 'learning_rate': 0.002158049142189269, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17644205589209283, 'dropout_rate_Layer_2': 0.37517830146989456, 'dropout_rate_Layer_3': 0.07079427495943241, 'dropout_rate_Layer_4': 0.36808063738904934, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.2639416226169305e-05, 'l1_Layer_2': 0.023939082423268185, 'l1_Layer_3': 4.039405415702708e-05, 'l1_Layer_4': 0.001479134819359865, 'n_units_Layer_1': 90, 'n_units_Layer_2': 275, 'n_units_Layer_3': 225, 'n_units_Layer_4': 205}. Best is trial 221 with value: 6.674896464902816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.99 | sMAPE for Validation Set is: 17.33% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.83 | sMAPE for Test Set is: 17.47% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:09:45,824]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:09:55,200]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:09:58,783]\u001b[0m Trial 319 finished with value: 6.620745374818422 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017230142990759861, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1658340381022845, 'dropout_rate_Layer_2': 0.2485458592357299, 'dropout_rate_Layer_3': 0.32624339287453963, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003132005409393824, 'l1_Layer_2': 9.14916052265951e-05, 'l1_Layer_3': 0.0013211359508008657, 'n_units_Layer_1': 230, 'n_units_Layer_2': 225, 'n_units_Layer_3': 300}. Best is trial 319 with value: 6.620745374818422.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.62 | sMAPE for Validation Set is: 16.35% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.80 | sMAPE for Test Set is: 17.41% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:10:02,954]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:10:08,527]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:10:15,012]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:10:18,592]\u001b[0m Trial 317 finished with value: 8.04651601227524 and parameters: {'n_hidden': 4, 'learning_rate': 0.00280644586621782, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29122486004213005, 'dropout_rate_Layer_2': 0.04127546548012045, 'dropout_rate_Layer_3': 0.3970389896794266, 'dropout_rate_Layer_4': 0.22683696645084972, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.2836086732170776e-05, 'l1_Layer_2': 0.0034406232361284374, 'l1_Layer_3': 0.006243051712281465, 'l1_Layer_4': 0.0002413246453370272, 'n_units_Layer_1': 195, 'n_units_Layer_2': 220, 'n_units_Layer_3': 280, 'n_units_Layer_4': 195}. Best is trial 319 with value: 6.620745374818422.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.05 | sMAPE for Validation Set is: 20.09% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 6.24 | sMAPE for Test Set is: 18.78% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:10:28,817]\u001b[0m Trial 327 finished with value: 6.459078235368711 and parameters: {'n_hidden': 3, 'learning_rate': 0.00185655977828923, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1720220180407132, 'dropout_rate_Layer_2': 0.24209742025382658, 'dropout_rate_Layer_3': 0.33010040531057455, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00047441386279152044, 'l1_Layer_2': 0.00010011319349967427, 'l1_Layer_3': 0.0015936610779710022, 'n_units_Layer_1': 230, 'n_units_Layer_2': 225, 'n_units_Layer_3': 300}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.46 | sMAPE for Validation Set is: 16.15% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.82 | sMAPE for Test Set is: 17.67% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:10:40,927]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:11:13,838]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:11:26,004]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:11:36,558]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:12:07,815]\u001b[0m Trial 335 finished with value: 6.947986326151053 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011578385136952337, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18317396332309538, 'dropout_rate_Layer_2': 0.014899761493610473, 'dropout_rate_Layer_3': 0.053216665597016516, 'dropout_rate_Layer_4': 0.35497470426769595, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.6433145003965053e-05, 'l1_Layer_2': 0.031244387980646566, 'l1_Layer_3': 0.00800935120977052, 'l1_Layer_4': 0.001212164734387608, 'n_units_Layer_1': 105, 'n_units_Layer_2': 290, 'n_units_Layer_3': 225, 'n_units_Layer_4': 215}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.95 | sMAPE for Validation Set is: 17.27% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.85 | sMAPE for Test Set is: 17.53% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:12:08,348]\u001b[0m Trial 328 finished with value: 7.788328161488253 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010966615940640942, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02605270266014667, 'dropout_rate_Layer_2': 0.12547094574545675, 'dropout_rate_Layer_3': 0.23635240960497245, 'dropout_rate_Layer_4': 0.2161819290207514, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.2620509087658965e-05, 'l1_Layer_2': 0.004141204398395355, 'l1_Layer_3': 0.0057210579688283395, 'l1_Layer_4': 0.0001685720876946116, 'n_units_Layer_1': 100, 'n_units_Layer_2': 215, 'n_units_Layer_3': 285, 'n_units_Layer_4': 295}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.79 | sMAPE for Validation Set is: 19.12% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 6.56 | sMAPE for Test Set is: 19.59% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:12:14,067]\u001b[0m Trial 334 finished with value: 7.582037753719192 and parameters: {'n_hidden': 4, 'learning_rate': 0.002454174797520541, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.028595169814004534, 'dropout_rate_Layer_2': 0.051974058928930256, 'dropout_rate_Layer_3': 0.3638822111541077, 'dropout_rate_Layer_4': 0.2276804586445651, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.0325339776484954e-05, 'l1_Layer_2': 0.004568900454832907, 'l1_Layer_3': 0.008798490396399676, 'l1_Layer_4': 0.00021286391617933507, 'n_units_Layer_1': 100, 'n_units_Layer_2': 215, 'n_units_Layer_3': 285, 'n_units_Layer_4': 300}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.58 | sMAPE for Validation Set is: 18.70% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 6.44 | sMAPE for Test Set is: 18.96% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:12:16,733]\u001b[0m Trial 337 finished with value: 6.9375523083525215 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018881100382633078, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17720582074248642, 'dropout_rate_Layer_2': 0.0013833496754838241, 'dropout_rate_Layer_3': 0.06565322055765871, 'dropout_rate_Layer_4': 0.3539127938546883, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.4592862534545593e-05, 'l1_Layer_2': 0.03143339276743997, 'l1_Layer_3': 0.007901286875884839, 'l1_Layer_4': 0.0010167221663206765, 'n_units_Layer_1': 100, 'n_units_Layer_2': 290, 'n_units_Layer_3': 230, 'n_units_Layer_4': 50}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.94 | sMAPE for Validation Set is: 17.25% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.91 | sMAPE for Test Set is: 17.68% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:12:20,200]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:12:20,910]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:12:24,850]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:12:25,593]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:12:31,974]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:12:33,521]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:12:40,211]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:12:48,022]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:12:50,886]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:12:58,710]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:13:27,047]\u001b[0m Trial 343 finished with value: 7.934517728851714 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015526587684058207, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.004316687017710066, 'dropout_rate_Layer_2': 0.12256798461852826, 'dropout_rate_Layer_3': 0.14718624361280402, 'dropout_rate_Layer_4': 0.2975937068741646, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.8408685644417275e-05, 'l1_Layer_2': 0.005906047908138186, 'l1_Layer_3': 0.008246549753022723, 'l1_Layer_4': 5.148412524710767e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 200, 'n_units_Layer_3': 285, 'n_units_Layer_4': 300}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.93 | sMAPE for Validation Set is: 19.67% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 6.54 | sMAPE for Test Set is: 19.41% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:13:32,083]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:13:36,387]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:13:39,469]\u001b[0m Trial 342 finished with value: 8.41282510355198 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011296518007765405, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006145809655630025, 'dropout_rate_Layer_2': 0.12289228468536662, 'dropout_rate_Layer_3': 0.1447113760217081, 'dropout_rate_Layer_4': 0.2996378111215632, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.884924859542193e-05, 'l1_Layer_2': 0.006799673822071751, 'l1_Layer_3': 0.00928721400690298, 'l1_Layer_4': 6.680049261981897e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 205, 'n_units_Layer_3': 290, 'n_units_Layer_4': 300}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.41 | sMAPE for Validation Set is: 21.15% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 6.67 | sMAPE for Test Set is: 20.15% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:13:43,315]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:13:49,422]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:13:55,268]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:13:55,353]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:14:06,435]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:14:06,930]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:14:15,834]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:14:16,856]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:14:22,926]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:14:26,228]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:14:28,386]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:14:46,631]\u001b[0m Trial 355 finished with value: 6.575570849946092 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013190335569052232, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16302144170941907, 'dropout_rate_Layer_2': 0.3267226790012261, 'dropout_rate_Layer_3': 0.3033176649333324, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003573553366018201, 'l1_Layer_2': 0.017369937367614573, 'l1_Layer_3': 0.0002444011131437876, 'n_units_Layer_1': 160, 'n_units_Layer_2': 145, 'n_units_Layer_3': 285}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.58 | sMAPE for Validation Set is: 16.49% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.68 | sMAPE for Test Set is: 17.12% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:14:51,597]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:14:55,832]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:14:55,973]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:14:56,909]\u001b[0m Trial 366 finished with value: 6.6326452967913 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025432980184067235, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13530825954913966, 'dropout_rate_Layer_2': 0.2632802588175113, 'dropout_rate_Layer_3': 0.35194795239251603, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.507813664988008e-05, 'l1_Layer_2': 2.6252632764478183e-05, 'l1_Layer_3': 0.0015114855327114267, 'n_units_Layer_1': 260, 'n_units_Layer_2': 215, 'n_units_Layer_3': 275}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.63 | sMAPE for Validation Set is: 16.79% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.94 | sMAPE for Test Set is: 18.13% | rMAE for Test Set is: 0.73\n",
      "MAE for Validation Set is: 8.07 | sMAPE for Validation Set is: 20.20% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 6.60 | sMAPE for Test Set is: 20.12% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:15:03,444]\u001b[0m Trial 351 finished with value: 8.066115928896922 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009893932192468773, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.002355791459428866, 'dropout_rate_Layer_2': 0.11794035008260437, 'dropout_rate_Layer_3': 0.22975039347261547, 'dropout_rate_Layer_4': 0.3008620817323638, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.748690860002289e-05, 'l1_Layer_2': 0.007057165822604338, 'l1_Layer_3': 0.010846306046407446, 'l1_Layer_4': 5.6622376776713244e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 205, 'n_units_Layer_3': 290, 'n_units_Layer_4': 300}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:15:07,131]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:15:21,067]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:15:23,863]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:15:31,871]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:15:39,621]\u001b[0m Trial 369 finished with value: 6.9931417980762385 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017523446570405176, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1632823354528796, 'dropout_rate_Layer_2': 0.38139377725735263, 'dropout_rate_Layer_3': 0.09790291370728718, 'dropout_rate_Layer_4': 0.3576141165583633, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.6235073345514232e-05, 'l1_Layer_2': 0.03758513275485985, 'l1_Layer_3': 0.007869526329893458, 'l1_Layer_4': 0.0013252074176284946, 'n_units_Layer_1': 105, 'n_units_Layer_2': 295, 'n_units_Layer_3': 230, 'n_units_Layer_4': 205}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.99 | sMAPE for Validation Set is: 17.34% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.90 | sMAPE for Test Set is: 17.60% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:15:43,132]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:15:45,270]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:15:50,923]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:15:52,767]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:15:58,128]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:15:58,222]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:16:05,847]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:16:06,641]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:16:12,023]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:16:42,100]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:17:03,540]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:17:08,319]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:17:10,740]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:17:15,574]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:17:19,950]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:17:36,058]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:17:40,631]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:17:44,156]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:17:45,114]\u001b[0m Trial 392 finished with value: 9.194081136665309 and parameters: {'n_hidden': 4, 'learning_rate': 0.001786766027624655, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12006274470453322, 'dropout_rate_Layer_2': 0.09420654710219437, 'dropout_rate_Layer_3': 0.36473753483703797, 'dropout_rate_Layer_4': 0.3793246301981665, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.643719788485026e-05, 'l1_Layer_2': 0.0009111357365420215, 'l1_Layer_3': 0.000542232177041751, 'l1_Layer_4': 9.883682704791904e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 230, 'n_units_Layer_3': 145, 'n_units_Layer_4': 225}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.19 | sMAPE for Validation Set is: 22.19% | rMAE for Validation Set is: 0.87\n",
      "MAE for Test Set is: 6.43 | sMAPE for Test Set is: 19.10% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:17:58,064]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:18:05,047]\u001b[0m Trial 384 finished with value: 7.781416054664376 and parameters: {'n_hidden': 4, 'learning_rate': 0.0036777862420385105, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04538751150828041, 'dropout_rate_Layer_2': 0.0636734717995959, 'dropout_rate_Layer_3': 0.31205725007977664, 'dropout_rate_Layer_4': 0.22548028405012505, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.0111644436806082e-05, 'l1_Layer_2': 0.013168127853916776, 'l1_Layer_3': 0.031475846630220884, 'l1_Layer_4': 0.002402902285910572, 'n_units_Layer_1': 70, 'n_units_Layer_2': 220, 'n_units_Layer_3': 195, 'n_units_Layer_4': 255}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.78 | sMAPE for Validation Set is: 19.17% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 6.68 | sMAPE for Test Set is: 19.48% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:18:05,911]\u001b[0m Trial 390 finished with value: 7.006970357149005 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013320969304781308, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1820057498227408, 'dropout_rate_Layer_2': 0.3683229644453708, 'dropout_rate_Layer_3': 0.09693282519417848, 'dropout_rate_Layer_4': 0.3604164294033383, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.818580101207472e-05, 'l1_Layer_2': 0.03975993204485515, 'l1_Layer_3': 0.006864055987069199, 'l1_Layer_4': 0.0017326650225282143, 'n_units_Layer_1': 105, 'n_units_Layer_2': 295, 'n_units_Layer_3': 225, 'n_units_Layer_4': 210}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.01 | sMAPE for Validation Set is: 17.34% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.02 | sMAPE for Test Set is: 17.82% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:18:12,766]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:18:13,048]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:18:19,331]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:18:23,593]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:18:24,079]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:18:26,775]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:18:30,568]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:18:35,077]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:18:37,115]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:18:39,013]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:18:44,811]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:18:53,367]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:18:57,780]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:19:06,527]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:19:12,428]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:19:16,943]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:19:24,655]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:19:28,752]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:19:30,392]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:19:31,370]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:19:36,706]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:19:36,770]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:19:40,726]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:19:42,314]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:19:48,949]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:19:53,134]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:19:54,794]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:19:55,226]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:19:57,722]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:20:02,373]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:20:08,811]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:20:14,088]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:20:19,521]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:20:23,702]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:20:52,013]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:20:55,891]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:21:05,015]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:21:11,803]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:21:22,546]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:21:37,072]\u001b[0m Trial 425 finished with value: 7.868060727272618 and parameters: {'n_hidden': 4, 'learning_rate': 0.004677479233389604, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08704358674272922, 'dropout_rate_Layer_2': 0.19747258626793548, 'dropout_rate_Layer_3': 0.21684445899214988, 'dropout_rate_Layer_4': 0.1727324297672431, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 6.703083731143278e-05, 'l1_Layer_2': 0.0015304464013217373, 'l1_Layer_3': 0.014338461680214026, 'l1_Layer_4': 0.0004698082441384583, 'n_units_Layer_1': 110, 'n_units_Layer_2': 215, 'n_units_Layer_3': 195, 'n_units_Layer_4': 280}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.87 | sMAPE for Validation Set is: 19.09% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 7.17 | sMAPE for Test Set is: 20.33% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:21:50,238]\u001b[0m Trial 427 finished with value: 7.092051285969255 and parameters: {'n_hidden': 3, 'learning_rate': 0.014396900899365617, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2762834713866456, 'dropout_rate_Layer_2': 0.37252503744719073, 'dropout_rate_Layer_3': 0.17074530805001226, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3511206660577734e-05, 'l1_Layer_2': 2.248042573943308e-05, 'l1_Layer_3': 8.747659307257946e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 70, 'n_units_Layer_3': 125}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.09 | sMAPE for Validation Set is: 17.45% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.43 | sMAPE for Test Set is: 18.95% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:22:01,868]\u001b[0m Trial 435 finished with value: 7.064733297935855 and parameters: {'n_hidden': 4, 'learning_rate': 0.001112768550727313, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17293091186624515, 'dropout_rate_Layer_2': 0.009415157487553089, 'dropout_rate_Layer_3': 0.21668941631272598, 'dropout_rate_Layer_4': 0.34692465748172013, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0009470202807792317, 'l1_Layer_2': 0.05791339056241057, 'l1_Layer_3': 0.014439526303515247, 'l1_Layer_4': 0.0022158315482902046, 'n_units_Layer_1': 80, 'n_units_Layer_2': 285, 'n_units_Layer_3': 210, 'n_units_Layer_4': 205}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.06 | sMAPE for Validation Set is: 17.35% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.93 | sMAPE for Test Set is: 17.59% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:22:06,948]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:22:15,909]\u001b[0m Trial 438 finished with value: 7.040318491738602 and parameters: {'n_hidden': 4, 'learning_rate': 0.001387576939154089, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17322185785131414, 'dropout_rate_Layer_2': 0.011747557443422617, 'dropout_rate_Layer_3': 0.2051600311418959, 'dropout_rate_Layer_4': 0.3472502498590023, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0017178618678930085, 'l1_Layer_2': 0.06002770268742506, 'l1_Layer_3': 0.01488014587703462, 'l1_Layer_4': 0.000323832615797976, 'n_units_Layer_1': 80, 'n_units_Layer_2': 285, 'n_units_Layer_3': 210, 'n_units_Layer_4': 215}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.04 | sMAPE for Validation Set is: 17.54% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.89 | sMAPE for Test Set is: 17.70% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:22:19,743]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:22:28,300]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:22:28,743]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:22:36,117]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:22:36,578]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:22:45,781]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:22:55,702]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:23:17,740]\u001b[0m Trial 440 finished with value: 7.038133022851782 and parameters: {'n_hidden': 4, 'learning_rate': 0.0023707703600553778, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20396658586318794, 'dropout_rate_Layer_2': 0.007578432145400873, 'dropout_rate_Layer_3': 0.010871786413395756, 'dropout_rate_Layer_4': 0.34592962903114544, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.2019880412486614e-05, 'l1_Layer_2': 0.05805798167692966, 'l1_Layer_3': 2.289788047679577e-05, 'l1_Layer_4': 0.001348563683574914, 'n_units_Layer_1': 80, 'n_units_Layer_2': 285, 'n_units_Layer_3': 265, 'n_units_Layer_4': 50}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:23:17,898]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.04 | sMAPE for Validation Set is: 17.45% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.87 | sMAPE for Test Set is: 17.69% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:23:24,170]\u001b[0m Trial 443 finished with value: 8.046034616203059 and parameters: {'n_hidden': 3, 'learning_rate': 0.01621405251751579, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01052724565616924, 'dropout_rate_Layer_2': 0.08449366150140644, 'dropout_rate_Layer_3': 0.18360451095008232, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.8831026985070167e-05, 'l1_Layer_2': 7.107072480004624e-05, 'l1_Layer_3': 1.4704055231234703e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 220, 'n_units_Layer_3': 150}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.05 | sMAPE for Validation Set is: 20.23% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 6.72 | sMAPE for Test Set is: 19.96% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:23:25,112]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:23:30,217]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:23:30,476]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:23:32,433]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:23:41,126]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:23:42,839]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:23:48,385]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:23:55,910]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:24:57,612]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:25:13,198]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:25:35,319]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:25:42,931]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:26:04,093]\u001b[0m Trial 461 finished with value: 8.33416337662347 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012231971867947245, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02468124221640216, 'dropout_rate_Layer_2': 0.10340842590984062, 'dropout_rate_Layer_3': 0.33189043376542865, 'dropout_rate_Layer_4': 0.23155563393975562, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.529552809948662e-05, 'l1_Layer_2': 0.012145864951873296, 'l1_Layer_3': 0.004775679493317225, 'l1_Layer_4': 0.010934758134513398, 'n_units_Layer_1': 150, 'n_units_Layer_2': 165, 'n_units_Layer_3': 90, 'n_units_Layer_4': 225}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.33 | sMAPE for Validation Set is: 19.85% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 7.62 | sMAPE for Test Set is: 20.97% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:26:09,946]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:26:17,136]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:26:19,562]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:26:22,702]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:26:25,570]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:27:05,550]\u001b[0m Trial 465 finished with value: 8.035683528071674 and parameters: {'n_hidden': 4, 'learning_rate': 0.0069441436666549785, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06191338390454417, 'dropout_rate_Layer_2': 0.11689572612412974, 'dropout_rate_Layer_3': 0.2921681933937503, 'dropout_rate_Layer_4': 0.3485571405053337, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.2655588572978616e-05, 'l1_Layer_2': 0.061296954242723474, 'l1_Layer_3': 0.0553620939839228, 'l1_Layer_4': 3.2179428859280646e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 275, 'n_units_Layer_3': 270, 'n_units_Layer_4': 300}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.04 | sMAPE for Validation Set is: 19.35% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 6.97 | sMAPE for Test Set is: 19.79% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:27:08,010]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:27:13,796]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:27:14,293]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:27:21,701]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:27:26,924]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:27:34,146]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.87 | sMAPE for Validation Set is: 16.88% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.08 | sMAPE for Test Set is: 17.81% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:27:36,138]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:27:36,160]\u001b[0m Trial 471 finished with value: 6.865344992363252 and parameters: {'n_hidden': 3, 'learning_rate': 0.005633403564816699, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0357326859709436, 'dropout_rate_Layer_2': 0.13023385406681273, 'dropout_rate_Layer_3': 0.1805158785456652, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.681798154126341e-05, 'l1_Layer_2': 0.00023888725535657423, 'l1_Layer_3': 1.942383218151771e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 215, 'n_units_Layer_3': 150}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:27:40,830]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:27:52,946]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:27:55,873]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:27:59,206]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:28:12,156]\u001b[0m Trial 455 finished with value: 8.625806837818919 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010990478267566457, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.027913318758565106, 'dropout_rate_Layer_2': 0.10661280906058904, 'dropout_rate_Layer_3': 0.3263544159736461, 'dropout_rate_Layer_4': 0.21906921953389108, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 2.4106155722762724e-05, 'l1_Layer_2': 0.011535567409143518, 'l1_Layer_3': 0.004909147397784931, 'l1_Layer_4': 0.005635075403840683, 'n_units_Layer_1': 155, 'n_units_Layer_2': 240, 'n_units_Layer_3': 100, 'n_units_Layer_4': 235}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.63 | sMAPE for Validation Set is: 20.79% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 6.94 | sMAPE for Test Set is: 20.03% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:28:15,310]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:28:15,961]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:28:21,069]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:28:25,373]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:28:27,130]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:28:30,531]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:28:31,668]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:28:36,006]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:28:37,209]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:28:39,134]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:28:44,493]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:28:47,071]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:28:51,078]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:28:55,356]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:28:55,699]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:29:03,048]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:29:08,238]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:29:11,875]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:29:12,561]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:29:16,725]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:29:22,443]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:29:24,178]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:29:28,082]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:29:29,552]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:29:34,048]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:29:39,771]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:29:43,648]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:29:48,164]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:29:54,016]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:30:15,331]\u001b[0m Trial 496 finished with value: 7.310328181002781 and parameters: {'n_hidden': 3, 'learning_rate': 0.0057136352037210885, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.016463306506152797, 'dropout_rate_Layer_2': 0.12273145343771522, 'dropout_rate_Layer_3': 0.03992991975424847, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.0007408112847355e-05, 'l1_Layer_2': 0.00015887932739976098, 'l1_Layer_3': 3.232906548621556e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 240, 'n_units_Layer_3': 140}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.31 | sMAPE for Validation Set is: 17.89% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 6.52 | sMAPE for Test Set is: 19.01% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:30:20,710]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:30:27,470]\u001b[0m Trial 508 finished with value: 7.220815443373257 and parameters: {'n_hidden': 3, 'learning_rate': 0.0059447598614665404, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02059935864600643, 'dropout_rate_Layer_2': 0.12082958750935832, 'dropout_rate_Layer_3': 0.16610421472963438, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.7418683917804355e-05, 'l1_Layer_2': 0.0008822211753616938, 'l1_Layer_3': 3.197942936913438e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 230, 'n_units_Layer_3': 145}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.22 | sMAPE for Validation Set is: 17.76% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 6.04 | sMAPE for Test Set is: 17.96% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:30:30,040]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:30:38,265]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:30:52,179]\u001b[0m Trial 509 finished with value: 7.043980093244567 and parameters: {'n_hidden': 3, 'learning_rate': 0.005879387794287883, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.014772853742722608, 'dropout_rate_Layer_2': 0.12264401081466128, 'dropout_rate_Layer_3': 0.11902472684268156, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.7263051300752e-05, 'l1_Layer_2': 0.00028490470811741214, 'l1_Layer_3': 3.183822621231924e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 220, 'n_units_Layer_3': 140}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.04 | sMAPE for Validation Set is: 17.34% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.82 | sMAPE for Test Set is: 17.47% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:31:05,658]\u001b[0m Trial 514 finished with value: 8.036706399899844 and parameters: {'n_hidden': 4, 'learning_rate': 0.005746364733141947, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1385121925498286, 'dropout_rate_Layer_2': 0.269244076272827, 'dropout_rate_Layer_3': 0.2653954339754503, 'dropout_rate_Layer_4': 0.1645554035764661, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00141850603983941, 'l1_Layer_2': 0.0019251895987799658, 'l1_Layer_3': 0.012971531229326592, 'l1_Layer_4': 0.00025136839104030595, 'n_units_Layer_1': 130, 'n_units_Layer_2': 215, 'n_units_Layer_3': 180, 'n_units_Layer_4': 285}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.04 | sMAPE for Validation Set is: 19.34% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 7.28 | sMAPE for Test Set is: 20.57% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:31:14,622]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:31:22,977]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:31:24,801]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:31:31,047]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:31:51,821]\u001b[0m Trial 520 finished with value: 7.039319791833781 and parameters: {'n_hidden': 3, 'learning_rate': 0.0058898659453183655, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.004401779192551785, 'dropout_rate_Layer_2': 0.12237647725407011, 'dropout_rate_Layer_3': 0.03961027448408188, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.1455383585759005e-05, 'l1_Layer_2': 0.0026578136493517574, 'l1_Layer_3': 4.67233776674961e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 235, 'n_units_Layer_3': 140}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.04 | sMAPE for Validation Set is: 17.48% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.04 | sMAPE for Test Set is: 17.99% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:31:55,871]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:32:00,238]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:32:00,886]\u001b[0m Trial 517 finished with value: 7.369632200042905 and parameters: {'n_hidden': 3, 'learning_rate': 0.006717509283341191, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.018557182994204082, 'dropout_rate_Layer_2': 0.11593729835671385, 'dropout_rate_Layer_3': 0.03583709094363413, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.0691832816750775e-05, 'l1_Layer_2': 0.0008083692763214042, 'l1_Layer_3': 1.7633791022757e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 235, 'n_units_Layer_3': 140}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.37 | sMAPE for Validation Set is: 18.05% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 6.06 | sMAPE for Test Set is: 18.01% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:32:06,037]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:32:17,874]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:32:28,973]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:32:35,236]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:32:38,452]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:32:41,796]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:32:46,306]\u001b[0m Trial 525 finished with value: 7.980163533083775 and parameters: {'n_hidden': 4, 'learning_rate': 0.003981555375004571, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00018139577262298034, 'dropout_rate_Layer_2': 0.1832302839893055, 'dropout_rate_Layer_3': 0.2106011648601145, 'dropout_rate_Layer_4': 0.10549084615862313, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00023420637332366868, 'l1_Layer_2': 0.0006468698647908249, 'l1_Layer_3': 0.007849026652269496, 'l1_Layer_4': 0.0012511269425677864, 'n_units_Layer_1': 90, 'n_units_Layer_2': 230, 'n_units_Layer_3': 55, 'n_units_Layer_4': 265}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.98 | sMAPE for Validation Set is: 19.47% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 6.76 | sMAPE for Test Set is: 19.57% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:32:54,046]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:33:03,496]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:33:05,192]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:33:11,797]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:33:19,582]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:33:24,411]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:33:34,276]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:33:37,321]\u001b[0m Trial 523 finished with value: 6.8774160709494305 and parameters: {'n_hidden': 3, 'learning_rate': 0.0037641226554819235, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.020147426688384977, 'dropout_rate_Layer_2': 0.11769815465506464, 'dropout_rate_Layer_3': 0.17396990230820933, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2976086384246027e-05, 'l1_Layer_2': 0.000549356488573571, 'l1_Layer_3': 5.0233805733546925e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 215, 'n_units_Layer_3': 150}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.88 | sMAPE for Validation Set is: 16.80% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.63 | sMAPE for Test Set is: 16.89% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:33:52,246]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:34:00,547]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:34:25,586]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:34:29,123]\u001b[0m Trial 534 finished with value: 7.251862684464986 and parameters: {'n_hidden': 3, 'learning_rate': 0.006988645815354029, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02296817906682963, 'dropout_rate_Layer_2': 0.1456980471871477, 'dropout_rate_Layer_3': 0.13811422299490356, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.586525851151674e-05, 'l1_Layer_2': 0.0012670438265193257, 'l1_Layer_3': 3.546147969718369e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 245, 'n_units_Layer_3': 150}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.25 | sMAPE for Validation Set is: 17.62% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 6.12 | sMAPE for Test Set is: 17.92% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:34:34,986]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.51 | sMAPE for Validation Set is: 18.51% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 6.64 | sMAPE for Test Set is: 19.18% | rMAE for Test Set is: 0.82\n",
      "MAE for Validation Set is: 7.16 | sMAPE for Validation Set is: 17.51% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 5.64 | sMAPE for Test Set is: 16.90% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:34:58,499]\u001b[0m Trial 544 finished with value: 7.514357100159096 and parameters: {'n_hidden': 4, 'learning_rate': 0.002799134185380162, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10454942399907714, 'dropout_rate_Layer_2': 0.14106087295115272, 'dropout_rate_Layer_3': 0.16875304137215608, 'dropout_rate_Layer_4': 0.13064414589959789, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.061143403473952e-05, 'l1_Layer_2': 0.004717224520467072, 'l1_Layer_3': 0.06254108594886507, 'l1_Layer_4': 0.00010313061717727054, 'n_units_Layer_1': 110, 'n_units_Layer_2': 180, 'n_units_Layer_3': 225, 'n_units_Layer_4': 210}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:34:58,546]\u001b[0m Trial 538 finished with value: 7.164636416692751 and parameters: {'n_hidden': 3, 'learning_rate': 0.003600241500358769, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.034202374671749594, 'dropout_rate_Layer_2': 0.12082573663253453, 'dropout_rate_Layer_3': 0.0637470614992603, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.612587895064006e-05, 'l1_Layer_2': 0.0007473709521925883, 'l1_Layer_3': 2.468552543077145e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 215, 'n_units_Layer_3': 150}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:34:58,946]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:35:05,236]\u001b[0m Trial 547 finished with value: 7.152650108417319 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013185108000674617, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17908219850456442, 'dropout_rate_Layer_2': 0.04802672897536147, 'dropout_rate_Layer_3': 0.2330990546206693, 'dropout_rate_Layer_4': 0.3465048462554438, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0006644682109419306, 'l1_Layer_2': 0.05399858987274733, 'l1_Layer_3': 0.006675988384440985, 'l1_Layer_4': 0.00011545419424354067, 'n_units_Layer_1': 90, 'n_units_Layer_2': 270, 'n_units_Layer_3': 245, 'n_units_Layer_4': 200}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.15 | sMAPE for Validation Set is: 17.68% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 5.97 | sMAPE for Test Set is: 17.85% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:35:18,056]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:35:32,259]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:35:36,943]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:35:46,079]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:35:51,063]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:35:57,743]\u001b[0m Trial 553 finished with value: 7.184474329153695 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012958478717413472, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20735969958028788, 'dropout_rate_Layer_2': 0.022212478523551134, 'dropout_rate_Layer_3': 0.23564625463545172, 'dropout_rate_Layer_4': 0.3324529252606691, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000603529976682167, 'l1_Layer_2': 0.07053815292702464, 'l1_Layer_3': 0.007232030716801777, 'l1_Layer_4': 0.00012880007412179674, 'n_units_Layer_1': 90, 'n_units_Layer_2': 275, 'n_units_Layer_3': 245, 'n_units_Layer_4': 190}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.18 | sMAPE for Validation Set is: 17.84% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 5.95 | sMAPE for Test Set is: 17.82% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:36:09,720]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:36:15,277]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:36:20,966]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:36:21,962]\u001b[0m Trial 552 finished with value: 7.219255801761172 and parameters: {'n_hidden': 3, 'learning_rate': 0.003751531432170601, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.023735568970365748, 'dropout_rate_Layer_2': 0.09364927332103834, 'dropout_rate_Layer_3': 0.043852261423735106, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.107875851394687e-05, 'l1_Layer_2': 0.0009794049143708175, 'l1_Layer_3': 2.6260961800582838e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 230, 'n_units_Layer_3': 155}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.22 | sMAPE for Validation Set is: 17.67% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 6.15 | sMAPE for Test Set is: 17.99% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:36:29,047]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:36:34,684]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:36:40,393]\u001b[0m Trial 550 finished with value: 7.279943331162578 and parameters: {'n_hidden': 3, 'learning_rate': 0.003561103735457927, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02278089103625471, 'dropout_rate_Layer_2': 0.09489216701898331, 'dropout_rate_Layer_3': 0.16589320863737445, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.442700025578893e-05, 'l1_Layer_2': 0.0023503906563371382, 'l1_Layer_3': 3.600382264499006e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 230, 'n_units_Layer_3': 150}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.28 | sMAPE for Validation Set is: 17.86% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 6.03 | sMAPE for Test Set is: 17.90% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:36:41,019]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:36:46,078]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:36:46,765]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:36:51,709]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:36:53,527]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:36:55,268]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:36:59,322]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:37:06,249]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:37:11,887]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:37:15,639]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:37:18,313]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:37:24,970]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:37:30,363]\u001b[0m Trial 569 finished with value: 6.977651446154219 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011799552005363303, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22012871744809795, 'dropout_rate_Layer_2': 0.18480834641026608, 'dropout_rate_Layer_3': 0.23585565251500953, 'dropout_rate_Layer_4': 0.33530905193158744, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0007500568462564813, 'l1_Layer_2': 0.06696123291922296, 'l1_Layer_3': 0.00840008182702912, 'l1_Layer_4': 0.00012572505165942495, 'n_units_Layer_1': 95, 'n_units_Layer_2': 260, 'n_units_Layer_3': 235, 'n_units_Layer_4': 185}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.98 | sMAPE for Validation Set is: 17.27% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.91 | sMAPE for Test Set is: 17.65% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:37:37,761]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:37:41,894]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:37:50,223]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:38:24,406]\u001b[0m Trial 573 finished with value: 7.172378802772339 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035696295362717635, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03233398569506736, 'dropout_rate_Layer_2': 0.14337547929140293, 'dropout_rate_Layer_3': 0.15890350206455933, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010407242176294459, 'l1_Layer_2': 0.003254366746092957, 'l1_Layer_3': 5.4964929859084e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 230, 'n_units_Layer_3': 135}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.17 | sMAPE for Validation Set is: 17.52% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 5.85 | sMAPE for Test Set is: 17.49% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:38:30,148]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:38:33,709]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:38:34,063]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:38:36,199]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:38:41,370]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:38:46,200]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:38:50,699]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:38:55,365]\u001b[0m Trial 578 finished with value: 6.928132674757328 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036606555212484564, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05125033378029073, 'dropout_rate_Layer_2': 0.12244448262884801, 'dropout_rate_Layer_3': 0.034180764165300276, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.577861037154041e-05, 'l1_Layer_2': 0.0008701254555516678, 'l1_Layer_3': 3.2457075068455275e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 230, 'n_units_Layer_3': 170}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.93 | sMAPE for Validation Set is: 17.12% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.81 | sMAPE for Test Set is: 17.48% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:39:00,086]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:39:04,355]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:39:10,960]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:39:21,803]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:39:23,641]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:39:29,448]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:39:33,569]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:39:34,166]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:39:40,110]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:39:44,813]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:39:48,440]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:39:50,122]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:39:54,995]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:40:06,275]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:40:11,490]\u001b[0m Trial 594 finished with value: 7.105360139734919 and parameters: {'n_hidden': 4, 'learning_rate': 0.001458880420997235, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18736152827950409, 'dropout_rate_Layer_2': 0.1559105535501139, 'dropout_rate_Layer_3': 0.2616062357214934, 'dropout_rate_Layer_4': 0.37284545793700785, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.1740062688481796e-05, 'l1_Layer_2': 2.0945522136017e-05, 'l1_Layer_3': 0.011307167661436787, 'l1_Layer_4': 0.0013786589585216484, 'n_units_Layer_1': 105, 'n_units_Layer_2': 295, 'n_units_Layer_3': 260, 'n_units_Layer_4': 150}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.11 | sMAPE for Validation Set is: 17.54% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.90 | sMAPE for Test Set is: 17.55% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:40:16,505]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:40:17,332]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:40:20,340]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:40:28,114]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:40:34,574]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:40:56,094]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:40:58,548]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:40:59,654]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:41:06,123]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:41:08,489]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:41:17,978]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:41:24,632]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:41:28,404]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:41:38,871]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:41:43,134]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:41:48,924]\u001b[0m Trial 611 finished with value: 7.22394341051065 and parameters: {'n_hidden': 3, 'learning_rate': 0.004923280300862026, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04142945302150775, 'dropout_rate_Layer_2': 0.09362293270891849, 'dropout_rate_Layer_3': 0.03576525543880767, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014285904532241033, 'l1_Layer_2': 0.0006223843954326838, 'l1_Layer_3': 1.2614224686870045e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 235, 'n_units_Layer_3': 170}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.22 | sMAPE for Validation Set is: 17.69% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 6.01 | sMAPE for Test Set is: 17.71% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:41:50,560]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:41:57,173]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:42:02,222]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:42:12,559]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:42:24,942]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:42:31,314]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:42:36,295]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:42:46,095]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:42:46,600]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:42:46,881]\u001b[0m Trial 627 finished with value: 6.72292441867937 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014933269115008617, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16516767518275638, 'dropout_rate_Layer_2': 0.2792514575612525, 'dropout_rate_Layer_3': 0.2348229726097614, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012659409349284284, 'l1_Layer_2': 1.9781452533023918e-05, 'l1_Layer_3': 0.0008416352136474873, 'n_units_Layer_1': 290, 'n_units_Layer_2': 190, 'n_units_Layer_3': 275}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.72 | sMAPE for Validation Set is: 16.74% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.70 | sMAPE for Test Set is: 17.36% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:42:49,238]\u001b[0m Trial 622 finished with value: 7.468938007190462 and parameters: {'n_hidden': 3, 'learning_rate': 0.004281922619869965, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03206050666137782, 'dropout_rate_Layer_2': 0.10797602031355444, 'dropout_rate_Layer_3': 0.1355863474986149, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.549616196095044e-05, 'l1_Layer_2': 0.001616035759540276, 'l1_Layer_3': 1.1392205573253858e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 240, 'n_units_Layer_3': 165}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.47 | sMAPE for Validation Set is: 18.25% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 6.21 | sMAPE for Test Set is: 18.28% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:42:55,767]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:42:58,225]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:43:01,259]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:43:01,557]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:43:11,373]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:43:41,876]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:43:49,329]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:43:53,645]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:43:56,344]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:44:00,342]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:44:05,806]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:44:09,118]\u001b[0m Trial 631 finished with value: 7.528269145431019 and parameters: {'n_hidden': 3, 'learning_rate': 0.003158308544759437, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06111486652877089, 'dropout_rate_Layer_2': 0.07503376923127607, 'dropout_rate_Layer_3': 0.06810071802689442, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.518116089413704e-05, 'l1_Layer_2': 0.0016319210068679998, 'l1_Layer_3': 1.91022576315549e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 240, 'n_units_Layer_3': 165}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.53 | sMAPE for Validation Set is: 18.42% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 6.34 | sMAPE for Test Set is: 18.70% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:44:16,664]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:44:30,535]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:44:36,287]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:44:42,447]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:44:51,278]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:44:56,152]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:45:04,412]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:45:04,423]\u001b[0m Trial 636 finished with value: 6.9822432616212895 and parameters: {'n_hidden': 3, 'learning_rate': 0.003052970623813569, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0056549606040320905, 'dropout_rate_Layer_2': 0.07136234778251796, 'dropout_rate_Layer_3': 0.02123550037717957, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.531290578771045e-05, 'l1_Layer_2': 0.0006806795731794259, 'l1_Layer_3': 2.1087221821079432e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 255, 'n_units_Layer_3': 180}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.98 | sMAPE for Validation Set is: 16.96% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.62 | sMAPE for Test Set is: 16.91% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:45:07,661]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:45:15,254]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:45:15,993]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:45:20,624]\u001b[0m Trial 646 finished with value: 7.048305384866352 and parameters: {'n_hidden': 3, 'learning_rate': 0.003977507499188216, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.040520721879828595, 'dropout_rate_Layer_2': 0.10674968460486665, 'dropout_rate_Layer_3': 0.13544097834660582, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.533818078550396e-05, 'l1_Layer_2': 0.0021038626945019644, 'l1_Layer_3': 1.3716147756836675e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 240, 'n_units_Layer_3': 160}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.05 | sMAPE for Validation Set is: 17.01% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.17 | sMAPE for Test Set is: 17.96% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:45:21,815]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:45:26,820]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:45:27,959]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:45:33,027]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:45:33,179]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:45:33,834]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:45:42,209]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:45:44,537]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:45:48,969]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:45:49,364]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:45:53,887]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:45:59,783]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:46:03,719]\u001b[0m Trial 653 finished with value: 7.0463370234207074 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012270044145690617, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17443931345420283, 'dropout_rate_Layer_2': 0.3593013077644688, 'dropout_rate_Layer_3': 0.18467514751842118, 'dropout_rate_Layer_4': 0.3289672222079496, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.003137664827744e-05, 'l1_Layer_2': 0.03682672502397774, 'l1_Layer_3': 0.004802931780956508, 'l1_Layer_4': 0.0007466814504677019, 'n_units_Layer_1': 85, 'n_units_Layer_2': 285, 'n_units_Layer_3': 270, 'n_units_Layer_4': 155}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.05 | sMAPE for Validation Set is: 17.32% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.07 | sMAPE for Test Set is: 17.86% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:46:16,676]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:46:20,393]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:46:22,672]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:46:28,587]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:46:33,704]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:46:38,461]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:46:53,977]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:47:00,717]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:47:06,961]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:47:14,373]\u001b[0m Trial 671 finished with value: 7.0375243130742495 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013372413891065591, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1672557027568687, 'dropout_rate_Layer_2': 0.35744546420948586, 'dropout_rate_Layer_3': 0.19844453426647213, 'dropout_rate_Layer_4': 0.31649284417483564, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.3926562260934895e-05, 'l1_Layer_2': 0.03426803616808501, 'l1_Layer_3': 0.0037581184218619572, 'l1_Layer_4': 0.0007366605712773766, 'n_units_Layer_1': 120, 'n_units_Layer_2': 285, 'n_units_Layer_3': 275, 'n_units_Layer_4': 160}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.04 | sMAPE for Validation Set is: 17.40% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.02 | sMAPE for Test Set is: 17.81% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:47:18,440]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:47:22,910]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:47:26,416]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:47:28,855]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:47:32,629]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:47:35,219]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:47:43,201]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:48:42,124]\u001b[0m Trial 677 finished with value: 7.58101952739712 and parameters: {'n_hidden': 3, 'learning_rate': 0.007636719489757564, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0003392029575373448, 'dropout_rate_Layer_2': 0.1360482170216885, 'dropout_rate_Layer_3': 0.0016700910516229406, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.9177819455121355e-05, 'l1_Layer_2': 0.004427559521363508, 'l1_Layer_3': 1.7338080456510438e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 225, 'n_units_Layer_3': 145}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.58 | sMAPE for Validation Set is: 18.53% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 5.85 | sMAPE for Test Set is: 17.38% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:48:45,725]\u001b[0m Trial 686 finished with value: 7.289406262205521 and parameters: {'n_hidden': 3, 'learning_rate': 0.006806823979085446, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.026846799486098378, 'dropout_rate_Layer_2': 0.1349465786132033, 'dropout_rate_Layer_3': 0.014474625131887908, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.5316224017141024e-05, 'l1_Layer_2': 0.000722685324269078, 'l1_Layer_3': 1.6830631265260086e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 225, 'n_units_Layer_3': 130}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.29 | sMAPE for Validation Set is: 17.96% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 6.09 | sMAPE for Test Set is: 17.99% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:48:48,577]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:48:51,558]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:48:55,385]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:48:59,924]\u001b[0m Trial 666 finished with value: 7.035192188093338 and parameters: {'n_hidden': 3, 'learning_rate': 0.002311724764615606, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.009717055460734043, 'dropout_rate_Layer_2': 0.19134497445200044, 'dropout_rate_Layer_3': 0.0005845952855387075, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.4855449789912535e-05, 'l1_Layer_2': 0.004362927042041104, 'l1_Layer_3': 1.3836892058943387e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 260, 'n_units_Layer_3': 190}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.04 | sMAPE for Validation Set is: 17.32% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.81 | sMAPE for Test Set is: 17.48% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:49:00,584]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:49:06,909]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:49:07,429]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.28 | sMAPE for Validation Set is: 17.75% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 6.35 | sMAPE for Test Set is: 18.44% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:49:10,813]\u001b[0m Trial 687 finished with value: 7.2842815479897025 and parameters: {'n_hidden': 3, 'learning_rate': 0.007846518959806733, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.026143543100552755, 'dropout_rate_Layer_2': 0.13453064179351343, 'dropout_rate_Layer_3': 0.011255539873980968, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.6672046087291776e-05, 'l1_Layer_2': 0.0012316017285357752, 'l1_Layer_3': 4.2867924109539286e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 225, 'n_units_Layer_3': 130}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:49:19,083]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:49:23,877]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:49:26,290]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:49:31,208]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:49:40,454]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:49:44,670]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:49:54,520]\u001b[0m Trial 702 finished with value: 17.025136242330188 and parameters: {'n_hidden': 3, 'learning_rate': 0.008113489810262494, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1590807241165475, 'dropout_rate_Layer_2': 0.09109527353241335, 'dropout_rate_Layer_3': 0.2273227894102611, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002843577412993319, 'l1_Layer_2': 0.008315960533398463, 'l1_Layer_3': 0.09721828408628885, 'n_units_Layer_1': 60, 'n_units_Layer_2': 75, 'n_units_Layer_3': 245}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.03 | sMAPE for Validation Set is: 41.95% | rMAE for Validation Set is: 1.61\n",
      "MAE for Test Set is: 10.90 | sMAPE for Test Set is: 31.05% | rMAE for Test Set is: 1.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:49:55,024]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:49:58,429]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:50:03,106]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:50:03,652]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:50:03,956]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:50:12,575]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:50:12,731]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:50:17,608]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:50:25,953]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:50:29,570]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:50:33,667]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:50:33,955]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:50:34,263]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:50:43,004]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:50:43,390]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:50:43,513]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:50:43,651]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:50:53,640]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:50:59,030]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:51:02,476]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:51:03,157]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:51:05,861]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:51:08,680]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:51:09,389]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:51:18,031]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:51:18,253]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:51:19,200]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:51:26,047]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:51:28,886]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:51:33,610]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:51:42,434]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:51:43,564]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:51:43,646]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:51:48,036]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:51:52,275]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:51:58,720]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:52:04,242]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:52:14,089]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:52:14,919]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:52:20,629]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:52:21,699]\u001b[0m Trial 730 finished with value: 8.036623931978887 and parameters: {'n_hidden': 4, 'learning_rate': 0.004279417771160716, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05825123357230999, 'dropout_rate_Layer_2': 0.07383449634640331, 'dropout_rate_Layer_3': 0.209602250476489, 'dropout_rate_Layer_4': 0.08608283340136902, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.0751224377737e-05, 'l1_Layer_2': 0.00027609571344605876, 'l1_Layer_3': 0.01055020223994067, 'l1_Layer_4': 3.824287634735677e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 120, 'n_units_Layer_3': 220, 'n_units_Layer_4': 165}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.04 | sMAPE for Validation Set is: 20.01% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 6.87 | sMAPE for Test Set is: 20.05% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:52:23,845]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:52:26,718]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:52:29,563]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:52:32,091]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:52:34,803]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:52:44,484]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:52:48,499]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:52:53,028]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:52:53,329]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:52:53,645]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:53:06,807]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:53:07,226]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:53:11,998]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:53:15,991]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:53:17,893]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:53:24,116]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:53:28,654]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:53:35,475]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:53:41,158]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:53:44,832]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:53:50,971]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:53:51,457]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:53:58,391]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:53:58,900]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:54:01,762]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:54:06,042]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:54:10,722]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:54:11,436]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:54:20,481]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:54:25,714]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:54:30,411]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:54:34,978]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:54:38,807]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:54:55,912]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:55:03,045]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:55:08,190]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.26 | sMAPE for Validation Set is: 17.78% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 5.89 | sMAPE for Test Set is: 17.35% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:55:10,032]\u001b[0m Trial 773 finished with value: 7.2591892020174 and parameters: {'n_hidden': 3, 'learning_rate': 0.0056854008710140545, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02104164078906467, 'dropout_rate_Layer_2': 0.13910182834247287, 'dropout_rate_Layer_3': 0.044854157394414645, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.6356691653919854e-05, 'l1_Layer_2': 0.0008097892024122937, 'l1_Layer_3': 3.408198881535305e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 240, 'n_units_Layer_3': 140}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:55:15,128]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:55:15,854]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:55:29,323]\u001b[0m Trial 770 finished with value: 7.166676222386751 and parameters: {'n_hidden': 3, 'learning_rate': 0.005773902308426967, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.018249779304345647, 'dropout_rate_Layer_2': 0.15440018471541112, 'dropout_rate_Layer_3': 0.04456024912249261, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.5426098623815203e-05, 'l1_Layer_2': 0.0007896432176804766, 'l1_Layer_3': 3.371870720203919e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 240, 'n_units_Layer_3': 140}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.17 | sMAPE for Validation Set is: 17.64% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 6.04 | sMAPE for Test Set is: 18.01% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:55:36,940]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:55:48,677]\u001b[0m Trial 769 finished with value: 7.920579015769104 and parameters: {'n_hidden': 4, 'learning_rate': 0.002509295573604177, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03501911952467003, 'dropout_rate_Layer_2': 0.1542138006876003, 'dropout_rate_Layer_3': 0.14904642993430917, 'dropout_rate_Layer_4': 0.20585333673323847, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000169966163023565, 'l1_Layer_2': 0.016964366532404764, 'l1_Layer_3': 0.0020583270901435623, 'l1_Layer_4': 0.00031632301756987007, 'n_units_Layer_1': 120, 'n_units_Layer_2': 200, 'n_units_Layer_3': 295, 'n_units_Layer_4': 295}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.92 | sMAPE for Validation Set is: 19.21% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 6.75 | sMAPE for Test Set is: 19.41% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:55:50,584]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:55:56,755]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:55:57,502]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:56:04,702]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:56:10,204]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:56:15,515]\u001b[0m Trial 785 finished with value: 7.2682963604900435 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014267679245651397, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12119201120087691, 'dropout_rate_Layer_2': 0.3805854962736107, 'dropout_rate_Layer_3': 0.2272973529175439, 'dropout_rate_Layer_4': 0.3676699597048748, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.2240965863373176e-05, 'l1_Layer_2': 0.04588899810716714, 'l1_Layer_3': 0.008369319136759415, 'l1_Layer_4': 0.00010617509907955461, 'n_units_Layer_1': 80, 'n_units_Layer_2': 65, 'n_units_Layer_3': 215, 'n_units_Layer_4': 155}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.27 | sMAPE for Validation Set is: 17.64% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 6.13 | sMAPE for Test Set is: 17.96% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:56:20,235]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:56:21,740]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:56:29,348]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:56:34,964]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:56:50,800]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:56:54,469]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:56:54,804]\u001b[0m Trial 783 finished with value: 7.4107304057870165 and parameters: {'n_hidden': 3, 'learning_rate': 0.007507741341331674, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0005311485372175781, 'dropout_rate_Layer_2': 0.15112982327944677, 'dropout_rate_Layer_3': 0.12898600465420937, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.130020052201357e-05, 'l1_Layer_2': 0.00036208336689136806, 'l1_Layer_3': 1.9795855519260943e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 230, 'n_units_Layer_3': 125}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.41 | sMAPE for Validation Set is: 17.92% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 5.90 | sMAPE for Test Set is: 17.44% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 21:56:55,425]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:57:00,103]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:57:03,779]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:57:10,306]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:57:15,238]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:57:20,558]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:57:21,202]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:57:27,170]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:57:28,134]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:57:34,623]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:57:38,855]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:57:45,254]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:57:51,913]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:58:01,534]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:58:11,061]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:58:13,012]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:58:23,595]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:58:28,350]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:58:35,056]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:58:40,936]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:58:48,320]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:58:53,608]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:58:54,396]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:59:09,009]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:59:11,820]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:59:19,364]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:59:23,466]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:59:28,864]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:59:34,742]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:59:39,909]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:59:41,840]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:59:45,361]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:59:46,066]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:59:51,949]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:59:52,639]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 21:59:58,147]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:00:03,744]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:00:03,901]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:00:11,581]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:00:16,187]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:00:17,715]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:00:17,797]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:00:25,454]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:00:25,645]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:00:26,749]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:00:26,810]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:00:38,124]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:00:41,793]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:00:44,811]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:00:48,010]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:00:53,689]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:01:00,448]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:01:07,631]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:01:10,451]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:01:12,680]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:01:20,141]\u001b[0m Trial 850 finished with value: 6.505073551865263 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018577039687631598, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17009465259026013, 'dropout_rate_Layer_2': 0.16947598671509115, 'dropout_rate_Layer_3': 0.2921968559399133, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007859217249691978, 'l1_Layer_2': 1.2212757120766358e-05, 'l1_Layer_3': 0.011490099139693576, 'n_units_Layer_1': 200, 'n_units_Layer_2': 115, 'n_units_Layer_3': 300}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.51 | sMAPE for Validation Set is: 16.23% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.81 | sMAPE for Test Set is: 17.41% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:01:50,116]\u001b[0m Trial 846 finished with value: 8.440119424993986 and parameters: {'n_hidden': 3, 'learning_rate': 0.00636690660205371, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01610460669600136, 'dropout_rate_Layer_2': 0.10406565365012357, 'dropout_rate_Layer_3': 0.250482729203606, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.9337659922316195e-05, 'l1_Layer_2': 0.007478300060820572, 'l1_Layer_3': 0.004053437376709811, 'n_units_Layer_1': 80, 'n_units_Layer_2': 185, 'n_units_Layer_3': 155}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.44 | sMAPE for Validation Set is: 20.49% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 6.76 | sMAPE for Test Set is: 19.37% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:01:53,854]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:02:00,473]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:02:03,832]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:02:04,388]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:02:19,321]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:02:24,281]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:02:29,655]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:02:35,814]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:02:37,325]\u001b[0m Trial 859 finished with value: 6.630222369567863 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019548084844624967, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1719925010438534, 'dropout_rate_Layer_2': 0.2272144630301348, 'dropout_rate_Layer_3': 0.29693160081484266, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009015841292733652, 'l1_Layer_2': 2.0186473592068312e-05, 'l1_Layer_3': 0.008350251786151732, 'n_units_Layer_1': 220, 'n_units_Layer_2': 60, 'n_units_Layer_3': 285}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.63 | sMAPE for Validation Set is: 16.69% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.73 | sMAPE for Test Set is: 17.45% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:02:43,919]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:02:47,263]\u001b[0m Trial 855 finished with value: 6.7750485921749615 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007082081835803387, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09647726491302853, 'dropout_rate_Layer_2': 0.004900913682161261, 'dropout_rate_Layer_3': 0.20729489962715, 'dropout_rate_Layer_4': 0.34639022762125443, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.1947976311376032e-05, 'l1_Layer_2': 0.033823031871622375, 'l1_Layer_3': 1.2392943627290897e-05, 'l1_Layer_4': 0.0001036891556198027, 'n_units_Layer_1': 120, 'n_units_Layer_2': 280, 'n_units_Layer_3': 220, 'n_units_Layer_4': 180}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.78 | sMAPE for Validation Set is: 16.75% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.75 | sMAPE for Test Set is: 16.98% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:02:48,047]\u001b[0m Trial 861 finished with value: 6.653523338631321 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022596220935885867, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13968406175897416, 'dropout_rate_Layer_2': 0.17307734817448983, 'dropout_rate_Layer_3': 0.26568997144937284, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00071773257523496, 'l1_Layer_2': 1.1234275125716852e-05, 'l1_Layer_3': 0.020468692628024886, 'n_units_Layer_1': 200, 'n_units_Layer_2': 120, 'n_units_Layer_3': 300}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.65 | sMAPE for Validation Set is: 16.62% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.84 | sMAPE for Test Set is: 17.50% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:02:48,625]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:02:55,868]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:02:56,296]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:02:56,773]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:02:57,343]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:03:07,312]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:03:10,674]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:03:11,321]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:03:15,988]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:03:16,877]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:03:18,121]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:03:22,710]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:03:26,913]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:03:27,523]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:03:28,506]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:03:36,480]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:03:37,672]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:03:45,303]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:03:45,594]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:03:56,348]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.47 | sMAPE for Validation Set is: 16.28% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.39 | sMAPE for Test Set is: 16.66% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:04:05,081]\u001b[0m Trial 882 finished with value: 6.4683873750451175 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023501371617106405, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1785673373497595, 'dropout_rate_Layer_2': 0.1705833179608432, 'dropout_rate_Layer_3': 0.2814928345021395, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007493589946048938, 'l1_Layer_2': 2.34781620940948e-05, 'l1_Layer_3': 0.005665403161951178, 'n_units_Layer_1': 205, 'n_units_Layer_2': 120, 'n_units_Layer_3': 295}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:04:07,751]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:04:10,437]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:04:14,579]\u001b[0m Trial 877 finished with value: 6.643567456950465 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007339976641053211, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18818470919946848, 'dropout_rate_Layer_2': 0.021540919814685557, 'dropout_rate_Layer_3': 0.1635028111768353, 'dropout_rate_Layer_4': 0.3501641872220816, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.8466142544715265e-05, 'l1_Layer_2': 0.035703668618399256, 'l1_Layer_3': 1.3636928070293826e-05, 'l1_Layer_4': 0.00014258479395726703, 'n_units_Layer_1': 115, 'n_units_Layer_2': 290, 'n_units_Layer_3': 280, 'n_units_Layer_4': 190}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.64 | sMAPE for Validation Set is: 16.57% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.63 | sMAPE for Test Set is: 16.81% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:04:18,963]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:04:20,924]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:04:26,319]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:04:27,012]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:04:33,676]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:04:38,185]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:04:38,768]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:04:50,955]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:04:51,867]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:04:52,503]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:04:57,343]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:04:58,852]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:05:03,197]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:05:05,982]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:05:11,208]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:05:11,396]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:05:12,176]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:05:20,355]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:05:25,183]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:05:32,524]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:05:32,601]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:05:34,396]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:05:46,589]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:05:52,030]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:05:58,988]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:06:02,623]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:06:06,844]\u001b[0m Trial 907 finished with value: 8.132749728543798 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013275577440483434, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009240708524663369, 'dropout_rate_Layer_2': 0.17152552282162803, 'dropout_rate_Layer_3': 0.14995539613063147, 'dropout_rate_Layer_4': 0.3193330164397404, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 7.678487854882306e-05, 'l1_Layer_2': 0.005418734402345022, 'l1_Layer_3': 0.0101062444713902, 'l1_Layer_4': 8.301153665500995e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 200, 'n_units_Layer_3': 290, 'n_units_Layer_4': 300}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.13 | sMAPE for Validation Set is: 20.07% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 6.72 | sMAPE for Test Set is: 19.79% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:06:10,319]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:06:13,846]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:06:15,401]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:06:19,989]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:06:21,412]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:06:25,470]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:06:30,158]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:06:34,699]\u001b[0m Trial 916 finished with value: 6.908447031220021 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015211014784132118, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17051993605692606, 'dropout_rate_Layer_2': 0.015920714158444052, 'dropout_rate_Layer_3': 0.031759553263531665, 'dropout_rate_Layer_4': 0.35866798575638614, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.006316320500597077, 'l1_Layer_2': 0.06248889663985437, 'l1_Layer_3': 1.9611971359558214e-05, 'l1_Layer_4': 0.0009014305070851578, 'n_units_Layer_1': 115, 'n_units_Layer_2': 285, 'n_units_Layer_3': 280, 'n_units_Layer_4': 195}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:06:34,776]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.91 | sMAPE for Validation Set is: 17.18% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.88 | sMAPE for Test Set is: 17.60% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:06:42,013]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:06:42,785]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:06:48,295]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:06:49,371]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:06:53,493]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:06:56,919]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:07:04,497]\u001b[0m Trial 920 finished with value: 7.625065979415921 and parameters: {'n_hidden': 3, 'learning_rate': 0.006704230800523354, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.036974293953254925, 'dropout_rate_Layer_2': 0.10145026697740064, 'dropout_rate_Layer_3': 0.15244941776704124, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.346662159286967e-05, 'l1_Layer_2': 0.0006918615872283843, 'l1_Layer_3': 2.5857725922898727e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 230, 'n_units_Layer_3': 135}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.63 | sMAPE for Validation Set is: 18.55% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 6.43 | sMAPE for Test Set is: 18.65% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:07:04,689]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:07:11,682]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:07:18,180]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:07:25,185]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:07:25,504]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:07:28,750]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:07:35,570]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:07:51,770]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:07:55,764]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:08:03,883]\u001b[0m Trial 938 finished with value: 6.9536763218483655 and parameters: {'n_hidden': 3, 'learning_rate': 0.008237689145479494, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0011574895209667119, 'dropout_rate_Layer_2': 0.15190843002786925, 'dropout_rate_Layer_3': 0.10793401623973868, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.252441617382199e-05, 'l1_Layer_2': 0.00037883365523490504, 'l1_Layer_3': 2.031468983520795e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 220, 'n_units_Layer_3': 120}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.95 | sMAPE for Validation Set is: 17.09% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.11 | sMAPE for Test Set is: 17.91% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:08:04,742]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:08:09,812]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:08:18,580]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:08:20,143]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:08:25,931]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:08:30,456]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:08:39,124]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:08:50,871]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:08:57,112]\u001b[0m Trial 943 finished with value: 7.215031432915109 and parameters: {'n_hidden': 3, 'learning_rate': 0.007680937955684943, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0008422919929202768, 'dropout_rate_Layer_2': 0.15375333599189966, 'dropout_rate_Layer_3': 0.126076191424208, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.28061506444354e-05, 'l1_Layer_2': 0.00036544832557272036, 'l1_Layer_3': 2.0020390223530048e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 235, 'n_units_Layer_3': 125}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.22 | sMAPE for Validation Set is: 17.76% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 5.91 | sMAPE for Test Set is: 17.70% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:08:57,986]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:09:01,081]\u001b[0m Trial 942 finished with value: 7.791341466592897 and parameters: {'n_hidden': 4, 'learning_rate': 0.0021489939925661105, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.029228404169537068, 'dropout_rate_Layer_2': 0.1176941703575488, 'dropout_rate_Layer_3': 0.3985418692636405, 'dropout_rate_Layer_4': 0.2434331969294721, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.72390331514166e-05, 'l1_Layer_2': 0.003592219597678046, 'l1_Layer_3': 0.037268017253488654, 'l1_Layer_4': 6.287338346386745e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 195, 'n_units_Layer_3': 295, 'n_units_Layer_4': 280}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.79 | sMAPE for Validation Set is: 19.29% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 6.40 | sMAPE for Test Set is: 18.97% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:09:11,450]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:09:16,071]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:09:19,479]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:09:23,923]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:09:24,641]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:09:33,766]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:09:42,333]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:09:46,796]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:09:51,685]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.13 | sMAPE for Validation Set is: 20.48% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 6.83 | sMAPE for Test Set is: 20.41% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:09:53,843]\u001b[0m Trial 957 finished with value: 8.126827970829755 and parameters: {'n_hidden': 4, 'learning_rate': 0.002060985547067288, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.027206096995912026, 'dropout_rate_Layer_2': 0.06311624819086739, 'dropout_rate_Layer_3': 0.34616447884835744, 'dropout_rate_Layer_4': 0.23036708042134116, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.214611602786923e-05, 'l1_Layer_2': 0.0031349093654940937, 'l1_Layer_3': 0.043137331653285656, 'l1_Layer_4': 0.0011669719485184105, 'n_units_Layer_1': 110, 'n_units_Layer_2': 225, 'n_units_Layer_3': 295, 'n_units_Layer_4': 275}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:10:00,181]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:10:05,219]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:10:07,314]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:10:16,537]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:10:25,232]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:10:30,795]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:10:35,848]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:10:36,220]\u001b[0m Trial 962 finished with value: 7.010918049199621 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011499539697269739, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10323894239636171, 'dropout_rate_Layer_2': 0.22955268814895102, 'dropout_rate_Layer_3': 0.1900378147094591, 'dropout_rate_Layer_4': 0.3717046537463929, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.015970483456983466, 'l1_Layer_2': 0.02748453202808589, 'l1_Layer_3': 0.0037506798598586993, 'l1_Layer_4': 0.0016530163386653542, 'n_units_Layer_1': 100, 'n_units_Layer_2': 290, 'n_units_Layer_3': 220, 'n_units_Layer_4': 190}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:10:36,244]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.01 | sMAPE for Validation Set is: 17.34% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.90 | sMAPE for Test Set is: 17.61% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:10:47,366]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:10:49,703]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:11:15,784]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:11:16,031]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:11:16,511]\u001b[0m Trial 969 finished with value: 7.2914135102364375 and parameters: {'n_hidden': 3, 'learning_rate': 0.005695605342290846, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2160516890156703, 'dropout_rate_Layer_2': 0.1900186051275869, 'dropout_rate_Layer_3': 0.10827542151509695, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.792715184869313e-05, 'l1_Layer_2': 0.00044780011389378344, 'l1_Layer_3': 2.2956938886060506e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 225, 'n_units_Layer_3': 155}. Best is trial 327 with value: 6.459078235368711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.29 | sMAPE for Validation Set is: 17.81% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 5.76 | sMAPE for Test Set is: 17.09% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:11:19,990]\u001b[0m Trial 975 finished with value: 6.2897366345306125 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016630149027905094, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19611338173882106, 'dropout_rate_Layer_2': 0.13427611806157153, 'dropout_rate_Layer_3': 0.31802097875716595, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00020821224248725347, 'l1_Layer_2': 4.064846036420982e-05, 'l1_Layer_3': 0.011711692336596673, 'n_units_Layer_1': 240, 'n_units_Layer_2': 100, 'n_units_Layer_3': 285}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.29 | sMAPE for Validation Set is: 15.79% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.52 | sMAPE for Test Set is: 16.80% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:11:27,620]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:11:27,978]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:11:28,789]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:11:38,228]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:11:38,399]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:11:44,374]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:11:46,234]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:11:50,958]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:11:54,044]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:12:00,433]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:12:03,280]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:12:05,943]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:12:10,986]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:12:15,002]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:12:16,832]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:12:24,263]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:12:24,520]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:12:32,416]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:12:37,868]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:12:38,345]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:12:42,398]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:12:45,669]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:12:49,726]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:12:52,360]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:12:56,724]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:12:59,484]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:13:03,549]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:13:07,035]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:13:07,549]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:13:12,898]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:13:17,921]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:13:19,489]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:13:25,678]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:13:28,684]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:13:31,043]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:13:36,452]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:13:44,468]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:13:48,039]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:14:01,543]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:14:01,697]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:14:09,127]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:14:11,567]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:14:16,748]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:14:17,336]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:14:21,846]\u001b[0m Trial 1012 finished with value: 7.549318137064549 and parameters: {'n_hidden': 3, 'learning_rate': 0.007402851507107973, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02082959416516994, 'dropout_rate_Layer_2': 0.1109309861764373, 'dropout_rate_Layer_3': 0.04415406608985302, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.272534944147236e-05, 'l1_Layer_2': 0.0008739600893669311, 'l1_Layer_3': 1.727976208138371e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 230, 'n_units_Layer_3': 140}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.55 | sMAPE for Validation Set is: 18.33% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 6.46 | sMAPE for Test Set is: 18.92% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:14:25,779]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:14:27,267]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:14:28,866]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:14:50,078]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:14:50,173]\u001b[0m Trial 1029 finished with value: 8.262430921284624 and parameters: {'n_hidden': 4, 'learning_rate': 0.002820780451594317, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.034263645901211365, 'dropout_rate_Layer_2': 0.1499406924578389, 'dropout_rate_Layer_3': 0.3723621067542411, 'dropout_rate_Layer_4': 0.2641596006216562, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.231104001737885e-05, 'l1_Layer_2': 0.001396363139154518, 'l1_Layer_3': 0.0719672379720637, 'l1_Layer_4': 7.526009381577932e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 210, 'n_units_Layer_3': 255, 'n_units_Layer_4': 270}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.26 | sMAPE for Validation Set is: 19.96% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 6.54 | sMAPE for Test Set is: 18.89% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:14:59,162]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:14:59,332]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:15:00,638]\u001b[0m Trial 1030 finished with value: 8.269190241806555 and parameters: {'n_hidden': 4, 'learning_rate': 0.001061061385340356, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03723487910801916, 'dropout_rate_Layer_2': 0.1541834072307141, 'dropout_rate_Layer_3': 0.37067654488708013, 'dropout_rate_Layer_4': 0.2613087553057839, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 6.550860044645747e-05, 'l1_Layer_2': 0.0018941505357078577, 'l1_Layer_3': 0.06930473063341358, 'l1_Layer_4': 7.157687247543063e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 210, 'n_units_Layer_3': 255, 'n_units_Layer_4': 255}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.27 | sMAPE for Validation Set is: 19.91% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 6.41 | sMAPE for Test Set is: 18.67% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:15:08,839]\u001b[0m Trial 1020 finished with value: 7.508458924195842 and parameters: {'n_hidden': 3, 'learning_rate': 0.0070389480501481015, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20901368182901348, 'dropout_rate_Layer_2': 0.2077192600091704, 'dropout_rate_Layer_3': 0.007799302990964147, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.183367487565764e-05, 'l1_Layer_2': 0.0009935591832884267, 'l1_Layer_3': 2.3381338523400676e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 240, 'n_units_Layer_3': 135}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.51 | sMAPE for Validation Set is: 18.06% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 6.21 | sMAPE for Test Set is: 17.98% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:15:12,245]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:15:13,008]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:15:14,387]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:15:14,622]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:15:23,141]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:15:23,720]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:15:30,332]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:15:30,612]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:15:38,151]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:15:44,603]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:15:44,776]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:15:57,994]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:16:04,858]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:16:05,327]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:16:06,532]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:16:14,502]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:16:17,290]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:16:21,496]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:16:26,968]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:16:43,315]\u001b[0m Trial 1051 finished with value: 6.510778942001598 and parameters: {'n_hidden': 3, 'learning_rate': 0.001927724567427888, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21812102248642565, 'dropout_rate_Layer_2': 0.16753913643789553, 'dropout_rate_Layer_3': 0.29932445944609565, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0015809591379489312, 'l1_Layer_2': 2.2065100676199432e-05, 'l1_Layer_3': 0.004096342253634865, 'n_units_Layer_1': 205, 'n_units_Layer_2': 180, 'n_units_Layer_3': 270}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.51 | sMAPE for Validation Set is: 16.40% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.71 | sMAPE for Test Set is: 17.39% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:16:50,076]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:16:57,978]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:17:02,147]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:17:09,154]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:17:31,542]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:17:52,574]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:17:57,740]\u001b[0m Trial 1057 finished with value: 7.77366828005185 and parameters: {'n_hidden': 4, 'learning_rate': 0.0035754775981232155, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00041640723997436735, 'dropout_rate_Layer_2': 0.09635170393538338, 'dropout_rate_Layer_3': 0.35898686158679266, 'dropout_rate_Layer_4': 0.286708562353148, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.0381747877816462e-05, 'l1_Layer_2': 0.003555796114426449, 'l1_Layer_3': 0.04929282164910111, 'l1_Layer_4': 0.00011180445476790727, 'n_units_Layer_1': 90, 'n_units_Layer_2': 220, 'n_units_Layer_3': 235, 'n_units_Layer_4': 285}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.77 | sMAPE for Validation Set is: 19.03% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 6.05 | sMAPE for Test Set is: 18.05% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:17:58,302]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:18:03,973]\u001b[0m Trial 1060 finished with value: 7.071458260657843 and parameters: {'n_hidden': 3, 'learning_rate': 0.007825430654139457, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22132611211026, 'dropout_rate_Layer_2': 0.11680608396184174, 'dropout_rate_Layer_3': 0.10594583404730326, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.577865828266963e-05, 'l1_Layer_2': 0.0004758721487172042, 'l1_Layer_3': 1.8050706567227854e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 235, 'n_units_Layer_3': 160}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.07 | sMAPE for Validation Set is: 17.57% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.18 | sMAPE for Test Set is: 18.36% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:18:09,211]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:18:14,255]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:18:20,140]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:18:25,797]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:18:31,409]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:18:36,321]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:18:54,061]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:19:22,441]\u001b[0m Trial 1072 finished with value: 6.344576348683465 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018268979067013222, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2144343903102494, 'dropout_rate_Layer_2': 0.20519049107422566, 'dropout_rate_Layer_3': 0.3025219277458638, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005842933368667827, 'l1_Layer_2': 1.568912425810073e-05, 'l1_Layer_3': 0.0034919507849646937, 'n_units_Layer_1': 205, 'n_units_Layer_2': 180, 'n_units_Layer_3': 280}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.34 | sMAPE for Validation Set is: 15.80% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.46 | sMAPE for Test Set is: 16.59% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:19:28,380]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:19:29,036]\u001b[0m Trial 1063 finished with value: 7.12005116045253 and parameters: {'n_hidden': 3, 'learning_rate': 0.0060756696630013445, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22390229948898682, 'dropout_rate_Layer_2': 0.14431426815947448, 'dropout_rate_Layer_3': 0.1093731740906061, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.640638082153911e-05, 'l1_Layer_2': 0.0005630136947066822, 'l1_Layer_3': 1.7408946941001344e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 235, 'n_units_Layer_3': 130}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.12 | sMAPE for Validation Set is: 17.42% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.79 | sMAPE for Test Set is: 17.25% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:19:47,030]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:19:57,212]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:20:02,969]\u001b[0m Trial 1075 finished with value: 6.394838843005995 and parameters: {'n_hidden': 3, 'learning_rate': 0.001818372603429955, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21569554053650156, 'dropout_rate_Layer_2': 0.18991711602843148, 'dropout_rate_Layer_3': 0.301927509468891, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000429433458836523, 'l1_Layer_2': 1.4931635659276751e-05, 'l1_Layer_3': 0.003971895193141816, 'n_units_Layer_1': 205, 'n_units_Layer_2': 170, 'n_units_Layer_3': 285}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.39 | sMAPE for Validation Set is: 16.13% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.67 | sMAPE for Test Set is: 17.34% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:20:10,356]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:20:10,820]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:20:11,528]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:20:13,985]\u001b[0m Trial 1071 finished with value: 6.996232252169809 and parameters: {'n_hidden': 4, 'learning_rate': 0.0035299460640743486, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0015647420911713943, 'dropout_rate_Layer_2': 0.04514454869506039, 'dropout_rate_Layer_3': 0.3328733095570034, 'dropout_rate_Layer_4': 0.2398019076344419, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.1369482253761323e-05, 'l1_Layer_2': 0.003300690623582076, 'l1_Layer_3': 0.036998978120908674, 'l1_Layer_4': 0.0003933016977470528, 'n_units_Layer_1': 90, 'n_units_Layer_2': 225, 'n_units_Layer_3': 230, 'n_units_Layer_4': 235}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.00 | sMAPE for Validation Set is: 17.18% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.08 | sMAPE for Test Set is: 17.94% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:20:23,791]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:20:27,086]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:20:27,840]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:20:31,300]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:20:37,920]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:20:38,552]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:20:39,115]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:20:48,506]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:20:49,613]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:20:50,441]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:20:57,821]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:20:58,307]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:21:03,704]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:21:05,079]\u001b[0m Trial 1082 finished with value: 6.521989381712632 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018098437981392639, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2168636219913249, 'dropout_rate_Layer_2': 0.1678224088582587, 'dropout_rate_Layer_3': 0.2999373781034915, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006055768668480831, 'l1_Layer_2': 1.47349320671889e-05, 'l1_Layer_3': 0.0034102065762612985, 'n_units_Layer_1': 205, 'n_units_Layer_2': 180, 'n_units_Layer_3': 285}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.52 | sMAPE for Validation Set is: 16.41% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.63 | sMAPE for Test Set is: 17.24% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:21:05,422]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:21:07,147]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:21:16,155]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:21:18,136]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:21:18,568]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:21:19,141]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:21:26,072]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:21:31,261]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:21:33,763]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:21:34,555]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:21:37,230]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:21:41,728]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:21:44,372]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:21:44,947]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:21:54,414]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:21:58,620]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:21:58,999]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:22:06,497]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:22:36,867]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:22:42,203]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:22:49,147]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:22:54,814]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:23:08,797]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:23:14,092]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:23:31,185]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:23:36,773]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:23:41,891]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:24:09,731]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:24:13,892]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:24:18,204]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:24:18,934]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:24:26,182]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:24:26,749]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:24:27,022]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:24:38,313]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:24:40,696]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:24:47,524]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:24:47,995]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:24:54,638]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:24:58,932]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:25:02,647]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:25:06,410]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:25:09,312]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:25:13,114]\u001b[0m Trial 1112 finished with value: 7.729879339043209 and parameters: {'n_hidden': 4, 'learning_rate': 0.004508629703825032, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.020664888121331895, 'dropout_rate_Layer_2': 0.062264649432938274, 'dropout_rate_Layer_3': 0.36091608365659755, 'dropout_rate_Layer_4': 0.26309906088973695, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.2655420375868425e-05, 'l1_Layer_2': 0.0031169941333250113, 'l1_Layer_3': 0.07871453634292903, 'l1_Layer_4': 2.2817374300359487e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 235, 'n_units_Layer_3': 200, 'n_units_Layer_4': 230}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.73 | sMAPE for Validation Set is: 19.05% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 6.24 | sMAPE for Test Set is: 18.63% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:25:14,979]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:25:20,909]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:25:23,535]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:25:29,824]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:25:33,167]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:25:43,393]\u001b[0m Trial 1129 finished with value: 7.164500219684295 and parameters: {'n_hidden': 4, 'learning_rate': 0.0039375419671765334, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0617917469427421, 'dropout_rate_Layer_2': 0.28749092804924925, 'dropout_rate_Layer_3': 0.28076536850250045, 'dropout_rate_Layer_4': 0.14057296847190226, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.2222148996581777e-05, 'l1_Layer_2': 0.0007350904578978817, 'l1_Layer_3': 0.022993187383036587, 'l1_Layer_4': 8.937484815731431e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 215, 'n_units_Layer_3': 175, 'n_units_Layer_4': 215}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.16 | sMAPE for Validation Set is: 17.70% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 6.18 | sMAPE for Test Set is: 18.30% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:25:48,653]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:25:52,106]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:25:54,728]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:25:58,900]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:26:08,341]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:26:12,448]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:26:15,335]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:26:20,870]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:26:24,589]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:26:29,292]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:26:41,073]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:26:53,432]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:27:07,443]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:27:13,504]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:27:31,032]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:27:37,094]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:27:43,673]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:27:50,188]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:27:54,928]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:28:02,840]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:28:08,630]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:28:17,489]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:28:21,144]\u001b[0m Trial 1138 finished with value: 7.3270926365150855 and parameters: {'n_hidden': 4, 'learning_rate': 0.0037143758599244895, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06589809698858298, 'dropout_rate_Layer_2': 0.2966059979175844, 'dropout_rate_Layer_3': 0.3168981241376893, 'dropout_rate_Layer_4': 0.25212267251288956, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.778516594385118e-05, 'l1_Layer_2': 0.005210240322445126, 'l1_Layer_3': 0.024115777956504263, 'l1_Layer_4': 0.00011251891350513912, 'n_units_Layer_1': 75, 'n_units_Layer_2': 215, 'n_units_Layer_3': 235, 'n_units_Layer_4': 205}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.33 | sMAPE for Validation Set is: 17.86% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 6.10 | sMAPE for Test Set is: 17.94% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:28:24,573]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:28:52,776]\u001b[0m Trial 1169 finished with value: 6.5711137096864105 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031101293377910825, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21253977238646674, 'dropout_rate_Layer_2': 0.2306948866628423, 'dropout_rate_Layer_3': 0.14111075881359209, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0017439093551959313, 'l1_Layer_2': 2.131754801143255e-05, 'l1_Layer_3': 0.002294994857766234, 'n_units_Layer_1': 225, 'n_units_Layer_2': 50, 'n_units_Layer_3': 295}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.57 | sMAPE for Validation Set is: 16.42% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.45 | sMAPE for Test Set is: 16.59% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:28:58,948]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:29:03,225]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:29:07,205]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:29:12,867]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:29:18,027]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:29:23,385]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:29:37,566]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:29:42,047]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:29:44,130]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:29:50,552]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:29:52,327]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:29:53,592]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:29:59,728]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:30:00,738]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:30:07,728]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:30:08,648]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:30:16,190]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:30:16,929]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:30:23,379]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:30:26,955]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:30:28,388]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:30:33,723]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:30:36,432]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:30:38,061]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:30:46,202]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:30:50,278]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:30:56,175]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:30:59,539]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:31:06,433]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:31:16,497]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:31:22,045]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:31:24,879]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:31:29,007]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:31:41,096]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:31:44,454]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:31:46,416]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:31:51,905]\u001b[0m Trial 1195 finished with value: 7.012478293999611 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007011562023640371, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17621099118078343, 'dropout_rate_Layer_2': 0.31734857398284055, 'dropout_rate_Layer_3': 0.1840385600813016, 'dropout_rate_Layer_4': 0.1412459936806528, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 6.140423440537232e-05, 'l1_Layer_2': 0.044140339442589493, 'l1_Layer_3': 0.0029562265341761783, 'l1_Layer_4': 0.0018088977883098994, 'n_units_Layer_1': 80, 'n_units_Layer_2': 295, 'n_units_Layer_3': 245, 'n_units_Layer_4': 190}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.01 | sMAPE for Validation Set is: 17.18% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.99 | sMAPE for Test Set is: 17.67% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:31:54,332]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:31:57,520]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:32:00,615]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:32:03,160]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:32:05,839]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:32:06,381]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:32:06,841]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:32:17,367]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:32:17,592]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:32:17,787]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:32:28,740]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:32:31,843]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:32:32,567]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:32:36,031]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:32:41,878]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:32:45,878]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:32:46,166]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:32:49,981]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:32:57,316]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:32:57,479]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:33:04,980]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:33:09,955]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:33:14,395]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:33:43,023]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:34:12,741]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:34:18,435]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:34:24,727]\u001b[0m Trial 1230 finished with value: 6.8946297943525465 and parameters: {'n_hidden': 4, 'learning_rate': 0.00517909539053588, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07119007695304506, 'dropout_rate_Layer_2': 0.2925100038649025, 'dropout_rate_Layer_3': 0.325316922771244, 'dropout_rate_Layer_4': 0.2892562795333961, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.0216859339603369e-05, 'l1_Layer_2': 0.008010417950819304, 'l1_Layer_3': 0.024476269388026314, 'l1_Layer_4': 2.469460486933422e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 220, 'n_units_Layer_3': 175, 'n_units_Layer_4': 220}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.89 | sMAPE for Validation Set is: 16.98% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.19 | sMAPE for Test Set is: 18.04% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:34:25,192]\u001b[0m Trial 1223 finished with value: 7.48632206660631 and parameters: {'n_hidden': 4, 'learning_rate': 0.00526490383147351, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0450275762426296, 'dropout_rate_Layer_2': 0.29761754619235914, 'dropout_rate_Layer_3': 0.3229733178557873, 'dropout_rate_Layer_4': 0.27257332502049697, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.569209437484316e-05, 'l1_Layer_2': 0.0074687150897690974, 'l1_Layer_3': 0.03141270201112894, 'l1_Layer_4': 3.061213059268276e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 215, 'n_units_Layer_3': 240, 'n_units_Layer_4': 195}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.49 | sMAPE for Validation Set is: 18.28% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 6.18 | sMAPE for Test Set is: 18.16% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:34:25,586]\u001b[0m Trial 1226 finished with value: 7.5599272404902464 and parameters: {'n_hidden': 4, 'learning_rate': 0.005355789240622113, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02840026486454477, 'dropout_rate_Layer_2': 0.0464348301548734, 'dropout_rate_Layer_3': 0.32703509060019287, 'dropout_rate_Layer_4': 0.29071516272612347, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.52463526016366e-05, 'l1_Layer_2': 0.006741136888004702, 'l1_Layer_3': 0.022651458584318763, 'l1_Layer_4': 3.206934615645288e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 215, 'n_units_Layer_3': 185, 'n_units_Layer_4': 200}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.56 | sMAPE for Validation Set is: 18.39% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 6.71 | sMAPE for Test Set is: 19.23% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:34:35,973]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:34:42,736]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:34:46,701]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:34:52,664]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:34:57,377]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:34:57,539]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:34:57,722]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:35:07,966]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:35:31,159]\u001b[0m Trial 1239 finished with value: 7.223822934183549 and parameters: {'n_hidden': 3, 'learning_rate': 0.006389208272140877, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2168205918379998, 'dropout_rate_Layer_2': 0.17718144310332942, 'dropout_rate_Layer_3': 0.12211449146121336, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.914269480121767e-05, 'l1_Layer_2': 0.00022608684094649705, 'l1_Layer_3': 2.0822811514165035e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 220, 'n_units_Layer_3': 145}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.22 | sMAPE for Validation Set is: 17.66% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 6.24 | sMAPE for Test Set is: 18.23% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:35:35,888]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:35:40,947]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:35:48,877]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:35:49,465]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:35:52,358]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:35:59,547]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:36:02,772]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:36:04,836]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:36:05,579]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:36:09,821]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:36:15,235]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:36:19,989]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:36:22,903]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:36:26,030]\u001b[0m Trial 1243 finished with value: 7.232684470355178 and parameters: {'n_hidden': 3, 'learning_rate': 0.006467320434986078, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02162711429555003, 'dropout_rate_Layer_2': 0.07094616381372468, 'dropout_rate_Layer_3': 0.15630045560364544, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.213832702681992e-05, 'l1_Layer_2': 0.0008798380391103477, 'l1_Layer_3': 2.0042639340013547e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 220, 'n_units_Layer_3': 145}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.23 | sMAPE for Validation Set is: 17.45% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 6.42 | sMAPE for Test Set is: 18.67% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:36:29,384]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:36:32,455]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:36:39,222]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:36:41,901]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:36:45,480]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:36:48,750]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:36:54,296]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:36:58,756]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:37:03,703]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:37:07,106]\u001b[0m Trial 1263 finished with value: 6.596477283820981 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014475516549670722, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12476682110792642, 'dropout_rate_Layer_2': 0.17632132028482586, 'dropout_rate_Layer_3': 0.29841262178102296, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000324245232560721, 'l1_Layer_2': 2.2063940892842166e-05, 'l1_Layer_3': 0.003188367785000311, 'n_units_Layer_1': 220, 'n_units_Layer_2': 230, 'n_units_Layer_3': 285}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.60 | sMAPE for Validation Set is: 16.52% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.86 | sMAPE for Test Set is: 17.66% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:37:08,277]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:37:12,880]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:37:18,987]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:37:19,357]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:37:20,815]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:37:30,101]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:37:33,236]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:37:37,035]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:37:37,494]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:37:44,197]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:37:49,595]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:37:54,161]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:37:54,863]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:37:56,246]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:38:04,548]\u001b[0m Trial 1277 finished with value: 6.905080839846164 and parameters: {'n_hidden': 3, 'learning_rate': 0.004086603540830814, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.020761402452466122, 'dropout_rate_Layer_2': 0.11733328294328366, 'dropout_rate_Layer_3': 0.15560766682783236, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2227783608011881e-05, 'l1_Layer_2': 0.0021215954280275145, 'l1_Layer_3': 2.5251586841246095e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 220, 'n_units_Layer_3': 150}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.91 | sMAPE for Validation Set is: 17.12% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.00 | sMAPE for Test Set is: 17.68% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:38:05,188]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:38:05,509]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:38:15,353]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:38:21,348]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:38:24,464]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:38:29,468]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:38:34,735]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:38:40,497]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:38:49,587]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:38:56,940]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:39:02,650]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:39:07,271]\u001b[0m Trial 1285 finished with value: 7.458492278555472 and parameters: {'n_hidden': 4, 'learning_rate': 0.005313890744890043, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05696934364829308, 'dropout_rate_Layer_2': 0.31394319381658387, 'dropout_rate_Layer_3': 0.3021078541390378, 'dropout_rate_Layer_4': 0.3044994591562808, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.6009202062273105e-05, 'l1_Layer_2': 0.008753142672976647, 'l1_Layer_3': 0.023541597533397574, 'l1_Layer_4': 2.8191150478137165e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 285, 'n_units_Layer_3': 185, 'n_units_Layer_4': 190}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.46 | sMAPE for Validation Set is: 18.38% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 6.34 | sMAPE for Test Set is: 18.72% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:39:12,486]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.87 | sMAPE for Validation Set is: 17.24% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.67 | sMAPE for Test Set is: 17.23% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:39:15,468]\u001b[0m Trial 1292 finished with value: 6.865168222311045 and parameters: {'n_hidden': 3, 'learning_rate': 0.003242712306896729, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04043021707159725, 'dropout_rate_Layer_2': 0.1171311277640988, 'dropout_rate_Layer_3': 0.13959280225372764, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4482559561607649e-05, 'l1_Layer_2': 0.001971926077320922, 'l1_Layer_3': 1.6963885288850447e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 210, 'n_units_Layer_3': 150}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:39:21,121]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:39:32,731]\u001b[0m Trial 1296 finished with value: 6.513946176464887 and parameters: {'n_hidden': 3, 'learning_rate': 0.001971387064926669, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.161238813424894, 'dropout_rate_Layer_2': 0.18318293077878875, 'dropout_rate_Layer_3': 0.28598815908240327, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00026402409380835374, 'l1_Layer_2': 5.617407426575931e-05, 'l1_Layer_3': 0.0022502718054689917, 'n_units_Layer_1': 225, 'n_units_Layer_2': 225, 'n_units_Layer_3': 295}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.51 | sMAPE for Validation Set is: 16.36% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.74 | sMAPE for Test Set is: 17.46% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:39:37,387]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:39:52,538]\u001b[0m Trial 1293 finished with value: 6.997671330352513 and parameters: {'n_hidden': 4, 'learning_rate': 0.002677956783623861, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13765340721424196, 'dropout_rate_Layer_2': 0.36181035261550365, 'dropout_rate_Layer_3': 0.008059069202880876, 'dropout_rate_Layer_4': 0.3829532244169187, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0017420601871534238, 'l1_Layer_2': 0.09942822476007031, 'l1_Layer_3': 0.006276531959754807, 'l1_Layer_4': 0.0016629985250274828, 'n_units_Layer_1': 90, 'n_units_Layer_2': 295, 'n_units_Layer_3': 240, 'n_units_Layer_4': 50}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.00 | sMAPE for Validation Set is: 17.26% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.04 | sMAPE for Test Set is: 17.91% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:39:57,554]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:40:00,258]\u001b[0m Trial 1302 finished with value: 6.78725427508576 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032400765947897146, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05128869647264586, 'dropout_rate_Layer_2': 0.1208717650091948, 'dropout_rate_Layer_3': 0.143223579888423, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.46413772329274e-05, 'l1_Layer_2': 0.000567700741749318, 'l1_Layer_3': 2.0134070510486048e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 205, 'n_units_Layer_3': 145}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.79 | sMAPE for Validation Set is: 16.96% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.87 | sMAPE for Test Set is: 17.76% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:40:07,070]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:40:12,175]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:40:15,915]\u001b[0m Trial 1299 finished with value: 6.956213847201184 and parameters: {'n_hidden': 4, 'learning_rate': 0.001366784581376719, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16480628471459072, 'dropout_rate_Layer_2': 0.3033691900910028, 'dropout_rate_Layer_3': 0.030981549081900213, 'dropout_rate_Layer_4': 0.3875293551409123, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0017511810215364745, 'l1_Layer_2': 1.4283569194552113e-05, 'l1_Layer_3': 0.018883646909138088, 'l1_Layer_4': 0.0021625108967471556, 'n_units_Layer_1': 70, 'n_units_Layer_2': 280, 'n_units_Layer_3': 230, 'n_units_Layer_4': 135}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.96 | sMAPE for Validation Set is: 17.15% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.91 | sMAPE for Test Set is: 17.57% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:40:19,804]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:40:24,999]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:40:30,472]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:40:35,480]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:40:36,338]\u001b[0m Trial 1300 finished with value: 8.374178236529813 and parameters: {'n_hidden': 4, 'learning_rate': 0.01273362320496932, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08051026106786716, 'dropout_rate_Layer_2': 0.32197658554662933, 'dropout_rate_Layer_3': 0.30073215509094364, 'dropout_rate_Layer_4': 0.3359604600544166, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.1111805551713138e-05, 'l1_Layer_2': 0.009506870143512971, 'l1_Layer_3': 0.02405577337824896, 'l1_Layer_4': 2.7418806844889624e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 280, 'n_units_Layer_3': 185, 'n_units_Layer_4': 205}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.37 | sMAPE for Validation Set is: 20.20% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 6.49 | sMAPE for Test Set is: 19.02% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:40:41,865]\u001b[0m Trial 1308 finished with value: 6.855714311661889 and parameters: {'n_hidden': 3, 'learning_rate': 0.002947954161601093, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06416526048140195, 'dropout_rate_Layer_2': 0.11258740973341355, 'dropout_rate_Layer_3': 0.13716355737271826, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4847091176413504e-05, 'l1_Layer_2': 0.00036202633242074907, 'l1_Layer_3': 1.156671647823804e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 210, 'n_units_Layer_3': 150}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.86 | sMAPE for Validation Set is: 17.13% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.94 | sMAPE for Test Set is: 17.88% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:40:44,110]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:41:03,309]\u001b[0m Trial 1311 finished with value: 6.764982042111442 and parameters: {'n_hidden': 3, 'learning_rate': 0.003195028153296489, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06062512373238683, 'dropout_rate_Layer_2': 0.11391372943815177, 'dropout_rate_Layer_3': 0.14521172314998812, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3976011040842638e-05, 'l1_Layer_2': 0.0005639960259033278, 'l1_Layer_3': 1.5586393560749836e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 105, 'n_units_Layer_3': 170}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.76 | sMAPE for Validation Set is: 16.90% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.67 | sMAPE for Test Set is: 17.08% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:41:08,301]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:41:09,320]\u001b[0m Trial 1314 finished with value: 6.823956227120519 and parameters: {'n_hidden': 3, 'learning_rate': 0.002234971985035544, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05662690218584965, 'dropout_rate_Layer_2': 0.10386788656062643, 'dropout_rate_Layer_3': 0.1445444117107971, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.539754475059664e-05, 'l1_Layer_2': 0.00029485928170684743, 'l1_Layer_3': 1.0755053448639055e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 210, 'n_units_Layer_3': 150}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.82 | sMAPE for Validation Set is: 16.90% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.76 | sMAPE for Test Set is: 17.20% | rMAE for Test Set is: 0.71\n",
      "MAE for Validation Set is: 6.87 | sMAPE for Validation Set is: 16.98% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.81 | sMAPE for Test Set is: 17.37% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:41:14,790]\u001b[0m Trial 1313 finished with value: 6.87361163321376 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030629116300562222, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07093402593011566, 'dropout_rate_Layer_2': 0.04898573956376309, 'dropout_rate_Layer_3': 0.13387488369399897, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4946937513013575e-05, 'l1_Layer_2': 0.0005587259983670399, 'l1_Layer_3': 1.5506841224143143e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 210, 'n_units_Layer_3': 150}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:41:16,660]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:41:20,072]\u001b[0m Trial 1315 finished with value: 6.452753883234365 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016765571858252328, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1723797426351602, 'dropout_rate_Layer_2': 0.17886795428543747, 'dropout_rate_Layer_3': 0.27180843279892375, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001940458718258629, 'l1_Layer_2': 4.3031212764850526e-05, 'l1_Layer_3': 0.0021803287814372648, 'n_units_Layer_1': 205, 'n_units_Layer_2': 235, 'n_units_Layer_3': 295}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.45 | sMAPE for Validation Set is: 16.16% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.58 | sMAPE for Test Set is: 17.03% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:41:20,353]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:41:26,664]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:41:31,335]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:41:32,738]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:41:37,388]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:41:40,974]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:41:41,546]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:41:43,405]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:41:50,660]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:41:57,879]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:41:58,633]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:42:05,265]\u001b[0m Trial 1319 finished with value: 6.588054088833196 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017167378402595484, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.156522166271284, 'dropout_rate_Layer_2': 0.1783567902590386, 'dropout_rate_Layer_3': 0.27533897533435714, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00018575528612440776, 'l1_Layer_2': 4.634540121021817e-05, 'l1_Layer_3': 0.004277109814799766, 'n_units_Layer_1': 205, 'n_units_Layer_2': 235, 'n_units_Layer_3': 295}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.59 | sMAPE for Validation Set is: 16.54% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.02 | sMAPE for Test Set is: 18.24% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:42:24,836]\u001b[0m Trial 1331 finished with value: 6.844292296604071 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024303567313089082, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06200429585032817, 'dropout_rate_Layer_2': 0.10716277652912051, 'dropout_rate_Layer_3': 0.13533967575950107, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.6283342222671415e-05, 'l1_Layer_2': 0.00029435555574865586, 'l1_Layer_3': 1.2055299946414507e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 205, 'n_units_Layer_3': 180}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.84 | sMAPE for Validation Set is: 17.03% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.81 | sMAPE for Test Set is: 17.34% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:42:30,171]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:42:32,681]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:42:38,556]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:42:42,142]\u001b[0m Trial 1328 finished with value: 6.949527019637479 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011960685162640996, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1602621598069747, 'dropout_rate_Layer_2': 0.31325798022211626, 'dropout_rate_Layer_3': 0.045408481998334485, 'dropout_rate_Layer_4': 0.38051523441202756, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0016758452858235979, 'l1_Layer_2': 3.122881078591302e-05, 'l1_Layer_3': 0.035899388520810954, 'l1_Layer_4': 0.007746068502271584, 'n_units_Layer_1': 85, 'n_units_Layer_2': 275, 'n_units_Layer_3': 225, 'n_units_Layer_4': 130}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.95 | sMAPE for Validation Set is: 17.18% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.90 | sMAPE for Test Set is: 17.61% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:42:46,907]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:42:51,791]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:42:57,219]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:43:02,575]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:43:06,685]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:43:08,537]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.85 | sMAPE for Validation Set is: 17.10% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.62 | sMAPE for Test Set is: 16.98% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:43:12,137]\u001b[0m Trial 1337 finished with value: 6.853593011230951 and parameters: {'n_hidden': 3, 'learning_rate': 0.002524559742836545, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0621731565610025, 'dropout_rate_Layer_2': 0.0485844512190542, 'dropout_rate_Layer_3': 0.1335619500210493, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4727182188525017e-05, 'l1_Layer_2': 0.0002780936565686272, 'l1_Layer_3': 1.1636676215112165e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 200, 'n_units_Layer_3': 180}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:43:12,688]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:43:20,451]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:43:24,679]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:43:29,153]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:43:34,041]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:43:39,693]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:43:44,635]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:43:48,421]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:43:50,285]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:43:56,468]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:43:58,460]\u001b[0m Trial 1336 finished with value: 7.7973992579964495 and parameters: {'n_hidden': 4, 'learning_rate': 0.007086367590406381, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0539552268886047, 'dropout_rate_Layer_2': 0.3116819191388812, 'dropout_rate_Layer_3': 0.31014582963378734, 'dropout_rate_Layer_4': 0.30321310333132123, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.4006189982009173e-05, 'l1_Layer_2': 0.007675038054017884, 'l1_Layer_3': 0.02294755819359268, 'l1_Layer_4': 2.301068821475387e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 290, 'n_units_Layer_3': 175, 'n_units_Layer_4': 195}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.80 | sMAPE for Validation Set is: 18.88% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 6.20 | sMAPE for Test Set is: 18.13% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:44:02,741]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:44:08,652]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:44:11,837]\u001b[0m Trial 1344 finished with value: 6.779278244634802 and parameters: {'n_hidden': 3, 'learning_rate': 0.00264875101420503, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0715983251021198, 'dropout_rate_Layer_2': 0.10472364768797743, 'dropout_rate_Layer_3': 0.13083862887214318, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.414007002554799e-05, 'l1_Layer_2': 0.0002719756900743842, 'l1_Layer_3': 1.139316773520453e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 195, 'n_units_Layer_3': 165}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.78 | sMAPE for Validation Set is: 16.65% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.65 | sMAPE for Test Set is: 16.93% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:44:17,277]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:44:17,553]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:44:25,842]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:44:27,082]\u001b[0m Trial 1353 finished with value: 6.795697181303492 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023006517912108723, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06143530460699315, 'dropout_rate_Layer_2': 0.04704928481697562, 'dropout_rate_Layer_3': 0.13411026995619166, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.695440534203229e-05, 'l1_Layer_2': 0.0002843257795664046, 'l1_Layer_3': 1.1964812074792945e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 205, 'n_units_Layer_3': 190}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.80 | sMAPE for Validation Set is: 16.82% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.54 | sMAPE for Test Set is: 16.82% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:44:39,294]\u001b[0m Trial 1356 finished with value: 6.830692523651282 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022804342412257824, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06762586200764424, 'dropout_rate_Layer_2': 0.025617335445127305, 'dropout_rate_Layer_3': 0.13169221342293408, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.799002457147261e-05, 'l1_Layer_2': 0.0002521799964035233, 'l1_Layer_3': 1.317179767559884e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 205, 'n_units_Layer_3': 180}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.83 | sMAPE for Validation Set is: 16.85% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.59 | sMAPE for Test Set is: 16.74% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:44:46,143]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:44:51,674]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:44:56,557]\u001b[0m Trial 1362 finished with value: 6.856608285966089 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024253659674982344, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07435635958582126, 'dropout_rate_Layer_2': 0.029624724602041942, 'dropout_rate_Layer_3': 0.13412441272245565, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4336057664341732e-05, 'l1_Layer_2': 0.0002766639586477157, 'l1_Layer_3': 1.0127288155154295e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 195, 'n_units_Layer_3': 180}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.86 | sMAPE for Validation Set is: 17.01% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.82 | sMAPE for Test Set is: 17.26% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:44:59,157]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:45:04,663]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:45:10,647]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:45:17,524]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:45:18,644]\u001b[0m Trial 1367 finished with value: 6.7632165107624935 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022557934305835496, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07169627974760902, 'dropout_rate_Layer_2': 0.03451862524169455, 'dropout_rate_Layer_3': 0.13330624181590767, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.693879529477293e-05, 'l1_Layer_2': 0.0002757695263037773, 'l1_Layer_3': 1.1561462621862205e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 190, 'n_units_Layer_3': 180}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.76 | sMAPE for Validation Set is: 16.95% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.64 | sMAPE for Test Set is: 17.16% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:45:26,896]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:45:31,637]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:45:37,418]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:45:39,855]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:45:47,154]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:45:52,237]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:45:52,397]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:45:59,784]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:46:04,653]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:46:05,923]\u001b[0m Trial 1376 finished with value: 6.77805251121521 and parameters: {'n_hidden': 3, 'learning_rate': 0.002253042306680041, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06390638238225174, 'dropout_rate_Layer_2': 0.01595866289545534, 'dropout_rate_Layer_3': 0.13502433464060729, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.420329349461798e-05, 'l1_Layer_2': 0.00024303304751068286, 'l1_Layer_3': 1.1955122837955463e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 195, 'n_units_Layer_3': 185}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.78 | sMAPE for Validation Set is: 16.98% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.97 | sMAPE for Test Set is: 17.72% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:46:12,231]\u001b[0m Trial 1375 finished with value: 6.71304482463574 and parameters: {'n_hidden': 3, 'learning_rate': 0.002204534733196072, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08016827452001798, 'dropout_rate_Layer_2': 0.05289923606442687, 'dropout_rate_Layer_3': 0.13416397508199274, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4082995009248309e-05, 'l1_Layer_2': 0.0001678271382198844, 'l1_Layer_3': 1.2110364224689662e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 190, 'n_units_Layer_3': 185}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.71 | sMAPE for Validation Set is: 16.92% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.53 | sMAPE for Test Set is: 16.81% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:46:17,343]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:46:17,488]\u001b[0m Trial 1378 finished with value: 6.958916568147846 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022085441573386684, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06529052884969877, 'dropout_rate_Layer_2': 0.03047537387469013, 'dropout_rate_Layer_3': 0.13747734738198739, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3145715587878289e-05, 'l1_Layer_2': 0.0002493437249186826, 'l1_Layer_3': 1.15347801808092e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 190, 'n_units_Layer_3': 185}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.96 | sMAPE for Validation Set is: 17.22% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.09 | sMAPE for Test Set is: 17.95% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:46:21,713]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:46:28,596]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:46:28,716]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:46:29,598]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:46:35,320]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:46:43,414]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:46:44,044]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:46:49,559]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:46:49,915]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:46:50,561]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:47:00,811]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:47:16,394]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:47:24,102]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:47:25,585]\u001b[0m Trial 1395 finished with value: 6.617341690404232 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022290504004897436, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07612467144887693, 'dropout_rate_Layer_2': 0.011038242293077996, 'dropout_rate_Layer_3': 0.14538778699803637, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.779737863396335e-05, 'l1_Layer_2': 0.00019254707947917823, 'l1_Layer_3': 1.1751250624088092e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 185, 'n_units_Layer_3': 190}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.62 | sMAPE for Validation Set is: 16.58% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.51 | sMAPE for Test Set is: 16.78% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:47:31,952]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:47:34,639]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:47:38,430]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:47:41,284]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:47:47,753]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:47:53,257]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:47:58,079]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:48:02,481]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:48:04,488]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:48:11,517]\u001b[0m Trial 1396 finished with value: 8.168058619996467 and parameters: {'n_hidden': 4, 'learning_rate': 0.006079159401146072, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06487062443595595, 'dropout_rate_Layer_2': 0.27953858402919646, 'dropout_rate_Layer_3': 0.2864067645258282, 'dropout_rate_Layer_4': 0.11289194705784061, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.5826423095905727e-05, 'l1_Layer_2': 0.010320858504118109, 'l1_Layer_3': 0.033328282855887084, 'l1_Layer_4': 4.515252316601864e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 300, 'n_units_Layer_3': 155, 'n_units_Layer_4': 200}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.17 | sMAPE for Validation Set is: 19.47% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 6.17 | sMAPE for Test Set is: 18.01% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:48:13,831]\u001b[0m Trial 1387 finished with value: 8.104517932044727 and parameters: {'n_hidden': 4, 'learning_rate': 0.006317409564202074, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009934340270482855, 'dropout_rate_Layer_2': 0.291247194967011, 'dropout_rate_Layer_3': 0.338652216766669, 'dropout_rate_Layer_4': 0.11324484390021124, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.750654378108162e-05, 'l1_Layer_2': 0.010766990748977218, 'l1_Layer_3': 0.03318461298302863, 'l1_Layer_4': 4.487054977988304e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 205, 'n_units_Layer_3': 245, 'n_units_Layer_4': 200}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.10 | sMAPE for Validation Set is: 19.83% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 6.76 | sMAPE for Test Set is: 19.62% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:48:21,586]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:48:24,876]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:48:28,144]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:48:40,494]\u001b[0m Trial 1408 finished with value: 6.650439171716016 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025033255296661155, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06654402224628295, 'dropout_rate_Layer_2': 0.0319666669040626, 'dropout_rate_Layer_3': 0.1413269103680898, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3921673812290528e-05, 'l1_Layer_2': 0.00018150502094511277, 'l1_Layer_3': 1.0038141261429848e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 195, 'n_units_Layer_3': 180}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.65 | sMAPE for Validation Set is: 16.63% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.58 | sMAPE for Test Set is: 16.92% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:48:43,585]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:48:49,787]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:48:56,076]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:49:01,434]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:49:05,820]\u001b[0m Trial 1412 finished with value: 6.593624435318859 and parameters: {'n_hidden': 3, 'learning_rate': 0.00208566456978072, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06058034368363915, 'dropout_rate_Layer_2': 0.03162343679492359, 'dropout_rate_Layer_3': 0.14077902378508708, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4205170316459489e-05, 'l1_Layer_2': 0.00020801631959856863, 'l1_Layer_3': 1.3316746244472992e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 195, 'n_units_Layer_3': 180}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.59 | sMAPE for Validation Set is: 16.33% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.52 | sMAPE for Test Set is: 16.59% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:49:07,584]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:49:16,347]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:49:25,940]\u001b[0m Trial 1419 finished with value: 6.940725392944543 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021601392390794886, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05885411588698785, 'dropout_rate_Layer_2': 0.029983780874117967, 'dropout_rate_Layer_3': 0.140893701507534, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.027774261156717e-05, 'l1_Layer_2': 0.0001736402533930444, 'l1_Layer_3': 1.0018437785020335e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 195, 'n_units_Layer_3': 180}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.94 | sMAPE for Validation Set is: 17.37% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.81 | sMAPE for Test Set is: 17.64% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:49:36,492]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:49:41,067]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:49:46,488]\u001b[0m Trial 1413 finished with value: 7.5334383287243325 and parameters: {'n_hidden': 4, 'learning_rate': 0.004083177432947097, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10176179953958688, 'dropout_rate_Layer_2': 0.31298509922680334, 'dropout_rate_Layer_3': 0.31997595502552223, 'dropout_rate_Layer_4': 0.2972386610214232, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.006810938736536669, 'l1_Layer_2': 0.006676291285695039, 'l1_Layer_3': 0.06085242053766514, 'l1_Layer_4': 9.253099096365187e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 220, 'n_units_Layer_3': 190, 'n_units_Layer_4': 220}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.53 | sMAPE for Validation Set is: 18.52% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 6.10 | sMAPE for Test Set is: 18.19% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:49:48,005]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:49:54,384]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:49:57,272]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:49:59,533]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:50:08,977]\u001b[0m Trial 1426 finished with value: 6.90918939691682 and parameters: {'n_hidden': 3, 'learning_rate': 0.002168127207997756, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05990768445662468, 'dropout_rate_Layer_2': 0.029428536427118762, 'dropout_rate_Layer_3': 0.1414636916922243, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0064542372153773e-05, 'l1_Layer_2': 0.00017753617675958784, 'l1_Layer_3': 1.1050414736726628e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 195, 'n_units_Layer_3': 180}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.91 | sMAPE for Validation Set is: 17.14% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.76 | sMAPE for Test Set is: 17.32% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:50:10,069]\u001b[0m Trial 1421 finished with value: 6.514245149129013 and parameters: {'n_hidden': 3, 'learning_rate': 0.001602570398443448, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.057391931848803625, 'dropout_rate_Layer_2': 0.05087384171527368, 'dropout_rate_Layer_3': 0.14163155572152752, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0680663165004083e-05, 'l1_Layer_2': 0.00018458065934726307, 'l1_Layer_3': 1.0261967300523563e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 195, 'n_units_Layer_3': 180}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.51 | sMAPE for Validation Set is: 16.23% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.38 | sMAPE for Test Set is: 16.27% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:50:16,113]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:50:22,315]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:50:22,380]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:50:30,754]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:50:35,929]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:50:38,633]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:50:44,518]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:50:49,947]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:50:50,592]\u001b[0m Trial 1429 finished with value: 6.6017699869206 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016085407401920737, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05847420208806038, 'dropout_rate_Layer_2': 0.03034852507449063, 'dropout_rate_Layer_3': 0.1431678699462976, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0958319235609656e-05, 'l1_Layer_2': 0.00015195095788348838, 'l1_Layer_3': 1.0455431286270185e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 195, 'n_units_Layer_3': 180}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.60 | sMAPE for Validation Set is: 16.21% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.63 | sMAPE for Test Set is: 16.75% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:50:58,989]\u001b[0m Trial 1434 finished with value: 6.516044841669014 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015651533811484816, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05906489436194945, 'dropout_rate_Layer_2': 0.05187314753492805, 'dropout_rate_Layer_3': 0.14262414758323746, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0171224419599267e-05, 'l1_Layer_2': 0.00018323976795293792, 'l1_Layer_3': 1.0022385747524358e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 175, 'n_units_Layer_3': 180}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.52 | sMAPE for Validation Set is: 16.31% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.61 | sMAPE for Test Set is: 17.09% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:51:05,588]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.61 | sMAPE for Validation Set is: 16.30% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.82 | sMAPE for Test Set is: 17.27% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:51:08,176]\u001b[0m Trial 1436 finished with value: 6.6097643206219985 and parameters: {'n_hidden': 3, 'learning_rate': 0.002007121345273442, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08259069604738081, 'dropout_rate_Layer_2': 0.04706867393533798, 'dropout_rate_Layer_3': 0.1502616960576294, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0005356372041186e-05, 'l1_Layer_2': 0.00012447763541261424, 'l1_Layer_3': 1.0096028457835778e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 175, 'n_units_Layer_3': 180}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:51:13,855]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:51:17,665]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:51:23,804]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:51:23,851]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:51:29,982]\u001b[0m Trial 1439 finished with value: 6.576033817281604 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015103366882186354, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08255136348588275, 'dropout_rate_Layer_2': 0.05262014110492249, 'dropout_rate_Layer_3': 0.14962853353136013, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3873461411772274e-05, 'l1_Layer_2': 0.00011608057288514171, 'l1_Layer_3': 1.0108781133278956e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 200, 'n_units_Layer_3': 175}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.58 | sMAPE for Validation Set is: 16.44% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.79 | sMAPE for Test Set is: 17.55% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:51:34,347]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:51:48,116]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:51:54,102]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.66 | sMAPE for Validation Set is: 16.79% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.59 | sMAPE for Test Set is: 17.11% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:51:56,948]\u001b[0m Trial 1449 finished with value: 6.664151204780882 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015283704490794542, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08266604306309411, 'dropout_rate_Layer_2': 0.053492763650228106, 'dropout_rate_Layer_3': 0.14929369867923206, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4535606487964964e-05, 'l1_Layer_2': 0.00012033818934117249, 'l1_Layer_3': 1.0125558406340958e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 200, 'n_units_Layer_3': 175}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:52:02,005]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:52:05,451]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:52:10,077]\u001b[0m Trial 1446 finished with value: 6.561494628333346 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013999742590529174, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08368385851271705, 'dropout_rate_Layer_2': 0.04811463018699922, 'dropout_rate_Layer_3': 0.1511089496317592, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3515829145423336e-05, 'l1_Layer_2': 0.0001315700088936513, 'l1_Layer_3': 1.3017419303863707e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 180, 'n_units_Layer_3': 190}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.56 | sMAPE for Validation Set is: 16.46% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.59 | sMAPE for Test Set is: 16.92% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:52:10,925]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:52:11,092]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:52:17,849]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:52:24,076]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:52:28,590]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:52:34,031]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:52:49,308]\u001b[0m Trial 1456 finished with value: 6.546175684495178 and parameters: {'n_hidden': 3, 'learning_rate': 0.001244839943848269, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0825063847361012, 'dropout_rate_Layer_2': 0.0400813716558938, 'dropout_rate_Layer_3': 0.15151383187001938, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2040565507580511e-05, 'l1_Layer_2': 0.00010974366937722053, 'l1_Layer_3': 1.2964906566393456e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 180, 'n_units_Layer_3': 190}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:52:49,386]\u001b[0m Trial 1455 finished with value: 6.631234753627463 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015476463739893828, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10260383579171727, 'dropout_rate_Layer_2': 0.05146735216756654, 'dropout_rate_Layer_3': 0.14929684639977853, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2093646414684703e-05, 'l1_Layer_2': 0.00010790104071558521, 'l1_Layer_3': 1.0019846635030095e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 185, 'n_units_Layer_3': 190}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.55 | sMAPE for Validation Set is: 16.35% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.73 | sMAPE for Test Set is: 17.29% | rMAE for Test Set is: 0.71\n",
      "MAE for Validation Set is: 6.63 | sMAPE for Validation Set is: 16.55% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.80 | sMAPE for Test Set is: 17.54% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:52:59,087]\u001b[0m Trial 1461 finished with value: 6.515059966357282 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017523730018112287, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10553072923322138, 'dropout_rate_Layer_2': 0.1926590723717472, 'dropout_rate_Layer_3': 0.2898611409275148, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00021475094145211493, 'l1_Layer_2': 0.00011101172679990991, 'l1_Layer_3': 0.008802035771629134, 'n_units_Layer_1': 210, 'n_units_Layer_2': 235, 'n_units_Layer_3': 290}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.52 | sMAPE for Validation Set is: 16.35% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.61 | sMAPE for Test Set is: 17.01% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:53:04,538]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:53:18,182]\u001b[0m Trial 1462 finished with value: 6.578511595109433 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011231530433694625, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08424784971375998, 'dropout_rate_Layer_2': 0.040866142976638105, 'dropout_rate_Layer_3': 0.15202335096238723, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2150458456722706e-05, 'l1_Layer_2': 0.00012743659610336969, 'l1_Layer_3': 1.0041601246432005e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 180, 'n_units_Layer_3': 195}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.58 | sMAPE for Validation Set is: 16.47% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.69 | sMAPE for Test Set is: 17.40% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:53:23,143]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:53:29,068]\u001b[0m Trial 1463 finished with value: 6.5812383761372075 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011342791376803202, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08240796832961499, 'dropout_rate_Layer_2': 0.040382615236610575, 'dropout_rate_Layer_3': 0.14783895331818725, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.184263045868976e-05, 'l1_Layer_2': 0.00011040259109922033, 'l1_Layer_3': 1.2844993879448575e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 180, 'n_units_Layer_3': 195}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.58 | sMAPE for Validation Set is: 16.66% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.61 | sMAPE for Test Set is: 17.31% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:53:30,219]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:53:36,133]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:53:39,743]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:53:44,152]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:53:49,859]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:53:56,706]\u001b[0m Trial 1457 finished with value: 7.478999472170568 and parameters: {'n_hidden': 4, 'learning_rate': 0.003077139226460502, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11880022410153654, 'dropout_rate_Layer_2': 0.04663356316271095, 'dropout_rate_Layer_3': 0.29818697484244155, 'dropout_rate_Layer_4': 0.3173348701319427, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.6304656981352536e-05, 'l1_Layer_2': 0.004811085255422109, 'l1_Layer_3': 0.024013903826490872, 'l1_Layer_4': 2.443388670938389e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 210, 'n_units_Layer_3': 200, 'n_units_Layer_4': 235}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.48 | sMAPE for Validation Set is: 18.15% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 7.40 | sMAPE for Test Set is: 20.79% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:53:57,159]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:54:05,767]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:54:11,062]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:54:16,911]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:54:18,495]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:54:21,482]\u001b[0m Trial 1471 finished with value: 6.742740651760215 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012474017422717015, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09612522245464632, 'dropout_rate_Layer_2': 0.05557260204131915, 'dropout_rate_Layer_3': 0.149925827397234, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0065020033039519e-05, 'l1_Layer_2': 0.00011734600851636079, 'l1_Layer_3': 1.2922360724978257e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 175, 'n_units_Layer_3': 195}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.74 | sMAPE for Validation Set is: 16.97% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.71 | sMAPE for Test Set is: 17.49% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:54:26,751]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:54:31,682]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:54:31,924]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:54:42,501]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:54:43,303]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:54:50,459]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:54:51,366]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:54:56,608]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:54:58,851]\u001b[0m Trial 1479 finished with value: 6.670864787165567 and parameters: {'n_hidden': 3, 'learning_rate': 0.00104957260716296, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09590119009547039, 'dropout_rate_Layer_2': 0.038912397895229316, 'dropout_rate_Layer_3': 0.14985787270641804, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1803238595980306e-05, 'l1_Layer_2': 0.00011339749486303668, 'l1_Layer_3': 1.0005582701522643e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 175, 'n_units_Layer_3': 205}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.67 | sMAPE for Validation Set is: 16.72% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.55 | sMAPE for Test Set is: 17.05% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:55:02,556]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:55:04,053]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:55:12,925]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:55:18,582]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:55:19,518]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:55:30,588]\u001b[0m Trial 1486 finished with value: 6.514923811928409 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010130345835248319, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09189945555522826, 'dropout_rate_Layer_2': 0.03859548863499176, 'dropout_rate_Layer_3': 0.15020477978829871, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1909399912448553e-05, 'l1_Layer_2': 0.00011475617483121755, 'l1_Layer_3': 1.0091188348205688e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 175, 'n_units_Layer_3': 210}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.51 | sMAPE for Validation Set is: 16.26% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.49 | sMAPE for Test Set is: 16.71% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:55:36,011]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:55:36,434]\u001b[0m Trial 1493 finished with value: 6.66077950252945 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023999220828221346, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10600521139729596, 'dropout_rate_Layer_2': 0.21876361246197765, 'dropout_rate_Layer_3': 0.27819267188798347, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00023752565367975492, 'l1_Layer_2': 8.773292720463645e-05, 'l1_Layer_3': 3.753870070357935e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 140, 'n_units_Layer_3': 280}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.66 | sMAPE for Validation Set is: 16.71% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.84 | sMAPE for Test Set is: 17.68% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-05 22:55:45,998]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:55:50,233]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:55:51,254]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:55:55,723]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:55:56,369]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-05 22:55:57,264]\u001b[0m Trial 1489 finished with value: 7.534880295274864 and parameters: {'n_hidden': 4, 'learning_rate': 0.004436288531164838, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1266205439143291, 'dropout_rate_Layer_2': 0.0437521344158406, 'dropout_rate_Layer_3': 0.2845856100167885, 'dropout_rate_Layer_4': 0.2561346392033088, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.3212531391068444e-05, 'l1_Layer_2': 0.007738872830649758, 'l1_Layer_3': 0.014884454946977153, 'l1_Layer_4': 2.854988385707875e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 225, 'n_units_Layer_3': 200, 'n_units_Layer_4': 240}. Best is trial 975 with value: 6.2897366345306125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.53 | sMAPE for Validation Set is: 18.51% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 6.11 | sMAPE for Test Set is: 18.08% | rMAE for Test Set is: 0.75\n",
      "for 2019-01-01, MAE is:36.05 & sMAPE is:182.55% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :36.05 & 182.55% & 1.41\n",
      "for 2019-01-02, MAE is:34.94 & sMAPE is:136.19% & rMAE is:1.92 ||| daily mean of MAE & sMAPE & rMAE till now are :35.50 & 159.37% & 1.66\n",
      "for 2019-01-03, MAE is:10.69 & sMAPE is:22.27% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :27.23 & 113.67% & 1.68\n",
      "for 2019-01-04, MAE is:5.47 & sMAPE is:11.27% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :21.79 & 88.07% & 1.63\n",
      "for 2019-01-05, MAE is:11.49 & sMAPE is:29.18% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :19.73 & 76.29% & 1.52\n",
      "for 2019-01-06, MAE is:5.57 & sMAPE is:11.67% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :17.37 & 65.52% & 1.32\n",
      "for 2019-01-07, MAE is:9.12 & sMAPE is:19.24% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :16.19 & 58.91% & 1.28\n",
      "for 2019-01-08, MAE is:7.09 & sMAPE is:24.60% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :15.05 & 54.62% & 1.14\n",
      "for 2019-01-09, MAE is:10.63 & sMAPE is:35.52% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :14.56 & 52.50% & 1.09\n",
      "for 2019-01-10, MAE is:16.21 & sMAPE is:26.36% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :14.73 & 49.88% & 1.12\n",
      "for 2019-01-11, MAE is:5.36 & sMAPE is:10.17% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :13.87 & 46.27% & 1.14\n",
      "for 2019-01-12, MAE is:3.21 & sMAPE is:6.98% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :12.99 & 43.00% & 1.08\n",
      "for 2019-01-13, MAE is:9.34 & sMAPE is:29.49% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :12.71 & 41.96% & 1.05\n",
      "for 2019-01-14, MAE is:18.88 & sMAPE is:80.94% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :13.15 & 44.74% & 1.04\n",
      "for 2019-01-15, MAE is:8.85 & sMAPE is:20.58% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :12.86 & 43.13% & 1.00\n",
      "for 2019-01-16, MAE is:4.87 & sMAPE is:10.23% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :12.36 & 41.08% & 0.96\n",
      "for 2019-01-17, MAE is:4.74 & sMAPE is:10.28% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :11.91 & 39.26% & 0.92\n",
      "for 2019-01-18, MAE is:9.28 & sMAPE is:16.09% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :11.77 & 37.98% & 0.92\n",
      "for 2019-01-19, MAE is:2.93 & sMAPE is:5.37% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :11.30 & 36.26% & 0.89\n",
      "for 2019-01-20, MAE is:3.65 & sMAPE is:6.71% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :10.92 & 34.78% & 0.86\n",
      "for 2019-01-21, MAE is:11.47 & sMAPE is:17.48% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :10.94 & 33.96% & 0.83\n",
      "for 2019-01-22, MAE is:5.57 & sMAPE is:8.81% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :10.70 & 32.82% & 0.81\n",
      "for 2019-01-23, MAE is:11.42 & sMAPE is:16.28% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :10.73 & 32.10% & 0.81\n",
      "for 2019-01-24, MAE is:19.61 & sMAPE is:25.59% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :11.10 & 31.83% & 0.80\n",
      "for 2019-01-25, MAE is:6.57 & sMAPE is:9.58% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :10.92 & 30.94% & 0.81\n",
      "for 2019-01-26, MAE is:2.81 & sMAPE is:5.34% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :10.61 & 29.95% & 0.84\n",
      "for 2019-01-27, MAE is:6.25 & sMAPE is:16.86% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :10.45 & 29.47% & 0.83\n",
      "for 2019-01-28, MAE is:5.20 & sMAPE is:9.33% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :10.26 & 28.75% & 0.82\n",
      "for 2019-01-29, MAE is:7.35 & sMAPE is:12.48% & rMAE is:2.16 ||| daily mean of MAE & sMAPE & rMAE till now are :10.16 & 28.19% & 0.87\n",
      "for 2019-01-30, MAE is:4.58 & sMAPE is:7.73% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :9.97 & 27.51% & 0.85\n",
      "for 2019-01-31, MAE is:4.71 & sMAPE is:8.02% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :9.80 & 26.88% & 0.83\n",
      "for 2019-02-01, MAE is:5.48 & sMAPE is:9.15% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :9.67 & 26.32% & 0.82\n",
      "for 2019-02-02, MAE is:2.37 & sMAPE is:4.89% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :9.45 & 25.67% & 0.82\n",
      "for 2019-02-03, MAE is:2.62 & sMAPE is:5.34% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :9.25 & 25.07% & 0.81\n",
      "for 2019-02-04, MAE is:6.32 & sMAPE is:12.33% & rMAE is:1.67 ||| daily mean of MAE & sMAPE & rMAE till now are :9.16 & 24.71% & 0.83\n",
      "for 2019-02-05, MAE is:5.24 & sMAPE is:11.18% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :9.05 & 24.34% & 0.82\n",
      "for 2019-02-06, MAE is:3.79 & sMAPE is:6.97% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :8.91 & 23.87% & 0.82\n",
      "for 2019-02-07, MAE is:4.88 & sMAPE is:9.73% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :8.81 & 23.49% & 0.81\n",
      "for 2019-02-08, MAE is:5.80 & sMAPE is:14.32% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :8.73 & 23.26% & 0.80\n",
      "for 2019-02-09, MAE is:24.10 & sMAPE is:129.17% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :9.11 & 25.91% & 0.80\n",
      "for 2019-02-10, MAE is:20.70 & sMAPE is:73.13% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :9.40 & 27.06% & 0.81\n",
      "for 2019-02-11, MAE is:8.46 & sMAPE is:36.99% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :9.37 & 27.29% & 0.81\n",
      "for 2019-02-12, MAE is:5.24 & sMAPE is:11.70% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :9.28 & 26.93% & 0.83\n",
      "for 2019-02-13, MAE is:2.69 & sMAPE is:6.04% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :9.13 & 26.46% & 0.81\n",
      "for 2019-02-14, MAE is:4.84 & sMAPE is:9.73% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :9.03 & 26.09% & 0.82\n",
      "for 2019-02-15, MAE is:6.94 & sMAPE is:15.79% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :8.99 & 25.86% & 0.82\n",
      "for 2019-02-16, MAE is:5.55 & sMAPE is:15.39% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :8.91 & 25.64% & 0.81\n",
      "for 2019-02-17, MAE is:6.11 & sMAPE is:15.59% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :8.86 & 25.43% & 0.80\n",
      "for 2019-02-18, MAE is:5.46 & sMAPE is:12.76% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :8.79 & 25.17% & 0.80\n",
      "for 2019-02-19, MAE is:2.42 & sMAPE is:5.85% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :8.66 & 24.78% & 0.79\n",
      "for 2019-02-20, MAE is:5.39 & sMAPE is:12.05% & rMAE is:1.78 ||| daily mean of MAE & sMAPE & rMAE till now are :8.59 & 24.53% & 0.81\n",
      "for 2019-02-21, MAE is:3.17 & sMAPE is:7.07% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :8.49 & 24.20% & 0.80\n",
      "for 2019-02-22, MAE is:4.56 & sMAPE is:10.03% & rMAE is:1.98 ||| daily mean of MAE & sMAPE & rMAE till now are :8.42 & 23.93% & 0.83\n",
      "for 2019-02-23, MAE is:1.77 & sMAPE is:4.26% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :8.29 & 23.57% & 0.83\n",
      "for 2019-02-24, MAE is:3.13 & sMAPE is:8.37% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :8.20 & 23.29% & 0.83\n",
      "for 2019-02-25, MAE is:4.29 & sMAPE is:9.73% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :8.13 & 23.05% & 0.84\n",
      "for 2019-02-26, MAE is:5.15 & sMAPE is:11.80% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :8.08 & 22.85% & 0.85\n",
      "for 2019-02-27, MAE is:3.73 & sMAPE is:9.27% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :8.00 & 22.62% & 0.85\n",
      "for 2019-02-28, MAE is:4.19 & sMAPE is:10.50% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :7.94 & 22.41% & 0.86\n",
      "for 2019-03-01, MAE is:3.95 & sMAPE is:9.01% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :7.87 & 22.19% & 0.87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-03-02, MAE is:3.88 & sMAPE is:10.08% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :7.81 & 21.99% & 0.87\n",
      "for 2019-03-03, MAE is:12.52 & sMAPE is:50.62% & rMAE is:2.06 ||| daily mean of MAE & sMAPE & rMAE till now are :7.88 & 22.45% & 0.88\n",
      "for 2019-03-04, MAE is:14.23 & sMAPE is:68.70% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :7.98 & 23.19% & 0.88\n",
      "for 2019-03-05, MAE is:16.26 & sMAPE is:76.29% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :8.11 & 24.02% & 0.89\n",
      "for 2019-03-06, MAE is:5.93 & sMAPE is:15.61% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :8.08 & 23.89% & 0.90\n",
      "for 2019-03-07, MAE is:7.74 & sMAPE is:20.90% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :8.07 & 23.84% & 0.91\n",
      "for 2019-03-08, MAE is:6.35 & sMAPE is:19.66% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :8.05 & 23.78% & 0.90\n",
      "for 2019-03-09, MAE is:29.01 & sMAPE is:140.46% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :8.36 & 25.49% & 0.90\n",
      "for 2019-03-10, MAE is:22.62 & sMAPE is:118.34% & rMAE is:2.84 ||| daily mean of MAE & sMAPE & rMAE till now are :8.56 & 26.84% & 0.93\n",
      "for 2019-03-11, MAE is:9.01 & sMAPE is:23.10% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :8.57 & 26.79% & 0.92\n",
      "for 2019-03-12, MAE is:6.65 & sMAPE is:20.39% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :8.54 & 26.70% & 0.91\n",
      "for 2019-03-13, MAE is:9.69 & sMAPE is:29.26% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :8.56 & 26.73% & 0.92\n",
      "for 2019-03-14, MAE is:3.44 & sMAPE is:9.78% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :8.49 & 26.50% & 0.92\n",
      "for 2019-03-15, MAE is:7.91 & sMAPE is:27.05% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :8.48 & 26.51% & 0.92\n",
      "for 2019-03-16, MAE is:17.10 & sMAPE is:86.79% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :8.59 & 27.31% & 0.92\n",
      "for 2019-03-17, MAE is:27.42 & sMAPE is:148.46% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :8.84 & 28.91% & 0.92\n",
      "for 2019-03-18, MAE is:12.04 & sMAPE is:38.49% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :8.88 & 29.03% & 0.93\n",
      "for 2019-03-19, MAE is:4.64 & sMAPE is:10.70% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :8.83 & 28.79% & 0.92\n",
      "for 2019-03-20, MAE is:3.13 & sMAPE is:7.22% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :8.76 & 28.52% & 0.92\n",
      "for 2019-03-21, MAE is:3.28 & sMAPE is:8.39% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :8.69 & 28.27% & 0.92\n",
      "for 2019-03-22, MAE is:3.60 & sMAPE is:8.60% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :8.63 & 28.03% & 0.92\n",
      "for 2019-03-23, MAE is:4.20 & sMAPE is:12.38% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :8.57 & 27.84% & 0.91\n",
      "for 2019-03-24, MAE is:3.50 & sMAPE is:10.62% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :8.51 & 27.63% & 0.90\n",
      "for 2019-03-25, MAE is:3.40 & sMAPE is:10.63% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :8.45 & 27.43% & 0.90\n",
      "for 2019-03-26, MAE is:3.75 & sMAPE is:9.38% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :8.40 & 27.21% & 0.89\n",
      "for 2019-03-27, MAE is:2.33 & sMAPE is:5.61% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :8.32 & 26.96% & 0.90\n",
      "for 2019-03-28, MAE is:4.63 & sMAPE is:11.39% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :8.28 & 26.78% & 0.90\n",
      "for 2019-03-29, MAE is:4.27 & sMAPE is:11.07% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :8.24 & 26.61% & 0.91\n",
      "for 2019-03-30, MAE is:4.41 & sMAPE is:13.11% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :8.19 & 26.45% & 0.91\n",
      "for 2019-03-31, MAE is:7.20 & sMAPE is:33.67% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :8.18 & 26.53% & 0.91\n",
      "for 2019-04-01, MAE is:4.08 & sMAPE is:10.30% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :8.14 & 26.36% & 0.91\n",
      "for 2019-04-02, MAE is:2.54 & sMAPE is:7.53% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :8.08 & 26.15% & 0.91\n",
      "for 2019-04-03, MAE is:10.84 & sMAPE is:29.11% & rMAE is:2.96 ||| daily mean of MAE & sMAPE & rMAE till now are :8.11 & 26.18% & 0.93\n",
      "for 2019-04-04, MAE is:8.47 & sMAPE is:21.58% & rMAE is:2.88 ||| daily mean of MAE & sMAPE & rMAE till now are :8.11 & 26.13% & 0.95\n",
      "for 2019-04-05, MAE is:5.62 & sMAPE is:13.61% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :8.08 & 26.00% & 0.95\n",
      "for 2019-04-06, MAE is:6.57 & sMAPE is:18.25% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :8.07 & 25.92% & 0.95\n",
      "for 2019-04-07, MAE is:5.68 & sMAPE is:15.25% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :8.04 & 25.81% & 0.95\n",
      "for 2019-04-08, MAE is:3.04 & sMAPE is:7.33% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :7.99 & 25.62% & 0.94\n",
      "for 2019-04-09, MAE is:4.48 & sMAPE is:11.61% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :7.96 & 25.48% & 0.94\n",
      "for 2019-04-10, MAE is:3.49 & sMAPE is:8.36% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :7.91 & 25.31% & 0.94\n",
      "for 2019-04-11, MAE is:4.12 & sMAPE is:9.16% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :7.87 & 25.15% & 0.94\n",
      "for 2019-04-12, MAE is:3.95 & sMAPE is:8.71% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :7.84 & 24.99% & 0.94\n",
      "for 2019-04-13, MAE is:2.46 & sMAPE is:5.78% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :7.78 & 24.80% & 0.93\n",
      "for 2019-04-14, MAE is:4.45 & sMAPE is:11.70% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :7.75 & 24.68% & 0.94\n",
      "for 2019-04-15, MAE is:6.14 & sMAPE is:14.71% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :7.74 & 24.58% & 0.95\n",
      "for 2019-04-16, MAE is:6.01 & sMAPE is:14.73% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :7.72 & 24.49% & 0.95\n",
      "for 2019-04-17, MAE is:3.14 & sMAPE is:7.61% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :7.68 & 24.33% & 0.96\n",
      "for 2019-04-18, MAE is:7.18 & sMAPE is:17.65% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :7.67 & 24.27% & 0.96\n",
      "for 2019-04-19, MAE is:3.18 & sMAPE is:8.04% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :7.63 & 24.12% & 0.96\n",
      "for 2019-04-20, MAE is:4.21 & sMAPE is:10.73% & rMAE is:1.92 ||| daily mean of MAE & sMAPE & rMAE till now are :7.60 & 24.00% & 0.97\n",
      "for 2019-04-21, MAE is:2.32 & sMAPE is:5.98% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :7.55 & 23.84% & 0.97\n",
      "for 2019-04-22, MAE is:10.45 & sMAPE is:41.37% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :7.58 & 23.99% & 0.96\n",
      "for 2019-04-23, MAE is:17.71 & sMAPE is:115.43% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :7.67 & 24.80% & 0.96\n",
      "for 2019-04-24, MAE is:10.27 & sMAPE is:48.34% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :7.69 & 25.01% & 0.96\n",
      "for 2019-04-25, MAE is:8.20 & sMAPE is:21.28% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :7.70 & 24.98% & 0.96\n",
      "for 2019-04-26, MAE is:7.95 & sMAPE is:19.78% & rMAE is:2.21 ||| daily mean of MAE & sMAPE & rMAE till now are :7.70 & 24.93% & 0.98\n",
      "for 2019-04-27, MAE is:2.04 & sMAPE is:6.24% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :7.65 & 24.77% & 0.97\n",
      "for 2019-04-28, MAE is:4.79 & sMAPE is:13.91% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :7.63 & 24.68% & 0.97\n",
      "for 2019-04-29, MAE is:6.86 & sMAPE is:17.29% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :7.62 & 24.62% & 0.97\n",
      "for 2019-04-30, MAE is:5.04 & sMAPE is:11.86% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :7.60 & 24.51% & 0.96\n",
      "for 2019-05-01, MAE is:13.30 & sMAPE is:52.64% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :7.64 & 24.74% & 0.96\n",
      "for 2019-05-02, MAE is:10.80 & sMAPE is:51.76% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :7.67 & 24.96% & 0.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-05-03, MAE is:5.88 & sMAPE is:16.39% & rMAE is:1.62 ||| daily mean of MAE & sMAPE & rMAE till now are :7.66 & 24.90% & 0.96\n",
      "for 2019-05-04, MAE is:2.09 & sMAPE is:5.40% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :7.61 & 24.74% & 0.96\n",
      "for 2019-05-05, MAE is:8.38 & sMAPE is:26.11% & rMAE is:1.73 ||| daily mean of MAE & sMAPE & rMAE till now are :7.62 & 24.75% & 0.96\n",
      "for 2019-05-06, MAE is:5.18 & sMAPE is:12.27% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :7.60 & 24.65% & 0.97\n",
      "for 2019-05-07, MAE is:4.53 & sMAPE is:8.48% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :7.57 & 24.52% & 0.97\n",
      "for 2019-05-08, MAE is:7.60 & sMAPE is:16.82% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :7.57 & 24.46% & 0.96\n",
      "for 2019-05-09, MAE is:9.56 & sMAPE is:22.65% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :7.59 & 24.45% & 0.96\n",
      "for 2019-05-10, MAE is:3.95 & sMAPE is:8.82% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :7.56 & 24.33% & 0.96\n",
      "for 2019-05-11, MAE is:3.65 & sMAPE is:9.40% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :7.53 & 24.21% & 0.96\n",
      "for 2019-05-12, MAE is:15.23 & sMAPE is:64.48% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :7.59 & 24.52% & 0.96\n",
      "for 2019-05-13, MAE is:5.20 & sMAPE is:13.26% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :7.57 & 24.43% & 0.97\n",
      "for 2019-05-14, MAE is:3.89 & sMAPE is:8.53% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :7.54 & 24.32% & 0.97\n",
      "for 2019-05-15, MAE is:7.07 & sMAPE is:16.26% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :7.54 & 24.26% & 0.97\n",
      "for 2019-05-16, MAE is:2.37 & sMAPE is:6.12% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :7.50 & 24.12% & 0.96\n",
      "for 2019-05-17, MAE is:9.75 & sMAPE is:24.90% & rMAE is:3.39 ||| daily mean of MAE & sMAPE & rMAE till now are :7.52 & 24.13% & 0.98\n",
      "for 2019-05-18, MAE is:2.73 & sMAPE is:7.25% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :7.48 & 24.01% & 0.98\n",
      "for 2019-05-19, MAE is:1.86 & sMAPE is:5.15% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :7.44 & 23.87% & 0.97\n",
      "for 2019-05-20, MAE is:7.99 & sMAPE is:18.33% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :7.45 & 23.83% & 0.98\n",
      "for 2019-05-21, MAE is:4.69 & sMAPE is:11.47% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :7.43 & 23.74% & 0.98\n",
      "for 2019-05-22, MAE is:3.11 & sMAPE is:7.63% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :7.40 & 23.63% & 0.97\n",
      "for 2019-05-23, MAE is:4.29 & sMAPE is:10.12% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :7.38 & 23.54% & 0.98\n",
      "for 2019-05-24, MAE is:4.16 & sMAPE is:10.01% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :7.35 & 23.44% & 0.98\n",
      "for 2019-05-25, MAE is:2.05 & sMAPE is:6.00% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :7.32 & 23.32% & 0.97\n",
      "for 2019-05-26, MAE is:6.04 & sMAPE is:22.35% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :7.31 & 23.31% & 0.97\n",
      "for 2019-05-27, MAE is:4.79 & sMAPE is:17.99% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :7.29 & 23.28% & 0.97\n",
      "for 2019-05-28, MAE is:4.48 & sMAPE is:10.48% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :7.27 & 23.19% & 0.97\n",
      "for 2019-05-29, MAE is:9.40 & sMAPE is:24.76% & rMAE is:3.68 ||| daily mean of MAE & sMAPE & rMAE till now are :7.29 & 23.20% & 0.99\n",
      "for 2019-05-30, MAE is:16.68 & sMAPE is:93.57% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :7.35 & 23.67% & 0.99\n",
      "for 2019-05-31, MAE is:10.23 & sMAPE is:32.34% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :7.37 & 23.73% & 0.99\n",
      "for 2019-06-01, MAE is:4.76 & sMAPE is:15.80% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :7.35 & 23.68% & 0.99\n",
      "for 2019-06-02, MAE is:4.00 & sMAPE is:14.52% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :7.33 & 23.62% & 0.99\n",
      "for 2019-06-03, MAE is:8.17 & sMAPE is:22.70% & rMAE is:1.94 ||| daily mean of MAE & sMAPE & rMAE till now are :7.33 & 23.61% & 0.99\n",
      "for 2019-06-04, MAE is:4.74 & sMAPE is:12.04% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :7.32 & 23.54% & 0.99\n",
      "for 2019-06-05, MAE is:10.93 & sMAPE is:34.58% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :7.34 & 23.61% & 1.00\n",
      "for 2019-06-06, MAE is:3.43 & sMAPE is:10.78% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :7.32 & 23.53% & 0.99\n",
      "for 2019-06-07, MAE is:8.00 & sMAPE is:20.32% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :7.32 & 23.51% & 0.99\n",
      "for 2019-06-08, MAE is:14.33 & sMAPE is:93.26% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :7.36 & 23.94% & 0.99\n",
      "for 2019-06-09, MAE is:12.38 & sMAPE is:82.28% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :7.40 & 24.31% & 0.99\n",
      "for 2019-06-10, MAE is:4.72 & sMAPE is:17.62% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :7.38 & 24.27% & 0.99\n",
      "for 2019-06-11, MAE is:8.27 & sMAPE is:20.95% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :7.38 & 24.25% & 0.99\n",
      "for 2019-06-12, MAE is:7.61 & sMAPE is:18.51% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :7.39 & 24.21% & 0.99\n",
      "for 2019-06-13, MAE is:12.20 & sMAPE is:37.02% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :7.42 & 24.29% & 0.99\n",
      "for 2019-06-14, MAE is:6.82 & sMAPE is:15.51% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :7.41 & 24.24% & 0.99\n",
      "for 2019-06-15, MAE is:6.69 & sMAPE is:21.61% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :7.41 & 24.22% & 0.99\n",
      "for 2019-06-16, MAE is:7.79 & sMAPE is:25.61% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :7.41 & 24.23% & 0.98\n",
      "for 2019-06-17, MAE is:7.98 & sMAPE is:17.80% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :7.41 & 24.19% & 0.98\n",
      "for 2019-06-18, MAE is:7.27 & sMAPE is:17.68% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :7.41 & 24.15% & 0.98\n",
      "for 2019-06-19, MAE is:4.73 & sMAPE is:11.14% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :7.40 & 24.08% & 0.98\n",
      "for 2019-06-20, MAE is:5.04 & sMAPE is:12.50% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :7.38 & 24.01% & 0.98\n",
      "for 2019-06-21, MAE is:3.90 & sMAPE is:10.90% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :7.36 & 23.93% & 0.98\n",
      "for 2019-06-22, MAE is:5.78 & sMAPE is:20.38% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :7.35 & 23.91% & 0.98\n",
      "for 2019-06-23, MAE is:3.14 & sMAPE is:11.80% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :7.33 & 23.84% & 0.98\n",
      "for 2019-06-24, MAE is:4.87 & sMAPE is:12.97% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :7.32 & 23.78% & 0.98\n",
      "for 2019-06-25, MAE is:7.75 & sMAPE is:17.35% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :7.32 & 23.74% & 0.98\n",
      "for 2019-06-26, MAE is:7.38 & sMAPE is:21.44% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :7.32 & 23.73% & 0.98\n",
      "for 2019-06-27, MAE is:10.22 & sMAPE is:34.02% & rMAE is:2.09 ||| daily mean of MAE & sMAPE & rMAE till now are :7.33 & 23.79% & 0.99\n",
      "for 2019-06-28, MAE is:9.21 & sMAPE is:22.00% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :7.34 & 23.78% & 0.99\n",
      "for 2019-06-29, MAE is:6.11 & sMAPE is:17.50% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :7.34 & 23.74% & 0.99\n",
      "for 2019-06-30, MAE is:9.67 & sMAPE is:46.09% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :7.35 & 23.87% & 0.99\n",
      "for 2019-07-01, MAE is:5.56 & sMAPE is:20.72% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :7.34 & 23.85% & 0.99\n",
      "for 2019-07-02, MAE is:3.39 & sMAPE is:11.85% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :7.32 & 23.78% & 0.99\n",
      "for 2019-07-03, MAE is:4.34 & sMAPE is:14.20% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :7.30 & 23.73% & 0.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-07-04, MAE is:4.29 & sMAPE is:14.62% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :7.29 & 23.68% & 0.99\n",
      "for 2019-07-05, MAE is:3.88 & sMAPE is:12.71% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :7.27 & 23.62% & 0.98\n",
      "for 2019-07-06, MAE is:2.89 & sMAPE is:11.07% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :7.25 & 23.56% & 0.98\n",
      "for 2019-07-07, MAE is:1.85 & sMAPE is:6.93% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :7.22 & 23.47% & 0.98\n",
      "for 2019-07-08, MAE is:3.24 & sMAPE is:10.37% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :7.20 & 23.40% & 0.97\n",
      "for 2019-07-09, MAE is:8.55 & sMAPE is:25.69% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :7.20 & 23.41% & 0.97\n",
      "for 2019-07-10, MAE is:7.93 & sMAPE is:21.31% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :7.21 & 23.40% & 0.97\n",
      "for 2019-07-11, MAE is:8.30 & sMAPE is:19.34% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :7.21 & 23.38% & 0.97\n",
      "for 2019-07-12, MAE is:8.56 & sMAPE is:20.28% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :7.22 & 23.36% & 0.97\n",
      "for 2019-07-13, MAE is:2.82 & sMAPE is:7.94% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :7.20 & 23.28% & 0.96\n",
      "for 2019-07-14, MAE is:4.62 & sMAPE is:13.82% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :7.18 & 23.23% & 0.96\n",
      "for 2019-07-15, MAE is:5.46 & sMAPE is:14.96% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :7.17 & 23.19% & 0.96\n",
      "for 2019-07-16, MAE is:8.89 & sMAPE is:23.12% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :7.18 & 23.19% & 0.96\n",
      "for 2019-07-17, MAE is:6.70 & sMAPE is:15.51% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :7.18 & 23.15% & 0.97\n",
      "for 2019-07-18, MAE is:5.44 & sMAPE is:13.11% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :7.17 & 23.10% & 0.97\n",
      "for 2019-07-19, MAE is:9.11 & sMAPE is:22.12% & rMAE is:3.43 ||| daily mean of MAE & sMAPE & rMAE till now are :7.18 & 23.10% & 0.98\n",
      "for 2019-07-20, MAE is:2.66 & sMAPE is:6.99% & rMAE is:2.25 ||| daily mean of MAE & sMAPE & rMAE till now are :7.16 & 23.02% & 0.99\n",
      "for 2019-07-21, MAE is:2.69 & sMAPE is:7.98% & rMAE is:1.96 ||| daily mean of MAE & sMAPE & rMAE till now are :7.14 & 22.94% & 0.99\n",
      "for 2019-07-22, MAE is:4.13 & sMAPE is:10.81% & rMAE is:2.54 ||| daily mean of MAE & sMAPE & rMAE till now are :7.12 & 22.88% & 1.00\n",
      "for 2019-07-23, MAE is:10.39 & sMAPE is:24.06% & rMAE is:2.57 ||| daily mean of MAE & sMAPE & rMAE till now are :7.14 & 22.89% & 1.01\n",
      "for 2019-07-24, MAE is:7.05 & sMAPE is:13.81% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :7.14 & 22.84% & 1.01\n",
      "for 2019-07-25, MAE is:4.38 & sMAPE is:8.34% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :7.12 & 22.77% & 1.01\n",
      "for 2019-07-26, MAE is:3.56 & sMAPE is:8.00% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :7.11 & 22.70% & 1.01\n",
      "for 2019-07-27, MAE is:2.53 & sMAPE is:7.26% & rMAE is:2.07 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 22.63% & 1.02\n",
      "for 2019-07-28, MAE is:1.86 & sMAPE is:5.49% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :7.06 & 22.55% & 1.01\n",
      "for 2019-07-29, MAE is:7.31 & sMAPE is:16.99% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :7.06 & 22.52% & 1.02\n",
      "for 2019-07-30, MAE is:4.90 & sMAPE is:11.64% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :7.05 & 22.47% & 1.02\n",
      "for 2019-07-31, MAE is:9.33 & sMAPE is:19.95% & rMAE is:1.92 ||| daily mean of MAE & sMAPE & rMAE till now are :7.06 & 22.46% & 1.02\n",
      "for 2019-08-01, MAE is:6.04 & sMAPE is:13.08% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :7.06 & 22.41% & 1.02\n",
      "for 2019-08-02, MAE is:2.17 & sMAPE is:5.05% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :7.03 & 22.33% & 1.02\n",
      "for 2019-08-03, MAE is:2.77 & sMAPE is:7.59% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :7.01 & 22.26% & 1.02\n",
      "for 2019-08-04, MAE is:3.18 & sMAPE is:8.46% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :7.00 & 22.20% & 1.02\n",
      "for 2019-08-05, MAE is:5.44 & sMAPE is:12.38% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.99 & 22.15% & 1.02\n",
      "for 2019-08-06, MAE is:4.91 & sMAPE is:11.94% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.98 & 22.11% & 1.02\n",
      "for 2019-08-07, MAE is:2.89 & sMAPE is:7.54% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 22.04% & 1.02\n",
      "for 2019-08-08, MAE is:4.59 & sMAPE is:12.92% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 22.00% & 1.02\n",
      "for 2019-08-09, MAE is:4.15 & sMAPE is:10.89% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 21.95% & 1.02\n",
      "for 2019-08-10, MAE is:4.42 & sMAPE is:14.06% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 21.91% & 1.02\n",
      "for 2019-08-11, MAE is:5.22 & sMAPE is:21.42% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 21.91% & 1.01\n",
      "for 2019-08-12, MAE is:6.96 & sMAPE is:14.91% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 21.88% & 1.01\n",
      "for 2019-08-13, MAE is:6.29 & sMAPE is:15.42% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 21.85% & 1.01\n",
      "for 2019-08-14, MAE is:6.65 & sMAPE is:15.91% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :6.91 & 21.82% & 1.01\n",
      "for 2019-08-15, MAE is:4.31 & sMAPE is:11.42% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 21.78% & 1.01\n",
      "for 2019-08-16, MAE is:3.99 & sMAPE is:10.08% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 21.73% & 1.01\n",
      "for 2019-08-17, MAE is:3.38 & sMAPE is:12.71% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.88 & 21.69% & 1.01\n",
      "for 2019-08-18, MAE is:1.47 & sMAPE is:4.48% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 21.61% & 1.01\n",
      "for 2019-08-19, MAE is:4.50 & sMAPE is:12.45% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.84 & 21.57% & 1.01\n",
      "for 2019-08-20, MAE is:4.70 & sMAPE is:12.22% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 21.53% & 1.01\n",
      "for 2019-08-21, MAE is:8.12 & sMAPE is:19.34% & rMAE is:3.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.84 & 21.52% & 1.02\n",
      "for 2019-08-22, MAE is:4.13 & sMAPE is:10.68% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 21.48% & 1.02\n",
      "for 2019-08-23, MAE is:5.34 & sMAPE is:13.81% & rMAE is:3.24 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 21.44% & 1.03\n",
      "for 2019-08-24, MAE is:3.97 & sMAPE is:12.39% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :6.81 & 21.41% & 1.03\n",
      "for 2019-08-25, MAE is:7.51 & sMAPE is:23.94% & rMAE is:3.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.81 & 21.42% & 1.04\n",
      "for 2019-08-26, MAE is:8.47 & sMAPE is:18.96% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 21.41% & 1.04\n",
      "for 2019-08-27, MAE is:4.42 & sMAPE is:9.90% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :6.81 & 21.36% & 1.04\n",
      "for 2019-08-28, MAE is:9.82 & sMAPE is:19.77% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 21.35% & 1.04\n",
      "for 2019-08-29, MAE is:5.29 & sMAPE is:12.04% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :6.81 & 21.31% & 1.03\n",
      "for 2019-08-30, MAE is:6.14 & sMAPE is:15.29% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.81 & 21.29% & 1.04\n",
      "for 2019-08-31, MAE is:2.47 & sMAPE is:6.75% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 21.23% & 1.04\n",
      "for 2019-09-01, MAE is:4.37 & sMAPE is:14.45% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 21.20% & 1.04\n",
      "for 2019-09-02, MAE is:4.44 & sMAPE is:10.87% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 21.16% & 1.04\n",
      "for 2019-09-03, MAE is:4.38 & sMAPE is:11.35% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 21.12% & 1.04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-09-04, MAE is:6.56 & sMAPE is:15.18% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 21.09% & 1.04\n",
      "for 2019-09-05, MAE is:2.74 & sMAPE is:8.65% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 21.04% & 1.03\n",
      "for 2019-09-06, MAE is:1.91 & sMAPE is:6.04% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 20.98% & 1.03\n",
      "for 2019-09-07, MAE is:7.06 & sMAPE is:21.22% & rMAE is:3.94 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 20.99% & 1.04\n",
      "for 2019-09-08, MAE is:6.03 & sMAPE is:16.99% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 20.97% & 1.04\n",
      "for 2019-09-09, MAE is:8.31 & sMAPE is:19.15% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 20.96% & 1.04\n",
      "for 2019-09-10, MAE is:4.71 & sMAPE is:12.78% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 20.93% & 1.05\n",
      "for 2019-09-11, MAE is:3.85 & sMAPE is:11.85% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 20.89% & 1.04\n",
      "for 2019-09-12, MAE is:7.29 & sMAPE is:20.56% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 20.89% & 1.05\n",
      "for 2019-09-13, MAE is:7.76 & sMAPE is:22.03% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 20.90% & 1.05\n",
      "for 2019-09-14, MAE is:4.32 & sMAPE is:11.91% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 20.86% & 1.05\n",
      "for 2019-09-15, MAE is:3.56 & sMAPE is:14.74% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 20.84% & 1.05\n",
      "for 2019-09-16, MAE is:12.18 & sMAPE is:41.44% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 20.92% & 1.05\n",
      "for 2019-09-17, MAE is:5.43 & sMAPE is:15.13% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 20.90% & 1.05\n",
      "for 2019-09-18, MAE is:7.57 & sMAPE is:21.12% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 20.90% & 1.05\n",
      "for 2019-09-19, MAE is:7.33 & sMAPE is:16.80% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 20.88% & 1.05\n",
      "for 2019-09-20, MAE is:7.69 & sMAPE is:18.83% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 20.87% & 1.05\n",
      "for 2019-09-21, MAE is:4.99 & sMAPE is:13.97% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 20.85% & 1.05\n",
      "for 2019-09-22, MAE is:7.23 & sMAPE is:24.33% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 20.86% & 1.05\n",
      "for 2019-09-23, MAE is:9.79 & sMAPE is:25.79% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 20.88% & 1.05\n",
      "for 2019-09-24, MAE is:6.59 & sMAPE is:14.71% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 20.86% & 1.05\n",
      "for 2019-09-25, MAE is:9.40 & sMAPE is:21.40% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 20.86% & 1.05\n",
      "for 2019-09-26, MAE is:3.88 & sMAPE is:10.01% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 20.82% & 1.05\n",
      "for 2019-09-27, MAE is:7.52 & sMAPE is:21.40% & rMAE is:1.75 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 20.82% & 1.05\n",
      "for 2019-09-28, MAE is:4.19 & sMAPE is:14.07% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 20.79% & 1.05\n",
      "for 2019-09-29, MAE is:7.47 & sMAPE is:38.88% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 20.86% & 1.05\n",
      "for 2019-09-30, MAE is:5.15 & sMAPE is:15.04% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 20.84% & 1.05\n",
      "for 2019-10-01, MAE is:6.18 & sMAPE is:15.23% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 20.82% & 1.05\n",
      "for 2019-10-02, MAE is:5.55 & sMAPE is:14.85% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 20.80% & 1.05\n",
      "for 2019-10-03, MAE is:7.20 & sMAPE is:17.67% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 20.79% & 1.05\n",
      "for 2019-10-04, MAE is:7.97 & sMAPE is:17.33% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 20.77% & 1.05\n",
      "for 2019-10-05, MAE is:6.81 & sMAPE is:19.28% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 20.77% & 1.05\n",
      "for 2019-10-06, MAE is:2.66 & sMAPE is:7.49% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 20.72% & 1.04\n",
      "for 2019-10-07, MAE is:19.42 & sMAPE is:38.21% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 20.78% & 1.04\n",
      "for 2019-10-08, MAE is:8.04 & sMAPE is:16.10% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 20.77% & 1.04\n",
      "for 2019-10-09, MAE is:13.69 & sMAPE is:29.00% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 20.80% & 1.04\n",
      "for 2019-10-10, MAE is:8.15 & sMAPE is:18.38% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 20.79% & 1.04\n",
      "for 2019-10-11, MAE is:3.20 & sMAPE is:9.85% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 20.75% & 1.04\n",
      "for 2019-10-12, MAE is:9.42 & sMAPE is:52.73% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 20.86% & 1.04\n",
      "for 2019-10-13, MAE is:7.74 & sMAPE is:29.19% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 20.89% & 1.04\n",
      "for 2019-10-14, MAE is:15.35 & sMAPE is:43.70% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :6.81 & 20.97% & 1.04\n",
      "for 2019-10-15, MAE is:8.22 & sMAPE is:19.25% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 20.96% & 1.04\n",
      "for 2019-10-16, MAE is:8.03 & sMAPE is:17.34% & rMAE is:1.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 20.95% & 1.05\n",
      "for 2019-10-17, MAE is:9.13 & sMAPE is:20.08% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 20.95% & 1.05\n",
      "for 2019-10-18, MAE is:5.55 & sMAPE is:13.01% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 20.92% & 1.05\n",
      "for 2019-10-19, MAE is:6.02 & sMAPE is:18.46% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 20.91% & 1.04\n",
      "for 2019-10-20, MAE is:5.00 & sMAPE is:13.71% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 20.89% & 1.04\n",
      "for 2019-10-21, MAE is:8.04 & sMAPE is:18.60% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 20.88% & 1.04\n",
      "for 2019-10-22, MAE is:8.75 & sMAPE is:20.14% & rMAE is:3.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 20.88% & 1.05\n",
      "for 2019-10-23, MAE is:3.42 & sMAPE is:7.55% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 20.83% & 1.05\n",
      "for 2019-10-24, MAE is:4.17 & sMAPE is:10.71% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.81 & 20.80% & 1.05\n",
      "for 2019-10-25, MAE is:4.59 & sMAPE is:12.07% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 20.77% & 1.05\n",
      "for 2019-10-26, MAE is:6.72 & sMAPE is:25.45% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 20.78% & 1.05\n",
      "for 2019-10-27, MAE is:5.79 & sMAPE is:29.99% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 20.82% & 1.05\n",
      "for 2019-10-28, MAE is:11.60 & sMAPE is:35.34% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :6.81 & 20.86% & 1.05\n",
      "for 2019-10-29, MAE is:6.25 & sMAPE is:13.12% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.81 & 20.84% & 1.05\n",
      "for 2019-10-30, MAE is:6.08 & sMAPE is:13.27% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :6.81 & 20.81% & 1.05\n",
      "for 2019-10-31, MAE is:4.49 & sMAPE is:10.70% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 20.78% & 1.05\n",
      "for 2019-11-01, MAE is:4.90 & sMAPE is:13.14% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 20.75% & 1.05\n",
      "for 2019-11-02, MAE is:3.80 & sMAPE is:11.50% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 20.72% & 1.05\n",
      "for 2019-11-03, MAE is:2.04 & sMAPE is:5.83% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 20.68% & 1.05\n",
      "for 2019-11-04, MAE is:6.36 & sMAPE is:16.38% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 20.66% & 1.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-11-05, MAE is:5.40 & sMAPE is:12.75% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 20.64% & 1.05\n",
      "for 2019-11-06, MAE is:11.84 & sMAPE is:24.07% & rMAE is:2.41 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 20.65% & 1.05\n",
      "for 2019-11-07, MAE is:4.75 & sMAPE is:10.08% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 20.61% & 1.05\n",
      "for 2019-11-08, MAE is:6.98 & sMAPE is:14.71% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 20.59% & 1.05\n",
      "for 2019-11-09, MAE is:4.63 & sMAPE is:11.85% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 20.57% & 1.05\n",
      "for 2019-11-10, MAE is:6.67 & sMAPE is:16.88% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 20.55% & 1.05\n",
      "for 2019-11-11, MAE is:3.45 & sMAPE is:8.29% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 20.52% & 1.05\n",
      "for 2019-11-12, MAE is:4.44 & sMAPE is:10.94% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 20.49% & 1.05\n",
      "for 2019-11-13, MAE is:5.91 & sMAPE is:12.46% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 20.46% & 1.05\n",
      "for 2019-11-14, MAE is:4.90 & sMAPE is:10.90% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 20.43% & 1.05\n",
      "for 2019-11-15, MAE is:3.70 & sMAPE is:9.32% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 20.40% & 1.05\n",
      "for 2019-11-16, MAE is:2.08 & sMAPE is:5.39% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 20.35% & 1.05\n",
      "for 2019-11-17, MAE is:2.70 & sMAPE is:7.66% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 20.31% & 1.05\n",
      "for 2019-11-18, MAE is:6.74 & sMAPE is:16.56% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 20.30% & 1.05\n",
      "for 2019-11-19, MAE is:4.15 & sMAPE is:8.84% & rMAE is:1.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 20.26% & 1.05\n",
      "for 2019-11-20, MAE is:8.41 & sMAPE is:15.98% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 20.25% & 1.05\n",
      "for 2019-11-21, MAE is:7.36 & sMAPE is:15.20% & rMAE is:1.91 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 20.23% & 1.05\n",
      "for 2019-11-22, MAE is:4.65 & sMAPE is:11.01% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 20.20% & 1.05\n",
      "for 2019-11-23, MAE is:3.98 & sMAPE is:11.50% & rMAE is:1.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.69 & 20.18% & 1.06\n",
      "for 2019-11-24, MAE is:7.26 & sMAPE is:28.86% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :6.69 & 20.20% & 1.06\n",
      "for 2019-11-25, MAE is:6.40 & sMAPE is:12.70% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :6.69 & 20.18% & 1.05\n",
      "for 2019-11-26, MAE is:3.06 & sMAPE is:6.56% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 20.14% & 1.05\n",
      "for 2019-11-27, MAE is:3.11 & sMAPE is:7.08% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 20.10% & 1.05\n",
      "for 2019-11-28, MAE is:3.63 & sMAPE is:9.78% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 20.07% & 1.05\n",
      "for 2019-11-29, MAE is:9.67 & sMAPE is:28.37% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 20.09% & 1.05\n",
      "for 2019-11-30, MAE is:4.00 & sMAPE is:9.95% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 20.06% & 1.05\n",
      "for 2019-12-01, MAE is:3.51 & sMAPE is:8.37% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 20.03% & 1.05\n",
      "for 2019-12-02, MAE is:5.25 & sMAPE is:11.75% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 20.00% & 1.05\n",
      "for 2019-12-03, MAE is:6.43 & sMAPE is:12.53% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 19.98% & 1.05\n",
      "for 2019-12-04, MAE is:7.35 & sMAPE is:16.33% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 19.97% & 1.05\n",
      "for 2019-12-05, MAE is:7.74 & sMAPE is:18.77% & rMAE is:2.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 19.97% & 1.05\n",
      "for 2019-12-06, MAE is:3.47 & sMAPE is:12.55% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 19.95% & 1.05\n",
      "for 2019-12-07, MAE is:9.91 & sMAPE is:56.45% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 20.05% & 1.05\n",
      "for 2019-12-08, MAE is:21.07 & sMAPE is:101.36% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :6.69 & 20.29% & 1.05\n",
      "for 2019-12-09, MAE is:10.45 & sMAPE is:59.98% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 20.41% & 1.05\n",
      "for 2019-12-10, MAE is:11.17 & sMAPE is:35.83% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 20.45% & 1.05\n",
      "for 2019-12-11, MAE is:10.44 & sMAPE is:42.13% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 20.51% & 1.05\n",
      "for 2019-12-12, MAE is:6.08 & sMAPE is:13.80% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 20.50% & 1.05\n",
      "for 2019-12-13, MAE is:5.46 & sMAPE is:17.13% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 20.49% & 1.05\n",
      "for 2019-12-14, MAE is:4.58 & sMAPE is:18.23% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 20.48% & 1.05\n",
      "for 2019-12-15, MAE is:13.55 & sMAPE is:74.71% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 20.63% & 1.04\n",
      "for 2019-12-16, MAE is:6.65 & sMAPE is:18.96% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 20.63% & 1.04\n",
      "for 2019-12-17, MAE is:4.82 & sMAPE is:11.36% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 20.60% & 1.04\n",
      "for 2019-12-18, MAE is:4.07 & sMAPE is:10.26% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 20.57% & 1.04\n",
      "for 2019-12-19, MAE is:4.61 & sMAPE is:11.58% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 20.55% & 1.04\n",
      "for 2019-12-20, MAE is:2.81 & sMAPE is:8.28% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 20.51% & 1.04\n",
      "for 2019-12-21, MAE is:4.20 & sMAPE is:12.81% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 20.49% & 1.04\n",
      "for 2019-12-22, MAE is:3.71 & sMAPE is:11.06% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.69 & 20.47% & 1.04\n",
      "for 2019-12-23, MAE is:2.56 & sMAPE is:6.95% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 20.43% & 1.04\n",
      "for 2019-12-24, MAE is:5.75 & sMAPE is:19.47% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 20.43% & 1.04\n",
      "for 2019-12-25, MAE is:7.24 & sMAPE is:23.37% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 20.43% & 1.04\n",
      "for 2019-12-26, MAE is:10.03 & sMAPE is:32.41% & rMAE is:4.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.69 & 20.47% & 1.05\n",
      "for 2019-12-27, MAE is:7.79 & sMAPE is:21.94% & rMAE is:2.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.69 & 20.47% & 1.05\n",
      "for 2019-12-28, MAE is:1.82 & sMAPE is:5.61% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 20.43% & 1.05\n",
      "for 2019-12-29, MAE is:2.34 & sMAPE is:8.52% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 20.40% & 1.05\n",
      "for 2019-12-30, MAE is:4.62 & sMAPE is:28.20% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 20.42% & 1.05\n",
      "for 2019-12-31, MAE is:3.52 & sMAPE is:16.81% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 20.41% & 1.04\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 00:13:06,765]\u001b[0m A new study created in RDB with name: DK_2_2020\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 00:13:29,466]\u001b[0m Trial 3 finished with value: 5.745718231032458 and parameters: {'n_hidden': 3, 'learning_rate': 0.008425661009268995, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09745004063003129, 'dropout_rate_Layer_2': 0.3414524782608308, 'dropout_rate_Layer_3': 0.0767272869136392, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.013898058148506063, 'l1_Layer_2': 0.09055263625732857, 'l1_Layer_3': 0.027650002866354228, 'n_units_Layer_1': 280, 'n_units_Layer_2': 195, 'n_units_Layer_3': 120}. Best is trial 3 with value: 5.745718231032458.\u001b[0m\n",
      "\u001b[33m[W 2023-08-06 00:13:29,543]\u001b[0m Trial 0 failed because of the following error: AssertionError('This line should be unreachable.')\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\z110474\\Anaconda3\\envs\\ML\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameters.py\", line 290, in objective\n",
      "    return train_and_evaluate_model(trial, df_train, df_valid, df_test, hf_columns, fut_columns)\n",
      "  File \"C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameters.py\", line 225, in train_and_evaluate_model\n",
      "    model.fit(\n",
      "  File \"C:\\Users\\z110474\\Anaconda3\\envs\\ML\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\z110474\\Anaconda3\\envs\\ML\\lib\\site-packages\\optuna\\integration\\tfkeras.py\", line 60, in on_epoch_end\n",
      "    if self._trial.should_prune():\n",
      "  File \"C:\\Users\\z110474\\Anaconda3\\envs\\ML\\lib\\site-packages\\optuna\\trial\\_trial.py\", line 501, in should_prune\n",
      "    return self.study.pruner.prune(self.study, trial)\n",
      "  File \"C:\\Users\\z110474\\Anaconda3\\envs\\ML\\lib\\site-packages\\optuna\\pruners\\_hyperband.py\", line 183, in prune\n",
      "    return self._pruners[bracket_id].prune(bracket_study, trial)\n",
      "  File \"C:\\Users\\z110474\\Anaconda3\\envs\\ML\\lib\\site-packages\\optuna\\pruners\\_successive_halving.py\", line 192, in prune\n",
      "    trials = study.get_trials(deepcopy=False)\n",
      "  File \"C:\\Users\\z110474\\Anaconda3\\envs\\ML\\lib\\site-packages\\optuna\\pruners\\_hyperband.py\", line 309, in get_trials\n",
      "    return [t for t in trials if pruner._get_bracket_id(self, t) == self._bracket_id]\n",
      "  File \"C:\\Users\\z110474\\Anaconda3\\envs\\ML\\lib\\site-packages\\optuna\\pruners\\_hyperband.py\", line 309, in <listcomp>\n",
      "    return [t for t in trials if pruner._get_bracket_id(self, t) == self._bracket_id]\n",
      "  File \"C:\\Users\\z110474\\Anaconda3\\envs\\ML\\lib\\site-packages\\optuna\\pruners\\_hyperband.py\", line 262, in _get_bracket_id\n",
      "    assert False, \"This line should be unreachable.\"\n",
      "AssertionError: This line should be unreachable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.75 | sMAPE for Validation Set is: 17.14% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 12.69 | sMAPE for Test Set is: 50.71% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2023-08-06 00:13:33,478]\u001b[0m Trial 2 failed because of the following error: AssertionError('This line should be unreachable.')\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\z110474\\Anaconda3\\envs\\ML\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameters.py\", line 290, in objective\n",
      "    return train_and_evaluate_model(trial, df_train, df_valid, df_test, hf_columns, fut_columns)\n",
      "  File \"C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameters.py\", line 225, in train_and_evaluate_model\n",
      "    model.fit(\n",
      "  File \"C:\\Users\\z110474\\Anaconda3\\envs\\ML\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\z110474\\Anaconda3\\envs\\ML\\lib\\site-packages\\optuna\\integration\\tfkeras.py\", line 60, in on_epoch_end\n",
      "    if self._trial.should_prune():\n",
      "  File \"C:\\Users\\z110474\\Anaconda3\\envs\\ML\\lib\\site-packages\\optuna\\trial\\_trial.py\", line 501, in should_prune\n",
      "    return self.study.pruner.prune(self.study, trial)\n",
      "  File \"C:\\Users\\z110474\\Anaconda3\\envs\\ML\\lib\\site-packages\\optuna\\pruners\\_hyperband.py\", line 183, in prune\n",
      "    return self._pruners[bracket_id].prune(bracket_study, trial)\n",
      "  File \"C:\\Users\\z110474\\Anaconda3\\envs\\ML\\lib\\site-packages\\optuna\\pruners\\_successive_halving.py\", line 192, in prune\n",
      "    trials = study.get_trials(deepcopy=False)\n",
      "  File \"C:\\Users\\z110474\\Anaconda3\\envs\\ML\\lib\\site-packages\\optuna\\pruners\\_hyperband.py\", line 309, in get_trials\n",
      "    return [t for t in trials if pruner._get_bracket_id(self, t) == self._bracket_id]\n",
      "  File \"C:\\Users\\z110474\\Anaconda3\\envs\\ML\\lib\\site-packages\\optuna\\pruners\\_hyperband.py\", line 309, in <listcomp>\n",
      "    return [t for t in trials if pruner._get_bracket_id(self, t) == self._bracket_id]\n",
      "  File \"C:\\Users\\z110474\\Anaconda3\\envs\\ML\\lib\\site-packages\\optuna\\pruners\\_hyperband.py\", line 262, in _get_bracket_id\n",
      "    assert False, \"This line should be unreachable.\"\n",
      "AssertionError: This line should be unreachable.\n",
      "\u001b[33m[W 2023-08-06 00:13:44,226]\u001b[0m Trial 1 failed because of the following error: AssertionError('This line should be unreachable.')\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\z110474\\Anaconda3\\envs\\ML\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameters.py\", line 290, in objective\n",
      "    return train_and_evaluate_model(trial, df_train, df_valid, df_test, hf_columns, fut_columns)\n",
      "  File \"C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameters.py\", line 225, in train_and_evaluate_model\n",
      "    model.fit(\n",
      "  File \"C:\\Users\\z110474\\Anaconda3\\envs\\ML\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\z110474\\Anaconda3\\envs\\ML\\lib\\site-packages\\optuna\\integration\\tfkeras.py\", line 60, in on_epoch_end\n",
      "    if self._trial.should_prune():\n",
      "  File \"C:\\Users\\z110474\\Anaconda3\\envs\\ML\\lib\\site-packages\\optuna\\trial\\_trial.py\", line 501, in should_prune\n",
      "    return self.study.pruner.prune(self.study, trial)\n",
      "  File \"C:\\Users\\z110474\\Anaconda3\\envs\\ML\\lib\\site-packages\\optuna\\pruners\\_hyperband.py\", line 183, in prune\n",
      "    return self._pruners[bracket_id].prune(bracket_study, trial)\n",
      "  File \"C:\\Users\\z110474\\Anaconda3\\envs\\ML\\lib\\site-packages\\optuna\\pruners\\_successive_halving.py\", line 192, in prune\n",
      "    trials = study.get_trials(deepcopy=False)\n",
      "  File \"C:\\Users\\z110474\\Anaconda3\\envs\\ML\\lib\\site-packages\\optuna\\pruners\\_hyperband.py\", line 309, in get_trials\n",
      "    return [t for t in trials if pruner._get_bracket_id(self, t) == self._bracket_id]\n",
      "  File \"C:\\Users\\z110474\\Anaconda3\\envs\\ML\\lib\\site-packages\\optuna\\pruners\\_hyperband.py\", line 309, in <listcomp>\n",
      "    return [t for t in trials if pruner._get_bracket_id(self, t) == self._bracket_id]\n",
      "  File \"C:\\Users\\z110474\\Anaconda3\\envs\\ML\\lib\\site-packages\\optuna\\pruners\\_hyperband.py\", line 262, in _get_bracket_id\n",
      "    assert False, \"This line should be unreachable.\"\n",
      "AssertionError: This line should be unreachable.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "This line should be unreachable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:2\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "File \u001b[1;32m~\\Time Series Paper\\Modular_Codes- V 6.3\\large_scale_prediction.py:57\u001b[0m, in \u001b[0;36mlarge_scale_predictor\u001b[1;34m(zone, first_year, last_year)\u001b[0m\n\u001b[0;32m     55\u001b[0m df_train, df_valid, df_test \u001b[38;5;241m=\u001b[39m split_dataframe_by_years(dataframe\u001b[38;5;241m=\u001b[39mdf, test_year\u001b[38;5;241m=\u001b[39mtest_year, num_validation_years\u001b[38;5;241m=\u001b[39mnum_validation_years, num_train_years\u001b[38;5;241m=\u001b[39mnum_train_years )\n\u001b[0;32m     56\u001b[0m study_name \u001b[38;5;241m=\u001b[39m zone \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(test_year)\n\u001b[1;32m---> 57\u001b[0m \u001b[43moptimize_hyperparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstudy_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstudy_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m hp_study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mload_study(study_name\u001b[38;5;241m=\u001b[39mstudy_name, storage\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msqlite:///hyperparameter_optimization_trials/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m study_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.db\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     59\u001b[0m hp_params \u001b[38;5;241m=\u001b[39m hp_study\u001b[38;5;241m.\u001b[39mbest_params\n",
      "File \u001b[1;32m~\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameters.py:292\u001b[0m, in \u001b[0;36moptimize_hyperparameters\u001b[1;34m(df_train, df_valid, df_test, study_name, n_trials, n_jobs)\u001b[0m\n\u001b[0;32m    288\u001b[0m     fut_columns \u001b[38;5;241m=\u001b[39m get_fut_columns(df_train, trial_params)\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m train_and_evaluate_model(trial, df_train, df_valid, df_test, hf_columns, fut_columns)\n\u001b[1;32m--> 292\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\ML\\lib\\site-packages\\optuna\\study\\study.py:419\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    317\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    324\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    325\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \n\u001b[0;32m    328\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 419\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\ML\\lib\\site-packages\\optuna\\study\\_optimize.py:103\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    101\u001b[0m                     \u001b[38;5;66;03m# Raise if exception occurred in executing the completed futures.\u001b[39;00m\n\u001b[0;32m    102\u001b[0m                     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m completed:\n\u001b[1;32m--> 103\u001b[0m                         \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m                 futures\u001b[38;5;241m.\u001b[39madd(\n\u001b[0;32m    106\u001b[0m                     executor\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[0;32m    107\u001b[0m                         _optimize_sequential,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    118\u001b[0m                     )\n\u001b[0;32m    119\u001b[0m                 )\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\ML\\lib\\concurrent\\futures\\_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\ML\\lib\\concurrent\\futures\\_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 391\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    393\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    394\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\ML\\lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\ML\\lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as CircleCI).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\ML\\lib\\site-packages\\optuna\\study\\_optimize.py:187\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_heartbeat_enabled(study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    185\u001b[0m     optuna\u001b[38;5;241m.\u001b[39mstorages\u001b[38;5;241m.\u001b[39mfail_stale_trials(study)\n\u001b[1;32m--> 187\u001b[0m trial \u001b[38;5;241m=\u001b[39m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m state: Optional[TrialState] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    190\u001b[0m value_or_values: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Sequence[\u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\ML\\lib\\site-packages\\optuna\\study\\study.py:514\u001b[0m, in \u001b[0;36mStudy.ask\u001b[1;34m(self, fixed_distributions)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trial_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    513\u001b[0m     trial_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage\u001b[38;5;241m.\u001b[39mcreate_new_trial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_study_id)\n\u001b[1;32m--> 514\u001b[0m trial \u001b[38;5;241m=\u001b[39m \u001b[43mtrial_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrial\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m fixed_distributions\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    517\u001b[0m     trial\u001b[38;5;241m.\u001b[39m_suggest(name, param)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\ML\\lib\\site-packages\\optuna\\trial\\_trial.py:54\u001b[0m, in \u001b[0;36mTrial.__init__\u001b[1;34m(self, study, trial_id)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_study_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstudy\u001b[38;5;241m.\u001b[39m_study_id\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstudy\u001b[38;5;241m.\u001b[39m_storage\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_relative_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\ML\\lib\\site-packages\\optuna\\trial\\_trial.py:60\u001b[0m, in \u001b[0;36mTrial._init_relative_params\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_init_relative_params\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m     trial \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mget_trial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trial_id)\n\u001b[1;32m---> 60\u001b[0m     study \u001b[38;5;241m=\u001b[39m \u001b[43mpruners\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_filter_study\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelative_search_space \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstudy\u001b[38;5;241m.\u001b[39msampler\u001b[38;5;241m.\u001b[39minfer_relative_search_space(study, trial)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelative_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstudy\u001b[38;5;241m.\u001b[39msampler\u001b[38;5;241m.\u001b[39msample_relative(\n\u001b[0;32m     64\u001b[0m         study, trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelative_search_space\n\u001b[0;32m     65\u001b[0m     )\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\ML\\lib\\site-packages\\optuna\\pruners\\__init__.py:34\u001b[0m, in \u001b[0;36m_filter_study\u001b[1;34m(study, trial)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(study\u001b[38;5;241m.\u001b[39mpruner, HyperbandPruner):\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;66;03m# Create `_BracketStudy` to use trials that have the same bracket id.\u001b[39;00m\n\u001b[0;32m     33\u001b[0m     pruner: HyperbandPruner \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mpruner\n\u001b[1;32m---> 34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pruner\u001b[38;5;241m.\u001b[39m_create_bracket_study(study, \u001b[43mpruner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_bracket_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m study\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\ML\\lib\\site-packages\\optuna\\pruners\\_hyperband.py:262\u001b[0m, in \u001b[0;36mHyperbandPruner._get_bracket_id\u001b[1;34m(self, study, trial)\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m bracket_id\n\u001b[1;32m--> 262\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis line should be unreachable.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: This line should be unreachable."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for zone in zones:\n",
    "    large_scale_predictor(zone, first_year=2018, last_year=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
