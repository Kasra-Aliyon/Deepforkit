{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from large_scale_prediction import large_scale_predictor, large_scale_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "zones = ['CH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:21:41,288]\u001b[0m A new study created in RDB with name: CH_2018\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:22:23,750]\u001b[0m Trial 2 finished with value: 5.171146835472774 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035730655185706012, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18939776534096528, 'dropout_rate_Layer_2': 0.16716078200075946, 'dropout_rate_Layer_3': 0.024574290383670094, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.035898499107912624, 'l1_Layer_2': 0.004829286820209032, 'l1_Layer_3': 0.001530197892565234, 'n_units_Layer_1': 50, 'n_units_Layer_2': 215, 'n_units_Layer_3': 100}. Best is trial 2 with value: 5.171146835472774.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.17 | sMAPE for Validation Set is: 12.33% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 5.76 | sMAPE for Test Set is: 12.74% | rMAE for Test Set is: 0.74\n",
      "MAE for Validation Set is: 5.48 | sMAPE for Validation Set is: 12.77% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 5.83 | sMAPE for Test Set is: 12.63% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:22:23,886]\u001b[0m Trial 0 finished with value: 5.484170398294814 and parameters: {'n_hidden': 4, 'learning_rate': 0.004643984726011732, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37656053586567406, 'dropout_rate_Layer_2': 0.3686790220632687, 'dropout_rate_Layer_3': 0.16410246062815223, 'dropout_rate_Layer_4': 0.24766410944372952, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.004294912952417093, 'l1_Layer_2': 0.017658099441941737, 'l1_Layer_3': 1.1516122881833201e-05, 'l1_Layer_4': 0.0001190865885566072, 'n_units_Layer_1': 150, 'n_units_Layer_2': 50, 'n_units_Layer_3': 130, 'n_units_Layer_4': 75}. Best is trial 2 with value: 5.171146835472774.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:22:24,013]\u001b[0m Trial 1 pruned. Trial was pruned at epoch 24.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:22:30,388]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:22:30,546]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:22:31,230]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:22:38,751]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:22:41,058]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:22:45,111]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:22:46,571]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:22:53,122]\u001b[0m Trial 7 finished with value: 7.825352211513554 and parameters: {'n_hidden': 4, 'learning_rate': 0.022679232784007432, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3934488474483774, 'dropout_rate_Layer_2': 0.3714321588710565, 'dropout_rate_Layer_3': 0.051614007211758045, 'dropout_rate_Layer_4': 0.14709064070003994, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00966552015534555, 'l1_Layer_2': 0.0002089394198871832, 'l1_Layer_3': 2.2819268379065952e-05, 'l1_Layer_4': 0.0003082793114930948, 'n_units_Layer_1': 115, 'n_units_Layer_2': 290, 'n_units_Layer_3': 165, 'n_units_Layer_4': 280}. Best is trial 2 with value: 5.171146835472774.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.83 | sMAPE for Validation Set is: 17.43% | rMAE for Validation Set is: 1.12\n",
      "MAE for Test Set is: 8.33 | sMAPE for Test Set is: 17.11% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:22:56,654]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:22:58,761]\u001b[0m Trial 12 finished with value: 9.996047095923894 and parameters: {'n_hidden': 4, 'learning_rate': 0.040878542454192215, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10824184826152133, 'dropout_rate_Layer_2': 0.29444468053592626, 'dropout_rate_Layer_3': 0.39286789349930196, 'dropout_rate_Layer_4': 0.21419245551988786, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0001750465115884014, 'l1_Layer_2': 1.0455818490336999e-05, 'l1_Layer_3': 2.6778408710379126e-05, 'l1_Layer_4': 0.00047743679275064716, 'n_units_Layer_1': 235, 'n_units_Layer_2': 300, 'n_units_Layer_3': 210, 'n_units_Layer_4': 175}. Best is trial 2 with value: 5.171146835472774.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.00 | sMAPE for Validation Set is: 22.06% | rMAE for Validation Set is: 1.43\n",
      "MAE for Test Set is: 13.57 | sMAPE for Test Set is: 28.87% | rMAE for Test Set is: 1.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:23:04,967]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:23:08,345]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:23:11,651]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:23:14,009]\u001b[0m Trial 3 finished with value: 5.265252456753834 and parameters: {'n_hidden': 4, 'learning_rate': 0.007545186357890712, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1044595625025179, 'dropout_rate_Layer_2': 0.003900700450863637, 'dropout_rate_Layer_3': 0.39349056634078006, 'dropout_rate_Layer_4': 0.12051496893972989, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0008229932248100055, 'l1_Layer_2': 0.00018570087756948126, 'l1_Layer_3': 0.0006621908465666433, 'l1_Layer_4': 0.0035619671838368534, 'n_units_Layer_1': 80, 'n_units_Layer_2': 115, 'n_units_Layer_3': 195, 'n_units_Layer_4': 220}. Best is trial 2 with value: 5.171146835472774.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.27 | sMAPE for Validation Set is: 12.66% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 5.86 | sMAPE for Test Set is: 12.98% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:23:17,890]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:23:21,652]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:23:26,030]\u001b[0m Trial 15 finished with value: 6.1665310650120455 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010970380082922203, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.379896691804084, 'dropout_rate_Layer_2': 0.3454612406595231, 'dropout_rate_Layer_3': 0.35716929259287966, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011764512442711259, 'l1_Layer_2': 2.056357847177086e-05, 'l1_Layer_3': 0.002191472570334923, 'n_units_Layer_1': 265, 'n_units_Layer_2': 85, 'n_units_Layer_3': 85}. Best is trial 2 with value: 5.171146835472774.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.17 | sMAPE for Validation Set is: 13.91% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 6.21 | sMAPE for Test Set is: 13.16% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:23:28,320]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:23:31,723]\u001b[0m Trial 13 finished with value: 6.570751769378419 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013676295424424262, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23193490465818933, 'dropout_rate_Layer_2': 0.2513560677012927, 'dropout_rate_Layer_3': 0.35853490620958217, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0006491313776794563, 'l1_Layer_2': 5.13696018384794e-05, 'l1_Layer_3': 0.06542128389595997, 'n_units_Layer_1': 185, 'n_units_Layer_2': 160, 'n_units_Layer_3': 210}. Best is trial 2 with value: 5.171146835472774.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.57 | sMAPE for Validation Set is: 15.31% | rMAE for Validation Set is: 0.94\n",
      "MAE for Test Set is: 6.89 | sMAPE for Test Set is: 15.05% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:23:31,920]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:23:37,721]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:23:39,460]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:23:44,000]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:23:47,259]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:23:52,613]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:23:54,748]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:23:58,221]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:24:02,056]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:24:05,596]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:24:09,354]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:24:12,880]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:24:16,280]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:24:20,504]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:24:24,975]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:24:27,207]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:24:31,735]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:24:35,316]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:24:37,778]\u001b[0m Trial 31 finished with value: 5.188785361950624 and parameters: {'n_hidden': 4, 'learning_rate': 0.001989374029547501, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3392169585865028, 'dropout_rate_Layer_2': 0.22889020686586284, 'dropout_rate_Layer_3': 0.3801170162558784, 'dropout_rate_Layer_4': 0.2797451091795691, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.061873755099517425, 'l1_Layer_2': 0.0005066737015143021, 'l1_Layer_3': 0.005187792242732394, 'l1_Layer_4': 0.056593172337169914, 'n_units_Layer_1': 65, 'n_units_Layer_2': 205, 'n_units_Layer_3': 235, 'n_units_Layer_4': 120}. Best is trial 2 with value: 5.171146835472774.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.19 | sMAPE for Validation Set is: 12.82% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 5.76 | sMAPE for Test Set is: 12.83% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:24:41,206]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:24:46,751]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:24:47,257]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:25:07,953]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:25:10,513]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:25:14,920]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:25:19,740]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:25:20,070]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:25:27,505]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:25:29,286]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:25:29,664]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:25:33,560]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:25:38,700]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:25:43,131]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:25:46,409]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:25:50,380]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:25:54,011]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:25:58,128]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:26:01,855]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:26:06,362]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:26:10,612]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:26:15,222]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:26:24,047]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:26:24,077]\u001b[0m Trial 27 finished with value: 6.489898814684406 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013264971029991013, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0014450352073162255, 'dropout_rate_Layer_2': 0.3048594281614587, 'dropout_rate_Layer_3': 0.04641765430016869, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001184688762949611, 'l1_Layer_2': 0.01795191200040198, 'l1_Layer_3': 0.0037325539163058957, 'n_units_Layer_1': 180, 'n_units_Layer_2': 125, 'n_units_Layer_3': 100}. Best is trial 2 with value: 5.171146835472774.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.49 | sMAPE for Validation Set is: 14.73% | rMAE for Validation Set is: 0.93\n",
      "MAE for Test Set is: 6.96 | sMAPE for Test Set is: 14.89% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:26:24,657]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:26:32,029]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:26:33,822]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:26:34,254]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:26:35,870]\u001b[0m Trial 56 finished with value: 5.194248869325862 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007709887129455364, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.005829482053624613, 'dropout_rate_Layer_2': 0.020963886346887686, 'dropout_rate_Layer_3': 0.19147812141490503, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003968848811638306, 'l1_Layer_2': 0.0017245614793705538, 'l1_Layer_3': 0.008492624264314673, 'n_units_Layer_1': 160, 'n_units_Layer_2': 265, 'n_units_Layer_3': 115}. Best is trial 2 with value: 5.171146835472774.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.19 | sMAPE for Validation Set is: 12.13% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 5.46 | sMAPE for Test Set is: 11.97% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:26:38,421]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:26:44,656]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:26:47,925]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:26:48,184]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:26:53,029]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:26:57,597]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:27:03,446]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:27:05,806]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:27:09,782]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:27:09,987]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:27:15,925]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:27:16,835]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.94 | sMAPE for Validation Set is: 14.07% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 5.78 | sMAPE for Test Set is: 12.84% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:27:19,205]\u001b[0m Trial 79 finished with value: 5.944225830596696 and parameters: {'n_hidden': 3, 'learning_rate': 0.000769644857654376, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1553325222594656, 'dropout_rate_Layer_2': 0.3907666378388013, 'dropout_rate_Layer_3': 0.2824700620102421, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0088372648559551e-05, 'l1_Layer_2': 1.0176524779202145e-05, 'l1_Layer_3': 1.6583129713056245e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 50, 'n_units_Layer_3': 60}. Best is trial 2 with value: 5.171146835472774.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:27:23,950]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:27:26,549]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:27:27,613]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:27:31,529]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:27:34,623]\u001b[0m Trial 80 finished with value: 4.977206446862532 and parameters: {'n_hidden': 3, 'learning_rate': 0.010733995147786037, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3199055162307573, 'dropout_rate_Layer_2': 0.14810776523767397, 'dropout_rate_Layer_3': 0.04187552471105125, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0013379974020610384, 'l1_Layer_2': 0.08544719555371795, 'l1_Layer_3': 9.629919881030266e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 185, 'n_units_Layer_3': 105}. Best is trial 80 with value: 4.977206446862532.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.98 | sMAPE for Validation Set is: 12.22% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 5.96 | sMAPE for Test Set is: 13.34% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:27:35,110]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:27:35,704]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:27:41,427]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:27:42,318]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:27:43,612]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:27:44,092]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:27:46,152]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:27:52,781]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:27:53,440]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:27:54,121]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:27:54,736]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:27:59,732]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:28:04,055]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:28:05,764]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:28:06,569]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:28:07,718]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:28:15,510]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:28:17,202]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:28:22,147]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:28:24,753]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:28:30,707]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:28:38,313]\u001b[0m Trial 105 finished with value: 6.161391713774624 and parameters: {'n_hidden': 4, 'learning_rate': 0.005671716184444934, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39788192986775994, 'dropout_rate_Layer_2': 0.3478138368479837, 'dropout_rate_Layer_3': 0.002869976044865219, 'dropout_rate_Layer_4': 0.01364415198714196, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0770905052914423, 'l1_Layer_2': 0.0003727812534904559, 'l1_Layer_3': 0.004166110403364372, 'l1_Layer_4': 8.60914127022048e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 300, 'n_units_Layer_3': 135, 'n_units_Layer_4': 90}. Best is trial 80 with value: 4.977206446862532.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.16 | sMAPE for Validation Set is: 14.25% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 6.70 | sMAPE for Test Set is: 14.40% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:28:42,520]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:28:44,301]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:28:55,592]\u001b[0m Trial 110 finished with value: 5.453058228421699 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017214585766552799, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24321470764999212, 'dropout_rate_Layer_2': 0.3474473180750601, 'dropout_rate_Layer_3': 0.3237324101035555, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.990405721922636e-05, 'l1_Layer_2': 6.667879942563665e-05, 'l1_Layer_3': 1.0567230035534858e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 105, 'n_units_Layer_3': 95}. Best is trial 80 with value: 4.977206446862532.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.45 | sMAPE for Validation Set is: 12.86% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 6.94 | sMAPE for Test Set is: 15.05% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:28:58,251]\u001b[0m Trial 104 finished with value: 4.792483162569156 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007304670886041034, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0792893182747525, 'dropout_rate_Layer_2': 0.01515958229307084, 'dropout_rate_Layer_3': 0.07359770967235875, 'dropout_rate_Layer_4': 0.13187316963520185, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.035285134177069646, 'l1_Layer_2': 1.4116746276897814e-05, 'l1_Layer_3': 2.893374787818489e-05, 'l1_Layer_4': 0.00012939896341138712, 'n_units_Layer_1': 55, 'n_units_Layer_2': 155, 'n_units_Layer_3': 255, 'n_units_Layer_4': 270}. Best is trial 104 with value: 4.792483162569156.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.79 | sMAPE for Validation Set is: 11.37% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 5.21 | sMAPE for Test Set is: 11.51% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:29:01,655]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:29:01,845]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:29:13,813]\u001b[0m Trial 117 finished with value: 8.056541079125147 and parameters: {'n_hidden': 3, 'learning_rate': 0.027304730575088056, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2907031600380765, 'dropout_rate_Layer_2': 0.16871581616034503, 'dropout_rate_Layer_3': 0.21122966120860973, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.000560007894048261, 'l1_Layer_2': 0.0032312222623938564, 'l1_Layer_3': 0.04120564097060682, 'n_units_Layer_1': 90, 'n_units_Layer_2': 280, 'n_units_Layer_3': 210}. Best is trial 104 with value: 4.792483162569156.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.06 | sMAPE for Validation Set is: 17.57% | rMAE for Validation Set is: 1.15\n",
      "MAE for Test Set is: 8.87 | sMAPE for Test Set is: 18.11% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:29:16,889]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:29:20,494]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:29:21,052]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:29:21,191]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:29:26,340]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:29:28,860]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:29:32,513]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:29:34,555]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:29:38,417]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:29:41,384]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:29:46,296]\u001b[0m Trial 124 finished with value: 5.593932236674999 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024274157666706597, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2490054220833091, 'dropout_rate_Layer_2': 0.3628765854233882, 'dropout_rate_Layer_3': 0.2132302471780311, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3546612319482311e-05, 'l1_Layer_2': 6.162934506382693e-05, 'l1_Layer_3': 1.3399795170302635e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 225, 'n_units_Layer_3': 50}. Best is trial 104 with value: 4.792483162569156.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.59 | sMAPE for Validation Set is: 13.59% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 6.21 | sMAPE for Test Set is: 13.78% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:29:47,997]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:29:51,547]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:29:54,065]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:30:02,428]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:30:06,640]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:30:13,255]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:30:17,295]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:30:26,412]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:30:30,570]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:30:33,830]\u001b[0m Trial 114 finished with value: 6.4227161276851055 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013747613032218686, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3746772030548864, 'dropout_rate_Layer_2': 0.3768947557424142, 'dropout_rate_Layer_3': 0.16607746309362753, 'dropout_rate_Layer_4': 0.16305761289482634, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 2.5227083610648194e-05, 'l1_Layer_2': 0.09050259283332728, 'l1_Layer_3': 0.0051097094368517375, 'l1_Layer_4': 0.004685185587589118, 'n_units_Layer_1': 200, 'n_units_Layer_2': 290, 'n_units_Layer_3': 165, 'n_units_Layer_4': 235}. Best is trial 104 with value: 4.792483162569156.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.42 | sMAPE for Validation Set is: 15.44% | rMAE for Validation Set is: 0.92\n",
      "MAE for Test Set is: 6.81 | sMAPE for Test Set is: 14.66% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:30:35,500]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:30:38,171]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:30:41,426]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:30:49,399]\u001b[0m Trial 129 finished with value: 5.604687459792946 and parameters: {'n_hidden': 4, 'learning_rate': 0.010157135507982107, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24424256579622688, 'dropout_rate_Layer_2': 0.09091385835593288, 'dropout_rate_Layer_3': 0.33060052467783746, 'dropout_rate_Layer_4': 0.29420775516679504, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.6261801205567124e-05, 'l1_Layer_2': 0.04335316048926246, 'l1_Layer_3': 1.658898152949142e-05, 'l1_Layer_4': 0.0037997805428009275, 'n_units_Layer_1': 55, 'n_units_Layer_2': 75, 'n_units_Layer_3': 90, 'n_units_Layer_4': 140}. Best is trial 104 with value: 4.792483162569156.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.60 | sMAPE for Validation Set is: 13.70% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 5.79 | sMAPE for Test Set is: 12.78% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:30:54,556]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:31:03,194]\u001b[0m Trial 143 finished with value: 5.844430044252335 and parameters: {'n_hidden': 4, 'learning_rate': 0.003994077538312608, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3816266724265413, 'dropout_rate_Layer_2': 0.33165725687527864, 'dropout_rate_Layer_3': 0.01288136612964742, 'dropout_rate_Layer_4': 0.05168313036617318, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.03987976773256863, 'l1_Layer_2': 0.00014074171076859228, 'l1_Layer_3': 0.005227310280384887, 'l1_Layer_4': 0.00014229030508208725, 'n_units_Layer_1': 95, 'n_units_Layer_2': 260, 'n_units_Layer_3': 150, 'n_units_Layer_4': 80}. Best is trial 104 with value: 4.792483162569156.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.84 | sMAPE for Validation Set is: 13.65% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 6.08 | sMAPE for Test Set is: 13.15% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:31:11,150]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:31:13,815]\u001b[0m Trial 141 finished with value: 4.959540944112746 and parameters: {'n_hidden': 3, 'learning_rate': 0.002047967972694306, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25708431315324753, 'dropout_rate_Layer_2': 0.25029447367162716, 'dropout_rate_Layer_3': 0.23759233862652568, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.3819692772090104e-05, 'l1_Layer_2': 0.00011863104002079628, 'l1_Layer_3': 4.5677114713469074e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 230, 'n_units_Layer_3': 180}. Best is trial 104 with value: 4.792483162569156.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.96 | sMAPE for Validation Set is: 11.62% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 5.76 | sMAPE for Test Set is: 12.57% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:31:16,374]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:31:20,048]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:31:23,688]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:31:26,716]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:31:31,708]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:31:35,394]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:31:37,062]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:31:44,131]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:31:44,489]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:31:49,351]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:31:52,447]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:31:57,020]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:32:03,026]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:32:05,270]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:32:09,702]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:32:12,467]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:32:15,258]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:32:28,600]\u001b[0m Trial 155 finished with value: 6.901073144467849 and parameters: {'n_hidden': 3, 'learning_rate': 0.005148215067573498, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39179793061741575, 'dropout_rate_Layer_2': 0.3396826426390754, 'dropout_rate_Layer_3': 0.18092788490295134, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.846683690242504e-05, 'l1_Layer_2': 0.048847826055599945, 'l1_Layer_3': 2.2332396536168273e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 290, 'n_units_Layer_3': 165}. Best is trial 104 with value: 4.792483162569156.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.90 | sMAPE for Validation Set is: 15.66% | rMAE for Validation Set is: 0.99\n",
      "MAE for Test Set is: 7.61 | sMAPE for Test Set is: 15.97% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:32:29,169]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:32:30,771]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:32:36,338]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:32:38,635]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:32:40,706]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:32:45,714]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:32:49,226]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:32:50,488]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:32:53,670]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:32:54,234]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:32:59,226]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:33:04,798]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:33:10,535]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:33:17,313]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:33:20,633]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:33:22,477]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:33:25,754]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:33:27,105]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:33:32,250]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:33:34,626]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:33:39,636]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:33:44,305]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:33:44,452]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:33:44,611]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:33:51,979]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:33:52,188]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:33:59,792]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:34:06,260]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:34:15,594]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:34:18,401]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:34:26,955]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:34:30,250]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:34:36,035]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:34:38,305]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:34:47,100]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:34:48,247]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:34:50,169]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:34:58,904]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:35:04,394]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:35:07,929]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:35:09,356]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:35:19,512]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:35:23,185]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:35:26,096]\u001b[0m Trial 207 finished with value: 12.784349798046234 and parameters: {'n_hidden': 4, 'learning_rate': 0.07333079185519051, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2832082148879156, 'dropout_rate_Layer_2': 0.39169497191630215, 'dropout_rate_Layer_3': 0.16830835432096616, 'dropout_rate_Layer_4': 0.025899409513386786, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0011856629605012043, 'l1_Layer_2': 0.00035659068711318357, 'l1_Layer_3': 0.0007958374093639814, 'l1_Layer_4': 0.0006348038051969628, 'n_units_Layer_1': 220, 'n_units_Layer_2': 145, 'n_units_Layer_3': 205, 'n_units_Layer_4': 295}. Best is trial 104 with value: 4.792483162569156.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.78 | sMAPE for Validation Set is: 29.36% | rMAE for Validation Set is: 1.83\n",
      "MAE for Test Set is: 12.81 | sMAPE for Test Set is: 28.01% | rMAE for Test Set is: 1.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:35:34,943]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:35:38,818]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:35:42,107]\u001b[0m Trial 190 finished with value: 6.537749275806007 and parameters: {'n_hidden': 3, 'learning_rate': 0.018111126720837985, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1436632348169211, 'dropout_rate_Layer_2': 0.3626305179103077, 'dropout_rate_Layer_3': 0.14172514270955597, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.016447183659354252, 'l1_Layer_2': 2.050691298081513e-05, 'l1_Layer_3': 0.011733327821935095, 'n_units_Layer_1': 225, 'n_units_Layer_2': 145, 'n_units_Layer_3': 300}. Best is trial 104 with value: 4.792483162569156.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.54 | sMAPE for Validation Set is: 14.88% | rMAE for Validation Set is: 0.94\n",
      "MAE for Test Set is: 6.93 | sMAPE for Test Set is: 14.71% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:35:51,147]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:35:53,883]\u001b[0m Trial 210 finished with value: 6.006340512363603 and parameters: {'n_hidden': 3, 'learning_rate': 0.053205675695964114, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05219845843253701, 'dropout_rate_Layer_2': 0.30202609949010134, 'dropout_rate_Layer_3': 0.2604927860108915, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.3200300453764564e-05, 'l1_Layer_2': 0.00024210111163894548, 'l1_Layer_3': 0.0008047037030983438, 'n_units_Layer_1': 205, 'n_units_Layer_2': 170, 'n_units_Layer_3': 165}. Best is trial 104 with value: 4.792483162569156.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.01 | sMAPE for Validation Set is: 14.32% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 5.93 | sMAPE for Test Set is: 13.05% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:36:00,788]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:36:08,675]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:36:10,671]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:36:14,830]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:36:19,035]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:36:27,869]\u001b[0m Trial 220 finished with value: 7.386381843689432 and parameters: {'n_hidden': 3, 'learning_rate': 0.06712784109231766, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11468674199843026, 'dropout_rate_Layer_2': 0.0839446899185836, 'dropout_rate_Layer_3': 0.0749946049167382, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.010096908225225484, 'l1_Layer_2': 0.00014172696652965615, 'l1_Layer_3': 9.100353769514447e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 210, 'n_units_Layer_3': 300}. Best is trial 104 with value: 4.792483162569156.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.39 | sMAPE for Validation Set is: 16.69% | rMAE for Validation Set is: 1.06\n",
      "MAE for Test Set is: 8.75 | sMAPE for Test Set is: 18.44% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:36:30,805]\u001b[0m Trial 221 finished with value: 7.292421665804345 and parameters: {'n_hidden': 3, 'learning_rate': 0.0931077329530432, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29511165598582145, 'dropout_rate_Layer_2': 0.08236381407173952, 'dropout_rate_Layer_3': 0.10097024350940731, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.011239163416830086, 'l1_Layer_2': 0.00011994355829425779, 'l1_Layer_3': 8.82070713240198e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 205, 'n_units_Layer_3': 290}. Best is trial 104 with value: 4.792483162569156.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.29 | sMAPE for Validation Set is: 16.81% | rMAE for Validation Set is: 1.04\n",
      "MAE for Test Set is: 8.55 | sMAPE for Test Set is: 18.29% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:36:34,601]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:36:37,641]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:36:39,115]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:36:44,075]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:36:45,670]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:36:51,285]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:36:55,264]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:36:59,049]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:37:03,621]\u001b[0m Trial 230 finished with value: 12.946541589287628 and parameters: {'n_hidden': 3, 'learning_rate': 0.08172463611086862, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3827726418168702, 'dropout_rate_Layer_2': 0.20854946858331547, 'dropout_rate_Layer_3': 0.37757433848727995, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0009548308033362639, 'l1_Layer_2': 0.00046351974962746635, 'l1_Layer_3': 3.679313175588664e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 145, 'n_units_Layer_3': 175}. Best is trial 104 with value: 4.792483162569156.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.95 | sMAPE for Validation Set is: 28.33% | rMAE for Validation Set is: 1.85\n",
      "MAE for Test Set is: 12.39 | sMAPE for Test Set is: 25.83% | rMAE for Test Set is: 1.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:37:05,085]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:37:09,792]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:37:16,386]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:37:20,734]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:37:27,643]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:37:32,539]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:37:36,265]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:37:37,917]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:37:41,347]\u001b[0m Trial 213 finished with value: 5.5316675757518246 and parameters: {'n_hidden': 4, 'learning_rate': 0.014182042368945892, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1438264315796578, 'dropout_rate_Layer_2': 0.056434162803223345, 'dropout_rate_Layer_3': 0.0852323161214649, 'dropout_rate_Layer_4': 0.2650333553441566, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.312659153034839e-05, 'l1_Layer_2': 0.00030816553250123565, 'l1_Layer_3': 5.6793596372489664e-05, 'l1_Layer_4': 0.012073081678554904, 'n_units_Layer_1': 105, 'n_units_Layer_2': 115, 'n_units_Layer_3': 65, 'n_units_Layer_4': 270}. Best is trial 104 with value: 4.792483162569156.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.53 | sMAPE for Validation Set is: 12.94% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 6.39 | sMAPE for Test Set is: 13.42% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:37:45,987]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:37:52,189]\u001b[0m Trial 226 finished with value: 5.241759760956968 and parameters: {'n_hidden': 3, 'learning_rate': 0.0094103088968685, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2648020370478203, 'dropout_rate_Layer_2': 0.31364931464987783, 'dropout_rate_Layer_3': 0.1012914007633777, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4832245284866792e-05, 'l1_Layer_2': 0.00011203938631312787, 'l1_Layer_3': 2.3155808557968705e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 150, 'n_units_Layer_3': 170}. Best is trial 104 with value: 4.792483162569156.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.24 | sMAPE for Validation Set is: 12.69% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 6.79 | sMAPE for Test Set is: 15.03% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:37:52,529]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:37:58,357]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:37:58,947]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:37:59,304]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:38:05,982]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:38:08,438]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:38:09,344]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:38:11,159]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:38:11,634]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:38:20,559]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:38:24,345]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:38:25,577]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:38:33,359]\u001b[0m Trial 249 finished with value: 6.559114166975465 and parameters: {'n_hidden': 4, 'learning_rate': 0.021970141875282328, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37711765994007895, 'dropout_rate_Layer_2': 0.19405955669427974, 'dropout_rate_Layer_3': 0.20209077615927842, 'dropout_rate_Layer_4': 0.10463636891215611, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 3.902118472431026e-05, 'l1_Layer_2': 4.317837929524589e-05, 'l1_Layer_3': 0.0013898673448922891, 'l1_Layer_4': 1.2901066913135562e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 145, 'n_units_Layer_3': 50, 'n_units_Layer_4': 285}. Best is trial 104 with value: 4.792483162569156.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.56 | sMAPE for Validation Set is: 14.79% | rMAE for Validation Set is: 0.94\n",
      "MAE for Test Set is: 8.73 | sMAPE for Test Set is: 18.10% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:38:37,100]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:38:40,586]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:38:46,534]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:38:47,055]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.04 | sMAPE for Validation Set is: 13.76% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 6.39 | sMAPE for Test Set is: 13.52% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:38:51,067]\u001b[0m Trial 254 finished with value: 6.043776064758194 and parameters: {'n_hidden': 3, 'learning_rate': 0.02476424292736129, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15565839806468684, 'dropout_rate_Layer_2': 0.02650370794946695, 'dropout_rate_Layer_3': 0.1391454047021623, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0001355107357143015, 'l1_Layer_2': 0.0010752334309317695, 'l1_Layer_3': 0.014451689994153544, 'n_units_Layer_1': 105, 'n_units_Layer_2': 135, 'n_units_Layer_3': 135}. Best is trial 104 with value: 4.792483162569156.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:38:54,124]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:38:57,202]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:38:59,479]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:39:03,411]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:39:09,320]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:39:12,545]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:39:14,484]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:39:21,558]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:39:25,869]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:39:27,806]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:39:27,944]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:39:31,002]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:39:32,643]\u001b[0m Trial 262 finished with value: 5.299220838076131 and parameters: {'n_hidden': 4, 'learning_rate': 0.015907459570353468, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03145727491842846, 'dropout_rate_Layer_2': 0.27084916681874627, 'dropout_rate_Layer_3': 0.14043478198795328, 'dropout_rate_Layer_4': 0.18055343717822955, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.06321778424063548, 'l1_Layer_2': 1.1808254187990414e-05, 'l1_Layer_3': 0.0002668772802253333, 'l1_Layer_4': 0.01306516708824189, 'n_units_Layer_1': 240, 'n_units_Layer_2': 120, 'n_units_Layer_3': 95, 'n_units_Layer_4': 280}. Best is trial 104 with value: 4.792483162569156.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.30 | sMAPE for Validation Set is: 12.83% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 5.83 | sMAPE for Test Set is: 12.91% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:39:39,327]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:39:39,421]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:39:40,066]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:39:42,923]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:39:45,962]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:39:46,070]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:39:52,781]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:39:55,334]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:39:59,812]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:40:03,048]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:40:06,313]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:40:11,048]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:40:17,899]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:40:18,294]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:40:22,056]\u001b[0m Trial 280 finished with value: 5.640064767290538 and parameters: {'n_hidden': 4, 'learning_rate': 0.003229940797937816, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34129351689254706, 'dropout_rate_Layer_2': 0.3641539373279581, 'dropout_rate_Layer_3': 0.07692847204390288, 'dropout_rate_Layer_4': 0.09520336808427565, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.009093877803513799, 'l1_Layer_2': 1.8497323981984804e-05, 'l1_Layer_3': 0.007051509727591693, 'l1_Layer_4': 3.6010824352801653e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 190, 'n_units_Layer_3': 180, 'n_units_Layer_4': 105}. Best is trial 104 with value: 4.792483162569156.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.64 | sMAPE for Validation Set is: 13.10% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 6.13 | sMAPE for Test Set is: 13.23% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:40:26,524]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:40:28,593]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:40:31,540]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:40:34,575]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:40:34,995]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:40:42,657]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:40:50,787]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:40:53,038]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:40:58,734]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:41:02,261]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:41:03,631]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:41:05,921]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:41:11,540]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:41:11,965]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:41:14,436]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:41:21,579]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:41:37,037]\u001b[0m Trial 305 finished with value: 14.098577669319495 and parameters: {'n_hidden': 3, 'learning_rate': 0.040876746605690656, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1244323652077936, 'dropout_rate_Layer_2': 0.002348430953421528, 'dropout_rate_Layer_3': 0.2655299574342026, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00013012506274382097, 'l1_Layer_2': 0.002323563135990299, 'l1_Layer_3': 0.08395156067094028, 'n_units_Layer_1': 60, 'n_units_Layer_2': 210, 'n_units_Layer_3': 110}. Best is trial 104 with value: 4.792483162569156.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.10 | sMAPE for Validation Set is: 31.58% | rMAE for Validation Set is: 2.02\n",
      "MAE for Test Set is: 16.44 | sMAPE for Test Set is: 34.94% | rMAE for Test Set is: 2.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:41:40,217]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:41:42,837]\u001b[0m Trial 304 finished with value: 5.665884415477348 and parameters: {'n_hidden': 4, 'learning_rate': 0.002752594401490837, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3592435208725906, 'dropout_rate_Layer_2': 0.3478733025150084, 'dropout_rate_Layer_3': 0.03718255642737574, 'dropout_rate_Layer_4': 0.11736802219576563, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.006469596060040465, 'l1_Layer_2': 1.8879477835264497e-05, 'l1_Layer_3': 0.011484533946077584, 'l1_Layer_4': 3.173044776813801e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 200, 'n_units_Layer_3': 135, 'n_units_Layer_4': 110}. Best is trial 104 with value: 4.792483162569156.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.67 | sMAPE for Validation Set is: 13.27% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 5.92 | sMAPE for Test Set is: 12.84% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:41:51,256]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:41:57,695]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:42:03,424]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:42:09,036]\u001b[0m Trial 306 finished with value: 5.581545854520532 and parameters: {'n_hidden': 4, 'learning_rate': 0.0029295835556799247, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3570552227498053, 'dropout_rate_Layer_2': 0.3133792518531505, 'dropout_rate_Layer_3': 0.04321560849584192, 'dropout_rate_Layer_4': 0.08311786291492804, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0016898629750915284, 'l1_Layer_2': 1.010996850024202e-05, 'l1_Layer_3': 0.011167233768008168, 'l1_Layer_4': 3.261063719861287e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 150, 'n_units_Layer_3': 180, 'n_units_Layer_4': 95}. Best is trial 104 with value: 4.792483162569156.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.58 | sMAPE for Validation Set is: 13.15% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 5.82 | sMAPE for Test Set is: 12.75% | rMAE for Test Set is: 0.75\n",
      "MAE for Validation Set is: 4.87 | sMAPE for Validation Set is: 12.11% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 5.54 | sMAPE for Test Set is: 12.33% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:42:11,114]\u001b[0m Trial 294 finished with value: 4.873136831004749 and parameters: {'n_hidden': 4, 'learning_rate': 0.014069183111724901, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2776481820377716, 'dropout_rate_Layer_2': 0.34217950434352196, 'dropout_rate_Layer_3': 0.31476908960127553, 'dropout_rate_Layer_4': 0.3163121576352245, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 6.266212314238548e-05, 'l1_Layer_2': 0.057145931010586445, 'l1_Layer_3': 1.4182309582040385e-05, 'l1_Layer_4': 7.108126946479665e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 80, 'n_units_Layer_3': 80, 'n_units_Layer_4': 160}. Best is trial 104 with value: 4.792483162569156.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:42:14,918]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:42:18,833]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:42:28,717]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:42:34,527]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:42:52,849]\u001b[0m Trial 317 finished with value: 5.677539538617907 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005158320287222153, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21035447132895704, 'dropout_rate_Layer_2': 0.35703760337769574, 'dropout_rate_Layer_3': 0.33559359463271504, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0130964202182006e-05, 'l1_Layer_2': 3.590346738579627e-05, 'l1_Layer_3': 1.8297462910689823e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 100, 'n_units_Layer_3': 50}. Best is trial 104 with value: 4.792483162569156.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.68 | sMAPE for Validation Set is: 13.42% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 6.37 | sMAPE for Test Set is: 13.92% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:43:43,824]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:43:50,604]\u001b[0m Trial 311 finished with value: 5.624657577047579 and parameters: {'n_hidden': 4, 'learning_rate': 0.008322685387125515, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28952274459415256, 'dropout_rate_Layer_2': 0.36599744211578034, 'dropout_rate_Layer_3': 0.28509142875670723, 'dropout_rate_Layer_4': 0.22374356372445775, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 4.423498416366858e-05, 'l1_Layer_2': 0.08378510546615325, 'l1_Layer_3': 1.5019910844803162e-05, 'l1_Layer_4': 3.755199203410658e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 60, 'n_units_Layer_3': 80, 'n_units_Layer_4': 160}. Best is trial 104 with value: 4.792483162569156.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.62 | sMAPE for Validation Set is: 13.13% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 6.15 | sMAPE for Test Set is: 13.30% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:43:52,783]\u001b[0m Trial 315 finished with value: 4.7000636892922545 and parameters: {'n_hidden': 4, 'learning_rate': 0.01401570269407919, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2819813457516712, 'dropout_rate_Layer_2': 0.07898100413492475, 'dropout_rate_Layer_3': 0.2805409258234715, 'dropout_rate_Layer_4': 0.31848287819264137, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.332588409800624e-05, 'l1_Layer_2': 0.08527826723044263, 'l1_Layer_3': 1.2829990053725408e-05, 'l1_Layer_4': 5.3553056712911826e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 60, 'n_units_Layer_3': 85, 'n_units_Layer_4': 160}. Best is trial 315 with value: 4.7000636892922545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.70 | sMAPE for Validation Set is: 11.54% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.44 | sMAPE for Test Set is: 12.05% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:43:58,887]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:44:02,707]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:44:03,538]\u001b[0m Trial 313 finished with value: 4.653307364390994 and parameters: {'n_hidden': 4, 'learning_rate': 0.008317412279878632, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.269072705652561, 'dropout_rate_Layer_2': 0.3232729746445829, 'dropout_rate_Layer_3': 0.31417000582712556, 'dropout_rate_Layer_4': 0.32450371176584947, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 8.621684799723866e-05, 'l1_Layer_2': 0.0943904554629844, 'l1_Layer_3': 1.3533864185562712e-05, 'l1_Layer_4': 1.8136605126163605e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 100, 'n_units_Layer_3': 85, 'n_units_Layer_4': 160}. Best is trial 313 with value: 4.653307364390994.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.65 | sMAPE for Validation Set is: 11.51% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.22 | sMAPE for Test Set is: 11.59% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:44:07,135]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:44:10,723]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:44:12,968]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:44:16,701]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:44:23,471]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:44:25,817]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:44:30,893]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:44:34,972]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:44:39,467]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:44:44,680]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:44:51,412]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:45:05,919]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:45:10,272]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:45:14,664]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:45:24,026]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:45:31,328]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:45:42,656]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:45:49,883]\u001b[0m Trial 339 finished with value: 5.358815179155303 and parameters: {'n_hidden': 4, 'learning_rate': 0.002658923234217957, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10664019023243425, 'dropout_rate_Layer_2': 0.34773476364583544, 'dropout_rate_Layer_3': 0.03404743287978538, 'dropout_rate_Layer_4': 0.09642779605417448, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.005332750446499922, 'l1_Layer_2': 1.4009149581731915e-05, 'l1_Layer_3': 0.005121955358748839, 'l1_Layer_4': 3.730435113175726e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 195, 'n_units_Layer_3': 240, 'n_units_Layer_4': 105}. Best is trial 313 with value: 4.653307364390994.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.36 | sMAPE for Validation Set is: 12.71% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 5.87 | sMAPE for Test Set is: 12.87% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:46:02,204]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:46:09,410]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:46:13,149]\u001b[0m Trial 319 finished with value: 4.859256903690111 and parameters: {'n_hidden': 4, 'learning_rate': 0.00803548109544126, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2873587613697033, 'dropout_rate_Layer_2': 0.08014427378371387, 'dropout_rate_Layer_3': 0.26627920594199656, 'dropout_rate_Layer_4': 0.13170046160218202, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.435049482980087e-05, 'l1_Layer_2': 0.08271781186789512, 'l1_Layer_3': 1.6290193160034254e-05, 'l1_Layer_4': 7.021025219743726e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 120, 'n_units_Layer_3': 55, 'n_units_Layer_4': 170}. Best is trial 313 with value: 4.653307364390994.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.86 | sMAPE for Validation Set is: 11.92% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 5.31 | sMAPE for Test Set is: 11.81% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:46:14,841]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:46:16,287]\u001b[0m Trial 342 finished with value: 5.594623125696092 and parameters: {'n_hidden': 3, 'learning_rate': 0.027803367351176885, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15678663520844288, 'dropout_rate_Layer_2': 0.11487490619767311, 'dropout_rate_Layer_3': 0.0012512825562062124, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022682122296425065, 'l1_Layer_2': 0.005903181447326298, 'l1_Layer_3': 2.6991410570336124e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 190, 'n_units_Layer_3': 265}. Best is trial 313 with value: 4.653307364390994.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.59 | sMAPE for Validation Set is: 13.45% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 6.28 | sMAPE for Test Set is: 13.95% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:46:26,991]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:46:47,212]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:46:51,026]\u001b[0m Trial 341 finished with value: 4.875851146704214 and parameters: {'n_hidden': 3, 'learning_rate': 0.012435955378017586, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08375031531228458, 'dropout_rate_Layer_2': 0.008843278660615617, 'dropout_rate_Layer_3': 0.08672668729265454, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0430413156930705e-05, 'l1_Layer_2': 0.0007056559149455346, 'l1_Layer_3': 0.017758345282888766, 'n_units_Layer_1': 145, 'n_units_Layer_2': 85, 'n_units_Layer_3': 120}. Best is trial 313 with value: 4.653307364390994.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.88 | sMAPE for Validation Set is: 11.82% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 5.52 | sMAPE for Test Set is: 12.10% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:47:20,531]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:47:21,294]\u001b[0m Trial 350 finished with value: 5.521003403850108 and parameters: {'n_hidden': 4, 'learning_rate': 0.005695011307541831, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12579437318246717, 'dropout_rate_Layer_2': 0.3392177551636133, 'dropout_rate_Layer_3': 0.052166529368710975, 'dropout_rate_Layer_4': 0.12655761523418355, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00483586260955494, 'l1_Layer_2': 2.435955673073883e-05, 'l1_Layer_3': 0.007413376106459869, 'l1_Layer_4': 1.9490593138337235e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 205, 'n_units_Layer_3': 140, 'n_units_Layer_4': 90}. Best is trial 313 with value: 4.653307364390994.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.52 | sMAPE for Validation Set is: 13.16% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 5.94 | sMAPE for Test Set is: 13.01% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:47:30,068]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:48:14,126]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:48:33,247]\u001b[0m Trial 347 finished with value: 5.1982049547405005 and parameters: {'n_hidden': 4, 'learning_rate': 0.010007034166753484, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26664452592659793, 'dropout_rate_Layer_2': 0.3523530140151718, 'dropout_rate_Layer_3': 0.2558190641324674, 'dropout_rate_Layer_4': 0.14179918562751476, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 6.51252277215084e-05, 'l1_Layer_2': 0.07288979157009058, 'l1_Layer_3': 1.4394773936948428e-05, 'l1_Layer_4': 1.4507092185485205e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 110, 'n_units_Layer_3': 75, 'n_units_Layer_4': 190}. Best is trial 313 with value: 4.653307364390994.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.20 | sMAPE for Validation Set is: 12.90% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 5.68 | sMAPE for Test Set is: 12.64% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:49:06,582]\u001b[0m Trial 354 finished with value: 4.694652727675838 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005035920628177523, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26317232073153857, 'dropout_rate_Layer_2': 0.3026450601635103, 'dropout_rate_Layer_3': 0.1560594663978528, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.8761945799811946e-05, 'l1_Layer_2': 8.758808860040989e-05, 'l1_Layer_3': 0.00010955567222738163, 'n_units_Layer_1': 210, 'n_units_Layer_2': 125, 'n_units_Layer_3': 150}. Best is trial 313 with value: 4.653307364390994.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.69 | sMAPE for Validation Set is: 11.44% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.15 | sMAPE for Test Set is: 11.39% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:49:17,077]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:49:21,512]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:49:39,246]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:49:42,384]\u001b[0m Trial 346 finished with value: 4.82161573567648 and parameters: {'n_hidden': 4, 'learning_rate': 0.006423724360850982, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26785281704848635, 'dropout_rate_Layer_2': 0.3571566205243011, 'dropout_rate_Layer_3': 0.26121264231709823, 'dropout_rate_Layer_4': 0.13570820706722092, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 6.167015108005539e-05, 'l1_Layer_2': 0.06753348523950327, 'l1_Layer_3': 1.4857445808799722e-05, 'l1_Layer_4': 0.0001805916459137603, 'n_units_Layer_1': 180, 'n_units_Layer_2': 110, 'n_units_Layer_3': 75, 'n_units_Layer_4': 185}. Best is trial 313 with value: 4.653307364390994.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.82 | sMAPE for Validation Set is: 11.69% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 5.18 | sMAPE for Test Set is: 11.42% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:49:46,832]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:49:55,486]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:50:05,113]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:50:16,201]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:50:16,409]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:50:24,269]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:50:56,606]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:51:28,481]\u001b[0m Trial 359 finished with value: 4.934424699991109 and parameters: {'n_hidden': 4, 'learning_rate': 0.011692678566649435, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2794342241365028, 'dropout_rate_Layer_2': 0.3341203190031954, 'dropout_rate_Layer_3': 0.2566138681535618, 'dropout_rate_Layer_4': 0.13045403557028173, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.684754844800753e-05, 'l1_Layer_2': 0.06401303940288407, 'l1_Layer_3': 1.3202621247576816e-05, 'l1_Layer_4': 0.0002981818972593809, 'n_units_Layer_1': 185, 'n_units_Layer_2': 100, 'n_units_Layer_3': 70, 'n_units_Layer_4': 190}. Best is trial 313 with value: 4.653307364390994.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.93 | sMAPE for Validation Set is: 12.29% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 5.42 | sMAPE for Test Set is: 12.27% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:52:01,280]\u001b[0m Trial 366 finished with value: 5.017129633142518 and parameters: {'n_hidden': 4, 'learning_rate': 0.009925660502658414, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2534135598016766, 'dropout_rate_Layer_2': 0.3481524054617799, 'dropout_rate_Layer_3': 0.2391565859167343, 'dropout_rate_Layer_4': 0.15125201556414758, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.5619263897912654e-05, 'l1_Layer_2': 0.06234059710810892, 'l1_Layer_3': 2.4427510773329294e-05, 'l1_Layer_4': 0.00011947595059022847, 'n_units_Layer_1': 165, 'n_units_Layer_2': 105, 'n_units_Layer_3': 70, 'n_units_Layer_4': 195}. Best is trial 313 with value: 4.653307364390994.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.02 | sMAPE for Validation Set is: 12.58% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 5.60 | sMAPE for Test Set is: 12.40% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:52:11,083]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:52:31,153]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:52:40,671]\u001b[0m Trial 368 finished with value: 5.163088790386971 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005883180345871118, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014110160927555584, 'dropout_rate_Layer_2': 0.01357731148050087, 'dropout_rate_Layer_3': 0.039521684096007335, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003908298572764321, 'l1_Layer_2': 0.002243953264771236, 'l1_Layer_3': 0.0032721870069523603, 'n_units_Layer_1': 160, 'n_units_Layer_2': 235, 'n_units_Layer_3': 115}. Best is trial 313 with value: 4.653307364390994.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.16 | sMAPE for Validation Set is: 12.15% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 5.26 | sMAPE for Test Set is: 11.61% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:52:44,461]\u001b[0m Trial 367 finished with value: 4.66999024224237 and parameters: {'n_hidden': 4, 'learning_rate': 0.00506656297945999, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2532965448411324, 'dropout_rate_Layer_2': 0.32706221613562486, 'dropout_rate_Layer_3': 0.2437453443303351, 'dropout_rate_Layer_4': 0.13322086863781848, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.372285450610628e-05, 'l1_Layer_2': 0.028820314531279898, 'l1_Layer_3': 1.2686001247235293e-05, 'l1_Layer_4': 0.00027291007443087944, 'n_units_Layer_1': 175, 'n_units_Layer_2': 105, 'n_units_Layer_3': 70, 'n_units_Layer_4': 195}. Best is trial 313 with value: 4.653307364390994.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.67 | sMAPE for Validation Set is: 11.44% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.30 | sMAPE for Test Set is: 11.69% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:52:44,740]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:52:51,194]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.12 | sMAPE for Validation Set is: 12.10% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 5.60 | sMAPE for Test Set is: 12.24% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:52:54,504]\u001b[0m Trial 365 finished with value: 5.120213281246982 and parameters: {'n_hidden': 4, 'learning_rate': 0.010068349811379385, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2561823633327012, 'dropout_rate_Layer_2': 0.325153763444841, 'dropout_rate_Layer_3': 0.2420279984406885, 'dropout_rate_Layer_4': 0.13356021991888747, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 7.633636220032202e-05, 'l1_Layer_2': 0.06405993529766449, 'l1_Layer_3': 1.2240090583484235e-05, 'l1_Layer_4': 0.00018321435918848325, 'n_units_Layer_1': 165, 'n_units_Layer_2': 105, 'n_units_Layer_3': 70, 'n_units_Layer_4': 170}. Best is trial 313 with value: 4.653307364390994.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:52:58,931]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:52:59,131]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:53:05,878]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:53:16,275]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:53:20,632]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:53:25,627]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:53:35,685]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:53:41,998]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:53:53,914]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:54:13,227]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:54:19,037]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:54:24,216]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:54:29,541]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:54:37,272]\u001b[0m Trial 386 finished with value: 5.849572608666268 and parameters: {'n_hidden': 4, 'learning_rate': 0.0055566765715848515, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23261585570953236, 'dropout_rate_Layer_2': 0.3503203102254779, 'dropout_rate_Layer_3': 0.020575626386253917, 'dropout_rate_Layer_4': 0.012670376879893605, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.07088137910168202, 'l1_Layer_2': 4.5457799254619406e-05, 'l1_Layer_3': 1.6874554156987487e-05, 'l1_Layer_4': 4.088583356892854e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 225, 'n_units_Layer_3': 275, 'n_units_Layer_4': 180}. Best is trial 313 with value: 4.653307364390994.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.85 | sMAPE for Validation Set is: 13.80% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 6.43 | sMAPE for Test Set is: 14.00% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:54:40,222]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:55:10,647]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:55:28,532]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:55:33,065]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:55:33,343]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:55:38,585]\u001b[0m Trial 371 finished with value: 4.815674639307588 and parameters: {'n_hidden': 4, 'learning_rate': 0.009567438663586936, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2555603992559283, 'dropout_rate_Layer_2': 0.32273180225449316, 'dropout_rate_Layer_3': 0.23964610364665762, 'dropout_rate_Layer_4': 0.13510641368343115, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.6196272148893186e-05, 'l1_Layer_2': 0.05794422449259458, 'l1_Layer_3': 1.2413384779556544e-05, 'l1_Layer_4': 0.00011764843295534358, 'n_units_Layer_1': 155, 'n_units_Layer_2': 95, 'n_units_Layer_3': 65, 'n_units_Layer_4': 190}. Best is trial 313 with value: 4.653307364390994.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.82 | sMAPE for Validation Set is: 11.85% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 5.83 | sMAPE for Test Set is: 12.57% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:55:42,277]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:55:42,911]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:55:52,151]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:56:01,512]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:56:04,503]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:56:14,534]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:56:20,916]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:56:24,810]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:56:24,905]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:56:31,699]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:56:44,774]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:56:51,112]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:57:00,147]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:57:02,944]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:57:10,897]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:57:22,003]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:57:31,027]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:57:33,942]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:57:52,506]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:57:55,319]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:58:03,494]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:58:05,963]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:58:09,012]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:58:11,608]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:58:12,030]\u001b[0m Trial 404 finished with value: 4.842430614426149 and parameters: {'n_hidden': 4, 'learning_rate': 0.01101002621494435, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.273040578513057, 'dropout_rate_Layer_2': 0.3470709696021944, 'dropout_rate_Layer_3': 0.24828623314576626, 'dropout_rate_Layer_4': 0.15312706930484385, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.674255605322669e-05, 'l1_Layer_2': 0.04984434104273391, 'l1_Layer_3': 1.3424128108781003e-05, 'l1_Layer_4': 5.534657548715736e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 90, 'n_units_Layer_3': 80, 'n_units_Layer_4': 165}. Best is trial 313 with value: 4.653307364390994.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.84 | sMAPE for Validation Set is: 11.96% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 5.50 | sMAPE for Test Set is: 12.29% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:58:16,145]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:58:20,414]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:58:24,438]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:58:26,883]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:58:27,592]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:58:34,489]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:58:40,075]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:58:42,725]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:58:46,520]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:58:48,848]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:58:57,571]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:59:03,167]\u001b[0m Trial 428 finished with value: 5.717687640651867 and parameters: {'n_hidden': 4, 'learning_rate': 0.00671224318191583, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17244290284031316, 'dropout_rate_Layer_2': 0.36088406109988014, 'dropout_rate_Layer_3': 0.09786350988271654, 'dropout_rate_Layer_4': 0.1429059751983541, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.003391290686754582, 'l1_Layer_2': 0.0006956110206160336, 'l1_Layer_3': 0.005666765024007537, 'l1_Layer_4': 1.2788939458380113e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 185, 'n_units_Layer_3': 180, 'n_units_Layer_4': 130}. Best is trial 313 with value: 4.653307364390994.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.72 | sMAPE for Validation Set is: 13.23% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 6.05 | sMAPE for Test Set is: 12.92% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:59:21,098]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:59:30,030]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:59:37,881]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:59:43,364]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.00 | sMAPE for Validation Set is: 11.73% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 5.30 | sMAPE for Test Set is: 11.52% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:59:44,817]\u001b[0m Trial 432 finished with value: 5.003341345343067 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019126225616882598, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14321094667596965, 'dropout_rate_Layer_2': 0.3712947878209263, 'dropout_rate_Layer_3': 0.05579668423164762, 'dropout_rate_Layer_4': 0.10842009955890965, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.010592962642964231, 'l1_Layer_2': 0.00037618180379320323, 'l1_Layer_3': 5.8200800551424934e-05, 'l1_Layer_4': 0.0002019061944288308, 'n_units_Layer_1': 80, 'n_units_Layer_2': 185, 'n_units_Layer_3': 165, 'n_units_Layer_4': 260}. Best is trial 313 with value: 4.653307364390994.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:59:45,803]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:59:52,130]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:59:55,599]\u001b[0m Trial 395 finished with value: 4.890729539638569 and parameters: {'n_hidden': 4, 'learning_rate': 0.0028154916238165707, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24764864277415582, 'dropout_rate_Layer_2': 0.31561113711738686, 'dropout_rate_Layer_3': 0.25373241880270136, 'dropout_rate_Layer_4': 0.1434970528498614, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 6.275816595733239e-05, 'l1_Layer_2': 0.07853816334619054, 'l1_Layer_3': 1.0138431945035851e-05, 'l1_Layer_4': 0.0001858909814384478, 'n_units_Layer_1': 155, 'n_units_Layer_2': 95, 'n_units_Layer_3': 70, 'n_units_Layer_4': 165}. Best is trial 313 with value: 4.653307364390994.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.89 | sMAPE for Validation Set is: 12.20% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 5.84 | sMAPE for Test Set is: 12.88% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:59:56,631]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:59:58,122]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:00:05,166]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:00:07,293]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:00:13,451]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:00:17,755]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:00:21,886]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:00:24,105]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:00:30,187]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:00:36,794]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:00:38,820]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:00:43,756]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:00:44,327]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:00:49,327]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:00:53,302]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:00:58,722]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:01:08,251]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:01:15,475]\u001b[0m Trial 444 finished with value: 4.533807734213284 and parameters: {'n_hidden': 3, 'learning_rate': 0.011539804541879351, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08002161723346345, 'dropout_rate_Layer_2': 0.08415679411690849, 'dropout_rate_Layer_3': 0.008775054960163953, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1063196532189286e-05, 'l1_Layer_2': 0.0073670674264226755, 'l1_Layer_3': 9.181394701519349e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 65, 'n_units_Layer_3': 60}. Best is trial 444 with value: 4.533807734213284.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.53 | sMAPE for Validation Set is: 11.20% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 4.81 | sMAPE for Test Set is: 10.69% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:01:20,434]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:01:26,088]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:01:28,624]\u001b[0m Trial 456 finished with value: 4.991307645785298 and parameters: {'n_hidden': 4, 'learning_rate': 0.004026705734146487, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12050232652071975, 'dropout_rate_Layer_2': 0.3438958173346364, 'dropout_rate_Layer_3': 0.0351438013694583, 'dropout_rate_Layer_4': 0.11866183644951113, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.050035320251324455, 'l1_Layer_2': 0.0009993684208969586, 'l1_Layer_3': 0.0066991856260634666, 'l1_Layer_4': 2.378880561128198e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 205, 'n_units_Layer_3': 120, 'n_units_Layer_4': 150}. Best is trial 444 with value: 4.533807734213284.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.99 | sMAPE for Validation Set is: 12.44% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 5.62 | sMAPE for Test Set is: 12.60% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:01:35,897]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:01:46,519]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:01:52,851]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:01:55,969]\u001b[0m Trial 461 finished with value: 4.486272155226276 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005518637899663158, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27869286168071267, 'dropout_rate_Layer_2': 0.29556105666040583, 'dropout_rate_Layer_3': 0.16125413845348133, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.538037902697003e-05, 'l1_Layer_2': 9.236542220418119e-05, 'l1_Layer_3': 3.230396151122288e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 100, 'n_units_Layer_3': 125}. Best is trial 461 with value: 4.486272155226276.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.49 | sMAPE for Validation Set is: 11.08% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.55 | sMAPE for Test Set is: 14.20% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:02:01,166]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:02:04,644]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:02:08,231]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:02:12,921]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:02:16,064]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:02:24,014]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:02:26,710]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:02:32,177]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:02:36,401]\u001b[0m Trial 467 finished with value: 4.549359874125966 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013314256614727553, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2839925194289568, 'dropout_rate_Layer_2': 0.2943134679398985, 'dropout_rate_Layer_3': 0.1583212418775634, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.449528761978889e-05, 'l1_Layer_2': 8.619297609532568e-05, 'l1_Layer_3': 3.4844803946879176e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 90, 'n_units_Layer_3': 125}. Best is trial 461 with value: 4.486272155226276.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.55 | sMAPE for Validation Set is: 11.28% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.57 | sMAPE for Test Set is: 12.15% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:02:36,987]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:02:41,156]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:02:41,903]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:02:47,331]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:02:51,373]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:02:52,628]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:02:54,612]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:03:01,886]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:03:10,377]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:03:10,967]\u001b[0m Trial 476 finished with value: 4.539231614196322 and parameters: {'n_hidden': 4, 'learning_rate': 0.002945291815612817, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12046467160199101, 'dropout_rate_Layer_2': 0.36786454757643605, 'dropout_rate_Layer_3': 0.053348601392663564, 'dropout_rate_Layer_4': 0.12381885857205223, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0060914272332143705, 'l1_Layer_2': 2.3304218515925802e-05, 'l1_Layer_3': 0.011961735323884276, 'l1_Layer_4': 3.94403264531185e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 195, 'n_units_Layer_3': 245, 'n_units_Layer_4': 125}. Best is trial 461 with value: 4.486272155226276.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.54 | sMAPE for Validation Set is: 11.46% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.43 | sMAPE for Test Set is: 12.24% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:03:17,114]\u001b[0m Trial 480 finished with value: 4.92994746028822 and parameters: {'n_hidden': 4, 'learning_rate': 0.0027971212450096238, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12047823897608921, 'dropout_rate_Layer_2': 0.36890715136568125, 'dropout_rate_Layer_3': 0.009159402350655127, 'dropout_rate_Layer_4': 0.08693743256388656, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.02841006174107231, 'l1_Layer_2': 1.0060815240491103e-05, 'l1_Layer_3': 0.008666865178925566, 'l1_Layer_4': 3.838473991431802e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 190, 'n_units_Layer_3': 105, 'n_units_Layer_4': 120}. Best is trial 461 with value: 4.486272155226276.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.93 | sMAPE for Validation Set is: 12.35% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 6.13 | sMAPE for Test Set is: 13.69% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:03:20,002]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:03:25,264]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:03:28,092]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:03:30,704]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:03:33,638]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:03:35,202]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:03:36,467]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:03:38,052]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:03:38,504]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:03:47,955]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:03:48,158]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:03:59,141]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:04:03,779]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:04:16,144]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:04:16,990]\u001b[0m Trial 496 finished with value: 4.714375111541713 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010914716753371546, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3034474427141044, 'dropout_rate_Layer_2': 0.27205044301764825, 'dropout_rate_Layer_3': 0.18484725585508885, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.3093282214973756e-05, 'l1_Layer_2': 0.00012073762623967992, 'l1_Layer_3': 7.067957149265572e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 130, 'n_units_Layer_3': 125}. Best is trial 461 with value: 4.486272155226276.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.71 | sMAPE for Validation Set is: 11.51% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.46 | sMAPE for Test Set is: 12.07% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:04:36,513]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:04:41,376]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:04:42,146]\u001b[0m Trial 499 finished with value: 4.821650651269341 and parameters: {'n_hidden': 4, 'learning_rate': 0.002171838839683124, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08905988771347238, 'dropout_rate_Layer_2': 0.3611572117862512, 'dropout_rate_Layer_3': 0.016670148668549274, 'dropout_rate_Layer_4': 0.08857284174891043, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.009295473148034616, 'l1_Layer_2': 3.0188788871604108e-05, 'l1_Layer_3': 0.007270646928744746, 'l1_Layer_4': 0.019446814036825782, 'n_units_Layer_1': 165, 'n_units_Layer_2': 200, 'n_units_Layer_3': 235, 'n_units_Layer_4': 135}. Best is trial 461 with value: 4.486272155226276.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.82 | sMAPE for Validation Set is: 12.01% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 5.56 | sMAPE for Test Set is: 12.50% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:04:48,261]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:04:53,453]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:05:05,168]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:05:08,138]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:05:08,369]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:05:24,853]\u001b[0m Trial 503 finished with value: 4.61448053696524 and parameters: {'n_hidden': 3, 'learning_rate': 0.009337316139470508, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08361343726041333, 'dropout_rate_Layer_2': 0.07472649728984984, 'dropout_rate_Layer_3': 0.006438224140874277, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1550008015328711e-05, 'l1_Layer_2': 0.010315542207092769, 'l1_Layer_3': 6.491280846377854e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 50, 'n_units_Layer_3': 50}. Best is trial 461 with value: 4.486272155226276.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.61 | sMAPE for Validation Set is: 11.46% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.61 | sMAPE for Test Set is: 12.45% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:05:46,162]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:05:46,504]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:05:52,296]\u001b[0m Trial 509 finished with value: 4.345716921000064 and parameters: {'n_hidden': 4, 'learning_rate': 0.003016509261925893, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07303378778935794, 'dropout_rate_Layer_2': 0.3422822336747942, 'dropout_rate_Layer_3': 0.010882195382092985, 'dropout_rate_Layer_4': 0.10642965234117226, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0048547711789427355, 'l1_Layer_2': 2.5034520818325778e-05, 'l1_Layer_3': 0.004418299737578966, 'l1_Layer_4': 0.004264881163334171, 'n_units_Layer_1': 175, 'n_units_Layer_2': 205, 'n_units_Layer_3': 245, 'n_units_Layer_4': 120}. Best is trial 509 with value: 4.345716921000064.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.35 | sMAPE for Validation Set is: 10.80% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.05 | sMAPE for Test Set is: 11.30% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:05:52,637]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:05:57,904]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:06:00,055]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:06:01,265]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:06:10,061]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:06:12,060]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:06:15,167]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:06:19,433]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:06:22,964]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:06:27,479]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:06:32,177]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:06:33,431]\u001b[0m Trial 508 finished with value: 4.475582746327257 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006416853348006373, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3133398160549006, 'dropout_rate_Layer_2': 0.2718226044757172, 'dropout_rate_Layer_3': 0.18850003113172087, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.224008785890009e-05, 'l1_Layer_2': 0.01120631830491984, 'l1_Layer_3': 0.000713746044893304, 'n_units_Layer_1': 220, 'n_units_Layer_2': 160, 'n_units_Layer_3': 140}. Best is trial 509 with value: 4.345716921000064.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.48 | sMAPE for Validation Set is: 11.14% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.44 | sMAPE for Test Set is: 12.15% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:06:35,663]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:06:47,741]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:06:53,148]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:06:54,945]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:06:56,221]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:06:59,724]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:07:07,500]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:07:12,427]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:07:13,092]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:07:18,009]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:07:21,526]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:07:26,146]\u001b[0m Trial 519 finished with value: 4.469017808131 and parameters: {'n_hidden': 4, 'learning_rate': 0.002102760647585763, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06865325448266743, 'dropout_rate_Layer_2': 0.3640564544469331, 'dropout_rate_Layer_3': 0.04615267233136026, 'dropout_rate_Layer_4': 0.0970916784631603, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.006653219130607215, 'l1_Layer_2': 2.4856667043945355e-05, 'l1_Layer_3': 0.004357049937136801, 'l1_Layer_4': 0.005713441222245728, 'n_units_Layer_1': 165, 'n_units_Layer_2': 205, 'n_units_Layer_3': 240, 'n_units_Layer_4': 145}. Best is trial 509 with value: 4.345716921000064.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.47 | sMAPE for Validation Set is: 11.10% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.96 | sMAPE for Test Set is: 11.04% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:07:29,233]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:07:33,721]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:07:35,949]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:07:39,714]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:07:43,037]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:07:46,075]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:07:50,172]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:07:52,749]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:07:58,336]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:07:58,814]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:08:05,597]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:08:08,539]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:08:12,004]\u001b[0m Trial 537 finished with value: 4.585585386246943 and parameters: {'n_hidden': 4, 'learning_rate': 0.002187986193067435, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06926672649767948, 'dropout_rate_Layer_2': 0.34169096860416037, 'dropout_rate_Layer_3': 0.027938671549438875, 'dropout_rate_Layer_4': 0.09515279647301506, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.016185809633513876, 'l1_Layer_2': 2.095100403559734e-05, 'l1_Layer_3': 0.0016682358009658875, 'l1_Layer_4': 0.002231288132943983, 'n_units_Layer_1': 190, 'n_units_Layer_2': 210, 'n_units_Layer_3': 250, 'n_units_Layer_4': 110}. Best is trial 509 with value: 4.345716921000064.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.59 | sMAPE for Validation Set is: 11.35% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.41 | sMAPE for Test Set is: 12.08% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:08:14,861]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:08:21,323]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:08:29,023]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:08:33,860]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:08:36,187]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:08:41,135]\u001b[0m Trial 545 finished with value: 4.533741050321519 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007879033365987513, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32650893565240807, 'dropout_rate_Layer_2': 0.2636727230803372, 'dropout_rate_Layer_3': 0.16538596335891584, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.39967384160648e-05, 'l1_Layer_2': 0.006772143165283741, 'l1_Layer_3': 7.693935268696369e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 140, 'n_units_Layer_3': 160}. Best is trial 509 with value: 4.345716921000064.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.53 | sMAPE for Validation Set is: 11.21% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.30 | sMAPE for Test Set is: 11.77% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:08:48,177]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:08:55,400]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:09:02,703]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:09:09,095]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:09:16,089]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:09:16,250]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:09:17,113]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:09:24,825]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:09:27,189]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:09:30,501]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:09:30,883]\u001b[0m Trial 551 finished with value: 4.533120602986444 and parameters: {'n_hidden': 4, 'learning_rate': 0.0021002084391269953, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03641484208367582, 'dropout_rate_Layer_2': 0.339925923556493, 'dropout_rate_Layer_3': 0.05244260197573289, 'dropout_rate_Layer_4': 0.10213695933259678, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.01063889936809499, 'l1_Layer_2': 3.371889519147222e-05, 'l1_Layer_3': 0.0006848588721626868, 'l1_Layer_4': 0.0022445099489187873, 'n_units_Layer_1': 190, 'n_units_Layer_2': 195, 'n_units_Layer_3': 250, 'n_units_Layer_4': 110}. Best is trial 509 with value: 4.345716921000064.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.53 | sMAPE for Validation Set is: 11.27% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.32 | sMAPE for Test Set is: 11.94% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:09:31,100]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:09:35,738]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:09:44,504]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:09:49,629]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:10:10,233]\u001b[0m Trial 568 finished with value: 4.641977763544469 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024818918217769576, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19486890207295374, 'dropout_rate_Layer_2': 0.08643049207160015, 'dropout_rate_Layer_3': 0.014675949826337574, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001185719341985442, 'l1_Layer_2': 0.008944094827359967, 'l1_Layer_3': 8.364576746371663e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 55, 'n_units_Layer_3': 50}. Best is trial 509 with value: 4.345716921000064.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.64 | sMAPE for Validation Set is: 11.59% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.59 | sMAPE for Test Set is: 12.40% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:10:19,073]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:10:23,590]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:10:26,250]\u001b[0m Trial 571 finished with value: 4.565579578880935 and parameters: {'n_hidden': 3, 'learning_rate': 0.002219093389291181, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21049968432369243, 'dropout_rate_Layer_2': 0.09233430912507935, 'dropout_rate_Layer_3': 0.00502865851958699, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012122540043702878, 'l1_Layer_2': 0.012807868102707141, 'l1_Layer_3': 5.3563780641330456e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 50, 'n_units_Layer_3': 50}. Best is trial 509 with value: 4.345716921000064.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.57 | sMAPE for Validation Set is: 11.48% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.16 | sMAPE for Test Set is: 11.63% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:10:27,147]\u001b[0m Trial 566 finished with value: 4.921579846554407 and parameters: {'n_hidden': 4, 'learning_rate': 0.002638849744408509, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03795481003106677, 'dropout_rate_Layer_2': 0.3546083206074519, 'dropout_rate_Layer_3': 0.062190805712496314, 'dropout_rate_Layer_4': 0.07136569751289326, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.009335129910760648, 'l1_Layer_2': 4.016529695588098e-05, 'l1_Layer_3': 0.003545899608725994, 'l1_Layer_4': 0.004703450448862487, 'n_units_Layer_1': 210, 'n_units_Layer_2': 215, 'n_units_Layer_3': 245, 'n_units_Layer_4': 135}. Best is trial 509 with value: 4.345716921000064.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.92 | sMAPE for Validation Set is: 12.14% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 5.56 | sMAPE for Test Set is: 12.47% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:10:27,421]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:10:29,837]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:10:37,235]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:10:40,509]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:10:41,197]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:10:50,543]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:10:52,615]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:10:54,042]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:10:55,983]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:10:58,880]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:11:07,139]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:11:11,156]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:11:22,764]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:11:27,209]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:11:30,780]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:11:33,950]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:11:37,523]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:11:37,625]\u001b[0m Trial 587 finished with value: 4.933430472756675 and parameters: {'n_hidden': 4, 'learning_rate': 0.0025734223637537607, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.023505826173280807, 'dropout_rate_Layer_2': 0.37816300032626476, 'dropout_rate_Layer_3': 0.04874162652910759, 'dropout_rate_Layer_4': 0.09606871773924788, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00889004488727802, 'l1_Layer_2': 5.273189311419087e-05, 'l1_Layer_3': 0.006807520911174603, 'l1_Layer_4': 0.006551382658078667, 'n_units_Layer_1': 210, 'n_units_Layer_2': 200, 'n_units_Layer_3': 240, 'n_units_Layer_4': 125}. Best is trial 509 with value: 4.345716921000064.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.93 | sMAPE for Validation Set is: 12.21% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 5.50 | sMAPE for Test Set is: 12.39% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:11:40,204]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:11:44,771]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:11:47,379]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:11:50,136]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:11:53,187]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:11:53,799]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:11:57,748]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:12:02,383]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:12:05,319]\u001b[0m Trial 586 finished with value: 4.521623259203394 and parameters: {'n_hidden': 4, 'learning_rate': 0.002665904590063068, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03347142215624605, 'dropout_rate_Layer_2': 0.3795374304488691, 'dropout_rate_Layer_3': 0.08433588476113124, 'dropout_rate_Layer_4': 0.09721089812374831, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.004525647122238511, 'l1_Layer_2': 1.6168518378355264e-05, 'l1_Layer_3': 0.004986324750748108, 'l1_Layer_4': 0.0058873765094349445, 'n_units_Layer_1': 225, 'n_units_Layer_2': 200, 'n_units_Layer_3': 225, 'n_units_Layer_4': 125}. Best is trial 509 with value: 4.345716921000064.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.52 | sMAPE for Validation Set is: 11.30% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.24 | sMAPE for Test Set is: 11.79% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:12:10,260]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:12:13,525]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:12:18,788]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:12:19,433]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:12:24,078]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:12:27,905]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:12:30,297]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:12:37,468]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:12:39,153]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:12:45,113]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:12:50,871]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:12:53,365]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:12:57,645]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:13:02,620]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:13:05,560]\u001b[0m Trial 600 finished with value: 4.505307336177684 and parameters: {'n_hidden': 3, 'learning_rate': 0.000628915852308361, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25249460345895675, 'dropout_rate_Layer_2': 0.12320564025554567, 'dropout_rate_Layer_3': 0.07079444130655742, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005355848844760898, 'l1_Layer_2': 0.021963174765980815, 'l1_Layer_3': 1.0801608424076585e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 90, 'n_units_Layer_3': 90}. Best is trial 509 with value: 4.345716921000064.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.51 | sMAPE for Validation Set is: 11.26% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.06 | sMAPE for Test Set is: 11.38% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:13:10,006]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:13:11,940]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:13:17,913]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:13:20,406]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:13:20,463]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:13:24,816]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:13:29,352]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:13:30,316]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:13:34,456]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:13:35,054]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:13:38,422]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:13:44,085]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:13:46,948]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:13:47,433]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:13:52,291]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:13:57,365]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:13:57,930]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:14:02,147]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:14:14,060]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:14:14,382]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:14:19,804]\u001b[0m Trial 634 finished with value: 4.671028102634118 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009444247202841518, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30647065900854426, 'dropout_rate_Layer_2': 0.31382209910782105, 'dropout_rate_Layer_3': 0.09607290302110776, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.64661434377869e-05, 'l1_Layer_2': 4.696967359514336e-05, 'l1_Layer_3': 0.00010024082577022076, 'n_units_Layer_1': 205, 'n_units_Layer_2': 120, 'n_units_Layer_3': 190}. Best is trial 509 with value: 4.345716921000064.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.67 | sMAPE for Validation Set is: 11.36% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.45 | sMAPE for Test Set is: 11.99% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:14:22,328]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:14:26,281]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:14:28,231]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:14:38,368]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:14:39,913]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:14:44,638]\u001b[0m Trial 632 finished with value: 4.471067322366065 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005348149067621092, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2538245403909173, 'dropout_rate_Layer_2': 0.14339747392406055, 'dropout_rate_Layer_3': 0.07752903539138555, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006016274808640145, 'l1_Layer_2': 0.027536527172262574, 'l1_Layer_3': 1.1279403595331368e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 95, 'n_units_Layer_3': 90}. Best is trial 509 with value: 4.345716921000064.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.47 | sMAPE for Validation Set is: 11.15% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.06 | sMAPE for Test Set is: 11.36% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:14:44,893]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:14:52,451]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:14:52,885]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:15:05,711]\u001b[0m Trial 644 finished with value: 4.620796276834869 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009412662519006769, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28831683248977125, 'dropout_rate_Layer_2': 0.3345565649190169, 'dropout_rate_Layer_3': 0.1265955091764552, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.262556027158867e-05, 'l1_Layer_2': 4.593496044724153e-05, 'l1_Layer_3': 0.00017327156216352137, 'n_units_Layer_1': 170, 'n_units_Layer_2': 115, 'n_units_Layer_3': 190}. Best is trial 509 with value: 4.345716921000064.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.62 | sMAPE for Validation Set is: 11.26% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.48 | sMAPE for Test Set is: 12.24% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:15:07,591]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:15:11,559]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:15:14,836]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:15:16,255]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:15:17,137]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:15:17,268]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:15:19,039]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:15:27,432]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:15:28,272]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:15:28,470]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:15:28,514]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:15:41,022]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:15:41,274]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:15:46,137]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:15:50,889]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:15:59,344]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:16:07,256]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:16:09,568]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:16:15,845]\u001b[0m Trial 663 finished with value: 4.528946135439242 and parameters: {'n_hidden': 4, 'learning_rate': 0.0022628537574687873, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12016889218048182, 'dropout_rate_Layer_2': 0.36760031957845424, 'dropout_rate_Layer_3': 0.07406696582552495, 'dropout_rate_Layer_4': 0.09649401240595454, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.010090367462602483, 'l1_Layer_2': 1.9000649071072454e-05, 'l1_Layer_3': 0.00012405685789603136, 'l1_Layer_4': 0.005078949856463713, 'n_units_Layer_1': 210, 'n_units_Layer_2': 190, 'n_units_Layer_3': 220, 'n_units_Layer_4': 90}. Best is trial 509 with value: 4.345716921000064.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.53 | sMAPE for Validation Set is: 11.20% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.29 | sMAPE for Test Set is: 11.82% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:16:18,675]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:16:19,563]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:16:22,145]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:16:27,418]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:16:30,298]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:16:32,129]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:16:43,728]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:16:44,180]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:16:44,388]\u001b[0m Trial 662 finished with value: 4.522205561845662 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005512244144119016, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27482229721288776, 'dropout_rate_Layer_2': 0.1368422021729358, 'dropout_rate_Layer_3': 0.0999264499045636, 'dropout_rate_Layer_4': 0.2566358033288198, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.006883373099095713, 'l1_Layer_2': 0.03197949928738385, 'l1_Layer_3': 1.3994789363022094e-05, 'l1_Layer_4': 1.0687897293183173e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 105, 'n_units_Layer_3': 90, 'n_units_Layer_4': 140}. Best is trial 509 with value: 4.345716921000064.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.52 | sMAPE for Validation Set is: 11.36% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.24 | sMAPE for Test Set is: 11.65% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:16:44,701]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:16:55,173]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:17:01,857]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:17:06,308]\u001b[0m Trial 677 finished with value: 4.59183839636364 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008196309902286245, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34126305844438315, 'dropout_rate_Layer_2': 0.0968393814882232, 'dropout_rate_Layer_3': 0.07746812587926924, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.553869900876147e-05, 'l1_Layer_2': 2.385343256085036e-05, 'l1_Layer_3': 0.00016401829451019923, 'n_units_Layer_1': 185, 'n_units_Layer_2': 105, 'n_units_Layer_3': 210}. Best is trial 509 with value: 4.345716921000064.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.59 | sMAPE for Validation Set is: 11.29% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.01 | sMAPE for Test Set is: 13.25% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:17:06,807]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:17:07,555]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:17:17,496]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:17:19,927]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:17:30,250]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:17:36,297]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:17:40,620]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:17:41,499]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:17:47,676]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:17:50,300]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:17:53,447]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:18:00,980]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:18:07,692]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:18:08,439]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:18:13,359]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:18:16,784]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:18:17,230]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:18:22,847]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:18:26,925]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:18:27,671]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:18:28,127]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:18:31,899]\u001b[0m Trial 678 finished with value: 4.621988701962447 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005234522404331094, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2738629887520831, 'dropout_rate_Layer_2': 0.14001740947162866, 'dropout_rate_Layer_3': 0.08590129310085025, 'dropout_rate_Layer_4': 0.2873565865044892, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00546387235657187, 'l1_Layer_2': 0.03801722862035657, 'l1_Layer_3': 1.1980850504337626e-05, 'l1_Layer_4': 1.1400379182660616e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 100, 'n_units_Layer_3': 90, 'n_units_Layer_4': 140}. Best is trial 509 with value: 4.345716921000064.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.62 | sMAPE for Validation Set is: 11.54% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.17 | sMAPE for Test Set is: 11.49% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:18:39,108]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:18:45,157]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:18:47,381]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:18:48,286]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:18:56,487]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:18:56,761]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:18:58,106]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:19:04,153]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:19:06,387]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:19:12,711]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:19:14,937]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:19:15,505]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:19:27,700]\u001b[0m Trial 713 finished with value: 4.829631731061741 and parameters: {'n_hidden': 3, 'learning_rate': 0.001256953088731482, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3077934815833972, 'dropout_rate_Layer_2': 0.2930419312505943, 'dropout_rate_Layer_3': 0.10949307750681966, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.821170185463281e-05, 'l1_Layer_2': 2.76028057304781e-05, 'l1_Layer_3': 7.783156883924141e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 120, 'n_units_Layer_3': 195}. Best is trial 509 with value: 4.345716921000064.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.83 | sMAPE for Validation Set is: 11.85% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 5.31 | sMAPE for Test Set is: 11.81% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:19:34,211]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:19:34,683]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:19:46,720]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:19:53,293]\u001b[0m Trial 704 finished with value: 4.343141581448319 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011448506444749016, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13017444494842514, 'dropout_rate_Layer_2': 0.15320905242570626, 'dropout_rate_Layer_3': 0.059876227478298225, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006117580563442586, 'l1_Layer_2': 0.00029408564641078463, 'l1_Layer_3': 0.0034118413508198255, 'n_units_Layer_1': 155, 'n_units_Layer_2': 280, 'n_units_Layer_3': 215}. Best is trial 704 with value: 4.343141581448319.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:19:53,385]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.34 | sMAPE for Validation Set is: 10.80% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.81 | sMAPE for Test Set is: 10.89% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:19:57,022]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:20:04,226]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:20:08,044]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:20:10,041]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:20:13,804]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:20:19,013]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:20:22,857]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:20:23,933]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:20:29,223]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:20:31,856]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:20:39,403]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:20:43,277]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:20:46,267]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:20:52,710]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:20:57,571]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:21:01,883]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:21:10,544]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:21:15,732]\u001b[0m Trial 722 finished with value: 4.363835453369987 and parameters: {'n_hidden': 4, 'learning_rate': 0.0023358521999841896, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08081231110632658, 'dropout_rate_Layer_2': 0.35680779049873024, 'dropout_rate_Layer_3': 0.002530113366399755, 'dropout_rate_Layer_4': 0.09037852348099605, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.019855236236861532, 'l1_Layer_2': 1.55176803915989e-05, 'l1_Layer_3': 0.0026886113829833877, 'l1_Layer_4': 2.8136169749692106e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 200, 'n_units_Layer_3': 85, 'n_units_Layer_4': 120}. Best is trial 704 with value: 4.343141581448319.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.36 | sMAPE for Validation Set is: 10.84% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.11 | sMAPE for Test Set is: 11.48% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:21:20,831]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:21:24,720]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:21:32,728]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:21:34,762]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:21:40,693]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:21:52,654]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:22:01,651]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:22:08,835]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:22:17,974]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:22:18,071]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:22:27,333]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:22:30,464]\u001b[0m Trial 744 finished with value: 4.369250769331026 and parameters: {'n_hidden': 4, 'learning_rate': 0.0020586256055971815, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08101139432352202, 'dropout_rate_Layer_2': 0.0739823350949812, 'dropout_rate_Layer_3': 0.025728436140187484, 'dropout_rate_Layer_4': 0.1292164302467944, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.019795210056212632, 'l1_Layer_2': 1.1592072526602905e-05, 'l1_Layer_3': 0.0021427611551380313, 'l1_Layer_4': 2.6832393943230105e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 90, 'n_units_Layer_3': 65, 'n_units_Layer_4': 135}. Best is trial 704 with value: 4.343141581448319.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.37 | sMAPE for Validation Set is: 10.93% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.98 | sMAPE for Test Set is: 11.20% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:22:36,936]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:22:44,945]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:23:01,157]\u001b[0m Trial 749 finished with value: 4.303453489042528 and parameters: {'n_hidden': 4, 'learning_rate': 0.0021106432544082056, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08247670754401185, 'dropout_rate_Layer_2': 0.37190833286134145, 'dropout_rate_Layer_3': 0.02188477002496502, 'dropout_rate_Layer_4': 0.11118072115857956, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.020720156234830995, 'l1_Layer_2': 1.1104464303177344e-05, 'l1_Layer_3': 0.0021130890226447783, 'l1_Layer_4': 2.7633555638900336e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 200, 'n_units_Layer_3': 235, 'n_units_Layer_4': 115}. Best is trial 749 with value: 4.303453489042528.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.30 | sMAPE for Validation Set is: 10.66% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.03 | sMAPE for Test Set is: 11.23% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:23:04,978]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:23:09,424]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:23:16,083]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:23:17,087]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:23:17,400]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:23:26,692]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:23:30,870]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:23:31,099]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:23:33,882]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:23:39,665]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:23:40,628]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:23:46,459]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:23:51,474]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:23:52,054]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:23:52,746]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:24:03,512]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:24:03,816]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:24:03,998]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.42 | sMAPE for Validation Set is: 11.00% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.17 | sMAPE for Test Set is: 11.61% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:24:09,921]\u001b[0m Trial 750 finished with value: 4.419649057401625 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011505607076336699, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.137007291894298, 'dropout_rate_Layer_2': 0.17513314138523448, 'dropout_rate_Layer_3': 0.058661580167736836, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005868719887204077, 'l1_Layer_2': 6.314403382871543e-05, 'l1_Layer_3': 1.7722588277828236e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 175, 'n_units_Layer_3': 245}. Best is trial 749 with value: 4.303453489042528.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:24:18,439]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:24:21,730]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:24:22,532]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:24:32,905]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:24:37,098]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:24:39,919]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:24:43,466]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:24:49,495]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:24:53,973]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:24:54,463]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:25:01,065]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:25:06,578]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:25:11,214]\u001b[0m Trial 780 finished with value: 4.702241986743565 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011963969780203415, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3090321283795744, 'dropout_rate_Layer_2': 0.2973096752931993, 'dropout_rate_Layer_3': 0.10805720582235652, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.9764046833998885e-05, 'l1_Layer_2': 2.203761749328091e-05, 'l1_Layer_3': 7.857146397766153e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 125, 'n_units_Layer_3': 190}. Best is trial 749 with value: 4.303453489042528.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.70 | sMAPE for Validation Set is: 11.56% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.12 | sMAPE for Test Set is: 13.38% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:25:17,910]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:25:22,074]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:25:27,325]\u001b[0m Trial 772 finished with value: 4.764120823730969 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005158594971669091, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2405351480174498, 'dropout_rate_Layer_2': 0.1315081423974604, 'dropout_rate_Layer_3': 0.09266239109179376, 'dropout_rate_Layer_4': 0.2557687444526303, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0053319398592243245, 'l1_Layer_2': 0.023169971613177638, 'l1_Layer_3': 1.1912155047021871e-05, 'l1_Layer_4': 0.0001731149859066244, 'n_units_Layer_1': 95, 'n_units_Layer_2': 110, 'n_units_Layer_3': 80, 'n_units_Layer_4': 155}. Best is trial 749 with value: 4.303453489042528.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.76 | sMAPE for Validation Set is: 11.82% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 5.45 | sMAPE for Test Set is: 12.08% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:25:29,745]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:25:35,575]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:25:37,846]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:25:39,979]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:25:45,456]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:25:48,481]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:25:52,962]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:25:53,689]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:25:59,694]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:26:02,727]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:26:09,582]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:26:09,824]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:26:12,519]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:26:22,101]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:26:22,610]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:26:31,624]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:26:31,795]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:26:32,264]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:26:40,476]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.31 | sMAPE for Validation Set is: 10.71% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.99 | sMAPE for Test Set is: 11.19% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:26:43,054]\u001b[0m Trial 784 finished with value: 4.309247189624793 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018832606194521553, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03630452462972514, 'dropout_rate_Layer_2': 0.3386426869793224, 'dropout_rate_Layer_3': 0.021519432632938942, 'dropout_rate_Layer_4': 0.06664751253530043, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.004837776556927493, 'l1_Layer_2': 0.0014477666144298406, 'l1_Layer_3': 0.0026951068511176157, 'l1_Layer_4': 0.004689960485554498, 'n_units_Layer_1': 155, 'n_units_Layer_2': 205, 'n_units_Layer_3': 50, 'n_units_Layer_4': 125}. Best is trial 749 with value: 4.303453489042528.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:26:46,649]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:26:59,002]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:27:05,476]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:27:05,979]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:27:12,247]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:27:15,203]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:27:15,275]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:27:21,138]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:27:29,238]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:27:32,788]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:27:35,279]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:27:39,798]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:27:41,784]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:27:46,405]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:28:07,390]\u001b[0m Trial 823 finished with value: 4.586254873082625 and parameters: {'n_hidden': 3, 'learning_rate': 0.001540343941640475, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2550072085708848, 'dropout_rate_Layer_2': 0.2811498008210238, 'dropout_rate_Layer_3': 0.10999116750197963, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.8577719189451766e-05, 'l1_Layer_2': 5.184204650325521e-05, 'l1_Layer_3': 0.000276015476482791, 'n_units_Layer_1': 195, 'n_units_Layer_2': 160, 'n_units_Layer_3': 180}. Best is trial 749 with value: 4.303453489042528.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.59 | sMAPE for Validation Set is: 11.41% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.91 | sMAPE for Test Set is: 12.97% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:28:11,614]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:28:16,280]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:28:22,097]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:28:26,909]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:28:30,870]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:28:35,370]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:28:42,170]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:28:42,519]\u001b[0m Trial 813 finished with value: 4.2740021060343345 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011537175158817124, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13590506517861684, 'dropout_rate_Layer_2': 0.1708070384931034, 'dropout_rate_Layer_3': 0.06259553037204967, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004212477306486734, 'l1_Layer_2': 2.049879302218985e-05, 'l1_Layer_3': 1.892882696453427e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 180, 'n_units_Layer_3': 245}. Best is trial 813 with value: 4.2740021060343345.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.27 | sMAPE for Validation Set is: 10.59% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.19 | sMAPE for Test Set is: 11.58% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:28:47,823]\u001b[0m Trial 822 finished with value: 4.306879427592848 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011984337618933447, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.131008318231587, 'dropout_rate_Layer_2': 0.16167447297149082, 'dropout_rate_Layer_3': 0.06541975474698355, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00052588472771153, 'l1_Layer_2': 6.74539808468198e-05, 'l1_Layer_3': 0.0033711087648501193, 'n_units_Layer_1': 145, 'n_units_Layer_2': 135, 'n_units_Layer_3': 235}. Best is trial 813 with value: 4.2740021060343345.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.31 | sMAPE for Validation Set is: 10.62% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.78 | sMAPE for Test Set is: 10.70% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:28:49,153]\u001b[0m Trial 819 finished with value: 4.399746541786016 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010792030677588954, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1331933414111062, 'dropout_rate_Layer_2': 0.16750909081324947, 'dropout_rate_Layer_3': 0.06309647265612967, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004693931115017596, 'l1_Layer_2': 8.02357983882547e-05, 'l1_Layer_3': 1.84217448365808e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 180, 'n_units_Layer_3': 245}. Best is trial 813 with value: 4.2740021060343345.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.40 | sMAPE for Validation Set is: 10.83% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.30 | sMAPE for Test Set is: 11.76% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:28:57,965]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:29:07,312]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:29:07,704]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:29:16,600]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:29:17,194]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:29:25,586]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:29:30,076]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:29:34,565]\u001b[0m Trial 833 finished with value: 4.469165897120754 and parameters: {'n_hidden': 4, 'learning_rate': 0.003290047222692507, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07396657210547829, 'dropout_rate_Layer_2': 0.3148323168442288, 'dropout_rate_Layer_3': 0.04852329922738402, 'dropout_rate_Layer_4': 0.10235523220473411, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.006536189824887068, 'l1_Layer_2': 4.719496500360373e-05, 'l1_Layer_3': 0.0008897353468924077, 'l1_Layer_4': 0.0035101250347214295, 'n_units_Layer_1': 250, 'n_units_Layer_2': 190, 'n_units_Layer_3': 50, 'n_units_Layer_4': 170}. Best is trial 813 with value: 4.2740021060343345.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.47 | sMAPE for Validation Set is: 11.17% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.42 | sMAPE for Test Set is: 12.14% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:29:34,749]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:29:42,238]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:29:48,841]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:29:49,018]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:29:49,615]\u001b[0m Trial 831 finished with value: 4.379450448287488 and parameters: {'n_hidden': 3, 'learning_rate': 0.001159988132369957, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13279216570038654, 'dropout_rate_Layer_2': 0.1951306139048625, 'dropout_rate_Layer_3': 0.06193583160116714, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00048246176332362084, 'l1_Layer_2': 7.162731877304938e-05, 'l1_Layer_3': 1.7443243500680023e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 175, 'n_units_Layer_3': 245}. Best is trial 813 with value: 4.2740021060343345.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.38 | sMAPE for Validation Set is: 11.09% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.38 | sMAPE for Test Set is: 12.11% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:29:59,449]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:29:59,632]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:30:00,066]\u001b[0m Trial 839 finished with value: 4.592255158224585 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008651310503260316, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32900376803011616, 'dropout_rate_Layer_2': 0.22513390122398558, 'dropout_rate_Layer_3': 0.04940847884882317, 'dropout_rate_Layer_4': 0.1573918771797842, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.013654129626240536, 'l1_Layer_2': 0.004010867301383699, 'l1_Layer_3': 2.4651006662458144e-05, 'l1_Layer_4': 5.338236810995181e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 80, 'n_units_Layer_3': 135, 'n_units_Layer_4': 210}. Best is trial 813 with value: 4.2740021060343345.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.59 | sMAPE for Validation Set is: 11.36% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.19 | sMAPE for Test Set is: 11.46% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:30:08,053]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:30:11,412]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:30:15,008]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:30:19,543]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:30:20,179]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:30:30,174]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:30:38,485]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:30:44,334]\u001b[0m Trial 855 finished with value: 4.404377683296771 and parameters: {'n_hidden': 4, 'learning_rate': 0.0035345501396058547, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.051320405249098075, 'dropout_rate_Layer_2': 0.3052920937558942, 'dropout_rate_Layer_3': 0.03164720667957284, 'dropout_rate_Layer_4': 0.0771447129319055, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.007626925965259719, 'l1_Layer_2': 2.7238527821230793e-05, 'l1_Layer_3': 0.0006820930824758073, 'l1_Layer_4': 2.5855649844137325e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 210, 'n_units_Layer_3': 55, 'n_units_Layer_4': 130}. Best is trial 813 with value: 4.2740021060343345.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.40 | sMAPE for Validation Set is: 11.13% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.36 | sMAPE for Test Set is: 12.06% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:30:47,485]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:30:51,388]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:30:52,612]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:30:58,650]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:30:59,219]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:31:02,529]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:31:11,182]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:31:16,152]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:31:18,550]\u001b[0m Trial 859 finished with value: 4.6276134987694375 and parameters: {'n_hidden': 4, 'learning_rate': 0.002242180036145267, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04706717080293986, 'dropout_rate_Layer_2': 0.3111280947542988, 'dropout_rate_Layer_3': 0.032046842616562, 'dropout_rate_Layer_4': 0.08955860493561223, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.011867439511218162, 'l1_Layer_2': 2.9163646364606676e-05, 'l1_Layer_3': 0.0013150159234621153, 'l1_Layer_4': 2.475580725850247e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 210, 'n_units_Layer_3': 55, 'n_units_Layer_4': 140}. Best is trial 813 with value: 4.2740021060343345.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.63 | sMAPE for Validation Set is: 11.27% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.15 | sMAPE for Test Set is: 11.54% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:31:23,664]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:31:26,557]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:31:30,749]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:31:35,652]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:31:38,204]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:31:41,955]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:31:44,884]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:31:45,098]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:31:50,235]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:31:54,807]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:31:56,565]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:32:00,072]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:32:07,471]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:32:10,510]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:32:15,965]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:32:16,645]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:32:23,260]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:32:24,007]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:32:32,714]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:32:42,206]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:32:42,584]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:32:50,397]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:32:54,288]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:32:54,497]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:33:02,635]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:33:05,331]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:33:07,529]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:33:11,124]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:33:11,713]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:33:13,232]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:33:17,927]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:33:20,725]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:33:23,507]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:33:33,471]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:33:41,552]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:33:42,138]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:33:47,788]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:33:52,988]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:33:59,604]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:34:05,357]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:34:06,150]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:34:11,686]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:34:12,819]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:34:24,272]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:34:28,768]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:34:46,260]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:34:49,939]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:34:52,136]\u001b[0m Trial 899 finished with value: 4.269356305328384 and parameters: {'n_hidden': 4, 'learning_rate': 0.0024385442505285176, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03677940317656145, 'dropout_rate_Layer_2': 0.3236445744643182, 'dropout_rate_Layer_3': 0.007792170903407013, 'dropout_rate_Layer_4': 0.09255003635979703, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00951688227462704, 'l1_Layer_2': 2.8931122955248774e-05, 'l1_Layer_3': 0.0008772074793703072, 'l1_Layer_4': 0.007477089808451596, 'n_units_Layer_1': 260, 'n_units_Layer_2': 190, 'n_units_Layer_3': 245, 'n_units_Layer_4': 130}. Best is trial 899 with value: 4.269356305328384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.27 | sMAPE for Validation Set is: 10.58% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.95 | sMAPE for Test Set is: 11.08% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:35:00,655]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:35:07,638]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:35:12,062]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:35:24,069]\u001b[0m Trial 913 finished with value: 4.4255233724734415 and parameters: {'n_hidden': 4, 'learning_rate': 0.0022001665294969263, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07591312021017532, 'dropout_rate_Layer_2': 0.33057942029071197, 'dropout_rate_Layer_3': 0.06482921456878817, 'dropout_rate_Layer_4': 0.1272724254921371, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.008634501426357721, 'l1_Layer_2': 2.251987073590045e-05, 'l1_Layer_3': 0.00032661575798499523, 'l1_Layer_4': 2.8011624592270455e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 215, 'n_units_Layer_3': 65, 'n_units_Layer_4': 130}. Best is trial 899 with value: 4.269356305328384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.43 | sMAPE for Validation Set is: 11.17% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.58 | sMAPE for Test Set is: 12.54% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:35:31,350]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:35:38,260]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:35:51,960]\u001b[0m Trial 904 finished with value: 4.624235363708084 and parameters: {'n_hidden': 3, 'learning_rate': 0.002276746913417239, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20753200719641537, 'dropout_rate_Layer_2': 0.16087928902188195, 'dropout_rate_Layer_3': 0.08905203128796504, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003724995206028979, 'l1_Layer_2': 2.483894378966386e-05, 'l1_Layer_3': 1.3764431858809954e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 135, 'n_units_Layer_3': 235}. Best is trial 899 with value: 4.269356305328384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.62 | sMAPE for Validation Set is: 11.55% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.44 | sMAPE for Test Set is: 12.19% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:36:01,946]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:36:28,827]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:36:37,448]\u001b[0m Trial 916 finished with value: 5.114512454002707 and parameters: {'n_hidden': 4, 'learning_rate': 0.0062633395097196854, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2820531438180355, 'dropout_rate_Layer_2': 0.3471851094205641, 'dropout_rate_Layer_3': 0.2993335187439512, 'dropout_rate_Layer_4': 0.3813156364327911, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.17308548261336e-05, 'l1_Layer_2': 0.03731630555737558, 'l1_Layer_3': 0.005184308040347876, 'l1_Layer_4': 0.00012904398385392413, 'n_units_Layer_1': 150, 'n_units_Layer_2': 100, 'n_units_Layer_3': 75, 'n_units_Layer_4': 90}. Best is trial 899 with value: 4.269356305328384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.11 | sMAPE for Validation Set is: 12.30% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 5.61 | sMAPE for Test Set is: 12.32% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:36:41,408]\u001b[0m Trial 922 finished with value: 4.511910759923178 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015201822166942278, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02471401974103271, 'dropout_rate_Layer_2': 0.32878960893083264, 'dropout_rate_Layer_3': 0.06770602895240921, 'dropout_rate_Layer_4': 0.06251466207085755, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.008410561609967905, 'l1_Layer_2': 2.208414162128964e-05, 'l1_Layer_3': 0.0002419716371077076, 'l1_Layer_4': 0.006231653074132682, 'n_units_Layer_1': 255, 'n_units_Layer_2': 215, 'n_units_Layer_3': 65, 'n_units_Layer_4': 140}. Best is trial 899 with value: 4.269356305328384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.51 | sMAPE for Validation Set is: 11.14% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.09 | sMAPE for Test Set is: 11.35% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:36:45,118]\u001b[0m Trial 923 finished with value: 4.818989288216419 and parameters: {'n_hidden': 3, 'learning_rate': 0.00382930422839654, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10603767854937156, 'dropout_rate_Layer_2': 0.22538737058559083, 'dropout_rate_Layer_3': 0.12553142839589482, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.695605816487719e-05, 'l1_Layer_2': 0.000317591012731821, 'l1_Layer_3': 0.007777585698309573, 'n_units_Layer_1': 130, 'n_units_Layer_2': 105, 'n_units_Layer_3': 215}. Best is trial 899 with value: 4.269356305328384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.82 | sMAPE for Validation Set is: 11.92% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 5.16 | sMAPE for Test Set is: 11.39% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:36:47,249]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:36:47,680]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:36:55,299]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:36:55,598]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:36:55,865]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:37:05,071]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:37:10,034]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:37:10,217]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:37:11,899]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:37:20,325]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:37:21,016]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:37:28,200]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:37:28,448]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:37:29,350]\u001b[0m Trial 926 finished with value: 4.668151729772877 and parameters: {'n_hidden': 4, 'learning_rate': 0.0021157564932429186, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.030181607463632486, 'dropout_rate_Layer_2': 0.30152226943721894, 'dropout_rate_Layer_3': 0.07009155197777905, 'dropout_rate_Layer_4': 0.057016634545329334, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.009304209486260961, 'l1_Layer_2': 2.128679245353199e-05, 'l1_Layer_3': 0.00019010633386343077, 'l1_Layer_4': 0.007274231149288073, 'n_units_Layer_1': 255, 'n_units_Layer_2': 220, 'n_units_Layer_3': 65, 'n_units_Layer_4': 135}. Best is trial 899 with value: 4.269356305328384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.67 | sMAPE for Validation Set is: 11.76% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.42 | sMAPE for Test Set is: 12.29% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:37:38,489]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:37:43,153]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:37:53,471]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:38:09,202]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:38:09,287]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:38:16,273]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:38:16,745]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:38:19,788]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:38:25,737]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:38:26,637]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:38:31,023]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:38:34,172]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:38:36,973]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:38:40,092]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:38:43,110]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:38:45,587]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:38:46,134]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:38:48,138]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:38:53,791]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:38:54,551]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:38:55,209]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:39:01,586]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:39:05,788]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:39:12,509]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:39:26,949]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:39:31,278]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:39:41,502]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:39:50,962]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:39:59,269]\u001b[0m Trial 944 finished with value: 4.374422112681124 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007738157637303799, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16653132850710078, 'dropout_rate_Layer_2': 0.19033427821291748, 'dropout_rate_Layer_3': 0.022957834710585566, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00022640346731610548, 'l1_Layer_2': 0.00018181517792075584, 'l1_Layer_3': 0.00013195482145403345, 'n_units_Layer_1': 115, 'n_units_Layer_2': 175, 'n_units_Layer_3': 275}. Best is trial 899 with value: 4.269356305328384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.37 | sMAPE for Validation Set is: 10.86% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.81 | sMAPE for Test Set is: 12.69% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:40:02,736]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:40:09,435]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:40:10,078]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:40:17,433]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:40:36,421]\u001b[0m Trial 965 finished with value: 4.413946737008832 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014131732749731282, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22448749605473467, 'dropout_rate_Layer_2': 0.18861773695610043, 'dropout_rate_Layer_3': 0.018370197976638587, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00017432788422051137, 'l1_Layer_2': 0.00010362267563184896, 'l1_Layer_3': 0.0001457261086807353, 'n_units_Layer_1': 115, 'n_units_Layer_2': 175, 'n_units_Layer_3': 275}. Best is trial 899 with value: 4.269356305328384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.41 | sMAPE for Validation Set is: 11.11% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.79 | sMAPE for Test Set is: 12.97% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:40:41,182]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:40:49,652]\u001b[0m Trial 974 finished with value: 4.678023421680018 and parameters: {'n_hidden': 3, 'learning_rate': 0.001508111982367225, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34488775377699815, 'dropout_rate_Layer_2': 0.11870668327622155, 'dropout_rate_Layer_3': 0.11110329389181439, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0024696292695151937, 'l1_Layer_2': 0.005980655612741362, 'l1_Layer_3': 2.0322227595524505e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 115, 'n_units_Layer_3': 145}. Best is trial 899 with value: 4.269356305328384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.68 | sMAPE for Validation Set is: 11.29% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.28 | sMAPE for Test Set is: 11.65% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:40:52,422]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:40:57,028]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:41:02,104]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:41:02,387]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:41:09,540]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:41:14,423]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:41:19,406]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:41:24,040]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:41:39,056]\u001b[0m Trial 967 finished with value: 4.341316649802792 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007736215098993347, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2255369198077886, 'dropout_rate_Layer_2': 0.1882215749890774, 'dropout_rate_Layer_3': 0.028840123912105217, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007416654780209607, 'l1_Layer_2': 9.865870461906766e-05, 'l1_Layer_3': 6.539625120466956e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 175, 'n_units_Layer_3': 275}. Best is trial 899 with value: 4.269356305328384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.34 | sMAPE for Validation Set is: 10.76% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.90 | sMAPE for Test Set is: 12.61% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:42:00,342]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:42:14,120]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:42:21,257]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:42:27,105]\u001b[0m Trial 981 finished with value: 4.3712002788842055 and parameters: {'n_hidden': 3, 'learning_rate': 0.000746251971356936, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16116259131402771, 'dropout_rate_Layer_2': 0.27717578777231744, 'dropout_rate_Layer_3': 0.021580877339344294, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006903984945565257, 'l1_Layer_2': 0.00018114230086831276, 'l1_Layer_3': 1.0068847567209451e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 200, 'n_units_Layer_3': 265}. Best is trial 899 with value: 4.269356305328384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.37 | sMAPE for Validation Set is: 10.99% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.78 | sMAPE for Test Set is: 12.81% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:42:33,747]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:42:40,765]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:42:41,048]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:42:49,736]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:42:51,287]\u001b[0m Trial 980 finished with value: 4.359400380350358 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008167106713293605, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1625675016160673, 'dropout_rate_Layer_2': 0.19357297951707728, 'dropout_rate_Layer_3': 0.024243228323344163, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00023365398762295825, 'l1_Layer_2': 0.00018214813886549392, 'l1_Layer_3': 6.21794056947912e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 205, 'n_units_Layer_3': 265}. Best is trial 899 with value: 4.269356305328384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.36 | sMAPE for Validation Set is: 10.80% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.11 | sMAPE for Test Set is: 13.51% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:42:53,449]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:43:00,286]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:43:03,828]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:43:04,495]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:43:09,438]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:43:13,417]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:43:13,569]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:43:20,211]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:43:25,250]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:43:27,181]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:43:33,002]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:43:39,599]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:43:40,386]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:43:40,537]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:43:42,620]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:44:00,676]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:44:05,426]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:44:12,390]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:44:12,844]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:44:20,884]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:44:37,516]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:44:41,441]\u001b[0m Trial 1007 finished with value: 4.396168857548712 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007123081464742935, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18997628245447762, 'dropout_rate_Layer_2': 0.27415309952627437, 'dropout_rate_Layer_3': 0.005579310045315949, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008075909774939659, 'l1_Layer_2': 0.00029744788661014484, 'l1_Layer_3': 3.195106120468209e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 200, 'n_units_Layer_3': 260}. Best is trial 899 with value: 4.269356305328384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.40 | sMAPE for Validation Set is: 11.08% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.34 | sMAPE for Test Set is: 11.67% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:44:45,835]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:44:49,204]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:45:00,130]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.47 | sMAPE for Validation Set is: 11.21% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.93 | sMAPE for Test Set is: 13.02% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:45:01,983]\u001b[0m Trial 1008 finished with value: 4.472379209702241 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007031393137746796, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18971367452641905, 'dropout_rate_Layer_2': 0.2716488664892225, 'dropout_rate_Layer_3': 0.0036492656613543555, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007578503393617667, 'l1_Layer_2': 0.00015924083333074856, 'l1_Layer_3': 3.444970421261846e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 200, 'n_units_Layer_3': 260}. Best is trial 899 with value: 4.269356305328384.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:45:07,504]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:45:15,293]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:45:17,862]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:45:21,494]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:45:25,419]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:45:29,843]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:45:42,970]\u001b[0m Trial 1014 finished with value: 4.384515112525258 and parameters: {'n_hidden': 4, 'learning_rate': 0.0027229513226233477, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05325500477558605, 'dropout_rate_Layer_2': 0.25804166390613936, 'dropout_rate_Layer_3': 0.07446180145910401, 'dropout_rate_Layer_4': 0.07363186558484532, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.006960225604252095, 'l1_Layer_2': 4.1927241698803834e-05, 'l1_Layer_3': 0.0029027979426103118, 'l1_Layer_4': 3.128614067775111e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 195, 'n_units_Layer_3': 245, 'n_units_Layer_4': 130}. Best is trial 899 with value: 4.269356305328384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.38 | sMAPE for Validation Set is: 10.84% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.61 | sMAPE for Test Set is: 12.43% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:45:55,616]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:46:00,448]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:46:00,891]\u001b[0m Trial 1027 finished with value: 4.5014370403254285 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018770245485387421, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20332538687843696, 'dropout_rate_Layer_2': 0.1464546619385999, 'dropout_rate_Layer_3': 0.02990628519521494, 'dropout_rate_Layer_4': 0.11067822605711886, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0076033504221892975, 'l1_Layer_2': 1.969327112815107e-05, 'l1_Layer_3': 0.0026378304085231913, 'l1_Layer_4': 2.3471847458467424e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 210, 'n_units_Layer_3': 240, 'n_units_Layer_4': 115}. Best is trial 899 with value: 4.269356305328384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.50 | sMAPE for Validation Set is: 11.19% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.22 | sMAPE for Test Set is: 11.78% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:46:02,712]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:46:11,921]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:46:15,910]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:46:19,367]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:46:21,369]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:46:22,165]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:46:26,356]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:46:37,038]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:46:40,295]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:46:44,366]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:46:48,390]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:46:48,552]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:46:55,918]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:46:58,857]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:47:03,910]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:47:08,702]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:47:12,020]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:47:16,043]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:47:19,024]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:47:24,143]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:47:24,276]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:47:25,084]\u001b[0m Trial 1039 finished with value: 4.651157314826213 and parameters: {'n_hidden': 4, 'learning_rate': 0.002509675238103623, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19043238176769478, 'dropout_rate_Layer_2': 0.31990804128894706, 'dropout_rate_Layer_3': 0.08372367774749237, 'dropout_rate_Layer_4': 0.08353457827979587, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0053158426672760585, 'l1_Layer_2': 5.064680900538579e-05, 'l1_Layer_3': 0.0021097746356474804, 'l1_Layer_4': 1.7770794779267658e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 210, 'n_units_Layer_3': 250, 'n_units_Layer_4': 115}. Best is trial 899 with value: 4.269356305328384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.65 | sMAPE for Validation Set is: 11.61% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.75 | sMAPE for Test Set is: 12.91% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:47:38,293]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:47:38,591]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:47:47,626]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:47:51,750]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:47:56,757]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:48:04,778]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:48:13,077]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:48:17,236]\u001b[0m Trial 1051 finished with value: 4.567229049374493 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011279348978752409, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18092471183223213, 'dropout_rate_Layer_2': 0.10705757397625251, 'dropout_rate_Layer_3': 0.0660991851888988, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005043798057867339, 'l1_Layer_2': 0.018894758597466435, 'l1_Layer_3': 3.60901438733161e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 90, 'n_units_Layer_3': 200}. Best is trial 899 with value: 4.269356305328384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.57 | sMAPE for Validation Set is: 11.14% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.21 | sMAPE for Test Set is: 11.63% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:48:21,780]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:48:26,808]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:48:33,721]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:48:37,808]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:48:41,953]\u001b[0m Trial 1056 finished with value: 4.572825676950885 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011756375436502461, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18167951467774868, 'dropout_rate_Layer_2': 0.04838404405653869, 'dropout_rate_Layer_3': 0.22698525719275103, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00234036180922958, 'l1_Layer_2': 0.016993088558223575, 'l1_Layer_3': 4.114384911982926e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 70, 'n_units_Layer_3': 210}. Best is trial 899 with value: 4.269356305328384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.57 | sMAPE for Validation Set is: 11.23% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.08 | sMAPE for Test Set is: 11.28% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:48:42,557]\u001b[0m Trial 1060 finished with value: 4.7026427991740976 and parameters: {'n_hidden': 4, 'learning_rate': 0.002489840762212444, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2080215601531653, 'dropout_rate_Layer_2': 0.04898485926549935, 'dropout_rate_Layer_3': 0.08519682011872512, 'dropout_rate_Layer_4': 0.0799384019603354, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.006362541924383313, 'l1_Layer_2': 3.952748518177124e-05, 'l1_Layer_3': 0.0021539253280209625, 'l1_Layer_4': 0.0021769359144043978, 'n_units_Layer_1': 195, 'n_units_Layer_2': 215, 'n_units_Layer_3': 245, 'n_units_Layer_4': 120}. Best is trial 899 with value: 4.269356305328384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.70 | sMAPE for Validation Set is: 11.51% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.27 | sMAPE for Test Set is: 11.75% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:48:54,339]\u001b[0m Trial 1059 finished with value: 4.480553993082135 and parameters: {'n_hidden': 3, 'learning_rate': 0.002508857223172519, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04141629899918626, 'dropout_rate_Layer_2': 0.04558279949602201, 'dropout_rate_Layer_3': 0.08544891782775975, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006682808417270019, 'l1_Layer_2': 3.816309977395402e-05, 'l1_Layer_3': 0.002160988711547149, 'n_units_Layer_1': 180, 'n_units_Layer_2': 215, 'n_units_Layer_3': 245}. Best is trial 899 with value: 4.269356305328384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.48 | sMAPE for Validation Set is: 11.20% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.13 | sMAPE for Test Set is: 11.60% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:48:57,949]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:48:58,096]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:48:58,611]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:49:01,874]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:49:10,711]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:49:16,026]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:49:25,449]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:49:28,067]\u001b[0m Trial 1073 finished with value: 4.665210132292529 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019266779059610632, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.315659915859343, 'dropout_rate_Layer_2': 0.3206623484611141, 'dropout_rate_Layer_3': 0.14230372791433568, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.7325665054471817e-05, 'l1_Layer_2': 7.924080838048775e-05, 'l1_Layer_3': 0.0012152713934714223, 'n_units_Layer_1': 255, 'n_units_Layer_2': 120, 'n_units_Layer_3': 195}. Best is trial 899 with value: 4.269356305328384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.67 | sMAPE for Validation Set is: 11.46% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.95 | sMAPE for Test Set is: 12.90% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:49:32,425]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:49:35,671]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:49:38,554]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:49:42,432]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:49:47,205]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:49:51,158]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:49:58,632]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:49:59,140]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:50:02,314]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:50:14,849]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:50:15,207]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:50:18,701]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:50:24,591]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:50:24,850]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:50:25,193]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:50:34,909]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:50:40,645]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:50:43,710]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:50:51,133]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:50:51,708]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:50:54,683]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:51:04,087]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:51:04,193]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:51:04,364]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:51:09,665]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:51:16,964]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:51:19,987]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:51:27,033]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:51:27,762]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:51:34,810]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:51:34,920]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:51:41,019]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:51:47,077]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:51:53,458]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:52:00,716]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:52:01,558]\u001b[0m Trial 1098 finished with value: 4.315989321809908 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016604625812867212, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.047114947303421306, 'dropout_rate_Layer_2': 0.009766296908696168, 'dropout_rate_Layer_3': 0.07685125159420805, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007446177997263556, 'l1_Layer_2': 2.449231293759614e-05, 'l1_Layer_3': 0.0009440188536547658, 'n_units_Layer_1': 185, 'n_units_Layer_2': 205, 'n_units_Layer_3': 245}. Best is trial 899 with value: 4.269356305328384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.32 | sMAPE for Validation Set is: 10.75% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.89 | sMAPE for Test Set is: 11.01% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:52:07,608]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:52:09,935]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:52:10,675]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:52:14,573]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:52:21,571]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:52:25,648]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:52:28,932]\u001b[0m Trial 1108 finished with value: 4.713904856987284 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016567159021526152, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24585919187350674, 'dropout_rate_Layer_2': 0.15436936716536168, 'dropout_rate_Layer_3': 0.11810959794059347, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.027563331917626763, 'l1_Layer_2': 0.006885861740952252, 'l1_Layer_3': 9.958785710499861e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 105, 'n_units_Layer_3': 65}. Best is trial 899 with value: 4.269356305328384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.71 | sMAPE for Validation Set is: 11.60% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.22 | sMAPE for Test Set is: 11.64% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:52:32,286]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:52:37,459]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:52:43,792]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:52:45,697]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:52:50,980]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:52:51,863]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:53:02,946]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:53:06,642]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:53:07,824]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:53:13,690]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:53:14,223]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:53:21,824]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:53:25,935]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:53:27,233]\u001b[0m Trial 1117 finished with value: 4.26330745002189 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018523403574238677, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04635961111819567, 'dropout_rate_Layer_2': 0.03969430077655349, 'dropout_rate_Layer_3': 0.0838068397383583, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003777501068016998, 'l1_Layer_2': 3.046848363231151e-05, 'l1_Layer_3': 0.0008434623297289577, 'n_units_Layer_1': 170, 'n_units_Layer_2': 200, 'n_units_Layer_3': 235}. Best is trial 1117 with value: 4.26330745002189.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.26 | sMAPE for Validation Set is: 10.68% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.20 | sMAPE for Test Set is: 11.70% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:53:34,581]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:53:37,226]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:53:43,312]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:53:46,968]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:53:55,234]\u001b[0m Trial 1129 finished with value: 4.359187027888591 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018031749024100554, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07600215365554566, 'dropout_rate_Layer_2': 0.017084097943274715, 'dropout_rate_Layer_3': 0.07412325374557245, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007592803338372527, 'l1_Layer_2': 2.4649557885728188e-05, 'l1_Layer_3': 0.0016572024586848882, 'n_units_Layer_1': 165, 'n_units_Layer_2': 215, 'n_units_Layer_3': 50}. Best is trial 1117 with value: 4.26330745002189.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.36 | sMAPE for Validation Set is: 10.72% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.52 | sMAPE for Test Set is: 12.14% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:53:59,135]\u001b[0m Trial 1131 finished with value: 5.719162908293015 and parameters: {'n_hidden': 3, 'learning_rate': 0.009576272664190826, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34409912711470836, 'dropout_rate_Layer_2': 0.10901734878692934, 'dropout_rate_Layer_3': 0.030437768193388056, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009574385304250298, 'l1_Layer_2': 0.05111239528616263, 'l1_Layer_3': 0.002853884629683, 'n_units_Layer_1': 180, 'n_units_Layer_2': 70, 'n_units_Layer_3': 95}. Best is trial 1117 with value: 4.26330745002189.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.72 | sMAPE for Validation Set is: 13.28% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 6.13 | sMAPE for Test Set is: 13.21% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:54:00,263]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:54:05,849]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:54:13,170]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:54:21,608]\u001b[0m Trial 1136 finished with value: 4.297303856471398 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015577272764493786, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04742328331133384, 'dropout_rate_Layer_2': 0.02247075977542852, 'dropout_rate_Layer_3': 0.0719738647961225, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003256002220049387, 'l1_Layer_2': 2.552364550457049e-05, 'l1_Layer_3': 0.0006619367144224647, 'n_units_Layer_1': 170, 'n_units_Layer_2': 220, 'n_units_Layer_3': 50}. Best is trial 1117 with value: 4.26330745002189.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.30 | sMAPE for Validation Set is: 10.54% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.09 | sMAPE for Test Set is: 11.39% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:54:22,064]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:54:27,856]\u001b[0m Trial 1140 finished with value: 4.328978628068886 and parameters: {'n_hidden': 3, 'learning_rate': 0.001818950266506251, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.050581027969239245, 'dropout_rate_Layer_2': 0.036861553701158775, 'dropout_rate_Layer_3': 0.0688639045453456, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005004005288298073, 'l1_Layer_2': 1.8503868296335232e-05, 'l1_Layer_3': 0.0008475684152477313, 'n_units_Layer_1': 170, 'n_units_Layer_2': 210, 'n_units_Layer_3': 55}. Best is trial 1117 with value: 4.26330745002189.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.33 | sMAPE for Validation Set is: 10.60% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.14 | sMAPE for Test Set is: 11.53% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:54:28,462]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:54:37,679]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:54:43,095]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:54:47,746]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:55:18,466]\u001b[0m Trial 1149 finished with value: 4.311381657105808 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013899427318241485, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.045993992758353204, 'dropout_rate_Layer_2': 0.018606716340264486, 'dropout_rate_Layer_3': 0.06799196633427557, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004707977060938867, 'l1_Layer_2': 2.4193524037823867e-05, 'l1_Layer_3': 0.0006749885906577842, 'n_units_Layer_1': 165, 'n_units_Layer_2': 200, 'n_units_Layer_3': 55}. Best is trial 1117 with value: 4.26330745002189.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.31 | sMAPE for Validation Set is: 10.61% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.78 | sMAPE for Test Set is: 10.76% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:55:23,167]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:55:28,136]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:55:34,666]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:55:40,423]\u001b[0m Trial 1148 finished with value: 4.2971957832164165 and parameters: {'n_hidden': 3, 'learning_rate': 0.001381563471311127, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05703257919658072, 'dropout_rate_Layer_2': 0.02424659487673994, 'dropout_rate_Layer_3': 0.0648954205819557, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0040321252190717695, 'l1_Layer_2': 2.5017746411907452e-05, 'l1_Layer_3': 0.000572165199352959, 'n_units_Layer_1': 165, 'n_units_Layer_2': 195, 'n_units_Layer_3': 55}. Best is trial 1117 with value: 4.26330745002189.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.30 | sMAPE for Validation Set is: 10.78% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.27 | sMAPE for Test Set is: 11.78% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:55:43,750]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:55:46,734]\u001b[0m Trial 1145 finished with value: 4.473712215325908 and parameters: {'n_hidden': 3, 'learning_rate': 0.000500749612745796, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16755479972420745, 'dropout_rate_Layer_2': 0.20153954902548066, 'dropout_rate_Layer_3': 0.0197261422957829, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00017575684715398637, 'l1_Layer_2': 0.00015143636636439606, 'l1_Layer_3': 0.00011087422022575381, 'n_units_Layer_1': 115, 'n_units_Layer_2': 150, 'n_units_Layer_3': 280}. Best is trial 1117 with value: 4.26330745002189.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.47 | sMAPE for Validation Set is: 11.25% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.69 | sMAPE for Test Set is: 12.53% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:55:50,411]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:55:52,680]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:55:57,022]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:55:57,564]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:56:04,512]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:56:04,760]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:56:13,133]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:56:20,267]\u001b[0m Trial 1137 finished with value: 4.33519582525312 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008294480504671377, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17242159224858242, 'dropout_rate_Layer_2': 0.1793822860914919, 'dropout_rate_Layer_3': 0.022347614195457798, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001582094799318806, 'l1_Layer_2': 0.0006491787258449055, 'l1_Layer_3': 0.00012305837741807363, 'n_units_Layer_1': 100, 'n_units_Layer_2': 150, 'n_units_Layer_3': 280}. Best is trial 1117 with value: 4.26330745002189.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.34 | sMAPE for Validation Set is: 10.74% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.68 | sMAPE for Test Set is: 12.24% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:56:26,415]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:56:30,272]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:56:39,988]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:56:48,302]\u001b[0m Trial 1156 finished with value: 4.321885368269027 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013576638120318567, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.044901875377439955, 'dropout_rate_Layer_2': 0.01881548456663343, 'dropout_rate_Layer_3': 0.06865104856642729, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00280030546126592, 'l1_Layer_2': 2.264583926979286e-05, 'l1_Layer_3': 0.0007064032302011904, 'n_units_Layer_1': 165, 'n_units_Layer_2': 190, 'n_units_Layer_3': 50}. Best is trial 1117 with value: 4.26330745002189.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.32 | sMAPE for Validation Set is: 10.66% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.92 | sMAPE for Test Set is: 11.00% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:56:52,923]\u001b[0m Trial 1163 finished with value: 4.28248451035338 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011487489598269315, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05953590349590021, 'dropout_rate_Layer_2': 0.022575923581537483, 'dropout_rate_Layer_3': 0.06894233991642464, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0034162176019363988, 'l1_Layer_2': 1.4367887614260351e-05, 'l1_Layer_3': 0.00047132177029294756, 'n_units_Layer_1': 160, 'n_units_Layer_2': 195, 'n_units_Layer_3': 55}. Best is trial 1117 with value: 4.26330745002189.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:56:52,977]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.28 | sMAPE for Validation Set is: 10.60% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.93 | sMAPE for Test Set is: 11.15% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:56:59,869]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:57:00,062]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:57:07,819]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:57:12,910]\u001b[0m Trial 1167 finished with value: 4.3408171766829895 and parameters: {'n_hidden': 3, 'learning_rate': 0.001436386388275878, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05713157120534869, 'dropout_rate_Layer_2': 0.026342961346659248, 'dropout_rate_Layer_3': 0.06892689667392776, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003364008406757636, 'l1_Layer_2': 1.7833750913447705e-05, 'l1_Layer_3': 0.0005220738817413557, 'n_units_Layer_1': 160, 'n_units_Layer_2': 195, 'n_units_Layer_3': 55}. Best is trial 1117 with value: 4.26330745002189.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.34 | sMAPE for Validation Set is: 10.72% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.87 | sMAPE for Test Set is: 10.96% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:57:13,231]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:57:19,756]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:57:19,885]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:57:25,440]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:57:49,646]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:57:54,563]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:57:59,475]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:58:06,749]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:58:11,847]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:58:16,775]\u001b[0m Trial 1178 finished with value: 4.314467848763564 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015561570234974684, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.051123471053182205, 'dropout_rate_Layer_2': 0.03821345571837575, 'dropout_rate_Layer_3': 0.07976376932405539, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002843138730702505, 'l1_Layer_2': 1.3225558157281658e-05, 'l1_Layer_3': 0.0005697733807042456, 'n_units_Layer_1': 160, 'n_units_Layer_2': 195, 'n_units_Layer_3': 50}. Best is trial 1117 with value: 4.26330745002189.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.31 | sMAPE for Validation Set is: 10.75% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.93 | sMAPE for Test Set is: 11.13% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:58:40,763]\u001b[0m Trial 1172 finished with value: 4.929415202407198 and parameters: {'n_hidden': 4, 'learning_rate': 0.005861058889347407, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2676995505626995, 'dropout_rate_Layer_2': 0.17277214129247379, 'dropout_rate_Layer_3': 0.2561714857797187, 'dropout_rate_Layer_4': 0.2101580811967308, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00011816547226292865, 'l1_Layer_2': 0.02876475468568958, 'l1_Layer_3': 1.3356269485974553e-05, 'l1_Layer_4': 7.787167355513238e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 190, 'n_units_Layer_3': 50, 'n_units_Layer_4': 85}. Best is trial 1117 with value: 4.26330745002189.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.93 | sMAPE for Validation Set is: 12.00% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 6.21 | sMAPE for Test Set is: 13.51% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:58:47,883]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:58:51,284]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:58:56,174]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:59:01,006]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:59:07,827]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:59:08,267]\u001b[0m Trial 1183 finished with value: 4.250506714518066 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011714548965335077, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04409240359385302, 'dropout_rate_Layer_2': 0.0183174930083203, 'dropout_rate_Layer_3': 0.0678766647101778, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002811628878868367, 'l1_Layer_2': 1.470867598703687e-05, 'l1_Layer_3': 0.0005262219320289092, 'n_units_Layer_1': 165, 'n_units_Layer_2': 185, 'n_units_Layer_3': 55}. Best is trial 1183 with value: 4.250506714518066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.25 | sMAPE for Validation Set is: 10.56% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.17 | sMAPE for Test Set is: 11.52% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:59:19,231]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:59:21,797]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:59:28,957]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:59:42,148]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:59:48,487]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:59:56,234]\u001b[0m Trial 1187 finished with value: 4.260685257649732 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008226501043992408, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04618568495613863, 'dropout_rate_Layer_2': 0.002372980493713938, 'dropout_rate_Layer_3': 0.062332625559250475, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0022286437768571903, 'l1_Layer_2': 1.429387110755977e-05, 'l1_Layer_3': 0.0004413712073022198, 'n_units_Layer_1': 170, 'n_units_Layer_2': 185, 'n_units_Layer_3': 50}. Best is trial 1183 with value: 4.250506714518066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.26 | sMAPE for Validation Set is: 10.57% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.07 | sMAPE for Test Set is: 11.39% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:00:05,445]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:00:10,541]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:00:16,999]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:00:23,642]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:00:44,419]\u001b[0m Trial 1170 finished with value: 4.299262356633803 and parameters: {'n_hidden': 3, 'learning_rate': 0.000645949734781673, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1188956751263977, 'dropout_rate_Layer_2': 0.11107188653349694, 'dropout_rate_Layer_3': 0.07970584131299704, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011182689874594389, 'l1_Layer_2': 0.0007529791177638534, 'l1_Layer_3': 0.0005007274564095888, 'n_units_Layer_1': 100, 'n_units_Layer_2': 130, 'n_units_Layer_3': 255}. Best is trial 1183 with value: 4.250506714518066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.30 | sMAPE for Validation Set is: 10.70% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.48 | sMAPE for Test Set is: 12.13% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:00:54,031]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:01:25,217]\u001b[0m Trial 1201 finished with value: 4.218588302783682 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007367584042567088, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04929107931445149, 'dropout_rate_Layer_2': 0.002975798738588775, 'dropout_rate_Layer_3': 0.05817778690909122, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016292426656395176, 'l1_Layer_2': 1.5253921069285405e-05, 'l1_Layer_3': 0.0005444367111425506, 'n_units_Layer_1': 150, 'n_units_Layer_2': 175, 'n_units_Layer_3': 50}. Best is trial 1201 with value: 4.218588302783682.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.22 | sMAPE for Validation Set is: 10.34% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.83 | sMAPE for Test Set is: 10.82% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:01:27,817]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:01:28,876]\u001b[0m Trial 1197 finished with value: 4.179802120695345 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006210377372645942, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04988704396856388, 'dropout_rate_Layer_2': 0.0017911766684285488, 'dropout_rate_Layer_3': 0.05887447093869227, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014568624284683309, 'l1_Layer_2': 1.1844934066513628e-05, 'l1_Layer_3': 0.0005049617275805617, 'n_units_Layer_1': 155, 'n_units_Layer_2': 180, 'n_units_Layer_3': 50}. Best is trial 1197 with value: 4.179802120695345.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.18 | sMAPE for Validation Set is: 10.30% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.05 | sMAPE for Test Set is: 11.28% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:01:50,492]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:01:50,659]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:01:59,145]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:02:03,354]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:02:10,018]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:02:22,058]\u001b[0m Trial 1204 finished with value: 4.172875820125282 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006359404058316307, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05054650153443645, 'dropout_rate_Layer_2': 0.0018560478304573864, 'dropout_rate_Layer_3': 0.058668478156463665, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0017518996143148426, 'l1_Layer_2': 1.2051963147722759e-05, 'l1_Layer_3': 0.0005086222675832502, 'n_units_Layer_1': 145, 'n_units_Layer_2': 175, 'n_units_Layer_3': 50}. Best is trial 1204 with value: 4.172875820125282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.17 | sMAPE for Validation Set is: 10.32% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.01 | sMAPE for Test Set is: 11.24% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:02:25,482]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:02:29,814]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:02:33,936]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:02:56,426]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:03:01,968]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:03:07,398]\u001b[0m Trial 1209 finished with value: 4.1964087443112 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005350683709074443, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05235727805569278, 'dropout_rate_Layer_2': 0.0008472428743620354, 'dropout_rate_Layer_3': 0.05841006808267756, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012728510279193688, 'l1_Layer_2': 1.2274270691558806e-05, 'l1_Layer_3': 0.000538595730559755, 'n_units_Layer_1': 145, 'n_units_Layer_2': 165, 'n_units_Layer_3': 50}. Best is trial 1204 with value: 4.172875820125282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.20 | sMAPE for Validation Set is: 10.27% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.92 | sMAPE for Test Set is: 11.05% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:03:08,083]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:03:21,488]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:03:34,558]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:04:13,612]\u001b[0m Trial 1192 finished with value: 4.328697993426792 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006418847694985492, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11934778132796504, 'dropout_rate_Layer_2': 0.23212825604709628, 'dropout_rate_Layer_3': 0.08260310431390633, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001011576288344952, 'l1_Layer_2': 0.00037110629549630023, 'l1_Layer_3': 0.00021799550190608585, 'n_units_Layer_1': 100, 'n_units_Layer_2': 120, 'n_units_Layer_3': 255}. Best is trial 1204 with value: 4.172875820125282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.33 | sMAPE for Validation Set is: 10.99% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.82 | sMAPE for Test Set is: 12.75% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:04:20,718]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:04:25,640]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:04:26,000]\u001b[0m Trial 1221 finished with value: 4.274930331009948 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005981173876732426, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.051101760450186294, 'dropout_rate_Layer_2': 0.002076136165374314, 'dropout_rate_Layer_3': 0.059141613532314376, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014190878935905332, 'l1_Layer_2': 1.1803459978890362e-05, 'l1_Layer_3': 0.0004020120482140747, 'n_units_Layer_1': 150, 'n_units_Layer_2': 170, 'n_units_Layer_3': 55}. Best is trial 1204 with value: 4.172875820125282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.27 | sMAPE for Validation Set is: 10.59% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.49 | sMAPE for Test Set is: 12.25% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:04:36,209]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:04:40,567]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:04:45,947]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:04:49,111]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:04:49,557]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:04:54,309]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:04:59,622]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:05:02,981]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:05:07,843]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:05:15,582]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:05:21,039]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:05:28,940]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:05:35,194]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:05:39,366]\u001b[0m Trial 1220 finished with value: 5.230391482982777 and parameters: {'n_hidden': 4, 'learning_rate': 0.008520048927544823, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2518109148155617, 'dropout_rate_Layer_2': 0.30037173340507917, 'dropout_rate_Layer_3': 0.11637681022329834, 'dropout_rate_Layer_4': 0.33239425171444936, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.1262949748739215e-05, 'l1_Layer_2': 0.030033008661033624, 'l1_Layer_3': 0.035721752315134525, 'l1_Layer_4': 0.0001118847222762289, 'n_units_Layer_1': 105, 'n_units_Layer_2': 75, 'n_units_Layer_3': 60, 'n_units_Layer_4': 175}. Best is trial 1204 with value: 4.172875820125282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.23 | sMAPE for Validation Set is: 12.88% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 6.08 | sMAPE for Test Set is: 13.47% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:05:48,944]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:05:49,848]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:05:59,822]\u001b[0m Trial 1230 finished with value: 6.323360396514835 and parameters: {'n_hidden': 3, 'learning_rate': 0.01597782135590592, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2231063485276939, 'dropout_rate_Layer_2': 0.09870724365456858, 'dropout_rate_Layer_3': 0.1492414935719545, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003398472833319983, 'l1_Layer_2': 0.03101029428143388, 'l1_Layer_3': 2.6691772296398317e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 265, 'n_units_Layer_3': 90}. Best is trial 1204 with value: 4.172875820125282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.32 | sMAPE for Validation Set is: 14.45% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 7.92 | sMAPE for Test Set is: 16.69% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:06:08,015]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:06:12,005]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:06:16,291]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:06:20,234]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:06:20,481]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:06:24,503]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:06:30,824]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:06:31,279]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:06:35,020]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:06:38,893]\u001b[0m Trial 1240 finished with value: 4.195973422878059 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007787753818933399, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05888623752925559, 'dropout_rate_Layer_2': 0.0010866389717905762, 'dropout_rate_Layer_3': 0.06118346732684562, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011460638960535002, 'l1_Layer_2': 1.3609598541561769e-05, 'l1_Layer_3': 0.0004316275501955438, 'n_units_Layer_1': 140, 'n_units_Layer_2': 175, 'n_units_Layer_3': 60}. Best is trial 1204 with value: 4.172875820125282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.20 | sMAPE for Validation Set is: 10.51% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.48 | sMAPE for Test Set is: 12.31% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:06:41,503]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:06:46,595]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:06:47,590]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:06:55,376]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:06:55,884]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:06:58,760]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:07:07,350]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:07:08,131]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:07:13,857]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:07:27,418]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:07:34,303]\u001b[0m Trial 1253 finished with value: 4.093521075168802 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007477235183840368, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06171684223244542, 'dropout_rate_Layer_2': 0.00996936840277244, 'dropout_rate_Layer_3': 0.0569167956955836, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001443761128346654, 'l1_Layer_2': 1.1651442752196104e-05, 'l1_Layer_3': 0.0004490866562074712, 'n_units_Layer_1': 135, 'n_units_Layer_2': 160, 'n_units_Layer_3': 55}. Best is trial 1253 with value: 4.093521075168802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.09 | sMAPE for Validation Set is: 10.16% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.04 | sMAPE for Test Set is: 11.34% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:07:40,731]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:07:46,247]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:07:50,607]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:07:54,284]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:08:04,224]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:08:20,312]\u001b[0m Trial 1256 finished with value: 4.177362490042184 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007497762197023613, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06249529297012198, 'dropout_rate_Layer_2': 0.008530299593820755, 'dropout_rate_Layer_3': 0.059131500954665656, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001434338468061818, 'l1_Layer_2': 1.0025349720987961e-05, 'l1_Layer_3': 0.00039711641047820854, 'n_units_Layer_1': 145, 'n_units_Layer_2': 160, 'n_units_Layer_3': 55}. Best is trial 1253 with value: 4.093521075168802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.18 | sMAPE for Validation Set is: 10.28% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.09 | sMAPE for Test Set is: 11.33% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:08:26,163]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:08:33,092]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:08:36,527]\u001b[0m Trial 1262 finished with value: 4.14360384033379 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008108776458999984, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.044650793550891944, 'dropout_rate_Layer_2': 0.0005613028178587647, 'dropout_rate_Layer_3': 0.0590830816016915, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001260819637621014, 'l1_Layer_2': 1.4637962911743507e-05, 'l1_Layer_3': 0.0005758926119047896, 'n_units_Layer_1': 150, 'n_units_Layer_2': 170, 'n_units_Layer_3': 50}. Best is trial 1253 with value: 4.093521075168802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.14 | sMAPE for Validation Set is: 10.39% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.16 | sMAPE for Test Set is: 11.54% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:08:48,973]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:09:24,091]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:10:06,370]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:10:06,576]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:10:11,975]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:10:13,213]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:10:20,159]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:10:25,364]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:10:25,676]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:10:28,048]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:10:36,707]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:10:44,016]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:10:51,775]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:10:54,975]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:10:58,697]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:11:06,039]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:11:29,568]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:11:35,357]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:11:43,651]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:11:46,982]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:11:51,113]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:12:01,462]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:12:26,122]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:12:29,878]\u001b[0m Trial 1281 finished with value: 5.002964150403909 and parameters: {'n_hidden': 4, 'learning_rate': 0.005683299712319829, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2553064014979043, 'dropout_rate_Layer_2': 0.3523968249975197, 'dropout_rate_Layer_3': 0.1792260267616208, 'dropout_rate_Layer_4': 0.24474476088033043, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.0371974369360297e-05, 'l1_Layer_2': 0.00010665483431877429, 'l1_Layer_3': 1.0017952064472616e-05, 'l1_Layer_4': 9.926707711614424e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 95, 'n_units_Layer_3': 70, 'n_units_Layer_4': 170}. Best is trial 1253 with value: 4.093521075168802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.00 | sMAPE for Validation Set is: 12.03% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 6.50 | sMAPE for Test Set is: 13.48% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:12:35,242]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:12:44,647]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:12:49,097]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:12:56,105]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:13:00,795]\u001b[0m Trial 1294 finished with value: 4.221695220927731 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005184155142358282, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04527525838532693, 'dropout_rate_Layer_2': 0.021416563444294774, 'dropout_rate_Layer_3': 0.060189816999441294, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001403701452156416, 'l1_Layer_2': 1.2229641975482435e-05, 'l1_Layer_3': 0.0004499493271634516, 'n_units_Layer_1': 155, 'n_units_Layer_2': 160, 'n_units_Layer_3': 50}. Best is trial 1253 with value: 4.093521075168802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.22 | sMAPE for Validation Set is: 10.51% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.96 | sMAPE for Test Set is: 11.21% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:13:02,667]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:13:07,972]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:13:12,504]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:13:12,644]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:13:20,377]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:13:27,104]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:13:30,308]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:13:34,021]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:13:57,688]\u001b[0m Trial 1309 finished with value: 8.372489628960523 and parameters: {'n_hidden': 4, 'learning_rate': 0.03540045661215144, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28194606442133585, 'dropout_rate_Layer_2': 0.03661030241370414, 'dropout_rate_Layer_3': 0.03467057014581912, 'dropout_rate_Layer_4': 0.20374623461246183, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.891675068644034e-05, 'l1_Layer_2': 0.05477893366335396, 'l1_Layer_3': 1.859346847530877e-05, 'l1_Layer_4': 4.8818346919883567e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 130, 'n_units_Layer_3': 125, 'n_units_Layer_4': 105}. Best is trial 1253 with value: 4.093521075168802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.37 | sMAPE for Validation Set is: 19.27% | rMAE for Validation Set is: 1.20\n",
      "MAE for Test Set is: 9.18 | sMAPE for Test Set is: 19.18% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:14:06,393]\u001b[0m Trial 1278 finished with value: 4.406377906590645 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009882254604432804, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09512418622456839, 'dropout_rate_Layer_2': 0.2380319454077733, 'dropout_rate_Layer_3': 0.1116743895003588, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010418288164885443, 'l1_Layer_2': 0.0007114418436886028, 'l1_Layer_3': 0.00030529232479459853, 'n_units_Layer_1': 100, 'n_units_Layer_2': 100, 'n_units_Layer_3': 220}. Best is trial 1253 with value: 4.093521075168802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.41 | sMAPE for Validation Set is: 11.06% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.44 | sMAPE for Test Set is: 12.21% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:14:14,940]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:14:21,302]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:15:52,333]\u001b[0m Trial 1313 finished with value: 5.081914298749726 and parameters: {'n_hidden': 4, 'learning_rate': 0.008238781317366661, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26679875469573683, 'dropout_rate_Layer_2': 0.362444994088507, 'dropout_rate_Layer_3': 0.15010161045475795, 'dropout_rate_Layer_4': 0.2166952227031381, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.6211592533363735e-05, 'l1_Layer_2': 4.189489640045099e-05, 'l1_Layer_3': 1.0059425740586992e-05, 'l1_Layer_4': 2.31801767515778e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 245, 'n_units_Layer_3': 165, 'n_units_Layer_4': 175}. Best is trial 1253 with value: 4.093521075168802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.08 | sMAPE for Validation Set is: 12.09% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 5.87 | sMAPE for Test Set is: 12.73% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:15:59,802]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:16:14,876]\u001b[0m Trial 1308 finished with value: 4.491530205994789 and parameters: {'n_hidden': 3, 'learning_rate': 0.002027956258531251, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12126102394194815, 'dropout_rate_Layer_2': 0.23193311358604077, 'dropout_rate_Layer_3': 0.10952840735690123, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012113198307162201, 'l1_Layer_2': 0.0006945308730262568, 'l1_Layer_3': 0.00024262957447735822, 'n_units_Layer_1': 100, 'n_units_Layer_2': 95, 'n_units_Layer_3': 220}. Best is trial 1253 with value: 4.093521075168802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.49 | sMAPE for Validation Set is: 11.16% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.35 | sMAPE for Test Set is: 11.86% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:16:21,481]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:16:27,932]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:16:37,429]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:16:47,223]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:16:53,221]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:17:06,732]\u001b[0m Trial 1310 finished with value: 4.255910253955443 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006314483212500803, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09986727835409231, 'dropout_rate_Layer_2': 0.17484642178786294, 'dropout_rate_Layer_3': 0.1059799558677217, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.28060469862544e-05, 'l1_Layer_2': 0.0006841129340577914, 'l1_Layer_3': 0.0006795717433842111, 'n_units_Layer_1': 105, 'n_units_Layer_2': 95, 'n_units_Layer_3': 220}. Best is trial 1253 with value: 4.093521075168802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.26 | sMAPE for Validation Set is: 10.84% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.48 | sMAPE for Test Set is: 12.22% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:17:14,585]\u001b[0m Trial 1315 finished with value: 4.110698166870316 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005752702075222974, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04832555721695726, 'dropout_rate_Layer_2': 0.010798069029163722, 'dropout_rate_Layer_3': 0.06534125652135277, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014441639210651706, 'l1_Layer_2': 1.1869433580662502e-05, 'l1_Layer_3': 0.000559484378089198, 'n_units_Layer_1': 155, 'n_units_Layer_2': 175, 'n_units_Layer_3': 55}. Best is trial 1253 with value: 4.093521075168802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.11 | sMAPE for Validation Set is: 10.19% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.95 | sMAPE for Test Set is: 11.09% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:17:27,387]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:17:34,716]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:17:35,550]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:17:38,492]\u001b[0m Trial 1301 finished with value: 4.282073803385321 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006373054941678042, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12184363228854721, 'dropout_rate_Layer_2': 0.22524686028965585, 'dropout_rate_Layer_3': 0.10715373439624332, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.659724562796377e-05, 'l1_Layer_2': 0.0007150061763741228, 'l1_Layer_3': 0.00026346497618846755, 'n_units_Layer_1': 100, 'n_units_Layer_2': 90, 'n_units_Layer_3': 225}. Best is trial 1253 with value: 4.093521075168802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.28 | sMAPE for Validation Set is: 10.68% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.13 | sMAPE for Test Set is: 11.41% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:17:57,496]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:17:58,168]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:17:58,313]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:18:09,143]\u001b[0m Trial 1322 finished with value: 4.486856569271514 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008914039000058972, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21379826950680839, 'dropout_rate_Layer_2': 0.09185356698050268, 'dropout_rate_Layer_3': 0.0017222535387571014, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.460132368583458e-05, 'l1_Layer_2': 0.013414052555390195, 'l1_Layer_3': 4.366854347356077e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 85, 'n_units_Layer_3': 60}. Best is trial 1253 with value: 4.093521075168802.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:18:09,321]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.49 | sMAPE for Validation Set is: 11.20% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.13 | sMAPE for Test Set is: 11.48% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:18:09,961]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:18:18,733]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:18:25,682]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:18:26,179]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:18:28,331]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:18:36,812]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:18:44,476]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:18:46,498]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:18:58,350]\u001b[0m Trial 1328 finished with value: 4.137605753175818 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007007515240423493, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03284612348905728, 'dropout_rate_Layer_2': 0.016932169272023515, 'dropout_rate_Layer_3': 0.05936811719263248, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011491216144113433, 'l1_Layer_2': 1.1904520030110668e-05, 'l1_Layer_3': 0.0005969797603937399, 'n_units_Layer_1': 140, 'n_units_Layer_2': 160, 'n_units_Layer_3': 50}. Best is trial 1253 with value: 4.093521075168802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.14 | sMAPE for Validation Set is: 10.25% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.11 | sMAPE for Test Set is: 11.39% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:19:05,574]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:19:13,943]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:19:24,319]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:19:24,681]\u001b[0m Trial 1335 finished with value: 4.443412607901589 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009188969004417399, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2591378877990642, 'dropout_rate_Layer_2': 0.11570441870547932, 'dropout_rate_Layer_3': 0.014602747101529145, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.5291562232122802e-05, 'l1_Layer_2': 0.00636660153388747, 'l1_Layer_3': 1.519432428674292e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 85, 'n_units_Layer_3': 60}. Best is trial 1253 with value: 4.093521075168802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.44 | sMAPE for Validation Set is: 10.98% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.06 | sMAPE for Test Set is: 11.32% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:19:40,254]\u001b[0m Trial 1339 finished with value: 4.15652748464428 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007284753409023494, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03337615167053194, 'dropout_rate_Layer_2': 0.017087604334867532, 'dropout_rate_Layer_3': 0.05083690057170767, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010769109745161962, 'l1_Layer_2': 1.1863566810453556e-05, 'l1_Layer_3': 0.00038324960464341525, 'n_units_Layer_1': 140, 'n_units_Layer_2': 145, 'n_units_Layer_3': 50}. Best is trial 1253 with value: 4.093521075168802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.16 | sMAPE for Validation Set is: 10.15% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.99 | sMAPE for Test Set is: 11.09% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:19:43,050]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:19:48,823]\u001b[0m Trial 1340 finished with value: 4.398516830381291 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009056121999136232, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25900734789725555, 'dropout_rate_Layer_2': 0.12072608766348061, 'dropout_rate_Layer_3': 0.02203507332838857, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.991550281134126e-05, 'l1_Layer_2': 0.007374474841400579, 'l1_Layer_3': 1.7224699959333245e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 85, 'n_units_Layer_3': 65}. Best is trial 1253 with value: 4.093521075168802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.40 | sMAPE for Validation Set is: 11.05% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.02 | sMAPE for Test Set is: 11.19% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:19:55,665]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:19:57,797]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:20:03,033]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:20:08,598]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:20:14,836]\u001b[0m Trial 1345 finished with value: 4.194436235365699 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007151424716801541, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.029213836340573146, 'dropout_rate_Layer_2': 0.01709863752054478, 'dropout_rate_Layer_3': 0.05149615613639978, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010925804445961387, 'l1_Layer_2': 1.0103164611117409e-05, 'l1_Layer_3': 0.0003541766832423447, 'n_units_Layer_1': 140, 'n_units_Layer_2': 160, 'n_units_Layer_3': 50}. Best is trial 1253 with value: 4.093521075168802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.19 | sMAPE for Validation Set is: 10.39% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.10 | sMAPE for Test Set is: 11.49% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:20:19,457]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:20:23,601]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:20:27,336]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:20:31,488]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:20:39,316]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:20:42,332]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:20:48,056]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:20:52,305]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:20:54,809]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:21:03,111]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:21:10,262]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:21:14,641]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:21:21,688]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:21:28,933]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:21:39,834]\u001b[0m Trial 1361 finished with value: 4.116169967251783 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006183509899472208, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.030562892165703195, 'dropout_rate_Layer_2': 0.00045842096916770244, 'dropout_rate_Layer_3': 0.046635764593740234, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001089632872921423, 'l1_Layer_2': 1.023367379175786e-05, 'l1_Layer_3': 0.0003027103779344563, 'n_units_Layer_1': 130, 'n_units_Layer_2': 160, 'n_units_Layer_3': 60}. Best is trial 1253 with value: 4.093521075168802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.12 | sMAPE for Validation Set is: 10.13% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.13 | sMAPE for Test Set is: 11.38% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:21:45,364]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:21:48,083]\u001b[0m Trial 1360 finished with value: 4.149629417744429 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006203554595858348, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.029272726707058515, 'dropout_rate_Layer_2': 0.0005092121728650096, 'dropout_rate_Layer_3': 0.04864606486871928, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008134297548492909, 'l1_Layer_2': 1.176770872703499e-05, 'l1_Layer_3': 0.0003151645940309132, 'n_units_Layer_1': 130, 'n_units_Layer_2': 160, 'n_units_Layer_3': 60}. Best is trial 1253 with value: 4.093521075168802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.15 | sMAPE for Validation Set is: 10.31% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.36 | sMAPE for Test Set is: 11.98% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:21:51,346]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:21:54,906]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:21:59,882]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:22:09,217]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:22:14,034]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:22:16,780]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:22:22,376]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:22:26,734]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:22:45,670]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:22:50,788]\u001b[0m Trial 1371 finished with value: 4.2140505539149995 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007188974918814604, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.018860197254844176, 'dropout_rate_Layer_2': 0.0069406605064263535, 'dropout_rate_Layer_3': 0.05589304982962929, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000555858151228368, 'l1_Layer_2': 1.1582540019734994e-05, 'l1_Layer_3': 0.00037864729842463035, 'n_units_Layer_1': 125, 'n_units_Layer_2': 160, 'n_units_Layer_3': 60}. Best is trial 1253 with value: 4.093521075168802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.21 | sMAPE for Validation Set is: 10.38% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.15 | sMAPE for Test Set is: 11.51% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:22:56,103]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:23:02,398]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:23:08,049]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:23:11,344]\u001b[0m Trial 1367 finished with value: 4.105778387094564 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005061216257188263, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03362740976716795, 'dropout_rate_Layer_2': 4.839838613474121e-05, 'dropout_rate_Layer_3': 0.05690842761926123, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010439723573928796, 'l1_Layer_2': 1.0035028980113602e-05, 'l1_Layer_3': 0.0004494645489790449, 'n_units_Layer_1': 140, 'n_units_Layer_2': 165, 'n_units_Layer_3': 50}. Best is trial 1253 with value: 4.093521075168802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.11 | sMAPE for Validation Set is: 10.26% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.27 | sMAPE for Test Set is: 11.77% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:23:28,604]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:23:32,058]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:23:42,651]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:23:48,480]\u001b[0m Trial 1383 finished with value: 4.112577604514926 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007386693240743012, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01982423571068386, 'dropout_rate_Layer_2': 0.0009173883486502804, 'dropout_rate_Layer_3': 0.05504517734712083, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006141558333117406, 'l1_Layer_2': 1.1554269864005298e-05, 'l1_Layer_3': 0.0002619300560240756, 'n_units_Layer_1': 125, 'n_units_Layer_2': 160, 'n_units_Layer_3': 70}. Best is trial 1253 with value: 4.093521075168802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.11 | sMAPE for Validation Set is: 10.16% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.95 | sMAPE for Test Set is: 11.05% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:24:06,318]\u001b[0m Trial 1386 finished with value: 4.545147618834533 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012389199876066033, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2606032521225796, 'dropout_rate_Layer_2': 0.20215611039751252, 'dropout_rate_Layer_3': 0.04855782024164383, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.405226150300819e-05, 'l1_Layer_2': 0.005585170563880682, 'l1_Layer_3': 4.0104099893034505e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 115, 'n_units_Layer_3': 80}. Best is trial 1253 with value: 4.093521075168802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.55 | sMAPE for Validation Set is: 11.33% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.41 | sMAPE for Test Set is: 12.10% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:24:13,546]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:24:19,598]\u001b[0m Trial 1385 finished with value: 4.200537184705503 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005514704008684758, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007573607393265319, 'dropout_rate_Layer_2': 0.00169750955239527, 'dropout_rate_Layer_3': 0.057099443476623116, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004054730065479547, 'l1_Layer_2': 1.007172439324792e-05, 'l1_Layer_3': 0.0002727739480954387, 'n_units_Layer_1': 130, 'n_units_Layer_2': 155, 'n_units_Layer_3': 70}. Best is trial 1253 with value: 4.093521075168802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.20 | sMAPE for Validation Set is: 10.50% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.57 | sMAPE for Test Set is: 12.43% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:24:22,031]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:24:23,508]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:24:23,901]\u001b[0m Trial 1388 finished with value: 4.520960217632173 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009901844978458072, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2580039957546764, 'dropout_rate_Layer_2': 0.20154070628287457, 'dropout_rate_Layer_3': 0.001002644207377678, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.13785019505574e-05, 'l1_Layer_2': 0.005798173176451216, 'l1_Layer_3': 3.437827574059053e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 160, 'n_units_Layer_3': 85}. Best is trial 1253 with value: 4.093521075168802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.52 | sMAPE for Validation Set is: 11.22% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.15 | sMAPE for Test Set is: 11.53% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:24:39,186]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:24:46,871]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:24:53,469]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:24:56,543]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:25:02,108]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:25:05,274]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:25:11,288]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:25:14,117]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:25:19,074]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:25:26,744]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:25:27,502]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:25:33,873]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:25:38,746]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:25:46,156]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:25:50,842]\u001b[0m Trial 1391 finished with value: 4.916870603534764 and parameters: {'n_hidden': 4, 'learning_rate': 0.012235130006132714, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1458476882762693, 'dropout_rate_Layer_2': 0.016036862678808085, 'dropout_rate_Layer_3': 0.20793441255047437, 'dropout_rate_Layer_4': 0.1905640308451726, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 8.05289899241782e-05, 'l1_Layer_2': 0.025694782020413667, 'l1_Layer_3': 1.8638058492418886e-05, 'l1_Layer_4': 0.0006322627373186019, 'n_units_Layer_1': 60, 'n_units_Layer_2': 50, 'n_units_Layer_3': 185, 'n_units_Layer_4': 250}. Best is trial 1253 with value: 4.093521075168802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.92 | sMAPE for Validation Set is: 12.08% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 5.62 | sMAPE for Test Set is: 12.26% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:25:53,799]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:25:59,813]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:26:05,271]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:26:08,516]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:26:13,716]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:26:26,391]\u001b[0m Trial 1405 finished with value: 4.446090193212144 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008734315610962628, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3291824685542175, 'dropout_rate_Layer_2': 0.20882175960971075, 'dropout_rate_Layer_3': 0.18033373517442883, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.010745482582066e-05, 'l1_Layer_2': 0.00010336428494983912, 'l1_Layer_3': 0.015818131259330497, 'n_units_Layer_1': 200, 'n_units_Layer_2': 145, 'n_units_Layer_3': 165}. Best is trial 1253 with value: 4.093521075168802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.45 | sMAPE for Validation Set is: 10.92% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.71 | sMAPE for Test Set is: 12.61% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:26:34,257]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:26:49,975]\u001b[0m Trial 1414 finished with value: 4.115903993594136 and parameters: {'n_hidden': 3, 'learning_rate': 0.000505515439798372, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.012835026176577738, 'dropout_rate_Layer_2': 0.008985399231038516, 'dropout_rate_Layer_3': 0.05533632808759257, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003489966504538543, 'l1_Layer_2': 1.0123205528361543e-05, 'l1_Layer_3': 0.0002961680113571175, 'n_units_Layer_1': 120, 'n_units_Layer_2': 145, 'n_units_Layer_3': 65}. Best is trial 1253 with value: 4.093521075168802.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:26:50,132]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.12 | sMAPE for Validation Set is: 10.17% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.13 | sMAPE for Test Set is: 11.48% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:27:00,334]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:27:01,840]\u001b[0m Trial 1413 finished with value: 4.19170643767831 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008471328301523348, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015228283084534368, 'dropout_rate_Layer_2': 0.0001535944429349787, 'dropout_rate_Layer_3': 0.04242571466502901, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010811807065410487, 'l1_Layer_2': 1.2331461165549403e-05, 'l1_Layer_3': 0.00030083215098313367, 'n_units_Layer_1': 120, 'n_units_Layer_2': 150, 'n_units_Layer_3': 70}. Best is trial 1253 with value: 4.093521075168802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.19 | sMAPE for Validation Set is: 10.38% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.36 | sMAPE for Test Set is: 11.93% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:27:09,785]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:27:12,705]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:27:19,373]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:27:26,217]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:27:33,705]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:27:53,091]\u001b[0m Trial 1423 finished with value: 4.102716730142661 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008239959849292534, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.013160533104387015, 'dropout_rate_Layer_2': 0.009522788309386665, 'dropout_rate_Layer_3': 0.043432619889941, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002929637400040398, 'l1_Layer_2': 1.2017547900132543e-05, 'l1_Layer_3': 0.00028580532265569836, 'n_units_Layer_1': 120, 'n_units_Layer_2': 145, 'n_units_Layer_3': 70}. Best is trial 1253 with value: 4.093521075168802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.10 | sMAPE for Validation Set is: 10.10% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.16 | sMAPE for Test Set is: 11.48% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:27:57,600]\u001b[0m Trial 1424 finished with value: 4.2041530618587695 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005065849175661545, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.002238840222982921, 'dropout_rate_Layer_2': 0.009538504298745998, 'dropout_rate_Layer_3': 0.042226023991931524, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003512908146858973, 'l1_Layer_2': 1.2200118700167442e-05, 'l1_Layer_3': 0.0002879675277014311, 'n_units_Layer_1': 120, 'n_units_Layer_2': 145, 'n_units_Layer_3': 70}. Best is trial 1253 with value: 4.093521075168802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.20 | sMAPE for Validation Set is: 10.53% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.32 | sMAPE for Test Set is: 11.91% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:28:01,544]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:28:05,796]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:28:09,368]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:28:15,980]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:28:21,394]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:28:26,767]\u001b[0m Trial 1396 finished with value: 4.3990330962362245 and parameters: {'n_hidden': 3, 'learning_rate': 0.000640175442565371, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14614883078922777, 'dropout_rate_Layer_2': 0.2092151460163928, 'dropout_rate_Layer_3': 0.13308883752418155, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.692541007093676e-05, 'l1_Layer_2': 0.0013185542548832343, 'l1_Layer_3': 0.001106341609532769, 'n_units_Layer_1': 100, 'n_units_Layer_2': 110, 'n_units_Layer_3': 255}. Best is trial 1253 with value: 4.093521075168802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.40 | sMAPE for Validation Set is: 11.20% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.58 | sMAPE for Test Set is: 12.58% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:28:27,240]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:28:33,985]\u001b[0m Trial 1426 finished with value: 4.141909678639425 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007064137054200948, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.000593116897525418, 'dropout_rate_Layer_2': 0.010298775838945026, 'dropout_rate_Layer_3': 0.04280493825023518, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00037741683832830846, 'l1_Layer_2': 1.0000884798748594e-05, 'l1_Layer_3': 0.0003028086514351371, 'n_units_Layer_1': 120, 'n_units_Layer_2': 145, 'n_units_Layer_3': 75}. Best is trial 1253 with value: 4.093521075168802.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.14 | sMAPE for Validation Set is: 10.31% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.46 | sMAPE for Test Set is: 12.14% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:28:35,324]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:28:44,823]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:28:45,777]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:29:02,427]\u001b[0m Trial 1429 finished with value: 4.088840244127163 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007017286586837491, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0013461947517463806, 'dropout_rate_Layer_2': 0.0001981304353267486, 'dropout_rate_Layer_3': 0.043595190059279997, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00042139004999721953, 'l1_Layer_2': 1.2752438117341377e-05, 'l1_Layer_3': 0.0002655955266408982, 'n_units_Layer_1': 130, 'n_units_Layer_2': 145, 'n_units_Layer_3': 75}. Best is trial 1429 with value: 4.088840244127163.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.09 | sMAPE for Validation Set is: 10.21% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.96 | sMAPE for Test Set is: 11.10% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:29:18,652]\u001b[0m Trial 1434 finished with value: 4.154938806395291 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006875641185188646, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0019059335857298573, 'dropout_rate_Layer_2': 0.01286295487616212, 'dropout_rate_Layer_3': 0.04266204917950579, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003836929880199279, 'l1_Layer_2': 1.2556510637364154e-05, 'l1_Layer_3': 0.00025914311692819665, 'n_units_Layer_1': 125, 'n_units_Layer_2': 145, 'n_units_Layer_3': 75}. Best is trial 1429 with value: 4.088840244127163.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.15 | sMAPE for Validation Set is: 10.43% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.01 | sMAPE for Test Set is: 11.21% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:29:24,321]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:29:36,188]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:29:52,677]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:29:56,825]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:30:01,589]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:30:06,463]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:30:09,741]\u001b[0m Trial 1439 finished with value: 5.347048024869276 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006842401695409563, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22144039873032229, 'dropout_rate_Layer_2': 0.12083410232528037, 'dropout_rate_Layer_3': 0.0416958158175022, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.7525211385063908e-05, 'l1_Layer_2': 0.009385395922849775, 'l1_Layer_3': 1.4818768211219218e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 190, 'n_units_Layer_3': 105}. Best is trial 1429 with value: 4.088840244127163.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.35 | sMAPE for Validation Set is: 12.66% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 5.69 | sMAPE for Test Set is: 12.53% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:30:13,753]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:30:18,101]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:30:18,193]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:30:20,664]\u001b[0m Trial 1438 finished with value: 4.26535085315145 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006400967085640955, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11909953440797354, 'dropout_rate_Layer_2': 0.1764362522795302, 'dropout_rate_Layer_3': 0.07490346952220962, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.998232652959162e-05, 'l1_Layer_2': 0.0003835244503371979, 'l1_Layer_3': 0.00018589481464657332, 'n_units_Layer_1': 125, 'n_units_Layer_2': 130, 'n_units_Layer_3': 240}. Best is trial 1429 with value: 4.088840244127163.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.27 | sMAPE for Validation Set is: 10.70% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.60 | sMAPE for Test Set is: 12.53% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:30:23,098]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:30:32,189]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:30:33,009]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:30:40,771]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:30:43,063]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:30:44,266]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:30:48,459]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:30:54,138]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:30:54,556]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:30:54,712]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:31:09,917]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:31:10,133]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:31:24,101]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:31:24,149]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:31:36,141]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:31:41,010]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:31:45,899]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:31:51,880]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:31:59,150]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:31:59,488]\u001b[0m Trial 1459 finished with value: 4.141939788621675 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006501295753435563, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0013786692775291307, 'dropout_rate_Layer_2': 0.0011519722775257483, 'dropout_rate_Layer_3': 0.046391958201152855, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00045066694631007816, 'l1_Layer_2': 1.1758972277856167e-05, 'l1_Layer_3': 0.00029458957653764005, 'n_units_Layer_1': 125, 'n_units_Layer_2': 135, 'n_units_Layer_3': 75}. Best is trial 1429 with value: 4.088840244127163.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.14 | sMAPE for Validation Set is: 10.38% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.92 | sMAPE for Test Set is: 11.02% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:32:10,522]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:32:10,885]\u001b[0m Trial 1465 finished with value: 4.442336403630965 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013287686697220033, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2968275922314783, 'dropout_rate_Layer_2': 0.15921887357994907, 'dropout_rate_Layer_3': 0.017990222743459655, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.488174864433763e-05, 'l1_Layer_2': 0.0014260470470748964, 'l1_Layer_3': 0.002125169135879342, 'n_units_Layer_1': 165, 'n_units_Layer_2': 90, 'n_units_Layer_3': 60}. Best is trial 1429 with value: 4.088840244127163.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.44 | sMAPE for Validation Set is: 11.20% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.27 | sMAPE for Test Set is: 11.78% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:32:21,498]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:32:25,312]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:32:33,851]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:32:34,821]\u001b[0m Trial 1467 finished with value: 4.111398366683022 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006613458804916767, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0013501930942071225, 'dropout_rate_Layer_2': 0.00040836281746570104, 'dropout_rate_Layer_3': 0.048061881331107455, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004730214679739149, 'l1_Layer_2': 1.0048866602995115e-05, 'l1_Layer_3': 0.0002975600012289689, 'n_units_Layer_1': 110, 'n_units_Layer_2': 130, 'n_units_Layer_3': 75}. Best is trial 1429 with value: 4.088840244127163.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.11 | sMAPE for Validation Set is: 10.27% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.02 | sMAPE for Test Set is: 11.21% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:32:41,788]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:32:51,712]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:32:52,278]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:32:59,753]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:33:02,547]\u001b[0m Trial 1475 finished with value: 4.193488809338717 and parameters: {'n_hidden': 3, 'learning_rate': 0.000574015966979822, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0033518553648490233, 'dropout_rate_Layer_2': 0.011256270773110312, 'dropout_rate_Layer_3': 0.040155703087466334, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004089863300142761, 'l1_Layer_2': 1.2397462608301707e-05, 'l1_Layer_3': 0.0002545713898012498, 'n_units_Layer_1': 110, 'n_units_Layer_2': 150, 'n_units_Layer_3': 75}. Best is trial 1429 with value: 4.088840244127163.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.19 | sMAPE for Validation Set is: 10.52% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.36 | sMAPE for Test Set is: 12.00% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:33:06,603]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:33:13,872]\u001b[0m Trial 1474 finished with value: 4.096329196172054 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005718446649404695, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00047578764350358037, 'dropout_rate_Layer_2': 0.011160862509348593, 'dropout_rate_Layer_3': 0.03975116862184971, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004110345000111484, 'l1_Layer_2': 1.1903930542682095e-05, 'l1_Layer_3': 0.0002429698974135346, 'n_units_Layer_1': 125, 'n_units_Layer_2': 150, 'n_units_Layer_3': 80}. Best is trial 1429 with value: 4.088840244127163.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.10 | sMAPE for Validation Set is: 10.26% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.03 | sMAPE for Test Set is: 11.21% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:33:18,175]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:33:24,696]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:33:36,110]\u001b[0m Trial 1480 finished with value: 4.1771659636275515 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006417783992486292, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0003040591034908205, 'dropout_rate_Layer_2': 0.0002452770401742757, 'dropout_rate_Layer_3': 0.04889651472382419, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002980360647725386, 'l1_Layer_2': 1.2876552811736686e-05, 'l1_Layer_3': 0.00029589113137171565, 'n_units_Layer_1': 115, 'n_units_Layer_2': 150, 'n_units_Layer_3': 75}. Best is trial 1429 with value: 4.088840244127163.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.18 | sMAPE for Validation Set is: 10.46% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.20 | sMAPE for Test Set is: 11.65% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:33:41,726]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:33:48,362]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:33:55,095]\u001b[0m Trial 1485 finished with value: 4.162504545399152 and parameters: {'n_hidden': 3, 'learning_rate': 0.000650889091256277, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.002080951687811028, 'dropout_rate_Layer_2': 0.014197627662240378, 'dropout_rate_Layer_3': 0.03951416934362935, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002832277610330526, 'l1_Layer_2': 1.3136209258266615e-05, 'l1_Layer_3': 0.00020271580595617524, 'n_units_Layer_1': 105, 'n_units_Layer_2': 150, 'n_units_Layer_3': 75}. Best is trial 1429 with value: 4.088840244127163.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.16 | sMAPE for Validation Set is: 10.48% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.11 | sMAPE for Test Set is: 11.48% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:33:55,296]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:34:02,596]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:34:06,955]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:34:07,165]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:34:14,960]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:34:15,633]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:34:21,621]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:34:26,956]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:34:30,565]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:34:54,370]\u001b[0m Trial 1490 finished with value: 4.479920945451691 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020828172748782224, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3530547059451857, 'dropout_rate_Layer_2': 0.2236617424585869, 'dropout_rate_Layer_3': 0.0012660949366561994, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00027249626771373025, 'l1_Layer_2': 0.0009786786234892827, 'l1_Layer_3': 0.0011676689096317325, 'n_units_Layer_1': 185, 'n_units_Layer_2': 240, 'n_units_Layer_3': 60}. Best is trial 1429 with value: 4.088840244127163.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.48 | sMAPE for Validation Set is: 11.11% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.03 | sMAPE for Test Set is: 11.22% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:34:55,730]\u001b[0m Trial 1499 finished with value: 4.5820865158750586 and parameters: {'n_hidden': 3, 'learning_rate': 0.003220680476453835, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29583156155209556, 'dropout_rate_Layer_2': 0.22046010594413662, 'dropout_rate_Layer_3': 0.020579834792781235, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00027252143472083573, 'l1_Layer_2': 0.0008161566782858029, 'l1_Layer_3': 0.002937870891914719, 'n_units_Layer_1': 190, 'n_units_Layer_2': 80, 'n_units_Layer_3': 60}. Best is trial 1429 with value: 4.088840244127163.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.58 | sMAPE for Validation Set is: 11.40% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.32 | sMAPE for Test Set is: 11.90% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:34:57,843]\u001b[0m Trial 1482 finished with value: 4.916474484891199 and parameters: {'n_hidden': 4, 'learning_rate': 0.009949161782022473, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2453393391316642, 'dropout_rate_Layer_2': 0.31661256723679887, 'dropout_rate_Layer_3': 0.2544893487744871, 'dropout_rate_Layer_4': 0.24127407691213432, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.3433307102188338e-05, 'l1_Layer_2': 0.026247772298929124, 'l1_Layer_3': 1.3302806078969578e-05, 'l1_Layer_4': 0.0003745797858350092, 'n_units_Layer_1': 190, 'n_units_Layer_2': 100, 'n_units_Layer_3': 90, 'n_units_Layer_4': 175}. Best is trial 1429 with value: 4.088840244127163.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.92 | sMAPE for Validation Set is: 11.63% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 5.08 | sMAPE for Test Set is: 11.17% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:35:21,508]\u001b[0m Trial 1498 finished with value: 4.809427449334712 and parameters: {'n_hidden': 4, 'learning_rate': 0.006602405087971278, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2649705883154516, 'dropout_rate_Layer_2': 0.33818434795415336, 'dropout_rate_Layer_3': 0.20282396849064205, 'dropout_rate_Layer_4': 0.13386122720436724, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.322952020123922e-05, 'l1_Layer_2': 0.06840532507447156, 'l1_Layer_3': 1.2460936321790547e-05, 'l1_Layer_4': 0.00019934399121161842, 'n_units_Layer_1': 180, 'n_units_Layer_2': 55, 'n_units_Layer_3': 75, 'n_units_Layer_4': 185}. Best is trial 1429 with value: 4.088840244127163.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.81 | sMAPE for Validation Set is: 11.75% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 5.43 | sMAPE for Test Set is: 11.88% | rMAE for Test Set is: 0.70\n",
      "for 2018-01-01, MAE is:24.20 & sMAPE is:94.70% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :24.20 & 94.70% & 1.42\n",
      "for 2018-01-02, MAE is:6.79 & sMAPE is:16.83% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :15.50 & 55.77% & 1.09\n",
      "for 2018-01-03, MAE is:7.92 & sMAPE is:17.65% & rMAE is:2.15 ||| daily mean of MAE & sMAPE & rMAE till now are :12.97 & 43.06% & 1.44\n",
      "WARNING:tensorflow:5 out of the last 28 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001E7E077CAF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "for 2018-01-04, MAE is:8.84 & sMAPE is:19.73% & rMAE is:2.43 ||| daily mean of MAE & sMAPE & rMAE till now are :11.94 & 37.23% & 1.69\n",
      "WARNING:tensorflow:6 out of the last 29 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001E7B8270940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "for 2018-01-05, MAE is:5.58 & sMAPE is:13.84% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :10.67 & 32.55% & 1.60\n",
      "for 2018-01-06, MAE is:3.88 & sMAPE is:10.80% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :9.54 & 28.92% & 1.40\n",
      "for 2018-01-07, MAE is:9.63 & sMAPE is:34.42% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :9.55 & 29.71% & 1.31\n",
      "for 2018-01-08, MAE is:14.57 & sMAPE is:35.39% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :10.18 & 30.42% & 1.20\n",
      "for 2018-01-09, MAE is:3.23 & sMAPE is:7.13% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :9.40 & 27.83% & 1.14\n",
      "for 2018-01-10, MAE is:3.17 & sMAPE is:6.85% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :8.78 & 25.73% & 1.09\n",
      "for 2018-01-11, MAE is:5.15 & sMAPE is:10.90% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :8.45 & 24.38% & 1.13\n",
      "for 2018-01-12, MAE is:3.77 & sMAPE is:8.59% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :8.06 & 23.07% & 1.13\n",
      "for 2018-01-13, MAE is:6.94 & sMAPE is:17.85% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :7.97 & 22.67% & 1.17\n",
      "for 2018-01-14, MAE is:2.23 & sMAPE is:5.46% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :7.56 & 21.44% & 1.10\n",
      "for 2018-01-15, MAE is:5.05 & sMAPE is:10.13% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :7.40 & 20.68% & 1.09\n",
      "for 2018-01-16, MAE is:2.90 & sMAPE is:6.43% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :7.11 & 19.79% & 1.09\n",
      "for 2018-01-17, MAE is:3.13 & sMAPE is:7.44% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.88 & 19.07% & 1.11\n",
      "for 2018-01-18, MAE is:2.64 & sMAPE is:5.93% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 18.34% & 1.10\n",
      "for 2018-01-19, MAE is:2.72 & sMAPE is:6.11% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.44 & 17.69% & 1.08\n",
      "for 2018-01-20, MAE is:3.98 & sMAPE is:9.44% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 17.28% & 1.09\n",
      "for 2018-01-21, MAE is:2.93 & sMAPE is:7.99% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.15 & 16.84% & 1.07\n",
      "for 2018-01-22, MAE is:3.61 & sMAPE is:8.83% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 16.47% & 1.07\n",
      "for 2018-01-23, MAE is:2.98 & sMAPE is:6.82% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :5.90 & 16.05% & 1.06\n",
      "for 2018-01-24, MAE is:3.84 & sMAPE is:8.79% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :5.82 & 15.75% & 1.06\n",
      "for 2018-01-25, MAE is:2.94 & sMAPE is:6.58% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :5.70 & 15.39% & 1.08\n",
      "for 2018-01-26, MAE is:4.16 & sMAPE is:9.29% & rMAE is:1.67 ||| daily mean of MAE & sMAPE & rMAE till now are :5.64 & 15.15% & 1.10\n",
      "for 2018-01-27, MAE is:2.91 & sMAPE is:6.83% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :5.54 & 14.84% & 1.12\n",
      "for 2018-01-28, MAE is:4.10 & sMAPE is:10.31% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :5.49 & 14.68% & 1.11\n",
      "for 2018-01-29, MAE is:3.88 & sMAPE is:8.57% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :5.44 & 14.47% & 1.12\n",
      "for 2018-01-30, MAE is:2.44 & sMAPE is:5.44% & rMAE is:2.22 ||| daily mean of MAE & sMAPE & rMAE till now are :5.34 & 14.17% & 1.16\n",
      "for 2018-01-31, MAE is:3.59 & sMAPE is:8.24% & rMAE is:3.07 ||| daily mean of MAE & sMAPE & rMAE till now are :5.28 & 13.98% & 1.22\n",
      "for 2018-02-01, MAE is:3.44 & sMAPE is:7.80% & rMAE is:2.79 ||| daily mean of MAE & sMAPE & rMAE till now are :5.22 & 13.78% & 1.27\n",
      "for 2018-02-02, MAE is:2.56 & sMAPE is:5.61% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :5.14 & 13.54% & 1.28\n",
      "for 2018-02-03, MAE is:3.32 & sMAPE is:7.62% & rMAE is:1.73 ||| daily mean of MAE & sMAPE & rMAE till now are :5.09 & 13.36% & 1.29\n",
      "for 2018-02-04, MAE is:2.66 & sMAPE is:6.56% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :5.02 & 13.17% & 1.29\n",
      "for 2018-02-05, MAE is:4.88 & sMAPE is:9.92% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :5.01 & 13.08% & 1.28\n",
      "for 2018-02-06, MAE is:5.90 & sMAPE is:11.38% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :5.04 & 13.03% & 1.27\n",
      "for 2018-02-07, MAE is:6.21 & sMAPE is:12.55% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :5.07 & 13.02% & 1.27\n",
      "for 2018-02-08, MAE is:7.83 & sMAPE is:15.86% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :5.14 & 13.09% & 1.27\n",
      "for 2018-02-09, MAE is:3.41 & sMAPE is:7.32% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :5.10 & 12.95% & 1.27\n",
      "for 2018-02-10, MAE is:2.18 & sMAPE is:4.99% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :5.03 & 12.75% & 1.26\n",
      "for 2018-02-11, MAE is:5.69 & sMAPE is:14.40% & rMAE is:2.72 ||| daily mean of MAE & sMAPE & rMAE till now are :5.04 & 12.79% & 1.29\n",
      "for 2018-02-12, MAE is:3.30 & sMAPE is:7.11% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :5.00 & 12.66% & 1.29\n",
      "for 2018-02-13, MAE is:2.74 & sMAPE is:5.79% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :4.95 & 12.51% & 1.27\n",
      "for 2018-02-14, MAE is:3.64 & sMAPE is:8.10% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :4.92 & 12.41% & 1.26\n",
      "for 2018-02-15, MAE is:3.20 & sMAPE is:6.98% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :4.88 & 12.29% & 1.25\n",
      "for 2018-02-16, MAE is:3.85 & sMAPE is:8.64% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.86 & 12.21% & 1.26\n",
      "for 2018-02-17, MAE is:4.48 & sMAPE is:10.27% & rMAE is:2.04 ||| daily mean of MAE & sMAPE & rMAE till now are :4.85 & 12.17% & 1.27\n",
      "for 2018-02-18, MAE is:2.06 & sMAPE is:5.05% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 12.03% & 1.28\n",
      "for 2018-02-19, MAE is:3.16 & sMAPE is:6.57% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :4.76 & 11.92% & 1.29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-02-20, MAE is:8.97 & sMAPE is:18.82% & rMAE is:2.97 ||| daily mean of MAE & sMAPE & rMAE till now are :4.85 & 12.05% & 1.32\n",
      "for 2018-02-21, MAE is:6.90 & sMAPE is:13.73% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :4.89 & 12.08% & 1.33\n",
      "for 2018-02-22, MAE is:5.67 & sMAPE is:11.14% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 12.07% & 1.32\n",
      "for 2018-02-23, MAE is:2.82 & sMAPE is:5.32% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :4.86 & 11.94% & 1.30\n",
      "for 2018-02-24, MAE is:7.17 & sMAPE is:13.45% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 11.97% & 1.29\n",
      "for 2018-02-25, MAE is:8.03 & sMAPE is:14.71% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.96 & 12.02% & 1.28\n",
      "for 2018-02-26, MAE is:7.45 & sMAPE is:10.13% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :5.00 & 11.99% & 1.26\n",
      "for 2018-02-27, MAE is:20.20 & sMAPE is:21.82% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :5.27 & 12.15% & 1.25\n",
      "for 2018-02-28, MAE is:14.32 & sMAPE is:16.14% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :5.42 & 12.22% & 1.23\n",
      "for 2018-03-01, MAE is:17.85 & sMAPE is:23.28% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :5.63 & 12.41% & 1.22\n",
      "for 2018-03-02, MAE is:32.19 & sMAPE is:41.09% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :6.06 & 12.88% & 1.22\n",
      "for 2018-03-03, MAE is:10.88 & sMAPE is:17.49% & rMAE is:4.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.14 & 12.95% & 1.27\n",
      "for 2018-03-04, MAE is:6.09 & sMAPE is:12.25% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.14 & 12.94% & 1.27\n",
      "for 2018-03-05, MAE is:4.62 & sMAPE is:7.88% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.11 & 12.86% & 1.26\n",
      "for 2018-03-06, MAE is:5.07 & sMAPE is:9.56% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :6.10 & 12.81% & 1.24\n",
      "for 2018-03-07, MAE is:5.34 & sMAPE is:10.30% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 12.77% & 1.23\n",
      "for 2018-03-08, MAE is:3.08 & sMAPE is:6.42% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 12.68% & 1.21\n",
      "for 2018-03-09, MAE is:4.28 & sMAPE is:9.29% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :6.02 & 12.63% & 1.19\n",
      "for 2018-03-10, MAE is:2.50 & sMAPE is:5.86% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :5.97 & 12.53% & 1.18\n",
      "for 2018-03-11, MAE is:7.95 & sMAPE is:28.86% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :5.99 & 12.76% & 1.17\n",
      "for 2018-03-12, MAE is:3.22 & sMAPE is:8.30% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :5.96 & 12.70% & 1.15\n",
      "for 2018-03-13, MAE is:13.46 & sMAPE is:28.39% & rMAE is:3.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.06 & 12.92% & 1.19\n",
      "for 2018-03-14, MAE is:4.83 & sMAPE is:9.84% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 12.88% & 1.18\n",
      "for 2018-03-15, MAE is:13.44 & sMAPE is:25.59% & rMAE is:1.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.14 & 13.05% & 1.19\n",
      "for 2018-03-16, MAE is:11.53 & sMAPE is:20.85% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :6.21 & 13.15% & 1.19\n",
      "for 2018-03-17, MAE is:14.73 & sMAPE is:28.77% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :6.33 & 13.36% & 1.19\n",
      "for 2018-03-18, MAE is:5.43 & sMAPE is:11.40% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 13.33% & 1.18\n",
      "for 2018-03-19, MAE is:7.40 & sMAPE is:12.96% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.33 & 13.33% & 1.17\n",
      "for 2018-03-20, MAE is:5.28 & sMAPE is:9.37% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :6.32 & 13.28% & 1.17\n",
      "for 2018-03-21, MAE is:11.69 & sMAPE is:20.97% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.38 & 13.37% & 1.17\n",
      "for 2018-03-22, MAE is:8.25 & sMAPE is:14.29% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 13.38% & 1.17\n",
      "for 2018-03-23, MAE is:8.37 & sMAPE is:15.29% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.43 & 13.41% & 1.17\n",
      "for 2018-03-24, MAE is:3.77 & sMAPE is:8.43% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 13.35% & 1.16\n",
      "for 2018-03-25, MAE is:3.07 & sMAPE is:9.42% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.36 & 13.30% & 1.15\n",
      "for 2018-03-26, MAE is:17.50 & sMAPE is:36.12% & rMAE is:4.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 13.57% & 1.19\n",
      "for 2018-03-27, MAE is:7.45 & sMAPE is:14.65% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 13.58% & 1.19\n",
      "for 2018-03-28, MAE is:6.53 & sMAPE is:13.76% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 13.58% & 1.19\n",
      "for 2018-03-29, MAE is:6.23 & sMAPE is:13.09% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 13.58% & 1.18\n",
      "for 2018-03-30, MAE is:3.37 & sMAPE is:8.83% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 13.52% & 1.17\n",
      "for 2018-03-31, MAE is:3.34 & sMAPE is:10.21% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.43 & 13.49% & 1.16\n",
      "for 2018-04-01, MAE is:2.79 & sMAPE is:14.85% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 13.50% & 1.15\n",
      "for 2018-04-02, MAE is:4.64 & sMAPE is:17.01% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :6.37 & 13.54% & 1.14\n",
      "for 2018-04-03, MAE is:11.48 & sMAPE is:33.68% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 13.76% & 1.14\n",
      "for 2018-04-04, MAE is:5.96 & sMAPE is:16.48% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 13.79% & 1.13\n",
      "for 2018-04-05, MAE is:12.01 & sMAPE is:30.59% & rMAE is:1.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 13.96% & 1.14\n",
      "for 2018-04-06, MAE is:5.54 & sMAPE is:13.57% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 13.96% & 1.14\n",
      "for 2018-04-07, MAE is:4.64 & sMAPE is:17.91% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.45 & 14.00% & 1.13\n",
      "for 2018-04-08, MAE is:6.60 & sMAPE is:29.84% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.45 & 14.16% & 1.14\n",
      "for 2018-04-09, MAE is:9.71 & sMAPE is:25.59% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 14.28% & 1.13\n",
      "for 2018-04-10, MAE is:7.10 & sMAPE is:17.93% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 14.31% & 1.14\n",
      "for 2018-04-11, MAE is:4.21 & sMAPE is:11.03% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 14.28% & 1.14\n",
      "for 2018-04-12, MAE is:9.93 & sMAPE is:26.10% & rMAE is:3.04 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 14.40% & 1.16\n",
      "for 2018-04-13, MAE is:10.50 & sMAPE is:24.37% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.54 & 14.49% & 1.16\n",
      "for 2018-04-14, MAE is:4.57 & sMAPE is:13.58% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.52 & 14.48% & 1.16\n",
      "for 2018-04-15, MAE is:6.81 & sMAPE is:23.48% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :6.52 & 14.57% & 1.16\n",
      "for 2018-04-16, MAE is:7.83 & sMAPE is:18.37% & rMAE is:2.00 ||| daily mean of MAE & sMAPE & rMAE till now are :6.54 & 14.61% & 1.16\n",
      "for 2018-04-17, MAE is:5.88 & sMAPE is:13.86% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 14.60% & 1.16\n",
      "for 2018-04-18, MAE is:5.25 & sMAPE is:12.93% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :6.52 & 14.58% & 1.16\n",
      "for 2018-04-19, MAE is:4.42 & sMAPE is:11.39% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 14.55% & 1.16\n",
      "for 2018-04-20, MAE is:4.72 & sMAPE is:12.40% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 14.54% & 1.15\n",
      "for 2018-04-21, MAE is:4.51 & sMAPE is:14.75% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 14.54% & 1.16\n",
      "for 2018-04-22, MAE is:8.40 & sMAPE is:46.98% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 14.83% & 1.15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-04-23, MAE is:3.62 & sMAPE is:12.18% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 14.80% & 1.14\n",
      "for 2018-04-24, MAE is:5.55 & sMAPE is:15.75% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.45 & 14.81% & 1.14\n",
      "for 2018-04-25, MAE is:5.71 & sMAPE is:19.53% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :6.44 & 14.85% & 1.13\n",
      "for 2018-04-26, MAE is:6.40 & sMAPE is:20.74% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :6.44 & 14.90% & 1.13\n",
      "for 2018-04-27, MAE is:6.41 & sMAPE is:18.08% & rMAE is:3.84 ||| daily mean of MAE & sMAPE & rMAE till now are :6.44 & 14.93% & 1.15\n",
      "for 2018-04-28, MAE is:4.01 & sMAPE is:14.50% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 14.93% & 1.15\n",
      "for 2018-04-29, MAE is:5.78 & sMAPE is:33.67% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 15.08% & 1.15\n",
      "for 2018-04-30, MAE is:8.32 & sMAPE is:59.63% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.43 & 15.46% & 1.15\n",
      "for 2018-05-01, MAE is:29.17 & sMAPE is:157.86% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 16.63% & 1.14\n",
      "for 2018-05-02, MAE is:15.73 & sMAPE is:51.23% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.69 & 16.92% & 1.15\n",
      "for 2018-05-03, MAE is:8.11 & sMAPE is:21.60% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 16.95% & 1.14\n",
      "for 2018-05-04, MAE is:4.73 & sMAPE is:12.32% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :6.69 & 16.92% & 1.15\n",
      "for 2018-05-05, MAE is:4.36 & sMAPE is:16.99% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 16.92% & 1.15\n",
      "for 2018-05-06, MAE is:5.91 & sMAPE is:46.38% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 17.15% & 1.15\n",
      "for 2018-05-07, MAE is:10.41 & sMAPE is:35.78% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.69 & 17.30% & 1.15\n",
      "for 2018-05-08, MAE is:4.80 & sMAPE is:15.59% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 17.28% & 1.14\n",
      "for 2018-05-09, MAE is:8.76 & sMAPE is:27.13% & rMAE is:2.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 17.36% & 1.15\n",
      "for 2018-05-10, MAE is:6.17 & sMAPE is:24.97% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.69 & 17.42% & 1.14\n",
      "for 2018-05-11, MAE is:14.66 & sMAPE is:47.74% & rMAE is:3.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 17.65% & 1.16\n",
      "for 2018-05-12, MAE is:5.33 & sMAPE is:17.33% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 17.65% & 1.16\n",
      "for 2018-05-13, MAE is:6.35 & sMAPE is:46.37% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 17.86% & 1.17\n",
      "for 2018-05-14, MAE is:9.58 & sMAPE is:32.59% & rMAE is:4.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 17.97% & 1.19\n",
      "for 2018-05-15, MAE is:11.85 & sMAPE is:32.80% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 18.08% & 1.19\n",
      "for 2018-05-16, MAE is:9.47 & sMAPE is:24.50% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 18.13% & 1.19\n",
      "for 2018-05-17, MAE is:4.29 & sMAPE is:12.28% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 18.09% & 1.18\n",
      "for 2018-05-18, MAE is:8.92 & sMAPE is:24.68% & rMAE is:3.28 ||| daily mean of MAE & sMAPE & rMAE till now are :6.81 & 18.14% & 1.20\n",
      "for 2018-05-19, MAE is:4.95 & sMAPE is:14.95% & rMAE is:1.98 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 18.11% & 1.21\n",
      "for 2018-05-20, MAE is:4.57 & sMAPE is:29.15% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 18.19% & 1.20\n",
      "for 2018-05-21, MAE is:10.20 & sMAPE is:77.27% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.81 & 18.61% & 1.20\n",
      "for 2018-05-22, MAE is:11.95 & sMAPE is:34.71% & rMAE is:5.15 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 18.72% & 1.23\n",
      "for 2018-05-23, MAE is:8.72 & sMAPE is:22.30% & rMAE is:4.70 ||| daily mean of MAE & sMAPE & rMAE till now are :6.86 & 18.75% & 1.25\n",
      "for 2018-05-24, MAE is:5.12 & sMAPE is:13.36% & rMAE is:1.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 18.71% & 1.25\n",
      "for 2018-05-25, MAE is:9.83 & sMAPE is:28.05% & rMAE is:5.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.87 & 18.78% & 1.28\n",
      "for 2018-05-26, MAE is:3.77 & sMAPE is:11.07% & rMAE is:3.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 18.72% & 1.30\n",
      "for 2018-05-27, MAE is:3.09 & sMAPE is:11.59% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 18.68% & 1.29\n",
      "for 2018-05-28, MAE is:18.31 & sMAPE is:49.18% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 18.88% & 1.28\n",
      "for 2018-05-29, MAE is:4.92 & sMAPE is:11.73% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.88 & 18.83% & 1.28\n",
      "for 2018-05-30, MAE is:10.93 & sMAPE is:25.97% & rMAE is:1.98 ||| daily mean of MAE & sMAPE & rMAE till now are :6.91 & 18.88% & 1.29\n",
      "for 2018-05-31, MAE is:4.16 & sMAPE is:10.41% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 18.82% & 1.29\n",
      "for 2018-06-01, MAE is:12.69 & sMAPE is:29.87% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 18.90% & 1.29\n",
      "for 2018-06-02, MAE is:6.20 & sMAPE is:16.72% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 18.88% & 1.29\n",
      "for 2018-06-03, MAE is:3.34 & sMAPE is:9.97% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 18.83% & 1.28\n",
      "for 2018-06-04, MAE is:7.50 & sMAPE is:16.81% & rMAE is:4.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.91 & 18.81% & 1.30\n",
      "for 2018-06-05, MAE is:10.24 & sMAPE is:22.02% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 18.83% & 1.30\n",
      "for 2018-06-06, MAE is:7.93 & sMAPE is:16.24% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 18.82% & 1.30\n",
      "for 2018-06-07, MAE is:9.01 & sMAPE is:18.39% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 18.81% & 1.30\n",
      "for 2018-06-08, MAE is:6.85 & sMAPE is:14.56% & rMAE is:2.75 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 18.79% & 1.31\n",
      "for 2018-06-09, MAE is:4.08 & sMAPE is:10.35% & rMAE is:2.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 18.73% & 1.31\n",
      "for 2018-06-10, MAE is:3.31 & sMAPE is:9.67% & rMAE is:3.06 ||| daily mean of MAE & sMAPE & rMAE till now are :6.91 & 18.68% & 1.33\n",
      "for 2018-06-11, MAE is:9.26 & sMAPE is:20.42% & rMAE is:5.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 18.69% & 1.35\n",
      "for 2018-06-12, MAE is:6.21 & sMAPE is:13.49% & rMAE is:2.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 18.66% & 1.36\n",
      "for 2018-06-13, MAE is:3.88 & sMAPE is:8.53% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 18.59% & 1.35\n",
      "for 2018-06-14, MAE is:4.46 & sMAPE is:10.16% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.88 & 18.54% & 1.35\n",
      "for 2018-06-15, MAE is:10.18 & sMAPE is:22.73% & rMAE is:7.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 18.57% & 1.39\n",
      "for 2018-06-16, MAE is:2.63 & sMAPE is:6.88% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.88 & 18.50% & 1.39\n",
      "for 2018-06-17, MAE is:6.15 & sMAPE is:23.32% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :6.87 & 18.53% & 1.39\n",
      "for 2018-06-18, MAE is:4.96 & sMAPE is:11.91% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.86 & 18.49% & 1.39\n",
      "for 2018-06-19, MAE is:6.73 & sMAPE is:15.08% & rMAE is:1.75 ||| daily mean of MAE & sMAPE & rMAE till now are :6.86 & 18.47% & 1.39\n",
      "for 2018-06-20, MAE is:3.11 & sMAPE is:7.00% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :6.84 & 18.40% & 1.38\n",
      "for 2018-06-21, MAE is:5.71 & sMAPE is:13.27% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 18.37% & 1.38\n",
      "for 2018-06-22, MAE is:5.75 & sMAPE is:20.19% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 18.38% & 1.38\n",
      "for 2018-06-23, MAE is:4.01 & sMAPE is:17.65% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.81 & 18.38% & 1.37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-06-24, MAE is:9.80 & sMAPE is:44.25% & rMAE is:2.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 18.53% & 1.38\n",
      "for 2018-06-25, MAE is:10.67 & sMAPE is:24.84% & rMAE is:3.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 18.56% & 1.39\n",
      "for 2018-06-26, MAE is:7.02 & sMAPE is:15.28% & rMAE is:2.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 18.54% & 1.40\n",
      "for 2018-06-27, MAE is:4.16 & sMAPE is:9.43% & rMAE is:1.92 ||| daily mean of MAE & sMAPE & rMAE till now are :6.84 & 18.49% & 1.40\n",
      "for 2018-06-28, MAE is:5.16 & sMAPE is:11.58% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 18.45% & 1.40\n",
      "for 2018-06-29, MAE is:9.41 & sMAPE is:22.76% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.84 & 18.48% & 1.39\n",
      "for 2018-06-30, MAE is:6.20 & sMAPE is:15.88% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.84 & 18.46% & 1.39\n",
      "for 2018-07-01, MAE is:6.26 & sMAPE is:20.44% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 18.47% & 1.38\n",
      "for 2018-07-02, MAE is:6.05 & sMAPE is:13.33% & rMAE is:2.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 18.45% & 1.39\n",
      "for 2018-07-03, MAE is:7.64 & sMAPE is:16.25% & rMAE is:2.15 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 18.43% & 1.40\n",
      "for 2018-07-04, MAE is:7.49 & sMAPE is:14.73% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :6.84 & 18.41% & 1.39\n",
      "for 2018-07-05, MAE is:3.47 & sMAPE is:7.33% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 18.35% & 1.39\n",
      "for 2018-07-06, MAE is:4.89 & sMAPE is:10.79% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.81 & 18.31% & 1.39\n",
      "for 2018-07-07, MAE is:3.51 & sMAPE is:9.49% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 18.27% & 1.39\n",
      "for 2018-07-08, MAE is:7.33 & sMAPE is:21.79% & rMAE is:3.18 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 18.29% & 1.40\n",
      "for 2018-07-09, MAE is:3.59 & sMAPE is:7.93% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 18.23% & 1.40\n",
      "for 2018-07-10, MAE is:10.49 & sMAPE is:21.09% & rMAE is:2.62 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 18.25% & 1.40\n",
      "for 2018-07-11, MAE is:7.00 & sMAPE is:14.03% & rMAE is:2.85 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 18.22% & 1.41\n",
      "for 2018-07-12, MAE is:4.13 & sMAPE is:8.23% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 18.17% & 1.41\n",
      "for 2018-07-13, MAE is:5.48 & sMAPE is:11.44% & rMAE is:2.13 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 18.14% & 1.42\n",
      "for 2018-07-14, MAE is:6.22 & sMAPE is:14.11% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 18.12% & 1.41\n",
      "for 2018-07-15, MAE is:9.31 & sMAPE is:22.79% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 18.14% & 1.41\n",
      "for 2018-07-16, MAE is:4.62 & sMAPE is:8.95% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 18.09% & 1.41\n",
      "for 2018-07-17, MAE is:4.25 & sMAPE is:8.56% & rMAE is:2.06 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 18.05% & 1.41\n",
      "for 2018-07-18, MAE is:3.69 & sMAPE is:7.77% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 17.99% & 1.41\n",
      "for 2018-07-19, MAE is:6.24 & sMAPE is:12.73% & rMAE is:4.16 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 17.97% & 1.42\n",
      "for 2018-07-20, MAE is:7.61 & sMAPE is:15.62% & rMAE is:4.10 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 17.96% & 1.43\n",
      "for 2018-07-21, MAE is:8.66 & sMAPE is:19.23% & rMAE is:3.10 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 17.96% & 1.44\n",
      "for 2018-07-22, MAE is:4.59 & sMAPE is:10.38% & rMAE is:4.24 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 17.93% & 1.46\n",
      "for 2018-07-23, MAE is:3.07 & sMAPE is:6.15% & rMAE is:2.10 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 17.87% & 1.46\n",
      "for 2018-07-24, MAE is:5.82 & sMAPE is:11.21% & rMAE is:2.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 17.84% & 1.46\n",
      "for 2018-07-25, MAE is:7.76 & sMAPE is:14.40% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 17.82% & 1.46\n",
      "for 2018-07-26, MAE is:6.24 & sMAPE is:11.76% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 17.79% & 1.46\n",
      "for 2018-07-27, MAE is:6.31 & sMAPE is:12.16% & rMAE is:3.15 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 17.76% & 1.47\n",
      "for 2018-07-28, MAE is:3.45 & sMAPE is:7.70% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 17.71% & 1.47\n",
      "for 2018-07-29, MAE is:6.61 & sMAPE is:15.17% & rMAE is:4.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 17.70% & 1.48\n",
      "for 2018-07-30, MAE is:4.57 & sMAPE is:8.78% & rMAE is:4.45 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 17.66% & 1.49\n",
      "for 2018-07-31, MAE is:5.09 & sMAPE is:9.53% & rMAE is:3.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.69 & 17.62% & 1.50\n",
      "for 2018-08-01, MAE is:6.11 & sMAPE is:11.31% & rMAE is:3.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.69 & 17.59% & 1.51\n",
      "for 2018-08-02, MAE is:11.26 & sMAPE is:20.96% & rMAE is:4.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 17.61% & 1.53\n",
      "for 2018-08-03, MAE is:9.00 & sMAPE is:15.24% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 17.60% & 1.52\n",
      "for 2018-08-04, MAE is:3.47 & sMAPE is:6.67% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 17.55% & 1.52\n",
      "for 2018-08-05, MAE is:4.61 & sMAPE is:9.63% & rMAE is:2.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 17.51% & 1.53\n",
      "for 2018-08-06, MAE is:8.42 & sMAPE is:13.95% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 17.49% & 1.52\n",
      "for 2018-08-07, MAE is:4.28 & sMAPE is:7.00% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.69 & 17.45% & 1.52\n",
      "for 2018-08-08, MAE is:4.34 & sMAPE is:7.63% & rMAE is:2.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 17.40% & 1.52\n",
      "for 2018-08-09, MAE is:5.42 & sMAPE is:10.18% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 17.37% & 1.52\n",
      "for 2018-08-10, MAE is:5.96 & sMAPE is:14.15% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 17.35% & 1.52\n",
      "for 2018-08-11, MAE is:7.93 & sMAPE is:18.59% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 17.36% & 1.52\n",
      "for 2018-08-12, MAE is:6.35 & sMAPE is:14.01% & rMAE is:4.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 17.34% & 1.53\n",
      "for 2018-08-13, MAE is:3.24 & sMAPE is:6.20% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 17.29% & 1.53\n",
      "for 2018-08-14, MAE is:4.84 & sMAPE is:9.18% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 17.26% & 1.52\n",
      "for 2018-08-15, MAE is:5.20 & sMAPE is:10.23% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 17.23% & 1.52\n",
      "for 2018-08-16, MAE is:7.09 & sMAPE is:13.44% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 17.21% & 1.52\n",
      "for 2018-08-17, MAE is:7.18 & sMAPE is:13.17% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 17.19% & 1.52\n",
      "for 2018-08-18, MAE is:4.73 & sMAPE is:9.43% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 17.16% & 1.51\n",
      "for 2018-08-19, MAE is:4.64 & sMAPE is:9.50% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 17.13% & 1.51\n",
      "for 2018-08-20, MAE is:3.01 & sMAPE is:5.43% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 17.08% & 1.51\n",
      "for 2018-08-21, MAE is:11.19 & sMAPE is:18.18% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 17.08% & 1.51\n",
      "for 2018-08-22, MAE is:4.84 & sMAPE is:7.70% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :6.63 & 17.04% & 1.50\n",
      "for 2018-08-23, MAE is:6.69 & sMAPE is:10.72% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.63 & 17.01% & 1.50\n",
      "for 2018-08-24, MAE is:3.08 & sMAPE is:5.25% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 16.96% & 1.50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-08-25, MAE is:6.70 & sMAPE is:12.28% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 16.94% & 1.50\n",
      "for 2018-08-26, MAE is:4.73 & sMAPE is:9.22% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 16.91% & 1.49\n",
      "for 2018-08-27, MAE is:4.62 & sMAPE is:7.82% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :6.60 & 16.87% & 1.49\n",
      "for 2018-08-28, MAE is:5.21 & sMAPE is:7.92% & rMAE is:2.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.60 & 16.84% & 1.49\n",
      "for 2018-08-29, MAE is:3.86 & sMAPE is:5.98% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 16.79% & 1.49\n",
      "for 2018-08-30, MAE is:4.36 & sMAPE is:6.90% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 16.75% & 1.49\n",
      "for 2018-08-31, MAE is:5.96 & sMAPE is:9.49% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :6.57 & 16.72% & 1.49\n",
      "for 2018-09-01, MAE is:5.40 & sMAPE is:9.37% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :6.57 & 16.69% & 1.49\n",
      "for 2018-09-02, MAE is:2.96 & sMAPE is:5.40% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 16.64% & 1.49\n",
      "for 2018-09-03, MAE is:4.70 & sMAPE is:7.56% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 16.61% & 1.49\n",
      "for 2018-09-04, MAE is:3.83 & sMAPE is:6.18% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :6.54 & 16.57% & 1.49\n",
      "for 2018-09-05, MAE is:6.34 & sMAPE is:10.03% & rMAE is:2.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 16.54% & 1.49\n",
      "for 2018-09-06, MAE is:5.51 & sMAPE is:8.79% & rMAE is:2.05 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 16.51% & 1.49\n",
      "for 2018-09-07, MAE is:5.25 & sMAPE is:8.76% & rMAE is:2.03 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 16.48% & 1.49\n",
      "for 2018-09-08, MAE is:2.75 & sMAPE is:5.06% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 16.43% & 1.49\n",
      "for 2018-09-09, MAE is:5.03 & sMAPE is:9.67% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 16.40% & 1.49\n",
      "for 2018-09-10, MAE is:4.39 & sMAPE is:7.24% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 16.37% & 1.49\n",
      "for 2018-09-11, MAE is:3.64 & sMAPE is:6.04% & rMAE is:2.18 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 16.33% & 1.49\n",
      "for 2018-09-12, MAE is:7.32 & sMAPE is:11.24% & rMAE is:2.73 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 16.31% & 1.50\n",
      "for 2018-09-13, MAE is:6.84 & sMAPE is:10.46% & rMAE is:1.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 16.28% & 1.50\n",
      "for 2018-09-14, MAE is:4.96 & sMAPE is:7.74% & rMAE is:2.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 16.25% & 1.50\n",
      "for 2018-09-15, MAE is:4.65 & sMAPE is:8.34% & rMAE is:2.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 16.22% & 1.51\n",
      "for 2018-09-16, MAE is:5.23 & sMAPE is:10.81% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 16.20% & 1.51\n",
      "for 2018-09-17, MAE is:7.29 & sMAPE is:11.66% & rMAE is:2.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 16.18% & 1.51\n",
      "for 2018-09-18, MAE is:5.66 & sMAPE is:9.46% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 16.16% & 1.51\n",
      "for 2018-09-19, MAE is:7.85 & sMAPE is:12.99% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 16.14% & 1.51\n",
      "for 2018-09-20, MAE is:6.28 & sMAPE is:10.41% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 16.12% & 1.50\n",
      "for 2018-09-21, MAE is:5.24 & sMAPE is:10.36% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 16.10% & 1.50\n",
      "for 2018-09-22, MAE is:13.75 & sMAPE is:24.30% & rMAE is:1.75 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 16.13% & 1.50\n",
      "for 2018-09-23, MAE is:3.24 & sMAPE is:6.29% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 16.09% & 1.50\n",
      "for 2018-09-24, MAE is:4.51 & sMAPE is:7.57% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 16.06% & 1.50\n",
      "for 2018-09-25, MAE is:5.84 & sMAPE is:8.88% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 16.04% & 1.49\n",
      "for 2018-09-26, MAE is:3.34 & sMAPE is:5.74% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 16.00% & 1.49\n",
      "for 2018-09-27, MAE is:4.94 & sMAPE is:8.00% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 15.97% & 1.49\n",
      "for 2018-09-28, MAE is:4.62 & sMAPE is:7.79% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.45 & 15.94% & 1.49\n",
      "for 2018-09-29, MAE is:8.34 & sMAPE is:15.13% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 15.94% & 1.49\n",
      "for 2018-09-30, MAE is:3.23 & sMAPE is:6.34% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.45 & 15.90% & 1.48\n",
      "for 2018-10-01, MAE is:12.13 & sMAPE is:18.54% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 15.91% & 1.48\n",
      "for 2018-10-02, MAE is:6.35 & sMAPE is:9.37% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 15.89% & 1.48\n",
      "for 2018-10-03, MAE is:5.28 & sMAPE is:7.63% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 15.86% & 1.48\n",
      "for 2018-10-04, MAE is:5.05 & sMAPE is:7.33% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 15.83% & 1.47\n",
      "for 2018-10-05, MAE is:10.11 & sMAPE is:14.71% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 15.82% & 1.47\n",
      "for 2018-10-06, MAE is:7.58 & sMAPE is:11.80% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 15.81% & 1.47\n",
      "for 2018-10-07, MAE is:7.00 & sMAPE is:11.72% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 15.79% & 1.47\n",
      "for 2018-10-08, MAE is:9.12 & sMAPE is:12.92% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 15.78% & 1.47\n",
      "for 2018-10-09, MAE is:5.73 & sMAPE is:7.70% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 15.75% & 1.47\n",
      "for 2018-10-10, MAE is:6.33 & sMAPE is:8.65% & rMAE is:2.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 15.73% & 1.47\n",
      "for 2018-10-11, MAE is:5.10 & sMAPE is:7.22% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 15.70% & 1.47\n",
      "for 2018-10-12, MAE is:5.70 & sMAPE is:8.36% & rMAE is:3.36 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 15.67% & 1.48\n",
      "for 2018-10-13, MAE is:8.19 & sMAPE is:13.04% & rMAE is:2.03 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 15.66% & 1.48\n",
      "for 2018-10-14, MAE is:8.93 & sMAPE is:16.70% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 15.67% & 1.48\n",
      "for 2018-10-15, MAE is:7.76 & sMAPE is:11.14% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 15.65% & 1.48\n",
      "for 2018-10-16, MAE is:7.19 & sMAPE is:9.56% & rMAE is:2.06 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 15.63% & 1.48\n",
      "for 2018-10-17, MAE is:6.30 & sMAPE is:8.22% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 15.60% & 1.48\n",
      "for 2018-10-18, MAE is:5.04 & sMAPE is:7.21% & rMAE is:2.05 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 15.58% & 1.48\n",
      "for 2018-10-19, MAE is:6.87 & sMAPE is:9.40% & rMAE is:2.17 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 15.55% & 1.48\n",
      "for 2018-10-20, MAE is:8.06 & sMAPE is:11.84% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 15.54% & 1.49\n",
      "for 2018-10-21, MAE is:6.40 & sMAPE is:10.53% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 15.52% & 1.48\n",
      "for 2018-10-22, MAE is:6.93 & sMAPE is:9.84% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 15.51% & 1.48\n",
      "for 2018-10-23, MAE is:5.20 & sMAPE is:7.23% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 15.48% & 1.48\n",
      "for 2018-10-24, MAE is:5.38 & sMAPE is:7.75% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 15.45% & 1.48\n",
      "for 2018-10-25, MAE is:4.96 & sMAPE is:7.15% & rMAE is:3.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 15.42% & 1.49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-10-26, MAE is:6.40 & sMAPE is:9.13% & rMAE is:2.96 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 15.40% & 1.50\n",
      "for 2018-10-27, MAE is:5.25 & sMAPE is:8.05% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 15.38% & 1.50\n",
      "for 2018-10-28, MAE is:5.10 & sMAPE is:8.34% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 15.35% & 1.49\n",
      "for 2018-10-29, MAE is:8.81 & sMAPE is:11.83% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 15.34% & 1.49\n",
      "for 2018-10-30, MAE is:7.72 & sMAPE is:10.12% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 15.33% & 1.49\n",
      "for 2018-10-31, MAE is:5.41 & sMAPE is:7.81% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 15.30% & 1.49\n",
      "for 2018-11-01, MAE is:7.26 & sMAPE is:11.95% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 15.29% & 1.49\n",
      "for 2018-11-02, MAE is:6.66 & sMAPE is:11.22% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 15.28% & 1.48\n",
      "for 2018-11-03, MAE is:11.52 & sMAPE is:20.05% & rMAE is:1.90 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 15.29% & 1.49\n",
      "for 2018-11-04, MAE is:8.30 & sMAPE is:15.03% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 15.29% & 1.48\n",
      "for 2018-11-05, MAE is:6.90 & sMAPE is:11.06% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 15.28% & 1.48\n",
      "for 2018-11-06, MAE is:6.84 & sMAPE is:11.94% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 15.27% & 1.48\n",
      "for 2018-11-07, MAE is:7.23 & sMAPE is:13.01% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.52 & 15.26% & 1.48\n",
      "for 2018-11-08, MAE is:6.35 & sMAPE is:10.34% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 15.24% & 1.47\n",
      "for 2018-11-09, MAE is:4.68 & sMAPE is:8.09% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 15.22% & 1.47\n",
      "for 2018-11-10, MAE is:3.35 & sMAPE is:6.91% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 15.19% & 1.47\n",
      "for 2018-11-11, MAE is:4.44 & sMAPE is:10.44% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 15.18% & 1.47\n",
      "for 2018-11-12, MAE is:9.90 & sMAPE is:17.08% & rMAE is:3.12 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 15.19% & 1.47\n",
      "for 2018-11-13, MAE is:6.99 & sMAPE is:11.20% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 15.17% & 1.47\n",
      "for 2018-11-14, MAE is:5.66 & sMAPE is:8.93% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 15.15% & 1.47\n",
      "for 2018-11-15, MAE is:4.98 & sMAPE is:8.01% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 15.13% & 1.47\n",
      "for 2018-11-16, MAE is:6.00 & sMAPE is:9.81% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 15.11% & 1.47\n",
      "for 2018-11-17, MAE is:6.10 & sMAPE is:10.31% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 15.10% & 1.46\n",
      "for 2018-11-18, MAE is:5.08 & sMAPE is:8.81% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 15.08% & 1.46\n",
      "for 2018-11-19, MAE is:3.92 & sMAPE is:5.66% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 15.05% & 1.45\n",
      "for 2018-11-20, MAE is:6.25 & sMAPE is:8.71% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 15.03% & 1.45\n",
      "for 2018-11-21, MAE is:5.33 & sMAPE is:6.61% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 15.01% & 1.45\n",
      "for 2018-11-22, MAE is:8.36 & sMAPE is:10.06% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 14.99% & 1.45\n",
      "for 2018-11-23, MAE is:10.96 & sMAPE is:13.06% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 14.98% & 1.44\n",
      "for 2018-11-24, MAE is:5.33 & sMAPE is:8.18% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 14.96% & 1.44\n",
      "for 2018-11-25, MAE is:2.67 & sMAPE is:4.18% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 14.93% & 1.44\n",
      "for 2018-11-26, MAE is:5.83 & sMAPE is:8.34% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 14.91% & 1.44\n",
      "for 2018-11-27, MAE is:12.47 & sMAPE is:14.97% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 14.91% & 1.44\n",
      "for 2018-11-28, MAE is:6.68 & sMAPE is:9.71% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 14.90% & 1.44\n",
      "for 2018-11-29, MAE is:3.22 & sMAPE is:5.26% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 14.87% & 1.43\n",
      "for 2018-11-30, MAE is:3.86 & sMAPE is:6.45% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 14.84% & 1.43\n",
      "for 2018-12-01, MAE is:5.39 & sMAPE is:9.47% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 14.82% & 1.43\n",
      "for 2018-12-02, MAE is:4.35 & sMAPE is:8.23% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 14.81% & 1.42\n",
      "for 2018-12-03, MAE is:4.25 & sMAPE is:7.52% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 14.78% & 1.42\n",
      "for 2018-12-04, MAE is:4.27 & sMAPE is:7.68% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 14.76% & 1.42\n",
      "for 2018-12-05, MAE is:4.60 & sMAPE is:7.71% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :6.45 & 14.74% & 1.42\n",
      "for 2018-12-06, MAE is:5.15 & sMAPE is:9.43% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.45 & 14.73% & 1.42\n",
      "for 2018-12-07, MAE is:3.81 & sMAPE is:7.32% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.44 & 14.70% & 1.41\n",
      "for 2018-12-08, MAE is:5.56 & sMAPE is:11.59% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.44 & 14.70% & 1.41\n",
      "for 2018-12-09, MAE is:3.70 & sMAPE is:8.92% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.43 & 14.68% & 1.41\n",
      "for 2018-12-10, MAE is:4.58 & sMAPE is:8.46% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :6.43 & 14.66% & 1.41\n",
      "for 2018-12-11, MAE is:5.23 & sMAPE is:9.06% & rMAE is:3.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 14.64% & 1.41\n",
      "for 2018-12-12, MAE is:7.26 & sMAPE is:10.38% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 14.63% & 1.41\n",
      "for 2018-12-13, MAE is:4.67 & sMAPE is:7.12% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 14.61% & 1.41\n",
      "for 2018-12-14, MAE is:9.75 & sMAPE is:13.32% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.43 & 14.61% & 1.41\n",
      "for 2018-12-15, MAE is:3.85 & sMAPE is:6.08% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 14.58% & 1.40\n",
      "for 2018-12-16, MAE is:3.69 & sMAPE is:6.33% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 14.56% & 1.40\n",
      "for 2018-12-17, MAE is:6.22 & sMAPE is:9.44% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 14.54% & 1.40\n",
      "for 2018-12-18, MAE is:4.51 & sMAPE is:7.06% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 14.52% & 1.40\n",
      "for 2018-12-19, MAE is:5.01 & sMAPE is:8.23% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 14.50% & 1.40\n",
      "for 2018-12-20, MAE is:6.07 & sMAPE is:10.12% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 14.49% & 1.40\n",
      "for 2018-12-21, MAE is:5.03 & sMAPE is:8.39% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 14.48% & 1.39\n",
      "for 2018-12-22, MAE is:3.30 & sMAPE is:6.34% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 14.45% & 1.39\n",
      "for 2018-12-23, MAE is:4.73 & sMAPE is:11.95% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 14.45% & 1.39\n",
      "for 2018-12-24, MAE is:7.95 & sMAPE is:17.41% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 14.45% & 1.38\n",
      "for 2018-12-25, MAE is:11.87 & sMAPE is:31.79% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 14.50% & 1.38\n",
      "for 2018-12-26, MAE is:5.36 & sMAPE is:12.41% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 14.50% & 1.38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-12-27, MAE is:11.83 & sMAPE is:21.13% & rMAE is:3.10 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 14.51% & 1.38\n",
      "for 2018-12-28, MAE is:3.10 & sMAPE is:5.46% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 14.49% & 1.38\n",
      "for 2018-12-29, MAE is:5.73 & sMAPE is:10.88% & rMAE is:1.92 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 14.48% & 1.38\n",
      "for 2018-12-30, MAE is:6.62 & sMAPE is:15.66% & rMAE is:2.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 14.48% & 1.39\n",
      "for 2018-12-31, MAE is:4.57 & sMAPE is:8.58% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 14.47% & 1.38\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 18:55:22,746]\u001b[0m A new study created in RDB with name: CH_2019\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:55:38,695]\u001b[0m Trial 1 finished with value: 6.680849832369629 and parameters: {'n_hidden': 4, 'learning_rate': 0.039762695272108045, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07615745319315859, 'dropout_rate_Layer_2': 0.1344937691922071, 'dropout_rate_Layer_3': 0.312337509784965, 'dropout_rate_Layer_4': 0.32094813348458384, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0019703528815709966, 'l1_Layer_2': 0.002878885295682691, 'l1_Layer_3': 0.044433637605456655, 'l1_Layer_4': 0.07916475161402158, 'n_units_Layer_1': 290, 'n_units_Layer_2': 205, 'n_units_Layer_3': 295, 'n_units_Layer_4': 220}. Best is trial 1 with value: 6.680849832369629.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.68 | sMAPE for Validation Set is: 14.57% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 5.77 | sMAPE for Test Set is: 16.03% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 18:55:42,616]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:55:45,256]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:55:48,232]\u001b[0m Trial 0 finished with value: 5.656631866202896 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013512624545246176, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3102087453666555, 'dropout_rate_Layer_2': 0.29967576189609235, 'dropout_rate_Layer_3': 0.033115318099130334, 'dropout_rate_Layer_4': 0.2196512688593915, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.005722615830942671, 'l1_Layer_2': 6.811615060443205e-05, 'l1_Layer_3': 0.032418291746402775, 'l1_Layer_4': 3.4308472007836724e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 195, 'n_units_Layer_3': 95, 'n_units_Layer_4': 265}. Best is trial 0 with value: 5.656631866202896.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.66 | sMAPE for Validation Set is: 12.53% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 4.81 | sMAPE for Test Set is: 13.79% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 18:55:51,063]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.53 | sMAPE for Validation Set is: 12.32% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 4.61 | sMAPE for Test Set is: 13.24% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 18:55:52,280]\u001b[0m Trial 3 finished with value: 5.52933399897492 and parameters: {'n_hidden': 3, 'learning_rate': 0.044987611341627445, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29884644931298193, 'dropout_rate_Layer_2': 0.234150585430428, 'dropout_rate_Layer_3': 0.030139744711223583, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0020982362864549503, 'l1_Layer_2': 0.016764617690001368, 'l1_Layer_3': 0.0035689964724394604, 'n_units_Layer_1': 210, 'n_units_Layer_2': 215, 'n_units_Layer_3': 220}. Best is trial 3 with value: 5.52933399897492.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:55:53,109]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:55:57,082]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:55:59,640]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:56:02,229]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:56:04,372]\u001b[0m Trial 2 finished with value: 5.361592407452993 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013467820941759274, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19527429245412398, 'dropout_rate_Layer_2': 0.2244493285438754, 'dropout_rate_Layer_3': 0.09272504096577326, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002262829830063139, 'l1_Layer_2': 8.482211648981295e-05, 'l1_Layer_3': 0.012982030150509602, 'n_units_Layer_1': 230, 'n_units_Layer_2': 130, 'n_units_Layer_3': 265}. Best is trial 2 with value: 5.361592407452993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.36 | sMAPE for Validation Set is: 11.72% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 5.15 | sMAPE for Test Set is: 15.21% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 18:56:08,729]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:56:08,881]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:56:09,205]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:56:15,072]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:56:18,586]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:56:20,221]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:56:21,071]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:56:26,079]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:56:26,338]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:56:26,590]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:56:33,505]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:56:34,180]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:56:36,298]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:56:42,690]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:56:43,082]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:56:45,584]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:56:47,996]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:56:48,585]\u001b[0m Trial 10 finished with value: 6.763490429368544 and parameters: {'n_hidden': 3, 'learning_rate': 0.012856350582076405, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24935781237708132, 'dropout_rate_Layer_2': 0.1968376397022567, 'dropout_rate_Layer_3': 0.11708175069059999, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4267423896122909e-05, 'l1_Layer_2': 1.4641359864900746e-05, 'l1_Layer_3': 0.09086283087876293, 'n_units_Layer_1': 285, 'n_units_Layer_2': 290, 'n_units_Layer_3': 130}. Best is trial 2 with value: 5.361592407452993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.76 | sMAPE for Validation Set is: 14.25% | rMAE for Validation Set is: 0.87\n",
      "MAE for Test Set is: 4.45 | sMAPE for Test Set is: 12.61% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 18:56:49,093]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:56:52,830]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:56:58,264]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:56:59,605]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:57:02,034]\u001b[0m Trial 31 finished with value: 8.311095601815309 and parameters: {'n_hidden': 3, 'learning_rate': 0.019114719587989278, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15827828014887704, 'dropout_rate_Layer_2': 0.07554262419165006, 'dropout_rate_Layer_3': 0.056367617084084644, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 3.076656192814212e-05, 'l1_Layer_2': 0.00011429271497071606, 'l1_Layer_3': 0.02513697351324454, 'n_units_Layer_1': 125, 'n_units_Layer_2': 250, 'n_units_Layer_3': 260}. Best is trial 2 with value: 5.361592407452993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.31 | sMAPE for Validation Set is: 17.40% | rMAE for Validation Set is: 1.07\n",
      "MAE for Test Set is: 6.75 | sMAPE for Test Set is: 19.15% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 18:57:03,335]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:57:06,790]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:57:08,175]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:57:09,192]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:57:14,048]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:57:14,211]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:57:14,366]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:57:23,109]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:57:24,303]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:57:26,689]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:57:29,160]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:57:29,763]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:57:30,888]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:57:35,200]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:57:37,690]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:57:47,113]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:57:47,410]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:57:49,087]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:57:53,467]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:57:57,113]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:57:57,262]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:57:59,614]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:58:03,794]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:58:07,309]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:58:07,363]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:58:12,108]\u001b[0m Trial 43 finished with value: 5.169147533207188 and parameters: {'n_hidden': 3, 'learning_rate': 0.02308586798761918, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21346359452263344, 'dropout_rate_Layer_2': 0.2484601115090091, 'dropout_rate_Layer_3': 0.03821654573400433, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.2509224877431584e-05, 'l1_Layer_2': 0.00606568550486663, 'l1_Layer_3': 0.0009374190083330291, 'n_units_Layer_1': 170, 'n_units_Layer_2': 105, 'n_units_Layer_3': 140}. Best is trial 43 with value: 5.169147533207188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.17 | sMAPE for Validation Set is: 11.54% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.16 | sMAPE for Test Set is: 15.04% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 18:58:12,806]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:58:13,937]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:58:14,014]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:58:18,347]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:58:19,708]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:58:21,756]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:58:22,023]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:58:27,799]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:58:27,990]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:58:33,394]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:58:33,457]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:58:36,777]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:58:39,549]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:58:41,549]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:58:41,833]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:58:46,685]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:58:47,310]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:58:50,998]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:58:52,433]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:58:55,103]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:58:57,680]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:58:58,186]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:59:01,545]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:59:05,858]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:59:06,379]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:59:06,665]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:59:12,172]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:59:13,841]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:59:14,327]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:59:14,544]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:59:21,899]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:59:22,076]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:59:25,917]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:59:27,098]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:59:28,468]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:59:33,251]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:59:33,590]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:59:38,350]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:59:38,522]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:59:45,486]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:59:49,307]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:59:50,820]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:59:53,026]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:59:54,624]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:59:55,164]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:59:59,676]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:00:01,347]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:00:03,830]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:00:07,137]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:00:07,481]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:00:07,900]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:00:13,292]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:00:15,396]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:00:16,578]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:00:19,114]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:00:22,920]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:00:27,509]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:00:31,710]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:00:33,993]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:00:35,503]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:00:35,953]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:00:35,988]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:00:36,868]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:00:43,477]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:00:44,146]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:00:46,706]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:00:47,573]\u001b[0m Trial 124 finished with value: 7.610366871494599 and parameters: {'n_hidden': 3, 'learning_rate': 0.021000774557782362, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14904573522792983, 'dropout_rate_Layer_2': 0.1443857426368337, 'dropout_rate_Layer_3': 0.3994425140618613, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.655618510584618e-05, 'l1_Layer_2': 0.004944230920873112, 'l1_Layer_3': 0.0002533077848832218, 'n_units_Layer_1': 115, 'n_units_Layer_2': 290, 'n_units_Layer_3': 175}. Best is trial 43 with value: 5.169147533207188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.61 | sMAPE for Validation Set is: 16.43% | rMAE for Validation Set is: 0.98\n",
      "MAE for Test Set is: 6.80 | sMAPE for Test Set is: 17.43% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:00:49,605]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:00:51,621]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:00:55,313]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:00:56,013]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:00:59,329]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:01:00,620]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:01:01,071]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:01:07,055]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:01:07,404]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:01:11,672]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:01:22,183]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:01:29,078]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:01:33,307]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:01:36,739]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:02:03,449]\u001b[0m Trial 132 finished with value: 5.3166781659099644 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005398669301917099, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3236537477877122, 'dropout_rate_Layer_2': 0.20896504140499458, 'dropout_rate_Layer_3': 0.11483909401638609, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006031646744058159, 'l1_Layer_2': 0.09892657810376793, 'l1_Layer_3': 0.000659753183686318, 'n_units_Layer_1': 245, 'n_units_Layer_2': 100, 'n_units_Layer_3': 300}. Best is trial 43 with value: 5.169147533207188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.32 | sMAPE for Validation Set is: 11.97% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.31 | sMAPE for Test Set is: 12.53% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:02:07,046]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:02:07,909]\u001b[0m Trial 135 finished with value: 13.960654835807548 and parameters: {'n_hidden': 4, 'learning_rate': 0.08425633210236201, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39571513263505753, 'dropout_rate_Layer_2': 0.28832413307992494, 'dropout_rate_Layer_3': 0.2822703931254706, 'dropout_rate_Layer_4': 0.37268773423854645, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00016324228956238177, 'l1_Layer_2': 0.03304628064286566, 'l1_Layer_3': 0.00029872995986855125, 'l1_Layer_4': 0.0781634211095416, 'n_units_Layer_1': 200, 'n_units_Layer_2': 50, 'n_units_Layer_3': 195, 'n_units_Layer_4': 75}. Best is trial 43 with value: 5.169147533207188.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.96 | sMAPE for Validation Set is: 29.35% | rMAE for Validation Set is: 1.80\n",
      "MAE for Test Set is: 8.22 | sMAPE for Test Set is: 22.32% | rMAE for Test Set is: 1.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:02:11,747]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:02:18,169]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:02:25,575]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:02:28,353]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:02:28,798]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:02:33,185]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:02:36,008]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:02:36,240]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:02:36,402]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:02:36,688]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:02:41,671]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:02:46,710]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:02:47,228]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:02:47,267]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:02:47,891]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:02:52,540]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:02:55,515]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:02:56,295]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:02:57,416]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:02:58,454]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:03:03,778]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:03:05,254]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:03:05,868]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:03:06,727]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:03:11,863]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:03:13,924]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:03:15,746]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:03:15,990]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:03:22,106]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:03:25,655]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:03:25,770]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:03:26,621]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:03:32,359]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:03:32,852]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:03:38,144]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:03:38,487]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:03:41,397]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:03:44,428]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:03:45,028]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:03:47,237]\u001b[0m Trial 174 finished with value: 5.141800956672796 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012643647674713463, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20707060257945187, 'dropout_rate_Layer_2': 0.3243354140713942, 'dropout_rate_Layer_3': 0.14735279773903306, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006863476992803092, 'l1_Layer_2': 0.0012307025319775102, 'l1_Layer_3': 0.0003065921838434958, 'n_units_Layer_1': 195, 'n_units_Layer_2': 65, 'n_units_Layer_3': 235}. Best is trial 174 with value: 5.141800956672796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.14 | sMAPE for Validation Set is: 11.39% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.20 | sMAPE for Test Set is: 12.25% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:03:48,896]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:03:50,913]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:03:51,183]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:03:55,439]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:03:55,965]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:04:00,409]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:04:03,544]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:04:06,075]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:04:08,671]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:04:10,770]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:04:11,847]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:04:19,006]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:04:26,727]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:04:28,221]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:04:32,601]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:04:32,625]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:04:38,516]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:04:38,891]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.46 | sMAPE for Validation Set is: 11.86% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 4.20 | sMAPE for Test Set is: 12.13% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:04:43,047]\u001b[0m Trial 197 finished with value: 5.457324575165797 and parameters: {'n_hidden': 3, 'learning_rate': 0.010888868709802407, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3417932012085662, 'dropout_rate_Layer_2': 0.012734443357736741, 'dropout_rate_Layer_3': 0.0019271569088478435, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006999968999474725, 'l1_Layer_2': 0.004344099069355433, 'l1_Layer_3': 1.2026046268271857e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 110, 'n_units_Layer_3': 235}. Best is trial 174 with value: 5.141800956672796.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:04:45,833]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:04:46,077]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:04:50,930]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:04:55,724]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:04:56,116]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:04:58,453]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:05:03,370]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:05:03,664]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:05:04,392]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:05:10,746]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:05:11,278]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:05:16,750]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:05:17,133]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:05:17,283]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:05:23,066]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:05:24,741]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:05:24,874]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:05:26,010]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:05:31,284]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:05:32,670]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:05:33,455]\u001b[0m Trial 206 finished with value: 4.916205940885917 and parameters: {'n_hidden': 4, 'learning_rate': 0.001890128330495002, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3710896946337723, 'dropout_rate_Layer_2': 0.25733170871191824, 'dropout_rate_Layer_3': 0.317113204178777, 'dropout_rate_Layer_4': 0.26453362738360514, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002656310858090641, 'l1_Layer_2': 7.547872071933997e-05, 'l1_Layer_3': 0.0017531997472090386, 'l1_Layer_4': 0.0001497136714467538, 'n_units_Layer_1': 285, 'n_units_Layer_2': 210, 'n_units_Layer_3': 280, 'n_units_Layer_4': 230}. Best is trial 206 with value: 4.916205940885917.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.92 | sMAPE for Validation Set is: 10.96% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.21 | sMAPE for Test Set is: 12.18% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:05:34,169]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:05:34,290]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:05:42,081]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:05:43,607]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:05:46,749]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:05:46,905]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:05:53,028]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:05:53,610]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:05:58,967]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:05:59,688]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:06:01,592]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:06:06,804]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:06:07,371]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:06:07,679]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:06:14,679]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:06:15,194]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:06:15,466]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:06:21,339]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:06:24,985]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:06:26,468]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:06:30,744]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:06:31,132]\u001b[0m Trial 236 finished with value: 4.9569412799032495 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009217541328042704, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18569671983835503, 'dropout_rate_Layer_2': 0.19986169190218886, 'dropout_rate_Layer_3': 0.15988731306765086, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0029607240100425103, 'l1_Layer_2': 4.490509488236472e-05, 'l1_Layer_3': 9.670212158740225e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 115, 'n_units_Layer_3': 280}. Best is trial 206 with value: 4.916205940885917.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:06:31,152]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.96 | sMAPE for Validation Set is: 11.01% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 3.88 | sMAPE for Test Set is: 11.27% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:06:38,099]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:06:39,325]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:06:39,477]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:06:46,286]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:06:47,064]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:06:51,994]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:06:52,233]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:06:52,740]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:06:59,937]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:07:01,453]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:07:04,041]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:07:05,130]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:07:10,081]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:07:13,585]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:07:13,875]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:07:20,933]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:07:21,836]\u001b[0m Trial 253 finished with value: 5.3041579433704 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008248755042706945, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3985763362677507, 'dropout_rate_Layer_2': 0.27440490423759756, 'dropout_rate_Layer_3': 0.15647622607972406, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01970889737492481, 'l1_Layer_2': 0.02746845729130527, 'l1_Layer_3': 0.0001214696877227013, 'n_units_Layer_1': 270, 'n_units_Layer_2': 95, 'n_units_Layer_3': 225}. Best is trial 206 with value: 4.916205940885917.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.30 | sMAPE for Validation Set is: 11.83% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.14 | sMAPE for Test Set is: 11.94% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:07:28,131]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:07:29,715]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:07:35,975]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:07:43,128]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:07:46,455]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:07:49,346]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:07:51,319]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:07:55,191]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:07:58,759]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:08:01,666]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:08:05,138]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:08:09,003]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:08:16,773]\u001b[0m Trial 265 finished with value: 4.867983882884517 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007469567471572782, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2595609089084918, 'dropout_rate_Layer_2': 0.27661568750631543, 'dropout_rate_Layer_3': 0.21672218438941726, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0031987116976709483, 'l1_Layer_2': 0.03147041368368229, 'l1_Layer_3': 2.437072886766784e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 170, 'n_units_Layer_3': 280}. Best is trial 265 with value: 4.867983882884517.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.87 | sMAPE for Validation Set is: 10.87% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.14 | sMAPE for Test Set is: 12.12% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:08:20,774]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:08:21,545]\u001b[0m Trial 276 finished with value: 5.0762439293301975 and parameters: {'n_hidden': 3, 'learning_rate': 0.003002298764147651, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13043583963405908, 'dropout_rate_Layer_2': 0.30937567355575835, 'dropout_rate_Layer_3': 0.29222469779801497, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013832538543895366, 'l1_Layer_2': 0.010478391015612838, 'l1_Layer_3': 0.0008677832257234534, 'n_units_Layer_1': 170, 'n_units_Layer_2': 255, 'n_units_Layer_3': 115}. Best is trial 265 with value: 4.867983882884517.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.08 | sMAPE for Validation Set is: 11.14% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.28 | sMAPE for Test Set is: 12.12% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:08:24,290]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:08:29,752]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:08:35,136]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:08:38,623]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:08:48,568]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:08:48,925]\u001b[0m Trial 281 finished with value: 5.151514199246242 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016798793263325313, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10667559600264229, 'dropout_rate_Layer_2': 0.2422043019526437, 'dropout_rate_Layer_3': 0.36400590424803747, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004136911407218024, 'l1_Layer_2': 0.0018779775217149354, 'l1_Layer_3': 0.0009773810791213272, 'n_units_Layer_1': 200, 'n_units_Layer_2': 255, 'n_units_Layer_3': 115}. Best is trial 265 with value: 4.867983882884517.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.15 | sMAPE for Validation Set is: 11.41% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 4.20 | sMAPE for Test Set is: 12.07% | rMAE for Test Set is: 0.68\n",
      "MAE for Validation Set is: 5.10 | sMAPE for Validation Set is: 11.46% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.57 | sMAPE for Test Set is: 13.22% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:08:50,766]\u001b[0m Trial 268 finished with value: 5.100658143476846 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005119548052690224, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21910554725509213, 'dropout_rate_Layer_2': 0.20946909115869797, 'dropout_rate_Layer_3': 0.17408644676991905, 'dropout_rate_Layer_4': 0.01138684767584669, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.01905409794734525, 'l1_Layer_2': 0.015079888335321843, 'l1_Layer_3': 5.076232113054798e-05, 'l1_Layer_4': 1.9243383739321022e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 80, 'n_units_Layer_3': 165, 'n_units_Layer_4': 300}. Best is trial 265 with value: 4.867983882884517.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:08:55,132]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:08:55,610]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:08:57,327]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:09:03,592]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:09:04,726]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:09:11,847]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:09:11,882]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:09:18,018]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:09:18,602]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:09:22,756]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:09:23,489]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:09:27,725]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:09:28,154]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:09:33,546]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:09:34,391]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:09:35,795]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:09:38,728]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:09:43,366]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:09:43,721]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:09:48,492]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:09:52,069]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:09:55,792]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:09:57,693]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:10:01,076]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:10:01,446]\u001b[0m Trial 286 finished with value: 4.785808165379743 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007391068190706243, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25613504294625755, 'dropout_rate_Layer_2': 0.3638084051342163, 'dropout_rate_Layer_3': 0.22617891858757266, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004130103959292284, 'l1_Layer_2': 0.006689192468951869, 'l1_Layer_3': 0.00018513903090710925, 'n_units_Layer_1': 245, 'n_units_Layer_2': 185, 'n_units_Layer_3': 230}. Best is trial 286 with value: 4.785808165379743.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.79 | sMAPE for Validation Set is: 10.69% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 3.99 | sMAPE for Test Set is: 11.63% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:10:06,557]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:10:10,070]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:10:11,611]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:10:15,687]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:10:19,477]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:10:21,294]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:10:23,841]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:10:24,549]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:10:27,196]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:10:29,907]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:10:31,292]\u001b[0m Trial 311 finished with value: 4.816481934037733 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012716441371439984, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1404660707029458, 'dropout_rate_Layer_2': 0.3026100394954094, 'dropout_rate_Layer_3': 0.25311893309983946, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0046515439143398314, 'l1_Layer_2': 0.0014531671847393401, 'l1_Layer_3': 0.0002634340339543567, 'n_units_Layer_1': 235, 'n_units_Layer_2': 150, 'n_units_Layer_3': 265}. Best is trial 286 with value: 4.785808165379743.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.82 | sMAPE for Validation Set is: 10.82% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.17 | sMAPE for Test Set is: 12.08% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:10:35,475]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:10:36,007]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:10:38,675]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:10:39,144]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:10:42,702]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:10:44,143]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:10:46,454]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:10:47,710]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:10:51,567]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:10:52,023]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:10:56,353]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:11:01,740]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:11:02,428]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:11:07,803]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:11:08,030]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:11:14,361]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:11:14,654]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:11:20,747]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:11:28,871]\u001b[0m Trial 332 finished with value: 4.773287699528914 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015744633983457207, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39589511667814986, 'dropout_rate_Layer_2': 0.0916330264564075, 'dropout_rate_Layer_3': 0.3992902842891545, 'dropout_rate_Layer_4': 0.2343679036297619, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0030979358748703706, 'l1_Layer_2': 9.49862613300319e-05, 'l1_Layer_3': 0.0048198710273993205, 'l1_Layer_4': 2.1870560827634027e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 105, 'n_units_Layer_3': 235, 'n_units_Layer_4': 215}. Best is trial 332 with value: 4.773287699528914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.77 | sMAPE for Validation Set is: 10.69% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.02 | sMAPE for Test Set is: 11.63% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:11:31,909]\u001b[0m Trial 337 finished with value: 4.650608253328051 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017078604310910423, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3485799243038523, 'dropout_rate_Layer_2': 0.06914021445513792, 'dropout_rate_Layer_3': 0.04543786632137344, 'dropout_rate_Layer_4': 0.19172871560925955, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.005411639928391504, 'l1_Layer_2': 8.790787216776067e-05, 'l1_Layer_3': 0.003598436900572146, 'l1_Layer_4': 3.4688318440633316e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 100, 'n_units_Layer_3': 285, 'n_units_Layer_4': 225}. Best is trial 337 with value: 4.650608253328051.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.65 | sMAPE for Validation Set is: 10.45% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.10 | sMAPE for Test Set is: 11.89% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:11:35,399]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:11:40,055]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:11:43,858]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:11:46,698]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:11:50,609]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:11:53,743]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:11:54,983]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:11:59,884]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:12:00,012]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:12:07,577]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:12:23,703]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:12:41,340]\u001b[0m Trial 355 finished with value: 4.853815256017547 and parameters: {'n_hidden': 3, 'learning_rate': 0.001164686303319702, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1407114578942947, 'dropout_rate_Layer_2': 0.30093269272012374, 'dropout_rate_Layer_3': 0.2640003645252739, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0016708415230777532, 'l1_Layer_2': 0.008779123293394446, 'l1_Layer_3': 0.00040278421365608945, 'n_units_Layer_1': 230, 'n_units_Layer_2': 140, 'n_units_Layer_3': 260}. Best is trial 337 with value: 4.650608253328051.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.85 | sMAPE for Validation Set is: 10.88% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.14 | sMAPE for Test Set is: 12.00% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:12:41,773]\u001b[0m Trial 343 finished with value: 6.784265246426816 and parameters: {'n_hidden': 4, 'learning_rate': 0.02844931945097495, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3681657031464618, 'dropout_rate_Layer_2': 0.3294620489674809, 'dropout_rate_Layer_3': 0.16022764192261532, 'dropout_rate_Layer_4': 0.0847493346322779, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0023774663707761684, 'l1_Layer_2': 0.0026686647534728534, 'l1_Layer_3': 2.8968038280406298e-05, 'l1_Layer_4': 0.004205789917194512, 'n_units_Layer_1': 180, 'n_units_Layer_2': 85, 'n_units_Layer_3': 210, 'n_units_Layer_4': 250}. Best is trial 337 with value: 4.650608253328051.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.78 | sMAPE for Validation Set is: 14.59% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 4.79 | sMAPE for Test Set is: 13.71% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:12:46,344]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:12:48,150]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:12:54,864]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:12:58,498]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:13:03,846]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:13:10,456]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:13:15,708]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:13:17,967]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:13:20,352]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:13:23,018]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:13:26,881]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:13:27,088]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.51 | sMAPE for Validation Set is: 12.17% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 4.40 | sMAPE for Test Set is: 12.56% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:13:31,022]\u001b[0m Trial 341 finished with value: 5.5052892525458015 and parameters: {'n_hidden': 4, 'learning_rate': 0.004156768811684471, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34927027868289207, 'dropout_rate_Layer_2': 0.3453831711809596, 'dropout_rate_Layer_3': 0.15893556222590674, 'dropout_rate_Layer_4': 0.08356985989477528, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.003037758618411361, 'l1_Layer_2': 0.003064712189399985, 'l1_Layer_3': 1.0141891447526314e-05, 'l1_Layer_4': 0.004312820069400628, 'n_units_Layer_1': 175, 'n_units_Layer_2': 95, 'n_units_Layer_3': 205, 'n_units_Layer_4': 235}. Best is trial 337 with value: 4.650608253328051.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:13:36,138]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:13:36,379]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:13:36,921]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:13:42,897]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:13:46,406]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:13:46,764]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:13:52,004]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:13:56,223]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:13:58,499]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:13:58,547]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:13:58,835]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:14:05,460]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:14:08,717]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:14:08,742]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:14:09,939]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:14:13,727]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:14:15,833]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:14:17,692]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:14:21,838]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:14:23,433]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:14:26,914]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:14:30,318]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:14:30,488]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:14:31,229]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:14:38,518]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:14:38,935]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:14:41,326]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:14:46,069]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:14:46,579]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:14:47,447]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:14:53,326]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:14:53,939]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:14:54,834]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:14:59,495]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:15:01,679]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:15:04,137]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:15:07,565]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:15:09,703]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:15:15,758]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:15:19,507]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:15:22,411]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:15:26,259]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:15:27,682]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:15:30,428]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:15:33,038]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:15:48,466]\u001b[0m Trial 389 finished with value: 4.828013058263719 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033521948513926592, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.140495105188263, 'dropout_rate_Layer_2': 0.193805223038266, 'dropout_rate_Layer_3': 0.03827761931532753, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00024398900703239646, 'l1_Layer_2': 0.020821604624953367, 'l1_Layer_3': 0.0020706707186532534, 'n_units_Layer_1': 100, 'n_units_Layer_2': 265, 'n_units_Layer_3': 145}. Best is trial 337 with value: 4.650608253328051.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.83 | sMAPE for Validation Set is: 10.68% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.24 | sMAPE for Test Set is: 12.33% | rMAE for Test Set is: 0.69\n",
      "MAE for Validation Set is: 4.82 | sMAPE for Validation Set is: 10.77% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.30 | sMAPE for Test Set is: 12.38% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:15:50,102]\u001b[0m Trial 407 finished with value: 4.8186342695261075 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030360461635368227, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.176739209787034, 'dropout_rate_Layer_2': 0.24604296913557655, 'dropout_rate_Layer_3': 0.12718040506435646, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005061342008687823, 'l1_Layer_2': 0.013999356479070853, 'l1_Layer_3': 0.0011535004267655706, 'n_units_Layer_1': 115, 'n_units_Layer_2': 285, 'n_units_Layer_3': 215}. Best is trial 337 with value: 4.650608253328051.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:15:52,949]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:15:59,097]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:16:02,888]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:16:07,713]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:16:39,094]\u001b[0m Trial 420 finished with value: 4.679067104746288 and parameters: {'n_hidden': 3, 'learning_rate': 0.003931090068435422, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12611145452805944, 'dropout_rate_Layer_2': 0.22247879612066104, 'dropout_rate_Layer_3': 0.002908985968556564, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003796172117155507, 'l1_Layer_2': 0.008173826281698148, 'l1_Layer_3': 0.001517879144449113, 'n_units_Layer_1': 90, 'n_units_Layer_2': 265, 'n_units_Layer_3': 240}. Best is trial 337 with value: 4.650608253328051.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.68 | sMAPE for Validation Set is: 10.35% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.00 | sMAPE for Test Set is: 11.53% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:16:49,916]\u001b[0m Trial 419 finished with value: 4.9923013057611065 and parameters: {'n_hidden': 3, 'learning_rate': 0.003017088958467676, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17972492243606375, 'dropout_rate_Layer_2': 0.20654828713173704, 'dropout_rate_Layer_3': 0.02499162700484136, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00023314307619252362, 'l1_Layer_2': 0.029144264385090136, 'l1_Layer_3': 0.0012626216039204653, 'n_units_Layer_1': 115, 'n_units_Layer_2': 265, 'n_units_Layer_3': 135}. Best is trial 337 with value: 4.650608253328051.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.99 | sMAPE for Validation Set is: 10.95% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 4.20 | sMAPE for Test Set is: 12.23% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:16:53,543]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:16:57,711]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:17:02,254]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:17:08,010]\u001b[0m Trial 415 finished with value: 5.153904335583166 and parameters: {'n_hidden': 4, 'learning_rate': 0.001552584917919555, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3410880021319015, 'dropout_rate_Layer_2': 0.3359976009246399, 'dropout_rate_Layer_3': 0.18462595217828487, 'dropout_rate_Layer_4': 0.05769453200590749, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0023415512713983754, 'l1_Layer_2': 0.0034659739389794266, 'l1_Layer_3': 4.75921853645155e-05, 'l1_Layer_4': 0.001365969308353433, 'n_units_Layer_1': 160, 'n_units_Layer_2': 95, 'n_units_Layer_3': 180, 'n_units_Layer_4': 255}. Best is trial 337 with value: 4.650608253328051.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.15 | sMAPE for Validation Set is: 11.51% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 4.45 | sMAPE for Test Set is: 12.77% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:17:14,898]\u001b[0m Trial 422 finished with value: 4.760150981251311 and parameters: {'n_hidden': 3, 'learning_rate': 0.0038192904530026115, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1289115981539514, 'dropout_rate_Layer_2': 0.223996859027262, 'dropout_rate_Layer_3': 0.14720201828327475, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00035734271814776795, 'l1_Layer_2': 0.0077872262463021215, 'l1_Layer_3': 0.0014422342069021744, 'n_units_Layer_1': 90, 'n_units_Layer_2': 260, 'n_units_Layer_3': 225}. Best is trial 337 with value: 4.650608253328051.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.76 | sMAPE for Validation Set is: 10.67% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.22 | sMAPE for Test Set is: 12.20% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:17:18,459]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:17:22,530]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:17:29,774]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:17:41,760]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:17:47,754]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:17:49,802]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:17:52,221]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:17:53,113]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:17:55,157]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:17:57,467]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:17:59,960]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:18:04,518]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:18:16,032]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:18:19,384]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:18:23,169]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:18:26,711]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:18:31,379]\u001b[0m Trial 428 finished with value: 4.797738419018644 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021226950523160052, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1557380434614342, 'dropout_rate_Layer_2': 0.1947270939073786, 'dropout_rate_Layer_3': 0.0010085775070212306, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00017829459255084074, 'l1_Layer_2': 0.013919416953322135, 'l1_Layer_3': 0.0012991515082036015, 'n_units_Layer_1': 70, 'n_units_Layer_2': 265, 'n_units_Layer_3': 250}. Best is trial 337 with value: 4.650608253328051.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.80 | sMAPE for Validation Set is: 10.60% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.19 | sMAPE for Test Set is: 12.05% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:18:35,551]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:18:41,425]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:18:44,578]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:18:48,163]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:18:51,576]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:19:00,942]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:19:05,357]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:19:10,847]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:19:15,451]\u001b[0m Trial 440 finished with value: 4.690162066787315 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018955255080231543, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18028612337539818, 'dropout_rate_Layer_2': 0.22255207231668558, 'dropout_rate_Layer_3': 0.02779693766675262, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001855672150802656, 'l1_Layer_2': 0.024892966018018114, 'l1_Layer_3': 0.0008589043657154194, 'n_units_Layer_1': 105, 'n_units_Layer_2': 270, 'n_units_Layer_3': 225}. Best is trial 337 with value: 4.650608253328051.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.69 | sMAPE for Validation Set is: 10.38% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.28 | sMAPE for Test Set is: 12.29% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:19:17,143]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:19:21,443]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:19:22,969]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:19:41,865]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:19:47,686]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:20:02,899]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:20:03,644]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:20:07,618]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:20:08,045]\u001b[0m Trial 445 finished with value: 4.634316738388837 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019281921170764028, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14592562105925153, 'dropout_rate_Layer_2': 0.16795244056281192, 'dropout_rate_Layer_3': 0.026800193379762707, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00043270177999795123, 'l1_Layer_2': 0.015016985554015564, 'l1_Layer_3': 0.002509234041930563, 'n_units_Layer_1': 70, 'n_units_Layer_2': 215, 'n_units_Layer_3': 225}. Best is trial 445 with value: 4.634316738388837.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.63 | sMAPE for Validation Set is: 10.45% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.18 | sMAPE for Test Set is: 12.19% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:20:09,717]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:20:14,048]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:20:14,974]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:20:18,629]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:20:21,462]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:20:25,619]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:20:28,353]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:20:28,925]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:20:32,843]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:20:38,522]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:20:42,629]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:20:47,138]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:20:48,809]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:20:52,899]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:20:55,768]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:20:58,790]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:21:04,608]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:21:08,765]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:21:12,014]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:21:14,738]\u001b[0m Trial 457 finished with value: 4.9319314289270615 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010886372646892464, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27622005553477375, 'dropout_rate_Layer_2': 0.39343175550924436, 'dropout_rate_Layer_3': 0.2371374984520978, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.01287416187704053, 'l1_Layer_2': 0.004040330704691196, 'l1_Layer_3': 6.073684153527394e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 120, 'n_units_Layer_3': 250}. Best is trial 445 with value: 4.634316738388837.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.93 | sMAPE for Validation Set is: 10.94% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.22 | sMAPE for Test Set is: 12.30% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:21:16,887]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:21:20,105]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:21:22,992]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:21:29,513]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:21:37,843]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:22:11,349]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:22:20,355]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:22:27,732]\u001b[0m Trial 478 finished with value: 5.118582517443644 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012038638299183384, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16566409455673695, 'dropout_rate_Layer_2': 0.1420946517207663, 'dropout_rate_Layer_3': 0.012422519184717852, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.102241713577752e-05, 'l1_Layer_2': 0.008941238183642638, 'l1_Layer_3': 0.001417307942513986, 'n_units_Layer_1': 75, 'n_units_Layer_2': 275, 'n_units_Layer_3': 225}. Best is trial 445 with value: 4.634316738388837.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.12 | sMAPE for Validation Set is: 11.26% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.52 | sMAPE for Test Set is: 12.94% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:22:37,191]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:22:45,993]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:22:51,058]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:22:55,174]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:22:59,907]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:23:02,585]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:23:08,329]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:23:08,606]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:23:14,964]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:23:22,297]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:23:55,869]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:23:59,382]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:24:06,635]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:24:10,220]\u001b[0m Trial 502 finished with value: 4.8528181542675375 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013963625208479613, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10017472574205691, 'dropout_rate_Layer_2': 0.016502744550436335, 'dropout_rate_Layer_3': 0.015671247146197897, 'dropout_rate_Layer_4': 0.032430509328471746, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00627843029429948, 'l1_Layer_2': 1.7379612569250645e-05, 'l1_Layer_3': 0.0003823014636427356, 'l1_Layer_4': 6.896052063866585e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 300, 'n_units_Layer_3': 260, 'n_units_Layer_4': 285}. Best is trial 445 with value: 4.634316738388837.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.85 | sMAPE for Validation Set is: 10.76% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.25 | sMAPE for Test Set is: 12.35% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:24:15,133]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:24:19,146]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:24:31,421]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:24:38,824]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:24:50,407]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:24:54,617]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:25:10,856]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:25:14,800]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:25:24,696]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:25:31,246]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:25:35,748]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:25:39,622]\u001b[0m Trial 511 finished with value: 4.736846955515154 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011731779455568135, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07425147325696714, 'dropout_rate_Layer_2': 0.010038296326218728, 'dropout_rate_Layer_3': 0.018649881616392333, 'dropout_rate_Layer_4': 0.03752759923712036, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.009336638565688758, 'l1_Layer_2': 1.731842081333335e-05, 'l1_Layer_3': 0.00037112566505379625, 'l1_Layer_4': 8.729101947647286e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 295, 'n_units_Layer_3': 265, 'n_units_Layer_4': 290}. Best is trial 445 with value: 4.634316738388837.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.74 | sMAPE for Validation Set is: 10.56% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.08 | sMAPE for Test Set is: 11.91% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:25:45,706]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:25:53,158]\u001b[0m Trial 496 finished with value: 5.4493046064660975 and parameters: {'n_hidden': 4, 'learning_rate': 0.001011210788037859, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2383493018606964, 'dropout_rate_Layer_2': 0.31690288540067196, 'dropout_rate_Layer_3': 0.19267566150761595, 'dropout_rate_Layer_4': 0.040441155206689644, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.04545547080690304, 'l1_Layer_2': 0.001560847121031162, 'l1_Layer_3': 0.00010267947007978385, 'l1_Layer_4': 0.0016324590706018325, 'n_units_Layer_1': 155, 'n_units_Layer_2': 50, 'n_units_Layer_3': 95, 'n_units_Layer_4': 185}. Best is trial 445 with value: 4.634316738388837.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.45 | sMAPE for Validation Set is: 12.08% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 4.70 | sMAPE for Test Set is: 13.64% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:26:04,541]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:26:26,313]\u001b[0m Trial 518 finished with value: 4.638730493790611 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009202312612826828, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07269068232140163, 'dropout_rate_Layer_2': 0.0025393282336276125, 'dropout_rate_Layer_3': 0.00029827972247035636, 'dropout_rate_Layer_4': 0.02053742878650164, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.010674584076919392, 'l1_Layer_2': 1.1016657126281453e-05, 'l1_Layer_3': 0.0003410123439105824, 'l1_Layer_4': 9.114442004998174e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 300, 'n_units_Layer_3': 260, 'n_units_Layer_4': 290}. Best is trial 445 with value: 4.634316738388837.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.64 | sMAPE for Validation Set is: 10.42% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.36 | sMAPE for Test Set is: 12.83% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:26:32,276]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:26:36,919]\u001b[0m Trial 520 finished with value: 4.728779138701811 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010496728230549787, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07972638721580631, 'dropout_rate_Layer_2': 0.007503452285143729, 'dropout_rate_Layer_3': 0.01598842467708798, 'dropout_rate_Layer_4': 0.041556354269144655, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.011730848018151498, 'l1_Layer_2': 1.3896344448235788e-05, 'l1_Layer_3': 0.00027694621799075053, 'l1_Layer_4': 9.39976553934061e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 300, 'n_units_Layer_3': 260, 'n_units_Layer_4': 285}. Best is trial 445 with value: 4.634316738388837.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.73 | sMAPE for Validation Set is: 10.53% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.11 | sMAPE for Test Set is: 11.97% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:26:39,915]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:26:47,145]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:26:50,150]\u001b[0m Trial 521 finished with value: 4.718654422142875 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010681686827459945, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07661336002091075, 'dropout_rate_Layer_2': 0.011423953068865414, 'dropout_rate_Layer_3': 0.0011569489994472867, 'dropout_rate_Layer_4': 0.020164019714731894, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00959748912939433, 'l1_Layer_2': 1.5064981157858076e-05, 'l1_Layer_3': 0.00029764603379305683, 'l1_Layer_4': 0.0001023120617882549, 'n_units_Layer_1': 225, 'n_units_Layer_2': 300, 'n_units_Layer_3': 260, 'n_units_Layer_4': 285}. Best is trial 445 with value: 4.634316738388837.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.72 | sMAPE for Validation Set is: 10.54% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.32 | sMAPE for Test Set is: 12.55% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:27:10,611]\u001b[0m Trial 524 finished with value: 4.592746872466814 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008950176022053159, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.059354366207512006, 'dropout_rate_Layer_2': 0.009319866163933928, 'dropout_rate_Layer_3': 0.007140131903401145, 'dropout_rate_Layer_4': 0.018625220068520392, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.01187642915343426, 'l1_Layer_2': 1.420300742202488e-05, 'l1_Layer_3': 0.00034198736063052965, 'l1_Layer_4': 0.00010586709350799252, 'n_units_Layer_1': 240, 'n_units_Layer_2': 300, 'n_units_Layer_3': 260, 'n_units_Layer_4': 285}. Best is trial 524 with value: 4.592746872466814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.59 | sMAPE for Validation Set is: 10.27% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.05 | sMAPE for Test Set is: 11.83% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:27:17,975]\u001b[0m Trial 522 finished with value: 4.618967794768194 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008696731960317109, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07657279263536079, 'dropout_rate_Layer_2': 0.007718087894590747, 'dropout_rate_Layer_3': 0.008116122880165364, 'dropout_rate_Layer_4': 0.01371402595044268, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.011911195595336675, 'l1_Layer_2': 1.663138162131666e-05, 'l1_Layer_3': 0.0003835559089669842, 'l1_Layer_4': 9.450606980508968e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 300, 'n_units_Layer_3': 260, 'n_units_Layer_4': 295}. Best is trial 524 with value: 4.592746872466814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.62 | sMAPE for Validation Set is: 10.32% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.10 | sMAPE for Test Set is: 11.98% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:27:22,895]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:27:28,641]\u001b[0m Trial 526 finished with value: 4.591675946601499 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008874557615768514, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08118610154200208, 'dropout_rate_Layer_2': 0.0044948563468132086, 'dropout_rate_Layer_3': 0.014226632452396918, 'dropout_rate_Layer_4': 0.014170933368417259, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.012334526001028709, 'l1_Layer_2': 1.0613263003600091e-05, 'l1_Layer_3': 0.0003181829535411309, 'l1_Layer_4': 0.00011443347542711581, 'n_units_Layer_1': 240, 'n_units_Layer_2': 295, 'n_units_Layer_3': 255, 'n_units_Layer_4': 285}. Best is trial 526 with value: 4.591675946601499.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:27:28,789]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.59 | sMAPE for Validation Set is: 10.31% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.90 | sMAPE for Test Set is: 11.26% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:27:37,087]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:27:41,985]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:27:44,485]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:27:48,791]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:27:51,891]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:28:28,458]\u001b[0m Trial 527 finished with value: 5.660525641370309 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014170627705828633, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25569750267482677, 'dropout_rate_Layer_2': 0.395059943799981, 'dropout_rate_Layer_3': 0.21839715530935494, 'dropout_rate_Layer_4': 0.011825266040107824, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0874373997227753, 'l1_Layer_2': 0.0013087923867036466, 'l1_Layer_3': 6.902151753262188e-05, 'l1_Layer_4': 0.001486059897247321, 'n_units_Layer_1': 135, 'n_units_Layer_2': 75, 'n_units_Layer_3': 80, 'n_units_Layer_4': 265}. Best is trial 526 with value: 4.591675946601499.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.66 | sMAPE for Validation Set is: 12.53% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 5.06 | sMAPE for Test Set is: 14.65% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:28:41,161]\u001b[0m Trial 537 finished with value: 4.552826084939684 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009413304755759276, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09997868145002341, 'dropout_rate_Layer_2': 0.02143748696302013, 'dropout_rate_Layer_3': 0.015956631788580082, 'dropout_rate_Layer_4': 0.0074788003275361725, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.014098144793423506, 'l1_Layer_2': 1.0556824077132737e-05, 'l1_Layer_3': 0.0004383360479727572, 'l1_Layer_4': 0.0001246115349582539, 'n_units_Layer_1': 245, 'n_units_Layer_2': 295, 'n_units_Layer_3': 255, 'n_units_Layer_4': 300}. Best is trial 537 with value: 4.552826084939684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.55 | sMAPE for Validation Set is: 10.19% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.24 | sMAPE for Test Set is: 11.99% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:28:46,636]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:28:48,824]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:28:52,612]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:28:55,693]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:28:57,447]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:29:01,275]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:29:03,269]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:29:14,599]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:29:17,696]\u001b[0m Trial 538 finished with value: 4.662701030012839 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008877789561814888, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09082045970636074, 'dropout_rate_Layer_2': 0.02133501841996423, 'dropout_rate_Layer_3': 0.01616565590262665, 'dropout_rate_Layer_4': 0.0016282321462177535, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.013821672844922353, 'l1_Layer_2': 1.1844149500881471e-05, 'l1_Layer_3': 0.0004124853123241615, 'l1_Layer_4': 0.00012481409155669243, 'n_units_Layer_1': 245, 'n_units_Layer_2': 295, 'n_units_Layer_3': 255, 'n_units_Layer_4': 280}. Best is trial 537 with value: 4.552826084939684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.66 | sMAPE for Validation Set is: 10.42% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.09 | sMAPE for Test Set is: 11.70% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:29:26,989]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:29:27,689]\u001b[0m Trial 542 finished with value: 4.629976300984566 and parameters: {'n_hidden': 4, 'learning_rate': 0.000908873200480474, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07351721159915392, 'dropout_rate_Layer_2': 0.03554511297212419, 'dropout_rate_Layer_3': 0.009138651486645652, 'dropout_rate_Layer_4': 0.00669797324609051, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0126010303857516, 'l1_Layer_2': 1.0278815081372792e-05, 'l1_Layer_3': 0.0002456546282593959, 'l1_Layer_4': 8.360857087901666e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 290, 'n_units_Layer_3': 255, 'n_units_Layer_4': 300}. Best is trial 537 with value: 4.552826084939684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.63 | sMAPE for Validation Set is: 10.37% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 3.96 | sMAPE for Test Set is: 11.53% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:29:34,222]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:29:34,550]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:29:37,367]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:29:44,388]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:29:45,833]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:29:52,823]\u001b[0m Trial 546 finished with value: 4.58296740997215 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007845593124189353, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05816991839037967, 'dropout_rate_Layer_2': 0.013517416467070609, 'dropout_rate_Layer_3': 0.014021569281580869, 'dropout_rate_Layer_4': 0.029936826272653348, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.013051376922515826, 'l1_Layer_2': 1.8334302851441165e-05, 'l1_Layer_3': 0.00026901907931318, 'l1_Layer_4': 0.0001463829897348976, 'n_units_Layer_1': 240, 'n_units_Layer_2': 300, 'n_units_Layer_3': 260, 'n_units_Layer_4': 285}. Best is trial 537 with value: 4.552826084939684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.58 | sMAPE for Validation Set is: 10.31% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.99 | sMAPE for Test Set is: 11.51% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:29:54,558]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:29:58,069]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:30:02,148]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:30:06,138]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:30:06,321]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:30:06,753]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:30:14,079]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:30:17,257]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:30:17,666]\u001b[0m Trial 554 finished with value: 4.877000136508622 and parameters: {'n_hidden': 4, 'learning_rate': 0.001053832496166833, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08397116590071294, 'dropout_rate_Layer_2': 0.027446693559382302, 'dropout_rate_Layer_3': 0.011381876548464261, 'dropout_rate_Layer_4': 0.0005774909187001472, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.010402117514890685, 'l1_Layer_2': 1.1634642239316986e-05, 'l1_Layer_3': 0.0004335306454717271, 'l1_Layer_4': 0.00010398952070970849, 'n_units_Layer_1': 250, 'n_units_Layer_2': 290, 'n_units_Layer_3': 250, 'n_units_Layer_4': 300}. Best is trial 537 with value: 4.552826084939684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.88 | sMAPE for Validation Set is: 10.83% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.12 | sMAPE for Test Set is: 11.94% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:30:18,510]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:30:19,183]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:30:23,284]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:30:29,455]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:30:30,160]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:30:30,401]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:30:31,161]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:30:42,159]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:30:43,899]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:30:44,241]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:30:47,797]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:30:51,680]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:30:54,218]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:30:57,771]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:31:01,485]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:31:03,287]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:31:09,694]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:31:11,673]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:31:14,212]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:31:19,577]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:31:21,753]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:31:27,160]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:31:58,197]\u001b[0m Trial 585 finished with value: 4.804875455266715 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006755853274955447, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09948321007915406, 'dropout_rate_Layer_2': 0.018232284536930425, 'dropout_rate_Layer_3': 0.013765585848878714, 'dropout_rate_Layer_4': 0.03287158710882836, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00934506317112426, 'l1_Layer_2': 1.1911879135847543e-05, 'l1_Layer_3': 0.0002042388494295732, 'l1_Layer_4': 0.00011895429037564292, 'n_units_Layer_1': 235, 'n_units_Layer_2': 280, 'n_units_Layer_3': 265, 'n_units_Layer_4': 285}. Best is trial 537 with value: 4.552826084939684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.80 | sMAPE for Validation Set is: 10.69% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.24 | sMAPE for Test Set is: 12.23% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:32:06,419]\u001b[0m Trial 573 finished with value: 4.923782100828444 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005720621088568605, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12085719903029193, 'dropout_rate_Layer_2': 0.3122656159843145, 'dropout_rate_Layer_3': 0.1764141270488529, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.007905240628330463, 'l1_Layer_2': 0.008002423686406319, 'l1_Layer_3': 0.0004499943568241133, 'n_units_Layer_1': 245, 'n_units_Layer_2': 120, 'n_units_Layer_3': 265}. Best is trial 537 with value: 4.552826084939684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.92 | sMAPE for Validation Set is: 10.93% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.13 | sMAPE for Test Set is: 12.00% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:32:07,120]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:32:09,303]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:32:19,723]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:32:25,987]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:32:32,640]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:32:34,586]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:32:42,392]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:32:48,364]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:32:52,012]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:32:58,150]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:33:17,029]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:33:21,621]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:33:22,270]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:33:26,931]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:33:33,896]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:33:37,515]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:33:41,510]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:33:49,721]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:33:56,086]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:33:59,305]\u001b[0m Trial 589 finished with value: 4.5700667173014455 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008257801288791851, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15856032102924675, 'dropout_rate_Layer_2': 0.23916172807070743, 'dropout_rate_Layer_3': 0.016399568645349253, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0032139380533876393, 'l1_Layer_2': 0.004831468468834019, 'l1_Layer_3': 0.0006798468033099766, 'n_units_Layer_1': 95, 'n_units_Layer_2': 290, 'n_units_Layer_3': 265}. Best is trial 537 with value: 4.552826084939684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.57 | sMAPE for Validation Set is: 10.28% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.98 | sMAPE for Test Set is: 11.60% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:34:08,011]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:34:20,034]\u001b[0m Trial 602 finished with value: 4.590630507020755 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010049937461083388, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09320383066278792, 'dropout_rate_Layer_2': 0.027489965076794794, 'dropout_rate_Layer_3': 0.00961358546640059, 'dropout_rate_Layer_4': 0.022377921071174006, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.011859500687942379, 'l1_Layer_2': 1.9703973226713348e-05, 'l1_Layer_3': 0.000440586276379669, 'l1_Layer_4': 0.00011535986905798415, 'n_units_Layer_1': 230, 'n_units_Layer_2': 275, 'n_units_Layer_3': 260, 'n_units_Layer_4': 285}. Best is trial 537 with value: 4.552826084939684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.59 | sMAPE for Validation Set is: 10.33% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.96 | sMAPE for Test Set is: 11.47% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:34:24,954]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:34:33,713]\u001b[0m Trial 608 finished with value: 4.6497090792522755 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009219429171535744, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11576717446275235, 'dropout_rate_Layer_2': 0.014593919367429304, 'dropout_rate_Layer_3': 0.021847821021821607, 'dropout_rate_Layer_4': 0.036556909340321006, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.012122017236882766, 'l1_Layer_2': 1.0080176293702728e-05, 'l1_Layer_3': 0.0005930048518623752, 'l1_Layer_4': 9.7091366912089e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 290, 'n_units_Layer_3': 250, 'n_units_Layer_4': 295}. Best is trial 537 with value: 4.552826084939684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.65 | sMAPE for Validation Set is: 10.34% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.20 | sMAPE for Test Set is: 11.92% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:34:51,961]\u001b[0m Trial 609 finished with value: 4.914152012501794 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008926984459709489, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07172106725160057, 'dropout_rate_Layer_2': 0.2928801750994811, 'dropout_rate_Layer_3': 0.23297032883520707, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0047671722658005145, 'l1_Layer_2': 0.00442037276864561, 'l1_Layer_3': 1.0868912517054706e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 110, 'n_units_Layer_3': 175}. Best is trial 537 with value: 4.552826084939684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.91 | sMAPE for Validation Set is: 10.95% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.03 | sMAPE for Test Set is: 11.55% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:34:57,130]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:35:01,335]\u001b[0m Trial 610 finished with value: 4.605330268355499 and parameters: {'n_hidden': 4, 'learning_rate': 0.000830590587003707, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09251438911522578, 'dropout_rate_Layer_2': 0.017516085403172732, 'dropout_rate_Layer_3': 0.02542939339281687, 'dropout_rate_Layer_4': 0.03692927862219103, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.011640653577438024, 'l1_Layer_2': 1.0190572556281304e-05, 'l1_Layer_3': 0.0005705574008647424, 'l1_Layer_4': 9.702113515165725e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 290, 'n_units_Layer_3': 250, 'n_units_Layer_4': 295}. Best is trial 537 with value: 4.552826084939684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.61 | sMAPE for Validation Set is: 10.33% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 3.95 | sMAPE for Test Set is: 11.36% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:35:05,861]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:35:11,823]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:36:00,463]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:36:05,343]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:36:12,671]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:36:37,465]\u001b[0m Trial 615 finished with value: 5.732698695708476 and parameters: {'n_hidden': 4, 'learning_rate': 0.0026640431622242567, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23519940545099094, 'dropout_rate_Layer_2': 0.3029600831270261, 'dropout_rate_Layer_3': 0.3317854340094405, 'dropout_rate_Layer_4': 0.08210682766465369, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.025882011815788895, 'l1_Layer_2': 0.003999071483386484, 'l1_Layer_3': 0.00020149815762501958, 'l1_Layer_4': 0.0002927000636291961, 'n_units_Layer_1': 220, 'n_units_Layer_2': 95, 'n_units_Layer_3': 180, 'n_units_Layer_4': 225}. Best is trial 537 with value: 4.552826084939684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.73 | sMAPE for Validation Set is: 12.46% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 4.66 | sMAPE for Test Set is: 12.97% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:36:41,026]\u001b[0m Trial 613 finished with value: 5.308662991292871 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007367864599127184, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27954563625425843, 'dropout_rate_Layer_2': 0.2980304038028966, 'dropout_rate_Layer_3': 0.1427566048359725, 'dropout_rate_Layer_4': 0.07948634333430198, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.022081553726105062, 'l1_Layer_2': 0.003717903267450967, 'l1_Layer_3': 0.00045785686133294315, 'l1_Layer_4': 0.00033144141967460217, 'n_units_Layer_1': 215, 'n_units_Layer_2': 95, 'n_units_Layer_3': 180, 'n_units_Layer_4': 225}. Best is trial 537 with value: 4.552826084939684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.31 | sMAPE for Validation Set is: 11.75% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.29 | sMAPE for Test Set is: 12.39% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:36:43,766]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:36:46,892]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:36:53,701]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:37:02,748]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:37:07,077]\u001b[0m Trial 621 finished with value: 4.896408621239264 and parameters: {'n_hidden': 3, 'learning_rate': 0.001324542595607774, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014163459611137415, 'dropout_rate_Layer_2': 0.3263492001938754, 'dropout_rate_Layer_3': 0.23230297750570955, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0032851645572252917, 'l1_Layer_2': 0.0018332207161202822, 'l1_Layer_3': 1.7632226257984445e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 100, 'n_units_Layer_3': 170}. Best is trial 537 with value: 4.552826084939684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.90 | sMAPE for Validation Set is: 10.76% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.00 | sMAPE for Test Set is: 11.54% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:37:12,940]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:37:17,299]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:37:22,191]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:37:22,939]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:37:24,335]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:37:33,522]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:37:33,802]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:37:40,996]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:37:51,293]\u001b[0m Trial 628 finished with value: 4.4951936493239595 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006657884602171349, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1871969152579693, 'dropout_rate_Layer_2': 0.1593998532891442, 'dropout_rate_Layer_3': 0.0018953198942001897, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0042635096557463985, 'l1_Layer_2': 0.00506529843073903, 'l1_Layer_3': 2.594810379342242e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 280, 'n_units_Layer_3': 215}. Best is trial 628 with value: 4.4951936493239595.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.50 | sMAPE for Validation Set is: 10.12% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.07 | sMAPE for Test Set is: 11.80% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:38:10,157]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:38:13,704]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:38:36,090]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:38:50,326]\u001b[0m Trial 632 finished with value: 4.645061087364148 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007105595404660194, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18573088864537926, 'dropout_rate_Layer_2': 0.15529660499401907, 'dropout_rate_Layer_3': 0.0009666978018399181, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004615429189060899, 'l1_Layer_2': 0.004999464263520281, 'l1_Layer_3': 0.0010851346093237112, 'n_units_Layer_1': 85, 'n_units_Layer_2': 280, 'n_units_Layer_3': 215}. Best is trial 628 with value: 4.4951936493239595.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.65 | sMAPE for Validation Set is: 10.36% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 3.97 | sMAPE for Test Set is: 11.53% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:39:27,439]\u001b[0m Trial 640 finished with value: 4.5760384082483405 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010003932165503508, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07897950962546112, 'dropout_rate_Layer_2': 0.01085232348238849, 'dropout_rate_Layer_3': 0.025099524111188248, 'dropout_rate_Layer_4': 0.008964574272496431, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0076974898599912155, 'l1_Layer_2': 1.3593816906670554e-05, 'l1_Layer_3': 0.0002602533654273624, 'l1_Layer_4': 9.428744287856061e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 295, 'n_units_Layer_3': 250, 'n_units_Layer_4': 290}. Best is trial 628 with value: 4.4951936493239595.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.58 | sMAPE for Validation Set is: 10.28% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.88 | sMAPE for Test Set is: 11.26% | rMAE for Test Set is: 0.63\n",
      "MAE for Validation Set is: 4.71 | sMAPE for Validation Set is: 10.56% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.03 | sMAPE for Test Set is: 11.52% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:39:27,597]\u001b[0m Trial 641 finished with value: 4.711445147684834 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009687905695200612, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07988128654959423, 'dropout_rate_Layer_2': 0.008504380278129829, 'dropout_rate_Layer_3': 0.03688574309071378, 'dropout_rate_Layer_4': 0.06961819183608647, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.007646073732750753, 'l1_Layer_2': 1.4216486806906047e-05, 'l1_Layer_3': 0.00023313944648665024, 'l1_Layer_4': 9.632765330731481e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 295, 'n_units_Layer_3': 250, 'n_units_Layer_4': 270}. Best is trial 628 with value: 4.4951936493239595.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:39:32,788]\u001b[0m Trial 639 finished with value: 4.924278146461401 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009348745385514903, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07884461905995573, 'dropout_rate_Layer_2': 0.011618509106105533, 'dropout_rate_Layer_3': 0.20928211430930482, 'dropout_rate_Layer_4': 0.01023416010433324, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.018345793313784626, 'l1_Layer_2': 1.1850486305200185e-05, 'l1_Layer_3': 0.0002605613434850736, 'l1_Layer_4': 9.07306664436309e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 295, 'n_units_Layer_3': 250, 'n_units_Layer_4': 270}. Best is trial 628 with value: 4.4951936493239595.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.92 | sMAPE for Validation Set is: 11.03% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.05 | sMAPE for Test Set is: 11.59% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:39:41,011]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:39:59,122]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:40:07,477]\u001b[0m Trial 636 finished with value: 4.626780652258428 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006652005904266552, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14536018860687655, 'dropout_rate_Layer_2': 0.12522084692488877, 'dropout_rate_Layer_3': 0.0003698317583434377, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004367586587191649, 'l1_Layer_2': 0.006108666968022829, 'l1_Layer_3': 0.0010563959165247132, 'n_units_Layer_1': 85, 'n_units_Layer_2': 250, 'n_units_Layer_3': 260}. Best is trial 628 with value: 4.4951936493239595.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.63 | sMAPE for Validation Set is: 10.39% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 3.95 | sMAPE for Test Set is: 11.52% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:40:07,796]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:40:18,808]\u001b[0m Trial 643 finished with value: 4.990514792721143 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006048029173396882, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0316121353222138, 'dropout_rate_Layer_2': 0.2222032474064531, 'dropout_rate_Layer_3': 0.27076928827676017, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003238962067428525, 'l1_Layer_2': 0.014287555515205172, 'l1_Layer_3': 4.2044781341937534e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 130, 'n_units_Layer_3': 150}. Best is trial 628 with value: 4.4951936493239595.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.99 | sMAPE for Validation Set is: 10.96% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 4.02 | sMAPE for Test Set is: 11.66% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:40:21,636]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:40:26,219]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:40:30,131]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:40:30,867]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:40:37,829]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:40:40,692]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:40:47,237]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:40:49,822]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:40:57,665]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:40:57,882]\u001b[0m Trial 650 finished with value: 4.645299510756018 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007623765247790643, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08874309825242956, 'dropout_rate_Layer_2': 0.01964965030401561, 'dropout_rate_Layer_3': 0.009691754959561536, 'dropout_rate_Layer_4': 0.008924090665824754, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.010358546283500289, 'l1_Layer_2': 1.2010366986332592e-05, 'l1_Layer_3': 0.0002915902792703292, 'l1_Layer_4': 0.00011167233527464046, 'n_units_Layer_1': 240, 'n_units_Layer_2': 295, 'n_units_Layer_3': 140, 'n_units_Layer_4': 295}. Best is trial 628 with value: 4.4951936493239595.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.65 | sMAPE for Validation Set is: 10.48% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 3.94 | sMAPE for Test Set is: 11.35% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:41:03,322]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:41:18,891]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:41:26,987]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:41:36,735]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:41:42,361]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:41:46,276]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:41:55,492]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:42:05,022]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:42:11,402]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:42:14,275]\u001b[0m Trial 649 finished with value: 4.974195667369849 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009080474912155675, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20629683036862592, 'dropout_rate_Layer_2': 0.2894857385951263, 'dropout_rate_Layer_3': 0.17792159481673084, 'dropout_rate_Layer_4': 0.126676164035767, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.014812835804421231, 'l1_Layer_2': 0.0007300221370727879, 'l1_Layer_3': 7.474417762981105e-05, 'l1_Layer_4': 0.0006682249824237313, 'n_units_Layer_1': 160, 'n_units_Layer_2': 90, 'n_units_Layer_3': 215, 'n_units_Layer_4': 195}. Best is trial 628 with value: 4.4951936493239595.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.97 | sMAPE for Validation Set is: 11.06% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.11 | sMAPE for Test Set is: 11.95% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:42:19,192]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:42:19,431]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:42:25,252]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:42:31,046]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:42:35,521]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:42:40,001]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:42:40,431]\u001b[0m Trial 659 finished with value: 5.336226734031734 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010787673000643618, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3263939000676439, 'dropout_rate_Layer_2': 0.2610793543695633, 'dropout_rate_Layer_3': 0.15248019821505485, 'dropout_rate_Layer_4': 0.03505275956897094, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00907818889145781, 'l1_Layer_2': 0.0023220911108009475, 'l1_Layer_3': 7.60819408761445e-05, 'l1_Layer_4': 0.009848262431869904, 'n_units_Layer_1': 155, 'n_units_Layer_2': 115, 'n_units_Layer_3': 155, 'n_units_Layer_4': 200}. Best is trial 628 with value: 4.4951936493239595.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.34 | sMAPE for Validation Set is: 11.94% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.50 | sMAPE for Test Set is: 13.08% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:42:42,786]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:42:49,069]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:42:53,579]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:42:58,551]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:42:58,937]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:43:05,791]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:43:08,312]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:43:14,121]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:43:22,146]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:43:31,024]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:43:38,922]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:43:49,448]\u001b[0m Trial 676 finished with value: 5.340853061418517 and parameters: {'n_hidden': 4, 'learning_rate': 0.000627361943514066, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26362123264858656, 'dropout_rate_Layer_2': 0.18354321441477325, 'dropout_rate_Layer_3': 0.20698591275400283, 'dropout_rate_Layer_4': 0.1540711223318907, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.010265343459058008, 'l1_Layer_2': 0.006571377030605774, 'l1_Layer_3': 0.0008063660396197956, 'l1_Layer_4': 0.003457817683052732, 'n_units_Layer_1': 245, 'n_units_Layer_2': 90, 'n_units_Layer_3': 215, 'n_units_Layer_4': 245}. Best is trial 628 with value: 4.4951936493239595.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.34 | sMAPE for Validation Set is: 11.89% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.29 | sMAPE for Test Set is: 12.38% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:44:02,363]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:44:16,534]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:44:20,632]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:44:22,794]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:44:26,094]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:44:28,455]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:44:31,482]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:44:33,952]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.69 | sMAPE for Validation Set is: 10.50% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.03 | sMAPE for Test Set is: 11.58% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:44:33,978]\u001b[0m Trial 688 finished with value: 4.689856719553361 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018192140295204867, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15158208019757624, 'dropout_rate_Layer_2': 0.1250378176538778, 'dropout_rate_Layer_3': 0.02327228991778017, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0024125657524937494, 'l1_Layer_2': 0.00888832000163807, 'l1_Layer_3': 9.673870598735662e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 250, 'n_units_Layer_3': 225}. Best is trial 628 with value: 4.4951936493239595.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:44:34,449]\u001b[0m Trial 687 finished with value: 4.496837155224004 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006771042829896909, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05823044705692174, 'dropout_rate_Layer_2': 0.01508170365731605, 'dropout_rate_Layer_3': 0.026508646686660354, 'dropout_rate_Layer_4': 0.05076642254867901, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.009164774971433398, 'l1_Layer_2': 1.1732399723859739e-05, 'l1_Layer_3': 0.00022649064438971561, 'l1_Layer_4': 7.927429296310213e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 285, 'n_units_Layer_3': 260, 'n_units_Layer_4': 270}. Best is trial 628 with value: 4.4951936493239595.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.50 | sMAPE for Validation Set is: 10.16% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 3.94 | sMAPE for Test Set is: 11.39% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:44:40,888]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:44:47,100]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:44:47,347]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:44:49,599]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:44:54,321]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:44:54,614]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:44:57,626]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:44:59,478]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:45:04,161]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:45:04,564]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:45:05,714]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:45:10,259]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:45:14,271]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:45:14,559]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:45:15,019]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:45:17,256]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:45:21,879]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:45:23,540]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:45:28,286]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:45:28,833]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:45:30,584]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:45:31,209]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:45:36,023]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:45:36,637]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:45:37,751]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:45:43,698]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:45:45,531]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:45:49,809]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:45:54,095]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:45:58,187]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:45:59,160]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:46:00,723]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:46:06,788]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:46:12,700]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:46:46,790]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:46:52,735]\u001b[0m Trial 724 finished with value: 4.8446664400029675 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006248553744644187, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03709845061240584, 'dropout_rate_Layer_2': 0.21497463485788215, 'dropout_rate_Layer_3': 0.2638866837333122, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0035070797338801513, 'l1_Layer_2': 0.01658340691597771, 'l1_Layer_3': 3.878646235605311e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 130, 'n_units_Layer_3': 150}. Best is trial 628 with value: 4.4951936493239595.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.84 | sMAPE for Validation Set is: 10.77% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.06 | sMAPE for Test Set is: 11.78% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:47:03,666]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:47:08,551]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:47:16,030]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:47:26,244]\u001b[0m Trial 732 finished with value: 4.784668076939646 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018083421276782975, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13946855705040692, 'dropout_rate_Layer_2': 0.10931410785596718, 'dropout_rate_Layer_3': 0.026795745755013006, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001987352780782531, 'l1_Layer_2': 0.0062952654922432925, 'l1_Layer_3': 0.0012883051561310803, 'n_units_Layer_1': 65, 'n_units_Layer_2': 265, 'n_units_Layer_3': 230}. Best is trial 628 with value: 4.4951936493239595.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.78 | sMAPE for Validation Set is: 10.68% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.07 | sMAPE for Test Set is: 11.86% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:47:33,837]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:47:34,067]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:47:38,416]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:47:41,370]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:47:46,270]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:47:50,880]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:48:05,824]\u001b[0m Trial 729 finished with value: 5.066785422268304 and parameters: {'n_hidden': 3, 'learning_rate': 0.000823833300247102, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.030758207011584996, 'dropout_rate_Layer_2': 0.2482419532134211, 'dropout_rate_Layer_3': 0.25948133733525797, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006373587240419403, 'l1_Layer_2': 0.012121131310895428, 'l1_Layer_3': 4.1003372400097074e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 110, 'n_units_Layer_3': 155}. Best is trial 628 with value: 4.4951936493239595.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.07 | sMAPE for Validation Set is: 11.34% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.48 | sMAPE for Test Set is: 13.00% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:48:08,532]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:48:12,612]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:48:15,467]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:48:23,735]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:48:29,862]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:48:33,581]\u001b[0m Trial 742 finished with value: 4.720728680341605 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020237923013780483, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.139095592794265, 'dropout_rate_Layer_2': 0.11261092326495488, 'dropout_rate_Layer_3': 0.038945267956390556, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003696588150601885, 'l1_Layer_2': 0.0062791696751690945, 'l1_Layer_3': 0.0012865488555190755, 'n_units_Layer_1': 60, 'n_units_Layer_2': 250, 'n_units_Layer_3': 110}. Best is trial 628 with value: 4.4951936493239595.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.72 | sMAPE for Validation Set is: 10.50% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.06 | sMAPE for Test Set is: 11.83% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:48:35,887]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:48:43,271]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:49:14,302]\u001b[0m Trial 751 finished with value: 4.780812185694163 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036679323714394634, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13547263624975892, 'dropout_rate_Layer_2': 0.09064101370005616, 'dropout_rate_Layer_3': 0.07684290971245486, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008032945805682585, 'l1_Layer_2': 0.0059875216272871085, 'l1_Layer_3': 0.0016482789213290085, 'n_units_Layer_1': 60, 'n_units_Layer_2': 260, 'n_units_Layer_3': 105}. Best is trial 628 with value: 4.4951936493239595.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.78 | sMAPE for Validation Set is: 10.54% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.18 | sMAPE for Test Set is: 12.18% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:49:27,941]\u001b[0m Trial 752 finished with value: 4.594693383691032 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008347923502524635, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07926631739486226, 'dropout_rate_Layer_2': 0.008977315389568988, 'dropout_rate_Layer_3': 0.02867735862618204, 'dropout_rate_Layer_4': 0.043764658548823304, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.006758951261293431, 'l1_Layer_2': 1.9307462122393615e-05, 'l1_Layer_3': 0.0001965626437764329, 'l1_Layer_4': 8.014774481836585e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 290, 'n_units_Layer_3': 265, 'n_units_Layer_4': 300}. Best is trial 628 with value: 4.4951936493239595.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.59 | sMAPE for Validation Set is: 10.37% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.93 | sMAPE for Test Set is: 11.40% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:49:35,119]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:49:37,795]\u001b[0m Trial 748 finished with value: 4.700129526291924 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008470535241626558, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07994818620738703, 'dropout_rate_Layer_2': 0.008992288280481138, 'dropout_rate_Layer_3': 0.030273219457319492, 'dropout_rate_Layer_4': 0.022859318517391584, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.008323064810816298, 'l1_Layer_2': 2.6545551319001503e-05, 'l1_Layer_3': 0.0007947663194577761, 'l1_Layer_4': 7.996786971755282e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 290, 'n_units_Layer_3': 265, 'n_units_Layer_4': 300}. Best is trial 628 with value: 4.4951936493239595.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.70 | sMAPE for Validation Set is: 10.53% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.07 | sMAPE for Test Set is: 11.80% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:49:47,569]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:49:51,523]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:50:08,004]\u001b[0m Trial 754 finished with value: 4.562091714607715 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006804759551461004, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1813720012738138, 'dropout_rate_Layer_2': 0.01574998934717019, 'dropout_rate_Layer_3': 0.011788859063226974, 'dropout_rate_Layer_4': 0.021942447162684856, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.006641918876512672, 'l1_Layer_2': 2.613253993244616e-05, 'l1_Layer_3': 0.000791414592033486, 'l1_Layer_4': 0.00011182253803450291, 'n_units_Layer_1': 245, 'n_units_Layer_2': 295, 'n_units_Layer_3': 250, 'n_units_Layer_4': 275}. Best is trial 628 with value: 4.4951936493239595.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.56 | sMAPE for Validation Set is: 10.28% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.09 | sMAPE for Test Set is: 11.96% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:50:42,398]\u001b[0m Trial 756 finished with value: 4.490219217985036 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006884554761413321, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09867602161630754, 'dropout_rate_Layer_2': 0.016621204702195032, 'dropout_rate_Layer_3': 0.02717504556636954, 'dropout_rate_Layer_4': 0.04440960302645668, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.007330595357752784, 'l1_Layer_2': 2.6509061793793355e-05, 'l1_Layer_3': 0.0006043698003477217, 'l1_Layer_4': 0.00011071441592479525, 'n_units_Layer_1': 250, 'n_units_Layer_2': 285, 'n_units_Layer_3': 270, 'n_units_Layer_4': 290}. Best is trial 756 with value: 4.490219217985036.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.49 | sMAPE for Validation Set is: 10.12% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 3.95 | sMAPE for Test Set is: 11.40% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:51:27,361]\u001b[0m Trial 757 finished with value: 4.53743072172339 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006786144753109656, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08613206630328882, 'dropout_rate_Layer_2': 0.016670041267981196, 'dropout_rate_Layer_3': 0.028341279840492783, 'dropout_rate_Layer_4': 0.044612279115631, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.007496669645981981, 'l1_Layer_2': 2.623027836325731e-05, 'l1_Layer_3': 0.0007554651318274309, 'l1_Layer_4': 5.8364888430260416e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 285, 'n_units_Layer_3': 270, 'n_units_Layer_4': 300}. Best is trial 756 with value: 4.490219217985036.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.54 | sMAPE for Validation Set is: 10.23% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.10 | sMAPE for Test Set is: 11.90% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:51:33,792]\u001b[0m Trial 759 finished with value: 4.605169413285106 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008014975746861774, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08695524860859809, 'dropout_rate_Layer_2': 0.015787620093169405, 'dropout_rate_Layer_3': 0.027786384289633072, 'dropout_rate_Layer_4': 0.04258956384540909, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.007410976889140588, 'l1_Layer_2': 2.2465190431951515e-05, 'l1_Layer_3': 0.0006145231165457939, 'l1_Layer_4': 5.928402917276827e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 285, 'n_units_Layer_3': 265, 'n_units_Layer_4': 300}. Best is trial 756 with value: 4.490219217985036.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.61 | sMAPE for Validation Set is: 10.34% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.16 | sMAPE for Test Set is: 12.04% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:51:50,295]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:51:52,499]\u001b[0m Trial 760 finished with value: 4.521577357073737 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005018859601511302, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19941377647278755, 'dropout_rate_Layer_2': 0.016536722342708747, 'dropout_rate_Layer_3': 0.027256353398320225, 'dropout_rate_Layer_4': 0.04252102190656445, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.006569241809768929, 'l1_Layer_2': 2.7582361611752123e-05, 'l1_Layer_3': 0.0007170683229588673, 'l1_Layer_4': 5.8450026194336066e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 290, 'n_units_Layer_3': 265, 'n_units_Layer_4': 290}. Best is trial 756 with value: 4.490219217985036.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.52 | sMAPE for Validation Set is: 10.20% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.04 | sMAPE for Test Set is: 11.71% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:51:55,286]\u001b[0m Trial 761 finished with value: 4.547274988305857 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005137532713421568, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13553033055719524, 'dropout_rate_Layer_2': 0.0072133095156102734, 'dropout_rate_Layer_3': 0.04546832880416579, 'dropout_rate_Layer_4': 0.04147171489062242, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0065829474072995366, 'l1_Layer_2': 2.7452171681784837e-05, 'l1_Layer_3': 0.0006410103822907479, 'l1_Layer_4': 0.00011675144390478941, 'n_units_Layer_1': 245, 'n_units_Layer_2': 285, 'n_units_Layer_3': 265, 'n_units_Layer_4': 290}. Best is trial 756 with value: 4.490219217985036.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.55 | sMAPE for Validation Set is: 10.24% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.04 | sMAPE for Test Set is: 11.77% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:52:02,514]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:52:13,076]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:53:27,464]\u001b[0m Trial 764 finished with value: 4.499295873255704 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005063252743689448, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08584683412833298, 'dropout_rate_Layer_2': 0.006217163836499272, 'dropout_rate_Layer_3': 0.045797380710168714, 'dropout_rate_Layer_4': 0.044954790823313634, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.006731244577391414, 'l1_Layer_2': 2.6155668358902104e-05, 'l1_Layer_3': 0.0006984053184362431, 'l1_Layer_4': 5.292520734438169e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 285, 'n_units_Layer_3': 270, 'n_units_Layer_4': 300}. Best is trial 756 with value: 4.490219217985036.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.50 | sMAPE for Validation Set is: 10.09% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 3.93 | sMAPE for Test Set is: 11.34% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:53:32,706]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:53:33,958]\u001b[0m Trial 763 finished with value: 4.584117124280451 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005731607902238487, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0836567677684944, 'dropout_rate_Layer_2': 0.0003230402728940703, 'dropout_rate_Layer_3': 0.04503898006941165, 'dropout_rate_Layer_4': 0.04457756230131513, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.006528103942958212, 'l1_Layer_2': 2.545933012413967e-05, 'l1_Layer_3': 0.0007544813434769383, 'l1_Layer_4': 6.174529248447014e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 285, 'n_units_Layer_3': 270, 'n_units_Layer_4': 300}. Best is trial 756 with value: 4.490219217985036.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.58 | sMAPE for Validation Set is: 10.33% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.18 | sMAPE for Test Set is: 12.23% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:53:52,407]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:53:55,571]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:54:01,840]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:54:03,094]\u001b[0m Trial 768 finished with value: 4.54347833579701 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005114024614841066, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13355120360366102, 'dropout_rate_Layer_2': 0.015658971689284658, 'dropout_rate_Layer_3': 0.04666363099085798, 'dropout_rate_Layer_4': 0.06805521332804425, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00644181579596507, 'l1_Layer_2': 2.9769068560620444e-05, 'l1_Layer_3': 0.0008182871305456701, 'l1_Layer_4': 5.543435178529815e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 275, 'n_units_Layer_3': 275, 'n_units_Layer_4': 300}. Best is trial 756 with value: 4.490219217985036.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.54 | sMAPE for Validation Set is: 10.22% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.88 | sMAPE for Test Set is: 11.23% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:54:09,035]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.55 | sMAPE for Validation Set is: 10.28% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.20 | sMAPE for Test Set is: 12.32% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:54:10,923]\u001b[0m Trial 767 finished with value: 4.5525613654392405 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005247759529009036, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20203761555549626, 'dropout_rate_Layer_2': 0.016088421531901344, 'dropout_rate_Layer_3': 0.036095647433900015, 'dropout_rate_Layer_4': 0.06924259044342466, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.006683820425018927, 'l1_Layer_2': 2.6246477490576747e-05, 'l1_Layer_3': 0.0007233568104230429, 'l1_Layer_4': 5.291432623895132e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 280, 'n_units_Layer_3': 275, 'n_units_Layer_4': 300}. Best is trial 756 with value: 4.490219217985036.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:54:15,428]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:54:15,889]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:54:45,853]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:54:49,770]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:55:37,002]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:55:54,788]\u001b[0m Trial 779 finished with value: 4.509288878929238 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005061533165447293, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16338510180377352, 'dropout_rate_Layer_2': 0.032631357078488965, 'dropout_rate_Layer_3': 0.04767252083428189, 'dropout_rate_Layer_4': 0.05771556025451548, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0058399269469095304, 'l1_Layer_2': 3.136363176756378e-05, 'l1_Layer_3': 0.0006317047644416911, 'l1_Layer_4': 5.704428225233642e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 275, 'n_units_Layer_3': 280, 'n_units_Layer_4': 295}. Best is trial 756 with value: 4.490219217985036.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.51 | sMAPE for Validation Set is: 10.11% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.02 | sMAPE for Test Set is: 11.71% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:55:58,848]\u001b[0m Trial 777 finished with value: 4.5530321073221325 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005005012368559229, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13635528018854012, 'dropout_rate_Layer_2': 0.0026757631105979243, 'dropout_rate_Layer_3': 0.041428038486870315, 'dropout_rate_Layer_4': 0.06892063439708317, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.006237562293371272, 'l1_Layer_2': 2.9774099534883147e-05, 'l1_Layer_3': 0.0007286466131389749, 'l1_Layer_4': 5.796148279413664e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 280, 'n_units_Layer_3': 275, 'n_units_Layer_4': 295}. Best is trial 756 with value: 4.490219217985036.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.55 | sMAPE for Validation Set is: 10.24% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.92 | sMAPE for Test Set is: 11.34% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:56:09,747]\u001b[0m Trial 778 finished with value: 4.477488015239689 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005065780060517233, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13732885793044175, 'dropout_rate_Layer_2': 0.015881442426366764, 'dropout_rate_Layer_3': 0.043260974991904705, 'dropout_rate_Layer_4': 0.09007804268216162, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.005845136188989934, 'l1_Layer_2': 2.9585360720079778e-05, 'l1_Layer_3': 0.0006912439713507906, 'l1_Layer_4': 5.740847847371527e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 275, 'n_units_Layer_3': 280, 'n_units_Layer_4': 295}. Best is trial 778 with value: 4.477488015239689.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.48 | sMAPE for Validation Set is: 10.07% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 3.91 | sMAPE for Test Set is: 11.25% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:56:29,111]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:56:45,191]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:56:47,914]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:56:50,179]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:56:53,668]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:56:56,048]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:57:14,473]\u001b[0m Trial 783 finished with value: 4.509889204035924 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005905980338302594, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16243855397577048, 'dropout_rate_Layer_2': 0.031594862655431585, 'dropout_rate_Layer_3': 0.037412334487288805, 'dropout_rate_Layer_4': 0.07226688423499376, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.007369495586039423, 'l1_Layer_2': 3.5738933823183706e-05, 'l1_Layer_3': 0.0005808371688281737, 'l1_Layer_4': 6.271842678126917e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 265, 'n_units_Layer_3': 270, 'n_units_Layer_4': 300}. Best is trial 778 with value: 4.477488015239689.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.51 | sMAPE for Validation Set is: 10.19% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 3.94 | sMAPE for Test Set is: 11.45% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:57:25,426]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:57:34,240]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:57:43,487]\u001b[0m Trial 785 finished with value: 4.461175029353279 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005024902031875163, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14415962413532415, 'dropout_rate_Layer_2': 0.007082003269645403, 'dropout_rate_Layer_3': 0.0521510080904601, 'dropout_rate_Layer_4': 0.06498950018646112, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00591511489731802, 'l1_Layer_2': 3.526659353132383e-05, 'l1_Layer_3': 0.0009479476823701957, 'l1_Layer_4': 4.9400863946518196e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 260, 'n_units_Layer_3': 280, 'n_units_Layer_4': 300}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.46 | sMAPE for Validation Set is: 10.04% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 3.92 | sMAPE for Test Set is: 11.35% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:57:43,761]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:57:46,032]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:57:54,042]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:57:54,760]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:58:28,174]\u001b[0m Trial 791 finished with value: 4.554883947252562 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005842615200902974, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13744465230066644, 'dropout_rate_Layer_2': 0.03236004622751976, 'dropout_rate_Layer_3': 0.03604609033238382, 'dropout_rate_Layer_4': 0.07714171507954437, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.006887405565228481, 'l1_Layer_2': 2.5917932964158727e-05, 'l1_Layer_3': 0.0009791634974589628, 'l1_Layer_4': 6.163929416671838e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 260, 'n_units_Layer_3': 280, 'n_units_Layer_4': 300}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.55 | sMAPE for Validation Set is: 10.27% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.11 | sMAPE for Test Set is: 11.93% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:58:39,132]\u001b[0m Trial 798 finished with value: 4.694324599435654 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024246844904191205, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1618990917973951, 'dropout_rate_Layer_2': 0.13473012592315992, 'dropout_rate_Layer_3': 0.005744118453772835, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002701424349015985, 'l1_Layer_2': 0.004682880405672775, 'l1_Layer_3': 0.0013459975469995577, 'n_units_Layer_1': 265, 'n_units_Layer_2': 265, 'n_units_Layer_3': 110}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.69 | sMAPE for Validation Set is: 10.42% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.21 | sMAPE for Test Set is: 12.25% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:58:55,186]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:59:32,199]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:59:43,436]\u001b[0m Trial 796 finished with value: 4.570191594546512 and parameters: {'n_hidden': 4, 'learning_rate': 0.000501996332328808, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16388616267153522, 'dropout_rate_Layer_2': 0.030541715052358677, 'dropout_rate_Layer_3': 0.05306097529064851, 'dropout_rate_Layer_4': 0.07642881953720611, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0056646707781969514, 'l1_Layer_2': 2.4803742678844844e-05, 'l1_Layer_3': 0.0006480865758325253, 'l1_Layer_4': 4.270783817302846e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 260, 'n_units_Layer_3': 280, 'n_units_Layer_4': 300}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.57 | sMAPE for Validation Set is: 10.27% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.88 | sMAPE for Test Set is: 11.13% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:59:48,847]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:59:53,645]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:59:57,383]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:59:57,837]\u001b[0m Trial 799 finished with value: 4.564409492006959 and parameters: {'n_hidden': 4, 'learning_rate': 0.000500052604333433, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13709948272146708, 'dropout_rate_Layer_2': 0.01520740146115309, 'dropout_rate_Layer_3': 0.04804080140073431, 'dropout_rate_Layer_4': 0.09947934438267507, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.007180118045613703, 'l1_Layer_2': 3.139604611466115e-05, 'l1_Layer_3': 0.0006037055251469688, 'l1_Layer_4': 4.4423418971878e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 265, 'n_units_Layer_3': 270, 'n_units_Layer_4': 290}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.56 | sMAPE for Validation Set is: 10.23% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.94 | sMAPE for Test Set is: 11.39% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:00:09,030]\u001b[0m Trial 800 finished with value: 4.475321916428359 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005000794138805348, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14839899531705883, 'dropout_rate_Layer_2': 0.03657980105368275, 'dropout_rate_Layer_3': 0.0505255876291793, 'dropout_rate_Layer_4': 0.09247766591935758, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.007116223053997692, 'l1_Layer_2': 3.130088558338052e-05, 'l1_Layer_3': 0.0009051478501137424, 'l1_Layer_4': 4.5689085700466786e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 265, 'n_units_Layer_3': 275, 'n_units_Layer_4': 290}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.48 | sMAPE for Validation Set is: 10.13% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 3.94 | sMAPE for Test Set is: 11.37% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:00:17,913]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:00:39,839]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:00:46,333]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:00:57,320]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:01:00,948]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:01:06,703]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:01:07,421]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:01:18,194]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:01:27,947]\u001b[0m Trial 810 finished with value: 4.482728030535096 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006063777887183313, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15234075723870633, 'dropout_rate_Layer_2': 0.036258033644530174, 'dropout_rate_Layer_3': 0.05711459857942978, 'dropout_rate_Layer_4': 0.10462062850046226, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0058727036791427, 'l1_Layer_2': 3.0133762238758973e-05, 'l1_Layer_3': 0.0007753250863812665, 'l1_Layer_4': 4.6323483405363044e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 250, 'n_units_Layer_3': 280, 'n_units_Layer_4': 290}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.48 | sMAPE for Validation Set is: 10.11% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 3.94 | sMAPE for Test Set is: 11.47% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:01:28,533]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:01:33,766]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:01:39,913]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:01:41,443]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:01:43,254]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:01:45,574]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:01:49,208]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:01:54,963]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:02:01,581]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:02:03,405]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:02:13,303]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:02:22,055]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:02:46,645]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:02:51,742]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:02:56,561]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:02:58,936]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:03:01,724]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:03:20,448]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:03:38,709]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:03:41,881]\u001b[0m Trial 823 finished with value: 4.560376601046026 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005004276392245725, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12373864483208709, 'dropout_rate_Layer_2': 0.03221318069793142, 'dropout_rate_Layer_3': 0.03954279007412073, 'dropout_rate_Layer_4': 0.06721504638438223, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0059298598610095085, 'l1_Layer_2': 3.3193384592082206e-05, 'l1_Layer_3': 0.0005876892269128304, 'l1_Layer_4': 5.447559507602828e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 250, 'n_units_Layer_3': 270, 'n_units_Layer_4': 295}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.56 | sMAPE for Validation Set is: 10.21% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.97 | sMAPE for Test Set is: 11.54% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:03:42,866]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:03:46,456]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:03:52,512]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:03:56,566]\u001b[0m Trial 830 finished with value: 4.730383309971687 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019216246168671297, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11400040176563347, 'dropout_rate_Layer_2': 0.039158587794133115, 'dropout_rate_Layer_3': 0.029953072273872273, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004365038980241757, 'l1_Layer_2': 0.0031468272752251257, 'l1_Layer_3': 0.0010314169111067827, 'n_units_Layer_1': 280, 'n_units_Layer_2': 260, 'n_units_Layer_3': 105}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.73 | sMAPE for Validation Set is: 10.54% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.42 | sMAPE for Test Set is: 12.93% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:04:15,318]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:04:22,501]\u001b[0m Trial 839 finished with value: 4.8644447400228055 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007027216285240955, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0646338751340227, 'dropout_rate_Layer_2': 0.15834979900342647, 'dropout_rate_Layer_3': 0.242238398595968, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0027699803413462052, 'l1_Layer_2': 0.014901287699604337, 'l1_Layer_3': 2.7494030875316082e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 155, 'n_units_Layer_3': 170}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.86 | sMAPE for Validation Set is: 10.85% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.05 | sMAPE for Test Set is: 11.76% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:04:35,297]\u001b[0m Trial 842 finished with value: 4.8039200208307 and parameters: {'n_hidden': 3, 'learning_rate': 0.000714890778794719, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.061160549158707334, 'dropout_rate_Layer_2': 0.16689549093628814, 'dropout_rate_Layer_3': 0.2421043465417452, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002676047528952373, 'l1_Layer_2': 0.014195167427572574, 'l1_Layer_3': 1.8446069076390203e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 155, 'n_units_Layer_3': 170}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.80 | sMAPE for Validation Set is: 10.71% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.07 | sMAPE for Test Set is: 11.66% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:04:38,359]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:04:43,154]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:04:45,442]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:04:52,775]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:04:55,235]\u001b[0m Trial 840 finished with value: 4.5286574705353 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006226422374549102, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20838623769930142, 'dropout_rate_Layer_2': 0.054446940392466336, 'dropout_rate_Layer_3': 0.05110106329962375, 'dropout_rate_Layer_4': 0.07081291032514564, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.005985047103286505, 'l1_Layer_2': 2.347847343600689e-05, 'l1_Layer_3': 0.000742874973851295, 'l1_Layer_4': 4.200218295613617e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 255, 'n_units_Layer_3': 270, 'n_units_Layer_4': 300}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.53 | sMAPE for Validation Set is: 10.16% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.07 | sMAPE for Test Set is: 11.82% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:04:55,537]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:04:59,735]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:05:17,008]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:05:21,258]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:06:00,074]\u001b[0m Trial 844 finished with value: 4.511032118211246 and parameters: {'n_hidden': 4, 'learning_rate': 0.000636185110475436, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1345668263846687, 'dropout_rate_Layer_2': 0.03368816197746442, 'dropout_rate_Layer_3': 0.0479398000791557, 'dropout_rate_Layer_4': 0.0710344398413595, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.007903499975889744, 'l1_Layer_2': 4.388342628015899e-05, 'l1_Layer_3': 0.0006349789732065181, 'l1_Layer_4': 3.600321247090008e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 270, 'n_units_Layer_3': 270, 'n_units_Layer_4': 300}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.51 | sMAPE for Validation Set is: 10.17% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 3.93 | sMAPE for Test Set is: 11.40% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:06:08,927]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:06:14,537]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:06:19,825]\u001b[0m Trial 853 finished with value: 4.577960082525649 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007212833011444751, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.155897075509864, 'dropout_rate_Layer_2': 0.3506651169865195, 'dropout_rate_Layer_3': 0.014057013365326911, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002097690082563119, 'l1_Layer_2': 0.009365849458133152, 'l1_Layer_3': 7.325866038269445e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 255, 'n_units_Layer_3': 265}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.58 | sMAPE for Validation Set is: 10.29% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.07 | sMAPE for Test Set is: 11.90% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:06:20,342]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:06:32,484]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:06:37,588]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:07:11,664]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:07:14,897]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:07:17,706]\u001b[0m Trial 850 finished with value: 5.193513838938496 and parameters: {'n_hidden': 4, 'learning_rate': 0.001141125766219609, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32340101047726305, 'dropout_rate_Layer_2': 0.2599478701199878, 'dropout_rate_Layer_3': 0.14872546364266684, 'dropout_rate_Layer_4': 0.10799744310266024, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.970920718186008e-05, 'l1_Layer_2': 0.0027745674312619566, 'l1_Layer_3': 7.400733247777753e-05, 'l1_Layer_4': 0.012655452315856143, 'n_units_Layer_1': 145, 'n_units_Layer_2': 135, 'n_units_Layer_3': 155, 'n_units_Layer_4': 190}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.19 | sMAPE for Validation Set is: 11.44% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 4.45 | sMAPE for Test Set is: 12.90% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:07:37,328]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:07:38,169]\u001b[0m Trial 861 finished with value: 4.559333135091616 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006403250018078068, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20940240102243146, 'dropout_rate_Layer_2': 0.056297833646743296, 'dropout_rate_Layer_3': 0.0524640457058748, 'dropout_rate_Layer_4': 0.07354442237116973, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.004827017129760483, 'l1_Layer_2': 4.5774347047752616e-05, 'l1_Layer_3': 0.0006213168498328022, 'l1_Layer_4': 3.4503964009883006e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 260, 'n_units_Layer_3': 275, 'n_units_Layer_4': 295}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.56 | sMAPE for Validation Set is: 10.30% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.12 | sMAPE for Test Set is: 12.03% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:07:45,897]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:07:53,138]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:07:57,500]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:08:02,966]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:08:03,376]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:08:08,466]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:08:15,374]\u001b[0m Trial 862 finished with value: 4.597183037221543 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005061150964031409, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14596301520005875, 'dropout_rate_Layer_2': 0.05287239151373197, 'dropout_rate_Layer_3': 0.06815352522142817, 'dropout_rate_Layer_4': 0.07082037953969265, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.007957804352166871, 'l1_Layer_2': 3.422198454387247e-05, 'l1_Layer_3': 0.0006117242377441057, 'l1_Layer_4': 3.269258355251878e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 255, 'n_units_Layer_3': 285, 'n_units_Layer_4': 295}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.60 | sMAPE for Validation Set is: 10.32% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.98 | sMAPE for Test Set is: 11.62% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:08:24,171]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:08:28,261]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:08:50,022]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:09:20,804]\u001b[0m Trial 870 finished with value: 4.560840199211235 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006178551055260643, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18669368476492318, 'dropout_rate_Layer_2': 0.0355945252858878, 'dropout_rate_Layer_3': 0.039855359055023694, 'dropout_rate_Layer_4': 0.08805059989359873, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.005690734010478477, 'l1_Layer_2': 3.0413102556067895e-05, 'l1_Layer_3': 0.0005427180405410365, 'l1_Layer_4': 3.300582358694089e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 265, 'n_units_Layer_3': 275, 'n_units_Layer_4': 290}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.56 | sMAPE for Validation Set is: 10.26% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.90 | sMAPE for Test Set is: 11.23% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:09:23,237]\u001b[0m Trial 871 finished with value: 4.596074076666735 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006335322695365676, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12173860914251351, 'dropout_rate_Layer_2': 0.036796111303884674, 'dropout_rate_Layer_3': 0.03977850123304904, 'dropout_rate_Layer_4': 0.09163120841841298, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0055387538005018675, 'l1_Layer_2': 2.9903561348061352e-05, 'l1_Layer_3': 0.000542679154914031, 'l1_Layer_4': 3.1174637505860164e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 265, 'n_units_Layer_3': 275, 'n_units_Layer_4': 290}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.60 | sMAPE for Validation Set is: 10.29% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.98 | sMAPE for Test Set is: 11.52% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:09:30,042]\u001b[0m Trial 875 finished with value: 4.59554052209499 and parameters: {'n_hidden': 4, 'learning_rate': 0.000608175524188262, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12235981713933411, 'dropout_rate_Layer_2': 0.034121824355605866, 'dropout_rate_Layer_3': 0.056313386950665345, 'dropout_rate_Layer_4': 0.06213485884419376, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00443054570873381, 'l1_Layer_2': 4.4570290909733486e-05, 'l1_Layer_3': 0.0005316071154492468, 'l1_Layer_4': 5.216767968246812e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 250, 'n_units_Layer_3': 270, 'n_units_Layer_4': 290}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.60 | sMAPE for Validation Set is: 10.36% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.09 | sMAPE for Test Set is: 11.89% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:09:34,556]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:09:40,513]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:09:44,311]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:09:48,713]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:09:53,079]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:09:53,179]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:09:54,480]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:09:58,713]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:10:02,946]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:10:04,186]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:10:11,450]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:10:13,212]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:10:40,425]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:11:17,210]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:11:23,696]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:11:30,852]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:11:33,341]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:11:37,393]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:11:43,845]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:11:49,287]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:11:55,723]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:12:08,387]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:12:23,143]\u001b[0m Trial 892 finished with value: 4.57457699318394 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005844208850149961, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15809312918684884, 'dropout_rate_Layer_2': 0.0446652381141699, 'dropout_rate_Layer_3': 0.04374325880941375, 'dropout_rate_Layer_4': 0.06778725440622889, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0057860616399259684, 'l1_Layer_2': 2.4358230237071568e-05, 'l1_Layer_3': 0.0012770104273217436, 'l1_Layer_4': 5.2161254876305714e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 270, 'n_units_Layer_3': 285, 'n_units_Layer_4': 290}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.57 | sMAPE for Validation Set is: 10.33% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.85 | sMAPE for Test Set is: 11.11% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:12:25,000]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:12:29,118]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:12:33,737]\u001b[0m Trial 893 finished with value: 4.508147512796428 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005918100523045453, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15596937097445146, 'dropout_rate_Layer_2': 0.0535398607743321, 'dropout_rate_Layer_3': 0.04774813988512582, 'dropout_rate_Layer_4': 0.06774594689603045, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.005427462649293863, 'l1_Layer_2': 2.5220202249455047e-05, 'l1_Layer_3': 0.0011495102404464402, 'l1_Layer_4': 5.1309506285319474e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 270, 'n_units_Layer_3': 285, 'n_units_Layer_4': 290}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.51 | sMAPE for Validation Set is: 10.16% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 3.90 | sMAPE for Test Set is: 11.33% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:12:35,405]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:12:59,569]\u001b[0m Trial 899 finished with value: 4.5973358011956105 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005550422177085745, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15274560465918938, 'dropout_rate_Layer_2': 0.05491376951952204, 'dropout_rate_Layer_3': 0.04495492671995621, 'dropout_rate_Layer_4': 0.06856819847788784, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.005635159881769977, 'l1_Layer_2': 2.292186884468337e-05, 'l1_Layer_3': 0.0011311537191070278, 'l1_Layer_4': 5.106176983862531e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 270, 'n_units_Layer_3': 285, 'n_units_Layer_4': 290}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.60 | sMAPE for Validation Set is: 10.29% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.93 | sMAPE for Test Set is: 11.30% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:13:17,918]\u001b[0m Trial 903 finished with value: 4.736499434654052 and parameters: {'n_hidden': 3, 'learning_rate': 0.001782988866516801, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.097613224711798, 'dropout_rate_Layer_2': 0.08449389171408059, 'dropout_rate_Layer_3': 0.2810925920334578, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0012526892868511502, 'l1_Layer_2': 0.0007937045699952438, 'l1_Layer_3': 0.0004907449433616377, 'n_units_Layer_1': 120, 'n_units_Layer_2': 140, 'n_units_Layer_3': 160}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.74 | sMAPE for Validation Set is: 10.61% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.00 | sMAPE for Test Set is: 11.57% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:13:18,230]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:13:23,928]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:13:28,304]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:13:30,716]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:13:34,521]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:13:34,784]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:13:41,704]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:13:46,803]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:13:47,442]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:13:52,710]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:13:53,065]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:13:59,003]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:14:03,625]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:14:11,094]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:14:15,258]\u001b[0m Trial 909 finished with value: 4.817501598541075 and parameters: {'n_hidden': 3, 'learning_rate': 0.001874988235471795, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08517969697112385, 'dropout_rate_Layer_2': 0.07103013390699132, 'dropout_rate_Layer_3': 0.28257366594346073, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0013601879535642082, 'l1_Layer_2': 0.0009531013440362091, 'l1_Layer_3': 0.0005845697875247495, 'n_units_Layer_1': 115, 'n_units_Layer_2': 155, 'n_units_Layer_3': 180}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.82 | sMAPE for Validation Set is: 10.60% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 3.96 | sMAPE for Test Set is: 11.36% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:14:32,323]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:14:43,644]\u001b[0m Trial 916 finished with value: 4.590234820669591 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015725522686467486, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1041839427927468, 'dropout_rate_Layer_2': 0.2305007493775715, 'dropout_rate_Layer_3': 0.01932569460332715, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004262783142131481, 'l1_Layer_2': 0.00329275632808434, 'l1_Layer_3': 0.0011812227800139191, 'n_units_Layer_1': 60, 'n_units_Layer_2': 255, 'n_units_Layer_3': 120}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.59 | sMAPE for Validation Set is: 10.43% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.05 | sMAPE for Test Set is: 11.81% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:14:48,541]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:14:52,746]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:14:53,086]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:15:01,025]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:15:05,184]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:15:19,377]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:15:25,862]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:15:29,263]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:15:30,276]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:15:37,335]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:15:42,459]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:15:51,353]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:15:59,146]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:16:03,210]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:16:15,549]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:16:21,021]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:16:27,660]\u001b[0m Trial 924 finished with value: 4.549418747855743 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005022959013605766, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19999920601264654, 'dropout_rate_Layer_2': 0.062125502889135785, 'dropout_rate_Layer_3': 0.05070348137208375, 'dropout_rate_Layer_4': 0.0725349499614399, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.007526881818023458, 'l1_Layer_2': 3.644082191900656e-05, 'l1_Layer_3': 0.0006004697483908192, 'l1_Layer_4': 6.60659787974076e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 280, 'n_units_Layer_3': 290, 'n_units_Layer_4': 290}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.55 | sMAPE for Validation Set is: 10.27% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.05 | sMAPE for Test Set is: 11.76% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:16:29,355]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:16:30,451]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:16:40,168]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:16:51,712]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:16:51,992]\u001b[0m Trial 943 finished with value: 5.875676452092397 and parameters: {'n_hidden': 3, 'learning_rate': 0.034947045390383714, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2512483291408209, 'dropout_rate_Layer_2': 0.24821807770209647, 'dropout_rate_Layer_3': 0.1833241503043332, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0900069704530534e-05, 'l1_Layer_2': 0.0002067051061746627, 'l1_Layer_3': 1.7962943683925994e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 65, 'n_units_Layer_3': 145}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.88 | sMAPE for Validation Set is: 12.46% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 5.11 | sMAPE for Test Set is: 14.73% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:16:59,477]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:17:06,783]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:17:10,004]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:17:14,182]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:17:17,587]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:17:21,974]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:17:23,860]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:17:25,043]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:17:27,355]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:17:29,509]\u001b[0m Trial 946 finished with value: 4.723531765666976 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021142719415542435, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12641048349426903, 'dropout_rate_Layer_2': 0.1491518165853551, 'dropout_rate_Layer_3': 0.007003856222946956, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006888689740822026, 'l1_Layer_2': 0.0046067625838411164, 'l1_Layer_3': 0.00012069281576037908, 'n_units_Layer_1': 100, 'n_units_Layer_2': 250, 'n_units_Layer_3': 110}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.72 | sMAPE for Validation Set is: 10.54% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.19 | sMAPE for Test Set is: 12.22% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:17:29,602]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:17:38,631]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:17:39,806]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:17:47,658]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:17:59,891]\u001b[0m Trial 958 finished with value: 4.730401017998851 and parameters: {'n_hidden': 3, 'learning_rate': 0.002105679191705393, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1301650361887224, 'dropout_rate_Layer_2': 0.31632503896895386, 'dropout_rate_Layer_3': 0.03993071412643012, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.010916943228507576, 'l1_Layer_2': 0.004536027604399716, 'l1_Layer_3': 0.00013241220863113807, 'n_units_Layer_1': 100, 'n_units_Layer_2': 245, 'n_units_Layer_3': 110}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.73 | sMAPE for Validation Set is: 10.63% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.29 | sMAPE for Test Set is: 12.47% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:18:36,245]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:18:49,119]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:18:55,442]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:19:00,759]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:19:03,477]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:19:06,323]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:19:06,939]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:19:12,346]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:19:14,947]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:19:15,557]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:19:21,665]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:19:25,864]\u001b[0m Trial 960 finished with value: 4.621132032516061 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017549148670423361, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07536815871550104, 'dropout_rate_Layer_2': 0.003428535019371126, 'dropout_rate_Layer_3': 0.2922512817551664, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001356880920895984, 'l1_Layer_2': 0.0170734741689366, 'l1_Layer_3': 0.0007499985878674072, 'n_units_Layer_1': 100, 'n_units_Layer_2': 145, 'n_units_Layer_3': 170}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.62 | sMAPE for Validation Set is: 10.29% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 3.90 | sMAPE for Test Set is: 11.31% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:19:28,060]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:19:32,687]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:19:40,366]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:19:48,663]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:19:51,575]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:19:55,795]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.69 | sMAPE for Validation Set is: 10.58% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.00 | sMAPE for Test Set is: 11.54% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:19:57,320]\u001b[0m Trial 974 finished with value: 4.687759952696121 and parameters: {'n_hidden': 3, 'learning_rate': 0.002113614723884721, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13610259350349507, 'dropout_rate_Layer_2': 0.15140758221465384, 'dropout_rate_Layer_3': 0.0077632794650225045, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01600109597778845, 'l1_Layer_2': 0.005571132020906629, 'l1_Layer_3': 8.810090522387082e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 255, 'n_units_Layer_3': 120}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:20:28,877]\u001b[0m Trial 978 finished with value: 4.535540508375933 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006169912610215424, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11392865264616946, 'dropout_rate_Layer_2': 0.04893992661074292, 'dropout_rate_Layer_3': 0.04169422109002529, 'dropout_rate_Layer_4': 0.07796233560339774, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.007372604611398551, 'l1_Layer_2': 4.529354264122565e-05, 'l1_Layer_3': 0.0005222355742268759, 'l1_Layer_4': 5.6882174435107216e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 240, 'n_units_Layer_3': 265, 'n_units_Layer_4': 285}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.54 | sMAPE for Validation Set is: 10.17% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.99 | sMAPE for Test Set is: 11.68% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:20:38,080]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:21:00,815]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:21:04,227]\u001b[0m Trial 983 finished with value: 4.720748694604557 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021487044243786884, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11959422870617069, 'dropout_rate_Layer_2': 0.15155090360790965, 'dropout_rate_Layer_3': 0.01796324883148234, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.017891760960640053, 'l1_Layer_2': 0.004557102969557265, 'l1_Layer_3': 7.502978502126407e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 245, 'n_units_Layer_3': 120}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.72 | sMAPE for Validation Set is: 10.56% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 3.93 | sMAPE for Test Set is: 11.34% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:21:07,819]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:21:08,350]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:21:08,656]\u001b[0m Trial 977 finished with value: 4.73636278883039 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018201025928921291, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0532026061778624, 'dropout_rate_Layer_2': 0.0033573165851799452, 'dropout_rate_Layer_3': 0.28998944810376026, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008535543884664827, 'l1_Layer_2': 0.0006387816312935256, 'l1_Layer_3': 0.0008358381110234566, 'n_units_Layer_1': 95, 'n_units_Layer_2': 145, 'n_units_Layer_3': 180}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.74 | sMAPE for Validation Set is: 10.67% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.15 | sMAPE for Test Set is: 12.26% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:21:17,155]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:21:21,213]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:21:23,166]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:21:27,567]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:21:38,174]\u001b[0m Trial 981 finished with value: 4.583565747631329 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006062341674093281, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15984580162570258, 'dropout_rate_Layer_2': 0.02043227055725194, 'dropout_rate_Layer_3': 0.02604444855253663, 'dropout_rate_Layer_4': 0.05273374402570981, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.006089919653700254, 'l1_Layer_2': 3.612636363135801e-05, 'l1_Layer_3': 0.0007319041949998659, 'l1_Layer_4': 7.085654216017518e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 270, 'n_units_Layer_3': 280, 'n_units_Layer_4': 285}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.58 | sMAPE for Validation Set is: 10.31% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.85 | sMAPE for Test Set is: 11.14% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:21:51,644]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:21:59,865]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:22:05,444]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:22:09,685]\u001b[0m Trial 993 finished with value: 4.538999316101856 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018845884179321184, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10503816050472266, 'dropout_rate_Layer_2': 0.15001747329255116, 'dropout_rate_Layer_3': 5.0032332781230074e-05, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006253711019048367, 'l1_Layer_2': 0.003077678632694991, 'l1_Layer_3': 7.82278597139379e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 245, 'n_units_Layer_3': 110}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.54 | sMAPE for Validation Set is: 10.18% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.95 | sMAPE for Test Set is: 11.45% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:22:16,767]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:22:21,371]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:22:27,500]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:22:29,368]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:22:52,391]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:22:57,486]\u001b[0m Trial 986 finished with value: 4.547089526062794 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005472136111242657, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1268558290749261, 'dropout_rate_Layer_2': 0.04504948599377934, 'dropout_rate_Layer_3': 0.05584773891616074, 'dropout_rate_Layer_4': 0.07384903891620592, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0076338453387728746, 'l1_Layer_2': 3.506200309480642e-05, 'l1_Layer_3': 0.00048580160505741005, 'l1_Layer_4': 4.354088344796329e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 245, 'n_units_Layer_3': 280, 'n_units_Layer_4': 295}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.55 | sMAPE for Validation Set is: 10.22% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.99 | sMAPE for Test Set is: 11.59% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:23:09,269]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:23:14,691]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:23:15,895]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:23:18,985]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:23:22,104]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:23:24,280]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:23:25,250]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:23:27,936]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:23:31,315]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:23:33,050]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:23:35,467]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:23:45,070]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:23:45,198]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:23:53,101]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:24:05,160]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:24:11,503]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:24:14,683]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:24:19,821]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:24:34,044]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:24:48,860]\u001b[0m Trial 1018 finished with value: 4.666420183847737 and parameters: {'n_hidden': 3, 'learning_rate': 0.002246792405928893, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13802259587194676, 'dropout_rate_Layer_2': 0.14181035851811405, 'dropout_rate_Layer_3': 0.033364519772715956, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00839633480288811, 'l1_Layer_2': 0.003916086503972734, 'l1_Layer_3': 0.00010604695999057272, 'n_units_Layer_1': 100, 'n_units_Layer_2': 235, 'n_units_Layer_3': 120}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.67 | sMAPE for Validation Set is: 10.47% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 3.92 | sMAPE for Test Set is: 11.34% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:24:57,865]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:25:06,907]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:25:07,294]\u001b[0m Trial 1019 finished with value: 4.625978575081356 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022493123126493234, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13790873367621484, 'dropout_rate_Layer_2': 0.13606561153128177, 'dropout_rate_Layer_3': 0.03526765585604822, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00643559520956215, 'l1_Layer_2': 0.0043052742356816135, 'l1_Layer_3': 0.00010810485381038801, 'n_units_Layer_1': 100, 'n_units_Layer_2': 245, 'n_units_Layer_3': 120}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.63 | sMAPE for Validation Set is: 10.45% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.22 | sMAPE for Test Set is: 12.30% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:25:13,184]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:25:25,890]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:25:37,947]\u001b[0m Trial 1024 finished with value: 4.609507689187425 and parameters: {'n_hidden': 3, 'learning_rate': 0.002273596877522328, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11621937331116032, 'dropout_rate_Layer_2': 0.12792103724376375, 'dropout_rate_Layer_3': 0.01698997878622697, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008981622099698192, 'l1_Layer_2': 0.006116281830163381, 'l1_Layer_3': 0.0001480558089254873, 'n_units_Layer_1': 90, 'n_units_Layer_2': 245, 'n_units_Layer_3': 125}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.61 | sMAPE for Validation Set is: 10.25% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.14 | sMAPE for Test Set is: 12.09% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:25:42,139]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:25:56,229]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:25:58,001]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:26:07,080]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:26:13,736]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:26:20,386]\u001b[0m Trial 1030 finished with value: 4.82697768788542 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031607180190946207, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.056096569891687945, 'dropout_rate_Layer_2': 0.0610431300259407, 'dropout_rate_Layer_3': 0.3102480975481681, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007676825547091388, 'l1_Layer_2': 0.0008102097430362907, 'l1_Layer_3': 0.0007297144464303816, 'n_units_Layer_1': 100, 'n_units_Layer_2': 150, 'n_units_Layer_3': 195}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.83 | sMAPE for Validation Set is: 10.77% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.22 | sMAPE for Test Set is: 12.19% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:26:25,683]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:26:29,730]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:26:45,198]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:26:49,674]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:26:59,766]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:27:06,069]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:27:10,205]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:27:16,143]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:27:21,509]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:27:23,919]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:27:26,969]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:27:29,411]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:27:38,795]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:27:43,007]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:27:51,427]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:27:55,186]\u001b[0m Trial 1046 finished with value: 4.752699230716217 and parameters: {'n_hidden': 3, 'learning_rate': 0.002028631138434478, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13510868657992767, 'dropout_rate_Layer_2': 0.14936496424782558, 'dropout_rate_Layer_3': 0.01355738255264785, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01177427957726836, 'l1_Layer_2': 0.006435061946321558, 'l1_Layer_3': 7.665432256684098e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 245, 'n_units_Layer_3': 125}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:27:55,206]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.75 | sMAPE for Validation Set is: 10.59% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.07 | sMAPE for Test Set is: 11.75% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:28:03,109]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:28:03,343]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:28:11,343]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:28:17,024]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:28:26,060]\u001b[0m Trial 1048 finished with value: 4.82797970763798 and parameters: {'n_hidden': 3, 'learning_rate': 0.004631963226072266, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.052640823415878266, 'dropout_rate_Layer_2': 0.030054134978308472, 'dropout_rate_Layer_3': 0.3060985287242145, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009913105348231452, 'l1_Layer_2': 0.001156151710411122, 'l1_Layer_3': 0.001716385350738445, 'n_units_Layer_1': 85, 'n_units_Layer_2': 135, 'n_units_Layer_3': 195}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.83 | sMAPE for Validation Set is: 10.78% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.13 | sMAPE for Test Set is: 11.70% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:28:26,645]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:28:29,438]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:28:34,386]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:28:39,208]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:28:42,213]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:28:44,495]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:28:52,298]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:28:58,578]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:29:09,195]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:29:18,824]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.64 | sMAPE for Validation Set is: 10.41% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 3.99 | sMAPE for Test Set is: 11.59% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:29:31,113]\u001b[0m Trial 1065 finished with value: 4.6404777123897 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023928297323323935, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14613322428385458, 'dropout_rate_Layer_2': 0.1413170928099236, 'dropout_rate_Layer_3': 0.028808174846701735, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00933676773759986, 'l1_Layer_2': 0.0035659137007149275, 'l1_Layer_3': 0.00013291631727301847, 'n_units_Layer_1': 95, 'n_units_Layer_2': 235, 'n_units_Layer_3': 120}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:29:37,580]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:29:43,851]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:29:48,920]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:29:55,412]\u001b[0m Trial 1066 finished with value: 4.7417586512006205 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023904745370169397, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14389063981952308, 'dropout_rate_Layer_2': 0.14127731897339535, 'dropout_rate_Layer_3': 0.027630160505745044, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01350762739193261, 'l1_Layer_2': 0.003095924941036258, 'l1_Layer_3': 0.00013618794199054626, 'n_units_Layer_1': 95, 'n_units_Layer_2': 235, 'n_units_Layer_3': 120}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.74 | sMAPE for Validation Set is: 10.62% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.17 | sMAPE for Test Set is: 12.11% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:29:58,310]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:29:58,469]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:30:05,058]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:30:07,246]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:30:08,971]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:30:13,452]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:30:17,742]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:30:21,748]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:30:46,592]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:30:59,976]\u001b[0m Trial 1078 finished with value: 5.193870360096519 and parameters: {'n_hidden': 3, 'learning_rate': 0.004247590959909315, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05510014501442514, 'dropout_rate_Layer_2': 0.06826071025135193, 'dropout_rate_Layer_3': 0.2983998345964231, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00048401920182042726, 'l1_Layer_2': 0.0004653243654072366, 'l1_Layer_3': 0.0007008593819043571, 'n_units_Layer_1': 60, 'n_units_Layer_2': 150, 'n_units_Layer_3': 200}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.19 | sMAPE for Validation Set is: 11.66% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.00 | sMAPE for Test Set is: 14.25% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:31:06,798]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:31:07,000]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:31:14,093]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:31:33,551]\u001b[0m Trial 1075 finished with value: 5.298063103295793 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005964588689162228, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2644917484642196, 'dropout_rate_Layer_2': 0.18132192918799214, 'dropout_rate_Layer_3': 0.20009690373912367, 'dropout_rate_Layer_4': 0.15683281524438755, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.010110737044115333, 'l1_Layer_2': 0.00659726968223901, 'l1_Layer_3': 0.000802033091845192, 'l1_Layer_4': 0.0024806165398931603, 'n_units_Layer_1': 250, 'n_units_Layer_2': 90, 'n_units_Layer_3': 210, 'n_units_Layer_4': 245}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.30 | sMAPE for Validation Set is: 11.77% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.29 | sMAPE for Test Set is: 12.45% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:31:39,929]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:31:45,064]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:31:49,230]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.32 | sMAPE for Validation Set is: 11.81% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.21 | sMAPE for Test Set is: 12.14% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:31:58,174]\u001b[0m Trial 1077 finished with value: 5.3164969326619556 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005880752563881032, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26130331999198575, 'dropout_rate_Layer_2': 0.18111120136369646, 'dropout_rate_Layer_3': 0.1950945805328777, 'dropout_rate_Layer_4': 0.15673091091380573, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.010365346741830782, 'l1_Layer_2': 0.007010037686783728, 'l1_Layer_3': 0.0018509301501139074, 'l1_Layer_4': 0.0034411231208278993, 'n_units_Layer_1': 245, 'n_units_Layer_2': 90, 'n_units_Layer_3': 220, 'n_units_Layer_4': 255}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:32:02,373]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:32:06,041]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:32:50,805]\u001b[0m Trial 1085 finished with value: 4.549953410265833 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005431290214545687, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.138917455316797, 'dropout_rate_Layer_2': 0.03450983555312234, 'dropout_rate_Layer_3': 0.026573597298180075, 'dropout_rate_Layer_4': 0.06552734262272913, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.005206261708857156, 'l1_Layer_2': 3.6189604970522905e-05, 'l1_Layer_3': 0.0011122005204526478, 'l1_Layer_4': 4.5367149058032174e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 275, 'n_units_Layer_3': 265, 'n_units_Layer_4': 300}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.55 | sMAPE for Validation Set is: 10.21% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.94 | sMAPE for Test Set is: 11.39% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:32:57,918]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:33:04,088]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:33:06,993]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:33:08,929]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:33:12,308]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:33:15,585]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:33:19,475]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:33:24,510]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:33:28,967]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:33:34,131]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:33:47,723]\u001b[0m Trial 1091 finished with value: 5.2928786150348035 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005509936678629303, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25368266145692947, 'dropout_rate_Layer_2': 0.16869453764513279, 'dropout_rate_Layer_3': 0.17534492039403926, 'dropout_rate_Layer_4': 0.1694668540549069, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.012522561631688647, 'l1_Layer_2': 0.007362170981986471, 'l1_Layer_3': 0.0020226026627640815, 'l1_Layer_4': 0.0025420705114395925, 'n_units_Layer_1': 250, 'n_units_Layer_2': 90, 'n_units_Layer_3': 220, 'n_units_Layer_4': 250}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.29 | sMAPE for Validation Set is: 11.77% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.21 | sMAPE for Test Set is: 12.17% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:33:50,719]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:33:53,813]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:34:05,426]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:34:09,639]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:34:16,715]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:34:19,604]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:34:23,982]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:34:29,961]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:34:32,949]\u001b[0m Trial 1083 finished with value: 5.345253736773016 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005748194649836906, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26428940494666736, 'dropout_rate_Layer_2': 0.18393575790840064, 'dropout_rate_Layer_3': 0.18770547672406468, 'dropout_rate_Layer_4': 0.1596187249517256, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.012197473525728194, 'l1_Layer_2': 0.00922805685994931, 'l1_Layer_3': 0.0009274902208253686, 'l1_Layer_4': 0.0024890925783602547, 'n_units_Layer_1': 255, 'n_units_Layer_2': 90, 'n_units_Layer_3': 220, 'n_units_Layer_4': 245}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.35 | sMAPE for Validation Set is: 11.89% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.28 | sMAPE for Test Set is: 12.45% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:34:38,138]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:34:42,069]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:34:42,754]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:34:52,005]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:35:01,729]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:35:03,894]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:35:08,472]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:35:11,742]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:35:14,045]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:35:18,055]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:35:20,128]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:35:23,656]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:35:35,033]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:35:39,049]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:35:39,344]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:35:48,453]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:35:50,296]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:35:57,724]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:36:00,112]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:36:04,599]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:36:10,752]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:36:14,597]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:36:17,392]\u001b[0m Trial 1113 finished with value: 4.54948987063083 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006186074149593254, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12926777027234118, 'dropout_rate_Layer_2': 0.005714851301706124, 'dropout_rate_Layer_3': 0.032761627131260206, 'dropout_rate_Layer_4': 0.088113350854276, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.005877288021374055, 'l1_Layer_2': 2.8634484907037013e-05, 'l1_Layer_3': 0.0012463555283463766, 'l1_Layer_4': 5.0258287440950855e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 265, 'n_units_Layer_3': 285, 'n_units_Layer_4': 290}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.55 | sMAPE for Validation Set is: 10.23% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.90 | sMAPE for Test Set is: 11.27% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:36:17,784]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:36:24,564]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:36:25,283]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:36:31,580]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:36:32,742]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:36:36,677]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:36:37,977]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:36:43,021]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:36:48,263]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:36:54,209]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:36:54,722]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:37:00,886]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:37:02,943]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:37:05,280]\u001b[0m Trial 1129 finished with value: 4.759810635453053 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015843963933147565, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07554941855378114, 'dropout_rate_Layer_2': 0.02858239460109997, 'dropout_rate_Layer_3': 0.25076472777289793, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0017740731523226856, 'l1_Layer_2': 0.001417583939296568, 'l1_Layer_3': 0.0016933311653445579, 'n_units_Layer_1': 215, 'n_units_Layer_2': 125, 'n_units_Layer_3': 155}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.76 | sMAPE for Validation Set is: 10.63% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 3.97 | sMAPE for Test Set is: 11.40% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:37:09,798]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:37:16,410]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:37:16,949]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:37:22,721]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:37:25,174]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:37:29,161]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:37:29,325]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:37:29,994]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:37:39,652]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:37:43,455]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:37:55,252]\u001b[0m Trial 1131 finished with value: 4.786204412440792 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016632795244896773, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22933140729491694, 'dropout_rate_Layer_2': 0.11804463758766255, 'dropout_rate_Layer_3': 0.256846987936674, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001890053519111496, 'l1_Layer_2': 0.001679873570496486, 'l1_Layer_3': 0.0011011532715015234, 'n_units_Layer_1': 110, 'n_units_Layer_2': 125, 'n_units_Layer_3': 195}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.79 | sMAPE for Validation Set is: 10.66% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.04 | sMAPE for Test Set is: 11.66% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:38:00,327]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:38:04,733]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:38:09,013]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:38:13,764]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:38:18,537]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:38:22,382]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:38:22,528]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:38:28,236]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:38:34,000]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:38:37,278]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:38:38,224]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:38:47,915]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:39:11,528]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:39:19,580]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:39:24,123]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:39:28,967]\u001b[0m Trial 1171 finished with value: 5.273436003210825 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006571981936798811, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2121482425935465, 'dropout_rate_Layer_2': 0.11481338613947888, 'dropout_rate_Layer_3': 0.17370322091446788, 'dropout_rate_Layer_4': 0.2165632095286994, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.050882112036363725, 'l1_Layer_2': 0.013498966680435489, 'l1_Layer_3': 0.0023895537958275037, 'l1_Layer_4': 0.0010074708022991844, 'n_units_Layer_1': 290, 'n_units_Layer_2': 85, 'n_units_Layer_3': 200, 'n_units_Layer_4': 50}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.27 | sMAPE for Validation Set is: 11.77% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.26 | sMAPE for Test Set is: 12.21% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:39:33,403]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:39:43,537]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:39:49,111]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:39:54,385]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:40:05,263]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:40:12,510]\u001b[0m Trial 1172 finished with value: 4.676254723001016 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005768514851314395, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1369973170156023, 'dropout_rate_Layer_2': 0.1330970425407091, 'dropout_rate_Layer_3': 0.022681263046779407, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005174876223694882, 'l1_Layer_2': 0.005792190520524188, 'l1_Layer_3': 3.7959655317647864e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 230, 'n_units_Layer_3': 135}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.68 | sMAPE for Validation Set is: 10.41% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.06 | sMAPE for Test Set is: 11.81% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:40:14,003]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:40:17,635]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:40:20,401]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:40:22,555]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:40:27,283]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:40:27,954]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:40:34,272]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:40:38,494]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:40:42,579]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:40:49,279]\u001b[0m Trial 1178 finished with value: 4.599811299948276 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007960582286467159, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12367404195886256, 'dropout_rate_Layer_2': 0.13684406622563874, 'dropout_rate_Layer_3': 0.0007228234789017716, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005156638704030211, 'l1_Layer_2': 0.007585812581351887, 'l1_Layer_3': 7.992715126039104e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 250, 'n_units_Layer_3': 120}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.60 | sMAPE for Validation Set is: 10.29% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.89 | sMAPE for Test Set is: 11.27% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:40:53,286]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:40:58,326]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:41:02,057]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:41:02,752]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:41:03,603]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:41:09,031]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:41:14,008]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:41:19,677]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:41:22,862]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:41:23,385]\u001b[0m Trial 1186 finished with value: 5.295201803052891 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012933323327902041, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22071525881476098, 'dropout_rate_Layer_2': 0.10430975229822118, 'dropout_rate_Layer_3': 0.20417463400659072, 'dropout_rate_Layer_4': 0.2764061628270857, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.01654740107392902, 'l1_Layer_2': 0.04373598257877603, 'l1_Layer_3': 0.006114630697323268, 'l1_Layer_4': 0.0012462751291943371, 'n_units_Layer_1': 280, 'n_units_Layer_2': 100, 'n_units_Layer_3': 200, 'n_units_Layer_4': 95}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.30 | sMAPE for Validation Set is: 11.77% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.26 | sMAPE for Test Set is: 12.13% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:41:31,121]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:41:38,449]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:41:43,517]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:41:47,640]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:41:51,801]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:41:51,929]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:41:53,091]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:42:02,123]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:42:02,770]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:42:10,445]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:42:14,876]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:42:39,787]\u001b[0m Trial 1202 finished with value: 4.5307354218023015 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005622306401104483, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10760991379222772, 'dropout_rate_Layer_2': 0.12763648797745628, 'dropout_rate_Layer_3': 0.03047652035968975, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006671077217883789, 'l1_Layer_2': 0.003336720358844437, 'l1_Layer_3': 3.5416267542320805e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 230, 'n_units_Layer_3': 105}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.53 | sMAPE for Validation Set is: 10.24% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.94 | sMAPE for Test Set is: 11.51% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:42:43,919]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:42:52,149]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:42:59,996]\u001b[0m Trial 1209 finished with value: 4.935480136178726 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022082105311715923, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06580143774901338, 'dropout_rate_Layer_2': 0.04622298817787069, 'dropout_rate_Layer_3': 0.25343490674857566, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0013815801690012148, 'l1_Layer_2': 0.0010617745378516165, 'l1_Layer_3': 0.0010085353590564916, 'n_units_Layer_1': 125, 'n_units_Layer_2': 150, 'n_units_Layer_3': 270}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.94 | sMAPE for Validation Set is: 10.91% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.06 | sMAPE for Test Set is: 11.61% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:43:04,749]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.55 | sMAPE for Validation Set is: 10.18% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.03 | sMAPE for Test Set is: 11.72% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:43:06,970]\u001b[0m Trial 1211 finished with value: 4.547658550366344 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006800843167125865, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15938266602792237, 'dropout_rate_Layer_2': 0.12254757685347673, 'dropout_rate_Layer_3': 0.03167266687564708, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00748093437338741, 'l1_Layer_2': 0.0031907060249644977, 'l1_Layer_3': 1.8020442620401943e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 240, 'n_units_Layer_3': 140}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:43:10,893]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:43:12,415]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:43:17,914]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:43:23,849]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:43:35,194]\u001b[0m Trial 1214 finished with value: 4.4858621214044385 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005014482529549006, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1391031541712879, 'dropout_rate_Layer_2': 0.02134249583050111, 'dropout_rate_Layer_3': 0.07867275832179116, 'dropout_rate_Layer_4': 0.08134617596415417, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.005722619482480124, 'l1_Layer_2': 3.2381348433610923e-05, 'l1_Layer_3': 0.0007380452630327747, 'l1_Layer_4': 8.628973138949214e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 275, 'n_units_Layer_3': 280, 'n_units_Layer_4': 300}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.49 | sMAPE for Validation Set is: 10.16% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 3.88 | sMAPE for Test Set is: 11.22% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:43:44,158]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:43:48,540]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:44:04,540]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:44:06,174]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:44:07,571]\u001b[0m Trial 1217 finished with value: 4.557455558617022 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005242740271396534, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10970912117443489, 'dropout_rate_Layer_2': 0.12142926144079932, 'dropout_rate_Layer_3': 0.00013790883307766757, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006161610803631228, 'l1_Layer_2': 0.00515840308986842, 'l1_Layer_3': 3.939374753844802e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 215, 'n_units_Layer_3': 100}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.56 | sMAPE for Validation Set is: 10.27% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.90 | sMAPE for Test Set is: 11.30% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:44:13,852]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:44:25,778]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:44:30,388]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:44:31,894]\u001b[0m Trial 1228 finished with value: 4.9390376421059985 and parameters: {'n_hidden': 3, 'learning_rate': 0.006293320943039074, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05873405775967123, 'dropout_rate_Layer_2': 0.07404389491354284, 'dropout_rate_Layer_3': 0.23722926176173373, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0038381261288645612, 'l1_Layer_2': 0.0007845556174757009, 'l1_Layer_3': 0.0004216375661528705, 'n_units_Layer_1': 135, 'n_units_Layer_2': 120, 'n_units_Layer_3': 200}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.94 | sMAPE for Validation Set is: 10.87% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.27 | sMAPE for Test Set is: 12.14% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:44:33,455]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:44:36,008]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:44:45,167]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:44:51,945]\u001b[0m Trial 1225 finished with value: 4.4955344459642035 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006650089419349274, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08209776891236653, 'dropout_rate_Layer_2': 0.11730570636351488, 'dropout_rate_Layer_3': 0.031048471026771263, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006437954382343505, 'l1_Layer_2': 0.0033556959622557505, 'l1_Layer_3': 2.1061043340823688e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 230, 'n_units_Layer_3': 145}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.50 | sMAPE for Validation Set is: 10.14% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.01 | sMAPE for Test Set is: 11.67% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:44:54,410]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:44:56,683]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:44:59,364]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:45:02,188]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:45:05,270]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:45:06,495]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:45:11,723]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:45:11,796]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:45:13,113]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:45:19,637]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:45:22,847]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:45:26,861]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:45:29,066]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:45:29,650]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:45:32,651]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:45:33,737]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:45:40,166]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:45:45,414]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:45:48,599]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:45:53,332]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:45:59,852]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:46:14,352]\u001b[0m Trial 1253 finished with value: 5.324702338120125 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008541084053778889, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2919199400051471, 'dropout_rate_Layer_2': 0.12120863788177973, 'dropout_rate_Layer_3': 0.15729697526011507, 'dropout_rate_Layer_4': 0.16874930260795085, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.03722509288963558, 'l1_Layer_2': 0.005205203657496124, 'l1_Layer_3': 0.0068540465726155755, 'l1_Layer_4': 0.00031634365758135874, 'n_units_Layer_1': 240, 'n_units_Layer_2': 95, 'n_units_Layer_3': 180, 'n_units_Layer_4': 60}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.32 | sMAPE for Validation Set is: 11.90% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.41 | sMAPE for Test Set is: 12.61% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:46:20,129]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:46:22,551]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:46:26,942]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:46:28,893]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:46:34,994]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:46:39,916]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:46:40,331]\u001b[0m Trial 1256 finished with value: 4.827826721956833 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008370063790829495, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2909563739405519, 'dropout_rate_Layer_2': 0.12119269196411006, 'dropout_rate_Layer_3': 0.17931254137538213, 'dropout_rate_Layer_4': 0.1435540974048048, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.02425741256680956, 'l1_Layer_2': 0.005202720120129917, 'l1_Layer_3': 0.0006033081004984789, 'l1_Layer_4': 0.0002560437495993699, 'n_units_Layer_1': 240, 'n_units_Layer_2': 80, 'n_units_Layer_3': 180, 'n_units_Layer_4': 165}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.83 | sMAPE for Validation Set is: 10.88% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.05 | sMAPE for Test Set is: 11.67% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:46:46,098]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:46:46,143]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:46:52,747]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:46:57,724]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:47:01,846]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:47:06,319]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:47:10,620]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:47:15,748]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:47:42,619]\u001b[0m Trial 1266 finished with value: 4.543487995336842 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007251869519779378, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1029792009978343, 'dropout_rate_Layer_2': 0.12690974259570595, 'dropout_rate_Layer_3': 0.050839580291619266, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003685124155807452, 'l1_Layer_2': 0.007833648717245975, 'l1_Layer_3': 2.7136602513291557e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 225, 'n_units_Layer_3': 140}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.54 | sMAPE for Validation Set is: 10.15% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.06 | sMAPE for Test Set is: 11.80% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:48:00,241]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:48:16,293]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:48:24,466]\u001b[0m Trial 1268 finished with value: 4.556998749796018 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006928919631752907, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10316614194761975, 'dropout_rate_Layer_2': 0.12892663817719452, 'dropout_rate_Layer_3': 0.00796997619942892, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0039047098731236573, 'l1_Layer_2': 0.0037563210523761034, 'l1_Layer_3': 2.6312360632245852e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 225, 'n_units_Layer_3': 140}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.56 | sMAPE for Validation Set is: 10.20% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.03 | sMAPE for Test Set is: 11.68% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:48:25,634]\u001b[0m Trial 1275 finished with value: 4.603677705226665 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007863098032444278, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0813671005926986, 'dropout_rate_Layer_2': 0.1134648446209116, 'dropout_rate_Layer_3': 0.00866641954745645, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006638841894929821, 'l1_Layer_2': 0.0037139339209549724, 'l1_Layer_3': 2.534841528497409e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 195, 'n_units_Layer_3': 140}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.60 | sMAPE for Validation Set is: 10.24% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 3.97 | sMAPE for Test Set is: 11.41% | rMAE for Test Set is: 0.64\n",
      "MAE for Validation Set is: 4.51 | sMAPE for Validation Set is: 10.14% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 3.88 | sMAPE for Test Set is: 11.31% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:48:25,802]\u001b[0m Trial 1269 finished with value: 4.510791377586138 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005065355090562404, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05767457895030001, 'dropout_rate_Layer_2': 0.12875790324476624, 'dropout_rate_Layer_3': 0.05068244170646647, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003507225268738068, 'l1_Layer_2': 0.008359152593367196, 'l1_Layer_3': 2.5817186686063625e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 210, 'n_units_Layer_3': 265}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:48:33,060]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:48:36,724]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:48:39,639]\u001b[0m Trial 1278 finished with value: 5.24728640288614 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013603002576241764, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21876845472790896, 'dropout_rate_Layer_2': 0.0739599984514385, 'dropout_rate_Layer_3': 0.1767681245712645, 'dropout_rate_Layer_4': 0.1428833184233487, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.02627331041479229, 'l1_Layer_2': 0.059899934740542844, 'l1_Layer_3': 0.0006010816655097979, 'l1_Layer_4': 6.725901369422878e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 80, 'n_units_Layer_3': 170, 'n_units_Layer_4': 170}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.25 | sMAPE for Validation Set is: 11.74% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.20 | sMAPE for Test Set is: 12.01% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:48:42,261]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:48:44,875]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:48:48,194]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:48:51,467]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:48:56,747]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:49:06,279]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:49:07,306]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:49:07,395]\u001b[0m Trial 1281 finished with value: 4.854557108004443 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013468738005487464, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29998879814391843, 'dropout_rate_Layer_2': 0.07860266247960243, 'dropout_rate_Layer_3': 0.1816230611210264, 'dropout_rate_Layer_4': 0.14738520494979246, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00026540547342996496, 'l1_Layer_2': 0.0549718898819498, 'l1_Layer_3': 0.0006494605147132628, 'l1_Layer_4': 0.002131626296029934, 'n_units_Layer_1': 300, 'n_units_Layer_2': 80, 'n_units_Layer_3': 195, 'n_units_Layer_4': 130}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.85 | sMAPE for Validation Set is: 10.97% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 3.96 | sMAPE for Test Set is: 11.38% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:49:16,137]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:49:16,646]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:49:20,875]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:49:22,726]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:49:24,719]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:49:28,585]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:49:32,724]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:49:33,438]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:49:34,957]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:49:38,500]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:49:45,876]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:49:58,751]\u001b[0m Trial 1291 finished with value: 4.545848621505155 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007503746829827087, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09848945291214894, 'dropout_rate_Layer_2': 0.009696004079555568, 'dropout_rate_Layer_3': 0.05440729096131681, 'dropout_rate_Layer_4': 0.056304617771602755, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.008170029212842702, 'l1_Layer_2': 3.472329454808871e-05, 'l1_Layer_3': 0.00039012266063129627, 'l1_Layer_4': 4.43982416221264e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 250, 'n_units_Layer_3': 295, 'n_units_Layer_4': 285}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.55 | sMAPE for Validation Set is: 10.26% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.93 | sMAPE for Test Set is: 11.42% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:50:02,336]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:50:06,578]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:50:07,413]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:50:13,596]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:50:14,128]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:50:21,541]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:50:24,230]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:50:27,332]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:50:48,395]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:50:52,710]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:50:52,897]\u001b[0m Trial 1301 finished with value: 4.573388731941387 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006435725532672452, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1399223112427151, 'dropout_rate_Layer_2': 0.017647105553515344, 'dropout_rate_Layer_3': 0.05117693943949267, 'dropout_rate_Layer_4': 0.05392831601073267, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.004874068825335271, 'l1_Layer_2': 2.1935550466973872e-05, 'l1_Layer_3': 0.0014336036861808618, 'l1_Layer_4': 9.592127211558089e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 260, 'n_units_Layer_3': 275, 'n_units_Layer_4': 295}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.57 | sMAPE for Validation Set is: 10.27% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.06 | sMAPE for Test Set is: 11.79% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:51:05,996]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:51:06,340]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:51:07,796]\u001b[0m Trial 1312 finished with value: 4.631077374066721 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010131076131272051, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23621859891812663, 'dropout_rate_Layer_2': 0.036443084250397266, 'dropout_rate_Layer_3': 0.2576761890680643, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011134021956130198, 'l1_Layer_2': 0.0012147096747698416, 'l1_Layer_3': 0.0002198771800882102, 'n_units_Layer_1': 230, 'n_units_Layer_2': 165, 'n_units_Layer_3': 150}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.63 | sMAPE for Validation Set is: 10.40% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 3.93 | sMAPE for Test Set is: 11.39% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:51:13,973]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:51:16,057]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:51:20,706]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:51:26,056]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:51:34,517]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:51:39,260]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:51:44,028]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:51:47,547]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:51:48,762]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:51:53,581]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:51:59,150]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:52:02,159]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:52:05,903]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:52:08,927]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:52:11,046]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:52:16,243]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:52:22,832]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:52:26,855]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:52:39,106]\u001b[0m Trial 1319 finished with value: 4.5922254448762825 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007479987121253798, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09903709914901405, 'dropout_rate_Layer_2': 0.11065034504495276, 'dropout_rate_Layer_3': 0.00015335721916682988, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.007363755723955498, 'l1_Layer_2': 0.0028163994226506586, 'l1_Layer_3': 3.403608520363165e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 210, 'n_units_Layer_3': 150}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.59 | sMAPE for Validation Set is: 10.33% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.00 | sMAPE for Test Set is: 11.64% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:52:43,524]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:52:52,164]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:52:56,138]\u001b[0m Trial 1332 finished with value: 4.768093327055209 and parameters: {'n_hidden': 4, 'learning_rate': 0.001085214777469632, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28888263094347183, 'dropout_rate_Layer_2': 0.06105326285234505, 'dropout_rate_Layer_3': 0.016228507363694272, 'dropout_rate_Layer_4': 0.13740378770108647, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00023968993133227274, 'l1_Layer_2': 0.06474303949079317, 'l1_Layer_3': 4.858594060062823e-05, 'l1_Layer_4': 2.1504719708936978e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 65, 'n_units_Layer_3': 265, 'n_units_Layer_4': 140}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.77 | sMAPE for Validation Set is: 10.59% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 3.97 | sMAPE for Test Set is: 11.29% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:53:09,949]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:53:13,060]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:53:15,950]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:53:16,794]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:53:31,926]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:53:36,969]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:53:36,988]\u001b[0m Trial 1325 finished with value: 4.601660286669847 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005898988195650888, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09471093092721304, 'dropout_rate_Layer_2': 0.019839326592905913, 'dropout_rate_Layer_3': 0.05337485523965741, 'dropout_rate_Layer_4': 0.06053648397979127, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0067166706776278515, 'l1_Layer_2': 6.198753162783738e-05, 'l1_Layer_3': 0.0006014383141145093, 'l1_Layer_4': 7.547336322883397e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 265, 'n_units_Layer_3': 280, 'n_units_Layer_4': 300}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.60 | sMAPE for Validation Set is: 10.26% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.84 | sMAPE for Test Set is: 11.09% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:53:45,464]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:53:45,581]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:53:52,462]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:53:55,148]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:54:00,150]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:54:03,976]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:54:08,400]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:54:13,188]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:54:13,261]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:54:19,985]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:54:24,351]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:54:24,752]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:54:32,363]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:54:56,249]\u001b[0m Trial 1356 finished with value: 4.71382058062811 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009352594804052602, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21547723711988698, 'dropout_rate_Layer_2': 0.03985083382034389, 'dropout_rate_Layer_3': 0.27497192607046095, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001173565183238066, 'l1_Layer_2': 0.0007486934733136952, 'l1_Layer_3': 0.0001630094058595941, 'n_units_Layer_1': 235, 'n_units_Layer_2': 170, 'n_units_Layer_3': 135}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.71 | sMAPE for Validation Set is: 10.62% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 3.97 | sMAPE for Test Set is: 11.60% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:55:02,446]\u001b[0m Trial 1342 finished with value: 4.489024472316551 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005620106394749576, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03613201761340224, 'dropout_rate_Layer_2': 0.10723805916945327, 'dropout_rate_Layer_3': 0.007163461684144024, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008607554152714214, 'l1_Layer_2': 0.0032830620224923303, 'l1_Layer_3': 3.639423148073606e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 220, 'n_units_Layer_3': 140}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.49 | sMAPE for Validation Set is: 10.12% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 3.88 | sMAPE for Test Set is: 11.22% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:55:06,723]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:55:16,759]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:55:20,855]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:55:25,518]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:55:27,993]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:55:34,329]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:55:39,092]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:55:44,346]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:55:49,502]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:55:49,915]\u001b[0m Trial 1360 finished with value: 4.5596052909075 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007563994326904712, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09368614539163063, 'dropout_rate_Layer_2': 0.13029456759837324, 'dropout_rate_Layer_3': 0.018512623655102884, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0032597549528484674, 'l1_Layer_2': 0.001902763034931888, 'l1_Layer_3': 4.907220871095984e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 215, 'n_units_Layer_3': 130}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.56 | sMAPE for Validation Set is: 10.23% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.86 | sMAPE for Test Set is: 11.23% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:55:56,984]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:56:10,225]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:56:11,025]\u001b[0m Trial 1358 finished with value: 4.588373247857867 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007347283454218797, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09078462826695537, 'dropout_rate_Layer_2': 0.13005305703314807, 'dropout_rate_Layer_3': 0.01829359694398788, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003927265740223667, 'l1_Layer_2': 2.7979096231605595e-05, 'l1_Layer_3': 1.7833021073536688e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 230, 'n_units_Layer_3': 130}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.59 | sMAPE for Validation Set is: 10.28% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.91 | sMAPE for Test Set is: 11.33% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:56:50,120]\u001b[0m Trial 1366 finished with value: 4.524543744798479 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005047651240922687, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07247914313907326, 'dropout_rate_Layer_2': 0.10156392557464736, 'dropout_rate_Layer_3': 0.02108794155987271, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008794521499662084, 'l1_Layer_2': 0.002122074627524116, 'l1_Layer_3': 5.1483000923945736e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 225, 'n_units_Layer_3': 155}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.52 | sMAPE for Validation Set is: 10.16% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 3.89 | sMAPE for Test Set is: 11.25% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:56:54,076]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:56:54,233]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:56:56,036]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:57:03,186]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:57:06,759]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:57:15,336]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:57:21,116]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:57:27,942]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:57:48,784]\u001b[0m Trial 1373 finished with value: 4.5322965030563624 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005045673664037881, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04216545745995322, 'dropout_rate_Layer_2': 0.10047637330408277, 'dropout_rate_Layer_3': 0.01866418779662588, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0031579074281518843, 'l1_Layer_2': 0.002151630846926834, 'l1_Layer_3': 4.9348201542271034e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 215, 'n_units_Layer_3': 150}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.53 | sMAPE for Validation Set is: 10.17% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.91 | sMAPE for Test Set is: 11.37% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:58:08,477]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:58:16,347]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:58:16,915]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:58:35,813]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:58:40,327]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:58:44,231]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:58:50,722]\u001b[0m Trial 1379 finished with value: 4.5362675461866795 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006320589114366263, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11032517286488248, 'dropout_rate_Layer_2': 0.018057136386286265, 'dropout_rate_Layer_3': 0.01799560927741779, 'dropout_rate_Layer_4': 0.03977086243591518, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.006554762027407455, 'l1_Layer_2': 2.4995393246141102e-05, 'l1_Layer_3': 0.000646597849535006, 'l1_Layer_4': 6.743770695539666e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 290, 'n_units_Layer_3': 290, 'n_units_Layer_4': 300}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.54 | sMAPE for Validation Set is: 10.21% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.96 | sMAPE for Test Set is: 11.48% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:58:54,538]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:58:55,063]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:58:57,832]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:59:04,560]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:59:08,932]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:59:11,588]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:59:14,946]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:59:15,726]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:59:25,527]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:59:31,261]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:59:35,071]\u001b[0m Trial 1399 finished with value: 4.987452954637715 and parameters: {'n_hidden': 4, 'learning_rate': 0.012574434698849809, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2561339722817831, 'dropout_rate_Layer_2': 0.06912030498872648, 'dropout_rate_Layer_3': 0.007079136028402926, 'dropout_rate_Layer_4': 0.1689068812379443, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0009381765002176061, 'l1_Layer_2': 0.05504462258042503, 'l1_Layer_3': 0.00011988347218349764, 'l1_Layer_4': 1.2870888532828182e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 85, 'n_units_Layer_3': 260, 'n_units_Layer_4': 120}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.99 | sMAPE for Validation Set is: 10.94% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.50 | sMAPE for Test Set is: 12.57% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:59:53,990]\u001b[0m Trial 1402 finished with value: 4.770029058558538 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006682160616474731, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2272269056336788, 'dropout_rate_Layer_2': 0.037797870634525624, 'dropout_rate_Layer_3': 0.2567187661068263, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0068200691131937e-05, 'l1_Layer_2': 0.0009170217831189309, 'l1_Layer_3': 0.00034708681002785564, 'n_units_Layer_1': 250, 'n_units_Layer_2': 170, 'n_units_Layer_3': 140}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:59:54,023]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.77 | sMAPE for Validation Set is: 10.64% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.00 | sMAPE for Test Set is: 11.56% | rMAE for Test Set is: 0.65\n",
      "MAE for Validation Set is: 4.56 | sMAPE for Validation Set is: 10.25% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.84 | sMAPE for Test Set is: 11.04% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:59:58,366]\u001b[0m Trial 1388 finished with value: 4.560836248224676 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005082721430451886, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03887104054022087, 'dropout_rate_Layer_2': 0.08294350609828459, 'dropout_rate_Layer_3': 0.021341638645614586, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002810019777167759, 'l1_Layer_2': 0.001546884284833604, 'l1_Layer_3': 4.519212870325245e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 210, 'n_units_Layer_3': 150}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:00:01,981]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:00:04,728]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:00:07,518]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:00:10,285]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:00:18,316]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:00:21,740]\u001b[0m Trial 1404 finished with value: 4.801372788267652 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006889867413534153, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24030027312785449, 'dropout_rate_Layer_2': 0.058255732397129424, 'dropout_rate_Layer_3': 0.2482346838121557, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.82818158000555e-05, 'l1_Layer_2': 0.0007728294172243897, 'l1_Layer_3': 0.0003455350015468108, 'n_units_Layer_1': 240, 'n_units_Layer_2': 175, 'n_units_Layer_3': 130}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.80 | sMAPE for Validation Set is: 10.71% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.05 | sMAPE for Test Set is: 11.73% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 21:00:24,882]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:00:25,777]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:00:35,338]\u001b[0m Trial 1409 finished with value: 4.822494305640848 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007072487399522386, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2151959679736224, 'dropout_rate_Layer_2': 0.03747559534539571, 'dropout_rate_Layer_3': 0.26580866715532936, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.563029391239326e-05, 'l1_Layer_2': 0.0004015540370464177, 'l1_Layer_3': 0.00019152751026042962, 'n_units_Layer_1': 240, 'n_units_Layer_2': 190, 'n_units_Layer_3': 125}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.82 | sMAPE for Validation Set is: 10.77% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.07 | sMAPE for Test Set is: 11.70% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 21:00:38,632]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:00:41,339]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:00:44,501]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:00:48,234]\u001b[0m Trial 1413 finished with value: 4.754508749213299 and parameters: {'n_hidden': 4, 'learning_rate': 0.013447239305825616, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2726979524133305, 'dropout_rate_Layer_2': 0.029483106823210162, 'dropout_rate_Layer_3': 0.02325534489561409, 'dropout_rate_Layer_4': 0.1079877395613263, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0001578968554920333, 'l1_Layer_2': 0.05425043780625056, 'l1_Layer_3': 0.00013512147647167346, 'l1_Layer_4': 2.2317748453360835e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 85, 'n_units_Layer_3': 260, 'n_units_Layer_4': 125}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.75 | sMAPE for Validation Set is: 10.59% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.16 | sMAPE for Test Set is: 11.88% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 21:00:49,115]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:00:56,776]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:01:03,574]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:01:04,428]\u001b[0m Trial 1400 finished with value: 4.55145367129555 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006278345109492734, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.043497440472142976, 'dropout_rate_Layer_2': 0.10364762416318947, 'dropout_rate_Layer_3': 0.022679474382104225, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0031373820376087236, 'l1_Layer_2': 0.001640484092782822, 'l1_Layer_3': 2.112686603844119e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 205, 'n_units_Layer_3': 145}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.55 | sMAPE for Validation Set is: 10.23% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.82 | sMAPE for Test Set is: 11.11% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 21:01:10,707]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:01:16,703]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:01:53,181]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:02:10,379]\u001b[0m Trial 1423 finished with value: 4.569007697083209 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005984861531328842, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10367556885080806, 'dropout_rate_Layer_2': 0.008400003486376338, 'dropout_rate_Layer_3': 0.050861972688476316, 'dropout_rate_Layer_4': 0.10966947440778406, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.003729727458562884, 'l1_Layer_2': 3.0716285441951205e-05, 'l1_Layer_3': 0.0005509175205312994, 'l1_Layer_4': 3.7080657246095206e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 260, 'n_units_Layer_3': 300, 'n_units_Layer_4': 290}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.57 | sMAPE for Validation Set is: 10.31% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.97 | sMAPE for Test Set is: 11.42% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 21:02:15,234]\u001b[0m Trial 1421 finished with value: 4.552213563146538 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006232138219721552, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.058070068023097596, 'dropout_rate_Layer_2': 0.09109182673521735, 'dropout_rate_Layer_3': 0.014541326381542957, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003717216587313428, 'l1_Layer_2': 0.001624445663282724, 'l1_Layer_3': 1.2282983722198159e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 215, 'n_units_Layer_3': 150}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.55 | sMAPE for Validation Set is: 10.19% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.90 | sMAPE for Test Set is: 11.29% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 21:02:16,952]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:02:24,044]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:02:28,732]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:02:34,482]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:02:36,122]\u001b[0m Trial 1425 finished with value: 4.64748265380522 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005767564212084676, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.032766689113274954, 'dropout_rate_Layer_2': 0.08993709293334051, 'dropout_rate_Layer_3': 0.016135801854684436, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0034969009703729377, 'l1_Layer_2': 0.0011443567053517555, 'l1_Layer_3': 2.297427592773718e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 210, 'n_units_Layer_3': 150}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.65 | sMAPE for Validation Set is: 10.55% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.02 | sMAPE for Test Set is: 11.76% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 21:02:41,703]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:02:41,899]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:02:43,153]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:02:43,951]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:02:50,264]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:02:54,579]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:02:57,866]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:03:00,836]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:03:04,039]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:03:08,602]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:03:12,185]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:03:12,839]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:03:16,061]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:03:19,792]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:03:26,063]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:03:34,795]\u001b[0m Trial 1444 finished with value: 5.093122572041978 and parameters: {'n_hidden': 4, 'learning_rate': 0.012855525815202329, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27063665999215053, 'dropout_rate_Layer_2': 0.035324422619098586, 'dropout_rate_Layer_3': 0.01413017567169691, 'dropout_rate_Layer_4': 0.08946135674944806, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00019267995185325931, 'l1_Layer_2': 0.05597178210723689, 'l1_Layer_3': 0.0002298854335757519, 'l1_Layer_4': 2.395904858241347e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 70, 'n_units_Layer_3': 265, 'n_units_Layer_4': 120}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.09 | sMAPE for Validation Set is: 11.35% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.18 | sMAPE for Test Set is: 12.25% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 21:03:37,885]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:03:46,017]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:03:50,977]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:03:55,489]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:03:57,452]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:04:02,644]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:04:03,273]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:04:08,579]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:04:12,804]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:04:17,402]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:04:18,839]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:04:23,167]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:04:23,615]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:04:31,017]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:04:39,352]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:04:44,893]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:04:48,505]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:04:49,454]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:04:53,749]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:04:58,822]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:04:59,675]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:05:05,400]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:05:12,058]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:05:12,726]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:05:15,079]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:05:23,116]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:05:25,208]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:05:31,660]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:05:37,376]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:05:42,191]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:05:45,410]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:05:45,798]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:05:46,998]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:05:56,157]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:05:59,698]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:06:04,095]\u001b[0m Trial 1461 finished with value: 4.609357839851629 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005749095270478942, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07750251587304556, 'dropout_rate_Layer_2': 0.11167225968443513, 'dropout_rate_Layer_3': 0.033251070320470505, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007396580536441989, 'l1_Layer_2': 0.002315770881679231, 'l1_Layer_3': 5.884923332829656e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 225, 'n_units_Layer_3': 135}. Best is trial 785 with value: 4.461175029353279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.61 | sMAPE for Validation Set is: 10.29% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 3.98 | sMAPE for Test Set is: 11.57% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 21:06:08,522]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:06:13,212]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:06:16,207]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:06:19,306]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:06:24,196]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:06:29,062]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:06:29,287]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:06:35,236]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:06:38,739]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:06:39,864]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:06:46,360]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:06:48,155]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:06:52,476]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:06:54,596]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:07:00,282]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:07:02,010]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:07:02,351]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:07:13,977]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-01-01, MAE is:7.14 & sMAPE is:17.31% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :7.14 & 17.31% & 1.09\n",
      "for 2019-01-02, MAE is:6.08 & sMAPE is:10.77% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 14.04% & 0.80\n",
      "for 2019-01-03, MAE is:2.88 & sMAPE is:4.74% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :5.37 & 10.94% & 1.14\n",
      "for 2019-01-04, MAE is:2.97 & sMAPE is:4.89% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :4.77 & 9.42% & 1.06\n",
      "for 2019-01-05, MAE is:3.63 & sMAPE is:6.01% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.54 & 8.74% & 0.99\n",
      "for 2019-01-06, MAE is:3.51 & sMAPE is:6.12% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :4.37 & 8.30% & 0.87\n",
      "for 2019-01-07, MAE is:5.47 & sMAPE is:8.37% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :4.53 & 8.31% & 0.82\n",
      "for 2019-01-08, MAE is:7.54 & sMAPE is:12.06% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 8.78% & 0.77\n",
      "for 2019-01-09, MAE is:3.66 & sMAPE is:5.83% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :4.76 & 8.45% & 0.79\n",
      "for 2019-01-10, MAE is:5.40 & sMAPE is:8.28% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :4.83 & 8.44% & 0.80\n",
      "for 2019-01-11, MAE is:4.84 & sMAPE is:8.18% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :4.83 & 8.41% & 0.89\n",
      "for 2019-01-12, MAE is:5.22 & sMAPE is:8.44% & rMAE is:2.00 ||| daily mean of MAE & sMAPE & rMAE till now are :4.86 & 8.42% & 0.98\n",
      "for 2019-01-13, MAE is:4.78 & sMAPE is:10.09% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.86 & 8.54% & 0.94\n",
      "for 2019-01-14, MAE is:3.09 & sMAPE is:5.98% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :4.73 & 8.36% & 0.92\n",
      "for 2019-01-15, MAE is:4.04 & sMAPE is:7.18% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 8.28% & 0.92\n",
      "for 2019-01-16, MAE is:4.85 & sMAPE is:7.99% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 8.26% & 0.96\n",
      "for 2019-01-17, MAE is:4.73 & sMAPE is:8.36% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :4.70 & 8.27% & 0.96\n",
      "for 2019-01-18, MAE is:3.87 & sMAPE is:6.07% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.65 & 8.15% & 0.98\n",
      "for 2019-01-19, MAE is:3.93 & sMAPE is:6.64% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :4.61 & 8.07% & 0.97\n",
      "for 2019-01-20, MAE is:3.78 & sMAPE is:6.54% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 7.99% & 0.94\n",
      "for 2019-01-21, MAE is:4.71 & sMAPE is:6.59% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :4.58 & 7.93% & 0.91\n",
      "for 2019-01-22, MAE is:4.91 & sMAPE is:6.78% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :4.59 & 7.87% & 0.92\n",
      "for 2019-01-23, MAE is:5.71 & sMAPE is:7.96% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :4.64 & 7.88% & 0.90\n",
      "for 2019-01-24, MAE is:18.32 & sMAPE is:23.78% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :5.21 & 8.54% & 0.90\n",
      "for 2019-01-25, MAE is:8.63 & sMAPE is:11.34% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :5.35 & 8.65% & 0.92\n",
      "for 2019-01-26, MAE is:3.86 & sMAPE is:6.69% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :5.29 & 8.58% & 0.90\n",
      "for 2019-01-27, MAE is:3.52 & sMAPE is:7.26% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :5.22 & 8.53% & 0.88\n",
      "for 2019-01-28, MAE is:3.24 & sMAPE is:6.04% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :5.15 & 8.44% & 0.86\n",
      "for 2019-01-29, MAE is:4.20 & sMAPE is:6.98% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :5.12 & 8.39% & 0.86\n",
      "for 2019-01-30, MAE is:2.95 & sMAPE is:5.02% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :5.05 & 8.28% & 0.85\n",
      "for 2019-01-31, MAE is:4.50 & sMAPE is:7.17% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :5.03 & 8.24% & 0.83\n",
      "for 2019-02-01, MAE is:4.48 & sMAPE is:8.19% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :5.01 & 8.24% & 0.81\n",
      "for 2019-02-02, MAE is:2.22 & sMAPE is:4.15% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :4.93 & 8.11% & 0.81\n",
      "for 2019-02-03, MAE is:1.91 & sMAPE is:3.89% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :4.84 & 7.99% & 0.81\n",
      "for 2019-02-04, MAE is:3.33 & sMAPE is:6.11% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 7.94% & 0.81\n",
      "for 2019-02-05, MAE is:4.46 & sMAPE is:7.63% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :4.79 & 7.93% & 0.81\n",
      "for 2019-02-06, MAE is:4.11 & sMAPE is:7.49% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :4.77 & 7.92% & 0.80\n",
      "for 2019-02-07, MAE is:3.33 & sMAPE is:6.72% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.73 & 7.89% & 0.79\n",
      "for 2019-02-08, MAE is:4.24 & sMAPE is:8.89% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :4.72 & 7.91% & 0.78\n",
      "for 2019-02-09, MAE is:6.31 & sMAPE is:14.06% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :4.76 & 8.06% & 0.80\n",
      "for 2019-02-10, MAE is:6.38 & sMAPE is:15.27% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 8.24% & 0.81\n",
      "for 2019-02-11, MAE is:7.49 & sMAPE is:15.54% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :4.86 & 8.41% & 0.82\n",
      "for 2019-02-12, MAE is:3.14 & sMAPE is:6.00% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :4.82 & 8.36% & 0.81\n",
      "for 2019-02-13, MAE is:3.32 & sMAPE is:7.23% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :4.79 & 8.33% & 0.82\n",
      "for 2019-02-14, MAE is:5.30 & sMAPE is:11.24% & rMAE is:2.04 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 8.40% & 0.84\n",
      "for 2019-02-15, MAE is:5.38 & sMAPE is:11.16% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :4.81 & 8.46% & 0.85\n",
      "for 2019-02-16, MAE is:4.85 & sMAPE is:11.73% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :4.81 & 8.53% & 0.85\n",
      "for 2019-02-17, MAE is:2.54 & sMAPE is:6.26% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :4.77 & 8.48% & 0.84\n",
      "for 2019-02-18, MAE is:3.08 & sMAPE is:6.88% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :4.73 & 8.45% & 0.84\n",
      "for 2019-02-19, MAE is:3.22 & sMAPE is:6.85% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :4.70 & 8.41% & 0.84\n",
      "for 2019-02-20, MAE is:4.19 & sMAPE is:8.54% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 8.42% & 0.85\n",
      "for 2019-02-21, MAE is:3.00 & sMAPE is:6.77% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :4.66 & 8.39% & 0.85\n",
      "for 2019-02-22, MAE is:4.07 & sMAPE is:9.16% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :4.65 & 8.40% & 0.86\n",
      "for 2019-02-23, MAE is:4.08 & sMAPE is:10.15% & rMAE is:2.51 ||| daily mean of MAE & sMAPE & rMAE till now are :4.64 & 8.43% & 0.89\n",
      "for 2019-02-24, MAE is:3.05 & sMAPE is:7.73% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.61 & 8.42% & 0.90\n",
      "for 2019-02-25, MAE is:5.28 & sMAPE is:11.03% & rMAE is:3.39 ||| daily mean of MAE & sMAPE & rMAE till now are :4.62 & 8.47% & 0.95\n",
      "for 2019-02-26, MAE is:4.44 & sMAPE is:10.10% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :4.62 & 8.50% & 0.95\n",
      "for 2019-02-27, MAE is:5.82 & sMAPE is:14.02% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :4.64 & 8.59% & 0.95\n",
      "for 2019-02-28, MAE is:4.26 & sMAPE is:10.60% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.63 & 8.62% & 0.95\n",
      "for 2019-03-01, MAE is:3.18 & sMAPE is:7.43% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :4.61 & 8.60% & 0.95\n",
      "for 2019-03-02, MAE is:4.50 & sMAPE is:11.39% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :4.61 & 8.65% & 0.96\n",
      "for 2019-03-03, MAE is:10.50 & sMAPE is:44.04% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.70 & 9.22% & 0.96\n",
      "for 2019-03-04, MAE is:3.71 & sMAPE is:10.15% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 9.24% & 0.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-03-05, MAE is:4.47 & sMAPE is:11.85% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 9.28% & 0.94\n",
      "for 2019-03-06, MAE is:4.20 & sMAPE is:10.82% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :4.67 & 9.30% & 0.95\n",
      "for 2019-03-07, MAE is:5.04 & sMAPE is:14.42% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 9.38% & 0.95\n",
      "for 2019-03-08, MAE is:4.91 & sMAPE is:12.37% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 9.42% & 0.95\n",
      "for 2019-03-09, MAE is:3.64 & sMAPE is:11.79% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :4.67 & 9.46% & 0.94\n",
      "for 2019-03-10, MAE is:4.91 & sMAPE is:21.11% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :4.67 & 9.63% & 0.94\n",
      "for 2019-03-11, MAE is:7.20 & sMAPE is:20.29% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.71 & 9.78% & 0.94\n",
      "for 2019-03-12, MAE is:5.30 & sMAPE is:13.03% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :4.72 & 9.82% & 0.94\n",
      "for 2019-03-13, MAE is:3.23 & sMAPE is:9.57% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 9.82% & 0.94\n",
      "for 2019-03-14, MAE is:3.68 & sMAPE is:11.68% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 9.85% & 0.94\n",
      "for 2019-03-15, MAE is:4.29 & sMAPE is:14.08% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 9.90% & 0.93\n",
      "for 2019-03-16, MAE is:3.98 & sMAPE is:17.48% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :4.67 & 10.00% & 0.92\n",
      "for 2019-03-17, MAE is:13.03 & sMAPE is:94.84% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :4.78 & 11.12% & 0.92\n",
      "for 2019-03-18, MAE is:10.08 & sMAPE is:27.84% & rMAE is:3.29 ||| daily mean of MAE & sMAPE & rMAE till now are :4.85 & 11.34% & 0.95\n",
      "for 2019-03-19, MAE is:6.39 & sMAPE is:15.45% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 11.39% & 0.96\n",
      "for 2019-03-20, MAE is:4.63 & sMAPE is:11.69% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.86 & 11.39% & 0.96\n",
      "for 2019-03-21, MAE is:4.17 & sMAPE is:10.51% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.85 & 11.38% & 0.95\n",
      "for 2019-03-22, MAE is:4.70 & sMAPE is:12.15% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.85 & 11.39% & 0.94\n",
      "for 2019-03-23, MAE is:3.93 & sMAPE is:11.97% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.84 & 11.40% & 0.94\n",
      "for 2019-03-24, MAE is:5.17 & sMAPE is:18.84% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :4.84 & 11.49% & 0.93\n",
      "for 2019-03-25, MAE is:2.98 & sMAPE is:8.24% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :4.82 & 11.45% & 0.93\n",
      "for 2019-03-26, MAE is:3.29 & sMAPE is:8.42% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 11.42% & 0.92\n",
      "for 2019-03-27, MAE is:3.40 & sMAPE is:8.92% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.79 & 11.39% & 0.93\n",
      "for 2019-03-28, MAE is:5.19 & sMAPE is:13.60% & rMAE is:2.68 ||| daily mean of MAE & sMAPE & rMAE till now are :4.79 & 11.41% & 0.95\n",
      "for 2019-03-29, MAE is:4.13 & sMAPE is:10.59% & rMAE is:2.52 ||| daily mean of MAE & sMAPE & rMAE till now are :4.78 & 11.40% & 0.97\n",
      "for 2019-03-30, MAE is:5.00 & sMAPE is:15.25% & rMAE is:2.75 ||| daily mean of MAE & sMAPE & rMAE till now are :4.79 & 11.45% & 0.99\n",
      "for 2019-03-31, MAE is:5.34 & sMAPE is:20.41% & rMAE is:1.81 ||| daily mean of MAE & sMAPE & rMAE till now are :4.79 & 11.55% & 1.00\n",
      "for 2019-04-01, MAE is:4.36 & sMAPE is:12.22% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :4.79 & 11.55% & 1.00\n",
      "for 2019-04-02, MAE is:3.54 & sMAPE is:9.89% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :4.78 & 11.53% & 1.01\n",
      "for 2019-04-03, MAE is:5.49 & sMAPE is:13.81% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.78 & 11.56% & 1.01\n",
      "for 2019-04-04, MAE is:2.96 & sMAPE is:7.29% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.76 & 11.51% & 1.02\n",
      "for 2019-04-05, MAE is:6.30 & sMAPE is:15.59% & rMAE is:1.78 ||| daily mean of MAE & sMAPE & rMAE till now are :4.78 & 11.56% & 1.03\n",
      "for 2019-04-06, MAE is:4.03 & sMAPE is:11.12% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :4.77 & 11.55% & 1.02\n",
      "for 2019-04-07, MAE is:4.38 & sMAPE is:12.86% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :4.77 & 11.57% & 1.02\n",
      "for 2019-04-08, MAE is:4.11 & sMAPE is:9.82% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :4.76 & 11.55% & 1.02\n",
      "for 2019-04-09, MAE is:3.14 & sMAPE is:7.41% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :4.74 & 11.51% & 1.01\n",
      "for 2019-04-10, MAE is:3.82 & sMAPE is:9.38% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.74 & 11.48% & 1.01\n",
      "for 2019-04-11, MAE is:7.34 & sMAPE is:17.22% & rMAE is:2.11 ||| daily mean of MAE & sMAPE & rMAE till now are :4.76 & 11.54% & 1.02\n",
      "for 2019-04-12, MAE is:4.14 & sMAPE is:9.19% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :4.76 & 11.52% & 1.03\n",
      "for 2019-04-13, MAE is:4.06 & sMAPE is:10.26% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :4.75 & 11.51% & 1.03\n",
      "for 2019-04-14, MAE is:4.85 & sMAPE is:12.62% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :4.75 & 11.52% & 1.03\n",
      "for 2019-04-15, MAE is:4.48 & sMAPE is:9.98% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :4.75 & 11.50% & 1.03\n",
      "for 2019-04-16, MAE is:2.78 & sMAPE is:6.04% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :4.73 & 11.45% & 1.03\n",
      "for 2019-04-17, MAE is:5.98 & sMAPE is:13.24% & rMAE is:3.77 ||| daily mean of MAE & sMAPE & rMAE till now are :4.74 & 11.47% & 1.05\n",
      "for 2019-04-18, MAE is:4.21 & sMAPE is:10.87% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :4.74 & 11.46% & 1.05\n",
      "for 2019-04-19, MAE is:5.86 & sMAPE is:17.81% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :4.75 & 11.52% & 1.04\n",
      "for 2019-04-20, MAE is:6.96 & sMAPE is:21.47% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :4.77 & 11.61% & 1.05\n",
      "for 2019-04-21, MAE is:5.49 & sMAPE is:21.62% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :4.77 & 11.70% & 1.04\n",
      "for 2019-04-22, MAE is:18.31 & sMAPE is:76.36% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :4.89 & 12.28% & 1.04\n",
      "for 2019-04-23, MAE is:10.10 & sMAPE is:55.17% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.94 & 12.66% & 1.03\n",
      "for 2019-04-24, MAE is:4.67 & sMAPE is:14.77% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.94 & 12.68% & 1.03\n",
      "for 2019-04-25, MAE is:3.18 & sMAPE is:9.82% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :4.92 & 12.65% & 1.02\n",
      "for 2019-04-26, MAE is:6.38 & sMAPE is:17.93% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :4.93 & 12.70% & 1.03\n",
      "for 2019-04-27, MAE is:3.55 & sMAPE is:11.33% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :4.92 & 12.69% & 1.03\n",
      "for 2019-04-28, MAE is:9.20 & sMAPE is:31.77% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :4.96 & 12.85% & 1.03\n",
      "for 2019-04-29, MAE is:9.97 & sMAPE is:25.64% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.00 & 12.95% & 1.02\n",
      "for 2019-04-30, MAE is:5.64 & sMAPE is:13.81% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :5.01 & 12.96% & 1.02\n",
      "for 2019-05-01, MAE is:9.36 & sMAPE is:34.81% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :5.04 & 13.14% & 1.02\n",
      "for 2019-05-02, MAE is:7.35 & sMAPE is:20.62% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :5.06 & 13.20% & 1.02\n",
      "for 2019-05-03, MAE is:2.46 & sMAPE is:6.16% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :5.04 & 13.15% & 1.02\n",
      "for 2019-05-04, MAE is:3.08 & sMAPE is:8.51% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :5.02 & 13.11% & 1.02\n",
      "for 2019-05-05, MAE is:4.09 & sMAPE is:12.45% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :5.02 & 13.10% & 1.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-05-06, MAE is:2.78 & sMAPE is:6.62% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :5.00 & 13.05% & 1.03\n",
      "for 2019-05-07, MAE is:4.71 & sMAPE is:9.71% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :5.00 & 13.03% & 1.02\n",
      "for 2019-05-08, MAE is:6.03 & sMAPE is:13.66% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :5.00 & 13.03% & 1.02\n",
      "for 2019-05-09, MAE is:8.93 & sMAPE is:22.39% & rMAE is:2.07 ||| daily mean of MAE & sMAPE & rMAE till now are :5.03 & 13.10% & 1.03\n",
      "for 2019-05-10, MAE is:5.43 & sMAPE is:12.45% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :5.04 & 13.10% & 1.03\n",
      "for 2019-05-11, MAE is:3.36 & sMAPE is:8.42% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :5.02 & 13.06% & 1.03\n",
      "for 2019-05-12, MAE is:8.55 & sMAPE is:50.55% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :5.05 & 13.35% & 1.02\n",
      "for 2019-05-13, MAE is:6.12 & sMAPE is:15.55% & rMAE is:2.66 ||| daily mean of MAE & sMAPE & rMAE till now are :5.06 & 13.36% & 1.04\n",
      "for 2019-05-14, MAE is:5.15 & sMAPE is:12.68% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :5.06 & 13.36% & 1.03\n",
      "for 2019-05-15, MAE is:4.26 & sMAPE is:10.23% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :5.05 & 13.33% & 1.04\n",
      "for 2019-05-16, MAE is:3.26 & sMAPE is:8.35% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :5.04 & 13.30% & 1.04\n",
      "for 2019-05-17, MAE is:2.82 & sMAPE is:7.56% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :5.02 & 13.26% & 1.03\n",
      "for 2019-05-18, MAE is:5.14 & sMAPE is:15.04% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :5.03 & 13.27% & 1.03\n",
      "for 2019-05-19, MAE is:5.84 & sMAPE is:20.25% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :5.03 & 13.32% & 1.03\n",
      "for 2019-05-20, MAE is:5.78 & sMAPE is:13.95% & rMAE is:1.62 ||| daily mean of MAE & sMAPE & rMAE till now are :5.04 & 13.32% & 1.03\n",
      "for 2019-05-21, MAE is:3.00 & sMAPE is:7.24% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :5.02 & 13.28% & 1.03\n",
      "for 2019-05-22, MAE is:3.64 & sMAPE is:9.19% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :5.01 & 13.25% & 1.03\n",
      "for 2019-05-23, MAE is:4.29 & sMAPE is:10.17% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :5.01 & 13.23% & 1.04\n",
      "for 2019-05-24, MAE is:3.31 & sMAPE is:8.42% & rMAE is:2.21 ||| daily mean of MAE & sMAPE & rMAE till now are :5.00 & 13.20% & 1.04\n",
      "for 2019-05-25, MAE is:4.41 & sMAPE is:13.25% & rMAE is:3.42 ||| daily mean of MAE & sMAPE & rMAE till now are :4.99 & 13.20% & 1.06\n",
      "for 2019-05-26, MAE is:9.20 & sMAPE is:47.56% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :5.02 & 13.43% & 1.06\n",
      "for 2019-05-27, MAE is:4.11 & sMAPE is:12.93% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :5.01 & 13.43% & 1.06\n",
      "for 2019-05-28, MAE is:2.56 & sMAPE is:6.72% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :5.00 & 13.38% & 1.06\n",
      "for 2019-05-29, MAE is:4.18 & sMAPE is:11.11% & rMAE is:2.06 ||| daily mean of MAE & sMAPE & rMAE till now are :4.99 & 13.37% & 1.06\n",
      "for 2019-05-30, MAE is:9.52 & sMAPE is:40.42% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :5.02 & 13.55% & 1.06\n",
      "for 2019-05-31, MAE is:4.86 & sMAPE is:14.88% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :5.02 & 13.56% & 1.06\n",
      "for 2019-06-01, MAE is:3.33 & sMAPE is:10.89% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :5.01 & 13.54% & 1.06\n",
      "for 2019-06-02, MAE is:5.89 & sMAPE is:39.07% & rMAE is:1.86 ||| daily mean of MAE & sMAPE & rMAE till now are :5.02 & 13.71% & 1.06\n",
      "for 2019-06-03, MAE is:7.57 & sMAPE is:23.45% & rMAE is:4.71 ||| daily mean of MAE & sMAPE & rMAE till now are :5.03 & 13.77% & 1.09\n",
      "for 2019-06-04, MAE is:3.74 & sMAPE is:9.73% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :5.02 & 13.74% & 1.09\n",
      "for 2019-06-05, MAE is:3.96 & sMAPE is:11.32% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :5.02 & 13.73% & 1.09\n",
      "for 2019-06-06, MAE is:2.88 & sMAPE is:8.27% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :5.00 & 13.69% & 1.08\n",
      "for 2019-06-07, MAE is:5.79 & sMAPE is:17.00% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :5.01 & 13.72% & 1.08\n",
      "for 2019-06-08, MAE is:5.86 & sMAPE is:35.45% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :5.01 & 13.85% & 1.08\n",
      "for 2019-06-09, MAE is:7.19 & sMAPE is:33.49% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :5.03 & 13.97% & 1.08\n",
      "for 2019-06-10, MAE is:3.13 & sMAPE is:11.10% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :5.02 & 13.96% & 1.08\n",
      "for 2019-06-11, MAE is:5.88 & sMAPE is:15.84% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :5.02 & 13.97% & 1.08\n",
      "for 2019-06-12, MAE is:5.21 & sMAPE is:13.77% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :5.02 & 13.97% & 1.08\n",
      "for 2019-06-13, MAE is:4.26 & sMAPE is:11.71% & rMAE is:1.62 ||| daily mean of MAE & sMAPE & rMAE till now are :5.02 & 13.95% & 1.08\n",
      "for 2019-06-14, MAE is:2.73 & sMAPE is:7.28% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :5.00 & 13.91% & 1.08\n",
      "for 2019-06-15, MAE is:4.60 & sMAPE is:16.35% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :5.00 & 13.93% & 1.07\n",
      "for 2019-06-16, MAE is:5.31 & sMAPE is:19.17% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :5.00 & 13.96% & 1.07\n",
      "for 2019-06-17, MAE is:2.98 & sMAPE is:8.11% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :4.99 & 13.92% & 1.07\n",
      "for 2019-06-18, MAE is:2.18 & sMAPE is:6.17% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.98 & 13.88% & 1.07\n",
      "for 2019-06-19, MAE is:2.57 & sMAPE is:7.53% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :4.96 & 13.84% & 1.06\n",
      "for 2019-06-20, MAE is:3.10 & sMAPE is:9.36% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :4.95 & 13.81% & 1.06\n",
      "for 2019-06-21, MAE is:2.85 & sMAPE is:7.81% & rMAE is:2.10 ||| daily mean of MAE & sMAPE & rMAE till now are :4.94 & 13.78% & 1.07\n",
      "for 2019-06-22, MAE is:3.63 & sMAPE is:11.84% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :4.93 & 13.77% & 1.07\n",
      "for 2019-06-23, MAE is:7.63 & sMAPE is:45.78% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :4.95 & 13.95% & 1.07\n",
      "for 2019-06-24, MAE is:3.12 & sMAPE is:10.15% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :4.94 & 13.93% & 1.07\n",
      "for 2019-06-25, MAE is:2.14 & sMAPE is:6.25% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :4.92 & 13.89% & 1.07\n",
      "for 2019-06-26, MAE is:3.04 & sMAPE is:9.07% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :4.91 & 13.86% & 1.07\n",
      "for 2019-06-27, MAE is:2.84 & sMAPE is:8.58% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 13.83% & 1.07\n",
      "for 2019-06-28, MAE is:2.59 & sMAPE is:7.68% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :4.88 & 13.80% & 1.07\n",
      "for 2019-06-29, MAE is:2.36 & sMAPE is:7.53% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 13.76% & 1.07\n",
      "for 2019-06-30, MAE is:17.60 & sMAPE is:96.34% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :4.94 & 14.22% & 1.07\n",
      "for 2019-07-01, MAE is:2.82 & sMAPE is:9.35% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :4.93 & 14.19% & 1.07\n",
      "for 2019-07-02, MAE is:2.97 & sMAPE is:9.20% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :4.92 & 14.16% & 1.07\n",
      "for 2019-07-03, MAE is:2.65 & sMAPE is:8.19% & rMAE is:1.81 ||| daily mean of MAE & sMAPE & rMAE till now are :4.91 & 14.13% & 1.07\n",
      "for 2019-07-04, MAE is:2.75 & sMAPE is:8.36% & rMAE is:2.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.89 & 14.10% & 1.08\n",
      "for 2019-07-05, MAE is:2.49 & sMAPE is:7.54% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :4.88 & 14.06% & 1.08\n",
      "for 2019-07-06, MAE is:4.08 & sMAPE is:13.98% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :4.88 & 14.06% & 1.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-07-07, MAE is:4.85 & sMAPE is:35.91% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.88 & 14.18% & 1.08\n",
      "for 2019-07-08, MAE is:1.72 & sMAPE is:5.44% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :4.86 & 14.13% & 1.08\n",
      "for 2019-07-09, MAE is:1.99 & sMAPE is:5.90% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.85 & 14.09% & 1.07\n",
      "for 2019-07-10, MAE is:2.78 & sMAPE is:7.77% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.83 & 14.06% & 1.07\n",
      "for 2019-07-11, MAE is:4.74 & sMAPE is:11.82% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.83 & 14.05% & 1.07\n",
      "for 2019-07-12, MAE is:2.75 & sMAPE is:7.17% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :4.82 & 14.01% & 1.06\n",
      "for 2019-07-13, MAE is:5.67 & sMAPE is:17.69% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :4.83 & 14.03% & 1.06\n",
      "for 2019-07-14, MAE is:5.98 & sMAPE is:21.62% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :4.83 & 14.07% & 1.06\n",
      "for 2019-07-15, MAE is:2.14 & sMAPE is:5.54% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :4.82 & 14.02% & 1.05\n",
      "for 2019-07-16, MAE is:4.37 & sMAPE is:10.73% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.82 & 14.01% & 1.05\n",
      "for 2019-07-17, MAE is:5.15 & sMAPE is:12.04% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :4.82 & 14.00% & 1.05\n",
      "for 2019-07-18, MAE is:2.78 & sMAPE is:6.53% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :4.81 & 13.96% & 1.05\n",
      "for 2019-07-19, MAE is:3.82 & sMAPE is:9.57% & rMAE is:1.94 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 13.94% & 1.06\n",
      "for 2019-07-20, MAE is:2.67 & sMAPE is:7.29% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :4.79 & 13.91% & 1.06\n",
      "for 2019-07-21, MAE is:3.89 & sMAPE is:13.84% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :4.79 & 13.91% & 1.06\n",
      "for 2019-07-22, MAE is:3.30 & sMAPE is:8.18% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :4.78 & 13.88% & 1.06\n",
      "for 2019-07-23, MAE is:3.61 & sMAPE is:7.90% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.78 & 13.85% & 1.06\n",
      "for 2019-07-24, MAE is:4.67 & sMAPE is:9.61% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :4.78 & 13.83% & 1.06\n",
      "for 2019-07-25, MAE is:3.89 & sMAPE is:7.68% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :4.77 & 13.80% & 1.06\n",
      "for 2019-07-26, MAE is:3.41 & sMAPE is:7.30% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :4.76 & 13.77% & 1.06\n",
      "for 2019-07-27, MAE is:2.95 & sMAPE is:7.80% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :4.76 & 13.74% & 1.06\n",
      "for 2019-07-28, MAE is:7.02 & sMAPE is:23.98% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :4.77 & 13.79% & 1.06\n",
      "for 2019-07-29, MAE is:2.12 & sMAPE is:5.56% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :4.75 & 13.75% & 1.06\n",
      "for 2019-07-30, MAE is:2.78 & sMAPE is:7.18% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :4.74 & 13.72% & 1.06\n",
      "for 2019-07-31, MAE is:2.95 & sMAPE is:8.14% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :4.74 & 13.69% & 1.05\n",
      "for 2019-08-01, MAE is:3.46 & sMAPE is:9.62% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :4.73 & 13.67% & 1.05\n",
      "for 2019-08-02, MAE is:3.34 & sMAPE is:8.83% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :4.72 & 13.65% & 1.05\n",
      "for 2019-08-03, MAE is:4.38 & sMAPE is:12.74% & rMAE is:2.56 ||| daily mean of MAE & sMAPE & rMAE till now are :4.72 & 13.64% & 1.06\n",
      "for 2019-08-04, MAE is:2.52 & sMAPE is:7.33% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :4.71 & 13.61% & 1.06\n",
      "for 2019-08-05, MAE is:3.68 & sMAPE is:9.81% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :4.71 & 13.60% & 1.06\n",
      "for 2019-08-06, MAE is:2.81 & sMAPE is:6.99% & rMAE is:1.86 ||| daily mean of MAE & sMAPE & rMAE till now are :4.70 & 13.57% & 1.06\n",
      "for 2019-08-07, MAE is:2.12 & sMAPE is:5.50% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 13.53% & 1.07\n",
      "for 2019-08-08, MAE is:4.63 & sMAPE is:12.62% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 13.53% & 1.07\n",
      "for 2019-08-09, MAE is:3.87 & sMAPE is:10.63% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 13.51% & 1.06\n",
      "for 2019-08-10, MAE is:12.06 & sMAPE is:58.72% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.72 & 13.72% & 1.06\n",
      "for 2019-08-11, MAE is:7.84 & sMAPE is:40.46% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :4.73 & 13.84% & 1.06\n",
      "for 2019-08-12, MAE is:1.93 & sMAPE is:5.97% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :4.72 & 13.80% & 1.06\n",
      "for 2019-08-13, MAE is:2.32 & sMAPE is:7.29% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :4.71 & 13.77% & 1.05\n",
      "for 2019-08-14, MAE is:3.59 & sMAPE is:10.80% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.70 & 13.76% & 1.05\n",
      "for 2019-08-15, MAE is:3.66 & sMAPE is:12.10% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.70 & 13.75% & 1.05\n",
      "for 2019-08-16, MAE is:3.54 & sMAPE is:11.36% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 13.74% & 1.05\n",
      "for 2019-08-17, MAE is:2.06 & sMAPE is:8.58% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 13.72% & 1.04\n",
      "for 2019-08-18, MAE is:3.74 & sMAPE is:16.50% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 13.73% & 1.04\n",
      "for 2019-08-19, MAE is:1.96 & sMAPE is:6.23% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :4.66 & 13.70% & 1.04\n",
      "for 2019-08-20, MAE is:2.70 & sMAPE is:7.87% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :4.66 & 13.67% & 1.04\n",
      "for 2019-08-21, MAE is:2.95 & sMAPE is:8.22% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :4.65 & 13.65% & 1.04\n",
      "for 2019-08-22, MAE is:3.84 & sMAPE is:10.96% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :4.65 & 13.64% & 1.04\n",
      "for 2019-08-23, MAE is:2.24 & sMAPE is:6.66% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.64 & 13.61% & 1.04\n",
      "for 2019-08-24, MAE is:2.80 & sMAPE is:9.66% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :4.63 & 13.59% & 1.03\n",
      "for 2019-08-25, MAE is:3.28 & sMAPE is:12.40% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :4.62 & 13.59% & 1.03\n",
      "for 2019-08-26, MAE is:2.08 & sMAPE is:5.56% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.61 & 13.55% & 1.03\n",
      "for 2019-08-27, MAE is:4.06 & sMAPE is:9.47% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :4.61 & 13.54% & 1.03\n",
      "for 2019-08-28, MAE is:5.25 & sMAPE is:11.81% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.61 & 13.53% & 1.03\n",
      "for 2019-08-29, MAE is:2.49 & sMAPE is:5.89% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :4.60 & 13.50% & 1.02\n",
      "for 2019-08-30, MAE is:3.60 & sMAPE is:8.90% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :4.60 & 13.48% & 1.02\n",
      "for 2019-08-31, MAE is:3.00 & sMAPE is:8.99% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.59 & 13.46% & 1.02\n",
      "for 2019-09-01, MAE is:3.77 & sMAPE is:12.66% & rMAE is:2.24 ||| daily mean of MAE & sMAPE & rMAE till now are :4.59 & 13.46% & 1.02\n",
      "for 2019-09-02, MAE is:3.26 & sMAPE is:8.62% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :4.58 & 13.44% & 1.03\n",
      "for 2019-09-03, MAE is:4.37 & sMAPE is:11.80% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :4.58 & 13.43% & 1.03\n",
      "for 2019-09-04, MAE is:5.47 & sMAPE is:16.01% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :4.59 & 13.44% & 1.02\n",
      "for 2019-09-05, MAE is:3.55 & sMAPE is:11.46% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :4.58 & 13.43% & 1.02\n",
      "for 2019-09-06, MAE is:3.48 & sMAPE is:10.31% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :4.58 & 13.42% & 1.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-09-07, MAE is:4.37 & sMAPE is:14.03% & rMAE is:2.12 ||| daily mean of MAE & sMAPE & rMAE till now are :4.58 & 13.42% & 1.02\n",
      "for 2019-09-08, MAE is:8.31 & sMAPE is:28.72% & rMAE is:1.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.59 & 13.48% & 1.03\n",
      "for 2019-09-09, MAE is:2.31 & sMAPE is:5.78% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :4.58 & 13.45% & 1.03\n",
      "for 2019-09-10, MAE is:4.84 & sMAPE is:12.51% & rMAE is:3.08 ||| daily mean of MAE & sMAPE & rMAE till now are :4.58 & 13.45% & 1.03\n",
      "for 2019-09-11, MAE is:4.50 & sMAPE is:12.65% & rMAE is:2.05 ||| daily mean of MAE & sMAPE & rMAE till now are :4.58 & 13.45% & 1.04\n",
      "for 2019-09-12, MAE is:5.73 & sMAPE is:15.56% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :4.59 & 13.45% & 1.04\n",
      "for 2019-09-13, MAE is:3.35 & sMAPE is:9.26% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :4.58 & 13.44% & 1.04\n",
      "for 2019-09-14, MAE is:3.46 & sMAPE is:9.76% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :4.58 & 13.42% & 1.04\n",
      "for 2019-09-15, MAE is:7.70 & sMAPE is:28.59% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :4.59 & 13.48% & 1.04\n",
      "for 2019-09-16, MAE is:4.36 & sMAPE is:10.09% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.59 & 13.47% & 1.04\n",
      "for 2019-09-17, MAE is:3.73 & sMAPE is:8.95% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :4.59 & 13.45% & 1.04\n",
      "for 2019-09-18, MAE is:9.20 & sMAPE is:23.37% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :4.60 & 13.49% & 1.04\n",
      "for 2019-09-19, MAE is:4.51 & sMAPE is:10.14% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :4.60 & 13.48% & 1.04\n",
      "for 2019-09-20, MAE is:4.45 & sMAPE is:10.16% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :4.60 & 13.46% & 1.03\n",
      "for 2019-09-21, MAE is:4.95 & sMAPE is:14.08% & rMAE is:3.06 ||| daily mean of MAE & sMAPE & rMAE till now are :4.60 & 13.47% & 1.04\n",
      "for 2019-09-22, MAE is:5.75 & sMAPE is:19.72% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :4.61 & 13.49% & 1.04\n",
      "for 2019-09-23, MAE is:7.51 & sMAPE is:17.42% & rMAE is:3.00 ||| daily mean of MAE & sMAPE & rMAE till now are :4.62 & 13.50% & 1.05\n",
      "for 2019-09-24, MAE is:3.70 & sMAPE is:8.53% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :4.62 & 13.49% & 1.05\n",
      "for 2019-09-25, MAE is:7.92 & sMAPE is:18.59% & rMAE is:2.91 ||| daily mean of MAE & sMAPE & rMAE till now are :4.63 & 13.51% & 1.06\n",
      "for 2019-09-26, MAE is:4.58 & sMAPE is:11.00% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :4.63 & 13.50% & 1.06\n",
      "for 2019-09-27, MAE is:5.57 & sMAPE is:14.05% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :4.63 & 13.50% & 1.06\n",
      "for 2019-09-28, MAE is:5.92 & sMAPE is:18.80% & rMAE is:2.38 ||| daily mean of MAE & sMAPE & rMAE till now are :4.64 & 13.52% & 1.06\n",
      "for 2019-09-29, MAE is:6.07 & sMAPE is:23.28% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :4.64 & 13.55% & 1.06\n",
      "for 2019-09-30, MAE is:10.37 & sMAPE is:28.35% & rMAE is:1.90 ||| daily mean of MAE & sMAPE & rMAE till now are :4.66 & 13.61% & 1.06\n",
      "for 2019-10-01, MAE is:4.03 & sMAPE is:9.73% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :4.66 & 13.59% & 1.07\n",
      "for 2019-10-02, MAE is:5.60 & sMAPE is:13.04% & rMAE is:4.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.66 & 13.59% & 1.08\n",
      "for 2019-10-03, MAE is:5.31 & sMAPE is:13.02% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :4.67 & 13.59% & 1.08\n",
      "for 2019-10-04, MAE is:4.66 & sMAPE is:10.91% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.67 & 13.58% & 1.08\n",
      "for 2019-10-05, MAE is:8.90 & sMAPE is:25.75% & rMAE is:1.93 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 13.62% & 1.08\n",
      "for 2019-10-06, MAE is:5.31 & sMAPE is:16.61% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 13.63% & 1.08\n",
      "for 2019-10-07, MAE is:9.24 & sMAPE is:20.75% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :4.70 & 13.66% & 1.08\n",
      "for 2019-10-08, MAE is:4.85 & sMAPE is:11.73% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :4.70 & 13.65% & 1.08\n",
      "for 2019-10-09, MAE is:4.16 & sMAPE is:10.51% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :4.70 & 13.64% & 1.08\n",
      "for 2019-10-10, MAE is:4.33 & sMAPE is:11.83% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :4.70 & 13.64% & 1.08\n",
      "for 2019-10-11, MAE is:3.99 & sMAPE is:11.44% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 13.63% & 1.08\n",
      "for 2019-10-12, MAE is:6.62 & sMAPE is:24.09% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :4.70 & 13.66% & 1.08\n",
      "for 2019-10-13, MAE is:4.11 & sMAPE is:15.47% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :4.70 & 13.67% & 1.08\n",
      "for 2019-10-14, MAE is:8.86 & sMAPE is:22.47% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :4.71 & 13.70% & 1.08\n",
      "for 2019-10-15, MAE is:9.80 & sMAPE is:24.17% & rMAE is:3.55 ||| daily mean of MAE & sMAPE & rMAE till now are :4.73 & 13.74% & 1.09\n",
      "for 2019-10-16, MAE is:4.75 & sMAPE is:11.78% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :4.73 & 13.73% & 1.09\n",
      "for 2019-10-17, MAE is:8.88 & sMAPE is:20.42% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :4.75 & 13.75% & 1.09\n",
      "for 2019-10-18, MAE is:3.66 & sMAPE is:9.35% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :4.74 & 13.74% & 1.09\n",
      "for 2019-10-19, MAE is:8.27 & sMAPE is:26.20% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.75 & 13.78% & 1.09\n",
      "for 2019-10-20, MAE is:7.49 & sMAPE is:23.86% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :4.76 & 13.82% & 1.09\n",
      "for 2019-10-21, MAE is:5.99 & sMAPE is:13.91% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.77 & 13.82% & 1.09\n",
      "for 2019-10-22, MAE is:6.12 & sMAPE is:12.98% & rMAE is:1.99 ||| daily mean of MAE & sMAPE & rMAE till now are :4.77 & 13.81% & 1.09\n",
      "for 2019-10-23, MAE is:5.21 & sMAPE is:12.03% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :4.77 & 13.81% & 1.10\n",
      "for 2019-10-24, MAE is:3.98 & sMAPE is:10.40% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :4.77 & 13.80% & 1.09\n",
      "for 2019-10-25, MAE is:5.33 & sMAPE is:14.68% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :4.77 & 13.80% & 1.10\n",
      "for 2019-10-26, MAE is:4.36 & sMAPE is:15.85% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :4.77 & 13.81% & 1.09\n",
      "for 2019-10-27, MAE is:6.90 & sMAPE is:25.60% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :4.78 & 13.84% & 1.10\n",
      "for 2019-10-28, MAE is:6.89 & sMAPE is:15.20% & rMAE is:2.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.79 & 13.85% & 1.10\n",
      "for 2019-10-29, MAE is:5.40 & sMAPE is:10.60% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :4.79 & 13.84% & 1.10\n",
      "for 2019-10-30, MAE is:5.91 & sMAPE is:12.21% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :4.79 & 13.83% & 1.10\n",
      "for 2019-10-31, MAE is:4.04 & sMAPE is:9.04% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :4.79 & 13.82% & 1.10\n",
      "for 2019-11-01, MAE is:6.02 & sMAPE is:16.88% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :4.79 & 13.83% & 1.10\n",
      "for 2019-11-02, MAE is:4.01 & sMAPE is:13.43% & rMAE is:1.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.79 & 13.83% & 1.10\n",
      "for 2019-11-03, MAE is:6.71 & sMAPE is:25.31% & rMAE is:2.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 13.86% & 1.10\n",
      "for 2019-11-04, MAE is:6.20 & sMAPE is:18.64% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 13.88% & 1.10\n",
      "for 2019-11-05, MAE is:5.44 & sMAPE is:13.33% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 13.88% & 1.10\n",
      "for 2019-11-06, MAE is:9.21 & sMAPE is:18.91% & rMAE is:3.91 ||| daily mean of MAE & sMAPE & rMAE till now are :4.82 & 13.89% & 1.11\n",
      "for 2019-11-07, MAE is:4.07 & sMAPE is:9.02% & rMAE is:2.24 ||| daily mean of MAE & sMAPE & rMAE till now are :4.82 & 13.88% & 1.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-11-08, MAE is:6.87 & sMAPE is:14.44% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.82 & 13.88% & 1.11\n",
      "for 2019-11-09, MAE is:2.74 & sMAPE is:6.66% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :4.82 & 13.86% & 1.11\n",
      "for 2019-11-10, MAE is:3.29 & sMAPE is:7.81% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :4.81 & 13.84% & 1.11\n",
      "for 2019-11-11, MAE is:5.59 & sMAPE is:11.47% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :4.81 & 13.83% & 1.11\n",
      "for 2019-11-12, MAE is:2.93 & sMAPE is:6.36% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :4.81 & 13.81% & 1.10\n",
      "for 2019-11-13, MAE is:6.61 & sMAPE is:13.19% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :4.81 & 13.80% & 1.10\n",
      "for 2019-11-14, MAE is:3.29 & sMAPE is:6.60% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.81 & 13.78% & 1.10\n",
      "for 2019-11-15, MAE is:2.45 & sMAPE is:4.96% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 13.75% & 1.10\n",
      "for 2019-11-16, MAE is:2.93 & sMAPE is:6.14% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :4.79 & 13.73% & 1.10\n",
      "for 2019-11-17, MAE is:1.86 & sMAPE is:4.09% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.79 & 13.70% & 1.10\n",
      "for 2019-11-18, MAE is:2.64 & sMAPE is:5.12% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.78 & 13.67% & 1.09\n",
      "for 2019-11-19, MAE is:5.20 & sMAPE is:9.06% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.78 & 13.66% & 1.09\n",
      "for 2019-11-20, MAE is:6.03 & sMAPE is:9.81% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :4.78 & 13.65% & 1.09\n",
      "for 2019-11-21, MAE is:4.36 & sMAPE is:7.74% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.78 & 13.63% & 1.09\n",
      "for 2019-11-22, MAE is:3.16 & sMAPE is:6.32% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :4.78 & 13.61% & 1.09\n",
      "for 2019-11-23, MAE is:2.65 & sMAPE is:5.91% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :4.77 & 13.58% & 1.09\n",
      "for 2019-11-24, MAE is:5.15 & sMAPE is:13.59% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :4.77 & 13.58% & 1.09\n",
      "for 2019-11-25, MAE is:3.72 & sMAPE is:7.98% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :4.77 & 13.57% & 1.09\n",
      "for 2019-11-26, MAE is:2.89 & sMAPE is:5.99% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.76 & 13.54% & 1.09\n",
      "for 2019-11-27, MAE is:2.84 & sMAPE is:6.30% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :4.76 & 13.52% & 1.09\n",
      "for 2019-11-28, MAE is:4.29 & sMAPE is:11.47% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :4.76 & 13.52% & 1.09\n",
      "for 2019-11-29, MAE is:5.83 & sMAPE is:12.55% & rMAE is:2.07 ||| daily mean of MAE & sMAPE & rMAE till now are :4.76 & 13.51% & 1.09\n",
      "for 2019-11-30, MAE is:2.26 & sMAPE is:4.93% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :4.75 & 13.49% & 1.09\n",
      "for 2019-12-01, MAE is:2.39 & sMAPE is:5.29% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :4.74 & 13.46% & 1.09\n",
      "for 2019-12-02, MAE is:2.42 & sMAPE is:4.92% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.74 & 13.44% & 1.09\n",
      "for 2019-12-03, MAE is:2.48 & sMAPE is:4.61% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :4.73 & 13.41% & 1.08\n",
      "for 2019-12-04, MAE is:3.79 & sMAPE is:7.03% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :4.73 & 13.39% & 1.08\n",
      "for 2019-12-05, MAE is:2.99 & sMAPE is:5.25% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :4.72 & 13.37% & 1.08\n",
      "for 2019-12-06, MAE is:7.84 & sMAPE is:14.15% & rMAE is:2.03 ||| daily mean of MAE & sMAPE & rMAE till now are :4.73 & 13.37% & 1.08\n",
      "for 2019-12-07, MAE is:4.02 & sMAPE is:9.11% & rMAE is:2.04 ||| daily mean of MAE & sMAPE & rMAE till now are :4.73 & 13.36% & 1.08\n",
      "for 2019-12-08, MAE is:2.36 & sMAPE is:5.46% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :4.72 & 13.33% & 1.08\n",
      "for 2019-12-09, MAE is:4.41 & sMAPE is:9.13% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :4.72 & 13.32% & 1.08\n",
      "for 2019-12-10, MAE is:2.66 & sMAPE is:5.70% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :4.72 & 13.30% & 1.08\n",
      "for 2019-12-11, MAE is:3.08 & sMAPE is:6.94% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :4.71 & 13.28% & 1.08\n",
      "for 2019-12-12, MAE is:3.94 & sMAPE is:8.56% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :4.71 & 13.27% & 1.08\n",
      "for 2019-12-13, MAE is:3.54 & sMAPE is:7.62% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :4.71 & 13.25% & 1.08\n",
      "for 2019-12-14, MAE is:2.28 & sMAPE is:5.50% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :4.70 & 13.23% & 1.08\n",
      "for 2019-12-15, MAE is:3.79 & sMAPE is:9.85% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :4.70 & 13.22% & 1.08\n",
      "for 2019-12-16, MAE is:2.89 & sMAPE is:6.89% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 13.20% & 1.08\n",
      "for 2019-12-17, MAE is:2.73 & sMAPE is:6.30% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 13.18% & 1.08\n",
      "for 2019-12-18, MAE is:3.46 & sMAPE is:7.71% & rMAE is:2.87 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 13.17% & 1.08\n",
      "for 2019-12-19, MAE is:3.69 & sMAPE is:9.04% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 13.15% & 1.08\n",
      "for 2019-12-20, MAE is:3.53 & sMAPE is:9.19% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 13.14% & 1.08\n",
      "for 2019-12-21, MAE is:3.71 & sMAPE is:12.30% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :4.67 & 13.14% & 1.08\n",
      "for 2019-12-22, MAE is:8.15 & sMAPE is:38.44% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 13.21% & 1.07\n",
      "for 2019-12-23, MAE is:6.85 & sMAPE is:34.98% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 13.27% & 1.07\n",
      "for 2019-12-24, MAE is:6.08 & sMAPE is:27.88% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 13.31% & 1.07\n",
      "for 2019-12-25, MAE is:8.20 & sMAPE is:47.56% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :4.70 & 13.41% & 1.07\n",
      "for 2019-12-26, MAE is:4.32 & sMAPE is:14.51% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :4.70 & 13.41% & 1.07\n",
      "for 2019-12-27, MAE is:8.43 & sMAPE is:23.54% & rMAE is:2.90 ||| daily mean of MAE & sMAPE & rMAE till now are :4.71 & 13.44% & 1.07\n",
      "for 2019-12-28, MAE is:2.68 & sMAPE is:7.56% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :4.71 & 13.42% & 1.07\n",
      "for 2019-12-29, MAE is:3.46 & sMAPE is:11.80% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.70 & 13.42% & 1.07\n",
      "for 2019-12-30, MAE is:5.25 & sMAPE is:15.74% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :4.70 & 13.43% & 1.07\n",
      "for 2019-12-31, MAE is:3.36 & sMAPE is:9.15% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :4.70 & 13.41% & 1.07\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 23:56:43,224]\u001b[0m A new study created in RDB with name: CH_2020\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:57:06,015]\u001b[0m Trial 3 finished with value: 8.316689416132382 and parameters: {'n_hidden': 4, 'learning_rate': 0.0027227239870864675, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34070244416226386, 'dropout_rate_Layer_2': 0.34076587586086937, 'dropout_rate_Layer_3': 0.1436392225336594, 'dropout_rate_Layer_4': 0.3776948489516273, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.4814898708918103e-05, 'l1_Layer_2': 0.003348938099134228, 'l1_Layer_3': 0.06503896401018643, 'l1_Layer_4': 0.00010066567149091365, 'n_units_Layer_1': 240, 'n_units_Layer_2': 290, 'n_units_Layer_3': 215, 'n_units_Layer_4': 55}. Best is trial 3 with value: 8.316689416132382.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.32 | sMAPE for Validation Set is: 21.37% | rMAE for Validation Set is: 1.35\n",
      "MAE for Test Set is: 11.87 | sMAPE for Test Set is: 36.35% | rMAE for Test Set is: 1.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 23:57:08,658]\u001b[0m Trial 0 finished with value: 4.655047943090372 and parameters: {'n_hidden': 3, 'learning_rate': 0.03877945815820864, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34813535767425036, 'dropout_rate_Layer_2': 0.3724202668605832, 'dropout_rate_Layer_3': 0.055507789054656344, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00042345225941428053, 'l1_Layer_2': 5.176309447746827e-05, 'l1_Layer_3': 1.415987236158406e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 245, 'n_units_Layer_3': 65}. Best is trial 0 with value: 4.655047943090372.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.66 | sMAPE for Validation Set is: 13.11% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 7.75 | sMAPE for Test Set is: 26.72% | rMAE for Test Set is: 1.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 23:57:12,081]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:57:22,181]\u001b[0m Trial 6 finished with value: 8.22216492477076 and parameters: {'n_hidden': 4, 'learning_rate': 0.004443896602790285, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3405170688058479, 'dropout_rate_Layer_2': 0.22344064145320683, 'dropout_rate_Layer_3': 0.2318647846840659, 'dropout_rate_Layer_4': 0.17504136347089283, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.052753105764937684, 'l1_Layer_2': 0.0011424844095881343, 'l1_Layer_3': 0.00010656211321058942, 'l1_Layer_4': 0.03387833137018411, 'n_units_Layer_1': 140, 'n_units_Layer_2': 290, 'n_units_Layer_3': 150, 'n_units_Layer_4': 100}. Best is trial 0 with value: 4.655047943090372.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.22 | sMAPE for Validation Set is: 21.12% | rMAE for Validation Set is: 1.33\n",
      "MAE for Test Set is: 12.03 | sMAPE for Test Set is: 36.59% | rMAE for Test Set is: 1.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 23:57:26,803]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:57:31,561]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:57:34,037]\u001b[0m Trial 2 finished with value: 4.4146328306553295 and parameters: {'n_hidden': 4, 'learning_rate': 0.0028064118122600483, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0096774112407787, 'dropout_rate_Layer_2': 0.1623531782860305, 'dropout_rate_Layer_3': 0.18097912378750755, 'dropout_rate_Layer_4': 0.09042804972883439, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.026912401142789182, 'l1_Layer_2': 0.00019627178279597868, 'l1_Layer_3': 3.397657854510685e-05, 'l1_Layer_4': 4.3922301255366075e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 110, 'n_units_Layer_3': 275, 'n_units_Layer_4': 205}. Best is trial 2 with value: 4.4146328306553295.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.41 | sMAPE for Validation Set is: 12.43% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 7.31 | sMAPE for Test Set is: 25.55% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 23:57:34,581]\u001b[0m Trial 4 finished with value: 4.5115232750290595 and parameters: {'n_hidden': 3, 'learning_rate': 0.02504730832912609, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17703394677757608, 'dropout_rate_Layer_2': 0.24077760357514025, 'dropout_rate_Layer_3': 0.1436777431187499, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.1110043297296525e-05, 'l1_Layer_2': 0.0020808124829780877, 'l1_Layer_3': 0.0006337409405970286, 'n_units_Layer_1': 60, 'n_units_Layer_2': 295, 'n_units_Layer_3': 140}. Best is trial 2 with value: 4.4146328306553295.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.51 | sMAPE for Validation Set is: 12.82% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 7.25 | sMAPE for Test Set is: 25.43% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 23:57:35,949]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.92 | sMAPE for Validation Set is: 11.40% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.28 | sMAPE for Test Set is: 19.74% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 23:57:39,201]\u001b[0m Trial 1 finished with value: 3.921573025039232 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007313617958373536, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39998020186958233, 'dropout_rate_Layer_2': 0.013291975075039054, 'dropout_rate_Layer_3': 0.27812889344296715, 'dropout_rate_Layer_4': 0.09421912060099435, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0031549036264459243, 'l1_Layer_2': 0.0005256345800390833, 'l1_Layer_3': 0.0006732976602955762, 'l1_Layer_4': 5.290025329620822e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 160, 'n_units_Layer_3': 285, 'n_units_Layer_4': 100}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:57:41,326]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:57:46,626]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:57:46,841]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:57:47,256]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:57:47,647]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:57:52,306]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:57:56,678]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:58:02,180]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:58:09,164]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:58:12,529]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:58:17,387]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:58:17,493]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:58:22,881]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:58:23,088]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:58:25,120]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:58:27,956]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:58:31,915]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:58:37,812]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:58:39,532]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:58:41,219]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:58:46,383]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:58:46,511]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:58:53,106]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:58:53,749]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:58:59,214]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:58:59,834]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:59:08,493]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:59:13,765]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.29 | sMAPE for Validation Set is: 12.31% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 6.23 | sMAPE for Test Set is: 22.65% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 23:59:16,705]\u001b[0m Trial 29 finished with value: 4.285554473582148 and parameters: {'n_hidden': 3, 'learning_rate': 0.003713194340450012, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1768611047156337, 'dropout_rate_Layer_2': 0.11175291142940319, 'dropout_rate_Layer_3': 0.01531187835816299, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00018592212330490428, 'l1_Layer_2': 0.017855313756053065, 'l1_Layer_3': 0.009435199368750254, 'n_units_Layer_1': 95, 'n_units_Layer_2': 115, 'n_units_Layer_3': 145}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:59:20,276]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:59:22,207]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:59:26,494]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:59:29,039]\u001b[0m Trial 40 finished with value: 4.524774822673762 and parameters: {'n_hidden': 4, 'learning_rate': 0.009369292555468096, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05641830376377047, 'dropout_rate_Layer_2': 0.1130068717827395, 'dropout_rate_Layer_3': 0.17102425529673082, 'dropout_rate_Layer_4': 0.006934207696671052, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.001892596171113718, 'l1_Layer_2': 0.00023478321891176398, 'l1_Layer_3': 6.109693188788427e-05, 'l1_Layer_4': 4.492767246374435e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 135, 'n_units_Layer_3': 275, 'n_units_Layer_4': 155}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.52 | sMAPE for Validation Set is: 12.85% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 7.47 | sMAPE for Test Set is: 26.13% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 23:59:33,469]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:59:33,684]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:59:37,970]\u001b[0m Trial 45 finished with value: 5.714969447853401 and parameters: {'n_hidden': 3, 'learning_rate': 0.08209897873458195, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3841719685202603, 'dropout_rate_Layer_2': 0.3919964913634934, 'dropout_rate_Layer_3': 0.003662857630007482, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010373777457951225, 'l1_Layer_2': 0.0001996738198781424, 'l1_Layer_3': 1.0888545482222076e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 250, 'n_units_Layer_3': 125}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.71 | sMAPE for Validation Set is: 16.02% | rMAE for Validation Set is: 0.93\n",
      "MAE for Test Set is: 6.89 | sMAPE for Test Set is: 24.32% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 23:59:40,096]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:59:40,212]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:59:43,458]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:59:48,044]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:59:48,340]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:59:51,989]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:59:56,555]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:00:02,463]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:00:03,032]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:00:09,898]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:00:09,944]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:00:14,222]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:00:17,717]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:00:17,752]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:00:21,661]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:00:24,440]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:00:24,700]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:00:25,382]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:00:30,577]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:00:34,353]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:00:38,584]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:00:43,246]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:00:44,562]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:00:48,072]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:00:50,491]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:00:51,026]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:00:53,173]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:00:58,325]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:01:00,155]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:01:00,313]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.39 | sMAPE for Validation Set is: 12.55% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 6.86 | sMAPE for Test Set is: 24.38% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:01:03,668]\u001b[0m Trial 65 finished with value: 4.388365296793606 and parameters: {'n_hidden': 3, 'learning_rate': 0.011944771743808834, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2008849889173686, 'dropout_rate_Layer_2': 0.23037914374243132, 'dropout_rate_Layer_3': 0.059725205431215844, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.529186266241941e-05, 'l1_Layer_2': 0.00018493605027279894, 'l1_Layer_3': 3.2280544691325636e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 230, 'n_units_Layer_3': 85}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:01:04,953]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:01:08,012]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:01:09,789]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:01:15,350]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:01:19,101]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.72 | sMAPE for Validation Set is: 13.38% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 6.52 | sMAPE for Test Set is: 23.43% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:01:21,023]\u001b[0m Trial 81 finished with value: 4.716031725153576 and parameters: {'n_hidden': 3, 'learning_rate': 0.03176870591299295, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25204785887943604, 'dropout_rate_Layer_2': 0.1595388287631646, 'dropout_rate_Layer_3': 0.03170981629693814, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.11166511609854e-05, 'l1_Layer_2': 3.0365875132968426e-05, 'l1_Layer_3': 2.1052203578304284e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 230, 'n_units_Layer_3': 75}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:01:24,567]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:01:31,451]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:01:35,163]\u001b[0m Trial 84 finished with value: 4.316131730665707 and parameters: {'n_hidden': 3, 'learning_rate': 0.007066783285096073, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24498726051651917, 'dropout_rate_Layer_2': 0.15004276376304007, 'dropout_rate_Layer_3': 0.024225065235796782, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.1403499331659776e-05, 'l1_Layer_2': 0.0004885541268099937, 'l1_Layer_3': 1.8213367403242036e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 230, 'n_units_Layer_3': 75}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.32 | sMAPE for Validation Set is: 12.47% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 5.83 | sMAPE for Test Set is: 21.30% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:01:36,380]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:01:41,446]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:01:45,947]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:01:50,333]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:01:56,885]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:02:00,675]\u001b[0m Trial 86 finished with value: 4.398405723873685 and parameters: {'n_hidden': 3, 'learning_rate': 0.007794333390530527, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0670720758478276, 'dropout_rate_Layer_2': 0.20860490294292905, 'dropout_rate_Layer_3': 0.09109362693621759, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00016577142607838695, 'l1_Layer_2': 0.00046777734985934847, 'l1_Layer_3': 0.00013632747618274053, 'n_units_Layer_1': 50, 'n_units_Layer_2': 235, 'n_units_Layer_3': 80}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.40 | sMAPE for Validation Set is: 12.55% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 6.59 | sMAPE for Test Set is: 23.62% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:02:10,654]\u001b[0m Trial 90 finished with value: 4.266227051088486 and parameters: {'n_hidden': 3, 'learning_rate': 0.006908486390771671, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2309270950385835, 'dropout_rate_Layer_2': 0.08319237874936494, 'dropout_rate_Layer_3': 0.15272747261489153, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.845752236076772e-05, 'l1_Layer_2': 0.0030161514129218464, 'l1_Layer_3': 2.9010124847478064e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 175, 'n_units_Layer_3': 80}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.27 | sMAPE for Validation Set is: 12.12% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 6.47 | sMAPE for Test Set is: 23.43% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:02:10,940]\u001b[0m Trial 83 finished with value: 4.1859582844970395 and parameters: {'n_hidden': 3, 'learning_rate': 0.001998148926029596, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34459142155181965, 'dropout_rate_Layer_2': 0.3859831807164477, 'dropout_rate_Layer_3': 0.377723941810463, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0021670072217656417, 'l1_Layer_2': 0.006136928353518389, 'l1_Layer_3': 0.00018857590343246918, 'n_units_Layer_1': 210, 'n_units_Layer_2': 280, 'n_units_Layer_3': 260}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.19 | sMAPE for Validation Set is: 12.26% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 6.02 | sMAPE for Test Set is: 22.10% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:02:15,587]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:02:19,712]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:02:20,100]\u001b[0m Trial 94 finished with value: 4.334953482830325 and parameters: {'n_hidden': 3, 'learning_rate': 0.00643369431235552, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24203973408937188, 'dropout_rate_Layer_2': 0.07451500937600147, 'dropout_rate_Layer_3': 0.13995526750879816, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.338941156392491e-05, 'l1_Layer_2': 0.004851721379437989, 'l1_Layer_3': 2.7545532160430493e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 180, 'n_units_Layer_3': 160}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.33 | sMAPE for Validation Set is: 12.40% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 7.21 | sMAPE for Test Set is: 25.39% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:02:23,879]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:02:27,310]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:02:30,342]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:02:31,407]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:02:35,288]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:02:35,821]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:02:41,579]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:02:43,030]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:02:44,980]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:02:49,342]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:02:50,695]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:02:52,668]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:02:55,138]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:02:59,656]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:03:02,748]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:03:04,187]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:03:13,298]\u001b[0m Trial 96 finished with value: 4.095047176607938 and parameters: {'n_hidden': 3, 'learning_rate': 0.001440984158165703, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16236790923268063, 'dropout_rate_Layer_2': 0.10269604029070148, 'dropout_rate_Layer_3': 0.056936137821103475, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.059691965143279076, 'l1_Layer_2': 0.051474712898087534, 'l1_Layer_3': 0.00037223625336456356, 'n_units_Layer_1': 175, 'n_units_Layer_2': 265, 'n_units_Layer_3': 165}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.10 | sMAPE for Validation Set is: 11.78% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.20 | sMAPE for Test Set is: 19.21% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:03:16,521]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:03:16,740]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:03:23,810]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:03:28,451]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:03:33,208]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:03:38,063]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:03:41,620]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:03:47,194]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:03:51,213]\u001b[0m Trial 114 finished with value: 4.160626831090205 and parameters: {'n_hidden': 4, 'learning_rate': 0.020331537336142482, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3116813656005378, 'dropout_rate_Layer_2': 0.1636964142257994, 'dropout_rate_Layer_3': 0.26754800353828573, 'dropout_rate_Layer_4': 0.13371489350427637, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 7.399664658402874e-05, 'l1_Layer_2': 3.0315171044426293e-05, 'l1_Layer_3': 1.261481844471134e-05, 'l1_Layer_4': 0.00023782629313390537, 'n_units_Layer_1': 105, 'n_units_Layer_2': 150, 'n_units_Layer_3': 125, 'n_units_Layer_4': 110}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.16 | sMAPE for Validation Set is: 12.13% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.17 | sMAPE for Test Set is: 22.48% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:03:56,777]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:04:00,462]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:04:00,846]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:04:04,963]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:04:08,547]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:04:12,543]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:04:18,779]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:04:21,539]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:04:25,115]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:04:32,443]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:04:36,991]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:04:38,517]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:04:40,207]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:04:45,327]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:04:50,516]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:05:14,149]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:05:21,965]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:05:26,267]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:05:27,860]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:05:31,896]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:05:34,656]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:05:38,013]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:05:44,824]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:05:48,910]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:05:53,052]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:05:53,195]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:06:00,795]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:06:08,735]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:06:19,423]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:06:33,901]\u001b[0m Trial 152 finished with value: 4.325575027838766 and parameters: {'n_hidden': 3, 'learning_rate': 0.006568573019254936, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04208383928439691, 'dropout_rate_Layer_2': 0.21524572246460605, 'dropout_rate_Layer_3': 0.09205034652062821, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002283296223070071, 'l1_Layer_2': 0.000445349612479122, 'l1_Layer_3': 0.0001472924485262815, 'n_units_Layer_1': 50, 'n_units_Layer_2': 225, 'n_units_Layer_3': 80}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.33 | sMAPE for Validation Set is: 12.30% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 7.12 | sMAPE for Test Set is: 25.06% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:06:37,615]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:06:45,086]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:06:50,803]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:06:55,307]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:07:00,370]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:07:04,109]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:07:04,648]\u001b[0m Trial 158 finished with value: 4.382385390821559 and parameters: {'n_hidden': 3, 'learning_rate': 0.004755456710043462, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10776593662811425, 'dropout_rate_Layer_2': 0.18814035588710054, 'dropout_rate_Layer_3': 0.13143177986545573, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004212959495700833, 'l1_Layer_2': 0.0001202468694351733, 'l1_Layer_3': 4.919938460099078e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 250, 'n_units_Layer_3': 65}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.38 | sMAPE for Validation Set is: 12.53% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 6.24 | sMAPE for Test Set is: 22.54% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:07:11,403]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:07:12,169]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:07:18,328]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:07:19,085]\u001b[0m Trial 154 finished with value: 4.866937028984339 and parameters: {'n_hidden': 3, 'learning_rate': 0.004133642600070447, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39869645996733, 'dropout_rate_Layer_2': 0.10742853163083065, 'dropout_rate_Layer_3': 0.35300115684093825, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.04832825042464237, 'l1_Layer_2': 0.00017618238118659226, 'l1_Layer_3': 0.0012959726621369922, 'n_units_Layer_1': 235, 'n_units_Layer_2': 110, 'n_units_Layer_3': 240}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.87 | sMAPE for Validation Set is: 13.57% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 7.38 | sMAPE for Test Set is: 25.79% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:07:20,388]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:07:24,900]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:07:28,649]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:07:30,172]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:07:32,582]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:07:35,787]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:07:40,077]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:07:40,468]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:07:47,607]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:07:54,649]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:07:59,161]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:07:59,620]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:08:04,698]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:08:04,873]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:08:13,731]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:08:15,643]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:08:19,955]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:08:20,442]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:08:21,479]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:08:25,172]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:08:28,132]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:08:29,186]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:08:35,725]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:08:35,863]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:08:42,224]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:08:45,659]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:08:45,773]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:08:51,527]\u001b[0m Trial 186 finished with value: 4.062597987292199 and parameters: {'n_hidden': 4, 'learning_rate': 0.004613593264054934, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.022484364609315587, 'dropout_rate_Layer_2': 0.3469430795669045, 'dropout_rate_Layer_3': 0.3996912049141717, 'dropout_rate_Layer_4': 0.07563169231657788, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002256862943815035, 'l1_Layer_2': 0.0011403918061015739, 'l1_Layer_3': 1.5449605204659815e-05, 'l1_Layer_4': 3.418810249246776e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 195, 'n_units_Layer_3': 170, 'n_units_Layer_4': 160}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.06 | sMAPE for Validation Set is: 11.65% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.62 | sMAPE for Test Set is: 20.75% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:08:52,079]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:08:54,412]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:08:58,428]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:09:04,541]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:09:12,271]\u001b[0m Trial 196 finished with value: 4.332873800471286 and parameters: {'n_hidden': 4, 'learning_rate': 0.00394928765092674, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.013623683105408287, 'dropout_rate_Layer_2': 0.34316310079327345, 'dropout_rate_Layer_3': 0.38665274417461615, 'dropout_rate_Layer_4': 0.07596436314785547, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00043206132809738186, 'l1_Layer_2': 0.0017509868812686632, 'l1_Layer_3': 1.0130960355993324e-05, 'l1_Layer_4': 4.252248826180227e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 190, 'n_units_Layer_3': 80, 'n_units_Layer_4': 155}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.33 | sMAPE for Validation Set is: 12.34% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 6.88 | sMAPE for Test Set is: 24.54% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:09:15,519]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:09:19,552]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:09:23,789]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:09:28,006]\u001b[0m Trial 188 finished with value: 4.213532158365019 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010027690746737103, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1597700250123139, 'dropout_rate_Layer_2': 0.005528874313098181, 'dropout_rate_Layer_3': 0.1846019749264452, 'dropout_rate_Layer_4': 0.006637521307468822, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.006208244563339343, 'l1_Layer_2': 0.012484476414299044, 'l1_Layer_3': 0.07377544140736594, 'l1_Layer_4': 1.622486564360621e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 220, 'n_units_Layer_3': 90, 'n_units_Layer_4': 50}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.21 | sMAPE for Validation Set is: 12.12% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 6.02 | sMAPE for Test Set is: 22.02% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:09:32,397]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:09:37,143]\u001b[0m Trial 202 finished with value: 4.571298333057921 and parameters: {'n_hidden': 4, 'learning_rate': 0.005255751320027327, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007364210381863107, 'dropout_rate_Layer_2': 0.32629753884100865, 'dropout_rate_Layer_3': 0.3787820792035559, 'dropout_rate_Layer_4': 0.057553820338899525, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.5214059349602658e-05, 'l1_Layer_2': 0.001792220195339956, 'l1_Layer_3': 1.0089080596844702e-05, 'l1_Layer_4': 4.2004499267207485e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 185, 'n_units_Layer_3': 105, 'n_units_Layer_4': 125}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.57 | sMAPE for Validation Set is: 12.93% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 7.22 | sMAPE for Test Set is: 25.41% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:09:37,949]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:09:45,165]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:09:46,576]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:09:50,486]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:09:53,372]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:09:55,783]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:10:00,406]\u001b[0m Trial 206 finished with value: 4.610453097700407 and parameters: {'n_hidden': 4, 'learning_rate': 0.005207653538673438, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.005906988183905752, 'dropout_rate_Layer_2': 0.3671622510481204, 'dropout_rate_Layer_3': 0.38446449957832585, 'dropout_rate_Layer_4': 0.019381044072566724, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.4302193888480886e-05, 'l1_Layer_2': 0.0018332397027177026, 'l1_Layer_3': 1.038651241363483e-05, 'l1_Layer_4': 0.00011230448424659726, 'n_units_Layer_1': 265, 'n_units_Layer_2': 180, 'n_units_Layer_3': 135, 'n_units_Layer_4': 190}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.61 | sMAPE for Validation Set is: 13.26% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 6.42 | sMAPE for Test Set is: 23.10% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:10:01,377]\u001b[0m Trial 197 finished with value: 4.22321433164998 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010608986275813183, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1511828947768117, 'dropout_rate_Layer_2': 0.001017896734186034, 'dropout_rate_Layer_3': 0.17638373953276776, 'dropout_rate_Layer_4': 0.014890097595881488, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.006983846632127632, 'l1_Layer_2': 0.01945457903037926, 'l1_Layer_3': 0.0799798006126582, 'l1_Layer_4': 2.5581280422901928e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 220, 'n_units_Layer_3': 85, 'n_units_Layer_4': 50}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:10:01,428]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.22 | sMAPE for Validation Set is: 12.14% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 5.94 | sMAPE for Test Set is: 21.74% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:10:01,524]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:10:09,971]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:10:11,393]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:10:12,583]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:10:17,861]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:10:20,915]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:10:21,035]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:10:21,177]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:10:29,488]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:10:29,769]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:10:35,884]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:10:36,238]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:10:46,377]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:10:57,418]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:10:57,599]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:11:04,216]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:11:07,506]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:11:07,708]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:11:14,271]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:11:15,645]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:11:21,948]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:11:24,086]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:11:28,162]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:11:28,486]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:11:31,527]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:11:35,325]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:11:36,180]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:11:37,658]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:11:41,104]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:11:43,088]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.49 | sMAPE for Validation Set is: 12.81% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 7.95 | sMAPE for Test Set is: 27.32% | rMAE for Test Set is: 1.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:11:44,575]\u001b[0m Trial 233 finished with value: 4.491763882850136 and parameters: {'n_hidden': 4, 'learning_rate': 0.005247843134936183, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3157010495408617, 'dropout_rate_Layer_2': 0.10159289429499047, 'dropout_rate_Layer_3': 0.31977494308698384, 'dropout_rate_Layer_4': 0.2056651493310977, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.1571669335849072e-05, 'l1_Layer_2': 0.001087826667723699, 'l1_Layer_3': 0.0001953261463554721, 'l1_Layer_4': 0.0008937286679476952, 'n_units_Layer_1': 90, 'n_units_Layer_2': 275, 'n_units_Layer_3': 160, 'n_units_Layer_4': 115}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:11:45,313]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:11:53,575]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:11:55,980]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:11:56,565]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:11:59,070]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:12:02,890]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:12:05,869]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:12:11,287]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:12:14,816]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:12:18,886]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:12:23,154]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:12:29,033]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:12:39,120]\u001b[0m Trial 251 finished with value: 3.99288357537552 and parameters: {'n_hidden': 4, 'learning_rate': 0.0030639409947845996, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27339034218713476, 'dropout_rate_Layer_2': 0.1536410238790692, 'dropout_rate_Layer_3': 0.3677610385376924, 'dropout_rate_Layer_4': 0.021302551397891778, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00021699821335069875, 'l1_Layer_2': 0.02956236894335362, 'l1_Layer_3': 3.1893897761651547e-05, 'l1_Layer_4': 8.94099237561102e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 220, 'n_units_Layer_3': 135, 'n_units_Layer_4': 225}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.99 | sMAPE for Validation Set is: 11.51% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.07 | sMAPE for Test Set is: 22.10% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:12:42,960]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:12:47,956]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:12:53,115]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:13:11,775]\u001b[0m Trial 246 finished with value: 4.026803852317498 and parameters: {'n_hidden': 4, 'learning_rate': 0.0241843970085032, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31651001026520875, 'dropout_rate_Layer_2': 0.23977228647971735, 'dropout_rate_Layer_3': 0.25456340829576096, 'dropout_rate_Layer_4': 0.11897379912045779, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0016032442528681255, 'l1_Layer_2': 4.570771609643898e-05, 'l1_Layer_3': 1.1914306506510385e-05, 'l1_Layer_4': 0.00038504361781636155, 'n_units_Layer_1': 145, 'n_units_Layer_2': 180, 'n_units_Layer_3': 115, 'n_units_Layer_4': 150}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.03 | sMAPE for Validation Set is: 11.59% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.63 | sMAPE for Test Set is: 23.80% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:13:16,254]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:13:20,215]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:13:20,598]\u001b[0m Trial 258 finished with value: 3.970049605493882 and parameters: {'n_hidden': 4, 'learning_rate': 0.017451885095501156, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32362791489616277, 'dropout_rate_Layer_2': 0.22706272013986561, 'dropout_rate_Layer_3': 0.25557331506700104, 'dropout_rate_Layer_4': 0.34734951592869223, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0011946578086131378, 'l1_Layer_2': 4.884081668561706e-05, 'l1_Layer_3': 1.9511379532841837e-05, 'l1_Layer_4': 0.0007658991338444268, 'n_units_Layer_1': 145, 'n_units_Layer_2': 185, 'n_units_Layer_3': 110, 'n_units_Layer_4': 125}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:13:20,618]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.97 | sMAPE for Validation Set is: 11.47% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.01 | sMAPE for Test Set is: 22.00% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:13:30,075]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:13:33,292]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:13:36,371]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:13:36,673]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:13:39,589]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:13:55,282]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:14:07,205]\u001b[0m Trial 272 finished with value: 4.180724253929749 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019924112682457684, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3752502297928131, 'dropout_rate_Layer_2': 0.34999143532298055, 'dropout_rate_Layer_3': 0.3679074289555939, 'dropout_rate_Layer_4': 0.07844697209310876, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0008351174370843062, 'l1_Layer_2': 3.1719936555757215e-05, 'l1_Layer_3': 1.0071023669706525e-05, 'l1_Layer_4': 8.732490641507656e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 110, 'n_units_Layer_3': 165, 'n_units_Layer_4': 215}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.18 | sMAPE for Validation Set is: 11.98% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 6.74 | sMAPE for Test Set is: 24.06% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:14:07,963]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:14:10,057]\u001b[0m Trial 261 finished with value: 4.6458703581891685 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019253232378940025, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07600718918116221, 'dropout_rate_Layer_2': 0.3206861459492548, 'dropout_rate_Layer_3': 0.3680656486424024, 'dropout_rate_Layer_4': 0.1154236287569296, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.4207659779826936e-05, 'l1_Layer_2': 3.306769884791776e-05, 'l1_Layer_3': 4.351321778128751e-05, 'l1_Layer_4': 4.256203428578677e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 250, 'n_units_Layer_3': 65, 'n_units_Layer_4': 160}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.65 | sMAPE for Validation Set is: 13.26% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 7.29 | sMAPE for Test Set is: 25.58% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:14:12,608]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:14:13,509]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:14:15,805]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:14:21,870]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:14:24,050]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:14:28,490]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:14:32,865]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:14:38,241]\u001b[0m Trial 279 finished with value: 4.20140937014887 and parameters: {'n_hidden': 3, 'learning_rate': 0.005498794437523613, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09978096714875606, 'dropout_rate_Layer_2': 0.07163255361458824, 'dropout_rate_Layer_3': 0.1013797170172918, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.617766893725649e-05, 'l1_Layer_2': 0.000651494888520354, 'l1_Layer_3': 7.545819198859066e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 175, 'n_units_Layer_3': 90}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.20 | sMAPE for Validation Set is: 12.15% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 6.20 | sMAPE for Test Set is: 22.56% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:14:39,136]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:14:45,249]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:14:47,823]\u001b[0m Trial 281 finished with value: 4.168467056498181 and parameters: {'n_hidden': 4, 'learning_rate': 0.002443708168331606, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3447443071397401, 'dropout_rate_Layer_2': 0.05916673213610551, 'dropout_rate_Layer_3': 0.3494708985013608, 'dropout_rate_Layer_4': 0.11069933906051438, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0010635397396350837, 'l1_Layer_2': 1.6126173407371105e-05, 'l1_Layer_3': 4.7568614297657524e-05, 'l1_Layer_4': 4.640945349411905e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 255, 'n_units_Layer_3': 135, 'n_units_Layer_4': 235}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.17 | sMAPE for Validation Set is: 11.98% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 7.07 | sMAPE for Test Set is: 25.06% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:14:49,975]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:14:51,263]\u001b[0m Trial 275 finished with value: 4.133246350963244 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018961043214097458, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36566888328133945, 'dropout_rate_Layer_2': 0.07029716678690034, 'dropout_rate_Layer_3': 0.3677051131853148, 'dropout_rate_Layer_4': 0.07806573330117166, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0009176174070908356, 'l1_Layer_2': 2.7080720390337063e-05, 'l1_Layer_3': 3.7428665793875965e-05, 'l1_Layer_4': 3.7218183126419155e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 300, 'n_units_Layer_3': 145, 'n_units_Layer_4': 180}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.13 | sMAPE for Validation Set is: 11.86% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 7.04 | sMAPE for Test Set is: 24.95% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:14:52,819]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:14:56,436]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:15:01,807]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:15:04,768]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:15:08,415]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:15:08,896]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:15:16,363]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:15:16,741]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:15:22,591]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:15:24,864]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:15:28,094]\u001b[0m Trial 289 finished with value: 4.190188738416249 and parameters: {'n_hidden': 4, 'learning_rate': 0.0020387417269887554, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3393047728448724, 'dropout_rate_Layer_2': 0.08441680073607247, 'dropout_rate_Layer_3': 0.3898371498295968, 'dropout_rate_Layer_4': 0.11396534893052676, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00046469573561665016, 'l1_Layer_2': 1.465157836916186e-05, 'l1_Layer_3': 6.135938936291429e-05, 'l1_Layer_4': 2.6623444452549636e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 280, 'n_units_Layer_3': 130, 'n_units_Layer_4': 180}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.19 | sMAPE for Validation Set is: 12.06% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 6.89 | sMAPE for Test Set is: 24.50% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:15:31,610]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:15:35,779]\u001b[0m Trial 291 finished with value: 4.264471574522263 and parameters: {'n_hidden': 4, 'learning_rate': 0.0020170336688428796, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33245754318743326, 'dropout_rate_Layer_2': 0.0643442295734714, 'dropout_rate_Layer_3': 0.3469721835718341, 'dropout_rate_Layer_4': 0.11540225572677809, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0004788944283592801, 'l1_Layer_2': 1.4735069348296833e-05, 'l1_Layer_3': 6.897622518610132e-05, 'l1_Layer_4': 1.3406252753940309e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 280, 'n_units_Layer_3': 125, 'n_units_Layer_4': 205}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.26 | sMAPE for Validation Set is: 12.28% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 7.12 | sMAPE for Test Set is: 25.06% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:15:36,006]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:15:44,036]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:15:47,083]\u001b[0m Trial 299 finished with value: 4.298428610894045 and parameters: {'n_hidden': 4, 'learning_rate': 0.004296413061754727, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.290410476388338, 'dropout_rate_Layer_2': 0.15243973465978797, 'dropout_rate_Layer_3': 0.3155335412997641, 'dropout_rate_Layer_4': 0.11774622991291392, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00014221774562558773, 'l1_Layer_2': 0.00745027868645874, 'l1_Layer_3': 0.002048477636365893, 'l1_Layer_4': 0.00025990468944539355, 'n_units_Layer_1': 245, 'n_units_Layer_2': 240, 'n_units_Layer_3': 210, 'n_units_Layer_4': 225}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.30 | sMAPE for Validation Set is: 12.21% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 6.73 | sMAPE for Test Set is: 23.94% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:15:49,887]\u001b[0m Trial 300 finished with value: 4.258498129453961 and parameters: {'n_hidden': 4, 'learning_rate': 0.003749498624261574, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2850129688484937, 'dropout_rate_Layer_2': 0.1524225251007368, 'dropout_rate_Layer_3': 0.33575957427166686, 'dropout_rate_Layer_4': 0.10239661956015379, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0003331364383826157, 'l1_Layer_2': 0.009527811574874222, 'l1_Layer_3': 0.0021390715520997684, 'l1_Layer_4': 0.0002590726716517343, 'n_units_Layer_1': 100, 'n_units_Layer_2': 245, 'n_units_Layer_3': 175, 'n_units_Layer_4': 210}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.26 | sMAPE for Validation Set is: 12.23% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 7.04 | sMAPE for Test Set is: 24.94% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:15:52,905]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:15:53,312]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:15:57,932]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:16:03,465]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:16:05,983]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:16:08,232]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:16:12,596]\u001b[0m Trial 307 finished with value: 4.175996453224836 and parameters: {'n_hidden': 3, 'learning_rate': 0.006519209259589302, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0892644538025652, 'dropout_rate_Layer_2': 0.10507387655037803, 'dropout_rate_Layer_3': 0.18909867160402283, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.017603347839503e-05, 'l1_Layer_2': 0.0008646354243684681, 'l1_Layer_3': 0.0011638597236585887, 'n_units_Layer_1': 85, 'n_units_Layer_2': 185, 'n_units_Layer_3': 165}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:16:12,698]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.18 | sMAPE for Validation Set is: 11.94% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 6.86 | sMAPE for Test Set is: 24.43% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:16:20,013]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:16:20,306]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:16:20,650]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:16:27,877]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:16:30,146]\u001b[0m Trial 310 finished with value: 4.188495982874261 and parameters: {'n_hidden': 3, 'learning_rate': 0.007024397009137742, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09271952596851371, 'dropout_rate_Layer_2': 0.021632683351419844, 'dropout_rate_Layer_3': 0.05877684387809662, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002900999714959713, 'l1_Layer_2': 0.0033950867528645874, 'l1_Layer_3': 0.000138030360788837, 'n_units_Layer_1': 85, 'n_units_Layer_2': 130, 'n_units_Layer_3': 165}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.19 | sMAPE for Validation Set is: 12.07% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 7.01 | sMAPE for Test Set is: 24.91% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:16:30,539]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:16:36,615]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:16:36,761]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:16:45,247]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:16:49,350]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:16:52,164]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:16:52,638]\u001b[0m Trial 322 finished with value: 4.448096871358278 and parameters: {'n_hidden': 3, 'learning_rate': 0.010363185638553034, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18656202002609365, 'dropout_rate_Layer_2': 0.05528095910207041, 'dropout_rate_Layer_3': 0.06149761235120967, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.7418285216825406e-05, 'l1_Layer_2': 0.0001572192570811184, 'l1_Layer_3': 6.210105298454651e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 150, 'n_units_Layer_3': 165}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.45 | sMAPE for Validation Set is: 12.72% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 7.30 | sMAPE for Test Set is: 25.60% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:16:57,522]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:17:00,630]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:17:03,590]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:17:04,628]\u001b[0m Trial 318 finished with value: 4.113113233736773 and parameters: {'n_hidden': 4, 'learning_rate': 0.001855307829755484, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3203998645201859, 'dropout_rate_Layer_2': 0.046351961719850815, 'dropout_rate_Layer_3': 0.3491537987652748, 'dropout_rate_Layer_4': 0.1312612756535768, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.01105604256566883, 'l1_Layer_2': 1.287225524333611e-05, 'l1_Layer_3': 6.487584763407085e-05, 'l1_Layer_4': 1.0053524067418365e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 285, 'n_units_Layer_3': 115, 'n_units_Layer_4': 170}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.11 | sMAPE for Validation Set is: 11.91% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.26 | sMAPE for Test Set is: 19.76% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:17:07,898]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:17:10,927]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:17:12,253]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:17:14,866]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:17:15,396]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:17:17,458]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:17:26,223]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:17:29,617]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:17:31,032]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:17:35,361]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:17:35,415]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:17:35,711]\u001b[0m Trial 334 finished with value: 4.409785011858024 and parameters: {'n_hidden': 3, 'learning_rate': 0.005521766006085205, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23977940326396308, 'dropout_rate_Layer_2': 0.18238078919277115, 'dropout_rate_Layer_3': 0.07707189131461147, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00044824215912738776, 'l1_Layer_2': 0.0003416286320718799, 'l1_Layer_3': 0.000147270555154468, 'n_units_Layer_1': 70, 'n_units_Layer_2': 215, 'n_units_Layer_3': 85}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.41 | sMAPE for Validation Set is: 12.69% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 6.61 | sMAPE for Test Set is: 23.77% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:17:43,206]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:17:43,631]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:17:46,139]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:17:49,913]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:17:54,959]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:17:56,025]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:18:00,160]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:18:00,197]\u001b[0m Trial 340 finished with value: 4.395123536613401 and parameters: {'n_hidden': 3, 'learning_rate': 0.005508347383117502, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03301249828241201, 'dropout_rate_Layer_2': 0.04036995909494745, 'dropout_rate_Layer_3': 0.03796016147671823, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014693968788811202, 'l1_Layer_2': 0.001246283929386119, 'l1_Layer_3': 0.0002733910130428618, 'n_units_Layer_1': 60, 'n_units_Layer_2': 165, 'n_units_Layer_3': 70}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.40 | sMAPE for Validation Set is: 12.59% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 6.10 | sMAPE for Test Set is: 22.24% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:18:00,311]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:18:14,716]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:18:20,356]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:18:22,995]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:18:26,665]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:18:33,071]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:18:35,619]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:18:36,097]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.66 | sMAPE for Validation Set is: 13.17% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 5.57 | sMAPE for Test Set is: 20.04% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:18:40,669]\u001b[0m Trial 351 finished with value: 4.658677170893777 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026466614650715865, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.023011957961875898, 'dropout_rate_Layer_2': 0.016288882016848583, 'dropout_rate_Layer_3': 0.0372516394858076, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.7966117275263396e-05, 'l1_Layer_2': 0.0014677844979216126, 'l1_Layer_3': 7.404231320197796e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 180, 'n_units_Layer_3': 215}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:18:41,517]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:18:46,662]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:18:47,373]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:18:51,838]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:18:57,406]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:19:01,421]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:19:05,303]\u001b[0m Trial 361 finished with value: 4.21003581353406 and parameters: {'n_hidden': 4, 'learning_rate': 0.002297168312465959, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37812375283307886, 'dropout_rate_Layer_2': 0.01436361065434066, 'dropout_rate_Layer_3': 0.2061474921332719, 'dropout_rate_Layer_4': 0.11617470762875007, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.011235319333139837, 'l1_Layer_2': 0.0031428797583134727, 'l1_Layer_3': 1.0365276765724225e-05, 'l1_Layer_4': 6.828188749556755e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 270, 'n_units_Layer_3': 120, 'n_units_Layer_4': 175}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.21 | sMAPE for Validation Set is: 12.04% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 5.28 | sMAPE for Test Set is: 19.57% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:19:09,051]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:19:10,116]\u001b[0m Trial 358 finished with value: 4.364721128230211 and parameters: {'n_hidden': 4, 'learning_rate': 0.009755564463475462, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18357677340329023, 'dropout_rate_Layer_2': 0.04133867004037062, 'dropout_rate_Layer_3': 0.20757649851538829, 'dropout_rate_Layer_4': 0.05440544389265506, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.020004149725986704, 'l1_Layer_2': 0.03573844906097495, 'l1_Layer_3': 2.387974465925959e-05, 'l1_Layer_4': 0.01007867116003131, 'n_units_Layer_1': 130, 'n_units_Layer_2': 270, 'n_units_Layer_3': 200, 'n_units_Layer_4': 150}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.36 | sMAPE for Validation Set is: 12.41% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 4.88 | sMAPE for Test Set is: 17.88% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:19:16,040]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:19:19,619]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:19:20,505]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.34 | sMAPE for Validation Set is: 12.36% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 6.86 | sMAPE for Test Set is: 24.48% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:19:23,563]\u001b[0m Trial 362 finished with value: 4.338861605956789 and parameters: {'n_hidden': 4, 'learning_rate': 0.0022900636720071398, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37541041770216166, 'dropout_rate_Layer_2': 0.0692645024522222, 'dropout_rate_Layer_3': 0.3650590278288266, 'dropout_rate_Layer_4': 0.13683468346847613, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00080045010516907, 'l1_Layer_2': 3.1206430550484316e-05, 'l1_Layer_3': 1.2452161644581482e-05, 'l1_Layer_4': 6.825449241183306e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 270, 'n_units_Layer_3': 120, 'n_units_Layer_4': 175}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:19:24,298]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:19:29,322]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:19:30,565]\u001b[0m Trial 368 finished with value: 4.1897761776194224 and parameters: {'n_hidden': 4, 'learning_rate': 0.002906788196599267, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3769794809525888, 'dropout_rate_Layer_2': 0.02987847730262957, 'dropout_rate_Layer_3': 0.204148156194351, 'dropout_rate_Layer_4': 0.10994442652377111, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0070243612329775745, 'l1_Layer_2': 0.003440840276628268, 'l1_Layer_3': 1.4526246817663783e-05, 'l1_Layer_4': 8.549596578832897e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 255, 'n_units_Layer_3': 110, 'n_units_Layer_4': 180}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.19 | sMAPE for Validation Set is: 11.99% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 5.29 | sMAPE for Test Set is: 19.57% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:19:31,879]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:19:37,776]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:19:38,541]\u001b[0m Trial 371 finished with value: 4.499816687271359 and parameters: {'n_hidden': 3, 'learning_rate': 0.007932812204282309, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08208121681745445, 'dropout_rate_Layer_2': 0.02328927155806073, 'dropout_rate_Layer_3': 0.00034580479844281004, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.5582940792265785e-05, 'l1_Layer_2': 0.0004614243522689922, 'l1_Layer_3': 2.140794775818583e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 205, 'n_units_Layer_3': 110}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.50 | sMAPE for Validation Set is: 12.84% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 6.00 | sMAPE for Test Set is: 21.84% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:19:39,041]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:19:39,204]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:19:45,013]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:19:47,528]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:19:49,063]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:19:54,107]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:19:58,058]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:20:02,105]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:20:04,922]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:20:08,071]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:20:11,626]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:20:11,771]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:20:14,431]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:20:24,669]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:20:31,251]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:20:43,867]\u001b[0m Trial 389 finished with value: 4.435043017673315 and parameters: {'n_hidden': 4, 'learning_rate': 0.0029104644205960543, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08417906247038567, 'dropout_rate_Layer_2': 0.04597019278063935, 'dropout_rate_Layer_3': 0.3147652225225892, 'dropout_rate_Layer_4': 0.07164036776678454, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 9.999597992834483e-05, 'l1_Layer_2': 0.021230965450926433, 'l1_Layer_3': 0.00012560182128760369, 'l1_Layer_4': 0.001985415880211328, 'n_units_Layer_1': 285, 'n_units_Layer_2': 275, 'n_units_Layer_3': 285, 'n_units_Layer_4': 260}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.44 | sMAPE for Validation Set is: 12.76% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 7.04 | sMAPE for Test Set is: 24.88% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:20:44,224]\u001b[0m Trial 383 finished with value: 4.134637151941019 and parameters: {'n_hidden': 4, 'learning_rate': 0.0026139302452773258, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18325607647245007, 'dropout_rate_Layer_2': 0.05273449012889744, 'dropout_rate_Layer_3': 0.29628198424477076, 'dropout_rate_Layer_4': 0.07345366267724052, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00010578184876416462, 'l1_Layer_2': 1.183410408662021e-05, 'l1_Layer_3': 0.010986947874134664, 'l1_Layer_4': 0.0003504350901542059, 'n_units_Layer_1': 70, 'n_units_Layer_2': 275, 'n_units_Layer_3': 235, 'n_units_Layer_4': 265}. Best is trial 1 with value: 3.921573025039232.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.13 | sMAPE for Validation Set is: 11.96% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.34 | sMAPE for Test Set is: 22.91% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:20:49,000]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:20:58,826]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:21:02,050]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:21:07,837]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:21:26,279]\u001b[0m Trial 393 finished with value: 3.9081112611804376 and parameters: {'n_hidden': 4, 'learning_rate': 0.002499226583167355, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33123358962482413, 'dropout_rate_Layer_2': 0.12134702361520286, 'dropout_rate_Layer_3': 0.25494780279982426, 'dropout_rate_Layer_4': 0.12893322389827302, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0001443568493791258, 'l1_Layer_2': 1.672429571219628e-05, 'l1_Layer_3': 0.0005826220018506421, 'l1_Layer_4': 0.0009002348042985701, 'n_units_Layer_1': 220, 'n_units_Layer_2': 235, 'n_units_Layer_3': 180, 'n_units_Layer_4': 120}. Best is trial 393 with value: 3.9081112611804376.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.91 | sMAPE for Validation Set is: 11.31% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.98 | sMAPE for Test Set is: 18.58% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:21:31,433]\u001b[0m Trial 399 finished with value: 4.21539806660771 and parameters: {'n_hidden': 3, 'learning_rate': 0.006223249360564908, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2389909525190117, 'dropout_rate_Layer_2': 0.16551826386070756, 'dropout_rate_Layer_3': 0.09893147441930535, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00018980590797902262, 'l1_Layer_2': 0.0005842716600522098, 'l1_Layer_3': 0.00015274545619161473, 'n_units_Layer_1': 80, 'n_units_Layer_2': 225, 'n_units_Layer_3': 75}. Best is trial 393 with value: 3.9081112611804376.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.22 | sMAPE for Validation Set is: 12.12% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 6.52 | sMAPE for Test Set is: 23.51% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:21:41,615]\u001b[0m Trial 398 finished with value: 4.347833502723296 and parameters: {'n_hidden': 4, 'learning_rate': 0.00406430833624599, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13516841948907246, 'dropout_rate_Layer_2': 0.07412209955141433, 'dropout_rate_Layer_3': 0.36011200159134, 'dropout_rate_Layer_4': 0.005212309653060639, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 4.6851862181318936e-05, 'l1_Layer_2': 1.1448069193117891e-05, 'l1_Layer_3': 0.008844762975744703, 'l1_Layer_4': 0.000367011084970891, 'n_units_Layer_1': 60, 'n_units_Layer_2': 255, 'n_units_Layer_3': 235, 'n_units_Layer_4': 300}. Best is trial 393 with value: 3.9081112611804376.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.35 | sMAPE for Validation Set is: 12.54% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 6.92 | sMAPE for Test Set is: 24.50% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:21:47,080]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:21:51,878]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:21:55,397]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:21:58,547]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:22:02,709]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:22:06,360]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:22:07,060]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:22:18,240]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:22:21,402]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:22:24,462]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:22:29,754]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:22:32,977]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:22:40,344]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:23:06,337]\u001b[0m Trial 408 finished with value: 3.984992074655642 and parameters: {'n_hidden': 4, 'learning_rate': 0.002595719886034289, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33188652747181785, 'dropout_rate_Layer_2': 0.03468520635390246, 'dropout_rate_Layer_3': 0.26439637023952384, 'dropout_rate_Layer_4': 0.1343146567663063, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0015093901381306287, 'l1_Layer_2': 1.822156488539601e-05, 'l1_Layer_3': 0.004133612477332855, 'l1_Layer_4': 0.0008094236189996112, 'n_units_Layer_1': 220, 'n_units_Layer_2': 235, 'n_units_Layer_3': 255, 'n_units_Layer_4': 125}. Best is trial 393 with value: 3.9081112611804376.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.98 | sMAPE for Validation Set is: 11.43% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.23 | sMAPE for Test Set is: 19.47% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:23:06,603]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:23:09,048]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:23:14,235]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:23:21,227]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:23:25,239]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:23:30,642]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:23:34,394]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:24:15,225]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:24:18,315]\u001b[0m Trial 423 finished with value: 4.165490225706686 and parameters: {'n_hidden': 4, 'learning_rate': 0.00392718513928624, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3642817310407667, 'dropout_rate_Layer_2': 0.3515481246317003, 'dropout_rate_Layer_3': 0.1898114072310777, 'dropout_rate_Layer_4': 0.11014352713353188, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.006363877473664415, 'l1_Layer_2': 0.0066009707968495025, 'l1_Layer_3': 0.000541862585102303, 'l1_Layer_4': 5.920787969969187e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 250, 'n_units_Layer_3': 120, 'n_units_Layer_4': 190}. Best is trial 393 with value: 3.9081112611804376.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.17 | sMAPE for Validation Set is: 11.96% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 5.77 | sMAPE for Test Set is: 21.29% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:24:23,180]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:24:26,331]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:24:30,976]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:24:36,648]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:24:41,070]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:24:44,679]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:24:47,963]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:24:51,089]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:24:54,252]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:25:13,320]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:25:22,821]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:25:27,899]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.90 | sMAPE for Validation Set is: 11.41% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.58 | sMAPE for Test Set is: 17.03% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:25:33,416]\u001b[0m Trial 390 finished with value: 3.903698763101461 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019042032705808034, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3580428837849027, 'dropout_rate_Layer_2': 0.04679767185402097, 'dropout_rate_Layer_3': 0.2569897081462967, 'dropout_rate_Layer_4': 0.12371820215311885, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00015977824674891876, 'l1_Layer_2': 0.0015956114286387005, 'l1_Layer_3': 0.0035885398457330075, 'l1_Layer_4': 0.0007795965949373234, 'n_units_Layer_1': 170, 'n_units_Layer_2': 245, 'n_units_Layer_3': 125, 'n_units_Layer_4': 125}. Best is trial 390 with value: 3.903698763101461.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:25:35,201]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:25:37,595]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:25:38,397]\u001b[0m Trial 418 finished with value: 4.543179570061313 and parameters: {'n_hidden': 4, 'learning_rate': 0.002484561832090482, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3666498377767879, 'dropout_rate_Layer_2': 0.04521653667648083, 'dropout_rate_Layer_3': 0.2935779349841543, 'dropout_rate_Layer_4': 0.15318750665191272, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00012129863630077631, 'l1_Layer_2': 1.639960092916359e-05, 'l1_Layer_3': 0.0031456544523903295, 'l1_Layer_4': 0.005378745185000116, 'n_units_Layer_1': 220, 'n_units_Layer_2': 240, 'n_units_Layer_3': 270, 'n_units_Layer_4': 100}. Best is trial 390 with value: 3.903698763101461.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.54 | sMAPE for Validation Set is: 12.96% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 7.47 | sMAPE for Test Set is: 25.99% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:25:42,898]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:25:43,605]\u001b[0m Trial 435 finished with value: 4.268265115295708 and parameters: {'n_hidden': 3, 'learning_rate': 0.003538899442439217, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12073257228709132, 'dropout_rate_Layer_2': 0.15487919823818652, 'dropout_rate_Layer_3': 0.14570234441032076, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00036745866231855653, 'l1_Layer_2': 0.0009542761465142326, 'l1_Layer_3': 0.0001652407880031957, 'n_units_Layer_1': 80, 'n_units_Layer_2': 240, 'n_units_Layer_3': 180}. Best is trial 390 with value: 3.903698763101461.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.27 | sMAPE for Validation Set is: 12.23% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 6.58 | sMAPE for Test Set is: 23.61% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:25:43,937]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:25:49,612]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:25:52,987]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:25:55,766]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:25:56,299]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:26:02,408]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:26:02,940]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:26:05,851]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:26:07,273]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:26:08,050]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:26:10,212]\u001b[0m Trial 443 finished with value: 4.16038902709382 and parameters: {'n_hidden': 3, 'learning_rate': 0.003803414269613218, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2597921765595355, 'dropout_rate_Layer_2': 0.1409988651981464, 'dropout_rate_Layer_3': 0.1457177160355998, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00024450964038045137, 'l1_Layer_2': 0.0009237731094231587, 'l1_Layer_3': 0.00016964340574621294, 'n_units_Layer_1': 100, 'n_units_Layer_2': 245, 'n_units_Layer_3': 155}. Best is trial 390 with value: 3.903698763101461.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.16 | sMAPE for Validation Set is: 12.11% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.30 | sMAPE for Test Set is: 22.88% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:26:10,347]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:26:15,182]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:26:22,847]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:26:23,306]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:26:23,680]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:26:30,679]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:26:31,262]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:26:39,208]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:26:39,428]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:26:44,578]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:26:56,646]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:26:56,795]\u001b[0m Trial 462 finished with value: 4.307592969562311 and parameters: {'n_hidden': 4, 'learning_rate': 0.002121937530660797, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3705219926912207, 'dropout_rate_Layer_2': 0.35895751309259055, 'dropout_rate_Layer_3': 0.37235182723922805, 'dropout_rate_Layer_4': 0.11839355137333842, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.026838990957057576, 'l1_Layer_2': 0.001426903148503259, 'l1_Layer_3': 1.039268440609733e-05, 'l1_Layer_4': 5.662895480268393e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 285, 'n_units_Layer_3': 105, 'n_units_Layer_4': 170}. Best is trial 390 with value: 3.903698763101461.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.31 | sMAPE for Validation Set is: 12.31% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 6.37 | sMAPE for Test Set is: 23.00% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:27:08,180]\u001b[0m Trial 464 finished with value: 4.114087206984365 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036871705534984736, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29585943251623037, 'dropout_rate_Layer_2': 0.17247303534072259, 'dropout_rate_Layer_3': 0.13119272494787512, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012710444113513025, 'l1_Layer_2': 0.0006088054330553306, 'l1_Layer_3': 5.9102506991845313e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 240, 'n_units_Layer_3': 175}. Best is trial 390 with value: 3.903698763101461.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.11 | sMAPE for Validation Set is: 11.95% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.35 | sMAPE for Test Set is: 23.17% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:27:14,557]\u001b[0m Trial 466 finished with value: 4.139084243357071 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031240015169162042, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27253652023376584, 'dropout_rate_Layer_2': 0.1447534553416576, 'dropout_rate_Layer_3': 0.1256239906191996, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00019417296959451787, 'l1_Layer_2': 0.0007570092926501616, 'l1_Layer_3': 0.00027310522229398795, 'n_units_Layer_1': 80, 'n_units_Layer_2': 160, 'n_units_Layer_3': 170}. Best is trial 390 with value: 3.903698763101461.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.14 | sMAPE for Validation Set is: 11.98% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.63 | sMAPE for Test Set is: 23.76% | rMAE for Test Set is: 1.09\n",
      "MAE for Validation Set is: 4.22 | sMAPE for Validation Set is: 12.11% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 6.19 | sMAPE for Test Set is: 22.43% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:27:16,242]\u001b[0m Trial 465 finished with value: 4.221026002921206 and parameters: {'n_hidden': 4, 'learning_rate': 0.001837596602654371, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3612679412046893, 'dropout_rate_Layer_2': 0.3607298985538471, 'dropout_rate_Layer_3': 0.372723780042898, 'dropout_rate_Layer_4': 0.12151745366059333, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.018132487624494566, 'l1_Layer_2': 0.0017644879847521198, 'l1_Layer_3': 1.3008711044925734e-05, 'l1_Layer_4': 7.678634013962926e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 290, 'n_units_Layer_3': 105, 'n_units_Layer_4': 215}. Best is trial 390 with value: 3.903698763101461.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:27:20,060]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:27:22,081]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:27:24,672]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:27:27,644]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:27:33,756]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:27:37,769]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:27:38,750]\u001b[0m Trial 459 finished with value: 4.183042325325297 and parameters: {'n_hidden': 4, 'learning_rate': 0.001776191680453776, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36348563545214135, 'dropout_rate_Layer_2': 0.028442958726309774, 'dropout_rate_Layer_3': 0.27385299698762283, 'dropout_rate_Layer_4': 0.03997714416505038, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.5148984454026243e-05, 'l1_Layer_2': 0.005469109893693614, 'l1_Layer_3': 0.008479439943975181, 'l1_Layer_4': 0.0001723412491585918, 'n_units_Layer_1': 190, 'n_units_Layer_2': 255, 'n_units_Layer_3': 180, 'n_units_Layer_4': 130}. Best is trial 390 with value: 3.903698763101461.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.18 | sMAPE for Validation Set is: 12.06% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 6.81 | sMAPE for Test Set is: 24.18% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:27:42,859]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:27:43,370]\u001b[0m Trial 469 finished with value: 4.083097965455366 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018001024541031182, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00933841192720856, 'dropout_rate_Layer_2': 0.3645259932852875, 'dropout_rate_Layer_3': 0.3733370524903811, 'dropout_rate_Layer_4': 0.12342773831485784, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.02262252228584179, 'l1_Layer_2': 0.001727803296282996, 'l1_Layer_3': 1.336071975529916e-05, 'l1_Layer_4': 0.00012259872494492215, 'n_units_Layer_1': 290, 'n_units_Layer_2': 290, 'n_units_Layer_3': 105, 'n_units_Layer_4': 225}. Best is trial 390 with value: 3.903698763101461.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.08 | sMAPE for Validation Set is: 11.70% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.29 | sMAPE for Test Set is: 19.45% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:27:44,638]\u001b[0m Trial 472 finished with value: 4.229370493107446 and parameters: {'n_hidden': 3, 'learning_rate': 0.003266078894872261, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30507988121522045, 'dropout_rate_Layer_2': 0.14321382389072873, 'dropout_rate_Layer_3': 0.13511302065839914, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001899632896890466, 'l1_Layer_2': 0.0006238908397762632, 'l1_Layer_3': 9.113427428514704e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 260, 'n_units_Layer_3': 175}. Best is trial 390 with value: 3.903698763101461.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.23 | sMAPE for Validation Set is: 12.09% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 7.39 | sMAPE for Test Set is: 25.85% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:27:49,042]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:27:51,466]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:27:53,428]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:27:54,502]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:27:59,261]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:28:01,987]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:28:03,656]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:28:07,147]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:28:10,641]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:28:13,153]\u001b[0m Trial 480 finished with value: 4.048793737151325 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029439440977816387, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3228793794420474, 'dropout_rate_Layer_2': 0.145216978875589, 'dropout_rate_Layer_3': 0.12137412540918947, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002381381861962197, 'l1_Layer_2': 0.00062542793419332, 'l1_Layer_3': 9.56428200960449e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 270, 'n_units_Layer_3': 185}. Best is trial 390 with value: 3.903698763101461.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.05 | sMAPE for Validation Set is: 11.76% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.19 | sMAPE for Test Set is: 22.56% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:28:14,299]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:28:18,235]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:28:21,154]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:28:24,626]\u001b[0m Trial 486 finished with value: 4.142035918431131 and parameters: {'n_hidden': 4, 'learning_rate': 0.004650182608019407, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29098500258110727, 'dropout_rate_Layer_2': 0.153163022608796, 'dropout_rate_Layer_3': 0.30324721015512673, 'dropout_rate_Layer_4': 0.14358874159661872, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0001096788505941251, 'l1_Layer_2': 0.007593872032306698, 'l1_Layer_3': 0.001348119279379081, 'l1_Layer_4': 0.00023782726424885955, 'n_units_Layer_1': 245, 'n_units_Layer_2': 245, 'n_units_Layer_3': 245, 'n_units_Layer_4': 240}. Best is trial 390 with value: 3.903698763101461.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:28:24,694]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.14 | sMAPE for Validation Set is: 11.94% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.90 | sMAPE for Test Set is: 24.54% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:28:30,099]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:28:30,308]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:28:30,833]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:28:38,261]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:28:38,640]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:28:43,111]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:28:46,064]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:28:49,752]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:28:52,282]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:28:52,520]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:28:53,223]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:29:01,219]\u001b[0m Trial 500 finished with value: 4.057452327881001 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023900703916633127, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27418263255899855, 'dropout_rate_Layer_2': 0.15771423136020968, 'dropout_rate_Layer_3': 0.15925491394059896, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012314061916337548, 'l1_Layer_2': 0.0005562018158111804, 'l1_Layer_3': 0.00012629435629625326, 'n_units_Layer_1': 100, 'n_units_Layer_2': 270, 'n_units_Layer_3': 195}. Best is trial 390 with value: 3.903698763101461.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.06 | sMAPE for Validation Set is: 11.80% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.17 | sMAPE for Test Set is: 22.50% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:29:01,720]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:29:09,647]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:29:12,871]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:29:15,899]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:29:20,636]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:29:24,797]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:29:29,887]\u001b[0m Trial 508 finished with value: 4.04553355062918 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020940153514794504, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33155850034458667, 'dropout_rate_Layer_2': 0.16071102465482312, 'dropout_rate_Layer_3': 0.165195641640242, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001338972688947999, 'l1_Layer_2': 0.0003861280249418118, 'l1_Layer_3': 0.00021168977952448973, 'n_units_Layer_1': 100, 'n_units_Layer_2': 270, 'n_units_Layer_3': 195}. Best is trial 390 with value: 3.903698763101461.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.05 | sMAPE for Validation Set is: 11.66% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.24 | sMAPE for Test Set is: 22.59% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:29:30,634]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:29:34,817]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:29:35,136]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:29:41,593]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:29:45,250]\u001b[0m Trial 504 finished with value: 4.047356131489717 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015249923779745724, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1280150407771749, 'dropout_rate_Layer_2': 0.38926102989442957, 'dropout_rate_Layer_3': 0.3128351885348237, 'dropout_rate_Layer_4': 0.12514204496914294, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0014740083470787268, 'l1_Layer_2': 0.0015091991600749573, 'l1_Layer_3': 1.2343496756510799e-05, 'l1_Layer_4': 5.226300946631834e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 300, 'n_units_Layer_3': 75, 'n_units_Layer_4': 205}. Best is trial 390 with value: 3.903698763101461.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.05 | sMAPE for Validation Set is: 11.66% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.90 | sMAPE for Test Set is: 21.55% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:29:45,429]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:29:53,100]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:29:53,502]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:29:59,515]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:30:03,101]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:30:03,732]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:30:08,637]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:30:10,841]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:30:13,584]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:30:15,983]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:30:22,148]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:30:25,692]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:30:30,788]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:30:34,758]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:30:38,910]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:30:46,262]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:30:50,506]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:30:54,019]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:30:57,842]\u001b[0m Trial 530 finished with value: 4.151751739037547 and parameters: {'n_hidden': 3, 'learning_rate': 0.002442319679891343, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3058573678293035, 'dropout_rate_Layer_2': 0.14267649034296015, 'dropout_rate_Layer_3': 0.1721275864645647, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00018280731505972513, 'l1_Layer_2': 0.00048170811605335634, 'l1_Layer_3': 0.00017783109292011007, 'n_units_Layer_1': 80, 'n_units_Layer_2': 255, 'n_units_Layer_3': 170}. Best is trial 390 with value: 3.903698763101461.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.15 | sMAPE for Validation Set is: 12.09% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.84 | sMAPE for Test Set is: 24.45% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:31:05,564]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:31:09,084]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:31:09,485]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:31:15,142]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:31:18,806]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:31:21,716]\u001b[0m Trial 535 finished with value: 4.0386360504285355 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024029179405820455, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33686389666911254, 'dropout_rate_Layer_2': 0.15348235040400812, 'dropout_rate_Layer_3': 0.10882481251672188, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00020923491176093738, 'l1_Layer_2': 0.0004883298896150292, 'l1_Layer_3': 0.00017079318329905633, 'n_units_Layer_1': 80, 'n_units_Layer_2': 255, 'n_units_Layer_3': 170}. Best is trial 390 with value: 3.903698763101461.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.04 | sMAPE for Validation Set is: 11.73% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.40 | sMAPE for Test Set is: 23.18% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:31:23,792]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:31:24,590]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:31:28,994]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:31:36,371]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:31:38,896]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:31:47,251]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:31:56,042]\u001b[0m Trial 547 finished with value: 4.314560647903208 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024909782509651545, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3370639728028244, 'dropout_rate_Layer_2': 0.14121680385764435, 'dropout_rate_Layer_3': 0.19053727948673865, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00022118734497396855, 'l1_Layer_2': 0.0003904973337631736, 'l1_Layer_3': 9.65237087472455e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 260, 'n_units_Layer_3': 175}. Best is trial 390 with value: 3.903698763101461.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.31 | sMAPE for Validation Set is: 12.39% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 6.55 | sMAPE for Test Set is: 23.54% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:31:56,526]\u001b[0m Trial 548 finished with value: 4.068388648907788 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024646414815693426, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34151099795743806, 'dropout_rate_Layer_2': 0.13828396877772497, 'dropout_rate_Layer_3': 0.19209388569630084, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00023502423040035823, 'l1_Layer_2': 0.0003745407877315746, 'l1_Layer_3': 9.809715799981913e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 280, 'n_units_Layer_3': 165}. Best is trial 390 with value: 3.903698763101461.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.07 | sMAPE for Validation Set is: 11.72% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.28 | sMAPE for Test Set is: 22.76% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:32:01,775]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:32:06,274]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:32:06,591]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:32:13,194]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:32:13,699]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:32:18,637]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:32:21,622]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:32:22,152]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:32:27,621]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:32:28,934]\u001b[0m Trial 509 finished with value: 3.987448374283824 and parameters: {'n_hidden': 4, 'learning_rate': 0.000515325505798076, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3090177634136273, 'dropout_rate_Layer_2': 0.17743395153256356, 'dropout_rate_Layer_3': 0.3437033816607838, 'dropout_rate_Layer_4': 0.09839018647671831, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 8.349675169566986e-05, 'l1_Layer_2': 3.6433172579491654e-05, 'l1_Layer_3': 0.004418496793576319, 'l1_Layer_4': 0.0005211194756904858, 'n_units_Layer_1': 270, 'n_units_Layer_2': 190, 'n_units_Layer_3': 285, 'n_units_Layer_4': 155}. Best is trial 390 with value: 3.903698763101461.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.99 | sMAPE for Validation Set is: 11.55% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.02 | sMAPE for Test Set is: 22.49% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:32:33,825]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:32:45,499]\u001b[0m Trial 562 finished with value: 4.3335097033307095 and parameters: {'n_hidden': 3, 'learning_rate': 0.006723817246677681, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.274502356983954, 'dropout_rate_Layer_2': 0.2536136736498662, 'dropout_rate_Layer_3': 0.3983049858560381, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00015657482572052378, 'l1_Layer_2': 0.0007944906256211013, 'l1_Layer_3': 0.000573967509566407, 'n_units_Layer_1': 260, 'n_units_Layer_2': 255, 'n_units_Layer_3': 260}. Best is trial 390 with value: 3.903698763101461.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.33 | sMAPE for Validation Set is: 12.44% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 6.66 | sMAPE for Test Set is: 23.81% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:32:48,938]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:32:53,448]\u001b[0m Trial 561 finished with value: 4.081701713869248 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016754692207191625, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32809243559487045, 'dropout_rate_Layer_2': 0.16158610008193858, 'dropout_rate_Layer_3': 0.213115558998343, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00041660693392506936, 'l1_Layer_2': 0.00044829536538244574, 'l1_Layer_3': 0.0001530825703009624, 'n_units_Layer_1': 75, 'n_units_Layer_2': 280, 'n_units_Layer_3': 170}. Best is trial 390 with value: 3.903698763101461.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.08 | sMAPE for Validation Set is: 11.78% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.05 | sMAPE for Test Set is: 22.07% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:32:57,651]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:33:12,910]\u001b[0m Trial 564 finished with value: 4.146153891828029 and parameters: {'n_hidden': 4, 'learning_rate': 0.004261316043357728, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29248571325927264, 'dropout_rate_Layer_2': 0.16419243595448532, 'dropout_rate_Layer_3': 0.3234142610963836, 'dropout_rate_Layer_4': 0.11681108020880179, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00012010933890260377, 'l1_Layer_2': 0.006097718647971138, 'l1_Layer_3': 0.0009202645935301825, 'l1_Layer_4': 0.00027554866386691264, 'n_units_Layer_1': 220, 'n_units_Layer_2': 240, 'n_units_Layer_3': 150, 'n_units_Layer_4': 225}. Best is trial 390 with value: 3.903698763101461.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.15 | sMAPE for Validation Set is: 12.02% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 7.15 | sMAPE for Test Set is: 25.31% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:33:16,577]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:33:21,732]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:33:25,946]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:33:53,237]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:33:59,922]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:34:04,326]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:34:09,528]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:34:17,071]\u001b[0m Trial 571 finished with value: 4.259293113376397 and parameters: {'n_hidden': 4, 'learning_rate': 0.002837888177842147, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2921474207925185, 'dropout_rate_Layer_2': 0.1769144913078465, 'dropout_rate_Layer_3': 0.3747331000816118, 'dropout_rate_Layer_4': 0.13252738003558256, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.719287223980023e-05, 'l1_Layer_2': 0.004466883802959222, 'l1_Layer_3': 1.7118674077240218e-05, 'l1_Layer_4': 8.059938346267664e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 300, 'n_units_Layer_3': 170, 'n_units_Layer_4': 190}. Best is trial 390 with value: 3.903698763101461.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.26 | sMAPE for Validation Set is: 12.16% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 6.68 | sMAPE for Test Set is: 23.97% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:34:20,925]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:34:24,558]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:34:24,976]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:34:36,327]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:34:39,141]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:34:39,836]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:34:45,248]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:34:51,407]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:34:55,124]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:35:16,798]\u001b[0m Trial 568 finished with value: 4.301197572180679 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008634477631897467, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3241691751924656, 'dropout_rate_Layer_2': 0.06206297447485459, 'dropout_rate_Layer_3': 0.3951722460099912, 'dropout_rate_Layer_4': 0.14510650708269127, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 6.523975876232224e-05, 'l1_Layer_2': 1.4353301840420676e-05, 'l1_Layer_3': 0.0043251080592965055, 'l1_Layer_4': 0.0009494705034496477, 'n_units_Layer_1': 50, 'n_units_Layer_2': 155, 'n_units_Layer_3': 285, 'n_units_Layer_4': 105}. Best is trial 390 with value: 3.903698763101461.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.30 | sMAPE for Validation Set is: 12.34% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 6.01 | sMAPE for Test Set is: 21.67% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:35:18,986]\u001b[0m Trial 582 finished with value: 4.121635578775318 and parameters: {'n_hidden': 4, 'learning_rate': 0.0021265944072127807, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.308183462244168, 'dropout_rate_Layer_2': 0.15347981833694913, 'dropout_rate_Layer_3': 0.3038487027461136, 'dropout_rate_Layer_4': 0.11032845202741462, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.794956574565441e-05, 'l1_Layer_2': 0.00632921624516678, 'l1_Layer_3': 1.735675455148537e-05, 'l1_Layer_4': 4.5970691979251225e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 290, 'n_units_Layer_3': 125, 'n_units_Layer_4': 230}. Best is trial 390 with value: 3.903698763101461.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.12 | sMAPE for Validation Set is: 11.95% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.49 | sMAPE for Test Set is: 23.37% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:35:21,709]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:35:23,804]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:35:24,318]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:35:28,390]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:35:32,358]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:35:35,130]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:35:38,790]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:35:43,324]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:35:47,081]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:35:50,551]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:35:54,081]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:36:04,692]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:36:08,725]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:36:13,002]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:36:13,016]\u001b[0m Trial 597 finished with value: 4.155560046210191 and parameters: {'n_hidden': 3, 'learning_rate': 0.002074431399623048, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29726418059893633, 'dropout_rate_Layer_2': 0.128684862810162, 'dropout_rate_Layer_3': 0.17589377069986606, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00026164205135125775, 'l1_Layer_2': 0.00031141082457403414, 'l1_Layer_3': 0.00019052570099876843, 'n_units_Layer_1': 70, 'n_units_Layer_2': 260, 'n_units_Layer_3': 165}. Best is trial 390 with value: 3.903698763101461.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.16 | sMAPE for Validation Set is: 12.11% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.60 | sMAPE for Test Set is: 23.72% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:36:18,168]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:36:24,296]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:36:30,370]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:36:41,606]\u001b[0m Trial 601 finished with value: 4.156728313106842 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016378215986873235, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3125628272226968, 'dropout_rate_Layer_2': 0.12235688531451201, 'dropout_rate_Layer_3': 0.1825452887752128, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003130613621140472, 'l1_Layer_2': 0.00046151690757474564, 'l1_Layer_3': 0.00029545711488990087, 'n_units_Layer_1': 85, 'n_units_Layer_2': 265, 'n_units_Layer_3': 165}. Best is trial 390 with value: 3.903698763101461.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.16 | sMAPE for Validation Set is: 12.05% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.44 | sMAPE for Test Set is: 23.34% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:36:45,740]\u001b[0m Trial 566 finished with value: 3.9797513992648774 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008899311252136083, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32275207833325625, 'dropout_rate_Layer_2': 0.20890563935516787, 'dropout_rate_Layer_3': 0.38566597005746156, 'dropout_rate_Layer_4': 0.09454880248881353, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.9790149581536124e-05, 'l1_Layer_2': 1.420320299314605e-05, 'l1_Layer_3': 0.004800075701285618, 'l1_Layer_4': 0.0009556896373449126, 'n_units_Layer_1': 300, 'n_units_Layer_2': 160, 'n_units_Layer_3': 280, 'n_units_Layer_4': 110}. Best is trial 390 with value: 3.903698763101461.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.98 | sMAPE for Validation Set is: 11.50% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.12 | sMAPE for Test Set is: 18.87% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:37:04,502]\u001b[0m Trial 604 finished with value: 4.140604228627082 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025827825605297242, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3106511331227476, 'dropout_rate_Layer_2': 0.11954220456520574, 'dropout_rate_Layer_3': 0.17739317229255344, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00029386007784665193, 'l1_Layer_2': 0.0005843141338626745, 'l1_Layer_3': 0.000126510935871155, 'n_units_Layer_1': 75, 'n_units_Layer_2': 255, 'n_units_Layer_3': 185}. Best is trial 390 with value: 3.903698763101461.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.14 | sMAPE for Validation Set is: 11.96% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.62 | sMAPE for Test Set is: 23.84% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:37:10,473]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:37:14,122]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:37:20,796]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:37:25,460]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:38:04,555]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:38:07,459]\u001b[0m Trial 590 finished with value: 3.866048016994359 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005514937932580078, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3014089091372847, 'dropout_rate_Layer_2': 0.16842440672423611, 'dropout_rate_Layer_3': 0.36911890782698725, 'dropout_rate_Layer_4': 0.10419472789497333, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0004646643406200617, 'l1_Layer_2': 2.7795973222586092e-05, 'l1_Layer_3': 0.0012106347960991926, 'l1_Layer_4': 1.0612112151642908e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 205, 'n_units_Layer_3': 255, 'n_units_Layer_4': 290}. Best is trial 590 with value: 3.866048016994359.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.87 | sMAPE for Validation Set is: 11.18% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.99 | sMAPE for Test Set is: 18.41% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:38:08,496]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:38:13,110]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:38:15,964]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:38:18,689]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:38:22,181]\u001b[0m Trial 605 finished with value: 3.967064234795295 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005341298096413117, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35768159383955755, 'dropout_rate_Layer_2': 0.17446169020175167, 'dropout_rate_Layer_3': 0.2875999038643889, 'dropout_rate_Layer_4': 0.0999005446961349, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.301896596299039e-05, 'l1_Layer_2': 2.900553593075915e-05, 'l1_Layer_3': 0.001154895134746652, 'l1_Layer_4': 0.0017834490659927261, 'n_units_Layer_1': 290, 'n_units_Layer_2': 210, 'n_units_Layer_3': 280, 'n_units_Layer_4': 140}. Best is trial 590 with value: 3.866048016994359.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.97 | sMAPE for Validation Set is: 11.46% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.90 | sMAPE for Test Set is: 18.18% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:38:23,261]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:38:25,606]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:38:29,823]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:38:32,197]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:38:33,912]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:38:37,299]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:38:40,518]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:38:46,536]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:38:50,707]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:38:53,448]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:38:56,099]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:38:59,006]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:39:01,564]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:39:05,450]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:39:11,717]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:39:15,080]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:39:15,854]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:39:23,692]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:39:27,687]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:39:31,609]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:39:36,096]\u001b[0m Trial 619 finished with value: 4.105120747369094 and parameters: {'n_hidden': 3, 'learning_rate': 0.00198420531250305, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2852879739625329, 'dropout_rate_Layer_2': 0.37042338483430937, 'dropout_rate_Layer_3': 0.18466759082323905, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005416321664860727, 'l1_Layer_2': 0.0003940863591459555, 'l1_Layer_3': 0.0010576449916400424, 'n_units_Layer_1': 65, 'n_units_Layer_2': 255, 'n_units_Layer_3': 185}. Best is trial 590 with value: 3.866048016994359.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.11 | sMAPE for Validation Set is: 12.03% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.88 | sMAPE for Test Set is: 21.57% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:39:38,144]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:39:41,629]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:39:42,695]\u001b[0m Trial 636 finished with value: 4.062820832245397 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021251624186906775, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3363637400937865, 'dropout_rate_Layer_2': 0.17125068131722848, 'dropout_rate_Layer_3': 0.22128174659419003, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002242764618359184, 'l1_Layer_2': 0.0002068110173006276, 'l1_Layer_3': 0.0003545098761524325, 'n_units_Layer_1': 75, 'n_units_Layer_2': 275, 'n_units_Layer_3': 195}. Best is trial 590 with value: 3.866048016994359.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.06 | sMAPE for Validation Set is: 11.68% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.64 | sMAPE for Test Set is: 23.84% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:39:47,941]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:39:50,922]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:39:58,362]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:40:05,542]\u001b[0m Trial 631 finished with value: 4.201877985950732 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011182945910956298, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2518264508356759, 'dropout_rate_Layer_2': 0.1654180353120528, 'dropout_rate_Layer_3': 0.24888992437823504, 'dropout_rate_Layer_4': 0.2959143165142774, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00020659686881806315, 'l1_Layer_2': 5.404118094332276e-05, 'l1_Layer_3': 0.0007917514323724637, 'l1_Layer_4': 2.572862595580033e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 200, 'n_units_Layer_3': 120, 'n_units_Layer_4': 230}. Best is trial 590 with value: 3.866048016994359.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.20 | sMAPE for Validation Set is: 12.11% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 6.44 | sMAPE for Test Set is: 22.75% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:40:08,134]\u001b[0m Trial 640 finished with value: 4.167729302979937 and parameters: {'n_hidden': 4, 'learning_rate': 0.002732160006691642, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.279725145129919, 'dropout_rate_Layer_2': 0.17019266023496932, 'dropout_rate_Layer_3': 0.3901115658415555, 'dropout_rate_Layer_4': 0.10568170121896117, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.353089276337721e-05, 'l1_Layer_2': 0.009251448864989593, 'l1_Layer_3': 2.3430027771225936e-05, 'l1_Layer_4': 6.551904188162011e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 280, 'n_units_Layer_3': 140, 'n_units_Layer_4': 225}. Best is trial 590 with value: 3.866048016994359.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.17 | sMAPE for Validation Set is: 11.99% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 6.81 | sMAPE for Test Set is: 24.29% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:40:12,334]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:40:15,819]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:40:21,886]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:40:23,869]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:40:27,752]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:40:31,728]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:40:31,747]\u001b[0m Trial 645 finished with value: 4.14622249283604 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021687409220400152, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31275320110150495, 'dropout_rate_Layer_2': 0.11979487693405208, 'dropout_rate_Layer_3': 0.24327545426784472, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005703377442389235, 'l1_Layer_2': 0.00022569321177371088, 'l1_Layer_3': 0.00040946453685407677, 'n_units_Layer_1': 75, 'n_units_Layer_2': 260, 'n_units_Layer_3': 190}. Best is trial 590 with value: 3.866048016994359.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.15 | sMAPE for Validation Set is: 12.01% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.71 | sMAPE for Test Set is: 24.10% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:40:35,519]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:40:39,902]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:40:41,889]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:40:44,900]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:40:45,021]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:40:49,577]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:40:49,843]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:40:56,092]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:40:56,281]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:41:02,909]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:41:06,062]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:41:13,881]\u001b[0m Trial 657 finished with value: 4.1297760470441816 and parameters: {'n_hidden': 3, 'learning_rate': 0.002786963425844188, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3228839246775451, 'dropout_rate_Layer_2': 0.17287129619776703, 'dropout_rate_Layer_3': 0.21520985100691542, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006637968204142225, 'l1_Layer_2': 0.00019894640072794004, 'l1_Layer_3': 0.0003971436073817578, 'n_units_Layer_1': 85, 'n_units_Layer_2': 250, 'n_units_Layer_3': 160}. Best is trial 590 with value: 3.866048016994359.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.13 | sMAPE for Validation Set is: 11.99% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.89 | sMAPE for Test Set is: 24.59% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:41:19,356]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:41:25,355]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:41:29,057]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:41:55,667]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:42:02,479]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:42:17,918]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:42:25,617]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:42:46,745]\u001b[0m Trial 673 finished with value: 4.150545589586432 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016410368493504723, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31246109270977857, 'dropout_rate_Layer_2': 0.1770662138659023, 'dropout_rate_Layer_3': 0.27151077061826173, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008750731757588602, 'l1_Layer_2': 0.00018648261008071557, 'l1_Layer_3': 0.0003636111789845597, 'n_units_Layer_1': 85, 'n_units_Layer_2': 250, 'n_units_Layer_3': 205}. Best is trial 590 with value: 3.866048016994359.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.15 | sMAPE for Validation Set is: 12.08% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.63 | sMAPE for Test Set is: 23.70% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:42:50,664]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:42:54,339]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:42:58,955]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:43:03,468]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:43:07,152]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:43:10,079]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:43:15,334]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:43:18,951]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:43:22,831]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:43:29,010]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:43:34,352]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:44:02,678]\u001b[0m Trial 685 finished with value: 4.005383881599099 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007347831934863128, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23385326830002184, 'dropout_rate_Layer_2': 0.22786259384177793, 'dropout_rate_Layer_3': 0.32848892627586085, 'dropout_rate_Layer_4': 0.19446729261573667, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 7.051646427570387e-05, 'l1_Layer_2': 0.001229571668966471, 'l1_Layer_3': 0.0014412045270386195, 'l1_Layer_4': 0.00011587717576908715, 'n_units_Layer_1': 270, 'n_units_Layer_2': 280, 'n_units_Layer_3': 160, 'n_units_Layer_4': 210}. Best is trial 590 with value: 3.866048016994359.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.01 | sMAPE for Validation Set is: 11.56% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.95 | sMAPE for Test Set is: 21.87% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:44:18,144]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:44:29,449]\u001b[0m Trial 662 finished with value: 3.9491391408465653 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005837501567656598, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29821638919953575, 'dropout_rate_Layer_2': 0.20038902992921342, 'dropout_rate_Layer_3': 0.3716706647402768, 'dropout_rate_Layer_4': 0.02229076781564185, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00011791134984818317, 'l1_Layer_2': 1.318413275733619e-05, 'l1_Layer_3': 0.0007888095658067579, 'l1_Layer_4': 3.931984717371526e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 215, 'n_units_Layer_3': 275, 'n_units_Layer_4': 65}. Best is trial 590 with value: 3.866048016994359.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.95 | sMAPE for Validation Set is: 11.40% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.30 | sMAPE for Test Set is: 19.55% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:44:29,690]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:44:34,615]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:44:38,628]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:44:43,003]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:44:57,778]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:45:01,612]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:45:02,417]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:45:06,194]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:45:10,115]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:45:15,323]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:45:16,230]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:45:19,772]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:45:23,625]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:45:24,659]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:45:30,749]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:45:30,861]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:45:31,228]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:45:31,463]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:45:38,742]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:45:42,636]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:45:43,402]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:45:45,388]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:45:48,476]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:45:52,746]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:45:53,376]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:45:53,785]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:45:54,480]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:46:00,740]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:46:02,403]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:46:03,298]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:46:04,049]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:46:11,441]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:46:11,836]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:46:17,980]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:46:24,254]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:46:28,598]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.02 | sMAPE for Validation Set is: 11.65% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.39 | sMAPE for Test Set is: 20.08% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:46:30,519]\u001b[0m Trial 716 finished with value: 4.018521976799494 and parameters: {'n_hidden': 4, 'learning_rate': 0.003613573791077762, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06332799502839341, 'dropout_rate_Layer_2': 0.3321401471667677, 'dropout_rate_Layer_3': 0.2274872297998351, 'dropout_rate_Layer_4': 0.11426921168752109, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.009209295900627811, 'l1_Layer_2': 0.0017479466448526149, 'l1_Layer_3': 5.0565392242479824e-05, 'l1_Layer_4': 8.925685598731865e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 170, 'n_units_Layer_3': 95, 'n_units_Layer_4': 165}. Best is trial 590 with value: 3.866048016994359.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:46:33,218]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:46:33,625]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:46:37,800]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:46:38,640]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:46:43,837]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:46:46,360]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:46:47,135]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:47:00,688]\u001b[0m Trial 727 finished with value: 4.173079837078933 and parameters: {'n_hidden': 4, 'learning_rate': 0.003364447621428116, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06993753505755498, 'dropout_rate_Layer_2': 0.31337702035367904, 'dropout_rate_Layer_3': 0.20550621786147136, 'dropout_rate_Layer_4': 0.11433802142153673, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.007799825431168423, 'l1_Layer_2': 0.0015105077752683414, 'l1_Layer_3': 3.28962937541205e-05, 'l1_Layer_4': 9.463496038109109e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 170, 'n_units_Layer_3': 90, 'n_units_Layer_4': 155}. Best is trial 590 with value: 3.866048016994359.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.17 | sMAPE for Validation Set is: 12.20% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 5.45 | sMAPE for Test Set is: 19.96% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:47:05,586]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:47:06,226]\u001b[0m Trial 732 finished with value: 4.039043847844143 and parameters: {'n_hidden': 3, 'learning_rate': 0.001732155407198916, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3210481784952998, 'dropout_rate_Layer_2': 0.17306628240495764, 'dropout_rate_Layer_3': 0.176524294711187, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00046705160417929027, 'l1_Layer_2': 0.0003604482805124673, 'l1_Layer_3': 0.0002084627828325534, 'n_units_Layer_1': 90, 'n_units_Layer_2': 270, 'n_units_Layer_3': 185}. Best is trial 590 with value: 3.866048016994359.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.04 | sMAPE for Validation Set is: 11.66% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.71 | sMAPE for Test Set is: 24.01% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:47:09,308]\u001b[0m Trial 731 finished with value: 4.118310024964743 and parameters: {'n_hidden': 4, 'learning_rate': 0.0032917634563025848, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.057825546523019224, 'dropout_rate_Layer_2': 0.3088233157556327, 'dropout_rate_Layer_3': 0.16337597552823838, 'dropout_rate_Layer_4': 0.13081054512733326, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.013609606812297174, 'l1_Layer_2': 0.0015648029376080642, 'l1_Layer_3': 2.4947308038517037e-05, 'l1_Layer_4': 2.321155274704176e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 290, 'n_units_Layer_3': 90, 'n_units_Layer_4': 200}. Best is trial 590 with value: 3.866048016994359.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.12 | sMAPE for Validation Set is: 11.87% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.48 | sMAPE for Test Set is: 20.31% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:47:12,758]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:47:15,819]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:47:18,572]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:47:20,854]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:47:23,227]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:47:24,041]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:47:25,501]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:47:30,634]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:47:33,431]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:47:35,646]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:47:38,311]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:47:40,809]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:47:44,291]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:47:48,767]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:47:52,846]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.09 | sMAPE for Validation Set is: 11.85% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.06 | sMAPE for Test Set is: 22.23% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:47:55,257]\u001b[0m Trial 742 finished with value: 4.094471568936964 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016016863417531333, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33678831713117174, 'dropout_rate_Layer_2': 0.1830819524359221, 'dropout_rate_Layer_3': 0.17094410902000667, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004812085611134036, 'l1_Layer_2': 0.0003046650327918972, 'l1_Layer_3': 0.0005055193825889814, 'n_units_Layer_1': 90, 'n_units_Layer_2': 280, 'n_units_Layer_3': 210}. Best is trial 590 with value: 3.866048016994359.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:47:58,377]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:47:59,765]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:48:04,157]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:48:05,196]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:48:09,931]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:48:11,798]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:48:16,461]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:48:19,806]\u001b[0m Trial 747 finished with value: 4.0859811969265145 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015588745800735899, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2855471194094733, 'dropout_rate_Layer_2': 0.18697228677988062, 'dropout_rate_Layer_3': 0.1715920546401516, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005079892456007775, 'l1_Layer_2': 0.0003051544538392501, 'l1_Layer_3': 0.00048820378323127675, 'n_units_Layer_1': 90, 'n_units_Layer_2': 280, 'n_units_Layer_3': 180}. Best is trial 590 with value: 3.866048016994359.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.09 | sMAPE for Validation Set is: 11.84% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.43 | sMAPE for Test Set is: 23.28% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:48:20,149]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:48:24,708]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:48:27,073]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:48:30,332]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:48:34,557]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:48:40,741]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:48:44,953]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:48:49,298]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:48:54,779]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:48:58,592]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:49:07,755]\u001b[0m Trial 766 finished with value: 4.1050645190244275 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017958367992878062, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2931908176531136, 'dropout_rate_Layer_2': 0.19900483767429097, 'dropout_rate_Layer_3': 0.19515042406855942, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00042232830287525377, 'l1_Layer_2': 0.00026878835309937244, 'l1_Layer_3': 0.0005221272014214553, 'n_units_Layer_1': 80, 'n_units_Layer_2': 270, 'n_units_Layer_3': 190}. Best is trial 590 with value: 3.866048016994359.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.11 | sMAPE for Validation Set is: 11.92% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.14 | sMAPE for Test Set is: 22.36% | rMAE for Test Set is: 1.01\n",
      "MAE for Validation Set is: 4.07 | sMAPE for Validation Set is: 11.87% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.19 | sMAPE for Test Set is: 22.71% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:49:09,797]\u001b[0m Trial 765 finished with value: 4.073442728541639 and parameters: {'n_hidden': 3, 'learning_rate': 0.001199298435956927, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29318495633791786, 'dropout_rate_Layer_2': 0.18340157191856074, 'dropout_rate_Layer_3': 0.2738444711119843, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000640932940413924, 'l1_Layer_2': 0.0002527825922572848, 'l1_Layer_3': 0.0005284353713384199, 'n_units_Layer_1': 80, 'n_units_Layer_2': 300, 'n_units_Layer_3': 190}. Best is trial 590 with value: 3.866048016994359.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:49:13,143]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:49:13,231]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:49:15,012]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:49:21,615]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:49:23,740]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:49:26,725]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:49:28,269]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:49:35,286]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:49:56,158]\u001b[0m Trial 757 finished with value: 4.12139627204927 and parameters: {'n_hidden': 4, 'learning_rate': 0.000536120910860181, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37616491660420276, 'dropout_rate_Layer_2': 0.15976390396340528, 'dropout_rate_Layer_3': 0.3345814173402049, 'dropout_rate_Layer_4': 0.3985462052274983, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 9.321018678239827e-05, 'l1_Layer_2': 0.00014164869716014406, 'l1_Layer_3': 0.00042438325476073325, 'l1_Layer_4': 0.00013254332195686852, 'n_units_Layer_1': 240, 'n_units_Layer_2': 225, 'n_units_Layer_3': 105, 'n_units_Layer_4': 195}. Best is trial 590 with value: 3.866048016994359.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.12 | sMAPE for Validation Set is: 11.91% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.19 | sMAPE for Test Set is: 22.48% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:50:07,865]\u001b[0m Trial 778 finished with value: 4.0649207124585764 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019909848648445297, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3004726693186348, 'dropout_rate_Layer_2': 0.19988306963252436, 'dropout_rate_Layer_3': 0.2894114288974323, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005457137458907574, 'l1_Layer_2': 0.0002835447788068563, 'l1_Layer_3': 0.0005367481362829913, 'n_units_Layer_1': 65, 'n_units_Layer_2': 280, 'n_units_Layer_3': 205}. Best is trial 590 with value: 3.866048016994359.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.06 | sMAPE for Validation Set is: 11.77% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.38 | sMAPE for Test Set is: 23.21% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:50:11,282]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:50:15,181]\u001b[0m Trial 781 finished with value: 4.064930887937101 and parameters: {'n_hidden': 4, 'learning_rate': 0.0024881782384174496, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.046953488128550616, 'dropout_rate_Layer_2': 0.046901766973796756, 'dropout_rate_Layer_3': 0.21753797661999563, 'dropout_rate_Layer_4': 0.09032835114334889, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0021339269996553498, 'l1_Layer_2': 1.4900081031820349e-05, 'l1_Layer_3': 4.734637337669848e-05, 'l1_Layer_4': 3.2421459920403384e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 180, 'n_units_Layer_3': 270, 'n_units_Layer_4': 175}. Best is trial 590 with value: 3.866048016994359.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.06 | sMAPE for Validation Set is: 11.68% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.87 | sMAPE for Test Set is: 21.27% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:50:17,853]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:50:20,320]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:50:24,501]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:50:26,319]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:50:29,502]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:50:31,964]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:50:35,068]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:50:39,482]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:50:43,736]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:50:50,879]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:50:54,624]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:51:00,511]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:51:02,076]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:51:05,888]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:51:06,825]\u001b[0m Trial 774 finished with value: 4.028622294844195 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005021809331610206, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37560481006974256, 'dropout_rate_Layer_2': 0.16153087030300975, 'dropout_rate_Layer_3': 0.3285621272907261, 'dropout_rate_Layer_4': 0.06585248948400099, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 8.791307727019928e-05, 'l1_Layer_2': 0.00021135571037726337, 'l1_Layer_3': 0.00036494168059756385, 'l1_Layer_4': 3.367029887451937e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 225, 'n_units_Layer_3': 240, 'n_units_Layer_4': 190}. Best is trial 590 with value: 3.866048016994359.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.03 | sMAPE for Validation Set is: 11.66% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.40 | sMAPE for Test Set is: 22.85% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:51:12,056]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:51:12,897]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:51:19,456]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:51:23,570]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:51:29,639]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:51:36,592]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:51:39,916]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:51:40,326]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:51:46,482]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:51:47,097]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:51:53,956]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:51:54,698]\u001b[0m Trial 798 finished with value: 4.078059031066504 and parameters: {'n_hidden': 4, 'learning_rate': 0.001063346963328634, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29202403638208957, 'dropout_rate_Layer_2': 0.17587352979295, 'dropout_rate_Layer_3': 0.36473214287895384, 'dropout_rate_Layer_4': 0.1459336588496595, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 6.134153601893062e-05, 'l1_Layer_2': 0.0034182137733583724, 'l1_Layer_3': 2.0338966398855902e-05, 'l1_Layer_4': 7.759100374342797e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 275, 'n_units_Layer_3': 165, 'n_units_Layer_4': 190}. Best is trial 590 with value: 3.866048016994359.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.08 | sMAPE for Validation Set is: 11.75% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.49 | sMAPE for Test Set is: 23.37% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:51:54,970]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:52:01,853]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:52:03,620]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:52:08,608]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:52:15,841]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:52:22,097]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:52:29,290]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:52:33,497]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:52:34,265]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:52:39,298]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:52:47,279]\u001b[0m Trial 811 finished with value: 4.031967939344864 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006998359929236718, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30407377520292256, 'dropout_rate_Layer_2': 0.17758970712479305, 'dropout_rate_Layer_3': 0.39966823799964146, 'dropout_rate_Layer_4': 0.17353204831061542, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.0409678654575006e-05, 'l1_Layer_2': 0.00412471015580704, 'l1_Layer_3': 2.737446289493758e-05, 'l1_Layer_4': 6.796256623044965e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 275, 'n_units_Layer_3': 175, 'n_units_Layer_4': 205}. Best is trial 590 with value: 3.866048016994359.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.03 | sMAPE for Validation Set is: 11.71% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.28 | sMAPE for Test Set is: 22.91% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:52:52,679]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:52:52,916]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:52:59,664]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:53:02,161]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:53:04,635]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:53:08,855]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:53:12,386]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:53:19,271]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:53:23,538]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:53:25,395]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:53:29,292]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:53:31,939]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:53:35,249]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:53:37,141]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:53:42,578]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:53:42,832]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:53:56,672]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:54:02,335]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:54:04,733]\u001b[0m Trial 838 finished with value: 4.126796087934539 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025126582060333398, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3442537272268149, 'dropout_rate_Layer_2': 0.1551375308031436, 'dropout_rate_Layer_3': 0.20236856805980735, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013494222474046022, 'l1_Layer_2': 0.0002496939617601086, 'l1_Layer_3': 0.000247198685307774, 'n_units_Layer_1': 80, 'n_units_Layer_2': 265, 'n_units_Layer_3': 210}. Best is trial 590 with value: 3.866048016994359.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.13 | sMAPE for Validation Set is: 11.92% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.51 | sMAPE for Test Set is: 23.47% | rMAE for Test Set is: 1.07\n",
      "MAE for Validation Set is: 3.99 | sMAPE for Validation Set is: 11.60% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.13 | sMAPE for Test Set is: 22.19% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:54:06,576]\u001b[0m Trial 780 finished with value: 3.993200690142491 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005155963908009752, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37533655851971925, 'dropout_rate_Layer_2': 0.1653273628940169, 'dropout_rate_Layer_3': 0.3330536719102257, 'dropout_rate_Layer_4': 0.352964219236083, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 9.361644545572278e-05, 'l1_Layer_2': 0.000228569665568685, 'l1_Layer_3': 0.002562939276169414, 'l1_Layer_4': 4.1175576882955195e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 225, 'n_units_Layer_3': 155, 'n_units_Layer_4': 275}. Best is trial 590 with value: 3.866048016994359.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:54:12,690]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:54:18,176]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:54:22,388]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:54:43,198]\u001b[0m Trial 845 finished with value: 4.094806350569485 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021142443061143083, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34242439493630794, 'dropout_rate_Layer_2': 0.15742633555626984, 'dropout_rate_Layer_3': 0.20702376164610806, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00016079791840321677, 'l1_Layer_2': 0.00020323309275677281, 'l1_Layer_3': 0.00018812274222375488, 'n_units_Layer_1': 80, 'n_units_Layer_2': 270, 'n_units_Layer_3': 190}. Best is trial 590 with value: 3.866048016994359.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.09 | sMAPE for Validation Set is: 11.78% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.60 | sMAPE for Test Set is: 23.66% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:54:56,030]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:55:08,879]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:55:16,981]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:55:20,893]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:55:25,586]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:55:45,370]\u001b[0m Trial 851 finished with value: 4.152147753047765 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030534416547425827, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3622084860324339, 'dropout_rate_Layer_2': 0.1531645774525147, 'dropout_rate_Layer_3': 0.21954177535048858, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013834218642570296, 'l1_Layer_2': 0.00012516007822765604, 'l1_Layer_3': 0.00012166670509673309, 'n_units_Layer_1': 80, 'n_units_Layer_2': 270, 'n_units_Layer_3': 195}. Best is trial 590 with value: 3.866048016994359.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.15 | sMAPE for Validation Set is: 12.08% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.47 | sMAPE for Test Set is: 23.37% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:56:01,311]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:56:04,057]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:56:05,897]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:56:08,913]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:56:11,461]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:56:14,129]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:56:17,193]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:56:21,973]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:56:25,199]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:56:29,073]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:56:33,607]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:56:44,130]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.00 | sMAPE for Validation Set is: 11.62% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.32 | sMAPE for Test Set is: 19.57% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:56:45,957]\u001b[0m Trial 821 finished with value: 4.001211109893948 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008382455308184457, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31264112801728516, 'dropout_rate_Layer_2': 0.18896600803288005, 'dropout_rate_Layer_3': 0.3992353223954294, 'dropout_rate_Layer_4': 0.08828409370025717, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.8173310822491247e-05, 'l1_Layer_2': 2.1407760847830218e-05, 'l1_Layer_3': 0.0023956863628929004, 'l1_Layer_4': 0.0013311204253263196, 'n_units_Layer_1': 290, 'n_units_Layer_2': 195, 'n_units_Layer_3': 295, 'n_units_Layer_4': 120}. Best is trial 590 with value: 3.866048016994359.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:56:48,629]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:56:54,437]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:57:01,040]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:57:04,759]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:57:05,675]\u001b[0m Trial 860 finished with value: 4.118562405144924 and parameters: {'n_hidden': 4, 'learning_rate': 0.00104031919146676, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31088032844698876, 'dropout_rate_Layer_2': 0.10327829936805155, 'dropout_rate_Layer_3': 0.350016974033442, 'dropout_rate_Layer_4': 0.09521513441123146, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.7523193841368126e-05, 'l1_Layer_2': 0.007910135728187237, 'l1_Layer_3': 2.311748043362846e-05, 'l1_Layer_4': 0.00019942942089343655, 'n_units_Layer_1': 255, 'n_units_Layer_2': 280, 'n_units_Layer_3': 215, 'n_units_Layer_4': 160}. Best is trial 590 with value: 3.866048016994359.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.12 | sMAPE for Validation Set is: 11.85% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.26 | sMAPE for Test Set is: 22.82% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:57:07,718]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:57:10,185]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:57:19,346]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:57:22,752]\u001b[0m Trial 842 finished with value: 4.146912884206079 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007948592329284567, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30253597143274097, 'dropout_rate_Layer_2': 0.20288096490060983, 'dropout_rate_Layer_3': 0.3726017763482336, 'dropout_rate_Layer_4': 0.2118232494747901, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 6.077805816418014e-05, 'l1_Layer_2': 1.9189000523223167e-05, 'l1_Layer_3': 0.0006925254149431245, 'l1_Layer_4': 0.001649712882963886, 'n_units_Layer_1': 300, 'n_units_Layer_2': 190, 'n_units_Layer_3': 265, 'n_units_Layer_4': 120}. Best is trial 590 with value: 3.866048016994359.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.15 | sMAPE for Validation Set is: 11.91% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.09 | sMAPE for Test Set is: 19.57% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:57:24,608]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:57:28,580]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:57:29,565]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:57:33,343]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:57:35,399]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:57:40,090]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:57:43,035]\u001b[0m Trial 871 finished with value: 4.121218995581793 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011379546654385285, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31140544440562506, 'dropout_rate_Layer_2': 0.10164108936612193, 'dropout_rate_Layer_3': 0.34840132699053883, 'dropout_rate_Layer_4': 0.09703220461154713, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.566824376446885e-05, 'l1_Layer_2': 0.008630894503711418, 'l1_Layer_3': 2.6566617821680774e-05, 'l1_Layer_4': 0.00020147014584706414, 'n_units_Layer_1': 250, 'n_units_Layer_2': 285, 'n_units_Layer_3': 210, 'n_units_Layer_4': 140}. Best is trial 590 with value: 3.866048016994359.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.12 | sMAPE for Validation Set is: 11.88% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.40 | sMAPE for Test Set is: 23.26% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:57:45,110]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:57:46,386]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:57:51,176]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:57:51,370]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:57:56,854]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:57:59,158]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:58:01,872]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:58:05,101]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:58:09,082]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:58:09,222]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:58:15,130]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:58:16,585]\u001b[0m Trial 878 finished with value: 4.145633661129843 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009980417817618554, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2965237010851679, 'dropout_rate_Layer_2': 0.04798216373332312, 'dropout_rate_Layer_3': 0.3482840242025148, 'dropout_rate_Layer_4': 0.09349604912831125, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.9957537930910114e-05, 'l1_Layer_2': 0.008618250251780967, 'l1_Layer_3': 2.6933306530204385e-05, 'l1_Layer_4': 0.00021832418590257897, 'n_units_Layer_1': 255, 'n_units_Layer_2': 280, 'n_units_Layer_3': 225, 'n_units_Layer_4': 140}. Best is trial 590 with value: 3.866048016994359.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.15 | sMAPE for Validation Set is: 12.00% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 7.13 | sMAPE for Test Set is: 25.25% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:58:19,676]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:58:21,722]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:58:25,901]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:58:29,962]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:58:30,056]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:58:30,316]\u001b[0m Trial 891 finished with value: 4.087261007280545 and parameters: {'n_hidden': 3, 'learning_rate': 0.003062922512668522, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39124693658749227, 'dropout_rate_Layer_2': 0.1833568896047257, 'dropout_rate_Layer_3': 0.2767041089905546, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006020210333716702, 'l1_Layer_2': 0.0003526413060765441, 'l1_Layer_3': 0.00024358918674256035, 'n_units_Layer_1': 75, 'n_units_Layer_2': 280, 'n_units_Layer_3': 190}. Best is trial 590 with value: 3.866048016994359.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.09 | sMAPE for Validation Set is: 11.81% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.79 | sMAPE for Test Set is: 24.28% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:58:37,770]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:58:42,695]\u001b[0m Trial 890 finished with value: 4.054896193922565 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028307303419050182, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32588177784013717, 'dropout_rate_Layer_2': 0.16420713955714136, 'dropout_rate_Layer_3': 0.22286137077206514, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006584207424331892, 'l1_Layer_2': 0.00034654598065430805, 'l1_Layer_3': 0.00013004365512564895, 'n_units_Layer_1': 75, 'n_units_Layer_2': 280, 'n_units_Layer_3': 190}. Best is trial 590 with value: 3.866048016994359.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.05 | sMAPE for Validation Set is: 11.81% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.35 | sMAPE for Test Set is: 23.07% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:58:43,123]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:58:47,203]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:58:50,077]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:58:50,588]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:58:56,026]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:58:56,438]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:58:56,525]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:59:04,337]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:59:06,320]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:59:08,312]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:59:09,544]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:59:10,538]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:59:10,955]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:59:16,972]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:59:21,323]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:59:23,277]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:59:26,177]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:59:26,521]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:59:27,413]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:59:35,078]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:59:35,644]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:59:35,911]\u001b[0m Trial 913 finished with value: 4.08630319845743 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026456654113876203, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3055296901608891, 'dropout_rate_Layer_2': 0.17750552246748874, 'dropout_rate_Layer_3': 0.2683269777506335, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006131345546894871, 'l1_Layer_2': 0.00036281573316203326, 'l1_Layer_3': 0.00023055312806229957, 'n_units_Layer_1': 85, 'n_units_Layer_2': 275, 'n_units_Layer_3': 200}. Best is trial 590 with value: 3.866048016994359.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.09 | sMAPE for Validation Set is: 11.81% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.30 | sMAPE for Test Set is: 22.86% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:59:42,084]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:59:42,199]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:59:43,136]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:59:49,739]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:59:52,142]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:59:52,859]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 00:59:55,403]\u001b[0m Trial 923 finished with value: 4.11585214215284 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034631286167826287, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32694458216758016, 'dropout_rate_Layer_2': 0.16926736366577394, 'dropout_rate_Layer_3': 0.27039959881555575, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000565214649316049, 'l1_Layer_2': 0.00029209643384524477, 'l1_Layer_3': 0.00023649911368621004, 'n_units_Layer_1': 85, 'n_units_Layer_2': 275, 'n_units_Layer_3': 200}. Best is trial 590 with value: 3.866048016994359.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.12 | sMAPE for Validation Set is: 11.82% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 7.00 | sMAPE for Test Set is: 24.82% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 00:59:59,419]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:00:00,341]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:00:09,276]\u001b[0m Trial 926 finished with value: 4.034505402131675 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027675203204775988, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32741820413679973, 'dropout_rate_Layer_2': 0.16986713823261343, 'dropout_rate_Layer_3': 0.2701166147588489, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005621096636404978, 'l1_Layer_2': 0.0003192906587217864, 'l1_Layer_3': 0.00022620749016269756, 'n_units_Layer_1': 85, 'n_units_Layer_2': 275, 'n_units_Layer_3': 200}. Best is trial 590 with value: 3.866048016994359.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.03 | sMAPE for Validation Set is: 11.74% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.18 | sMAPE for Test Set is: 22.58% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:00:13,882]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:00:27,155]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:00:27,273]\u001b[0m Trial 931 finished with value: 4.081538263645918 and parameters: {'n_hidden': 4, 'learning_rate': 0.003228606571028607, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05113453706513599, 'dropout_rate_Layer_2': 0.3193257102817121, 'dropout_rate_Layer_3': 0.3778810569587493, 'dropout_rate_Layer_4': 0.10517100829804116, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.001791891152132061, 'l1_Layer_2': 0.001864741376348869, 'l1_Layer_3': 1.1555877792610402e-05, 'l1_Layer_4': 0.0001400818661177473, 'n_units_Layer_1': 290, 'n_units_Layer_2': 300, 'n_units_Layer_3': 175, 'n_units_Layer_4': 215}. Best is trial 590 with value: 3.866048016994359.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.08 | sMAPE for Validation Set is: 11.75% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.75 | sMAPE for Test Set is: 21.23% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:00:33,050]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:00:34,141]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:00:35,931]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:00:37,368]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:00:45,413]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:00:45,471]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:01:09,670]\u001b[0m Trial 932 finished with value: 3.8286945024593364 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006138691620012986, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34011567097578527, 'dropout_rate_Layer_2': 0.26028193518172055, 'dropout_rate_Layer_3': 0.3465188272270089, 'dropout_rate_Layer_4': 0.10370078349248321, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00013317991885898356, 'l1_Layer_2': 6.944602637571104e-05, 'l1_Layer_3': 0.0013654434107586374, 'l1_Layer_4': 0.00367235562872732, 'n_units_Layer_1': 210, 'n_units_Layer_2': 175, 'n_units_Layer_3': 130, 'n_units_Layer_4': 135}. Best is trial 932 with value: 3.8286945024593364.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.83 | sMAPE for Validation Set is: 11.10% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.18 | sMAPE for Test Set is: 15.87% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:01:13,213]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:01:13,693]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:01:18,013]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:01:18,432]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:01:18,625]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:01:18,773]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:01:29,227]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:01:29,598]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:01:35,762]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:01:39,413]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:01:42,991]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:01:43,884]\u001b[0m Trial 946 finished with value: 4.266149254964051 and parameters: {'n_hidden': 4, 'learning_rate': 0.003214498568303047, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2609527368506242, 'dropout_rate_Layer_2': 0.34747339035598657, 'dropout_rate_Layer_3': 0.37801836671182215, 'dropout_rate_Layer_4': 0.10234873472475882, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002590334563591579, 'l1_Layer_2': 0.0020625902289506033, 'l1_Layer_3': 1.1114115095522972e-05, 'l1_Layer_4': 9.357530932417767e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 295, 'n_units_Layer_3': 105, 'n_units_Layer_4': 225}. Best is trial 932 with value: 3.8286945024593364.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.27 | sMAPE for Validation Set is: 12.21% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 5.81 | sMAPE for Test Set is: 21.22% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:01:49,712]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:01:53,326]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:01:55,456]\u001b[0m Trial 947 finished with value: 3.880458847575125 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005837226815156682, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3369276642588512, 'dropout_rate_Layer_2': 0.26899398563824656, 'dropout_rate_Layer_3': 0.34548583156942425, 'dropout_rate_Layer_4': 0.08226700842760275, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.626166768378223e-05, 'l1_Layer_2': 5.117241994762344e-05, 'l1_Layer_3': 0.001349920429679753, 'l1_Layer_4': 0.0004179302861891768, 'n_units_Layer_1': 210, 'n_units_Layer_2': 185, 'n_units_Layer_3': 115, 'n_units_Layer_4': 160}. Best is trial 932 with value: 3.8286945024593364.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.88 | sMAPE for Validation Set is: 11.23% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.47 | sMAPE for Test Set is: 16.79% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:01:55,734]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:02:03,031]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:02:03,715]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:02:08,882]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:02:12,152]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:02:14,991]\u001b[0m Trial 951 finished with value: 3.815572110319048 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005904076746617192, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3409209981885706, 'dropout_rate_Layer_2': 0.23821664192196373, 'dropout_rate_Layer_3': 0.34751595232033994, 'dropout_rate_Layer_4': 0.08148561190942347, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00037445774773315146, 'l1_Layer_2': 2.3832668733838902e-05, 'l1_Layer_3': 0.0013415447544242415, 'l1_Layer_4': 0.0004306803882957651, 'n_units_Layer_1': 210, 'n_units_Layer_2': 180, 'n_units_Layer_3': 110, 'n_units_Layer_4': 150}. Best is trial 951 with value: 3.815572110319048.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.82 | sMAPE for Validation Set is: 11.04% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.41 | sMAPE for Test Set is: 16.55% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:02:15,846]\u001b[0m Trial 957 finished with value: 4.152148004443952 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028568518076384332, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39099604478998057, 'dropout_rate_Layer_2': 0.2052474925979227, 'dropout_rate_Layer_3': 0.11518267472037018, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004986451369729819, 'l1_Layer_2': 0.0003536880519390618, 'l1_Layer_3': 0.00019073058092260073, 'n_units_Layer_1': 85, 'n_units_Layer_2': 270, 'n_units_Layer_3': 180}. Best is trial 951 with value: 3.815572110319048.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.15 | sMAPE for Validation Set is: 12.04% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.26 | sMAPE for Test Set is: 22.77% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:02:16,902]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:02:16,955]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:02:24,505]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:02:27,147]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:02:27,560]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:02:30,237]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:02:32,473]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:02:33,688]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:02:37,574]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:02:38,146]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:02:42,631]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:02:43,070]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:02:43,407]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:02:46,153]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:02:53,201]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:02:57,926]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:02:58,020]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:03:07,357]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:03:10,755]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:03:10,806]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:03:16,268]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:03:16,905]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:03:16,965]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:03:23,435]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:03:23,684]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:03:29,183]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:03:29,681]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:03:33,802]\u001b[0m Trial 983 finished with value: 4.273461084792069 and parameters: {'n_hidden': 4, 'learning_rate': 0.000983785464980647, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30921781253242914, 'dropout_rate_Layer_2': 0.039328915912906284, 'dropout_rate_Layer_3': 0.32107865375525985, 'dropout_rate_Layer_4': 0.09647234800194149, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.989305071998702e-05, 'l1_Layer_2': 0.013993718905205437, 'l1_Layer_3': 3.430116245701382e-05, 'l1_Layer_4': 0.0002106826333974697, 'n_units_Layer_1': 295, 'n_units_Layer_2': 280, 'n_units_Layer_3': 130, 'n_units_Layer_4': 285}. Best is trial 951 with value: 3.815572110319048.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.27 | sMAPE for Validation Set is: 12.28% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 7.13 | sMAPE for Test Set is: 25.12% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:03:35,834]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:03:39,070]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.82 | sMAPE for Validation Set is: 11.15% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.11 | sMAPE for Test Set is: 15.76% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:03:41,406]\u001b[0m Trial 986 finished with value: 3.8219534399034365 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007363132466050236, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33985622745980415, 'dropout_rate_Layer_2': 0.3093785994478626, 'dropout_rate_Layer_3': 0.32438418593669605, 'dropout_rate_Layer_4': 0.06664497509227442, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003954619472093094, 'l1_Layer_2': 3.5734957106200725e-05, 'l1_Layer_3': 0.0009139195964094077, 'l1_Layer_4': 1.666413929521624e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 170, 'n_units_Layer_3': 135, 'n_units_Layer_4': 170}. Best is trial 951 with value: 3.815572110319048.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:03:42,323]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:03:43,696]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:03:48,865]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:03:51,906]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:03:52,369]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:03:56,210]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:03:57,022]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:03:58,499]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:03:59,502]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:04:07,257]\u001b[0m Trial 993 finished with value: 4.066927596683608 and parameters: {'n_hidden': 3, 'learning_rate': 0.001753938337506923, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3533954242092712, 'dropout_rate_Layer_2': 0.14878609603034176, 'dropout_rate_Layer_3': 0.20944197336555626, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00040882153654732, 'l1_Layer_2': 0.0005529480792356635, 'l1_Layer_3': 0.0005449179526393961, 'n_units_Layer_1': 100, 'n_units_Layer_2': 300, 'n_units_Layer_3': 205}. Best is trial 951 with value: 3.815572110319048.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.07 | sMAPE for Validation Set is: 11.81% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.29 | sMAPE for Test Set is: 22.92% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:04:10,483]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:04:12,866]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:04:17,457]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:04:21,216]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:04:24,998]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:04:33,720]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:04:37,850]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:04:41,787]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:04:45,741]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:04:49,673]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:04:53,572]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.79 | sMAPE for Validation Set is: 11.03% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.81 | sMAPE for Test Set is: 17.78% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:04:55,812]\u001b[0m Trial 1004 finished with value: 3.7919393545378077 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007531605163242569, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0688182957908603, 'dropout_rate_Layer_2': 0.26690335137549914, 'dropout_rate_Layer_3': 0.3427617945648535, 'dropout_rate_Layer_4': 0.0619835361708531, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0004075761713749527, 'l1_Layer_2': 0.0013404699747696916, 'l1_Layer_3': 0.0007057820291243252, 'l1_Layer_4': 1.5029871478267471e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 170, 'n_units_Layer_3': 140, 'n_units_Layer_4': 160}. Best is trial 1004 with value: 3.7919393545378077.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:04:58,848]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:05:19,152]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:05:22,727]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:05:36,496]\u001b[0m Trial 1019 finished with value: 4.176399005520499 and parameters: {'n_hidden': 3, 'learning_rate': 0.003291198954636791, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3979980987287895, 'dropout_rate_Layer_2': 0.15007794074976985, 'dropout_rate_Layer_3': 0.2749416187356735, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010336563063480998, 'l1_Layer_2': 0.0007185031082610073, 'l1_Layer_3': 0.00029720805118240654, 'n_units_Layer_1': 90, 'n_units_Layer_2': 300, 'n_units_Layer_3': 195}. Best is trial 1004 with value: 3.7919393545378077.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.18 | sMAPE for Validation Set is: 12.18% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 6.17 | sMAPE for Test Set is: 22.54% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:05:39,150]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:05:43,356]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:05:58,948]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:05:59,545]\u001b[0m Trial 1021 finished with value: 4.0515416160464515 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012298689018162316, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0622006573672979, 'dropout_rate_Layer_2': 0.2926389566162233, 'dropout_rate_Layer_3': 0.32154927668133737, 'dropout_rate_Layer_4': 0.08505253306241131, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0005231611548101425, 'l1_Layer_2': 0.0005325942954998602, 'l1_Layer_3': 0.0002852902903004165, 'l1_Layer_4': 1.3674191627186246e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 170, 'n_units_Layer_3': 140, 'n_units_Layer_4': 180}. Best is trial 1004 with value: 3.7919393545378077.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.05 | sMAPE for Validation Set is: 11.70% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.04 | sMAPE for Test Set is: 22.04% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:06:07,302]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:06:09,837]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:06:10,000]\u001b[0m Trial 1003 finished with value: 4.2436766051802115 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007175347940756885, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2602441302168302, 'dropout_rate_Layer_2': 0.17768119685806322, 'dropout_rate_Layer_3': 0.3715655058453379, 'dropout_rate_Layer_4': 0.1338240128382345, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.853210392744693e-05, 'l1_Layer_2': 0.005444313280917675, 'l1_Layer_3': 4.240124608059446e-05, 'l1_Layer_4': 0.00016116113005402993, 'n_units_Layer_1': 260, 'n_units_Layer_2': 250, 'n_units_Layer_3': 110, 'n_units_Layer_4': 225}. Best is trial 1004 with value: 3.7919393545378077.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.24 | sMAPE for Validation Set is: 12.21% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 6.65 | sMAPE for Test Set is: 23.71% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:06:15,942]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:06:16,071]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:06:16,374]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:06:25,275]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:06:25,448]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:06:31,585]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:06:31,998]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:06:32,931]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:06:36,409]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:06:40,590]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:06:42,213]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:06:44,169]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:06:48,021]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:06:49,616]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:06:50,069]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:06:54,780]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:06:57,810]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:06:57,872]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:06:58,876]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:07:05,575]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:07:10,185]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:07:14,397]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:07:19,819]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:07:23,577]\u001b[0m Trial 1047 finished with value: 3.6927429834202457 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006092140453157097, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07096307309891706, 'dropout_rate_Layer_2': 0.24898823367845618, 'dropout_rate_Layer_3': 0.3419113660998973, 'dropout_rate_Layer_4': 0.027076742264630096, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00028027540294835705, 'l1_Layer_2': 4.355215595244939e-05, 'l1_Layer_3': 0.0006125188644661892, 'l1_Layer_4': 2.0329397931340526e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 185, 'n_units_Layer_3': 130, 'n_units_Layer_4': 150}. Best is trial 1047 with value: 3.6927429834202457.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.69 | sMAPE for Validation Set is: 10.72% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.51 | sMAPE for Test Set is: 17.05% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:07:27,179]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:07:28,027]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:07:33,599]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:07:35,055]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:07:42,093]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:07:57,158]\u001b[0m Trial 1054 finished with value: 4.178697647657696 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025866884280647887, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3565501481279974, 'dropout_rate_Layer_2': 0.1830229584467672, 'dropout_rate_Layer_3': 0.19516998496022842, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00040925789055817804, 'l1_Layer_2': 0.0004909884140910867, 'l1_Layer_3': 0.0004242363703905837, 'n_units_Layer_1': 80, 'n_units_Layer_2': 285, 'n_units_Layer_3': 190}. Best is trial 1047 with value: 3.6927429834202457.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.18 | sMAPE for Validation Set is: 12.01% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 6.48 | sMAPE for Test Set is: 23.45% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:07:57,819]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:07:59,322]\u001b[0m Trial 1058 finished with value: 4.225699745285666 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027024522503711406, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32750633887650576, 'dropout_rate_Layer_2': 0.18246901035657015, 'dropout_rate_Layer_3': 0.19345736569001248, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00027323668288787537, 'l1_Layer_2': 0.00017474040601368976, 'l1_Layer_3': 0.00017088977982918842, 'n_units_Layer_1': 90, 'n_units_Layer_2': 275, 'n_units_Layer_3': 190}. Best is trial 1047 with value: 3.6927429834202457.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.23 | sMAPE for Validation Set is: 12.26% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 6.42 | sMAPE for Test Set is: 23.07% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:08:01,719]\u001b[0m Trial 1028 finished with value: 3.737497041243192 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006218000791963201, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3422107045411483, 'dropout_rate_Layer_2': 0.3299895804135229, 'dropout_rate_Layer_3': 0.346123703591678, 'dropout_rate_Layer_4': 0.0282190634653861, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00018768913100412467, 'l1_Layer_2': 0.0020451192837589484, 'l1_Layer_3': 0.00205468517946449, 'l1_Layer_4': 1.9906708920746764e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 180, 'n_units_Layer_3': 90, 'n_units_Layer_4': 150}. Best is trial 1047 with value: 3.6927429834202457.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.74 | sMAPE for Validation Set is: 10.85% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.46 | sMAPE for Test Set is: 17.03% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:08:08,388]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:08:08,578]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:08:08,926]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:08:16,690]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:08:16,827]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:08:16,897]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:08:24,525]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:08:24,911]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:08:25,089]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:08:31,215]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:08:34,036]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:08:34,606]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:08:39,277]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:08:44,486]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:08:48,035]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:08:48,930]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:08:54,001]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:08:55,108]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:08:58,050]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:09:03,576]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:09:07,323]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:09:10,314]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:09:13,190]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.66 | sMAPE for Validation Set is: 10.62% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.30 | sMAPE for Test Set is: 16.29% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:09:16,225]\u001b[0m Trial 1061 finished with value: 3.6599234217727203 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007728154153694281, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07312105003424707, 'dropout_rate_Layer_2': 0.26443977651691347, 'dropout_rate_Layer_3': 0.35440368511278997, 'dropout_rate_Layer_4': 0.004840792862958264, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0008750554406439417, 'l1_Layer_2': 4.6883812685436814e-05, 'l1_Layer_3': 0.00036234013568200963, 'l1_Layer_4': 1.859770114683985e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 175, 'n_units_Layer_3': 125, 'n_units_Layer_4': 155}. Best is trial 1061 with value: 3.6599234217727203.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:09:16,774]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:09:19,281]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:09:19,348]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:09:26,361]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:09:26,846]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:09:32,524]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:09:33,888]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:09:34,927]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:09:39,216]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:09:42,467]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:09:46,962]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:09:52,147]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:09:54,872]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:09:58,608]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:10:01,541]\u001b[0m Trial 1087 finished with value: 4.052161820427666 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014986536480534748, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3353348609962531, 'dropout_rate_Layer_2': 0.07576776666178923, 'dropout_rate_Layer_3': 0.3615945797930672, 'dropout_rate_Layer_4': 0.0824352255481608, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00012080747529678244, 'l1_Layer_2': 0.010091638728201523, 'l1_Layer_3': 1.978406331505547e-05, 'l1_Layer_4': 0.00012776229126829463, 'n_units_Layer_1': 210, 'n_units_Layer_2': 270, 'n_units_Layer_3': 160, 'n_units_Layer_4': 195}. Best is trial 1061 with value: 3.6599234217727203.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.05 | sMAPE for Validation Set is: 11.68% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.22 | sMAPE for Test Set is: 22.73% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:10:02,978]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:10:06,684]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:10:06,769]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:10:12,432]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:10:15,694]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:10:18,251]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:10:19,385]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:10:23,994]\u001b[0m Trial 1097 finished with value: 4.193587635438091 and parameters: {'n_hidden': 4, 'learning_rate': 0.0034998813227839973, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3328460894198934, 'dropout_rate_Layer_2': 0.14302537431350537, 'dropout_rate_Layer_3': 0.3610037867076038, 'dropout_rate_Layer_4': 0.015269772348581671, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.844198154749308e-05, 'l1_Layer_2': 0.004753962313062571, 'l1_Layer_3': 0.00018541998680756018, 'l1_Layer_4': 0.00012881260577853298, 'n_units_Layer_1': 245, 'n_units_Layer_2': 270, 'n_units_Layer_3': 265, 'n_units_Layer_4': 145}. Best is trial 1061 with value: 3.6599234217727203.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.19 | sMAPE for Validation Set is: 12.17% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 6.80 | sMAPE for Test Set is: 24.36% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:10:24,485]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:10:30,340]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:10:31,060]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:10:31,234]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:10:37,811]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:10:38,690]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:10:39,943]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:10:45,921]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:10:48,722]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:10:52,837]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:10:54,169]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:10:59,217]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:11:00,706]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:11:08,231]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:11:08,433]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:11:16,108]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:11:18,124]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:11:21,593]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:11:23,967]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:11:29,279]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:11:34,397]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:11:35,081]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:11:42,210]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:11:44,553]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:11:47,208]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:11:51,069]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:11:51,924]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:11:54,907]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:11:57,634]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:12:01,894]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:12:02,926]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:12:04,826]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:12:12,305]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:12:15,017]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:12:15,749]\u001b[0m Trial 1108 finished with value: 3.6589975337786824 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007800262652530365, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08473568686176461, 'dropout_rate_Layer_2': 0.2624817296074753, 'dropout_rate_Layer_3': 0.3557377746824886, 'dropout_rate_Layer_4': 0.009981353131803705, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0002058951977404071, 'l1_Layer_2': 0.001959396385147516, 'l1_Layer_3': 0.0015305616922891775, 'l1_Layer_4': 1.788695922562886e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 175, 'n_units_Layer_3': 125, 'n_units_Layer_4': 165}. Best is trial 1108 with value: 3.6589975337786824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.66 | sMAPE for Validation Set is: 10.61% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.32 | sMAPE for Test Set is: 16.45% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:12:20,449]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:12:20,843]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:12:21,049]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:12:21,306]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:12:28,737]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:12:30,176]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:12:32,094]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:12:32,398]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:12:38,727]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:12:44,331]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:12:45,968]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:12:47,854]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:12:47,899]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:12:57,058]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:12:58,939]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:13:00,101]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:13:07,037]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:13:07,110]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:13:07,521]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:13:08,133]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:13:15,469]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:13:19,219]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:13:22,501]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:13:22,753]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:13:23,147]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:13:30,832]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:13:32,656]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:13:33,951]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:13:37,186]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:13:42,419]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:13:43,324]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:13:51,274]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:13:53,679]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:13:55,202]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:13:56,291]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:13:58,044]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:14:04,493]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:14:06,198]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:14:10,825]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:14:12,938]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:14:14,933]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:14:15,621]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:14:25,003]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:14:29,253]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:14:33,497]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:14:33,515]\u001b[0m Trial 1185 finished with value: 3.7733332259206573 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005745219037766278, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07583594894476689, 'dropout_rate_Layer_2': 0.2656065000312215, 'dropout_rate_Layer_3': 0.31369931030564485, 'dropout_rate_Layer_4': 0.00014037818905267025, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00019555616753878373, 'l1_Layer_2': 9.644918202337746e-05, 'l1_Layer_3': 0.0003542469280147414, 'l1_Layer_4': 1.2217276114885159e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 165, 'n_units_Layer_3': 110, 'n_units_Layer_4': 170}. Best is trial 1108 with value: 3.6589975337786824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.77 | sMAPE for Validation Set is: 11.00% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.45 | sMAPE for Test Set is: 16.72% | rMAE for Test Set is: 0.73\n",
      "MAE for Validation Set is: 3.89 | sMAPE for Validation Set is: 11.20% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.83 | sMAPE for Test Set is: 21.55% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:14:37,556]\u001b[0m Trial 1166 finished with value: 3.8850161232673037 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007830567965197139, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2691612006489714, 'dropout_rate_Layer_2': 0.0794583057947161, 'dropout_rate_Layer_3': 0.3408483362774778, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.4385743630398542e-05, 'l1_Layer_2': 0.0086464267285848, 'l1_Layer_3': 0.0013075220267204965, 'n_units_Layer_1': 235, 'n_units_Layer_2': 275, 'n_units_Layer_3': 135}. Best is trial 1108 with value: 3.6589975337786824.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:14:40,793]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:14:45,230]\u001b[0m Trial 1184 finished with value: 4.1909755325050995 and parameters: {'n_hidden': 4, 'learning_rate': 0.0033972333821209117, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35447585866037506, 'dropout_rate_Layer_2': 0.14322502482595992, 'dropout_rate_Layer_3': 0.3572151875664017, 'dropout_rate_Layer_4': 0.003323159287816891, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.9873228247801466e-05, 'l1_Layer_2': 0.005045875739280343, 'l1_Layer_3': 2.1766359839347706e-05, 'l1_Layer_4': 0.00012058808314949692, 'n_units_Layer_1': 255, 'n_units_Layer_2': 290, 'n_units_Layer_3': 265, 'n_units_Layer_4': 140}. Best is trial 1108 with value: 3.6589975337786824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.19 | sMAPE for Validation Set is: 12.12% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 6.68 | sMAPE for Test Set is: 23.91% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:14:48,207]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:15:01,522]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.07 | sMAPE for Validation Set is: 11.81% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.47 | sMAPE for Test Set is: 23.40% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:15:03,802]\u001b[0m Trial 1189 finished with value: 4.074380079843034 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015233560544462052, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26096548654484436, 'dropout_rate_Layer_2': 0.1852435015425482, 'dropout_rate_Layer_3': 0.28749769224281896, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006332153377202968, 'l1_Layer_2': 0.00017163174980017702, 'l1_Layer_3': 0.00014437633680243147, 'n_units_Layer_1': 65, 'n_units_Layer_2': 265, 'n_units_Layer_3': 185}. Best is trial 1108 with value: 3.6589975337786824.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:15:06,706]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:15:08,753]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:15:12,777]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:15:15,829]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:15:19,126]\u001b[0m Trial 1194 finished with value: 3.8641269474144977 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008879221201489688, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.250429517402988, 'dropout_rate_Layer_2': 0.08760167189077682, 'dropout_rate_Layer_3': 0.32684655502461474, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7616181450199174e-05, 'l1_Layer_2': 0.007229190446845361, 'l1_Layer_3': 0.0018676833827771927, 'n_units_Layer_1': 265, 'n_units_Layer_2': 300, 'n_units_Layer_3': 140}. Best is trial 1108 with value: 3.6589975337786824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.86 | sMAPE for Validation Set is: 11.22% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.54 | sMAPE for Test Set is: 16.68% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:15:19,722]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:15:25,738]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:15:26,284]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:15:31,500]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:15:31,912]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:15:38,585]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:15:39,518]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:15:45,442]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:15:48,367]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:15:48,760]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:15:50,201]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:15:55,058]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:15:58,445]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:16:00,238]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:16:01,563]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:16:07,609]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:16:09,598]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:16:13,177]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:16:14,578]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:16:21,287]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:16:25,324]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:16:31,290]\u001b[0m Trial 1214 finished with value: 3.7219539846210723 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005700419666566169, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0426028317150407, 'dropout_rate_Layer_2': 0.26385500021808805, 'dropout_rate_Layer_3': 0.34931189077573993, 'dropout_rate_Layer_4': 0.024822319632321215, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003746576123609139, 'l1_Layer_2': 3.678446029536789e-05, 'l1_Layer_3': 0.0009723910954895712, 'l1_Layer_4': 1.3513979121548183e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 195, 'n_units_Layer_3': 110, 'n_units_Layer_4': 150}. Best is trial 1108 with value: 3.6589975337786824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.72 | sMAPE for Validation Set is: 10.74% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.44 | sMAPE for Test Set is: 16.77% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:16:34,132]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:16:35,401]\u001b[0m Trial 1219 finished with value: 4.147642840424507 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017154155239185002, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3133592084517313, 'dropout_rate_Layer_2': 0.19855361997609103, 'dropout_rate_Layer_3': 0.2875165024648632, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004240993789859656, 'l1_Layer_2': 0.00014780539344563123, 'l1_Layer_3': 0.00016733722268704511, 'n_units_Layer_1': 55, 'n_units_Layer_2': 275, 'n_units_Layer_3': 180}. Best is trial 1108 with value: 3.6589975337786824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.15 | sMAPE for Validation Set is: 12.01% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.03 | sMAPE for Test Set is: 22.09% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:16:36,080]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:16:39,740]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:16:40,239]\u001b[0m Trial 1211 finished with value: 3.679414958518754 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005704111777575221, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05191820323179145, 'dropout_rate_Layer_2': 0.26302819519220055, 'dropout_rate_Layer_3': 0.35327013765869825, 'dropout_rate_Layer_4': 0.05140035555218478, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003666178528229007, 'l1_Layer_2': 6.0112024897366486e-05, 'l1_Layer_3': 0.0009710885011166863, 'l1_Layer_4': 1.4586166291944713e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 195, 'n_units_Layer_3': 110, 'n_units_Layer_4': 150}. Best is trial 1108 with value: 3.6589975337786824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.68 | sMAPE for Validation Set is: 10.68% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.41 | sMAPE for Test Set is: 16.73% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:16:46,639]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:16:48,462]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:16:53,560]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:16:53,900]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:16:55,184]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:16:55,529]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:17:02,803]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:17:03,630]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:17:06,618]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:17:11,256]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:17:19,184]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:17:23,479]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:17:24,426]\u001b[0m Trial 1234 finished with value: 4.250203642374532 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014246432176468454, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07907051546169973, 'dropout_rate_Layer_2': 0.07084468601918965, 'dropout_rate_Layer_3': 0.166117744791832, 'dropout_rate_Layer_4': 0.15193673196230678, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.023555028085540025, 'l1_Layer_2': 0.009049514238508943, 'l1_Layer_3': 1.0023668012078794e-05, 'l1_Layer_4': 6.346293533025228e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 280, 'n_units_Layer_3': 265, 'n_units_Layer_4': 155}. Best is trial 1108 with value: 3.6589975337786824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.25 | sMAPE for Validation Set is: 12.18% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 5.29 | sMAPE for Test Set is: 19.51% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:17:31,523]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:17:36,394]\u001b[0m Trial 1235 finished with value: 3.6306467462473964 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006621220896480385, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08408130384542346, 'dropout_rate_Layer_2': 0.2587575659285854, 'dropout_rate_Layer_3': 0.30002353845212426, 'dropout_rate_Layer_4': 0.03711141131948007, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0006770007426792949, 'l1_Layer_2': 0.000145269841287557, 'l1_Layer_3': 0.0002469106869069185, 'l1_Layer_4': 2.1615532569395945e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 195, 'n_units_Layer_3': 135, 'n_units_Layer_4': 150}. Best is trial 1235 with value: 3.6306467462473964.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.63 | sMAPE for Validation Set is: 10.57% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.59 | sMAPE for Test Set is: 17.37% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:17:39,322]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:17:41,746]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:17:43,517]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:17:46,913]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:17:51,171]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:17:51,647]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:17:54,379]\u001b[0m Trial 1238 finished with value: 3.975751997230217 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018833692752108317, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04291518093257868, 'dropout_rate_Layer_2': 0.3474009878085221, 'dropout_rate_Layer_3': 0.16322204731096224, 'dropout_rate_Layer_4': 0.11829274570637459, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.012466542545500113, 'l1_Layer_2': 1.7169319213489376e-05, 'l1_Layer_3': 1.1976141124603813e-05, 'l1_Layer_4': 6.576255730854546e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 280, 'n_units_Layer_3': 85, 'n_units_Layer_4': 90}. Best is trial 1235 with value: 3.6306467462473964.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.98 | sMAPE for Validation Set is: 11.47% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.27 | sMAPE for Test Set is: 19.59% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:17:58,435]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:18:02,076]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:18:05,519]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:18:09,050]\u001b[0m Trial 1241 finished with value: 3.928104374484198 and parameters: {'n_hidden': 4, 'learning_rate': 0.001542864138903058, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07304892498129398, 'dropout_rate_Layer_2': 0.08404111856057371, 'dropout_rate_Layer_3': 0.16368848046933945, 'dropout_rate_Layer_4': 0.15507589309503753, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.03194189226589779, 'l1_Layer_2': 0.00012493731484308797, 'l1_Layer_3': 1.778864451428856e-05, 'l1_Layer_4': 8.335689956667517e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 275, 'n_units_Layer_3': 265, 'n_units_Layer_4': 155}. Best is trial 1235 with value: 3.6306467462473964.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.93 | sMAPE for Validation Set is: 11.34% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.50 | sMAPE for Test Set is: 20.44% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:18:09,256]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:18:16,195]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:18:19,677]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:18:20,210]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:18:26,963]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:18:30,602]\u001b[0m Trial 1251 finished with value: 4.126640288328104 and parameters: {'n_hidden': 3, 'learning_rate': 0.002070887637411423, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3713104928325255, 'dropout_rate_Layer_2': 0.16742306814754226, 'dropout_rate_Layer_3': 0.1912584816913194, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007007382188377855, 'l1_Layer_2': 0.0002910897952984332, 'l1_Layer_3': 0.0005475619247978352, 'n_units_Layer_1': 80, 'n_units_Layer_2': 255, 'n_units_Layer_3': 180}. Best is trial 1235 with value: 3.6306467462473964.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.13 | sMAPE for Validation Set is: 11.83% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.57 | sMAPE for Test Set is: 23.54% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:18:34,238]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:18:34,369]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:18:35,730]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:18:41,824]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:18:45,635]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:18:46,198]\u001b[0m Trial 1255 finished with value: 3.8605262044998967 and parameters: {'n_hidden': 4, 'learning_rate': 0.001332247966698027, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10094276408441973, 'dropout_rate_Layer_2': 0.07698905231401329, 'dropout_rate_Layer_3': 0.1551345380858178, 'dropout_rate_Layer_4': 0.169802303597371, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003277011818550464, 'l1_Layer_2': 1.7994649272666444e-05, 'l1_Layer_3': 1.750497026826309e-05, 'l1_Layer_4': 0.00010544457021134521, 'n_units_Layer_1': 235, 'n_units_Layer_2': 270, 'n_units_Layer_3': 255, 'n_units_Layer_4': 165}. Best is trial 1235 with value: 3.6306467462473964.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.86 | sMAPE for Validation Set is: 11.23% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.15 | sMAPE for Test Set is: 19.30% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:18:50,979]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:18:54,220]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:18:54,343]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:18:56,188]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:19:02,565]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:19:06,256]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:19:10,959]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:19:13,380]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:19:16,598]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:19:20,064]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:19:23,967]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:19:26,104]\u001b[0m Trial 1267 finished with value: 3.9385165356568557 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016118126364697489, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10016000576748373, 'dropout_rate_Layer_2': 0.07902256329798243, 'dropout_rate_Layer_3': 0.14350544366253767, 'dropout_rate_Layer_4': 0.1721168442262329, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000245265351319366, 'l1_Layer_2': 1.7246593441125e-05, 'l1_Layer_3': 2.1793578897429965e-05, 'l1_Layer_4': 0.00023000002613400374, 'n_units_Layer_1': 240, 'n_units_Layer_2': 280, 'n_units_Layer_3': 70, 'n_units_Layer_4': 160}. Best is trial 1235 with value: 3.6306467462473964.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.94 | sMAPE for Validation Set is: 11.35% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.62 | sMAPE for Test Set is: 20.84% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:19:27,913]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:19:30,975]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:19:34,887]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:19:38,839]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:19:41,296]\u001b[0m Trial 1274 finished with value: 3.999071937086861 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012508189232881986, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0941532584169966, 'dropout_rate_Layer_2': 0.36119339967359754, 'dropout_rate_Layer_3': 0.1360863287990851, 'dropout_rate_Layer_4': 0.124222917899893, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.06030695420273657, 'l1_Layer_2': 2.1881307725860147e-05, 'l1_Layer_3': 1.95203348698139e-05, 'l1_Layer_4': 0.00010341149012189395, 'n_units_Layer_1': 230, 'n_units_Layer_2': 270, 'n_units_Layer_3': 250, 'n_units_Layer_4': 170}. Best is trial 1235 with value: 3.6306467462473964.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.00 | sMAPE for Validation Set is: 11.51% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.04 | sMAPE for Test Set is: 19.01% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:19:44,873]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:19:47,642]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:19:50,252]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:19:54,744]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:19:57,863]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:19:59,448]\u001b[0m Trial 1270 finished with value: 3.7469028691783737 and parameters: {'n_hidden': 4, 'learning_rate': 0.000686561414833237, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09807957078089902, 'dropout_rate_Layer_2': 0.23447386065782685, 'dropout_rate_Layer_3': 0.31521988743578777, 'dropout_rate_Layer_4': 0.01945836334046637, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0006348418141084613, 'l1_Layer_2': 3.6594812842512885e-05, 'l1_Layer_3': 0.0004911091740585122, 'l1_Layer_4': 3.045935861240552e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 190, 'n_units_Layer_3': 80, 'n_units_Layer_4': 185}. Best is trial 1235 with value: 3.6306467462473964.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 10.89% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.55 | sMAPE for Test Set is: 17.27% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:20:13,314]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:20:24,242]\u001b[0m Trial 1283 finished with value: 3.9631479326617565 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013810869774856912, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10895663773863463, 'dropout_rate_Layer_2': 0.08546909166768821, 'dropout_rate_Layer_3': 0.16416469744160644, 'dropout_rate_Layer_4': 0.18992859843654497, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.08818555243406864, 'l1_Layer_2': 2.3661241549884586e-05, 'l1_Layer_3': 2.4978211221363412e-05, 'l1_Layer_4': 0.00017000424456214963, 'n_units_Layer_1': 245, 'n_units_Layer_2': 270, 'n_units_Layer_3': 255, 'n_units_Layer_4': 165}. Best is trial 1235 with value: 3.6306467462473964.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.96 | sMAPE for Validation Set is: 11.41% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.40 | sMAPE for Test Set is: 20.23% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:20:25,774]\u001b[0m Trial 1287 finished with value: 3.9857189320985165 and parameters: {'n_hidden': 3, 'learning_rate': 0.002382991381489583, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3615070425034056, 'dropout_rate_Layer_2': 0.16928122336064605, 'dropout_rate_Layer_3': 0.17551527136789508, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008225620177832233, 'l1_Layer_2': 0.00034067816704391323, 'l1_Layer_3': 0.00010467689167220127, 'n_units_Layer_1': 60, 'n_units_Layer_2': 290, 'n_units_Layer_3': 185}. Best is trial 1235 with value: 3.6306467462473964.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.99 | sMAPE for Validation Set is: 11.58% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.13 | sMAPE for Test Set is: 22.43% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:20:31,392]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:20:34,993]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:20:35,940]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:20:40,258]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:20:40,910]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:20:47,651]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:20:48,589]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:20:49,273]\u001b[0m Trial 1288 finished with value: 3.9129838977401694 and parameters: {'n_hidden': 4, 'learning_rate': 0.001260502339255912, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11492021333024485, 'dropout_rate_Layer_2': 0.07197308899855934, 'dropout_rate_Layer_3': 0.13379577713076918, 'dropout_rate_Layer_4': 0.17337124405372703, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.011295343509293695, 'l1_Layer_2': 2.2874179599420373e-05, 'l1_Layer_3': 2.379665234455709e-05, 'l1_Layer_4': 0.00019108906526672006, 'n_units_Layer_1': 250, 'n_units_Layer_2': 265, 'n_units_Layer_3': 255, 'n_units_Layer_4': 160}. Best is trial 1235 with value: 3.6306467462473964.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.91 | sMAPE for Validation Set is: 11.31% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.97 | sMAPE for Test Set is: 18.75% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:20:57,738]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:21:06,987]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:21:10,749]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:21:17,191]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:21:21,758]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:21:25,317]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:21:28,933]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:21:32,831]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:21:33,534]\u001b[0m Trial 1301 finished with value: 3.875057653483953 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012335401616829877, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1224884745795093, 'dropout_rate_Layer_2': 0.0786095278970713, 'dropout_rate_Layer_3': 0.11578840661245804, 'dropout_rate_Layer_4': 0.171924503509129, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.08079978418385367, 'l1_Layer_2': 2.8083055834307574e-05, 'l1_Layer_3': 2.8758379602632302e-05, 'l1_Layer_4': 0.00019235878119400126, 'n_units_Layer_1': 245, 'n_units_Layer_2': 255, 'n_units_Layer_3': 255, 'n_units_Layer_4': 160}. Best is trial 1235 with value: 3.6306467462473964.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.88 | sMAPE for Validation Set is: 11.16% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.88 | sMAPE for Test Set is: 18.48% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:21:36,021]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:21:43,803]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:21:51,583]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:21:55,669]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:22:02,942]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:22:06,811]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:22:11,027]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:22:26,280]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:22:30,009]\u001b[0m Trial 1308 finished with value: 4.235247256160892 and parameters: {'n_hidden': 3, 'learning_rate': 0.002425285284607596, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38472586525890773, 'dropout_rate_Layer_2': 0.22058024249736138, 'dropout_rate_Layer_3': 0.18751199197872334, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006714611180397504, 'l1_Layer_2': 0.0003049701363756896, 'l1_Layer_3': 0.0013255015556424398, 'n_units_Layer_1': 100, 'n_units_Layer_2': 290, 'n_units_Layer_3': 185}. Best is trial 1235 with value: 3.6306467462473964.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.24 | sMAPE for Validation Set is: 12.35% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 6.24 | sMAPE for Test Set is: 22.73% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:22:30,747]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:22:34,991]\u001b[0m Trial 1311 finished with value: 3.9020581858206946 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010575237466586046, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12718944122902182, 'dropout_rate_Layer_2': 0.08882099476689355, 'dropout_rate_Layer_3': 0.13128094101702065, 'dropout_rate_Layer_4': 0.18275502592986234, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.07159927491729523, 'l1_Layer_2': 2.9466639952642655e-05, 'l1_Layer_3': 2.41545096568433e-05, 'l1_Layer_4': 0.0003115975018285673, 'n_units_Layer_1': 245, 'n_units_Layer_2': 260, 'n_units_Layer_3': 250, 'n_units_Layer_4': 170}. Best is trial 1235 with value: 3.6306467462473964.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.90 | sMAPE for Validation Set is: 11.24% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.38 | sMAPE for Test Set is: 20.18% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:22:35,691]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:22:40,536]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:22:41,143]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:22:52,615]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:22:57,511]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:23:26,857]\u001b[0m Trial 1323 finished with value: 3.88475088924003 and parameters: {'n_hidden': 4, 'learning_rate': 0.000724646215221229, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09816955039126742, 'dropout_rate_Layer_2': 0.0933433814963021, 'dropout_rate_Layer_3': 0.13697815070782135, 'dropout_rate_Layer_4': 0.18802426229474695, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.05212706486175486, 'l1_Layer_2': 2.7211458315210867e-05, 'l1_Layer_3': 2.3924753127249902e-05, 'l1_Layer_4': 0.00021073607222107027, 'n_units_Layer_1': 230, 'n_units_Layer_2': 260, 'n_units_Layer_3': 255, 'n_units_Layer_4': 175}. Best is trial 1235 with value: 3.6306467462473964.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.88 | sMAPE for Validation Set is: 11.18% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.81 | sMAPE for Test Set is: 18.21% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:23:29,781]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:23:30,042]\u001b[0m Trial 1322 finished with value: 3.894711218928047 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008807454371125203, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12922418273291839, 'dropout_rate_Layer_2': 0.08554941464871363, 'dropout_rate_Layer_3': 0.12073340195793594, 'dropout_rate_Layer_4': 0.157338237963486, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.08428613126792033, 'l1_Layer_2': 2.8526335560108225e-05, 'l1_Layer_3': 2.936585658181752e-05, 'l1_Layer_4': 0.00025821462226847816, 'n_units_Layer_1': 240, 'n_units_Layer_2': 260, 'n_units_Layer_3': 245, 'n_units_Layer_4': 175}. Best is trial 1235 with value: 3.6306467462473964.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.89 | sMAPE for Validation Set is: 11.25% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.12 | sMAPE for Test Set is: 19.31% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:23:30,400]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:23:38,071]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:23:39,694]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:23:45,421]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:23:53,348]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:24:06,298]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:24:09,794]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:24:13,736]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:24:17,105]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:24:17,809]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:24:25,172]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:24:25,457]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:24:26,054]\u001b[0m Trial 1313 finished with value: 4.074214525582403 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010564119098295166, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35103904642809336, 'dropout_rate_Layer_2': 0.16235741372897397, 'dropout_rate_Layer_3': 0.2819178593101364, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000524181542131003, 'l1_Layer_2': 0.000584827582056064, 'l1_Layer_3': 0.00016230559607318578, 'n_units_Layer_1': 95, 'n_units_Layer_2': 295, 'n_units_Layer_3': 175}. Best is trial 1235 with value: 3.6306467462473964.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.07 | sMAPE for Validation Set is: 11.77% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.90 | sMAPE for Test Set is: 21.74% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:24:26,248]\u001b[0m Trial 1332 finished with value: 3.944731325721385 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007807789708183701, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09799771916919352, 'dropout_rate_Layer_2': 0.10779115872897692, 'dropout_rate_Layer_3': 0.11822664524969215, 'dropout_rate_Layer_4': 0.19655384369906254, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.048374299618053875, 'l1_Layer_2': 3.920078055381525e-05, 'l1_Layer_3': 2.3333621494494454e-05, 'l1_Layer_4': 0.0004078691831285631, 'n_units_Layer_1': 240, 'n_units_Layer_2': 255, 'n_units_Layer_3': 245, 'n_units_Layer_4': 165}. Best is trial 1235 with value: 3.6306467462473964.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.94 | sMAPE for Validation Set is: 11.32% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.80 | sMAPE for Test Set is: 18.17% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:24:30,586]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:24:37,640]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:24:41,980]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:24:43,273]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:24:48,262]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:24:50,580]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:24:57,185]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:25:00,956]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:25:01,416]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:25:07,452]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:25:16,086]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:25:18,773]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:25:26,953]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:25:30,353]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:25:31,226]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:25:32,503]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:25:32,753]\u001b[0m Trial 1350 finished with value: 4.162623385623847 and parameters: {'n_hidden': 4, 'learning_rate': 0.0026302098335084546, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36583946289634445, 'dropout_rate_Layer_2': 0.1702542301437553, 'dropout_rate_Layer_3': 0.33558216696928833, 'dropout_rate_Layer_4': 0.12031193936313296, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.536878645438779e-05, 'l1_Layer_2': 0.003208417099148541, 'l1_Layer_3': 2.5674763876272205e-05, 'l1_Layer_4': 0.00042894352681264363, 'n_units_Layer_1': 165, 'n_units_Layer_2': 280, 'n_units_Layer_3': 275, 'n_units_Layer_4': 140}. Best is trial 1235 with value: 3.6306467462473964.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.16 | sMAPE for Validation Set is: 12.05% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 7.14 | sMAPE for Test Set is: 25.26% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:25:35,756]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:25:40,954]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:25:42,444]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:25:43,419]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:25:47,726]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:25:53,614]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:25:54,457]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:25:55,757]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:26:05,744]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:26:10,349]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:26:20,504]\u001b[0m Trial 1361 finished with value: 3.9286736536869564 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008859640581898362, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1221514164183302, 'dropout_rate_Layer_2': 0.23674809084380283, 'dropout_rate_Layer_3': 0.29892445792572103, 'dropout_rate_Layer_4': 0.016848872346347556, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0007892512559434984, 'l1_Layer_2': 0.0026597247712575782, 'l1_Layer_3': 0.0001720725544945915, 'l1_Layer_4': 6.087261423360456e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 185, 'n_units_Layer_3': 80, 'n_units_Layer_4': 155}. Best is trial 1235 with value: 3.6306467462473964.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.93 | sMAPE for Validation Set is: 11.43% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.26 | sMAPE for Test Set is: 16.06% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:26:24,796]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:26:33,932]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:26:34,233]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:26:38,923]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:26:39,711]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:26:40,333]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:26:46,350]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:26:47,153]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:26:54,531]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:26:59,270]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:26:59,517]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:27:05,962]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:27:08,037]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:27:11,112]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:27:14,964]\u001b[0m Trial 1369 finished with value: 3.8788778593464706 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010424079886691994, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1347996386953715, 'dropout_rate_Layer_2': 0.11146186583769918, 'dropout_rate_Layer_3': 0.13134712944513335, 'dropout_rate_Layer_4': 0.16749728430076438, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.05446633018703443, 'l1_Layer_2': 2.6895716203316643e-05, 'l1_Layer_3': 2.258122116413816e-05, 'l1_Layer_4': 0.0005856255368909778, 'n_units_Layer_1': 235, 'n_units_Layer_2': 255, 'n_units_Layer_3': 250, 'n_units_Layer_4': 175}. Best is trial 1235 with value: 3.6306467462473964.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.88 | sMAPE for Validation Set is: 11.19% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.80 | sMAPE for Test Set is: 18.21% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:27:18,037]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:27:18,701]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:27:19,802]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:27:26,743]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:27:29,222]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:27:31,829]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:27:34,326]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:27:36,170]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:27:40,457]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:27:45,042]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:27:48,134]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:27:48,923]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:27:52,051]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:27:54,156]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:27:57,268]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:28:03,712]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:28:09,684]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:28:10,332]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:28:10,701]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:28:18,760]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:28:18,920]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:28:27,012]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:28:29,294]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:28:29,992]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:28:35,198]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:28:39,733]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:28:47,165]\u001b[0m Trial 1407 finished with value: 3.7312656763501226 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005405066279874954, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04149132661255866, 'dropout_rate_Layer_2': 0.2617308906753074, 'dropout_rate_Layer_3': 0.3405980599635426, 'dropout_rate_Layer_4': 0.02532058464664228, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0001792125026352391, 'l1_Layer_2': 5.766527664245277e-05, 'l1_Layer_3': 0.00044402938874590724, 'l1_Layer_4': 1.4882343396389489e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 200, 'n_units_Layer_3': 110, 'n_units_Layer_4': 165}. Best is trial 1235 with value: 3.6306467462473964.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.73 | sMAPE for Validation Set is: 10.87% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.36 | sMAPE for Test Set is: 16.43% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:28:50,863]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:28:53,534]\u001b[0m Trial 1409 finished with value: 3.77444609837381 and parameters: {'n_hidden': 4, 'learning_rate': 0.000541026175974504, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10990103613826833, 'dropout_rate_Layer_2': 0.2630277346619728, 'dropout_rate_Layer_3': 0.33928898849694344, 'dropout_rate_Layer_4': 0.024899858236209507, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0002728634664051264, 'l1_Layer_2': 0.00028217536129962554, 'l1_Layer_3': 0.0006752106194954325, 'l1_Layer_4': 1.4933015446867946e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 155, 'n_units_Layer_3': 150, 'n_units_Layer_4': 165}. Best is trial 1235 with value: 3.6306467462473964.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.77 | sMAPE for Validation Set is: 10.93% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.30 | sMAPE for Test Set is: 16.25% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:28:56,411]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:28:59,554]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:29:00,214]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:29:05,365]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:29:06,323]\u001b[0m Trial 1399 finished with value: 3.924133664163131 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013305547772190457, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10260656546516961, 'dropout_rate_Layer_2': 0.11945173017070032, 'dropout_rate_Layer_3': 0.13585250774906665, 'dropout_rate_Layer_4': 0.1659716966692601, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.07148270893014001, 'l1_Layer_2': 2.7325663515863357e-05, 'l1_Layer_3': 1.8648711892849335e-05, 'l1_Layer_4': 0.00038071031550380486, 'n_units_Layer_1': 225, 'n_units_Layer_2': 235, 'n_units_Layer_3': 260, 'n_units_Layer_4': 180}. Best is trial 1235 with value: 3.6306467462473964.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.92 | sMAPE for Validation Set is: 11.32% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.23 | sMAPE for Test Set is: 19.58% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:29:13,057]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:29:16,832]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:29:20,097]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:29:23,716]\u001b[0m Trial 1416 finished with value: 3.8182126066626996 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005643028585496369, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04216279171349721, 'dropout_rate_Layer_2': 0.2570275157700621, 'dropout_rate_Layer_3': 0.33141556865685556, 'dropout_rate_Layer_4': 0.025353058666749008, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00018520057241944938, 'l1_Layer_2': 0.00012236617952755035, 'l1_Layer_3': 0.0002514871878113066, 'l1_Layer_4': 1.4014068414089754e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 150, 'n_units_Layer_3': 150, 'n_units_Layer_4': 145}. Best is trial 1235 with value: 3.6306467462473964.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.82 | sMAPE for Validation Set is: 11.14% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.58 | sMAPE for Test Set is: 17.32% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:29:28,533]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:29:29,138]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:29:34,590]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:29:36,485]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:29:39,235]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:29:44,325]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:29:51,470]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:29:55,880]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:29:59,852]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:29:59,898]\u001b[0m Trial 1421 finished with value: 3.8934504058418766 and parameters: {'n_hidden': 4, 'learning_rate': 0.001267798221951233, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09289613604601066, 'dropout_rate_Layer_2': 0.10290345165095724, 'dropout_rate_Layer_3': 0.13953681041528862, 'dropout_rate_Layer_4': 0.15648508921382684, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.09967072178591184, 'l1_Layer_2': 3.1793925852837944e-05, 'l1_Layer_3': 2.1853258010354258e-05, 'l1_Layer_4': 0.001024012154552373, 'n_units_Layer_1': 255, 'n_units_Layer_2': 230, 'n_units_Layer_3': 260, 'n_units_Layer_4': 185}. Best is trial 1235 with value: 3.6306467462473964.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.89 | sMAPE for Validation Set is: 11.25% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.08 | sMAPE for Test Set is: 19.18% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:30:03,547]\u001b[0m Trial 1427 finished with value: 3.7450150757617346 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005116953609610245, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11368474993063457, 'dropout_rate_Layer_2': 0.26626668463838105, 'dropout_rate_Layer_3': 0.3395438880861928, 'dropout_rate_Layer_4': 0.013199186812971796, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0002528735509360376, 'l1_Layer_2': 0.00017130124041874197, 'l1_Layer_3': 0.0003533104485492388, 'l1_Layer_4': 2.36724526923231e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 200, 'n_units_Layer_3': 170, 'n_units_Layer_4': 165}. Best is trial 1235 with value: 3.6306467462473964.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 10.93% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.66 | sMAPE for Test Set is: 17.56% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:30:17,720]\u001b[0m Trial 1422 finished with value: 3.931914915319261 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012648811667392878, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0944769408041364, 'dropout_rate_Layer_2': 0.12572788210272506, 'dropout_rate_Layer_3': 0.14096710978920338, 'dropout_rate_Layer_4': 0.1553946057262035, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.05543973481238767, 'l1_Layer_2': 3.068740453540485e-05, 'l1_Layer_3': 2.3905201151896994e-05, 'l1_Layer_4': 0.00034313484069151335, 'n_units_Layer_1': 250, 'n_units_Layer_2': 235, 'n_units_Layer_3': 240, 'n_units_Layer_4': 185}. Best is trial 1235 with value: 3.6306467462473964.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.93 | sMAPE for Validation Set is: 11.37% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.97 | sMAPE for Test Set is: 18.78% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:30:24,357]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:30:30,905]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:30:37,265]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:30:38,618]\u001b[0m Trial 1432 finished with value: 3.894717860168585 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012488494186876547, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09255042439889143, 'dropout_rate_Layer_2': 0.12388868209676752, 'dropout_rate_Layer_3': 0.14651085602977235, 'dropout_rate_Layer_4': 0.15912100999844295, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.09016670647087158, 'l1_Layer_2': 3.0412957586277508e-05, 'l1_Layer_3': 2.0950730591979063e-05, 'l1_Layer_4': 0.00030501942738321656, 'n_units_Layer_1': 255, 'n_units_Layer_2': 230, 'n_units_Layer_3': 260, 'n_units_Layer_4': 185}. Best is trial 1235 with value: 3.6306467462473964.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.89 | sMAPE for Validation Set is: 11.23% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.19 | sMAPE for Test Set is: 19.56% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:30:39,240]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:30:41,730]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:30:48,721]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:30:52,320]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:30:52,814]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:30:53,203]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:31:02,337]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:31:02,586]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:31:08,394]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:31:08,747]\u001b[0m Trial 1438 finished with value: 3.978661162466975 and parameters: {'n_hidden': 4, 'learning_rate': 0.00142600080334497, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09406677927469129, 'dropout_rate_Layer_2': 0.1165347000646676, 'dropout_rate_Layer_3': 0.14308638857180397, 'dropout_rate_Layer_4': 0.1647547109468419, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.08554105897232331, 'l1_Layer_2': 3.941886512141242e-05, 'l1_Layer_3': 2.0375440242949996e-05, 'l1_Layer_4': 0.00036637443672730415, 'n_units_Layer_1': 250, 'n_units_Layer_2': 230, 'n_units_Layer_3': 255, 'n_units_Layer_4': 180}. Best is trial 1235 with value: 3.6306467462473964.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.98 | sMAPE for Validation Set is: 11.48% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.02 | sMAPE for Test Set is: 18.92% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:31:14,788]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:31:15,029]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:31:23,434]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:31:36,216]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:31:36,949]\u001b[0m Trial 1447 finished with value: 3.900660169510868 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009865254875649104, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10976080046148726, 'dropout_rate_Layer_2': 0.1114137878892789, 'dropout_rate_Layer_3': 0.14155621992282202, 'dropout_rate_Layer_4': 0.16875327342719182, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.057477300766912716, 'l1_Layer_2': 3.0101324927388647e-05, 'l1_Layer_3': 2.0834254794627492e-05, 'l1_Layer_4': 0.00044942237869701016, 'n_units_Layer_1': 250, 'n_units_Layer_2': 220, 'n_units_Layer_3': 265, 'n_units_Layer_4': 190}. Best is trial 1235 with value: 3.6306467462473964.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.90 | sMAPE for Validation Set is: 11.20% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.92 | sMAPE for Test Set is: 18.66% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:31:41,903]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:31:43,160]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:31:48,939]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:31:54,653]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:31:59,099]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:32:13,890]\u001b[0m Trial 1456 finished with value: 3.872318669981574 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009171373738493791, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09021252588550073, 'dropout_rate_Layer_2': 0.1262393777894013, 'dropout_rate_Layer_3': 0.12449326829034658, 'dropout_rate_Layer_4': 0.17135789249236497, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.05127578812141482, 'l1_Layer_2': 3.876833055417052e-05, 'l1_Layer_3': 1.711069549060462e-05, 'l1_Layer_4': 0.0003995982449765428, 'n_units_Layer_1': 255, 'n_units_Layer_2': 225, 'n_units_Layer_3': 270, 'n_units_Layer_4': 180}. Best is trial 1235 with value: 3.6306467462473964.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.87 | sMAPE for Validation Set is: 11.21% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.96 | sMAPE for Test Set is: 18.77% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:32:15,058]\u001b[0m Trial 1459 finished with value: 3.8038094695853117 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006547911586725105, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.002638539166160997, 'dropout_rate_Layer_2': 0.2746836643983803, 'dropout_rate_Layer_3': 0.31302000215532055, 'dropout_rate_Layer_4': 0.012040302087372796, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0002471378328285084, 'l1_Layer_2': 0.00016889870765259351, 'l1_Layer_3': 0.0004349864700317892, 'l1_Layer_4': 3.368216487016488e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 190, 'n_units_Layer_3': 85, 'n_units_Layer_4': 175}. Best is trial 1235 with value: 3.6306467462473964.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.80 | sMAPE for Validation Set is: 11.13% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.74 | sMAPE for Test Set is: 17.88% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:32:25,398]\u001b[0m Trial 1457 finished with value: 3.8613693255685555 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010059753937934873, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09542623138706352, 'dropout_rate_Layer_2': 0.11410891371245233, 'dropout_rate_Layer_3': 0.14726618155510207, 'dropout_rate_Layer_4': 0.1677254854822629, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.08377231357238171, 'l1_Layer_2': 3.1337605658786546e-05, 'l1_Layer_3': 1.7027414935480633e-05, 'l1_Layer_4': 0.00039660140911472854, 'n_units_Layer_1': 260, 'n_units_Layer_2': 220, 'n_units_Layer_3': 270, 'n_units_Layer_4': 185}. Best is trial 1235 with value: 3.6306467462473964.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.86 | sMAPE for Validation Set is: 11.17% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.99 | sMAPE for Test Set is: 18.86% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:32:29,548]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:32:29,735]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:32:33,477]\u001b[0m Trial 1461 finished with value: 3.9297497599484537 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005052259826604347, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02294429958668125, 'dropout_rate_Layer_2': 0.262839656631824, 'dropout_rate_Layer_3': 0.3361681854765188, 'dropout_rate_Layer_4': 0.03530502138834555, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0001842445975713143, 'l1_Layer_2': 0.00019847929640502153, 'l1_Layer_3': 0.0002880565547385164, 'l1_Layer_4': 2.2375358047243396e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 210, 'n_units_Layer_3': 160, 'n_units_Layer_4': 165}. Best is trial 1235 with value: 3.6306467462473964.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.93 | sMAPE for Validation Set is: 11.38% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.99 | sMAPE for Test Set is: 18.52% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:32:39,726]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:32:41,067]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:32:47,882]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:32:50,885]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:32:57,593]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:33:00,781]\u001b[0m Trial 1458 finished with value: 3.811428932193493 and parameters: {'n_hidden': 4, 'learning_rate': 0.001081491651354484, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1164171242471743, 'dropout_rate_Layer_2': 0.11386222437931191, 'dropout_rate_Layer_3': 0.14496821852817943, 'dropout_rate_Layer_4': 0.17358668272191863, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.049102240298190034, 'l1_Layer_2': 3.73168533514177e-05, 'l1_Layer_3': 1.695590923025893e-05, 'l1_Layer_4': 0.00036896443641009486, 'n_units_Layer_1': 260, 'n_units_Layer_2': 225, 'n_units_Layer_3': 270, 'n_units_Layer_4': 190}. Best is trial 1235 with value: 3.6306467462473964.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.81 | sMAPE for Validation Set is: 11.04% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.22 | sMAPE for Test Set is: 19.64% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:33:01,793]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:33:17,888]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:33:25,882]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:33:32,777]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:33:36,962]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:33:39,707]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:33:44,063]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:33:48,495]\u001b[0m Trial 1471 finished with value: 3.9527626627605943 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008643701387190462, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11313288184321706, 'dropout_rate_Layer_2': 0.12808468606914308, 'dropout_rate_Layer_3': 0.1315720230833393, 'dropout_rate_Layer_4': 0.18266034300174788, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.049943477773872154, 'l1_Layer_2': 5.8314508555603964e-05, 'l1_Layer_3': 1.8068860260783043e-05, 'l1_Layer_4': 0.000601604203888097, 'n_units_Layer_1': 260, 'n_units_Layer_2': 215, 'n_units_Layer_3': 255, 'n_units_Layer_4': 190}. Best is trial 1235 with value: 3.6306467462473964.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.95 | sMAPE for Validation Set is: 11.35% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.80 | sMAPE for Test Set is: 18.16% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:34:02,648]\u001b[0m Trial 1473 finished with value: 3.81052154986774 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010886850168450055, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11417555781150808, 'dropout_rate_Layer_2': 0.1313724022664846, 'dropout_rate_Layer_3': 0.1293905828557887, 'dropout_rate_Layer_4': 0.16068423531777073, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.045284291755166815, 'l1_Layer_2': 5.705691756738206e-05, 'l1_Layer_3': 1.7818833731077904e-05, 'l1_Layer_4': 0.00032024787165610744, 'n_units_Layer_1': 260, 'n_units_Layer_2': 235, 'n_units_Layer_3': 255, 'n_units_Layer_4': 190}. Best is trial 1235 with value: 3.6306467462473964.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.81 | sMAPE for Validation Set is: 11.02% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.23 | sMAPE for Test Set is: 19.64% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:34:19,508]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:34:22,107]\u001b[0m Trial 1476 finished with value: 3.737519457389078 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005565152718902418, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1424485036586552, 'dropout_rate_Layer_2': 0.28798598420063526, 'dropout_rate_Layer_3': 0.13125077538523655, 'dropout_rate_Layer_4': 0.04703119646101515, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0011604008115400435, 'l1_Layer_2': 0.00010024652008926757, 'l1_Layer_3': 0.0004677101588016355, 'l1_Layer_4': 4.3757872211254056e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 205, 'n_units_Layer_3': 125, 'n_units_Layer_4': 190}. Best is trial 1235 with value: 3.6306467462473964.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.74 | sMAPE for Validation Set is: 10.92% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.93 | sMAPE for Test Set is: 18.68% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:34:27,600]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:34:27,786]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:34:34,138]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:34:34,524]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:34:39,705]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:34:40,075]\u001b[0m Trial 1479 finished with value: 3.8999262507312564 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007557781653093073, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12131301948704618, 'dropout_rate_Layer_2': 0.1430194305971495, 'dropout_rate_Layer_3': 0.12084322243079579, 'dropout_rate_Layer_4': 0.18766715929766767, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.05832109026879767, 'l1_Layer_2': 3.996266869568285e-05, 'l1_Layer_3': 2.4639648396279877e-05, 'l1_Layer_4': 0.0006956261478531202, 'n_units_Layer_1': 260, 'n_units_Layer_2': 220, 'n_units_Layer_3': 260, 'n_units_Layer_4': 190}. Best is trial 1235 with value: 3.6306467462473964.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.90 | sMAPE for Validation Set is: 11.17% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.91 | sMAPE for Test Set is: 18.57% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:34:45,415]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:34:45,739]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:34:46,234]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:34:55,055]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:34:55,137]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:34:55,332]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:35:05,293]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:35:05,563]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:35:10,405]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:35:15,256]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:35:15,915]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:35:17,652]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:35:21,471]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:35:23,210]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:35:24,529]\u001b[0m Trial 1480 finished with value: 3.8642138051365116 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007432238489896919, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10574664724621491, 'dropout_rate_Layer_2': 0.12514243112096948, 'dropout_rate_Layer_3': 0.12033156604739889, 'dropout_rate_Layer_4': 0.18902833547519415, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.037854755732443096, 'l1_Layer_2': 5.17719080710772e-05, 'l1_Layer_3': 2.4540969316388757e-05, 'l1_Layer_4': 0.000681186545663284, 'n_units_Layer_1': 265, 'n_units_Layer_2': 235, 'n_units_Layer_3': 250, 'n_units_Layer_4': 185}. Best is trial 1235 with value: 3.6306467462473964.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.86 | sMAPE for Validation Set is: 11.19% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.03 | sMAPE for Test Set is: 18.98% | rMAE for Test Set is: 0.83\n",
      "for 2020-01-01, MAE is:3.44 & sMAPE is:10.94% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :3.44 & 10.94% & 0.29\n",
      "for 2020-01-02, MAE is:7.44 & sMAPE is:20.50% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :5.44 & 15.72% & 0.52\n",
      "for 2020-01-03, MAE is:4.40 & sMAPE is:11.61% & rMAE is:2.28 ||| daily mean of MAE & sMAPE & rMAE till now are :5.09 & 14.35% & 1.11\n",
      "for 2020-01-04, MAE is:3.81 & sMAPE is:11.70% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :4.77 & 13.69% & 1.15\n",
      "for 2020-01-05, MAE is:4.53 & sMAPE is:12.77% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :4.72 & 13.50% & 1.03\n",
      "for 2020-01-06, MAE is:1.92 & sMAPE is:4.96% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :4.26 & 12.08% & 0.92\n",
      "for 2020-01-07, MAE is:4.87 & sMAPE is:11.93% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 12.06% & 0.86\n",
      "for 2020-01-08, MAE is:4.72 & sMAPE is:11.48% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 11.99% & 0.80\n",
      "for 2020-01-09, MAE is:2.98 & sMAPE is:7.08% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :4.23 & 11.44% & 0.77\n",
      "for 2020-01-10, MAE is:2.80 & sMAPE is:6.77% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :4.09 & 10.97% & 0.76\n",
      "for 2020-01-11, MAE is:3.36 & sMAPE is:8.46% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :4.02 & 10.74% & 0.74\n",
      "for 2020-01-12, MAE is:2.40 & sMAPE is:6.21% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :3.89 & 10.37% & 0.78\n",
      "for 2020-01-13, MAE is:3.91 & sMAPE is:9.01% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :3.89 & 10.26% & 0.81\n",
      "for 2020-01-14, MAE is:3.86 & sMAPE is:9.82% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :3.89 & 10.23% & 0.84\n",
      "for 2020-01-15, MAE is:3.18 & sMAPE is:7.83% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :3.84 & 10.07% & 0.85\n",
      "for 2020-01-16, MAE is:2.95 & sMAPE is:6.83% & rMAE is:2.46 ||| daily mean of MAE & sMAPE & rMAE till now are :3.79 & 9.87% & 0.95\n",
      "for 2020-01-17, MAE is:2.82 & sMAPE is:6.79% & rMAE is:2.28 ||| daily mean of MAE & sMAPE & rMAE till now are :3.73 & 9.69% & 1.03\n",
      "for 2020-01-18, MAE is:2.88 & sMAPE is:7.49% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :3.68 & 9.56% & 1.07\n",
      "for 2020-01-19, MAE is:4.48 & sMAPE is:11.90% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :3.72 & 9.69% & 1.10\n",
      "for 2020-01-20, MAE is:4.14 & sMAPE is:9.16% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :3.74 & 9.66% & 1.11\n",
      "for 2020-01-21, MAE is:3.86 & sMAPE is:8.24% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :3.75 & 9.59% & 1.10\n",
      "for 2020-01-22, MAE is:5.57 & sMAPE is:12.04% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :3.83 & 9.70% & 1.09\n",
      "for 2020-01-23, MAE is:6.63 & sMAPE is:13.09% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :3.95 & 9.85% & 1.08\n",
      "for 2020-01-24, MAE is:5.23 & sMAPE is:10.20% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.01 & 9.87% & 1.06\n",
      "for 2020-01-25, MAE is:3.84 & sMAPE is:9.36% & rMAE is:1.88 ||| daily mean of MAE & sMAPE & rMAE till now are :4.00 & 9.85% & 1.10\n",
      "for 2020-01-26, MAE is:5.42 & sMAPE is:14.93% & rMAE is:5.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.06 & 10.04% & 1.26\n",
      "for 2020-01-27, MAE is:2.73 & sMAPE is:6.46% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :4.01 & 9.91% & 1.25\n",
      "for 2020-01-28, MAE is:4.38 & sMAPE is:9.96% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :4.02 & 9.91% & 1.24\n",
      "for 2020-01-29, MAE is:4.25 & sMAPE is:9.99% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :4.03 & 9.91% & 1.21\n",
      "for 2020-01-30, MAE is:3.39 & sMAPE is:8.63% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :4.01 & 9.87% & 1.18\n",
      "for 2020-01-31, MAE is:1.86 & sMAPE is:4.78% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :3.94 & 9.71% & 1.15\n",
      "for 2020-02-01, MAE is:4.39 & sMAPE is:12.19% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :3.95 & 9.78% & 1.14\n",
      "for 2020-02-02, MAE is:3.67 & sMAPE is:11.30% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :3.94 & 9.83% & 1.13\n",
      "for 2020-02-03, MAE is:3.99 & sMAPE is:12.06% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :3.94 & 9.90% & 1.11\n",
      "for 2020-02-04, MAE is:2.86 & sMAPE is:8.45% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :3.91 & 9.85% & 1.09\n",
      "for 2020-02-05, MAE is:3.43 & sMAPE is:9.86% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :3.90 & 9.85% & 1.09\n",
      "for 2020-02-06, MAE is:4.09 & sMAPE is:10.75% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :3.90 & 9.88% & 1.09\n",
      "for 2020-02-07, MAE is:3.09 & sMAPE is:7.75% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :3.88 & 9.82% & 1.09\n",
      "for 2020-02-08, MAE is:2.98 & sMAPE is:8.66% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :3.86 & 9.79% & 1.08\n",
      "for 2020-02-09, MAE is:3.68 & sMAPE is:11.92% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :3.86 & 9.85% & 1.09\n",
      "for 2020-02-10, MAE is:3.69 & sMAPE is:13.21% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :3.85 & 9.93% & 1.10\n",
      "for 2020-02-11, MAE is:2.41 & sMAPE is:7.91% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :3.82 & 9.88% & 1.09\n",
      "for 2020-02-12, MAE is:3.15 & sMAPE is:8.87% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :3.80 & 9.86% & 1.08\n",
      "for 2020-02-13, MAE is:3.37 & sMAPE is:9.65% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :3.79 & 9.85% & 1.08\n",
      "for 2020-02-14, MAE is:2.76 & sMAPE is:7.60% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :3.77 & 9.80% & 1.07\n",
      "for 2020-02-15, MAE is:3.75 & sMAPE is:12.77% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :3.77 & 9.87% & 1.07\n",
      "for 2020-02-16, MAE is:2.85 & sMAPE is:10.38% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :3.75 & 9.88% & 1.06\n",
      "for 2020-02-17, MAE is:2.48 & sMAPE is:7.51% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :3.72 & 9.83% & 1.06\n",
      "for 2020-02-18, MAE is:2.95 & sMAPE is:9.57% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :3.71 & 9.82% & 1.06\n",
      "for 2020-02-19, MAE is:2.99 & sMAPE is:9.01% & rMAE is:1.94 ||| daily mean of MAE & sMAPE & rMAE till now are :3.69 & 9.81% & 1.08\n",
      "for 2020-02-20, MAE is:2.77 & sMAPE is:8.25% & rMAE is:1.62 ||| daily mean of MAE & sMAPE & rMAE till now are :3.67 & 9.78% & 1.09\n",
      "for 2020-02-21, MAE is:3.00 & sMAPE is:9.21% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :3.66 & 9.76% & 1.09\n",
      "for 2020-02-22, MAE is:3.46 & sMAPE is:10.94% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :3.66 & 9.79% & 1.09\n",
      "for 2020-02-23, MAE is:4.53 & sMAPE is:19.35% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :3.67 & 9.96% & 1.09\n",
      "for 2020-02-24, MAE is:3.54 & sMAPE is:11.75% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :3.67 & 10.00% & 1.09\n",
      "for 2020-02-25, MAE is:5.07 & sMAPE is:16.60% & rMAE is:4.06 ||| daily mean of MAE & sMAPE & rMAE till now are :3.70 & 10.11% & 1.15\n",
      "for 2020-02-26, MAE is:3.04 & sMAPE is:9.16% & rMAE is:2.37 ||| daily mean of MAE & sMAPE & rMAE till now are :3.69 & 10.10% & 1.17\n",
      "for 2020-02-27, MAE is:3.93 & sMAPE is:10.42% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :3.69 & 10.10% & 1.17\n",
      "for 2020-02-28, MAE is:1.97 & sMAPE is:5.59% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :3.66 & 10.03% & 1.16\n",
      "for 2020-02-29, MAE is:2.37 & sMAPE is:8.04% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :3.64 & 9.99% & 1.16\n",
      "for 2020-03-01, MAE is:5.84 & sMAPE is:26.17% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :3.67 & 10.26% & 1.16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-03-02, MAE is:5.02 & sMAPE is:14.84% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :3.70 & 10.33% & 1.17\n",
      "for 2020-03-03, MAE is:4.07 & sMAPE is:11.30% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :3.70 & 10.35% & 1.17\n",
      "for 2020-03-04, MAE is:5.54 & sMAPE is:14.02% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :3.73 & 10.41% & 1.17\n",
      "for 2020-03-05, MAE is:3.31 & sMAPE is:8.68% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :3.72 & 10.38% & 1.16\n",
      "for 2020-03-06, MAE is:2.28 & sMAPE is:7.08% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :3.70 & 10.33% & 1.16\n",
      "for 2020-03-07, MAE is:2.97 & sMAPE is:10.24% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :3.69 & 10.33% & 1.16\n",
      "for 2020-03-08, MAE is:3.56 & sMAPE is:15.85% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :3.69 & 10.41% & 1.17\n",
      "for 2020-03-09, MAE is:3.25 & sMAPE is:9.15% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :3.68 & 10.39% & 1.17\n",
      "for 2020-03-10, MAE is:2.77 & sMAPE is:8.42% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :3.67 & 10.36% & 1.17\n",
      "for 2020-03-11, MAE is:3.66 & sMAPE is:12.18% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :3.67 & 10.39% & 1.16\n",
      "for 2020-03-12, MAE is:3.96 & sMAPE is:11.73% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :3.67 & 10.41% & 1.15\n",
      "for 2020-03-13, MAE is:2.16 & sMAPE is:6.53% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :3.65 & 10.35% & 1.15\n",
      "for 2020-03-14, MAE is:4.42 & sMAPE is:14.87% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :3.66 & 10.41% & 1.15\n",
      "for 2020-03-15, MAE is:11.92 & sMAPE is:79.14% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :3.77 & 11.33% & 1.15\n",
      "for 2020-03-16, MAE is:4.64 & sMAPE is:13.92% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :3.79 & 11.37% & 1.15\n",
      "for 2020-03-17, MAE is:3.70 & sMAPE is:12.06% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :3.78 & 11.37% & 1.15\n",
      "for 2020-03-18, MAE is:3.60 & sMAPE is:13.51% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :3.78 & 11.40% & 1.14\n",
      "for 2020-03-19, MAE is:4.08 & sMAPE is:13.71% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :3.79 & 11.43% & 1.14\n",
      "for 2020-03-20, MAE is:4.43 & sMAPE is:17.15% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :3.79 & 11.50% & 1.13\n",
      "for 2020-03-21, MAE is:3.95 & sMAPE is:24.18% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :3.80 & 11.66% & 1.12\n",
      "for 2020-03-22, MAE is:9.62 & sMAPE is:81.93% & rMAE is:2.07 ||| daily mean of MAE & sMAPE & rMAE till now are :3.87 & 12.52% & 1.13\n",
      "for 2020-03-23, MAE is:6.98 & sMAPE is:31.38% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :3.90 & 12.74% & 1.13\n",
      "for 2020-03-24, MAE is:5.46 & sMAPE is:25.04% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :3.92 & 12.89% & 1.12\n",
      "for 2020-03-25, MAE is:3.72 & sMAPE is:16.12% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :3.92 & 12.93% & 1.12\n",
      "for 2020-03-26, MAE is:3.92 & sMAPE is:16.49% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :3.92 & 12.97% & 1.11\n",
      "for 2020-03-27, MAE is:3.76 & sMAPE is:15.32% & rMAE is:1.79 ||| daily mean of MAE & sMAPE & rMAE till now are :3.92 & 13.00% & 1.12\n",
      "for 2020-03-28, MAE is:7.20 & sMAPE is:48.96% & rMAE is:2.46 ||| daily mean of MAE & sMAPE & rMAE till now are :3.96 & 13.40% & 1.13\n",
      "for 2020-03-29, MAE is:6.12 & sMAPE is:64.09% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :3.98 & 13.97% & 1.14\n",
      "for 2020-03-30, MAE is:3.15 & sMAPE is:14.92% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :3.97 & 13.98% & 1.14\n",
      "for 2020-03-31, MAE is:4.96 & sMAPE is:18.80% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :3.98 & 14.04% & 1.13\n",
      "for 2020-04-01, MAE is:4.71 & sMAPE is:19.93% & rMAE is:2.56 ||| daily mean of MAE & sMAPE & rMAE till now are :3.99 & 14.10% & 1.15\n",
      "for 2020-04-02, MAE is:3.50 & sMAPE is:15.42% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :3.98 & 14.12% & 1.15\n",
      "for 2020-04-03, MAE is:2.23 & sMAPE is:9.81% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :3.97 & 14.07% & 1.15\n",
      "for 2020-04-04, MAE is:3.38 & sMAPE is:17.95% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :3.96 & 14.11% & 1.15\n",
      "for 2020-04-05, MAE is:7.91 & sMAPE is:83.59% & rMAE is:1.67 ||| daily mean of MAE & sMAPE & rMAE till now are :4.00 & 14.83% & 1.15\n",
      "for 2020-04-06, MAE is:4.53 & sMAPE is:29.34% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :4.01 & 14.98% & 1.15\n",
      "for 2020-04-07, MAE is:3.51 & sMAPE is:17.38% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :4.00 & 15.01% & 1.14\n",
      "for 2020-04-08, MAE is:3.83 & sMAPE is:17.38% & rMAE is:2.30 ||| daily mean of MAE & sMAPE & rMAE till now are :4.00 & 15.03% & 1.16\n",
      "for 2020-04-09, MAE is:4.39 & sMAPE is:20.16% & rMAE is:1.77 ||| daily mean of MAE & sMAPE & rMAE till now are :4.00 & 15.08% & 1.16\n",
      "for 2020-04-10, MAE is:3.43 & sMAPE is:20.63% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :4.00 & 15.14% & 1.16\n",
      "for 2020-04-11, MAE is:3.36 & sMAPE is:23.58% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :3.99 & 15.22% & 1.16\n",
      "for 2020-04-12, MAE is:5.28 & sMAPE is:54.83% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :4.00 & 15.61% & 1.15\n",
      "for 2020-04-13, MAE is:21.01 & sMAPE is:153.60% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :4.17 & 16.93% & 1.15\n",
      "for 2020-04-14, MAE is:6.59 & sMAPE is:41.98% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 17.17% & 1.16\n",
      "for 2020-04-15, MAE is:5.22 & sMAPE is:30.32% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 17.30% & 1.16\n",
      "for 2020-04-16, MAE is:3.96 & sMAPE is:18.76% & rMAE is:1.90 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 17.31% & 1.17\n",
      "for 2020-04-17, MAE is:2.89 & sMAPE is:12.41% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 17.26% & 1.16\n",
      "for 2020-04-18, MAE is:2.83 & sMAPE is:15.44% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :4.17 & 17.25% & 1.16\n",
      "for 2020-04-19, MAE is:6.31 & sMAPE is:71.12% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 17.74% & 1.17\n",
      "for 2020-04-20, MAE is:4.90 & sMAPE is:56.96% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 18.09% & 1.16\n",
      "for 2020-04-21, MAE is:5.89 & sMAPE is:55.26% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :4.21 & 18.42% & 1.15\n",
      "for 2020-04-22, MAE is:5.09 & sMAPE is:48.53% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :4.22 & 18.69% & 1.15\n",
      "for 2020-04-23, MAE is:2.72 & sMAPE is:14.65% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :4.21 & 18.65% & 1.15\n",
      "for 2020-04-24, MAE is:5.69 & sMAPE is:35.33% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :4.22 & 18.80% & 1.15\n",
      "for 2020-04-25, MAE is:3.28 & sMAPE is:21.58% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :4.21 & 18.82% & 1.14\n",
      "for 2020-04-26, MAE is:3.94 & sMAPE is:28.72% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.21 & 18.91% & 1.14\n",
      "for 2020-04-27, MAE is:2.59 & sMAPE is:11.33% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 18.84% & 1.13\n",
      "for 2020-04-28, MAE is:2.69 & sMAPE is:11.00% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :4.18 & 18.78% & 1.12\n",
      "for 2020-04-29, MAE is:1.87 & sMAPE is:8.00% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :4.17 & 18.69% & 1.11\n",
      "for 2020-04-30, MAE is:3.05 & sMAPE is:16.42% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :4.16 & 18.67% & 1.11\n",
      "for 2020-05-01, MAE is:8.50 & sMAPE is:92.21% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 19.27% & 1.11\n",
      "for 2020-05-02, MAE is:3.61 & sMAPE is:30.27% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 19.36% & 1.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-05-03, MAE is:2.95 & sMAPE is:22.30% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :4.18 & 19.38% & 1.11\n",
      "for 2020-05-04, MAE is:3.68 & sMAPE is:17.77% & rMAE is:1.86 ||| daily mean of MAE & sMAPE & rMAE till now are :4.17 & 19.37% & 1.12\n",
      "for 2020-05-05, MAE is:2.86 & sMAPE is:12.72% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :4.16 & 19.32% & 1.12\n",
      "for 2020-05-06, MAE is:3.07 & sMAPE is:14.49% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :4.15 & 19.28% & 1.12\n",
      "for 2020-05-07, MAE is:2.73 & sMAPE is:12.36% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :4.14 & 19.23% & 1.11\n",
      "for 2020-05-08, MAE is:2.86 & sMAPE is:13.21% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :4.13 & 19.18% & 1.11\n",
      "for 2020-05-09, MAE is:3.69 & sMAPE is:20.73% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.13 & 19.19% & 1.10\n",
      "for 2020-05-10, MAE is:2.92 & sMAPE is:20.88% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :4.12 & 19.20% & 1.10\n",
      "for 2020-05-11, MAE is:3.85 & sMAPE is:36.04% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :4.12 & 19.33% & 1.09\n",
      "for 2020-05-12, MAE is:3.75 & sMAPE is:19.12% & rMAE is:3.83 ||| daily mean of MAE & sMAPE & rMAE till now are :4.12 & 19.33% & 1.11\n",
      "for 2020-05-13, MAE is:4.92 & sMAPE is:21.38% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :4.12 & 19.35% & 1.11\n",
      "for 2020-05-14, MAE is:2.31 & sMAPE is:10.07% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :4.11 & 19.28% & 1.11\n",
      "for 2020-05-15, MAE is:1.47 & sMAPE is:6.66% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :4.09 & 19.18% & 1.11\n",
      "for 2020-05-16, MAE is:2.01 & sMAPE is:14.21% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.07 & 19.15% & 1.10\n",
      "for 2020-05-17, MAE is:6.71 & sMAPE is:65.29% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :4.09 & 19.48% & 1.10\n",
      "for 2020-05-18, MAE is:1.86 & sMAPE is:9.33% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :4.08 & 19.41% & 1.10\n",
      "for 2020-05-19, MAE is:2.64 & sMAPE is:12.41% & rMAE is:2.19 ||| daily mean of MAE & sMAPE & rMAE till now are :4.07 & 19.36% & 1.10\n",
      "for 2020-05-20, MAE is:2.33 & sMAPE is:10.87% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :4.05 & 19.30% & 1.10\n",
      "for 2020-05-21, MAE is:3.06 & sMAPE is:17.19% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :4.05 & 19.28% & 1.10\n",
      "for 2020-05-22, MAE is:2.60 & sMAPE is:14.27% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 19.25% & 1.10\n",
      "for 2020-05-23, MAE is:4.79 & sMAPE is:54.90% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 19.50% & 1.09\n",
      "for 2020-05-24, MAE is:21.99 & sMAPE is:147.11% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :4.17 & 20.38% & 1.09\n",
      "for 2020-05-25, MAE is:7.65 & sMAPE is:45.59% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 20.55% & 1.10\n",
      "for 2020-05-26, MAE is:2.33 & sMAPE is:11.93% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :4.18 & 20.49% & 1.09\n",
      "for 2020-05-27, MAE is:3.11 & sMAPE is:15.56% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :4.17 & 20.46% & 1.10\n",
      "for 2020-05-28, MAE is:1.80 & sMAPE is:9.23% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :4.15 & 20.38% & 1.09\n",
      "for 2020-05-29, MAE is:2.49 & sMAPE is:12.03% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :4.14 & 20.33% & 1.09\n",
      "for 2020-05-30, MAE is:2.99 & sMAPE is:23.38% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :4.14 & 20.35% & 1.09\n",
      "for 2020-05-31, MAE is:6.54 & sMAPE is:71.02% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :4.15 & 20.68% & 1.08\n",
      "for 2020-06-01, MAE is:7.67 & sMAPE is:74.64% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :4.17 & 21.03% & 1.08\n",
      "for 2020-06-02, MAE is:2.42 & sMAPE is:14.11% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :4.16 & 20.99% & 1.08\n",
      "for 2020-06-03, MAE is:3.54 & sMAPE is:16.92% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.16 & 20.96% & 1.08\n",
      "for 2020-06-04, MAE is:2.43 & sMAPE is:10.14% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.15 & 20.89% & 1.08\n",
      "for 2020-06-05, MAE is:4.27 & sMAPE is:19.10% & rMAE is:1.73 ||| daily mean of MAE & sMAPE & rMAE till now are :4.15 & 20.88% & 1.08\n",
      "for 2020-06-06, MAE is:7.97 & sMAPE is:73.64% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :4.17 & 21.21% & 1.08\n",
      "for 2020-06-07, MAE is:3.59 & sMAPE is:25.36% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :4.17 & 21.24% & 1.08\n",
      "for 2020-06-08, MAE is:9.43 & sMAPE is:35.96% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 21.33% & 1.07\n",
      "for 2020-06-09, MAE is:2.83 & sMAPE is:9.28% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 21.26% & 1.07\n",
      "for 2020-06-10, MAE is:4.79 & sMAPE is:17.04% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 21.23% & 1.07\n",
      "for 2020-06-11, MAE is:1.70 & sMAPE is:6.60% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :4.18 & 21.14% & 1.07\n",
      "for 2020-06-12, MAE is:1.96 & sMAPE is:8.80% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :4.17 & 21.07% & 1.06\n",
      "for 2020-06-13, MAE is:7.61 & sMAPE is:47.83% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 21.23% & 1.06\n",
      "for 2020-06-14, MAE is:2.80 & sMAPE is:18.69% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :4.18 & 21.21% & 1.06\n",
      "for 2020-06-15, MAE is:6.39 & sMAPE is:23.35% & rMAE is:2.70 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 21.23% & 1.07\n",
      "for 2020-06-16, MAE is:7.74 & sMAPE is:25.29% & rMAE is:2.75 ||| daily mean of MAE & sMAPE & rMAE till now are :4.22 & 21.25% & 1.08\n",
      "for 2020-06-17, MAE is:1.35 & sMAPE is:4.12% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 21.15% & 1.08\n",
      "for 2020-06-18, MAE is:2.29 & sMAPE is:7.60% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 21.07% & 1.07\n",
      "for 2020-06-19, MAE is:3.88 & sMAPE is:13.73% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 21.03% & 1.07\n",
      "for 2020-06-20, MAE is:2.95 & sMAPE is:13.84% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :4.18 & 20.98% & 1.07\n",
      "for 2020-06-21, MAE is:3.29 & sMAPE is:17.76% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :4.17 & 20.97% & 1.07\n",
      "for 2020-06-22, MAE is:2.75 & sMAPE is:9.53% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :4.16 & 20.90% & 1.07\n",
      "for 2020-06-23, MAE is:3.06 & sMAPE is:9.44% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :4.16 & 20.84% & 1.07\n",
      "for 2020-06-24, MAE is:3.45 & sMAPE is:10.26% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :4.15 & 20.77% & 1.07\n",
      "for 2020-06-25, MAE is:2.35 & sMAPE is:6.57% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.14 & 20.69% & 1.07\n",
      "for 2020-06-26, MAE is:3.30 & sMAPE is:9.34% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.14 & 20.63% & 1.06\n",
      "for 2020-06-27, MAE is:2.36 & sMAPE is:8.52% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.13 & 20.56% & 1.06\n",
      "for 2020-06-28, MAE is:4.39 & sMAPE is:26.68% & rMAE is:2.34 ||| daily mean of MAE & sMAPE & rMAE till now are :4.13 & 20.60% & 1.07\n",
      "for 2020-06-29, MAE is:1.99 & sMAPE is:7.13% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :4.12 & 20.52% & 1.07\n",
      "for 2020-06-30, MAE is:2.84 & sMAPE is:9.87% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :4.11 & 20.46% & 1.06\n",
      "for 2020-07-01, MAE is:4.84 & sMAPE is:14.57% & rMAE is:4.12 ||| daily mean of MAE & sMAPE & rMAE till now are :4.12 & 20.43% & 1.08\n",
      "for 2020-07-02, MAE is:2.41 & sMAPE is:6.36% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :4.11 & 20.36% & 1.08\n",
      "for 2020-07-03, MAE is:3.33 & sMAPE is:9.12% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :4.10 & 20.29% & 1.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-07-04, MAE is:3.08 & sMAPE is:15.11% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :4.10 & 20.27% & 1.08\n",
      "for 2020-07-05, MAE is:8.91 & sMAPE is:92.52% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :4.12 & 20.65% & 1.08\n",
      "for 2020-07-06, MAE is:2.40 & sMAPE is:11.76% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :4.11 & 20.61% & 1.08\n",
      "for 2020-07-07, MAE is:7.72 & sMAPE is:25.60% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :4.13 & 20.63% & 1.08\n",
      "for 2020-07-08, MAE is:4.01 & sMAPE is:10.97% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :4.13 & 20.58% & 1.08\n",
      "for 2020-07-09, MAE is:4.92 & sMAPE is:12.55% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :4.14 & 20.54% & 1.08\n",
      "for 2020-07-10, MAE is:1.85 & sMAPE is:4.77% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.12 & 20.46% & 1.08\n",
      "for 2020-07-11, MAE is:2.91 & sMAPE is:10.26% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :4.12 & 20.40% & 1.07\n",
      "for 2020-07-12, MAE is:4.83 & sMAPE is:20.53% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :4.12 & 20.41% & 1.07\n",
      "for 2020-07-13, MAE is:3.96 & sMAPE is:11.35% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :4.12 & 20.36% & 1.06\n",
      "for 2020-07-14, MAE is:2.08 & sMAPE is:5.54% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :4.11 & 20.28% & 1.06\n",
      "for 2020-07-15, MAE is:5.21 & sMAPE is:14.19% & rMAE is:3.51 ||| daily mean of MAE & sMAPE & rMAE till now are :4.12 & 20.25% & 1.08\n",
      "for 2020-07-16, MAE is:5.98 & sMAPE is:15.49% & rMAE is:2.67 ||| daily mean of MAE & sMAPE & rMAE till now are :4.13 & 20.23% & 1.09\n",
      "for 2020-07-17, MAE is:4.06 & sMAPE is:10.70% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :4.13 & 20.18% & 1.09\n",
      "for 2020-07-18, MAE is:2.00 & sMAPE is:7.01% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :4.11 & 20.11% & 1.09\n",
      "for 2020-07-19, MAE is:3.12 & sMAPE is:12.34% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :4.11 & 20.08% & 1.09\n",
      "for 2020-07-20, MAE is:4.00 & sMAPE is:12.18% & rMAE is:2.83 ||| daily mean of MAE & sMAPE & rMAE till now are :4.11 & 20.04% & 1.10\n",
      "for 2020-07-21, MAE is:2.75 & sMAPE is:7.83% & rMAE is:2.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.10 & 19.98% & 1.11\n",
      "for 2020-07-22, MAE is:2.55 & sMAPE is:6.96% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :4.09 & 19.91% & 1.11\n",
      "for 2020-07-23, MAE is:2.70 & sMAPE is:7.30% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :4.09 & 19.85% & 1.11\n",
      "for 2020-07-24, MAE is:1.68 & sMAPE is:4.87% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :4.08 & 19.78% & 1.10\n",
      "for 2020-07-25, MAE is:2.79 & sMAPE is:9.20% & rMAE is:3.18 ||| daily mean of MAE & sMAPE & rMAE till now are :4.07 & 19.73% & 1.11\n",
      "for 2020-07-26, MAE is:6.04 & sMAPE is:36.29% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :4.08 & 19.81% & 1.11\n",
      "for 2020-07-27, MAE is:5.43 & sMAPE is:18.76% & rMAE is:2.68 ||| daily mean of MAE & sMAPE & rMAE till now are :4.09 & 19.80% & 1.12\n",
      "for 2020-07-28, MAE is:2.11 & sMAPE is:6.78% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :4.08 & 19.74% & 1.12\n",
      "for 2020-07-29, MAE is:5.99 & sMAPE is:19.57% & rMAE is:2.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.09 & 19.74% & 1.12\n",
      "for 2020-07-30, MAE is:4.15 & sMAPE is:11.36% & rMAE is:2.70 ||| daily mean of MAE & sMAPE & rMAE till now are :4.09 & 19.70% & 1.13\n",
      "for 2020-07-31, MAE is:4.32 & sMAPE is:10.92% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :4.09 & 19.66% & 1.13\n",
      "for 2020-08-01, MAE is:2.74 & sMAPE is:7.98% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :4.08 & 19.60% & 1.13\n",
      "for 2020-08-02, MAE is:3.43 & sMAPE is:12.54% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :4.08 & 19.57% & 1.12\n",
      "for 2020-08-03, MAE is:7.14 & sMAPE is:21.10% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :4.09 & 19.58% & 1.13\n",
      "for 2020-08-04, MAE is:2.90 & sMAPE is:8.35% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :4.09 & 19.53% & 1.13\n",
      "for 2020-08-05, MAE is:3.32 & sMAPE is:9.87% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :4.08 & 19.48% & 1.13\n",
      "for 2020-08-06, MAE is:3.58 & sMAPE is:10.13% & rMAE is:1.75 ||| daily mean of MAE & sMAPE & rMAE till now are :4.08 & 19.44% & 1.13\n",
      "for 2020-08-07, MAE is:3.45 & sMAPE is:9.96% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :4.08 & 19.40% & 1.13\n",
      "for 2020-08-08, MAE is:3.07 & sMAPE is:9.78% & rMAE is:1.83 ||| daily mean of MAE & sMAPE & rMAE till now are :4.07 & 19.35% & 1.13\n",
      "for 2020-08-09, MAE is:2.81 & sMAPE is:9.92% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :4.07 & 19.31% & 1.13\n",
      "for 2020-08-10, MAE is:3.42 & sMAPE is:9.23% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :4.06 & 19.27% & 1.13\n",
      "for 2020-08-11, MAE is:3.25 & sMAPE is:8.56% & rMAE is:2.18 ||| daily mean of MAE & sMAPE & rMAE till now are :4.06 & 19.22% & 1.14\n",
      "for 2020-08-12, MAE is:5.03 & sMAPE is:14.90% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :4.07 & 19.20% & 1.14\n",
      "for 2020-08-13, MAE is:5.42 & sMAPE is:14.61% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.07 & 19.18% & 1.14\n",
      "for 2020-08-14, MAE is:1.94 & sMAPE is:5.16% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :4.06 & 19.12% & 1.14\n",
      "for 2020-08-15, MAE is:2.02 & sMAPE is:6.81% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :4.05 & 19.06% & 1.14\n",
      "for 2020-08-16, MAE is:1.93 & sMAPE is:7.03% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 19.01% & 1.14\n",
      "for 2020-08-17, MAE is:5.58 & sMAPE is:15.83% & rMAE is:2.92 ||| daily mean of MAE & sMAPE & rMAE till now are :4.05 & 19.00% & 1.15\n",
      "for 2020-08-18, MAE is:5.43 & sMAPE is:14.32% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :4.06 & 18.98% & 1.15\n",
      "for 2020-08-19, MAE is:3.84 & sMAPE is:9.49% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :4.06 & 18.93% & 1.15\n",
      "for 2020-08-20, MAE is:3.34 & sMAPE is:9.03% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :4.05 & 18.89% & 1.15\n",
      "for 2020-08-21, MAE is:2.30 & sMAPE is:6.76% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 18.84% & 1.15\n",
      "for 2020-08-22, MAE is:2.47 & sMAPE is:9.47% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 18.80% & 1.15\n",
      "for 2020-08-23, MAE is:5.83 & sMAPE is:28.33% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :4.05 & 18.84% & 1.15\n",
      "for 2020-08-24, MAE is:4.21 & sMAPE is:11.08% & rMAE is:1.75 ||| daily mean of MAE & sMAPE & rMAE till now are :4.05 & 18.81% & 1.15\n",
      "for 2020-08-25, MAE is:5.05 & sMAPE is:12.52% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :4.05 & 18.78% & 1.15\n",
      "for 2020-08-26, MAE is:2.41 & sMAPE is:8.54% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 18.74% & 1.15\n",
      "for 2020-08-27, MAE is:17.05 & sMAPE is:40.02% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :4.10 & 18.83% & 1.15\n",
      "for 2020-08-28, MAE is:4.92 & sMAPE is:10.46% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.10 & 18.79% & 1.14\n",
      "for 2020-08-29, MAE is:4.04 & sMAPE is:11.19% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :4.10 & 18.76% & 1.14\n",
      "for 2020-08-30, MAE is:2.98 & sMAPE is:9.63% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :4.10 & 18.72% & 1.14\n",
      "for 2020-08-31, MAE is:14.17 & sMAPE is:30.92% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.14 & 18.77% & 1.14\n",
      "for 2020-09-01, MAE is:5.90 & sMAPE is:10.84% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.14 & 18.74% & 1.13\n",
      "for 2020-09-02, MAE is:6.61 & sMAPE is:13.38% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.15 & 18.72% & 1.13\n",
      "for 2020-09-03, MAE is:4.20 & sMAPE is:9.53% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.16 & 18.68% & 1.13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-09-04, MAE is:5.33 & sMAPE is:12.89% & rMAE is:2.12 ||| daily mean of MAE & sMAPE & rMAE till now are :4.16 & 18.66% & 1.13\n",
      "for 2020-09-05, MAE is:2.23 & sMAPE is:6.48% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :4.15 & 18.61% & 1.13\n",
      "for 2020-09-06, MAE is:6.34 & sMAPE is:19.27% & rMAE is:2.19 ||| daily mean of MAE & sMAPE & rMAE till now are :4.16 & 18.61% & 1.14\n",
      "for 2020-09-07, MAE is:4.26 & sMAPE is:9.53% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.16 & 18.58% & 1.14\n",
      "for 2020-09-08, MAE is:3.35 & sMAPE is:7.76% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :4.16 & 18.53% & 1.13\n",
      "for 2020-09-09, MAE is:2.52 & sMAPE is:5.81% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :4.15 & 18.48% & 1.13\n",
      "for 2020-09-10, MAE is:12.11 & sMAPE is:26.10% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :4.18 & 18.51% & 1.13\n",
      "for 2020-09-11, MAE is:4.93 & sMAPE is:10.45% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 18.48% & 1.13\n",
      "for 2020-09-12, MAE is:1.75 & sMAPE is:4.42% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :4.18 & 18.43% & 1.13\n",
      "for 2020-09-13, MAE is:2.48 & sMAPE is:6.55% & rMAE is:1.83 ||| daily mean of MAE & sMAPE & rMAE till now are :4.17 & 18.38% & 1.13\n",
      "for 2020-09-14, MAE is:9.47 & sMAPE is:17.80% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 18.38% & 1.13\n",
      "for 2020-09-15, MAE is:12.70 & sMAPE is:18.96% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :4.22 & 18.38% & 1.13\n",
      "for 2020-09-16, MAE is:10.25 & sMAPE is:18.04% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :4.25 & 18.38% & 1.13\n",
      "for 2020-09-17, MAE is:12.22 & sMAPE is:25.28% & rMAE is:3.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.28 & 18.41% & 1.14\n",
      "for 2020-09-18, MAE is:4.50 & sMAPE is:9.33% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :4.28 & 18.37% & 1.14\n",
      "for 2020-09-19, MAE is:3.18 & sMAPE is:7.97% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :4.27 & 18.33% & 1.14\n",
      "for 2020-09-20, MAE is:4.76 & sMAPE is:12.79% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :4.28 & 18.31% & 1.15\n",
      "for 2020-09-21, MAE is:11.72 & sMAPE is:19.08% & rMAE is:2.48 ||| daily mean of MAE & sMAPE & rMAE till now are :4.30 & 18.31% & 1.15\n",
      "for 2020-09-22, MAE is:7.22 & sMAPE is:12.29% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :4.31 & 18.29% & 1.15\n",
      "for 2020-09-23, MAE is:3.31 & sMAPE is:6.55% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :4.31 & 18.25% & 1.15\n",
      "for 2020-09-24, MAE is:2.37 & sMAPE is:5.70% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :4.30 & 18.20% & 1.15\n",
      "for 2020-09-25, MAE is:5.82 & sMAPE is:13.67% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :4.31 & 18.18% & 1.15\n",
      "for 2020-09-26, MAE is:4.49 & sMAPE is:13.69% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :4.31 & 18.17% & 1.14\n",
      "for 2020-09-27, MAE is:6.84 & sMAPE is:21.31% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :4.32 & 18.18% & 1.14\n",
      "for 2020-09-28, MAE is:9.85 & sMAPE is:19.84% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 18.18% & 1.15\n",
      "for 2020-09-29, MAE is:5.80 & sMAPE is:10.19% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 18.15% & 1.15\n",
      "for 2020-09-30, MAE is:5.54 & sMAPE is:10.65% & rMAE is:2.23 ||| daily mean of MAE & sMAPE & rMAE till now are :4.35 & 18.13% & 1.15\n",
      "for 2020-10-01, MAE is:4.45 & sMAPE is:9.71% & rMAE is:2.03 ||| daily mean of MAE & sMAPE & rMAE till now are :4.35 & 18.10% & 1.15\n",
      "for 2020-10-02, MAE is:6.99 & sMAPE is:17.38% & rMAE is:2.18 ||| daily mean of MAE & sMAPE & rMAE till now are :4.36 & 18.09% & 1.16\n",
      "for 2020-10-03, MAE is:3.99 & sMAPE is:14.80% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :4.36 & 18.08% & 1.16\n",
      "for 2020-10-04, MAE is:10.12 & sMAPE is:70.57% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :4.38 & 18.27% & 1.15\n",
      "for 2020-10-05, MAE is:4.69 & sMAPE is:18.72% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :4.38 & 18.27% & 1.15\n",
      "for 2020-10-06, MAE is:3.91 & sMAPE is:13.21% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :4.38 & 18.25% & 1.15\n",
      "for 2020-10-07, MAE is:8.29 & sMAPE is:22.87% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 18.27% & 1.15\n",
      "for 2020-10-08, MAE is:4.23 & sMAPE is:12.62% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 18.25% & 1.14\n",
      "for 2020-10-09, MAE is:14.91 & sMAPE is:40.44% & rMAE is:4.79 ||| daily mean of MAE & sMAPE & rMAE till now are :4.43 & 18.33% & 1.16\n",
      "for 2020-10-10, MAE is:4.35 & sMAPE is:13.12% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :4.43 & 18.31% & 1.15\n",
      "for 2020-10-11, MAE is:5.21 & sMAPE is:17.80% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :4.43 & 18.31% & 1.15\n",
      "for 2020-10-12, MAE is:15.18 & sMAPE is:34.14% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :4.47 & 18.36% & 1.15\n",
      "for 2020-10-13, MAE is:7.87 & sMAPE is:16.83% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :4.48 & 18.36% & 1.15\n",
      "for 2020-10-14, MAE is:2.17 & sMAPE is:5.42% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :4.47 & 18.31% & 1.15\n",
      "for 2020-10-15, MAE is:5.11 & sMAPE is:11.74% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :4.47 & 18.29% & 1.15\n",
      "for 2020-10-16, MAE is:6.34 & sMAPE is:13.55% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :4.48 & 18.28% & 1.15\n",
      "for 2020-10-17, MAE is:6.91 & sMAPE is:17.70% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :4.49 & 18.27% & 1.14\n",
      "for 2020-10-18, MAE is:4.46 & sMAPE is:12.44% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :4.49 & 18.25% & 1.14\n",
      "for 2020-10-19, MAE is:5.43 & sMAPE is:12.00% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :4.49 & 18.23% & 1.14\n",
      "for 2020-10-20, MAE is:2.48 & sMAPE is:6.29% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :4.49 & 18.19% & 1.14\n",
      "for 2020-10-21, MAE is:7.92 & sMAPE is:20.65% & rMAE is:4.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.50 & 18.20% & 1.15\n",
      "for 2020-10-22, MAE is:7.41 & sMAPE is:17.59% & rMAE is:5.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.51 & 18.20% & 1.16\n",
      "for 2020-10-23, MAE is:4.61 & sMAPE is:9.74% & rMAE is:3.38 ||| daily mean of MAE & sMAPE & rMAE till now are :4.51 & 18.17% & 1.17\n",
      "for 2020-10-24, MAE is:3.95 & sMAPE is:12.70% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :4.51 & 18.15% & 1.17\n",
      "for 2020-10-25, MAE is:9.17 & sMAPE is:41.81% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :4.52 & 18.23% & 1.17\n",
      "for 2020-10-26, MAE is:3.86 & sMAPE is:9.99% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :4.52 & 18.20% & 1.17\n",
      "for 2020-10-27, MAE is:3.59 & sMAPE is:9.27% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :4.52 & 18.17% & 1.17\n",
      "for 2020-10-28, MAE is:4.28 & sMAPE is:12.12% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :4.51 & 18.15% & 1.16\n",
      "for 2020-10-29, MAE is:6.69 & sMAPE is:21.67% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.52 & 18.16% & 1.16\n",
      "for 2020-10-30, MAE is:4.62 & sMAPE is:14.94% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :4.52 & 18.15% & 1.16\n",
      "for 2020-10-31, MAE is:3.41 & sMAPE is:11.47% & rMAE is:1.93 ||| daily mean of MAE & sMAPE & rMAE till now are :4.52 & 18.13% & 1.16\n",
      "for 2020-11-01, MAE is:2.87 & sMAPE is:16.59% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :4.51 & 18.13% & 1.16\n",
      "for 2020-11-02, MAE is:7.65 & sMAPE is:46.22% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :4.52 & 18.22% & 1.16\n",
      "for 2020-11-03, MAE is:8.64 & sMAPE is:25.14% & rMAE is:2.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.54 & 18.24% & 1.16\n",
      "for 2020-11-04, MAE is:4.68 & sMAPE is:11.60% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :4.54 & 18.22% & 1.16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-11-05, MAE is:4.01 & sMAPE is:9.67% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :4.54 & 18.19% & 1.16\n",
      "for 2020-11-06, MAE is:7.86 & sMAPE is:20.65% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :4.55 & 18.20% & 1.16\n",
      "for 2020-11-07, MAE is:6.50 & sMAPE is:19.72% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.55 & 18.20% & 1.16\n",
      "for 2020-11-08, MAE is:3.45 & sMAPE is:10.48% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :4.55 & 18.18% & 1.16\n",
      "for 2020-11-09, MAE is:4.73 & sMAPE is:11.26% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :4.55 & 18.16% & 1.16\n",
      "for 2020-11-10, MAE is:8.66 & sMAPE is:18.95% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :4.56 & 18.16% & 1.15\n",
      "for 2020-11-11, MAE is:5.88 & sMAPE is:13.43% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 18.15% & 1.15\n",
      "for 2020-11-12, MAE is:4.59 & sMAPE is:11.51% & rMAE is:1.94 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 18.12% & 1.16\n",
      "for 2020-11-13, MAE is:6.12 & sMAPE is:15.69% & rMAE is:2.89 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 18.12% & 1.16\n",
      "for 2020-11-14, MAE is:4.56 & sMAPE is:13.72% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 18.10% & 1.16\n",
      "for 2020-11-15, MAE is:8.54 & sMAPE is:47.06% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :4.58 & 18.19% & 1.16\n",
      "for 2020-11-16, MAE is:8.34 & sMAPE is:30.90% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :4.60 & 18.23% & 1.16\n",
      "for 2020-11-17, MAE is:6.02 & sMAPE is:16.48% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :4.60 & 18.23% & 1.16\n",
      "for 2020-11-18, MAE is:3.86 & sMAPE is:9.75% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :4.60 & 18.20% & 1.16\n",
      "for 2020-11-19, MAE is:6.06 & sMAPE is:16.92% & rMAE is:2.21 ||| daily mean of MAE & sMAPE & rMAE till now are :4.60 & 18.20% & 1.16\n",
      "for 2020-11-20, MAE is:6.76 & sMAPE is:15.21% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :4.61 & 18.19% & 1.16\n",
      "for 2020-11-21, MAE is:1.96 & sMAPE is:4.93% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.60 & 18.15% & 1.16\n",
      "for 2020-11-22, MAE is:3.54 & sMAPE is:9.49% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :4.60 & 18.12% & 1.16\n",
      "for 2020-11-23, MAE is:3.19 & sMAPE is:6.59% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :4.59 & 18.09% & 1.16\n",
      "for 2020-11-24, MAE is:3.41 & sMAPE is:7.20% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :4.59 & 18.05% & 1.15\n",
      "for 2020-11-25, MAE is:4.01 & sMAPE is:8.31% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.59 & 18.02% & 1.15\n",
      "for 2020-11-26, MAE is:8.00 & sMAPE is:14.26% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.60 & 18.01% & 1.15\n",
      "for 2020-11-27, MAE is:13.45 & sMAPE is:20.89% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :4.63 & 18.02% & 1.15\n",
      "for 2020-11-28, MAE is:4.03 & sMAPE is:8.95% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :4.62 & 17.99% & 1.15\n",
      "for 2020-11-29, MAE is:6.86 & sMAPE is:15.26% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :4.63 & 17.99% & 1.15\n",
      "for 2020-11-30, MAE is:7.98 & sMAPE is:12.92% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :4.64 & 17.97% & 1.14\n",
      "for 2020-12-01, MAE is:10.67 & sMAPE is:18.74% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :4.66 & 17.97% & 1.14\n",
      "for 2020-12-02, MAE is:15.25 & sMAPE is:21.96% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 17.98% & 1.14\n",
      "for 2020-12-03, MAE is:4.42 & sMAPE is:7.94% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 17.95% & 1.14\n",
      "for 2020-12-04, MAE is:2.68 & sMAPE is:5.35% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 17.92% & 1.14\n",
      "for 2020-12-05, MAE is:5.51 & sMAPE is:11.32% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 17.90% & 1.14\n",
      "for 2020-12-06, MAE is:5.59 & sMAPE is:11.89% & rMAE is:2.83 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 17.88% & 1.15\n",
      "for 2020-12-07, MAE is:3.99 & sMAPE is:7.10% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 17.85% & 1.14\n",
      "for 2020-12-08, MAE is:15.55 & sMAPE is:22.40% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :4.72 & 17.86% & 1.15\n",
      "for 2020-12-09, MAE is:26.72 & sMAPE is:32.43% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :4.78 & 17.90% & 1.15\n",
      "for 2020-12-10, MAE is:20.66 & sMAPE is:28.32% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :4.83 & 17.93% & 1.15\n",
      "for 2020-12-11, MAE is:2.89 & sMAPE is:5.66% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :4.82 & 17.90% & 1.15\n",
      "for 2020-12-12, MAE is:3.60 & sMAPE is:7.28% & rMAE is:2.09 ||| daily mean of MAE & sMAPE & rMAE till now are :4.82 & 17.87% & 1.15\n",
      "for 2020-12-13, MAE is:2.27 & sMAPE is:5.06% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.81 & 17.83% & 1.15\n",
      "for 2020-12-14, MAE is:4.64 & sMAPE is:10.36% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :4.81 & 17.81% & 1.15\n",
      "for 2020-12-15, MAE is:7.08 & sMAPE is:13.24% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :4.82 & 17.80% & 1.15\n",
      "for 2020-12-16, MAE is:4.10 & sMAPE is:7.43% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :4.81 & 17.77% & 1.14\n",
      "for 2020-12-17, MAE is:2.27 & sMAPE is:4.40% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :4.81 & 17.73% & 1.14\n",
      "for 2020-12-18, MAE is:2.19 & sMAPE is:4.12% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 17.69% & 1.14\n",
      "for 2020-12-19, MAE is:2.95 & sMAPE is:5.98% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 17.66% & 1.14\n",
      "for 2020-12-20, MAE is:5.07 & sMAPE is:11.60% & rMAE is:3.20 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 17.64% & 1.14\n",
      "for 2020-12-21, MAE is:4.08 & sMAPE is:8.26% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :4.79 & 17.61% & 1.15\n",
      "for 2020-12-22, MAE is:7.19 & sMAPE is:14.86% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 17.61% & 1.15\n",
      "for 2020-12-23, MAE is:5.35 & sMAPE is:11.31% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 17.59% & 1.15\n",
      "for 2020-12-24, MAE is:4.06 & sMAPE is:12.85% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 17.58% & 1.14\n",
      "for 2020-12-25, MAE is:5.94 & sMAPE is:21.48% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 17.59% & 1.14\n",
      "for 2020-12-26, MAE is:3.74 & sMAPE is:12.16% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 17.57% & 1.14\n",
      "for 2020-12-27, MAE is:9.97 & sMAPE is:49.30% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.81 & 17.66% & 1.14\n",
      "for 2020-12-28, MAE is:13.33 & sMAPE is:33.99% & rMAE is:1.77 ||| daily mean of MAE & sMAPE & rMAE till now are :4.84 & 17.70% & 1.14\n",
      "for 2020-12-29, MAE is:7.91 & sMAPE is:17.17% & rMAE is:3.27 ||| daily mean of MAE & sMAPE & rMAE till now are :4.85 & 17.70% & 1.14\n",
      "for 2020-12-30, MAE is:5.86 & sMAPE is:11.81% & rMAE is:1.86 ||| daily mean of MAE & sMAPE & rMAE till now are :4.85 & 17.69% & 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:50:07,148]\u001b[0m A new study created in RDB with name: CH_2021\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-12-31, MAE is:6.34 & sMAPE is:12.98% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.85 & 17.67% & 1.14\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:50:21,705]\u001b[0m Trial 3 finished with value: 6.916806566411959 and parameters: {'n_hidden': 4, 'learning_rate': 0.03158952910842476, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11217012539542758, 'dropout_rate_Layer_2': 0.2890517854076335, 'dropout_rate_Layer_3': 0.08828642370725484, 'dropout_rate_Layer_4': 0.39677763387428366, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00013368957864298104, 'l1_Layer_2': 0.00011645607606501043, 'l1_Layer_3': 0.009255666532347627, 'l1_Layer_4': 0.0017491906005358145, 'n_units_Layer_1': 160, 'n_units_Layer_2': 100, 'n_units_Layer_3': 110, 'n_units_Layer_4': 55}. Best is trial 3 with value: 6.916806566411959.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.92 | sMAPE for Validation Set is: 24.79% | rMAE for Validation Set is: 1.14\n",
      "MAE for Test Set is: 63.68 | sMAPE for Test Set is: 55.09% | rMAE for Test Set is: 3.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:50:24,512]\u001b[0m Trial 2 finished with value: 6.862836460035602 and parameters: {'n_hidden': 3, 'learning_rate': 0.011331502992278752, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39423096923479817, 'dropout_rate_Layer_2': 0.33592462687055735, 'dropout_rate_Layer_3': 0.3546177930542672, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0008184230447066889, 'l1_Layer_2': 0.007554425764289065, 'l1_Layer_3': 0.0007578151724393309, 'n_units_Layer_1': 250, 'n_units_Layer_2': 150, 'n_units_Layer_3': 145}. Best is trial 2 with value: 6.862836460035602.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.86 | sMAPE for Validation Set is: 24.39% | rMAE for Validation Set is: 1.13\n",
      "MAE for Test Set is: 62.54 | sMAPE for Test Set is: 53.46% | rMAE for Test Set is: 2.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:50:30,014]\u001b[0m Trial 1 finished with value: 10.762464534472622 and parameters: {'n_hidden': 4, 'learning_rate': 0.03967576354337504, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008303921905010904, 'dropout_rate_Layer_2': 0.019635731341123286, 'dropout_rate_Layer_3': 0.2979403152702646, 'dropout_rate_Layer_4': 0.36152174674110144, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00016549852283939155, 'l1_Layer_2': 0.07732056566651864, 'l1_Layer_3': 5.416071581200361e-05, 'l1_Layer_4': 0.021503925890002894, 'n_units_Layer_1': 205, 'n_units_Layer_2': 90, 'n_units_Layer_3': 105, 'n_units_Layer_4': 170}. Best is trial 2 with value: 6.862836460035602.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.76 | sMAPE for Validation Set is: 33.76% | rMAE for Validation Set is: 1.77\n",
      "MAE for Test Set is: 80.05 | sMAPE for Test Set is: 84.12% | rMAE for Test Set is: 3.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:50:33,456]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:50:38,469]\u001b[0m Trial 4 finished with value: 7.113167741619666 and parameters: {'n_hidden': 4, 'learning_rate': 0.022095291929342425, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2605613121541048, 'dropout_rate_Layer_2': 0.002261201392359791, 'dropout_rate_Layer_3': 0.1497324425980855, 'dropout_rate_Layer_4': 0.09143027182342256, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.4019318385701925e-05, 'l1_Layer_2': 0.00021933534065101922, 'l1_Layer_3': 0.0049802445922696005, 'l1_Layer_4': 0.003533389433366919, 'n_units_Layer_1': 145, 'n_units_Layer_2': 190, 'n_units_Layer_3': 55, 'n_units_Layer_4': 160}. Best is trial 2 with value: 6.862836460035602.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.11 | sMAPE for Validation Set is: 24.89% | rMAE for Validation Set is: 1.17\n",
      "MAE for Test Set is: 60.07 | sMAPE for Test Set is: 50.57% | rMAE for Test Set is: 2.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:50:41,028]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:50:44,160]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:50:47,943]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:50:49,487]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:50:51,776]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:50:54,668]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:50:54,926]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.49 | sMAPE for Validation Set is: 16.85% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 50.49 | sMAPE for Test Set is: 38.50% | rMAE for Test Set is: 2.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:50:57,937]\u001b[0m Trial 0 finished with value: 4.486343895076268 and parameters: {'n_hidden': 3, 'learning_rate': 0.001749477271873724, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09917458806802998, 'dropout_rate_Layer_2': 0.19523072652753998, 'dropout_rate_Layer_3': 0.08257029531571702, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0005052075708666023, 'l1_Layer_2': 0.005468088234323223, 'l1_Layer_3': 0.0034704758205385384, 'n_units_Layer_1': 105, 'n_units_Layer_2': 275, 'n_units_Layer_3': 145}. Best is trial 0 with value: 4.486343895076268.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:51:02,334]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:51:04,583]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:51:07,940]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:51:10,426]\u001b[0m Trial 16 finished with value: 7.6775699112298 and parameters: {'n_hidden': 3, 'learning_rate': 0.057356523143444936, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2835857332356394, 'dropout_rate_Layer_2': 0.025803994669957576, 'dropout_rate_Layer_3': 0.20446973306274208, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00034084968999160514, 'l1_Layer_2': 0.06138127224848435, 'l1_Layer_3': 0.00027834876663298896, 'n_units_Layer_1': 200, 'n_units_Layer_2': 245, 'n_units_Layer_3': 120}. Best is trial 0 with value: 4.486343895076268.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.68 | sMAPE for Validation Set is: 26.55% | rMAE for Validation Set is: 1.26\n",
      "MAE for Test Set is: 76.62 | sMAPE for Test Set is: 78.70% | rMAE for Test Set is: 3.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:51:11,005]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:51:12,027]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:51:15,485]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:51:18,410]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:51:21,323]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:51:24,656]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:51:25,612]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:51:27,654]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:51:29,542]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:51:33,503]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:51:37,888]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:51:39,038]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:51:40,952]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:51:41,396]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:51:48,873]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:51:53,994]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:51:54,258]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:52:01,395]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:52:05,361]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:52:09,188]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:52:14,034]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:52:18,004]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:52:20,640]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:52:21,037]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:52:22,888]\u001b[0m Trial 37 finished with value: 4.760579028603316 and parameters: {'n_hidden': 4, 'learning_rate': 0.012169931524247059, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06892092491001907, 'dropout_rate_Layer_2': 0.13075685172540708, 'dropout_rate_Layer_3': 0.2670870428529872, 'dropout_rate_Layer_4': 0.252716843118667, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0005019508764684661, 'l1_Layer_2': 0.06706697819121359, 'l1_Layer_3': 0.004197891197661085, 'l1_Layer_4': 0.00821886628215676, 'n_units_Layer_1': 145, 'n_units_Layer_2': 135, 'n_units_Layer_3': 130, 'n_units_Layer_4': 130}. Best is trial 0 with value: 4.486343895076268.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.76 | sMAPE for Validation Set is: 17.64% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 61.02 | sMAPE for Test Set is: 51.28% | rMAE for Test Set is: 2.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:52:29,448]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:52:30,407]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:52:35,274]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:52:35,817]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:52:41,384]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:52:41,672]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:52:45,958]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:52:48,797]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:52:48,952]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:52:55,547]\u001b[0m Trial 12 finished with value: 5.926887838749724 and parameters: {'n_hidden': 4, 'learning_rate': 0.0037641939973698303, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15720515937953627, 'dropout_rate_Layer_2': 0.17851218811225747, 'dropout_rate_Layer_3': 0.2574696215787797, 'dropout_rate_Layer_4': 0.2612622245733672, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.6737490235782533e-05, 'l1_Layer_2': 0.004768965918147668, 'l1_Layer_3': 2.118873855264351e-05, 'l1_Layer_4': 0.007404273380999278, 'n_units_Layer_1': 230, 'n_units_Layer_2': 70, 'n_units_Layer_3': 135, 'n_units_Layer_4': 115}. Best is trial 0 with value: 4.486343895076268.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.93 | sMAPE for Validation Set is: 21.28% | rMAE for Validation Set is: 0.98\n",
      "MAE for Test Set is: 61.17 | sMAPE for Test Set is: 51.44% | rMAE for Test Set is: 2.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:52:57,786]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:52:58,918]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:53:01,460]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:53:02,024]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:53:06,357]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:53:08,032]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:53:12,253]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:53:13,271]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:53:14,700]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:53:18,171]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:53:22,617]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:53:23,270]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:53:23,433]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:53:25,539]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:53:28,096]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:53:33,280]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:53:33,535]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:53:33,783]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:53:41,611]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:53:44,372]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:53:47,379]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:53:47,383]\u001b[0m Trial 69 finished with value: 5.918354975249663 and parameters: {'n_hidden': 3, 'learning_rate': 0.014983684719035837, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34304662348821835, 'dropout_rate_Layer_2': 0.3495519324773917, 'dropout_rate_Layer_3': 0.27863255509197066, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.036278475418570474, 'l1_Layer_2': 0.0008608401872524036, 'l1_Layer_3': 0.0027452925991942392, 'n_units_Layer_1': 160, 'n_units_Layer_2': 240, 'n_units_Layer_3': 235}. Best is trial 0 with value: 4.486343895076268.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.92 | sMAPE for Validation Set is: 21.69% | rMAE for Validation Set is: 0.97\n",
      "MAE for Test Set is: 55.34 | sMAPE for Test Set is: 44.14% | rMAE for Test Set is: 2.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:53:48,602]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:53:49,702]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:53:51,443]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:53:52,601]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:53:54,422]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:53:56,732]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:54:04,089]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:54:04,297]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:54:04,802]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:54:05,311]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:54:10,475]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:54:14,194]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:54:15,681]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:54:15,797]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:54:16,842]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:54:22,901]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:54:23,841]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:54:27,199]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:54:27,319]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:54:32,453]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:54:33,191]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:54:39,248]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:54:39,532]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:54:44,694]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:54:53,673]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:54:53,914]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:55:00,582]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:55:05,485]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:55:05,652]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:55:11,403]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:55:14,847]\u001b[0m Trial 101 finished with value: 4.8184740801154184 and parameters: {'n_hidden': 4, 'learning_rate': 0.022271096038601237, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12991023263995632, 'dropout_rate_Layer_2': 0.01724741725795479, 'dropout_rate_Layer_3': 0.2859680962565593, 'dropout_rate_Layer_4': 0.3929440951543825, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000530622899067974, 'l1_Layer_2': 0.040231530942614266, 'l1_Layer_3': 0.012835961688928059, 'l1_Layer_4': 0.011365513710305964, 'n_units_Layer_1': 160, 'n_units_Layer_2': 95, 'n_units_Layer_3': 155, 'n_units_Layer_4': 240}. Best is trial 0 with value: 4.486343895076268.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.82 | sMAPE for Validation Set is: 18.15% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 14.97 | sMAPE for Test Set is: 15.19% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:55:25,101]\u001b[0m Trial 97 finished with value: 4.8023061859253495 and parameters: {'n_hidden': 4, 'learning_rate': 0.00812902936883539, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05767660449163958, 'dropout_rate_Layer_2': 0.02423318751884268, 'dropout_rate_Layer_3': 0.254101546393371, 'dropout_rate_Layer_4': 0.35309037110182295, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0006472316165763487, 'l1_Layer_2': 0.039395574692913216, 'l1_Layer_3': 0.012603245251013397, 'l1_Layer_4': 0.0052292114108863415, 'n_units_Layer_1': 200, 'n_units_Layer_2': 110, 'n_units_Layer_3': 155, 'n_units_Layer_4': 210}. Best is trial 0 with value: 4.486343895076268.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.80 | sMAPE for Validation Set is: 17.67% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 54.13 | sMAPE for Test Set is: 42.95% | rMAE for Test Set is: 2.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:55:29,586]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:55:30,214]\u001b[0m Trial 108 finished with value: 5.59849527673801 and parameters: {'n_hidden': 3, 'learning_rate': 0.011883891105466976, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03561693088109502, 'dropout_rate_Layer_2': 0.0017015874005356646, 'dropout_rate_Layer_3': 0.2092144247174596, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0012515417117971008, 'l1_Layer_2': 8.488651471902439e-05, 'l1_Layer_3': 0.0033460557960871954, 'n_units_Layer_1': 85, 'n_units_Layer_2': 105, 'n_units_Layer_3': 165}. Best is trial 0 with value: 4.486343895076268.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.60 | sMAPE for Validation Set is: 20.72% | rMAE for Validation Set is: 0.92\n",
      "MAE for Test Set is: 55.72 | sMAPE for Test Set is: 44.71% | rMAE for Test Set is: 2.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:55:36,659]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:55:41,239]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:55:51,049]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:55:55,691]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:55:55,888]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:55:55,926]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:56:03,117]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:56:07,822]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:56:16,074]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:56:20,264]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:56:22,699]\u001b[0m Trial 106 finished with value: 4.957499680182617 and parameters: {'n_hidden': 3, 'learning_rate': 0.003843055077950656, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16665237164022745, 'dropout_rate_Layer_2': 0.17091426881950955, 'dropout_rate_Layer_3': 0.2399227885248834, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.1249652660166924e-05, 'l1_Layer_2': 0.006160296065733511, 'l1_Layer_3': 0.00040221943073336493, 'n_units_Layer_1': 210, 'n_units_Layer_2': 175, 'n_units_Layer_3': 225}. Best is trial 0 with value: 4.486343895076268.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.96 | sMAPE for Validation Set is: 18.34% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 54.58 | sMAPE for Test Set is: 43.17% | rMAE for Test Set is: 2.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:56:26,834]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:56:27,038]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.46 | sMAPE for Validation Set is: 20.10% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 13.87 | sMAPE for Test Set is: 14.42% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:56:31,571]\u001b[0m Trial 119 finished with value: 5.462689700494127 and parameters: {'n_hidden': 4, 'learning_rate': 0.0026102397946434334, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17288135989438375, 'dropout_rate_Layer_2': 0.03627413884974625, 'dropout_rate_Layer_3': 0.22613071061507575, 'dropout_rate_Layer_4': 0.3810076385303553, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.001785812492385802, 'l1_Layer_2': 0.02072012761567417, 'l1_Layer_3': 0.017081251324035648, 'l1_Layer_4': 0.0019502958100822265, 'n_units_Layer_1': 215, 'n_units_Layer_2': 165, 'n_units_Layer_3': 135, 'n_units_Layer_4': 300}. Best is trial 0 with value: 4.486343895076268.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:56:34,845]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:56:38,367]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:56:41,290]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:56:44,112]\u001b[0m Trial 117 finished with value: 4.299612883702404 and parameters: {'n_hidden': 3, 'learning_rate': 0.004220324999419928, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18987862798462818, 'dropout_rate_Layer_2': 0.1326977762213889, 'dropout_rate_Layer_3': 0.0015506873992635617, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0005933047319077088, 'l1_Layer_2': 0.004718024477149715, 'l1_Layer_3': 0.0022607515972699267, 'n_units_Layer_1': 205, 'n_units_Layer_2': 285, 'n_units_Layer_3': 235}. Best is trial 117 with value: 4.299612883702404.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.30 | sMAPE for Validation Set is: 16.22% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 51.09 | sMAPE for Test Set is: 39.01% | rMAE for Test Set is: 2.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:56:46,873]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:56:50,019]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:56:55,123]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:56:59,041]\u001b[0m Trial 123 finished with value: 4.604111599249207 and parameters: {'n_hidden': 4, 'learning_rate': 0.002597717727316139, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16382990218564009, 'dropout_rate_Layer_2': 0.02729080125956651, 'dropout_rate_Layer_3': 0.19111409551185382, 'dropout_rate_Layer_4': 0.004880042858973768, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.001945195115676685, 'l1_Layer_2': 0.021551838948848663, 'l1_Layer_3': 0.005169789920023432, 'l1_Layer_4': 0.0023907438840372794, 'n_units_Layer_1': 210, 'n_units_Layer_2': 170, 'n_units_Layer_3': 135, 'n_units_Layer_4': 290}. Best is trial 117 with value: 4.299612883702404.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.60 | sMAPE for Validation Set is: 17.37% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 13.33 | sMAPE for Test Set is: 13.50% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:57:00,819]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:57:06,245]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:57:07,178]\u001b[0m Trial 128 finished with value: 5.206771557072079 and parameters: {'n_hidden': 3, 'learning_rate': 0.017451559213460595, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3993379573112566, 'dropout_rate_Layer_2': 0.12792593188179524, 'dropout_rate_Layer_3': 0.3968030352397667, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.002803818256069409, 'l1_Layer_2': 0.015980458532092845, 'l1_Layer_3': 0.009664529718099078, 'n_units_Layer_1': 175, 'n_units_Layer_2': 200, 'n_units_Layer_3': 260}. Best is trial 117 with value: 4.299612883702404.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.21 | sMAPE for Validation Set is: 19.24% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 56.33 | sMAPE for Test Set is: 45.30% | rMAE for Test Set is: 2.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:57:13,286]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:57:20,814]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:57:21,510]\u001b[0m Trial 132 finished with value: 5.016903346113951 and parameters: {'n_hidden': 4, 'learning_rate': 0.0027918570518358065, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1058742037201409, 'dropout_rate_Layer_2': 0.04821889727501289, 'dropout_rate_Layer_3': 0.16845563628994967, 'dropout_rate_Layer_4': 0.36238905128531385, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0012347933959041594, 'l1_Layer_2': 0.0027327818367735082, 'l1_Layer_3': 0.02005860135554971, 'l1_Layer_4': 0.0011549402059825747, 'n_units_Layer_1': 210, 'n_units_Layer_2': 130, 'n_units_Layer_3': 140, 'n_units_Layer_4': 285}. Best is trial 117 with value: 4.299612883702404.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.02 | sMAPE for Validation Set is: 18.83% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 15.89 | sMAPE for Test Set is: 15.52% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:57:26,517]\u001b[0m Trial 133 finished with value: 5.410995191141978 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014510291736617152, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20129963033497117, 'dropout_rate_Layer_2': 0.0421371677256711, 'dropout_rate_Layer_3': 0.2727508441046123, 'dropout_rate_Layer_4': 0.04005070895163204, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.007283290369975874, 'l1_Layer_2': 0.012873101648231102, 'l1_Layer_3': 0.011466567026489377, 'l1_Layer_4': 0.001111238300622666, 'n_units_Layer_1': 230, 'n_units_Layer_2': 170, 'n_units_Layer_3': 145, 'n_units_Layer_4': 290}. Best is trial 117 with value: 4.299612883702404.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.41 | sMAPE for Validation Set is: 20.02% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 14.06 | sMAPE for Test Set is: 14.42% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:57:26,716]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:57:27,059]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:57:35,125]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:57:43,715]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:57:49,049]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:57:53,159]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:57:57,313]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:58:01,701]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:58:02,075]\u001b[0m Trial 139 finished with value: 4.361385551636819 and parameters: {'n_hidden': 3, 'learning_rate': 0.007228524778172347, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19204470440080207, 'dropout_rate_Layer_2': 0.14330891478772426, 'dropout_rate_Layer_3': 0.14451359612030618, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0007945065074098976, 'l1_Layer_2': 0.0019097284889828562, 'l1_Layer_3': 0.002926742169101982, 'n_units_Layer_1': 190, 'n_units_Layer_2': 175, 'n_units_Layer_3': 285}. Best is trial 117 with value: 4.299612883702404.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.36 | sMAPE for Validation Set is: 16.38% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 53.61 | sMAPE for Test Set is: 41.78% | rMAE for Test Set is: 2.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:58:02,622]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:58:08,152]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.48 | sMAPE for Validation Set is: 16.51% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 51.23 | sMAPE for Test Set is: 39.47% | rMAE for Test Set is: 2.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:58:09,798]\u001b[0m Trial 140 finished with value: 4.481890950231722 and parameters: {'n_hidden': 3, 'learning_rate': 0.006856687390862066, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19445377704130626, 'dropout_rate_Layer_2': 0.14710861492744934, 'dropout_rate_Layer_3': 0.15621342498298463, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0008504617845014664, 'l1_Layer_2': 0.0026904306430599167, 'l1_Layer_3': 0.018256431262046992, 'n_units_Layer_1': 190, 'n_units_Layer_2': 165, 'n_units_Layer_3': 280}. Best is trial 117 with value: 4.299612883702404.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:58:15,436]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:58:18,625]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:58:20,914]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:58:20,959]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:58:24,247]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:58:28,766]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:58:29,345]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:58:29,892]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:58:36,772]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:58:37,084]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:58:40,012]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:58:44,670]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:58:46,289]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:58:46,862]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:58:47,236]\u001b[0m Trial 154 finished with value: 4.090826453381705 and parameters: {'n_hidden': 3, 'learning_rate': 0.013316700441264977, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.015577247408473233, 'dropout_rate_Layer_2': 0.033143856372418394, 'dropout_rate_Layer_3': 0.13159530145112489, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006957618392486255, 'l1_Layer_2': 0.0005535677937021027, 'l1_Layer_3': 0.0009060501867243766, 'n_units_Layer_1': 85, 'n_units_Layer_2': 70, 'n_units_Layer_3': 150}. Best is trial 154 with value: 4.090826453381705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.09 | sMAPE for Validation Set is: 15.47% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 12.82 | sMAPE for Test Set is: 12.88% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:58:57,315]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:58:58,697]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:59:04,413]\u001b[0m Trial 165 finished with value: 4.898750748120752 and parameters: {'n_hidden': 3, 'learning_rate': 0.011567932922704745, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.011561505186763174, 'dropout_rate_Layer_2': 0.1648532157115824, 'dropout_rate_Layer_3': 0.18876562978940956, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005725769282089187, 'l1_Layer_2': 0.09640312182855561, 'l1_Layer_3': 0.0035662730719431893, 'n_units_Layer_1': 110, 'n_units_Layer_2': 60, 'n_units_Layer_3': 295}. Best is trial 154 with value: 4.090826453381705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.90 | sMAPE for Validation Set is: 18.00% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 14.70 | sMAPE for Test Set is: 15.05% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:59:04,899]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:59:09,276]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:59:10,649]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:59:13,575]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:59:18,841]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:59:19,066]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:59:19,583]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:59:25,919]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:59:28,077]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:59:32,043]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:59:34,121]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:59:34,467]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:59:40,124]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:59:40,641]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:59:44,595]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:59:50,373]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:59:54,943]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:59:55,128]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:59:58,419]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:00:02,756]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:00:05,187]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:00:05,916]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:00:08,445]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.30 | sMAPE for Validation Set is: 16.14% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 12.77 | sMAPE for Test Set is: 13.01% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:00:09,260]\u001b[0m Trial 183 finished with value: 4.302302956461574 and parameters: {'n_hidden': 3, 'learning_rate': 0.0055925334738257775, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.229766791752468, 'dropout_rate_Layer_2': 0.05344694096272061, 'dropout_rate_Layer_3': 0.06451385599697668, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013810807670153284, 'l1_Layer_2': 0.002346393259370232, 'l1_Layer_3': 0.02990068471290706, 'n_units_Layer_1': 140, 'n_units_Layer_2': 150, 'n_units_Layer_3': 260}. Best is trial 154 with value: 4.090826453381705.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:00:13,342]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:00:17,265]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:00:17,641]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:00:24,391]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:00:25,459]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:00:27,987]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:00:30,832]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:00:34,296]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:00:34,628]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:00:34,764]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:00:41,398]\u001b[0m Trial 195 finished with value: 4.699435816966724 and parameters: {'n_hidden': 3, 'learning_rate': 0.005787714344463332, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008425025738116486, 'dropout_rate_Layer_2': 0.09328318220499583, 'dropout_rate_Layer_3': 0.3790389443958449, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003772786629538942, 'l1_Layer_2': 0.04608342567654194, 'l1_Layer_3': 0.001877093025737282, 'n_units_Layer_1': 95, 'n_units_Layer_2': 100, 'n_units_Layer_3': 300}. Best is trial 154 with value: 4.090826453381705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.70 | sMAPE for Validation Set is: 17.86% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 12.77 | sMAPE for Test Set is: 12.95% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:00:41,993]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:00:46,823]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:00:48,066]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:00:51,091]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:00:51,510]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:01:01,291]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:01:01,659]\u001b[0m Trial 204 finished with value: 4.229596399238183 and parameters: {'n_hidden': 3, 'learning_rate': 0.005239695772995348, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2581858517935511, 'dropout_rate_Layer_2': 0.10727765614138475, 'dropout_rate_Layer_3': 0.02528667269644726, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003711090432607457, 'l1_Layer_2': 0.0010137476879283273, 'l1_Layer_3': 0.00637842974179563, 'n_units_Layer_1': 95, 'n_units_Layer_2': 105, 'n_units_Layer_3': 280}. Best is trial 154 with value: 4.090826453381705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.23 | sMAPE for Validation Set is: 15.83% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 14.90 | sMAPE for Test Set is: 14.23% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:01:05,691]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:01:06,617]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:01:08,927]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:01:14,177]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:01:16,011]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:01:16,698]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:01:20,804]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:01:24,892]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:01:27,558]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:01:30,600]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:01:34,803]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:01:34,907]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:01:41,730]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:01:45,728]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:01:46,746]\u001b[0m Trial 218 finished with value: 4.172699409474237 and parameters: {'n_hidden': 3, 'learning_rate': 0.004809590957349306, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2634518971802323, 'dropout_rate_Layer_2': 0.00477840175328853, 'dropout_rate_Layer_3': 0.03200006185326012, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00462249440306279, 'l1_Layer_2': 0.000288254036922243, 'l1_Layer_3': 0.006851897012428835, 'n_units_Layer_1': 100, 'n_units_Layer_2': 105, 'n_units_Layer_3': 180}. Best is trial 154 with value: 4.090826453381705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.17 | sMAPE for Validation Set is: 15.70% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 13.98 | sMAPE for Test Set is: 13.42% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:01:50,232]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:01:51,613]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.27 | sMAPE for Validation Set is: 19.80% | rMAE for Validation Set is: 0.87\n",
      "MAE for Test Set is: 54.69 | sMAPE for Test Set is: 43.23% | rMAE for Test Set is: 2.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:01:55,492]\u001b[0m Trial 211 finished with value: 5.26815400137764 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031473595252437614, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.042884022290601655, 'dropout_rate_Layer_2': 0.043160302128907015, 'dropout_rate_Layer_3': 0.33594897874367236, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008352164636563989, 'l1_Layer_2': 0.009394196552098692, 'l1_Layer_3': 0.005952847301812048, 'n_units_Layer_1': 105, 'n_units_Layer_2': 125, 'n_units_Layer_3': 265}. Best is trial 154 with value: 4.090826453381705.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:02:03,506]\u001b[0m Trial 223 finished with value: 4.214152761816204 and parameters: {'n_hidden': 3, 'learning_rate': 0.004827632426802153, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25124670583747966, 'dropout_rate_Layer_2': 0.103266732671156, 'dropout_rate_Layer_3': 0.03751118728342352, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003948270761600887, 'l1_Layer_2': 0.00037863202583932916, 'l1_Layer_3': 0.007042194271694845, 'n_units_Layer_1': 100, 'n_units_Layer_2': 105, 'n_units_Layer_3': 185}. Best is trial 154 with value: 4.090826453381705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.21 | sMAPE for Validation Set is: 15.97% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 12.85 | sMAPE for Test Set is: 12.90% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:02:06,082]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:02:15,524]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:02:21,748]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:02:21,917]\u001b[0m Trial 229 finished with value: 5.255983717377361 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015516239051847898, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18187109399962784, 'dropout_rate_Layer_2': 0.043610256579224446, 'dropout_rate_Layer_3': 0.23760261010901187, 'dropout_rate_Layer_4': 0.0423100595648736, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00583070609129081, 'l1_Layer_2': 0.012166839708393759, 'l1_Layer_3': 0.0031431026857132267, 'l1_Layer_4': 0.0022993613230460255, 'n_units_Layer_1': 290, 'n_units_Layer_2': 170, 'n_units_Layer_3': 130, 'n_units_Layer_4': 290}. Best is trial 154 with value: 4.090826453381705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.26 | sMAPE for Validation Set is: 19.44% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 14.11 | sMAPE for Test Set is: 14.28% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:02:22,721]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.82 | sMAPE for Validation Set is: 14.74% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 13.43 | sMAPE for Test Set is: 13.04% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:02:25,861]\u001b[0m Trial 228 finished with value: 3.8222261392947083 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017917645532256985, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.002032752549269736, 'dropout_rate_Layer_2': 0.0284185923880141, 'dropout_rate_Layer_3': 0.29481535694728855, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001779869764404994, 'l1_Layer_2': 0.0008962274415720688, 'l1_Layer_3': 0.0001946300624686183, 'n_units_Layer_1': 260, 'n_units_Layer_2': 115, 'n_units_Layer_3': 190}. Best is trial 228 with value: 3.8222261392947083.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:02:31,723]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:02:35,010]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:02:35,167]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:02:40,526]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:02:44,162]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:02:45,485]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:02:47,475]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:02:53,156]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:02:57,056]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:03:00,793]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:03:01,351]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.62 | sMAPE for Validation Set is: 17.38% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 51.25 | sMAPE for Test Set is: 39.35% | rMAE for Test Set is: 2.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:03:01,454]\u001b[0m Trial 242 finished with value: 4.622877121715493 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011397576696523355, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.055263273976507765, 'dropout_rate_Layer_2': 0.0009207127840267955, 'dropout_rate_Layer_3': 0.30192498833834003, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001827114524664277, 'l1_Layer_2': 0.001078391021150832, 'l1_Layer_3': 5.1059967160342184e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 115, 'n_units_Layer_3': 265}. Best is trial 228 with value: 3.8222261392947083.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:03:04,483]\u001b[0m Trial 239 finished with value: 4.138486234766941 and parameters: {'n_hidden': 3, 'learning_rate': 0.002039518140306466, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.004051577624832231, 'dropout_rate_Layer_2': 0.015659598297613236, 'dropout_rate_Layer_3': 0.303696296212631, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0016297475426950614, 'l1_Layer_2': 0.00383601664756169, 'l1_Layer_3': 8.258696055934279e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 115, 'n_units_Layer_3': 260}. Best is trial 228 with value: 3.8222261392947083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.14 | sMAPE for Validation Set is: 15.98% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 52.11 | sMAPE for Test Set is: 39.95% | rMAE for Test Set is: 2.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:03:07,345]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:03:12,097]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:03:14,817]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:03:15,281]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:03:22,022]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:03:22,143]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:03:22,545]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:03:31,249]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:03:34,699]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:03:38,805]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:03:39,110]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:03:44,048]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:03:49,501]\u001b[0m Trial 259 finished with value: 4.4159104103740985 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022280298197164513, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03739403432144667, 'dropout_rate_Layer_2': 1.1928772028692303e-05, 'dropout_rate_Layer_3': 0.2464101986375805, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0014186807363856316, 'l1_Layer_2': 0.0075459729193147, 'l1_Layer_3': 2.18803152471061e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 110, 'n_units_Layer_3': 235}. Best is trial 228 with value: 3.8222261392947083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.42 | sMAPE for Validation Set is: 16.82% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 50.74 | sMAPE for Test Set is: 38.91% | rMAE for Test Set is: 2.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:03:53,164]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:03:57,031]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:03:57,704]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:04:00,619]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:04:03,559]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:04:08,892]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:04:12,963]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:04:13,013]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:04:13,648]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:04:23,233]\u001b[0m Trial 255 finished with value: 5.016345032676017 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008474420212263037, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14871286591487948, 'dropout_rate_Layer_2': 0.04208871423065774, 'dropout_rate_Layer_3': 0.2675244771465543, 'dropout_rate_Layer_4': 0.04361840161010399, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.007925166868667986, 'l1_Layer_2': 0.00025791237502176387, 'l1_Layer_3': 0.0069484204966341855, 'l1_Layer_4': 0.0007406315949558382, 'n_units_Layer_1': 220, 'n_units_Layer_2': 190, 'n_units_Layer_3': 80, 'n_units_Layer_4': 290}. Best is trial 228 with value: 3.8222261392947083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.02 | sMAPE for Validation Set is: 18.62% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 50.79 | sMAPE for Test Set is: 39.32% | rMAE for Test Set is: 2.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:04:26,209]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:04:28,734]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:04:31,828]\u001b[0m Trial 270 finished with value: 4.5736348831066955 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017429348218078412, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06481501157227317, 'dropout_rate_Layer_2': 0.013647686927703233, 'dropout_rate_Layer_3': 0.23511115590500747, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000610702916777214, 'l1_Layer_2': 0.0018635215343213744, 'l1_Layer_3': 1.1657519573670121e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 80, 'n_units_Layer_3': 285}. Best is trial 228 with value: 3.8222261392947083.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:04:31,851]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.57 | sMAPE for Validation Set is: 17.40% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 53.60 | sMAPE for Test Set is: 41.85% | rMAE for Test Set is: 2.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:04:32,450]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:04:40,351]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:04:40,756]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:04:47,152]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:04:48,191]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:04:52,837]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:04:57,041]\u001b[0m Trial 275 finished with value: 4.254567371614576 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024732690402121662, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30435974956096995, 'dropout_rate_Layer_2': 0.11536490887634455, 'dropout_rate_Layer_3': 0.10669182687883605, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003240681316823942, 'l1_Layer_2': 0.0002965272177531689, 'l1_Layer_3': 0.004741632456551688, 'n_units_Layer_1': 125, 'n_units_Layer_2': 65, 'n_units_Layer_3': 245}. Best is trial 228 with value: 3.8222261392947083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.25 | sMAPE for Validation Set is: 16.09% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 12.49 | sMAPE for Test Set is: 12.82% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:04:57,349]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:04:58,609]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:05:04,393]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:05:08,651]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:05:12,305]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:05:12,507]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:05:13,580]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:05:19,089]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:05:20,068]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:05:22,923]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:05:27,145]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:05:31,321]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:05:32,337]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:05:35,237]\u001b[0m Trial 276 finished with value: 3.7295493232800574 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017065865114786667, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08964076561780536, 'dropout_rate_Layer_2': 0.0017510524962785802, 'dropout_rate_Layer_3': 0.22387959781847322, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00045602802637780763, 'l1_Layer_2': 0.0007464698374590672, 'l1_Layer_3': 1.4153080220837366e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 95, 'n_units_Layer_3': 295}. Best is trial 276 with value: 3.7295493232800574.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.73 | sMAPE for Validation Set is: 14.47% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 12.52 | sMAPE for Test Set is: 12.14% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:05:39,220]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:05:40,886]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:05:42,798]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:05:49,921]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:05:54,219]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:05:58,796]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:05:59,191]\u001b[0m Trial 293 finished with value: 4.1560301575930785 and parameters: {'n_hidden': 3, 'learning_rate': 0.003713498668345092, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23432658139339224, 'dropout_rate_Layer_2': 0.020630793746176032, 'dropout_rate_Layer_3': 0.0549741309177037, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0018337550734358972, 'l1_Layer_2': 6.046625514351881e-05, 'l1_Layer_3': 0.01524647317036256, 'n_units_Layer_1': 125, 'n_units_Layer_2': 105, 'n_units_Layer_3': 190}. Best is trial 276 with value: 3.7295493232800574.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.16 | sMAPE for Validation Set is: 15.77% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 13.94 | sMAPE for Test Set is: 13.34% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:05:59,711]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:06:06,057]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:06:08,122]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:06:12,455]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:06:23,237]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:06:27,012]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:06:29,596]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:06:34,642]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:06:37,481]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:06:39,919]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:06:40,815]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:06:49,438]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:06:53,873]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:06:55,693]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:06:59,604]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:07:01,451]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:07:06,499]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:07:08,035]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:07:11,922]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:07:12,369]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:07:21,357]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:07:21,648]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:07:27,531]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:07:32,074]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.78 | sMAPE for Validation Set is: 14.64% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 12.08 | sMAPE for Test Set is: 12.23% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:07:34,027]\u001b[0m Trial 315 finished with value: 3.781720625034835 and parameters: {'n_hidden': 3, 'learning_rate': 0.002057286575871758, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12974677846706895, 'dropout_rate_Layer_2': 0.00016447498062764285, 'dropout_rate_Layer_3': 0.1287852958436572, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007012938913005316, 'l1_Layer_2': 0.0005635343740748186, 'l1_Layer_3': 1.885893214126134e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 80, 'n_units_Layer_3': 285}. Best is trial 276 with value: 3.7295493232800574.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:07:34,997]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:07:35,148]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:07:37,748]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:07:40,992]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:07:47,191]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:07:50,857]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:07:51,466]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:07:52,441]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:07:52,681]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:08:00,642]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:08:04,902]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:08:11,771]\u001b[0m Trial 336 finished with value: 4.493948954451162 and parameters: {'n_hidden': 3, 'learning_rate': 0.005863550240008838, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22330087945083277, 'dropout_rate_Layer_2': 0.01092335212652381, 'dropout_rate_Layer_3': 0.0013804251741462645, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0026971555423329617, 'l1_Layer_2': 0.0035292215194113476, 'l1_Layer_3': 0.03285319636032329, 'n_units_Layer_1': 150, 'n_units_Layer_2': 135, 'n_units_Layer_3': 265}. Best is trial 276 with value: 3.7295493232800574.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.49 | sMAPE for Validation Set is: 16.73% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 14.69 | sMAPE for Test Set is: 14.56% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:08:15,307]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:08:15,597]\u001b[0m Trial 337 finished with value: 4.221858775679891 and parameters: {'n_hidden': 3, 'learning_rate': 0.005924559414626925, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21758686219699683, 'dropout_rate_Layer_2': 0.04891917914773254, 'dropout_rate_Layer_3': 0.03286476146829344, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005453669107623331, 'l1_Layer_2': 0.004330610956597298, 'l1_Layer_3': 0.04154775476763883, 'n_units_Layer_1': 150, 'n_units_Layer_2': 90, 'n_units_Layer_3': 245}. Best is trial 276 with value: 3.7295493232800574.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.22 | sMAPE for Validation Set is: 15.82% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 12.88 | sMAPE for Test Set is: 13.18% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:08:15,717]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:08:17,525]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:08:22,618]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:08:23,044]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:08:28,136]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:08:30,902]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:08:31,080]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:08:31,460]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:08:32,025]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:08:41,227]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:08:49,179]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:08:49,241]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:08:54,410]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:08:55,015]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:09:01,391]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:09:06,634]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:09:12,215]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:09:17,175]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:09:20,391]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:09:23,323]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:09:23,893]\u001b[0m Trial 353 finished with value: 3.991026404388768 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030829115252020683, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04673881399098084, 'dropout_rate_Layer_2': 0.14162913148835338, 'dropout_rate_Layer_3': 0.03943582784813875, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00027397460203918355, 'l1_Layer_2': 0.0004841883535602683, 'l1_Layer_3': 0.01635582908507444, 'n_units_Layer_1': 100, 'n_units_Layer_2': 220, 'n_units_Layer_3': 205}. Best is trial 276 with value: 3.7295493232800574.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.99 | sMAPE for Validation Set is: 15.19% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 12.74 | sMAPE for Test Set is: 12.86% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:09:26,082]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:09:30,332]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:09:30,769]\u001b[0m Trial 356 finished with value: 3.7645644175408606 and parameters: {'n_hidden': 3, 'learning_rate': 0.003622397250255981, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.027802257785029868, 'dropout_rate_Layer_2': 0.2141585946429634, 'dropout_rate_Layer_3': 0.17396784102761656, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00044074170246849876, 'l1_Layer_2': 0.0004104970847123798, 'l1_Layer_3': 7.388086598672023e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 85, 'n_units_Layer_3': 300}. Best is trial 276 with value: 3.7295493232800574.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.76 | sMAPE for Validation Set is: 14.33% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 12.98 | sMAPE for Test Set is: 12.48% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:09:35,485]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:09:38,659]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:09:43,959]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:09:45,855]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:09:49,517]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:09:50,189]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:09:55,287]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:09:57,297]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:10:00,295]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:10:10,970]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:10:13,838]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:10:18,475]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:10:18,655]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:10:24,450]\u001b[0m Trial 377 finished with value: 3.7218176098578817 and parameters: {'n_hidden': 3, 'learning_rate': 0.004618416301303501, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02271965029946254, 'dropout_rate_Layer_2': 0.04619677413251637, 'dropout_rate_Layer_3': 0.18365276291413515, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00036212526962683576, 'l1_Layer_2': 0.00030778947692132653, 'l1_Layer_3': 0.00020692413639810303, 'n_units_Layer_1': 275, 'n_units_Layer_2': 80, 'n_units_Layer_3': 285}. Best is trial 377 with value: 3.7218176098578817.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.72 | sMAPE for Validation Set is: 14.66% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 13.60 | sMAPE for Test Set is: 13.09% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:10:27,064]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:10:27,278]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:10:27,772]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:10:28,881]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:10:36,322]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:10:36,919]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:10:39,465]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:10:41,128]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:10:43,695]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:10:43,755]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:10:49,303]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:10:52,823]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:10:54,503]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:10:55,741]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:10:59,195]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:10:59,720]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:11:05,577]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:11:08,596]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:11:08,859]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:11:17,276]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:11:19,314]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:11:23,807]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:11:25,073]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:11:25,525]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:11:25,831]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:11:31,760]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:11:33,131]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:11:34,878]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:11:35,549]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:11:37,965]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:11:41,951]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:11:45,550]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:11:49,967]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:11:52,339]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:11:54,909]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:11:58,270]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:12:00,655]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:12:01,398]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:12:04,024]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:12:07,983]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:12:08,989]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:12:14,238]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:12:20,395]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:12:20,895]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:12:23,065]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:12:26,859]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:12:27,295]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:12:33,201]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:12:33,237]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:12:33,497]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:12:40,029]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:12:43,388]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:12:43,672]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:12:45,798]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:12:50,148]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:12:52,352]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:12:53,102]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:12:55,169]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:13:00,074]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:13:01,780]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:13:04,283]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:13:04,631]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:13:09,617]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:13:11,978]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:13:13,845]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:13:17,673]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:13:18,010]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:13:23,049]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:13:23,859]\u001b[0m Trial 441 finished with value: 4.844845325802916 and parameters: {'n_hidden': 4, 'learning_rate': 0.002554488248904453, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11307404420041964, 'dropout_rate_Layer_2': 0.03726720736418367, 'dropout_rate_Layer_3': 0.2308511555932686, 'dropout_rate_Layer_4': 0.2468657818551815, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0061117785002589835, 'l1_Layer_2': 0.03774555805610843, 'l1_Layer_3': 0.014425470242641432, 'l1_Layer_4': 1.063516249534289e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 220, 'n_units_Layer_3': 155, 'n_units_Layer_4': 205}. Best is trial 377 with value: 3.7218176098578817.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.84 | sMAPE for Validation Set is: 17.99% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 48.60 | sMAPE for Test Set is: 37.06% | rMAE for Test Set is: 2.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:13:25,717]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:13:26,104]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:13:28,966]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:13:33,367]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:13:33,553]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:13:35,785]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:13:37,697]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:13:42,569]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:13:45,042]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:13:48,618]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:13:53,861]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:13:57,256]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:14:01,511]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:14:02,292]\u001b[0m Trial 455 finished with value: 4.195478240387685 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034828394862495356, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22931571802010733, 'dropout_rate_Layer_2': 0.056662027629493635, 'dropout_rate_Layer_3': 0.2928430105720772, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008536784292015605, 'l1_Layer_2': 0.003328569874615324, 'l1_Layer_3': 0.005129655067647492, 'n_units_Layer_1': 105, 'n_units_Layer_2': 190, 'n_units_Layer_3': 250}. Best is trial 377 with value: 3.7218176098578817.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.20 | sMAPE for Validation Set is: 15.84% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 12.24 | sMAPE for Test Set is: 12.42% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:14:05,574]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:14:09,108]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:14:11,507]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:14:15,037]\u001b[0m Trial 459 finished with value: 4.1644667008117935 and parameters: {'n_hidden': 3, 'learning_rate': 0.0037454664574126163, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24782461253828347, 'dropout_rate_Layer_2': 0.05321336095010161, 'dropout_rate_Layer_3': 0.29396375526885415, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008404204668587375, 'l1_Layer_2': 0.0040875784720936685, 'l1_Layer_3': 0.005376988241309856, 'n_units_Layer_1': 105, 'n_units_Layer_2': 85, 'n_units_Layer_3': 245}. Best is trial 377 with value: 3.7218176098578817.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.16 | sMAPE for Validation Set is: 15.64% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 13.84 | sMAPE for Test Set is: 13.58% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:14:15,682]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:14:16,077]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:14:26,959]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:14:27,260]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:14:31,583]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:14:34,940]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:14:38,623]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:14:41,751]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:14:46,048]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:14:46,132]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:14:46,334]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:14:46,805]\u001b[0m Trial 464 finished with value: 4.452185516392841 and parameters: {'n_hidden': 3, 'learning_rate': 0.003873415916426291, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08977744054172067, 'dropout_rate_Layer_2': 0.04044993757250866, 'dropout_rate_Layer_3': 0.321701340582708, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0014420552990776876, 'l1_Layer_2': 0.003730973225893672, 'l1_Layer_3': 0.00031962737888023427, 'n_units_Layer_1': 80, 'n_units_Layer_2': 185, 'n_units_Layer_3': 155}. Best is trial 377 with value: 3.7218176098578817.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.45 | sMAPE for Validation Set is: 17.01% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 13.03 | sMAPE for Test Set is: 13.02% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:14:55,415]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:14:57,172]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:14:59,948]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:15:00,691]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:15:04,113]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:15:09,060]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:15:13,111]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:15:15,936]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:15:16,379]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:15:21,959]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:15:22,876]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:15:28,552]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:15:31,402]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:15:36,432]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:15:39,037]\u001b[0m Trial 479 finished with value: 4.965380785237225 and parameters: {'n_hidden': 4, 'learning_rate': 0.001479744416464099, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07757106225248198, 'dropout_rate_Layer_2': 0.039707406294888926, 'dropout_rate_Layer_3': 0.2572283783259399, 'dropout_rate_Layer_4': 0.2446117634438199, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.05549084285676374, 'l1_Layer_2': 0.09048896179395141, 'l1_Layer_3': 0.00030504960990522057, 'l1_Layer_4': 0.003162882705172194, 'n_units_Layer_1': 155, 'n_units_Layer_2': 175, 'n_units_Layer_3': 190, 'n_units_Layer_4': 205}. Best is trial 377 with value: 3.7218176098578817.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.97 | sMAPE for Validation Set is: 18.40% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 55.66 | sMAPE for Test Set is: 44.71% | rMAE for Test Set is: 2.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:15:39,246]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:15:43,710]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:15:46,321]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:15:51,341]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:15:53,803]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:15:54,482]\u001b[0m Trial 488 finished with value: 4.2386217832830955 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022644119627672566, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014189359500071712, 'dropout_rate_Layer_2': 0.007506663130838377, 'dropout_rate_Layer_3': 0.30086817881323585, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011121576251452846, 'l1_Layer_2': 0.00014161815269195943, 'l1_Layer_3': 0.000878463720300954, 'n_units_Layer_1': 95, 'n_units_Layer_2': 115, 'n_units_Layer_3': 145}. Best is trial 377 with value: 3.7218176098578817.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.24 | sMAPE for Validation Set is: 15.97% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 12.13 | sMAPE for Test Set is: 12.29% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:15:55,216]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:15:55,506]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:16:02,155]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:16:06,825]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:16:07,186]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:16:07,877]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:16:10,519]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:16:15,295]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:16:21,220]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:16:21,680]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:16:21,897]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:16:28,930]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:16:31,685]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:16:32,940]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:16:33,139]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:16:39,924]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:16:40,424]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:16:40,443]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:16:40,572]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:16:47,524]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:16:51,235]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:16:51,549]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:16:51,692]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:16:57,358]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:16:59,642]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:17:01,472]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:17:06,810]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:17:09,663]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:17:09,794]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:17:11,322]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:17:13,420]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:17:17,151]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:17:21,688]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:17:21,743]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:17:23,090]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:17:30,013]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:17:30,402]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:17:30,513]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:17:39,029]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:17:39,616]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:17:40,428]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:17:42,457]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:17:44,908]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:17:50,753]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:17:53,323]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:17:57,037]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:18:00,440]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:18:01,652]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:18:06,323]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:18:11,014]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:18:11,652]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:18:18,228]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:18:18,759]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:18:19,937]\u001b[0m Trial 542 finished with value: 3.7509216242989907 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017695251671215276, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.040723743659399236, 'dropout_rate_Layer_2': 0.24059593322031014, 'dropout_rate_Layer_3': 0.29913508376489784, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005822536323945043, 'l1_Layer_2': 6.082380069583741e-05, 'l1_Layer_3': 0.001239681173331727, 'n_units_Layer_1': 95, 'n_units_Layer_2': 90, 'n_units_Layer_3': 150}. Best is trial 377 with value: 3.7218176098578817.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 14.30% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 12.67 | sMAPE for Test Set is: 12.40% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:18:24,533]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:18:26,467]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:18:26,759]\u001b[0m Trial 547 finished with value: 3.975302088929197 and parameters: {'n_hidden': 3, 'learning_rate': 0.010103609960578316, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.017736822079721125, 'dropout_rate_Layer_2': 0.019368199309820682, 'dropout_rate_Layer_3': 0.30112173912346357, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005785843558126552, 'l1_Layer_2': 0.00018203552895409273, 'l1_Layer_3': 0.0023011751295409356, 'n_units_Layer_1': 120, 'n_units_Layer_2': 95, 'n_units_Layer_3': 145}. Best is trial 377 with value: 3.7218176098578817.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.98 | sMAPE for Validation Set is: 15.14% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 14.28 | sMAPE for Test Set is: 13.83% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:18:28,235]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:18:36,200]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:18:37,829]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:18:38,976]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:18:39,532]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:18:44,149]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:18:47,704]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:18:48,135]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:18:48,915]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:18:53,266]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:19:00,095]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:19:00,770]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:19:02,786]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:19:12,323]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:19:17,043]\u001b[0m Trial 572 finished with value: 4.27217549835407 and parameters: {'n_hidden': 3, 'learning_rate': 0.004739083059091282, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.020140467923885554, 'dropout_rate_Layer_2': 0.20724160446244433, 'dropout_rate_Layer_3': 0.296988266665273, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000639500111796884, 'l1_Layer_2': 0.0005664907118767066, 'l1_Layer_3': 0.0008163854189063189, 'n_units_Layer_1': 110, 'n_units_Layer_2': 75, 'n_units_Layer_3': 140}. Best is trial 377 with value: 3.7218176098578817.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:19:17,177]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.27 | sMAPE for Validation Set is: 16.27% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 14.33 | sMAPE for Test Set is: 15.03% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:19:24,857]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:19:25,029]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:19:25,278]\u001b[0m Trial 570 finished with value: 4.19531461712599 and parameters: {'n_hidden': 3, 'learning_rate': 0.005181315697757689, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2422891625703255, 'dropout_rate_Layer_2': 0.045972685629552805, 'dropout_rate_Layer_3': 0.07580697574594535, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0021953808340054574, 'l1_Layer_2': 0.0025546972847967178, 'l1_Layer_3': 0.007256835619707828, 'n_units_Layer_1': 95, 'n_units_Layer_2': 60, 'n_units_Layer_3': 260}. Best is trial 377 with value: 3.7218176098578817.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.20 | sMAPE for Validation Set is: 15.81% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 12.74 | sMAPE for Test Set is: 12.68% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:19:30,251]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.16 | sMAPE for Validation Set is: 15.77% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 12.63 | sMAPE for Test Set is: 12.55% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:19:32,099]\u001b[0m Trial 565 finished with value: 4.160709092340319 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026097269400516703, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21961155950457958, 'dropout_rate_Layer_2': 0.07237728993284209, 'dropout_rate_Layer_3': 0.08881873471579226, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003999152211444474, 'l1_Layer_2': 0.001373941020693577, 'l1_Layer_3': 0.03324672787326985, 'n_units_Layer_1': 145, 'n_units_Layer_2': 95, 'n_units_Layer_3': 260}. Best is trial 377 with value: 3.7218176098578817.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:19:40,026]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:19:40,441]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:19:48,166]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:19:50,906]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:20:00,495]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:20:04,822]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:20:04,926]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:20:08,603]\u001b[0m Trial 581 finished with value: 4.81826645943669 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019671589324978633, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16522220118878622, 'dropout_rate_Layer_2': 0.019644670416469397, 'dropout_rate_Layer_3': 0.3515407912052328, 'dropout_rate_Layer_4': 0.02815201259778818, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.004356921315298101, 'l1_Layer_2': 0.03784666662747995, 'l1_Layer_3': 0.000146450492383993, 'l1_Layer_4': 0.013201861520389714, 'n_units_Layer_1': 150, 'n_units_Layer_2': 140, 'n_units_Layer_3': 145, 'n_units_Layer_4': 275}. Best is trial 377 with value: 3.7218176098578817.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.82 | sMAPE for Validation Set is: 17.76% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 13.72 | sMAPE for Test Set is: 14.16% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:20:11,521]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:20:15,758]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:20:17,142]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:20:23,371]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:20:24,879]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:20:27,461]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:20:29,375]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:20:34,366]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:20:38,062]\u001b[0m Trial 583 finished with value: 4.259443973250819 and parameters: {'n_hidden': 3, 'learning_rate': 0.002000336347900811, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2108709866409647, 'dropout_rate_Layer_2': 0.07320628836454014, 'dropout_rate_Layer_3': 0.07492719891802302, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003748852855799578, 'l1_Layer_2': 0.000455446969170548, 'l1_Layer_3': 0.03354290612943082, 'n_units_Layer_1': 50, 'n_units_Layer_2': 60, 'n_units_Layer_3': 270}. Best is trial 377 with value: 3.7218176098578817.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.26 | sMAPE for Validation Set is: 16.13% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 13.28 | sMAPE for Test Set is: 13.09% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:20:38,253]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:20:45,558]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:20:45,590]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:20:45,789]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:20:53,589]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:20:53,950]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:20:54,114]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:21:00,096]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:21:03,345]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:21:03,906]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:21:04,884]\u001b[0m Trial 594 finished with value: 4.975665178316659 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017541155199593992, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19244115897776137, 'dropout_rate_Layer_2': 0.020130826007113318, 'dropout_rate_Layer_3': 0.3800678514889232, 'dropout_rate_Layer_4': 0.02068047784615953, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002809395485280977, 'l1_Layer_2': 0.03750950963815791, 'l1_Layer_3': 0.00017805059082582746, 'l1_Layer_4': 0.015104330511379962, 'n_units_Layer_1': 170, 'n_units_Layer_2': 130, 'n_units_Layer_3': 140, 'n_units_Layer_4': 270}. Best is trial 377 with value: 3.7218176098578817.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.98 | sMAPE for Validation Set is: 18.55% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 18.29 | sMAPE for Test Set is: 17.15% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:21:10,807]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:21:13,541]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:21:17,124]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:21:17,306]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:21:20,458]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:21:24,428]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:21:24,523]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:21:29,046]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:21:31,317]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:21:35,790]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:21:38,083]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:21:38,785]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:21:42,088]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:21:46,140]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:21:48,202]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:21:50,879]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:21:53,306]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:21:55,324]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:21:59,604]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:22:00,154]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:22:07,447]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:22:14,836]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:22:15,019]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:22:15,247]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:22:26,778]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:22:27,291]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:22:32,986]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:22:35,751]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:22:41,665]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:22:43,699]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:22:46,592]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:22:50,557]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:22:55,901]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:22:56,739]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:23:01,815]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:23:04,393]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:23:06,928]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:23:09,529]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:23:10,975]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:23:14,104]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:23:20,392]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:23:21,323]\u001b[0m Trial 620 finished with value: 4.174302617421057 and parameters: {'n_hidden': 3, 'learning_rate': 0.00144059296837737, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22796372214292132, 'dropout_rate_Layer_2': 0.058870020363646504, 'dropout_rate_Layer_3': 0.0866153586287495, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003047992634854812, 'l1_Layer_2': 0.0006539700297919151, 'l1_Layer_3': 0.03845451108760677, 'n_units_Layer_1': 60, 'n_units_Layer_2': 100, 'n_units_Layer_3': 265}. Best is trial 377 with value: 3.7218176098578817.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.17 | sMAPE for Validation Set is: 15.80% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 15.64 | sMAPE for Test Set is: 15.13% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:23:25,737]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:23:32,235]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:23:34,876]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:23:37,495]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:23:39,564]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:23:43,226]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:23:50,195]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:23:52,510]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:23:55,482]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:23:58,797]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:24:01,848]\u001b[0m Trial 646 finished with value: 4.622320439578653 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008251457994123997, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14896034091763516, 'dropout_rate_Layer_2': 0.006005469815213521, 'dropout_rate_Layer_3': 0.17811255194042758, 'dropout_rate_Layer_4': 0.36261500583467104, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0030403942980253723, 'l1_Layer_2': 0.005292097043932457, 'l1_Layer_3': 8.771300070748495e-05, 'l1_Layer_4': 2.566117176004195e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 150, 'n_units_Layer_3': 155, 'n_units_Layer_4': 265}. Best is trial 377 with value: 3.7218176098578817.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.62 | sMAPE for Validation Set is: 17.63% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 48.11 | sMAPE for Test Set is: 36.14% | rMAE for Test Set is: 2.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:24:02,407]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:24:06,137]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:24:08,426]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:24:10,267]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:24:12,483]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:24:18,473]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:24:24,621]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:24:29,296]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:24:32,706]\u001b[0m Trial 650 finished with value: 4.182591938742245 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013709337618074417, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22265913970115578, 'dropout_rate_Layer_2': 0.05014338167974722, 'dropout_rate_Layer_3': 0.07464274117726381, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00023466447519883304, 'l1_Layer_2': 0.0007416564450104905, 'l1_Layer_3': 0.046516951735893576, 'n_units_Layer_1': 60, 'n_units_Layer_2': 90, 'n_units_Layer_3': 260}. Best is trial 377 with value: 3.7218176098578817.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.18 | sMAPE for Validation Set is: 15.87% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 13.46 | sMAPE for Test Set is: 13.32% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:24:35,243]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:24:38,186]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:24:46,721]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:24:50,917]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:24:56,344]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:25:05,856]\u001b[0m Trial 671 finished with value: 4.487523293464186 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007108132855797514, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12580488900213577, 'dropout_rate_Layer_2': 0.007451893906028281, 'dropout_rate_Layer_3': 0.15226419673190925, 'dropout_rate_Layer_4': 0.3456862296222026, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0029069267998543934, 'l1_Layer_2': 0.008799146181594846, 'l1_Layer_3': 0.00016454548028206847, 'l1_Layer_4': 1.3837308425311364e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 250, 'n_units_Layer_3': 155, 'n_units_Layer_4': 255}. Best is trial 377 with value: 3.7218176098578817.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.49 | sMAPE for Validation Set is: 17.14% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 47.98 | sMAPE for Test Set is: 36.23% | rMAE for Test Set is: 2.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:25:09,309]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:25:12,471]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:25:12,864]\u001b[0m Trial 667 finished with value: 4.918420551724199 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011547302885016257, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16163299760466587, 'dropout_rate_Layer_2': 0.009399880039281983, 'dropout_rate_Layer_3': 0.004967833006710942, 'dropout_rate_Layer_4': 0.3587015319156832, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0030931261603861903, 'l1_Layer_2': 0.0097343233226185, 'l1_Layer_3': 0.00015347569168725435, 'l1_Layer_4': 2.3649489394210588e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 135, 'n_units_Layer_3': 50, 'n_units_Layer_4': 255}. Best is trial 377 with value: 3.7218176098578817.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.92 | sMAPE for Validation Set is: 18.67% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 51.33 | sMAPE for Test Set is: 39.44% | rMAE for Test Set is: 2.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:25:19,090]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:25:19,271]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:25:19,872]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:25:25,920]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:25:28,592]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:25:30,468]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:25:33,554]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:25:38,137]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:25:41,636]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:25:44,626]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:25:45,273]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:26:05,361]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:26:28,842]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.58 | sMAPE for Validation Set is: 17.29% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 49.52 | sMAPE for Test Set is: 37.57% | rMAE for Test Set is: 2.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:26:30,472]\u001b[0m Trial 689 finished with value: 4.577120609456117 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009150370924795742, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04903646261420355, 'dropout_rate_Layer_2': 0.005549777058066259, 'dropout_rate_Layer_3': 0.0015492060788929174, 'dropout_rate_Layer_4': 0.3491118114353511, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0030232939967456945, 'l1_Layer_2': 0.008284496753115439, 'l1_Layer_3': 0.00020105535866187134, 'l1_Layer_4': 1.567552657581481e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 135, 'n_units_Layer_3': 50, 'n_units_Layer_4': 245}. Best is trial 377 with value: 3.7218176098578817.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:26:36,347]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:26:36,750]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:26:37,644]\u001b[0m Trial 675 finished with value: 4.208632081225722 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009938313205749144, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23598336499335143, 'dropout_rate_Layer_2': 0.052074566621981906, 'dropout_rate_Layer_3': 0.08560717607787058, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014744851532888788, 'l1_Layer_2': 0.0009105327580577604, 'l1_Layer_3': 0.05008012868240037, 'n_units_Layer_1': 60, 'n_units_Layer_2': 100, 'n_units_Layer_3': 260}. Best is trial 377 with value: 3.7218176098578817.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.21 | sMAPE for Validation Set is: 15.83% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 13.91 | sMAPE for Test Set is: 13.46% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:26:44,232]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:26:54,982]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:26:59,074]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:27:01,944]\u001b[0m Trial 696 finished with value: 3.812272787208538 and parameters: {'n_hidden': 3, 'learning_rate': 0.001588728481750724, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02528798407053664, 'dropout_rate_Layer_2': 0.014258011716585457, 'dropout_rate_Layer_3': 0.1002526320829408, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008207135545325286, 'l1_Layer_2': 0.0006048124245519825, 'l1_Layer_3': 4.7412747595618155e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 125, 'n_units_Layer_3': 150}. Best is trial 377 with value: 3.7218176098578817.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.81 | sMAPE for Validation Set is: 14.64% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 12.45 | sMAPE for Test Set is: 12.24% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:27:19,360]\u001b[0m Trial 697 finished with value: 3.8665991262308457 and parameters: {'n_hidden': 3, 'learning_rate': 0.001717264811354177, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09577412765174609, 'dropout_rate_Layer_2': 0.006665613258167347, 'dropout_rate_Layer_3': 0.3279724368716773, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001244784448510454, 'l1_Layer_2': 0.0003104044041758675, 'l1_Layer_3': 2.266206745691474e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 130, 'n_units_Layer_3': 160}. Best is trial 377 with value: 3.7218176098578817.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.87 | sMAPE for Validation Set is: 15.11% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 12.37 | sMAPE for Test Set is: 12.43% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:27:28,892]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:27:32,349]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:27:36,528]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.39 | sMAPE for Validation Set is: 16.60% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 47.55 | sMAPE for Test Set is: 35.63% | rMAE for Test Set is: 2.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:27:38,939]\u001b[0m Trial 698 finished with value: 4.385539150428418 and parameters: {'n_hidden': 4, 'learning_rate': 0.00088348474557052, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04158536160855188, 'dropout_rate_Layer_2': 0.0066628176263430795, 'dropout_rate_Layer_3': 0.0012585353325290267, 'dropout_rate_Layer_4': 0.3311918509149386, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00257420649079802, 'l1_Layer_2': 0.004805497847773595, 'l1_Layer_3': 0.00016068523006823384, 'l1_Layer_4': 1.6245045646021296e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 135, 'n_units_Layer_3': 50, 'n_units_Layer_4': 245}. Best is trial 377 with value: 3.7218176098578817.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:27:52,836]\u001b[0m Trial 701 finished with value: 4.36606995480749 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008470178395518345, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.044441849904751925, 'dropout_rate_Layer_2': 0.0005211969435317666, 'dropout_rate_Layer_3': 0.0021294851164277437, 'dropout_rate_Layer_4': 0.3555089024699431, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002715501454184117, 'l1_Layer_2': 0.004661687243154086, 'l1_Layer_3': 0.0002010040058898168, 'l1_Layer_4': 1.48796618599613e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 140, 'n_units_Layer_3': 50, 'n_units_Layer_4': 255}. Best is trial 377 with value: 3.7218176098578817.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.37 | sMAPE for Validation Set is: 16.60% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 48.25 | sMAPE for Test Set is: 36.42% | rMAE for Test Set is: 2.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:28:06,362]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:28:06,786]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:28:10,770]\u001b[0m Trial 702 finished with value: 4.443759987852368 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009221314481697905, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05216577985946431, 'dropout_rate_Layer_2': 3.7619162371701174e-05, 'dropout_rate_Layer_3': 0.02053381305989177, 'dropout_rate_Layer_4': 0.3425183153698789, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0024816328425023067, 'l1_Layer_2': 0.004905469934428265, 'l1_Layer_3': 0.00019198587392756214, 'l1_Layer_4': 1.5751961470285287e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 135, 'n_units_Layer_3': 50, 'n_units_Layer_4': 245}. Best is trial 377 with value: 3.7218176098578817.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.44 | sMAPE for Validation Set is: 16.97% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 47.59 | sMAPE for Test Set is: 35.71% | rMAE for Test Set is: 2.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:28:12,705]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:28:15,188]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:28:18,886]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:28:21,945]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:28:24,327]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:28:30,667]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:28:33,768]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:28:36,823]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:28:39,665]\u001b[0m Trial 707 finished with value: 3.7982022268311257 and parameters: {'n_hidden': 3, 'learning_rate': 0.001651404715521134, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09966027324210032, 'dropout_rate_Layer_2': 0.02178717208332607, 'dropout_rate_Layer_3': 0.09151933257837044, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018753468302386764, 'l1_Layer_2': 0.00026189892533641187, 'l1_Layer_3': 4.035385825436634e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 130, 'n_units_Layer_3': 290}. Best is trial 377 with value: 3.7218176098578817.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:28:39,688]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.80 | sMAPE for Validation Set is: 14.54% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 12.45 | sMAPE for Test Set is: 12.54% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:28:50,629]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:28:52,894]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:28:53,765]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:29:03,820]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:29:06,995]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:29:07,652]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:29:14,434]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:29:18,320]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:29:22,323]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:29:26,137]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:29:29,883]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:29:30,064]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:29:36,138]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:29:42,763]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:29:45,006]\u001b[0m Trial 723 finished with value: 3.865979196496633 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015534800615275791, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08444082523236231, 'dropout_rate_Layer_2': 0.036667847615540164, 'dropout_rate_Layer_3': 0.09429909428709164, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002346530129661086, 'l1_Layer_2': 0.0002849166724953819, 'l1_Layer_3': 4.087073169002512e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 125, 'n_units_Layer_3': 285}. Best is trial 377 with value: 3.7218176098578817.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.87 | sMAPE for Validation Set is: 15.09% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 12.38 | sMAPE for Test Set is: 12.60% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:29:49,328]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:29:59,890]\u001b[0m Trial 733 finished with value: 3.903814813246745 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016008403486864596, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10560084906219123, 'dropout_rate_Layer_2': 0.00011353416362768928, 'dropout_rate_Layer_3': 0.07156882995412207, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00033101621735339424, 'l1_Layer_2': 0.00030164010700470684, 'l1_Layer_3': 4.912690140051544e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 105, 'n_units_Layer_3': 255}. Best is trial 377 with value: 3.7218176098578817.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.90 | sMAPE for Validation Set is: 15.05% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 12.83 | sMAPE for Test Set is: 12.88% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:30:01,079]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:30:03,080]\u001b[0m Trial 731 finished with value: 4.066917891764292 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015227849842899758, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12129786491936359, 'dropout_rate_Layer_2': 0.02009254203412011, 'dropout_rate_Layer_3': 0.10544344532074892, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0013001493862705006, 'l1_Layer_2': 0.00025402904420967674, 'l1_Layer_3': 4.8648462956605125e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 250, 'n_units_Layer_3': 255}. Best is trial 377 with value: 3.7218176098578817.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.07 | sMAPE for Validation Set is: 15.48% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 12.16 | sMAPE for Test Set is: 12.49% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:30:08,738]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:30:12,606]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:30:16,791]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:30:17,791]\u001b[0m Trial 732 finished with value: 3.8892469917185184 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015666719757949127, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.111647478603274, 'dropout_rate_Layer_2': 0.020303981475701872, 'dropout_rate_Layer_3': 0.10392125997360864, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001169456205419438, 'l1_Layer_2': 0.0002646223912522323, 'l1_Layer_3': 4.436321881547636e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 85, 'n_units_Layer_3': 255}. Best is trial 377 with value: 3.7218176098578817.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.89 | sMAPE for Validation Set is: 14.94% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 13.54 | sMAPE for Test Set is: 13.42% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:30:19,658]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:30:21,137]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:30:25,562]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:30:28,295]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:30:31,906]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:30:35,654]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:30:39,487]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:30:40,149]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:30:45,202]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:30:47,674]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:30:51,414]\u001b[0m Trial 736 finished with value: 4.495767859628938 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008269601529373601, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.049750301993418566, 'dropout_rate_Layer_2': 0.01651435458835218, 'dropout_rate_Layer_3': 0.04669185812497591, 'dropout_rate_Layer_4': 0.34385260811234075, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.003285323167645496, 'l1_Layer_2': 0.0037674212138975377, 'l1_Layer_3': 0.0001617358174495585, 'l1_Layer_4': 1.6853775741996264e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 135, 'n_units_Layer_3': 50, 'n_units_Layer_4': 235}. Best is trial 377 with value: 3.7218176098578817.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.50 | sMAPE for Validation Set is: 16.98% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 48.24 | sMAPE for Test Set is: 36.43% | rMAE for Test Set is: 2.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:30:51,681]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:31:21,908]\u001b[0m Trial 751 finished with value: 4.0390536775262875 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015283190150161229, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12119054986369773, 'dropout_rate_Layer_2': 0.009112077094291661, 'dropout_rate_Layer_3': 0.10351801727479844, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018669074783758154, 'l1_Layer_2': 0.00026023722582650324, 'l1_Layer_3': 3.2213140613263496e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 90, 'n_units_Layer_3': 255}. Best is trial 377 with value: 3.7218176098578817.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.04 | sMAPE for Validation Set is: 15.26% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 12.74 | sMAPE for Test Set is: 13.04% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:31:26,975]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:31:30,916]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:31:35,671]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:31:39,784]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:31:47,122]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:31:49,843]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:31:54,009]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:31:56,145]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:31:58,925]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:32:01,829]\u001b[0m Trial 743 finished with value: 4.377940979256271 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013259772132543364, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2798489909437354, 'dropout_rate_Layer_2': 0.019281577235915115, 'dropout_rate_Layer_3': 0.2735423556353952, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00030257934909784805, 'l1_Layer_2': 4.094950139961394e-05, 'l1_Layer_3': 0.06647177035305397, 'n_units_Layer_1': 90, 'n_units_Layer_2': 90, 'n_units_Layer_3': 250}. Best is trial 377 with value: 3.7218176098578817.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.38 | sMAPE for Validation Set is: 16.49% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 13.31 | sMAPE for Test Set is: 13.48% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:32:07,749]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:32:08,105]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:32:14,248]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:32:14,652]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:32:20,757]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:32:31,031]\u001b[0m Trial 760 finished with value: 3.7873146193942873 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011713768682103203, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12114792523081401, 'dropout_rate_Layer_2': 0.01409161750990132, 'dropout_rate_Layer_3': 0.060599044850884486, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0014013084071589853, 'l1_Layer_2': 0.0003085896617798959, 'l1_Layer_3': 4.518138451233519e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 90, 'n_units_Layer_3': 255}. Best is trial 377 with value: 3.7218176098578817.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.79 | sMAPE for Validation Set is: 14.65% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 12.20 | sMAPE for Test Set is: 12.42% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:32:33,523]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:32:39,330]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:32:40,267]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:32:43,732]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:32:46,901]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:32:49,711]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:32:56,859]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:33:00,582]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:33:05,139]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:33:09,531]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:33:10,001]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:33:15,007]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:33:18,713]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:33:25,108]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:33:31,327]\u001b[0m Trial 774 finished with value: 4.019167558238284 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012177091218749038, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12482179759419101, 'dropout_rate_Layer_2': 0.012523870972727086, 'dropout_rate_Layer_3': 0.05369480890822177, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00121791654358476, 'l1_Layer_2': 0.0003054823531203596, 'l1_Layer_3': 5.6920498647701523e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 80, 'n_units_Layer_3': 255}. Best is trial 377 with value: 3.7218176098578817.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.02 | sMAPE for Validation Set is: 15.45% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 13.67 | sMAPE for Test Set is: 13.14% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:33:40,992]\u001b[0m Trial 784 finished with value: 4.242067497611157 and parameters: {'n_hidden': 3, 'learning_rate': 0.004577172570342767, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2518209053099129, 'dropout_rate_Layer_2': 7.53077837219035e-05, 'dropout_rate_Layer_3': 0.07169999171303629, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002912729572207509, 'l1_Layer_2': 0.0005694344497304522, 'l1_Layer_3': 0.03885486633177625, 'n_units_Layer_1': 75, 'n_units_Layer_2': 85, 'n_units_Layer_3': 230}. Best is trial 377 with value: 3.7218176098578817.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.24 | sMAPE for Validation Set is: 15.97% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 12.78 | sMAPE for Test Set is: 13.13% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:33:45,032]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:33:49,528]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:33:51,385]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:33:54,798]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:33:57,892]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:34:04,835]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:34:08,666]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:34:09,419]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:34:15,220]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:34:16,792]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:34:21,340]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:34:21,576]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:34:22,939]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:34:27,828]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:34:30,114]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:34:33,795]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:34:36,533]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:34:42,985]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:34:47,100]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:34:49,751]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:34:52,208]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:34:54,638]\u001b[0m Trial 799 finished with value: 4.101562548750732 and parameters: {'n_hidden': 3, 'learning_rate': 0.004708974744490682, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25223961171371473, 'dropout_rate_Layer_2': 0.0007993768861369785, 'dropout_rate_Layer_3': 0.015275222435748505, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004793547748280005, 'l1_Layer_2': 0.0007780574822822888, 'l1_Layer_3': 0.037069430574651126, 'n_units_Layer_1': 55, 'n_units_Layer_2': 85, 'n_units_Layer_3': 170}. Best is trial 377 with value: 3.7218176098578817.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.10 | sMAPE for Validation Set is: 15.54% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 12.71 | sMAPE for Test Set is: 12.90% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:34:57,313]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:34:58,232]\u001b[0m Trial 803 finished with value: 4.151354547250901 and parameters: {'n_hidden': 3, 'learning_rate': 0.00510319197893064, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.256104456597572, 'dropout_rate_Layer_2': 0.0012618464182319578, 'dropout_rate_Layer_3': 0.033303349360440104, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004258478895436534, 'l1_Layer_2': 0.0008231997529986844, 'l1_Layer_3': 0.03672221562702032, 'n_units_Layer_1': 60, 'n_units_Layer_2': 85, 'n_units_Layer_3': 255}. Best is trial 377 with value: 3.7218176098578817.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.15 | sMAPE for Validation Set is: 15.71% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 13.29 | sMAPE for Test Set is: 13.35% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:34:59,344]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:34:59,529]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:35:07,347]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:35:20,866]\u001b[0m Trial 811 finished with value: 4.182090351349132 and parameters: {'n_hidden': 3, 'learning_rate': 0.005962206331453246, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24312404844832958, 'dropout_rate_Layer_2': 0.016197726170929724, 'dropout_rate_Layer_3': 0.018122402340399822, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005650462559734614, 'l1_Layer_2': 0.001390007047144976, 'l1_Layer_3': 0.030661979742747248, 'n_units_Layer_1': 50, 'n_units_Layer_2': 110, 'n_units_Layer_3': 170}. Best is trial 377 with value: 3.7218176098578817.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.18 | sMAPE for Validation Set is: 15.80% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 13.12 | sMAPE for Test Set is: 13.09% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:35:25,127]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:35:27,786]\u001b[0m Trial 814 finished with value: 4.210801835401035 and parameters: {'n_hidden': 3, 'learning_rate': 0.005559333143745341, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24179376078237036, 'dropout_rate_Layer_2': 0.010630613339194128, 'dropout_rate_Layer_3': 0.03603357881371998, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005851721791856788, 'l1_Layer_2': 0.001556111661459284, 'l1_Layer_3': 0.03620589129067014, 'n_units_Layer_1': 50, 'n_units_Layer_2': 110, 'n_units_Layer_3': 165}. Best is trial 377 with value: 3.7218176098578817.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.21 | sMAPE for Validation Set is: 15.86% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 12.59 | sMAPE for Test Set is: 12.75% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:35:29,351]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:35:33,046]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:35:35,412]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:35:39,011]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:35:39,388]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:35:44,821]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:35:45,340]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:35:51,568]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:35:52,405]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:35:57,617]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:35:59,388]\u001b[0m Trial 812 finished with value: 3.9374432765307845 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008724905560218195, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0955658196766151, 'dropout_rate_Layer_2': 0.021113656658644998, 'dropout_rate_Layer_3': 0.06399548140048207, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0019121839043875712, 'l1_Layer_2': 0.0002771988096695113, 'l1_Layer_3': 3.7274524172839224e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 85, 'n_units_Layer_3': 260}. Best is trial 377 with value: 3.7218176098578817.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.94 | sMAPE for Validation Set is: 15.44% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 11.71 | sMAPE for Test Set is: 12.05% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:36:00,112]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:36:04,626]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:36:07,610]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:36:07,902]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:36:09,015]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:36:15,646]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:36:17,979]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:36:21,541]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:36:24,407]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:36:28,111]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:36:28,814]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:36:29,167]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:36:29,423]\u001b[0m Trial 827 finished with value: 4.072536702578889 and parameters: {'n_hidden': 3, 'learning_rate': 0.004118227812843809, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2440687752252985, 'dropout_rate_Layer_2': 0.011206469887640826, 'dropout_rate_Layer_3': 0.015864895806544703, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003306805118414744, 'l1_Layer_2': 0.001498611861221545, 'l1_Layer_3': 0.029503737346014153, 'n_units_Layer_1': 50, 'n_units_Layer_2': 115, 'n_units_Layer_3': 145}. Best is trial 377 with value: 3.7218176098578817.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.07 | sMAPE for Validation Set is: 15.46% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 12.33 | sMAPE for Test Set is: 12.52% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:36:34,192]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:36:38,723]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:36:40,115]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:36:40,445]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:36:42,656]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:36:49,157]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:36:51,253]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:36:52,558]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:36:55,266]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:36:59,182]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:36:59,545]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:37:02,854]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:37:07,250]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:37:07,340]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:37:08,827]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:37:14,517]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:37:14,741]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:37:18,976]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:37:21,458]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:37:25,608]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:37:28,200]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:37:30,402]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:37:34,072]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:37:34,737]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:37:39,452]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:37:42,040]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:37:46,948]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:37:47,693]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:37:48,101]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:37:52,052]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:37:55,703]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:37:56,365]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:38:05,031]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:38:10,032]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:38:10,196]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:38:17,285]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:38:20,069]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:38:23,953]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:38:24,446]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:38:28,543]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.16 | sMAPE for Validation Set is: 15.70% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 13.46 | sMAPE for Test Set is: 13.17% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:38:28,967]\u001b[0m Trial 872 finished with value: 4.158293006413494 and parameters: {'n_hidden': 3, 'learning_rate': 0.004975741460934211, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25853396350772095, 'dropout_rate_Layer_2': 0.021705814392124805, 'dropout_rate_Layer_3': 0.033317006340739676, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00032562663186930506, 'l1_Layer_2': 0.0014008324945745142, 'l1_Layer_3': 0.053240796711425106, 'n_units_Layer_1': 65, 'n_units_Layer_2': 120, 'n_units_Layer_3': 180}. Best is trial 377 with value: 3.7218176098578817.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:38:34,163]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:38:34,327]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:38:35,492]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:38:41,875]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:38:42,636]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:38:46,151]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:38:46,282]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:38:52,212]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:38:55,375]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:38:55,789]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:38:55,938]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:39:03,052]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:39:03,413]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:39:03,745]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:39:10,457]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:39:11,167]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:39:16,354]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:39:20,491]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:39:23,901]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:39:27,608]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:39:37,612]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:39:41,868]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:39:42,550]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:39:49,431]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:39:50,332]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:39:51,357]\u001b[0m Trial 883 finished with value: 3.6504163992425696 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012914133682692286, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10256279649174628, 'dropout_rate_Layer_2': 0.008073837962022217, 'dropout_rate_Layer_3': 0.29278764751856157, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012817662751083859, 'l1_Layer_2': 1.8443453877368997e-05, 'l1_Layer_3': 0.0004406126231019253, 'n_units_Layer_1': 90, 'n_units_Layer_2': 120, 'n_units_Layer_3': 160}. Best is trial 883 with value: 3.6504163992425696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.65 | sMAPE for Validation Set is: 14.21% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 12.46 | sMAPE for Test Set is: 12.20% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:39:55,503]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:39:57,626]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:40:01,440]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:40:02,732]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:40:05,552]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:40:06,433]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:40:10,638]\u001b[0m Trial 900 finished with value: 3.794380114429536 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015420751147613532, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014630315743115302, 'dropout_rate_Layer_2': 0.2071291711790789, 'dropout_rate_Layer_3': 0.09183523523031831, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006845726773228581, 'l1_Layer_2': 0.0002188934321211086, 'l1_Layer_3': 5.516858293491245e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 110, 'n_units_Layer_3': 130}. Best is trial 883 with value: 3.6504163992425696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.79 | sMAPE for Validation Set is: 14.87% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 12.44 | sMAPE for Test Set is: 12.51% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:40:13,271]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:40:23,576]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:40:26,498]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:40:26,921]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:40:27,847]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:40:32,040]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:40:36,173]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:40:47,644]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:40:53,606]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:40:58,387]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:41:02,758]\u001b[0m Trial 922 finished with value: 4.157481117507541 and parameters: {'n_hidden': 3, 'learning_rate': 0.004258915814542648, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2537841377103435, 'dropout_rate_Layer_2': 0.04547653807706044, 'dropout_rate_Layer_3': 0.05302705316645382, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005082937326597272, 'l1_Layer_2': 1.705095085114966e-05, 'l1_Layer_3': 0.03886562537340357, 'n_units_Layer_1': 65, 'n_units_Layer_2': 90, 'n_units_Layer_3': 175}. Best is trial 883 with value: 3.6504163992425696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.16 | sMAPE for Validation Set is: 15.71% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 14.48 | sMAPE for Test Set is: 13.65% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:41:08,754]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:41:10,340]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:41:13,590]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:41:16,636]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:41:20,850]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:41:21,974]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:41:26,734]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:41:26,959]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:41:27,758]\u001b[0m Trial 921 finished with value: 3.784308058981582 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012664757066635013, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.015618456019635973, 'dropout_rate_Layer_2': 0.22057937792906057, 'dropout_rate_Layer_3': 0.09204733069932039, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008605560428480862, 'l1_Layer_2': 0.00043595662432728544, 'l1_Layer_3': 0.0004894702530023255, 'n_units_Layer_1': 100, 'n_units_Layer_2': 120, 'n_units_Layer_3': 125}. Best is trial 883 with value: 3.6504163992425696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.78 | sMAPE for Validation Set is: 14.94% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 11.86 | sMAPE for Test Set is: 12.07% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:41:33,298]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:41:34,699]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:41:35,499]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:41:39,540]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:41:42,254]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:41:43,994]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:41:47,634]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:41:49,944]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:41:50,684]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:41:50,738]\u001b[0m Trial 932 finished with value: 4.195638605789 and parameters: {'n_hidden': 3, 'learning_rate': 0.004149817084309501, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25827117760822305, 'dropout_rate_Layer_2': 0.045249005035725515, 'dropout_rate_Layer_3': 0.05350954451292772, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004969470434615133, 'l1_Layer_2': 1.3116226929428117e-05, 'l1_Layer_3': 0.040533130909696125, 'n_units_Layer_1': 65, 'n_units_Layer_2': 75, 'n_units_Layer_3': 175}. Best is trial 883 with value: 3.6504163992425696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.20 | sMAPE for Validation Set is: 15.78% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 15.13 | sMAPE for Test Set is: 14.40% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:41:55,268]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:42:04,679]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:42:05,700]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:42:10,104]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:42:13,864]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:42:15,874]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:42:20,871]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:42:27,698]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:42:41,956]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:42:46,176]\u001b[0m Trial 952 finished with value: 4.239776823434325 and parameters: {'n_hidden': 3, 'learning_rate': 0.003554350190865631, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25596693711024576, 'dropout_rate_Layer_2': 0.05908037258536729, 'dropout_rate_Layer_3': 0.050680635841777184, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010562224932418511, 'l1_Layer_2': 1.2468164165488081e-05, 'l1_Layer_3': 0.042534808463722595, 'n_units_Layer_1': 80, 'n_units_Layer_2': 70, 'n_units_Layer_3': 185}. Best is trial 883 with value: 3.6504163992425696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.24 | sMAPE for Validation Set is: 16.00% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 12.63 | sMAPE for Test Set is: 12.80% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:42:48,460]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:42:52,805]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:42:57,146]\u001b[0m Trial 953 finished with value: 4.207127723680565 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035762985380106468, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2550672673475624, 'dropout_rate_Layer_2': 0.05360159248696361, 'dropout_rate_Layer_3': 0.050985073269703335, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010170202100249252, 'l1_Layer_2': 1.062886151881885e-05, 'l1_Layer_3': 0.0406923514349348, 'n_units_Layer_1': 65, 'n_units_Layer_2': 90, 'n_units_Layer_3': 175}. Best is trial 883 with value: 3.6504163992425696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.21 | sMAPE for Validation Set is: 15.95% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 14.11 | sMAPE for Test Set is: 13.53% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:43:03,302]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:43:19,110]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:43:20,090]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:43:25,510]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:43:26,191]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:43:30,212]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:43:31,239]\u001b[0m Trial 946 finished with value: 3.643694200371439 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009627635815519819, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.004753388102806755, 'dropout_rate_Layer_2': 0.22520206189249428, 'dropout_rate_Layer_3': 0.09307323838019194, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006680533908210199, 'l1_Layer_2': 0.00046173247735980936, 'l1_Layer_3': 0.0007472537243116688, 'n_units_Layer_1': 100, 'n_units_Layer_2': 125, 'n_units_Layer_3': 125}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.64 | sMAPE for Validation Set is: 14.20% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 12.24 | sMAPE for Test Set is: 12.03% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:43:36,084]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:43:37,039]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:43:38,667]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:43:40,941]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:43:43,235]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:43:45,271]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:43:46,861]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:43:51,515]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:43:56,046]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:43:59,718]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:44:04,064]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:44:05,316]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:44:11,333]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:44:13,541]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:44:16,272]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.30 | sMAPE for Validation Set is: 16.22% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 15.69 | sMAPE for Test Set is: 14.52% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:44:17,962]\u001b[0m Trial 971 finished with value: 4.302885499483143 and parameters: {'n_hidden': 3, 'learning_rate': 0.004761230977137197, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25139847792565495, 'dropout_rate_Layer_2': 0.050752596032156844, 'dropout_rate_Layer_3': 0.07639244027280107, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00044016377655177696, 'l1_Layer_2': 1.927186525195832e-05, 'l1_Layer_3': 0.03702451958404541, 'n_units_Layer_1': 65, 'n_units_Layer_2': 95, 'n_units_Layer_3': 165}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:44:21,237]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:44:23,022]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:44:28,281]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:44:34,640]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:44:35,446]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:44:41,131]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:44:41,657]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:44:47,432]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:44:49,873]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:44:53,962]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:44:54,626]\u001b[0m Trial 983 finished with value: 4.379413453392552 and parameters: {'n_hidden': 3, 'learning_rate': 0.003606811855092107, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22342955291579825, 'dropout_rate_Layer_2': 0.037240032930483585, 'dropout_rate_Layer_3': 0.31619401614637366, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00034495794944080523, 'l1_Layer_2': 4.475316923892307e-05, 'l1_Layer_3': 0.02819591005172591, 'n_units_Layer_1': 60, 'n_units_Layer_2': 90, 'n_units_Layer_3': 265}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.38 | sMAPE for Validation Set is: 16.56% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 13.48 | sMAPE for Test Set is: 13.55% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:44:58,474]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:45:00,882]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:45:02,986]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:45:07,067]\u001b[0m Trial 965 finished with value: 3.6597869800830893 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008612355667328138, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009623168720337671, 'dropout_rate_Layer_2': 0.2235969779768602, 'dropout_rate_Layer_3': 0.08539601610864876, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011827007421838635, 'l1_Layer_2': 0.00029759011967321586, 'l1_Layer_3': 9.190930643068054e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 135, 'n_units_Layer_3': 120}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.66 | sMAPE for Validation Set is: 14.30% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 12.00 | sMAPE for Test Set is: 11.96% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:45:10,462]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:45:11,041]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:45:16,457]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:45:20,109]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:45:23,756]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:45:27,057]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:45:28,584]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:45:33,465]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:45:33,927]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:45:38,763]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:45:41,547]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:45:43,579]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:45:47,993]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:45:50,254]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:45:55,724]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:45:55,864]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:46:02,084]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:46:02,641]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:46:09,912]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:46:10,247]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:46:13,644]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:46:18,163]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:46:18,394]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:46:22,925]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:46:25,481]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:46:26,720]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:46:31,430]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:46:31,928]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:46:37,656]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:46:37,854]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:46:38,200]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:46:39,711]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:46:47,564]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:46:48,168]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:46:50,241]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:46:51,149]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:46:56,719]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:46:59,324]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:47:01,903]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:47:02,528]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:47:03,844]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:47:09,631]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:47:13,591]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:47:15,862]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:47:20,263]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:47:22,430]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:47:26,983]\u001b[0m Trial 1030 finished with value: 4.155832841274577 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032496575887413074, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25384962998649707, 'dropout_rate_Layer_2': 0.04350408254588889, 'dropout_rate_Layer_3': 0.07955843264599097, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009766769563908412, 'l1_Layer_2': 2.6564468496124197e-05, 'l1_Layer_3': 0.030381971067093276, 'n_units_Layer_1': 60, 'n_units_Layer_2': 160, 'n_units_Layer_3': 195}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.16 | sMAPE for Validation Set is: 15.70% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 12.39 | sMAPE for Test Set is: 12.77% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:47:27,660]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:47:27,941]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:47:37,111]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:47:37,542]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:47:38,186]\u001b[0m Trial 1039 finished with value: 4.173171840006263 and parameters: {'n_hidden': 3, 'learning_rate': 0.0052298201008757, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24198936198931328, 'dropout_rate_Layer_2': 0.011760002771007218, 'dropout_rate_Layer_3': 0.015884799681262666, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006347894696568067, 'l1_Layer_2': 0.0011538178175323499, 'l1_Layer_3': 0.04169807088424082, 'n_units_Layer_1': 50, 'n_units_Layer_2': 95, 'n_units_Layer_3': 165}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.17 | sMAPE for Validation Set is: 15.72% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 13.80 | sMAPE for Test Set is: 13.48% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:47:47,430]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:47:47,811]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:47:57,922]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:47:58,313]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:48:04,905]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:48:07,918]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:48:10,734]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:48:15,755]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:48:17,268]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:48:18,178]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:48:23,948]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:48:24,304]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:48:28,193]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:48:31,522]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:48:33,830]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:48:39,361]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:48:45,487]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:48:46,831]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:48:54,686]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:48:55,458]\u001b[0m Trial 1063 finished with value: 3.917946713791473 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015922370084580993, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.012458953117703103, 'dropout_rate_Layer_2': 0.0002254607848760047, 'dropout_rate_Layer_3': 0.10232169311873306, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.740873069624394e-05, 'l1_Layer_2': 0.0007881703831224756, 'l1_Layer_3': 1.404358686146744e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 120, 'n_units_Layer_3': 295}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.92 | sMAPE for Validation Set is: 15.08% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 14.70 | sMAPE for Test Set is: 13.74% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:48:55,724]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:49:00,878]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:49:05,765]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:49:06,489]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:49:11,966]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:49:15,382]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:49:18,774]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:49:20,715]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:49:25,227]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.83 | sMAPE for Validation Set is: 14.58% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 12.36 | sMAPE for Test Set is: 12.70% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:49:27,513]\u001b[0m Trial 1062 finished with value: 3.829110102909189 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015498004467019958, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.012647500162533352, 'dropout_rate_Layer_2': 0.0002920556021506593, 'dropout_rate_Layer_3': 0.11043158954450441, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018817298268613866, 'l1_Layer_2': 0.0007477587611641337, 'l1_Layer_3': 5.3380552761707534e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 120, 'n_units_Layer_3': 130}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:49:34,696]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:49:40,289]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:49:40,633]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:49:46,178]\u001b[0m Trial 1071 finished with value: 4.035680313986988 and parameters: {'n_hidden': 3, 'learning_rate': 0.004437133560226098, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06351652895347204, 'dropout_rate_Layer_2': 0.00013970380934561974, 'dropout_rate_Layer_3': 0.04358738750770172, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006773152725336925, 'l1_Layer_2': 1.4159148634434878e-05, 'l1_Layer_3': 0.030234783688481714, 'n_units_Layer_1': 50, 'n_units_Layer_2': 80, 'n_units_Layer_3': 160}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.04 | sMAPE for Validation Set is: 15.37% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 13.49 | sMAPE for Test Set is: 13.27% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:49:50,206]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:49:55,226]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:49:55,406]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:49:56,961]\u001b[0m Trial 1075 finished with value: 3.935991987338222 and parameters: {'n_hidden': 3, 'learning_rate': 0.004950665506762967, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01719161400065053, 'dropout_rate_Layer_2': 0.0009605049580187626, 'dropout_rate_Layer_3': 0.02322301846896931, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00048440907591342365, 'l1_Layer_2': 1.6233640835167855e-05, 'l1_Layer_3': 0.029074397639386528, 'n_units_Layer_1': 100, 'n_units_Layer_2': 150, 'n_units_Layer_3': 180}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.94 | sMAPE for Validation Set is: 15.08% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 12.69 | sMAPE for Test Set is: 12.70% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:50:04,749]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:50:06,027]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:50:11,830]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:50:12,336]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:50:13,172]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:50:18,013]\u001b[0m Trial 1080 finished with value: 4.109051512505793 and parameters: {'n_hidden': 3, 'learning_rate': 0.00514396382408971, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2396386763644102, 'dropout_rate_Layer_2': 0.0003195833502081161, 'dropout_rate_Layer_3': 0.036681668500039094, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004936788787315896, 'l1_Layer_2': 3.483306128010089e-05, 'l1_Layer_3': 0.029069699928814804, 'n_units_Layer_1': 105, 'n_units_Layer_2': 95, 'n_units_Layer_3': 180}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.11 | sMAPE for Validation Set is: 15.49% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 12.40 | sMAPE for Test Set is: 12.71% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:50:23,289]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:50:26,432]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:50:30,728]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:50:32,163]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:50:35,574]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:50:36,517]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:50:40,714]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:50:45,211]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:50:46,525]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:50:50,220]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:50:51,443]\u001b[0m Trial 1094 finished with value: 3.9079783924209686 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015587192732857396, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03089606334353138, 'dropout_rate_Layer_2': 0.00977671046765967, 'dropout_rate_Layer_3': 0.09626432655111487, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.120321291231038e-05, 'l1_Layer_2': 0.0003550732937866133, 'l1_Layer_3': 1.1319755094911224e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 130, 'n_units_Layer_3': 285}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.91 | sMAPE for Validation Set is: 15.02% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.93 | sMAPE for Test Set is: 12.14% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:50:51,582]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:50:57,118]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:51:04,092]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:51:04,758]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:51:05,884]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:51:13,351]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:51:16,395]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:51:19,885]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:51:24,766]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:51:29,772]\u001b[0m Trial 1097 finished with value: 3.9041720250157597 and parameters: {'n_hidden': 3, 'learning_rate': 0.006995489752490955, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0882188235732946, 'dropout_rate_Layer_2': 0.0023000188767374917, 'dropout_rate_Layer_3': 0.0251636846046014, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004031584512947593, 'l1_Layer_2': 3.3107371519866026e-05, 'l1_Layer_3': 0.015234436815056873, 'n_units_Layer_1': 105, 'n_units_Layer_2': 160, 'n_units_Layer_3': 160}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.90 | sMAPE for Validation Set is: 14.85% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 12.74 | sMAPE for Test Set is: 12.61% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:51:32,802]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:51:36,960]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:51:37,216]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:51:43,351]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:51:46,608]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:51:47,622]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:51:53,990]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:51:54,071]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:52:02,104]\u001b[0m Trial 1107 finished with value: 3.9233462627485274 and parameters: {'n_hidden': 3, 'learning_rate': 0.007034257171752304, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01555184354295187, 'dropout_rate_Layer_2': 0.0008739315675523873, 'dropout_rate_Layer_3': 0.024221408365802326, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003972377534743798, 'l1_Layer_2': 3.460810256768637e-05, 'l1_Layer_3': 0.028341421068836588, 'n_units_Layer_1': 100, 'n_units_Layer_2': 150, 'n_units_Layer_3': 160}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.92 | sMAPE for Validation Set is: 14.89% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 12.48 | sMAPE for Test Set is: 12.56% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:52:02,766]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:52:03,256]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:52:10,883]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:52:13,172]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:52:14,359]\u001b[0m Trial 1116 finished with value: 4.028449077979768 and parameters: {'n_hidden': 3, 'learning_rate': 0.007209134579482778, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.020328890576095764, 'dropout_rate_Layer_2': 0.0013707738248195894, 'dropout_rate_Layer_3': 0.024949798620170317, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000399277905330558, 'l1_Layer_2': 3.877328199074548e-05, 'l1_Layer_3': 0.01646703429808753, 'n_units_Layer_1': 100, 'n_units_Layer_2': 150, 'n_units_Layer_3': 180}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.03 | sMAPE for Validation Set is: 15.28% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 12.24 | sMAPE for Test Set is: 12.52% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:52:16,075]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:52:26,988]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:52:32,276]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:52:36,010]\u001b[0m Trial 1124 finished with value: 3.810701348684216 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008868538134402269, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.012767577267003654, 'dropout_rate_Layer_2': 3.0977687096710865e-05, 'dropout_rate_Layer_3': 0.09378046022857195, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.383742072369269e-05, 'l1_Layer_2': 0.00033763441066509824, 'l1_Layer_3': 1.5467644418376076e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 125, 'n_units_Layer_3': 300}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.81 | sMAPE for Validation Set is: 14.49% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 12.07 | sMAPE for Test Set is: 12.26% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:52:55,215]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:52:59,990]\u001b[0m Trial 1131 finished with value: 3.9000146091349612 and parameters: {'n_hidden': 3, 'learning_rate': 0.007883081656691993, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.011265804310827948, 'dropout_rate_Layer_2': 0.0026603876659889794, 'dropout_rate_Layer_3': 0.025482410233942474, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004205101753142718, 'l1_Layer_2': 3.222913955851293e-05, 'l1_Layer_3': 0.014377923881742766, 'n_units_Layer_1': 100, 'n_units_Layer_2': 150, 'n_units_Layer_3': 160}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.90 | sMAPE for Validation Set is: 14.84% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 12.44 | sMAPE for Test Set is: 12.61% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:53:11,096]\u001b[0m Trial 1126 finished with value: 5.59972633701845 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008482695626677144, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16120688288170987, 'dropout_rate_Layer_2': 0.04451083333741116, 'dropout_rate_Layer_3': 0.00020805927465076873, 'dropout_rate_Layer_4': 0.14619086180560137, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0032340128687930506, 'l1_Layer_2': 0.015844423814547117, 'l1_Layer_3': 2.583431000961489e-05, 'l1_Layer_4': 0.016331592278450425, 'n_units_Layer_1': 160, 'n_units_Layer_2': 270, 'n_units_Layer_3': 145, 'n_units_Layer_4': 185}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.60 | sMAPE for Validation Set is: 20.49% | rMAE for Validation Set is: 0.92\n",
      "MAE for Test Set is: 54.91 | sMAPE for Test Set is: 43.65% | rMAE for Test Set is: 2.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:53:16,632]\u001b[0m Trial 1133 finished with value: 4.071404521286543 and parameters: {'n_hidden': 3, 'learning_rate': 0.011050013762610176, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.028606001972495954, 'dropout_rate_Layer_2': 0.0015255722757226884, 'dropout_rate_Layer_3': 0.03540325928205321, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004021777064718373, 'l1_Layer_2': 3.3315502890225057e-05, 'l1_Layer_3': 0.016722320956322815, 'n_units_Layer_1': 100, 'n_units_Layer_2': 155, 'n_units_Layer_3': 160}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.07 | sMAPE for Validation Set is: 15.42% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 13.81 | sMAPE for Test Set is: 13.56% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:53:24,253]\u001b[0m Trial 1132 finished with value: 3.7985271296657435 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006884582323722787, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.012779334647220558, 'dropout_rate_Layer_2': 0.000376016408196844, 'dropout_rate_Layer_3': 0.09206563955273322, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.634628463384493e-05, 'l1_Layer_2': 0.0003660344236934795, 'l1_Layer_3': 1.3470642088458974e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 125, 'n_units_Layer_3': 280}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.80 | sMAPE for Validation Set is: 14.58% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 11.97 | sMAPE for Test Set is: 12.22% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:53:28,771]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:53:31,247]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:53:37,284]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:53:43,493]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:53:46,423]\u001b[0m Trial 1127 finished with value: 3.7128017318913558 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008839324910598708, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0101562409523244, 'dropout_rate_Layer_2': 0.00028739780235713733, 'dropout_rate_Layer_3': 0.0930499810191798, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.007609618600947286, 'l1_Layer_2': 0.00034724666248402397, 'l1_Layer_3': 0.00025173542989421083, 'n_units_Layer_1': 110, 'n_units_Layer_2': 125, 'n_units_Layer_3': 280}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.71 | sMAPE for Validation Set is: 14.80% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 11.59 | sMAPE for Test Set is: 11.76% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:53:48,919]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:53:55,943]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:53:56,607]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:54:01,818]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:54:09,591]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:54:17,178]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:54:20,546]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:54:25,871]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:54:26,047]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:54:27,801]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:54:37,204]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:54:37,554]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:54:38,888]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:54:48,360]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:54:49,556]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:54:50,784]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.73 | sMAPE for Validation Set is: 14.71% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 11.43 | sMAPE for Test Set is: 11.70% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:54:56,535]\u001b[0m Trial 1145 finished with value: 3.726570306917862 and parameters: {'n_hidden': 3, 'learning_rate': 0.000671312272367633, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00271314472914392, 'dropout_rate_Layer_2': 0.000282674766981386, 'dropout_rate_Layer_3': 0.085665523809692, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7021131956670907e-05, 'l1_Layer_2': 0.00044427517341768136, 'l1_Layer_3': 1.0275953387510427e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 130, 'n_units_Layer_3': 300}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:54:59,292]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:55:04,004]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:55:04,674]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:55:04,734]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:55:05,349]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:55:10,576]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:55:17,845]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:55:36,528]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:55:39,578]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:55:43,761]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:55:44,053]\u001b[0m Trial 1165 finished with value: 3.9874270764698885 and parameters: {'n_hidden': 3, 'learning_rate': 0.008327296513644868, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.017649558927454987, 'dropout_rate_Layer_2': 0.014523529819750178, 'dropout_rate_Layer_3': 0.02305085251855884, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00030808419191516846, 'l1_Layer_2': 2.2536645277574283e-05, 'l1_Layer_3': 0.02210416136102958, 'n_units_Layer_1': 100, 'n_units_Layer_2': 165, 'n_units_Layer_3': 155}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.99 | sMAPE for Validation Set is: 15.24% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 12.80 | sMAPE for Test Set is: 12.98% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:55:51,061]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:55:55,545]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:55:58,892]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:56:03,948]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:56:04,808]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:56:09,958]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:56:09,974]\u001b[0m Trial 1164 finished with value: 3.686903449526902 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006626005093701788, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00707738453947826, 'dropout_rate_Layer_2': 0.00021747051803755457, 'dropout_rate_Layer_3': 0.08894526608083324, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.8756946074769085e-05, 'l1_Layer_2': 0.0004350841766565902, 'l1_Layer_3': 1.2290756406584733e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 135, 'n_units_Layer_3': 300}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.69 | sMAPE for Validation Set is: 14.48% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 11.43 | sMAPE for Test Set is: 11.58% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:56:16,663]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:56:27,858]\u001b[0m Trial 1174 finished with value: 4.0058406691428905 and parameters: {'n_hidden': 3, 'learning_rate': 0.008750364688837602, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00037788655781556546, 'dropout_rate_Layer_2': 0.015186533930014285, 'dropout_rate_Layer_3': 0.022093243342152197, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00029575963680807745, 'l1_Layer_2': 2.6983898312463412e-05, 'l1_Layer_3': 0.019588286106256497, 'n_units_Layer_1': 90, 'n_units_Layer_2': 160, 'n_units_Layer_3': 155}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.01 | sMAPE for Validation Set is: 15.29% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 12.09 | sMAPE for Test Set is: 12.41% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:56:33,224]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:56:33,487]\u001b[0m Trial 1176 finished with value: 3.6952024539639807 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006692085827560159, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0008147286636734537, 'dropout_rate_Layer_2': 0.0073907149592674784, 'dropout_rate_Layer_3': 0.07722372496478074, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.095664126072929e-05, 'l1_Layer_2': 2.487834314674777e-05, 'l1_Layer_3': 1.6944503375324868e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 125, 'n_units_Layer_3': 290}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.70 | sMAPE for Validation Set is: 14.40% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 12.20 | sMAPE for Test Set is: 12.04% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:56:39,731]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:56:40,308]\u001b[0m Trial 1177 finished with value: 3.699139835253676 and parameters: {'n_hidden': 3, 'learning_rate': 0.00066128064161072, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00048140151558514685, 'dropout_rate_Layer_2': 0.0002342825601326363, 'dropout_rate_Layer_3': 0.0770553002319393, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.6957862987786443e-05, 'l1_Layer_2': 0.0003419066333573557, 'l1_Layer_3': 1.2398485565426213e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 135, 'n_units_Layer_3': 285}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.70 | sMAPE for Validation Set is: 14.32% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 12.65 | sMAPE for Test Set is: 12.23% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:56:42,157]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:56:48,305]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:56:48,641]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:56:55,158]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:56:55,243]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:57:10,496]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:57:10,868]\u001b[0m Trial 1179 finished with value: 3.715022771508643 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007199649112906491, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.002477771672923624, 'dropout_rate_Layer_2': 0.00033683178381461673, 'dropout_rate_Layer_3': 0.0769523318673046, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.2871927503432894e-05, 'l1_Layer_2': 2.2418333415714696e-05, 'l1_Layer_3': 0.00016540158600976374, 'n_units_Layer_1': 190, 'n_units_Layer_2': 135, 'n_units_Layer_3': 290}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.72 | sMAPE for Validation Set is: 14.47% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 11.79 | sMAPE for Test Set is: 12.02% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:57:17,798]\u001b[0m Trial 1186 finished with value: 3.7213543773965334 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007296192803280463, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0011960768975413762, 'dropout_rate_Layer_2': 0.0011103191620365513, 'dropout_rate_Layer_3': 0.08619714329223375, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.572695040051035e-05, 'l1_Layer_2': 1.724271088706171e-05, 'l1_Layer_3': 1.0046935813001306e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 135, 'n_units_Layer_3': 300}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.72 | sMAPE for Validation Set is: 14.50% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 12.52 | sMAPE for Test Set is: 12.17% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:57:18,634]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:57:18,808]\u001b[0m Trial 1187 finished with value: 3.997654233658436 and parameters: {'n_hidden': 3, 'learning_rate': 0.010256195179813814, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.030287782840519698, 'dropout_rate_Layer_2': 0.017314787226436087, 'dropout_rate_Layer_3': 0.03083577805310619, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00026045058085001404, 'l1_Layer_2': 4.748987343061757e-05, 'l1_Layer_3': 0.01923837057625635, 'n_units_Layer_1': 95, 'n_units_Layer_2': 160, 'n_units_Layer_3': 140}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.00 | sMAPE for Validation Set is: 15.15% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 11.75 | sMAPE for Test Set is: 12.00% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:57:19,852]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:57:29,850]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:57:30,451]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:57:31,983]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:57:37,352]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:57:41,693]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:57:42,927]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:57:48,937]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:57:53,049]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:57:56,206]\u001b[0m Trial 1192 finished with value: 3.736506558140686 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006457815226345098, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00016861781307877643, 'dropout_rate_Layer_2': 1.0566070189786322e-05, 'dropout_rate_Layer_3': 0.08548845924721965, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.046851248754734e-05, 'l1_Layer_2': 2.405609199140542e-05, 'l1_Layer_3': 1.0210204164075585e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 140, 'n_units_Layer_3': 300}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.74 | sMAPE for Validation Set is: 14.76% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 12.11 | sMAPE for Test Set is: 11.98% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:57:59,687]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:58:07,706]\u001b[0m Trial 1198 finished with value: 3.7755048986017266 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006712008822317144, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.002308569480571632, 'dropout_rate_Layer_2': 0.0005053636939104812, 'dropout_rate_Layer_3': 0.08029942607244793, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.9713658617289283e-05, 'l1_Layer_2': 2.446633884628076e-05, 'l1_Layer_3': 0.0001665822031273373, 'n_units_Layer_1': 180, 'n_units_Layer_2': 140, 'n_units_Layer_3': 300}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.78 | sMAPE for Validation Set is: 14.74% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 12.12 | sMAPE for Test Set is: 12.02% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:58:12,305]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:58:16,908]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:58:17,616]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.99 | sMAPE for Validation Set is: 15.14% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 12.45 | sMAPE for Test Set is: 12.42% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:58:21,503]\u001b[0m Trial 1203 finished with value: 3.9935116787220224 and parameters: {'n_hidden': 3, 'learning_rate': 0.012607192487368869, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05496502747968139, 'dropout_rate_Layer_2': 1.2101329111066997e-05, 'dropout_rate_Layer_3': 0.04045838152073156, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003778499930799679, 'l1_Layer_2': 4.468431282674226e-05, 'l1_Layer_3': 0.011936536684650365, 'n_units_Layer_1': 100, 'n_units_Layer_2': 150, 'n_units_Layer_3': 145}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:58:24,215]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:58:28,765]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:58:29,439]\u001b[0m Trial 1202 finished with value: 4.002739925663452 and parameters: {'n_hidden': 3, 'learning_rate': 0.00677658793018041, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04943119659885328, 'dropout_rate_Layer_2': 0.008028414844439353, 'dropout_rate_Layer_3': 0.03694003670731148, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00037081037933263687, 'l1_Layer_2': 2.3605487685391814e-05, 'l1_Layer_3': 0.011991278806350125, 'n_units_Layer_1': 100, 'n_units_Layer_2': 160, 'n_units_Layer_3': 145}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.00 | sMAPE for Validation Set is: 15.28% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 11.66 | sMAPE for Test Set is: 11.86% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:58:32,922]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:58:35,029]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:58:40,428]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:58:41,883]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:58:47,101]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:58:49,895]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:58:54,137]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:58:57,073]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:59:01,497]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:59:02,991]\u001b[0m Trial 1211 finished with value: 3.7478117514214198 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007513066039233185, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00010320721043217593, 'dropout_rate_Layer_2': 0.00677855250467092, 'dropout_rate_Layer_3': 0.07837288338370701, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.279139889336803e-05, 'l1_Layer_2': 2.3394201642772016e-05, 'l1_Layer_3': 0.00015091570862690542, 'n_units_Layer_1': 180, 'n_units_Layer_2': 150, 'n_units_Layer_3': 300}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 14.43% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 12.46 | sMAPE for Test Set is: 12.05% | rMAE for Test Set is: 0.59\n",
      "MAE for Validation Set is: 3.77 | sMAPE for Validation Set is: 14.54% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 11.91 | sMAPE for Test Set is: 11.84% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:59:07,313]\u001b[0m Trial 1212 finished with value: 3.767784050196486 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007663282072426215, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0012349871794158779, 'dropout_rate_Layer_2': 0.006824414999230817, 'dropout_rate_Layer_3': 0.07916034194451348, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.384945232732994e-05, 'l1_Layer_2': 2.3787578355029122e-05, 'l1_Layer_3': 1.0825954883233982e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 150, 'n_units_Layer_3': 300}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:59:08,159]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:59:13,730]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:59:17,932]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:59:18,397]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:59:24,222]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:59:27,455]\u001b[0m Trial 1223 finished with value: 4.092179713479434 and parameters: {'n_hidden': 3, 'learning_rate': 0.00688477107270284, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04801433949831609, 'dropout_rate_Layer_2': 0.018214822326273417, 'dropout_rate_Layer_3': 0.03366813889491682, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004957866554319291, 'l1_Layer_2': 4.3871359119439644e-05, 'l1_Layer_3': 0.00023896312035745273, 'n_units_Layer_1': 110, 'n_units_Layer_2': 165, 'n_units_Layer_3': 155}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.09 | sMAPE for Validation Set is: 15.64% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 12.41 | sMAPE for Test Set is: 12.84% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:59:32,903]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.71 | sMAPE for Validation Set is: 14.58% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 11.83 | sMAPE for Test Set is: 11.96% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:59:35,383]\u001b[0m Trial 1221 finished with value: 3.7137448437407463 and parameters: {'n_hidden': 3, 'learning_rate': 0.000741995125900493, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008382590528486195, 'dropout_rate_Layer_2': 0.0007318906391558393, 'dropout_rate_Layer_3': 0.0767085006956741, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.464801264285179e-05, 'l1_Layer_2': 2.5374293761604487e-05, 'l1_Layer_3': 1.0124219832699519e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 155, 'n_units_Layer_3': 300}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:59:38,298]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:59:40,993]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:59:43,879]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:59:47,538]\u001b[0m Trial 1226 finished with value: 3.732009136311022 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007386649392859044, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0019559884375658825, 'dropout_rate_Layer_2': 0.000725023555094184, 'dropout_rate_Layer_3': 0.07632643758185256, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.103506017056692e-05, 'l1_Layer_2': 2.4206672638845584e-05, 'l1_Layer_3': 1.0239729211683512e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 150, 'n_units_Layer_3': 300}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.73 | sMAPE for Validation Set is: 14.40% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 12.49 | sMAPE for Test Set is: 12.13% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:59:48,959]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:59:54,461]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:59:56,494]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:59:58,693]\u001b[0m Trial 1227 finished with value: 3.736178510773238 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007530469878871611, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0016434099779259782, 'dropout_rate_Layer_2': 0.006775548963320161, 'dropout_rate_Layer_3': 0.07697883264310854, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.0228528885077907e-05, 'l1_Layer_2': 2.547421519579574e-05, 'l1_Layer_3': 1.1210308635009125e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 150, 'n_units_Layer_3': 300}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.74 | sMAPE for Validation Set is: 14.77% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 12.24 | sMAPE for Test Set is: 12.11% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:00:00,612]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:00:07,756]\u001b[0m Trial 1232 finished with value: 4.110430054268492 and parameters: {'n_hidden': 3, 'learning_rate': 0.0067154158503750765, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05175134633135005, 'dropout_rate_Layer_2': 0.016852051982470757, 'dropout_rate_Layer_3': 0.034991348696902486, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00046867303573024506, 'l1_Layer_2': 4.9370888196771885e-05, 'l1_Layer_3': 0.0002555101873727909, 'n_units_Layer_1': 105, 'n_units_Layer_2': 160, 'n_units_Layer_3': 155}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.11 | sMAPE for Validation Set is: 16.13% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 14.75 | sMAPE for Test Set is: 13.36% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:00:12,319]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:00:13,079]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:00:16,575]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:00:19,586]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:00:22,607]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:00:27,474]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:00:30,324]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:00:34,617]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:00:39,763]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:00:44,039]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:00:54,995]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:00:55,777]\u001b[0m Trial 1246 finished with value: 3.7423517187236146 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006166842267704627, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00015552768752184884, 'dropout_rate_Layer_2': 0.007500658200096459, 'dropout_rate_Layer_3': 0.07489984311115785, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.5805856343545086e-05, 'l1_Layer_2': 1.701627337207525e-05, 'l1_Layer_3': 1.05611558731621e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 150, 'n_units_Layer_3': 300}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.74 | sMAPE for Validation Set is: 14.66% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 12.13 | sMAPE for Test Set is: 11.94% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:01:03,019]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:01:03,979]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:01:10,429]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.12 | sMAPE for Validation Set is: 15.74% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 12.27 | sMAPE for Test Set is: 12.53% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:01:13,866]\u001b[0m Trial 1238 finished with value: 4.11633626424724 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010394907317557065, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04174608564432444, 'dropout_rate_Layer_2': 0.05223038338509198, 'dropout_rate_Layer_3': 0.011636936852189635, 'dropout_rate_Layer_4': 0.024801526825625222, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0039239844212442705, 'l1_Layer_2': 0.0046322914484848, 'l1_Layer_3': 7.637291571050721e-05, 'l1_Layer_4': 1.793590079489148e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 125, 'n_units_Layer_3': 130, 'n_units_Layer_4': 250}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:01:16,224]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:01:16,365]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:01:18,623]\u001b[0m Trial 1250 finished with value: 3.716475223381014 and parameters: {'n_hidden': 3, 'learning_rate': 0.000637614641174792, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006498233992133536, 'dropout_rate_Layer_2': 0.006741945542763734, 'dropout_rate_Layer_3': 0.07455944784547375, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.127757718141176e-05, 'l1_Layer_2': 3.2864211921342754e-05, 'l1_Layer_3': 1.1509286144104126e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 150, 'n_units_Layer_3': 300}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.72 | sMAPE for Validation Set is: 14.50% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 12.82 | sMAPE for Test Set is: 12.30% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:01:27,362]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:01:28,750]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:01:30,833]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:01:37,234]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:01:40,418]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:01:43,434]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:01:43,615]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:01:43,766]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:01:46,709]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:01:55,381]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:01:59,407]\u001b[0m Trial 1267 finished with value: 4.242896945965766 and parameters: {'n_hidden': 3, 'learning_rate': 0.007594390313729572, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07025396830920573, 'dropout_rate_Layer_2': 0.01819555480864162, 'dropout_rate_Layer_3': 0.031064043937270042, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023004258520819055, 'l1_Layer_2': 1.7581269053602744e-05, 'l1_Layer_3': 0.0001845665660404202, 'n_units_Layer_1': 90, 'n_units_Layer_2': 165, 'n_units_Layer_3': 140}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:01:59,516]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.24 | sMAPE for Validation Set is: 16.04% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 13.76 | sMAPE for Test Set is: 13.39% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:02:02,739]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:02:11,037]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:02:16,095]\u001b[0m Trial 1266 finished with value: 3.71025300444563 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007316699375595515, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0001214986422499128, 'dropout_rate_Layer_2': 0.006411721059107941, 'dropout_rate_Layer_3': 0.07087040615742078, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.9015260593713277e-05, 'l1_Layer_2': 3.2186159523980464e-05, 'l1_Layer_3': 1.241146637919809e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 150, 'n_units_Layer_3': 300}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.71 | sMAPE for Validation Set is: 14.37% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 12.80 | sMAPE for Test Set is: 12.24% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:02:20,872]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:02:21,463]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:02:23,082]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.73 | sMAPE for Validation Set is: 14.40% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 12.26 | sMAPE for Test Set is: 12.06% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:02:30,382]\u001b[0m Trial 1271 finished with value: 3.7251694469012757 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007472877661259667, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008064521235339017, 'dropout_rate_Layer_2': 5.264222101920629e-05, 'dropout_rate_Layer_3': 0.06787058283881717, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.9192102123649385e-05, 'l1_Layer_2': 3.3828518196458266e-05, 'l1_Layer_3': 1.0048122012697645e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 150, 'n_units_Layer_3': 300}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:02:32,276]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:02:32,568]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:02:37,013]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:02:44,355]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:02:45,323]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:02:46,073]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:02:46,752]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:02:57,185]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:02:57,395]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:03:03,923]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:03:04,694]\u001b[0m Trial 1285 finished with value: 4.065778236452252 and parameters: {'n_hidden': 3, 'learning_rate': 0.012719377537850893, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.020630686476417928, 'dropout_rate_Layer_2': 0.015016592021993954, 'dropout_rate_Layer_3': 0.020926592661814646, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003477148658482461, 'l1_Layer_2': 3.034871573654526e-05, 'l1_Layer_3': 0.012278327029057252, 'n_units_Layer_1': 100, 'n_units_Layer_2': 145, 'n_units_Layer_3': 160}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.07 | sMAPE for Validation Set is: 15.37% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 12.72 | sMAPE for Test Set is: 12.82% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:03:10,332]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:03:14,027]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:03:19,646]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:03:21,369]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:03:29,024]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:03:35,175]\u001b[0m Trial 1288 finished with value: 3.7054357753632488 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005671691003152854, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00044992350211820034, 'dropout_rate_Layer_2': 0.01340234452233312, 'dropout_rate_Layer_3': 0.07548122024010227, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.5806811347910076e-05, 'l1_Layer_2': 2.737801354028095e-05, 'l1_Layer_3': 1.0173466305555396e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 160, 'n_units_Layer_3': 295}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.71 | sMAPE for Validation Set is: 14.59% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 11.82 | sMAPE for Test Set is: 11.88% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:03:41,298]\u001b[0m Trial 1289 finished with value: 3.6790434984691074 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005341992069247424, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0068968789123142575, 'dropout_rate_Layer_2': 0.00046456672667311103, 'dropout_rate_Layer_3': 0.0753158308048522, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.430902059724393e-05, 'l1_Layer_2': 2.2062998719462016e-05, 'l1_Layer_3': 1.0242609718277294e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 160, 'n_units_Layer_3': 295}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.68 | sMAPE for Validation Set is: 14.40% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 11.86 | sMAPE for Test Set is: 12.01% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:03:47,483]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.72 | sMAPE for Validation Set is: 14.42% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 12.94 | sMAPE for Test Set is: 12.41% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:03:49,790]\u001b[0m Trial 1293 finished with value: 3.7168943375418055 and parameters: {'n_hidden': 3, 'learning_rate': 0.000606099848682923, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008749647546374896, 'dropout_rate_Layer_2': 0.007292375545101368, 'dropout_rate_Layer_3': 0.07570966479635827, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.476989727231785e-05, 'l1_Layer_2': 2.819607469260994e-05, 'l1_Layer_3': 1.202986267536326e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 150, 'n_units_Layer_3': 295}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:03:55,239]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:03:57,170]\u001b[0m Trial 1294 finished with value: 3.7444608530836807 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005542207502683829, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007795337459217863, 'dropout_rate_Layer_2': 0.00029312204097803665, 'dropout_rate_Layer_3': 0.07648334432111517, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.503587360224564e-05, 'l1_Layer_2': 2.5402351230382437e-05, 'l1_Layer_3': 1.2190087875097261e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 160, 'n_units_Layer_3': 295}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.74 | sMAPE for Validation Set is: 14.44% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 12.48 | sMAPE for Test Set is: 12.12% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:03:57,492]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:04:01,245]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.81 | sMAPE for Validation Set is: 14.59% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 11.20 | sMAPE for Test Set is: 11.53% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:04:02,744]\u001b[0m Trial 1295 finished with value: 3.8105238858339896 and parameters: {'n_hidden': 3, 'learning_rate': 0.012215093652130707, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04859228749933467, 'dropout_rate_Layer_2': 0.0006264579333672728, 'dropout_rate_Layer_3': 0.03063779901382823, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00024206806452273903, 'l1_Layer_2': 5.7788519944668805e-05, 'l1_Layer_3': 0.015054409054607048, 'n_units_Layer_1': 105, 'n_units_Layer_2': 170, 'n_units_Layer_3': 170}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:04:08,516]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:04:08,908]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:04:12,818]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:04:13,064]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:04:22,637]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:04:22,916]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:04:29,270]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:04:30,190]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:04:36,170]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:04:36,650]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:04:37,097]\u001b[0m Trial 1306 finished with value: 4.018125315622644 and parameters: {'n_hidden': 3, 'learning_rate': 0.012435478165752132, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04066330881271883, 'dropout_rate_Layer_2': 0.007000388481108319, 'dropout_rate_Layer_3': 0.038122398435250435, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00021492997795773827, 'l1_Layer_2': 5.8928556414714246e-05, 'l1_Layer_3': 0.00024449112080453906, 'n_units_Layer_1': 105, 'n_units_Layer_2': 165, 'n_units_Layer_3': 170}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.02 | sMAPE for Validation Set is: 15.29% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 12.45 | sMAPE for Test Set is: 12.80% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:04:44,627]\u001b[0m Trial 1305 finished with value: 3.7219629652346433 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005905540170459505, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008134187552593942, 'dropout_rate_Layer_2': 0.0003739084366396247, 'dropout_rate_Layer_3': 0.05934751296245078, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.4470139657601205e-05, 'l1_Layer_2': 1.5630747456638153e-05, 'l1_Layer_3': 1.001459085200885e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 160, 'n_units_Layer_3': 295}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.72 | sMAPE for Validation Set is: 14.68% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 11.83 | sMAPE for Test Set is: 12.03% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:04:45,013]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:04:59,635]\u001b[0m Trial 1313 finished with value: 3.7660991838227993 and parameters: {'n_hidden': 3, 'learning_rate': 0.000585147334717768, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00027261249295120436, 'dropout_rate_Layer_2': 0.0075807386685346895, 'dropout_rate_Layer_3': 0.061462682915756024, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.603002479555745e-05, 'l1_Layer_2': 2.1256798001949298e-05, 'l1_Layer_3': 1.2139792369954942e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 160, 'n_units_Layer_3': 295}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.77 | sMAPE for Validation Set is: 14.58% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 12.18 | sMAPE for Test Set is: 12.06% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:05:00,676]\u001b[0m Trial 1316 finished with value: 4.044726929196962 and parameters: {'n_hidden': 3, 'learning_rate': 0.02081460525572903, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03513114696311079, 'dropout_rate_Layer_2': 0.00859533436251766, 'dropout_rate_Layer_3': 0.03226860064592623, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00028063638151064617, 'l1_Layer_2': 9.806251900845555e-05, 'l1_Layer_3': 0.0001977986538710582, 'n_units_Layer_1': 95, 'n_units_Layer_2': 155, 'n_units_Layer_3': 140}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.04 | sMAPE for Validation Set is: 17.37% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 14.81 | sMAPE for Test Set is: 13.82% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:05:01,453]\u001b[0m Trial 1315 finished with value: 3.838963608275009 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005660317045056547, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.010406124984282448, 'dropout_rate_Layer_2': 0.000185932180393868, 'dropout_rate_Layer_3': 0.06074022161464193, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.7377410676553295e-05, 'l1_Layer_2': 1.194658080941967e-05, 'l1_Layer_3': 1.3113048929698319e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 160, 'n_units_Layer_3': 295}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.84 | sMAPE for Validation Set is: 14.89% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 12.61 | sMAPE for Test Set is: 12.39% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:05:02,992]\u001b[0m Trial 1312 finished with value: 3.7032446399833336 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005951487534270059, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0086702494644365, 'dropout_rate_Layer_2': 0.00020060736467084872, 'dropout_rate_Layer_3': 0.07376779658686788, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.642778078851577e-05, 'l1_Layer_2': 2.0387727052355647e-05, 'l1_Layer_3': 1.2665538612957501e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 160, 'n_units_Layer_3': 295}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.70 | sMAPE for Validation Set is: 14.35% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 12.04 | sMAPE for Test Set is: 11.91% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:05:14,053]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:05:18,109]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:05:18,471]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:05:19,046]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:05:27,352]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:05:29,319]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:05:33,042]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:05:33,068]\u001b[0m Trial 1318 finished with value: 3.7262188212626453 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005848242935167894, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.010054645160075017, 'dropout_rate_Layer_2': 0.014495243968432804, 'dropout_rate_Layer_3': 0.05709401113253125, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.076208981162391e-05, 'l1_Layer_2': 1.6290905417100006e-05, 'l1_Layer_3': 1.0308525903084705e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 170, 'n_units_Layer_3': 290}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.73 | sMAPE for Validation Set is: 14.56% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 11.90 | sMAPE for Test Set is: 11.98% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:05:34,617]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:05:39,617]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:05:47,467]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:05:47,657]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:05:47,775]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:05:57,709]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:05:59,038]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:06:00,899]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:06:05,051]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:06:09,378]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:06:10,188]\u001b[0m Trial 1329 finished with value: 3.7077934620707897 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006846672743152456, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01742649922517303, 'dropout_rate_Layer_2': 0.006798292040312144, 'dropout_rate_Layer_3': 0.06425022032108621, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.08074173415614e-05, 'l1_Layer_2': 3.6340634093225234e-05, 'l1_Layer_3': 1.6091710460893847e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 155, 'n_units_Layer_3': 295}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.71 | sMAPE for Validation Set is: 14.36% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 12.43 | sMAPE for Test Set is: 12.22% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:06:10,554]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:06:17,937]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:06:22,501]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:06:23,435]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:06:31,477]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:06:31,762]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:06:32,172]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:06:38,677]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:06:39,428]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:06:39,681]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:06:40,985]\u001b[0m Trial 1335 finished with value: 3.709919707296917 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005203500678760156, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01983312618809348, 'dropout_rate_Layer_2': 0.007407622677201202, 'dropout_rate_Layer_3': 0.06736546687183732, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.252248461209941e-05, 'l1_Layer_2': 3.3478328841730505e-05, 'l1_Layer_3': 1.5627019491357636e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 145, 'n_units_Layer_3': 290}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.71 | sMAPE for Validation Set is: 14.51% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 11.77 | sMAPE for Test Set is: 11.99% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:06:50,284]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:06:51,093]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:06:51,581]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:06:51,689]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:07:01,735]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:07:03,664]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:07:08,468]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:07:13,911]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:07:26,683]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:07:30,215]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:07:33,450]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:07:34,334]\u001b[0m Trial 1355 finished with value: 3.6672438306138684 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005399954153930599, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.019095207430240634, 'dropout_rate_Layer_2': 0.02271536578641021, 'dropout_rate_Layer_3': 0.06656350289458803, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.468259335660256e-05, 'l1_Layer_2': 1.9872298918121472e-05, 'l1_Layer_3': 1.6293675145478157e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 160, 'n_units_Layer_3': 285}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.67 | sMAPE for Validation Set is: 14.40% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 12.09 | sMAPE for Test Set is: 11.95% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:07:38,625]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:07:41,278]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:07:44,820]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:07:46,582]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:07:48,424]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:07:50,044]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:07:56,454]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:07:57,384]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:08:02,210]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:08:13,927]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.72 | sMAPE for Validation Set is: 14.61% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 12.02 | sMAPE for Test Set is: 11.87% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:08:19,937]\u001b[0m Trial 1366 finished with value: 3.7185539196938024 and parameters: {'n_hidden': 3, 'learning_rate': 0.000582764223864535, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.015334799717459921, 'dropout_rate_Layer_2': 0.013881025346400377, 'dropout_rate_Layer_3': 0.0636676156084781, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4366184879344684e-05, 'l1_Layer_2': 3.782510406344442e-05, 'l1_Layer_3': 1.5233823702773854e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 175, 'n_units_Layer_3': 290}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:08:20,925]\u001b[0m Trial 1368 finished with value: 3.738420360100593 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006355554427464761, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014543512927467122, 'dropout_rate_Layer_2': 0.014281252624328092, 'dropout_rate_Layer_3': 0.06450363543846833, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.385845557394218e-05, 'l1_Layer_2': 4.301215013125932e-05, 'l1_Layer_3': 1.4545494358908577e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 175, 'n_units_Layer_3': 290}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.74 | sMAPE for Validation Set is: 14.58% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 11.95 | sMAPE for Test Set is: 12.08% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:08:27,065]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:08:32,841]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:08:36,808]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:08:39,936]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:08:43,007]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:08:43,930]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:08:44,614]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:08:45,929]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:08:52,327]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:08:55,306]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:08:55,643]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:08:57,569]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:09:04,938]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:09:05,383]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:09:12,065]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:09:20,597]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:09:23,889]\u001b[0m Trial 1383 finished with value: 3.749497316845675 and parameters: {'n_hidden': 3, 'learning_rate': 0.000553952303123932, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01697245444050249, 'dropout_rate_Layer_2': 0.00758056768449096, 'dropout_rate_Layer_3': 0.07148668092882596, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.413648315489817e-05, 'l1_Layer_2': 1.4723294119690874e-05, 'l1_Layer_3': 1.2103539798039298e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 170, 'n_units_Layer_3': 295}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 14.56% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 12.13 | sMAPE for Test Set is: 12.30% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:09:30,249]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:09:31,498]\u001b[0m Trial 1389 finished with value: 3.7765098764613003 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005966457190004885, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01000179041974121, 'dropout_rate_Layer_2': 0.008499693669078101, 'dropout_rate_Layer_3': 0.07186336913110879, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.805639393088981e-05, 'l1_Layer_2': 1.470029601158753e-05, 'l1_Layer_3': 1.1987924937936384e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 155, 'n_units_Layer_3': 295}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.78 | sMAPE for Validation Set is: 14.63% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 12.77 | sMAPE for Test Set is: 12.39% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:09:35,925]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:09:36,685]\u001b[0m Trial 1386 finished with value: 3.7054379413103966 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005829908840282932, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008785054825173189, 'dropout_rate_Layer_2': 0.010091101481222466, 'dropout_rate_Layer_3': 0.07096786747452181, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.75454150476656e-05, 'l1_Layer_2': 1.0024373417819638e-05, 'l1_Layer_3': 1.1756821870142552e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 155, 'n_units_Layer_3': 295}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.71 | sMAPE for Validation Set is: 14.44% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 12.35 | sMAPE for Test Set is: 12.02% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:09:37,145]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:09:46,609]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:09:47,543]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:09:48,459]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:09:53,688]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:09:59,421]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:10:00,367]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:10:01,078]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.66 | sMAPE for Validation Set is: 14.30% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 12.59 | sMAPE for Test Set is: 12.30% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:10:07,506]\u001b[0m Trial 1391 finished with value: 3.660190918986256 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006928060845232838, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00923228030344452, 'dropout_rate_Layer_2': 0.018517871484589152, 'dropout_rate_Layer_3': 0.08049356427567633, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.285876240214671e-05, 'l1_Layer_2': 2.1696267330960842e-05, 'l1_Layer_3': 1.6128347125184583e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 160, 'n_units_Layer_3': 70}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:10:09,521]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:10:10,615]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:10:16,997]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:10:19,399]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:10:20,746]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:10:28,118]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:10:29,617]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:10:34,441]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:10:34,869]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:10:39,907]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:10:42,491]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:10:46,446]\u001b[0m Trial 1407 finished with value: 3.8978861344905233 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005020018498383821, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 5.984732752396544e-05, 'dropout_rate_Layer_2': 0.007440805505477091, 'dropout_rate_Layer_3': 0.08204522411795352, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.8107459178930316e-05, 'l1_Layer_2': 2.1306014149394603e-05, 'l1_Layer_3': 1.3685418227618785e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 155, 'n_units_Layer_3': 55}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.90 | sMAPE for Validation Set is: 14.92% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 12.64 | sMAPE for Test Set is: 12.77% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:10:47,203]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:10:47,626]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:10:52,839]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:10:54,369]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:10:56,890]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:11:01,358]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:11:02,139]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:11:08,343]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:11:09,652]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:11:13,916]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:11:20,806]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:11:23,313]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:11:27,538]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:11:27,874]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:11:28,495]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:11:36,168]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:11:37,289]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:11:38,205]\u001b[0m Trial 1420 finished with value: 3.7188343633375816 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008389255535943565, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009901200447558791, 'dropout_rate_Layer_2': 3.756486755493796e-05, 'dropout_rate_Layer_3': 0.07237757149340644, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.854394329293704e-05, 'l1_Layer_2': 2.6826045361883612e-05, 'l1_Layer_3': 2.043242105052942e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 150, 'n_units_Layer_3': 60}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.72 | sMAPE for Validation Set is: 14.69% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 11.86 | sMAPE for Test Set is: 11.95% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:11:38,502]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:11:47,161]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:11:53,998]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:11:58,102]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:11:58,726]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:11:59,792]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:12:06,323]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:12:10,997]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:12:11,537]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:12:17,960]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:12:20,592]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:12:22,606]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:12:23,001]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:12:31,521]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:12:31,565]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:12:31,958]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:12:32,906]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:12:40,624]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:12:44,842]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:12:45,172]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:12:46,183]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:12:57,839]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:12:58,232]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:12:58,280]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:13:02,866]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:13:06,521]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:13:08,489]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:13:09,631]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:13:13,371]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:13:14,406]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:13:20,390]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:13:22,283]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:13:27,486]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:13:28,407]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:13:34,965]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:13:41,096]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:13:43,977]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:13:45,353]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:13:47,678]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:13:52,207]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:13:56,512]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:13:59,183]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:14:02,956]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:14:03,557]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:14:10,066]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:14:10,453]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:14:11,450]\u001b[0m Trial 1467 finished with value: 4.629733736579244 and parameters: {'n_hidden': 4, 'learning_rate': 0.00338200358311258, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08967592555205382, 'dropout_rate_Layer_2': 0.041590565921717816, 'dropout_rate_Layer_3': 0.008921124868629152, 'dropout_rate_Layer_4': 0.35317391854225033, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.769843212272038e-05, 'l1_Layer_2': 0.006950253829778297, 'l1_Layer_3': 0.0002314918643236356, 'l1_Layer_4': 1.8769075768417554e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 140, 'n_units_Layer_3': 140, 'n_units_Layer_4': 295}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.63 | sMAPE for Validation Set is: 17.27% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 18.21 | sMAPE for Test Set is: 15.65% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:14:20,608]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:14:25,681]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:14:28,558]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:14:30,108]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:14:37,656]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:14:40,248]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:14:42,518]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:14:45,401]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:14:49,903]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:14:53,202]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:14:53,310]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:14:55,854]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:14:58,717]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:15:02,950]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:15:05,441]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:15:11,160]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:15:12,371]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:15:13,908]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:15:18,953]\u001b[0m Trial 1492 finished with value: 4.082469699942856 and parameters: {'n_hidden': 3, 'learning_rate': 0.0058750392889782765, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03755960288163653, 'dropout_rate_Layer_2': 0.0004781479756851755, 'dropout_rate_Layer_3': 0.005062638835122216, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00029028442701061467, 'l1_Layer_2': 3.090060634343301e-05, 'l1_Layer_3': 0.014345415733796045, 'n_units_Layer_1': 100, 'n_units_Layer_2': 155, 'n_units_Layer_3': 160}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.08 | sMAPE for Validation Set is: 15.42% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 12.11 | sMAPE for Test Set is: 12.47% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:15:19,455]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:15:29,169]\u001b[0m Trial 1498 finished with value: 3.7072590860890826 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005469164547319507, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007344721176168453, 'dropout_rate_Layer_2': 0.014926218223790876, 'dropout_rate_Layer_3': 0.0630927078642028, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3587121921365794e-05, 'l1_Layer_2': 2.2545653990788192e-05, 'l1_Layer_3': 2.0494479512321787e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 160, 'n_units_Layer_3': 280}. Best is trial 946 with value: 3.643694200371439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.71 | sMAPE for Validation Set is: 14.39% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 12.14 | sMAPE for Test Set is: 12.01% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:15:30,380]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-01-01, MAE is:4.54 & sMAPE is:9.63% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :4.54 & 9.63% & 0.28\n",
      "for 2021-01-02, MAE is:9.16 & sMAPE is:17.61% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 13.62% & 0.34\n",
      "for 2021-01-03, MAE is:3.61 & sMAPE is:7.71% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :5.77 & 11.65% & 0.28\n",
      "for 2021-01-04, MAE is:5.13 & sMAPE is:8.57% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :5.61 & 10.88% & 0.28\n",
      "for 2021-01-05, MAE is:1.87 & sMAPE is:3.29% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :4.86 & 9.36% & 0.26\n",
      "for 2021-01-06, MAE is:3.22 & sMAPE is:6.13% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.59 & 8.82% & 0.29\n",
      "for 2021-01-07, MAE is:13.61 & sMAPE is:20.10% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 10.43% & 0.34\n",
      "for 2021-01-08, MAE is:16.99 & sMAPE is:22.25% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :7.27 & 11.91% & 0.37\n",
      "for 2021-01-09, MAE is:3.68 & sMAPE is:6.03% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.87 & 11.26% & 0.39\n",
      "for 2021-01-10, MAE is:3.26 & sMAPE is:6.06% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 10.74% & 0.39\n",
      "for 2021-01-11, MAE is:5.85 & sMAPE is:8.26% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.45 & 10.51% & 0.40\n",
      "for 2021-01-12, MAE is:2.17 & sMAPE is:3.24% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 9.91% & 0.39\n",
      "for 2021-01-13, MAE is:4.10 & sMAPE is:6.12% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :5.94 & 9.61% & 0.39\n",
      "for 2021-01-14, MAE is:9.19 & sMAPE is:12.11% & rMAE is:1.94 ||| daily mean of MAE & sMAPE & rMAE till now are :6.17 & 9.79% & 0.50\n",
      "for 2021-01-15, MAE is:10.59 & sMAPE is:12.93% & rMAE is:2.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 10.00% & 0.64\n",
      "for 2021-01-16, MAE is:5.50 & sMAPE is:8.83% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 9.93% & 0.68\n",
      "for 2021-01-17, MAE is:6.95 & sMAPE is:12.98% & rMAE is:3.75 ||| daily mean of MAE & sMAPE & rMAE till now are :6.44 & 10.11% & 0.86\n",
      "for 2021-01-18, MAE is:3.47 & sMAPE is:5.27% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.27 & 9.84% & 0.85\n",
      "for 2021-01-19, MAE is:2.58 & sMAPE is:4.01% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 9.53% & 0.84\n",
      "for 2021-01-20, MAE is:6.06 & sMAPE is:10.25% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 9.57% & 0.83\n",
      "for 2021-01-21, MAE is:4.01 & sMAPE is:7.00% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :5.98 & 9.45% & 0.80\n",
      "for 2021-01-22, MAE is:3.55 & sMAPE is:6.65% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :5.87 & 9.32% & 0.77\n",
      "for 2021-01-23, MAE is:6.73 & sMAPE is:13.06% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :5.90 & 9.48% & 0.80\n",
      "for 2021-01-24, MAE is:6.32 & sMAPE is:12.95% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :5.92 & 9.63% & 0.80\n",
      "for 2021-01-25, MAE is:8.17 & sMAPE is:12.69% & rMAE is:2.05 ||| daily mean of MAE & sMAPE & rMAE till now are :6.01 & 9.75% & 0.85\n",
      "for 2021-01-26, MAE is:7.60 & sMAPE is:12.10% & rMAE is:2.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 9.84% & 0.92\n",
      "for 2021-01-27, MAE is:2.12 & sMAPE is:3.52% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :5.93 & 9.60% & 0.90\n",
      "for 2021-01-28, MAE is:3.68 & sMAPE is:6.40% & rMAE is:1.88 ||| daily mean of MAE & sMAPE & rMAE till now are :5.85 & 9.49% & 0.93\n",
      "for 2021-01-29, MAE is:3.21 & sMAPE is:6.24% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :5.75 & 9.38% & 0.93\n",
      "for 2021-01-30, MAE is:6.64 & sMAPE is:13.91% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :5.78 & 9.53% & 0.95\n",
      "for 2021-01-31, MAE is:3.69 & sMAPE is:7.60% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :5.72 & 9.47% & 0.95\n",
      "for 2021-02-01, MAE is:4.77 & sMAPE is:8.25% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :5.69 & 9.43% & 0.94\n",
      "for 2021-02-02, MAE is:2.63 & sMAPE is:4.69% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :5.59 & 9.28% & 0.92\n",
      "for 2021-02-03, MAE is:2.78 & sMAPE is:5.28% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :5.51 & 9.17% & 0.90\n",
      "for 2021-02-04, MAE is:5.49 & sMAPE is:10.52% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :5.51 & 9.21% & 0.91\n",
      "for 2021-02-05, MAE is:5.02 & sMAPE is:9.73% & rMAE is:3.34 ||| daily mean of MAE & sMAPE & rMAE till now are :5.50 & 9.22% & 0.98\n",
      "for 2021-02-06, MAE is:8.80 & sMAPE is:19.09% & rMAE is:3.03 ||| daily mean of MAE & sMAPE & rMAE till now are :5.59 & 9.49% & 1.04\n",
      "for 2021-02-07, MAE is:5.03 & sMAPE is:12.07% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :5.57 & 9.55% & 1.04\n",
      "for 2021-02-08, MAE is:7.44 & sMAPE is:14.43% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :5.62 & 9.68% & 1.06\n",
      "for 2021-02-09, MAE is:12.25 & sMAPE is:20.24% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :5.79 & 9.94% & 1.08\n",
      "for 2021-02-10, MAE is:11.55 & sMAPE is:17.75% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :5.93 & 10.13% & 1.07\n",
      "for 2021-02-11, MAE is:20.50 & sMAPE is:27.98% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.27 & 10.56% & 1.07\n",
      "for 2021-02-12, MAE is:6.64 & sMAPE is:9.67% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.28 & 10.54% & 1.05\n",
      "for 2021-02-13, MAE is:2.67 & sMAPE is:4.80% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.20 & 10.41% & 1.04\n",
      "for 2021-02-14, MAE is:2.19 & sMAPE is:4.38% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.11 & 10.27% & 1.02\n",
      "for 2021-02-15, MAE is:2.68 & sMAPE is:4.85% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 10.16% & 1.01\n",
      "for 2021-02-16, MAE is:4.10 & sMAPE is:7.06% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :5.99 & 10.09% & 1.01\n",
      "for 2021-02-17, MAE is:2.44 & sMAPE is:4.13% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :5.92 & 9.97% & 0.99\n",
      "for 2021-02-18, MAE is:4.69 & sMAPE is:8.16% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :5.90 & 9.93% & 0.97\n",
      "for 2021-02-19, MAE is:2.95 & sMAPE is:5.95% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :5.84 & 9.85% & 0.96\n",
      "for 2021-02-20, MAE is:4.33 & sMAPE is:10.42% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :5.81 & 9.86% & 0.95\n",
      "for 2021-02-21, MAE is:7.80 & sMAPE is:23.32% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :5.85 & 10.12% & 0.94\n",
      "for 2021-02-22, MAE is:4.03 & sMAPE is:8.29% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :5.81 & 10.09% & 0.93\n",
      "for 2021-02-23, MAE is:3.36 & sMAPE is:6.14% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :5.77 & 10.01% & 0.93\n",
      "for 2021-02-24, MAE is:3.08 & sMAPE is:6.32% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :5.72 & 9.94% & 0.92\n",
      "for 2021-02-25, MAE is:4.92 & sMAPE is:9.65% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :5.70 & 9.94% & 0.93\n",
      "for 2021-02-26, MAE is:4.66 & sMAPE is:9.24% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :5.68 & 9.93% & 0.94\n",
      "for 2021-02-27, MAE is:6.40 & sMAPE is:13.89% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :5.70 & 10.00% & 0.94\n",
      "for 2021-02-28, MAE is:5.77 & sMAPE is:13.92% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :5.70 & 10.06% & 0.94\n",
      "for 2021-03-01, MAE is:5.98 & sMAPE is:11.36% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :5.70 & 10.08% & 0.94\n",
      "for 2021-03-02, MAE is:7.30 & sMAPE is:12.94% & rMAE is:1.62 ||| daily mean of MAE & sMAPE & rMAE till now are :5.73 & 10.13% & 0.95\n",
      "for 2021-03-03, MAE is:5.61 & sMAPE is:10.44% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :5.73 & 10.14% & 0.95\n",
      "for 2021-03-04, MAE is:2.96 & sMAPE is:5.69% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :5.68 & 10.07% & 0.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-03-05, MAE is:3.49 & sMAPE is:6.57% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :5.65 & 10.01% & 0.96\n",
      "for 2021-03-06, MAE is:4.97 & sMAPE is:10.40% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :5.64 & 10.02% & 0.97\n",
      "for 2021-03-07, MAE is:6.92 & sMAPE is:15.60% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :5.66 & 10.10% & 0.98\n",
      "for 2021-03-08, MAE is:8.66 & sMAPE is:13.99% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :5.70 & 10.16% & 0.99\n",
      "for 2021-03-09, MAE is:7.33 & sMAPE is:11.54% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :5.73 & 10.18% & 0.99\n",
      "for 2021-03-10, MAE is:4.02 & sMAPE is:7.09% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :5.70 & 10.13% & 1.00\n",
      "for 2021-03-11, MAE is:2.76 & sMAPE is:5.33% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :5.66 & 10.07% & 1.00\n",
      "for 2021-03-12, MAE is:4.07 & sMAPE is:7.93% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :5.64 & 10.04% & 1.01\n",
      "for 2021-03-13, MAE is:6.78 & sMAPE is:14.14% & rMAE is:3.59 ||| daily mean of MAE & sMAPE & rMAE till now are :5.65 & 10.09% & 1.05\n",
      "for 2021-03-14, MAE is:9.95 & sMAPE is:33.96% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :5.71 & 10.42% & 1.04\n",
      "for 2021-03-15, MAE is:7.12 & sMAPE is:13.61% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :5.73 & 10.46% & 1.04\n",
      "for 2021-03-16, MAE is:10.03 & sMAPE is:17.51% & rMAE is:3.22 ||| daily mean of MAE & sMAPE & rMAE till now are :5.79 & 10.56% & 1.07\n",
      "for 2021-03-17, MAE is:5.50 & sMAPE is:8.65% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :5.78 & 10.53% & 1.06\n",
      "for 2021-03-18, MAE is:5.00 & sMAPE is:7.66% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :5.77 & 10.49% & 1.06\n",
      "for 2021-03-19, MAE is:5.45 & sMAPE is:9.10% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :5.77 & 10.48% & 1.05\n",
      "for 2021-03-20, MAE is:5.38 & sMAPE is:9.65% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :5.77 & 10.47% & 1.05\n",
      "for 2021-03-21, MAE is:6.28 & sMAPE is:13.49% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :5.77 & 10.50% & 1.04\n",
      "for 2021-03-22, MAE is:6.18 & sMAPE is:10.23% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :5.78 & 10.50% & 1.04\n",
      "for 2021-03-23, MAE is:7.75 & sMAPE is:12.63% & rMAE is:4.40 ||| daily mean of MAE & sMAPE & rMAE till now are :5.80 & 10.53% & 1.08\n",
      "for 2021-03-24, MAE is:8.93 & sMAPE is:15.04% & rMAE is:2.50 ||| daily mean of MAE & sMAPE & rMAE till now are :5.84 & 10.58% & 1.10\n",
      "for 2021-03-25, MAE is:5.53 & sMAPE is:8.98% & rMAE is:2.47 ||| daily mean of MAE & sMAPE & rMAE till now are :5.83 & 10.56% & 1.11\n",
      "for 2021-03-26, MAE is:4.46 & sMAPE is:7.48% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :5.82 & 10.53% & 1.12\n",
      "for 2021-03-27, MAE is:5.10 & sMAPE is:9.54% & rMAE is:1.93 ||| daily mean of MAE & sMAPE & rMAE till now are :5.81 & 10.51% & 1.13\n",
      "for 2021-03-28, MAE is:12.00 & sMAPE is:36.97% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 10.82% & 1.13\n",
      "for 2021-03-29, MAE is:9.20 & sMAPE is:17.29% & rMAE is:2.27 ||| daily mean of MAE & sMAPE & rMAE till now are :5.92 & 10.89% & 1.14\n",
      "for 2021-03-30, MAE is:6.74 & sMAPE is:11.75% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :5.93 & 10.90% & 1.14\n",
      "for 2021-03-31, MAE is:7.17 & sMAPE is:11.94% & rMAE is:1.78 ||| daily mean of MAE & sMAPE & rMAE till now are :5.94 & 10.91% & 1.15\n",
      "for 2021-04-01, MAE is:4.90 & sMAPE is:8.86% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :5.93 & 10.89% & 1.14\n",
      "for 2021-04-02, MAE is:6.41 & sMAPE is:14.50% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :5.94 & 10.93% & 1.14\n",
      "for 2021-04-03, MAE is:7.88 & sMAPE is:22.28% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :5.96 & 11.05% & 1.13\n",
      "for 2021-04-04, MAE is:8.07 & sMAPE is:35.12% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :5.98 & 11.31% & 1.13\n",
      "for 2021-04-05, MAE is:24.89 & sMAPE is:132.10% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.18 & 12.58% & 1.12\n",
      "for 2021-04-06, MAE is:21.89 & sMAPE is:47.53% & rMAE is:3.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.34 & 12.94% & 1.14\n",
      "for 2021-04-07, MAE is:13.58 & sMAPE is:21.77% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 13.03% & 1.15\n",
      "for 2021-04-08, MAE is:16.82 & sMAPE is:25.42% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :6.52 & 13.16% & 1.15\n",
      "for 2021-04-09, MAE is:6.01 & sMAPE is:8.97% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.52 & 13.12% & 1.14\n",
      "for 2021-04-10, MAE is:7.45 & sMAPE is:13.02% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 13.12% & 1.13\n",
      "for 2021-04-11, MAE is:6.29 & sMAPE is:12.29% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :6.52 & 13.11% & 1.12\n",
      "for 2021-04-12, MAE is:19.75 & sMAPE is:30.27% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 13.28% & 1.11\n",
      "for 2021-04-13, MAE is:13.35 & sMAPE is:17.44% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 13.32% & 1.11\n",
      "for 2021-04-14, MAE is:12.53 & sMAPE is:15.88% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 13.34% & 1.11\n",
      "for 2021-04-15, MAE is:11.64 & sMAPE is:13.67% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 13.35% & 1.11\n",
      "for 2021-04-16, MAE is:11.39 & sMAPE is:16.28% & rMAE is:2.12 ||| daily mean of MAE & sMAPE & rMAE till now are :6.86 & 13.37% & 1.12\n",
      "for 2021-04-17, MAE is:3.74 & sMAPE is:6.06% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.84 & 13.31% & 1.12\n",
      "for 2021-04-18, MAE is:4.35 & sMAPE is:7.00% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.81 & 13.25% & 1.12\n",
      "for 2021-04-19, MAE is:8.92 & sMAPE is:11.01% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 13.23% & 1.12\n",
      "for 2021-04-20, MAE is:8.97 & sMAPE is:10.70% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 13.20% & 1.12\n",
      "for 2021-04-21, MAE is:3.40 & sMAPE is:4.56% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 13.13% & 1.11\n",
      "for 2021-04-22, MAE is:5.22 & sMAPE is:7.39% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :6.81 & 13.07% & 1.11\n",
      "for 2021-04-23, MAE is:5.02 & sMAPE is:7.41% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 13.02% & 1.11\n",
      "for 2021-04-24, MAE is:9.96 & sMAPE is:20.66% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 13.09% & 1.11\n",
      "for 2021-04-25, MAE is:15.09 & sMAPE is:46.91% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 13.39% & 1.10\n",
      "for 2021-04-26, MAE is:7.53 & sMAPE is:11.73% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 13.37% & 1.10\n",
      "for 2021-04-27, MAE is:8.08 & sMAPE is:12.19% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :6.91 & 13.36% & 1.09\n",
      "for 2021-04-28, MAE is:4.75 & sMAPE is:7.31% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 13.31% & 1.09\n",
      "for 2021-04-29, MAE is:11.58 & sMAPE is:18.63% & rMAE is:1.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 13.35% & 1.09\n",
      "for 2021-04-30, MAE is:8.69 & sMAPE is:12.52% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 13.35% & 1.10\n",
      "for 2021-05-01, MAE is:6.46 & sMAPE is:11.13% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 13.33% & 1.10\n",
      "for 2021-05-02, MAE is:5.17 & sMAPE is:14.35% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 13.34% & 1.09\n",
      "for 2021-05-03, MAE is:5.10 & sMAPE is:8.48% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :6.91 & 13.30% & 1.09\n",
      "for 2021-05-04, MAE is:10.99 & sMAPE is:27.62% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 13.41% & 1.09\n",
      "for 2021-05-05, MAE is:5.10 & sMAPE is:8.78% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 13.38% & 1.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-05-06, MAE is:9.32 & sMAPE is:13.48% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 13.38% & 1.09\n",
      "for 2021-05-07, MAE is:7.32 & sMAPE is:10.80% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 13.36% & 1.09\n",
      "for 2021-05-08, MAE is:9.27 & sMAPE is:19.70% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.97 & 13.41% & 1.09\n",
      "for 2021-05-09, MAE is:41.51 & sMAPE is:129.54% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :7.23 & 14.31% & 1.09\n",
      "for 2021-05-10, MAE is:18.42 & sMAPE is:36.68% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :7.32 & 14.48% & 1.09\n",
      "for 2021-05-11, MAE is:4.98 & sMAPE is:7.38% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :7.30 & 14.42% & 1.09\n",
      "for 2021-05-12, MAE is:7.69 & sMAPE is:11.43% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :7.30 & 14.40% & 1.08\n",
      "for 2021-05-13, MAE is:5.74 & sMAPE is:10.51% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :7.29 & 14.37% & 1.08\n",
      "for 2021-05-14, MAE is:7.66 & sMAPE is:11.85% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :7.30 & 14.35% & 1.08\n",
      "for 2021-05-15, MAE is:5.46 & sMAPE is:8.85% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :7.28 & 14.31% & 1.08\n",
      "for 2021-05-16, MAE is:12.93 & sMAPE is:36.05% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :7.32 & 14.47% & 1.07\n",
      "for 2021-05-17, MAE is:6.46 & sMAPE is:10.17% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :7.32 & 14.44% & 1.07\n",
      "for 2021-05-18, MAE is:7.26 & sMAPE is:10.28% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :7.32 & 14.41% & 1.07\n",
      "for 2021-05-19, MAE is:5.98 & sMAPE is:8.02% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :7.31 & 14.37% & 1.07\n",
      "for 2021-05-20, MAE is:5.37 & sMAPE is:7.33% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :7.29 & 14.32% & 1.07\n",
      "for 2021-05-21, MAE is:17.66 & sMAPE is:33.82% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :7.37 & 14.45% & 1.06\n",
      "for 2021-05-22, MAE is:21.42 & sMAPE is:77.27% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :7.47 & 14.90% & 1.06\n",
      "for 2021-05-23, MAE is:18.59 & sMAPE is:75.42% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :7.54 & 15.32% & 1.06\n",
      "for 2021-05-24, MAE is:9.17 & sMAPE is:18.17% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :7.56 & 15.34% & 1.06\n",
      "for 2021-05-25, MAE is:4.66 & sMAPE is:7.55% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :7.54 & 15.29% & 1.05\n",
      "for 2021-05-26, MAE is:9.19 & sMAPE is:13.71% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :7.55 & 15.27% & 1.06\n",
      "for 2021-05-27, MAE is:7.21 & sMAPE is:9.73% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :7.54 & 15.24% & 1.06\n",
      "for 2021-05-28, MAE is:6.73 & sMAPE is:8.83% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :7.54 & 15.19% & 1.05\n",
      "for 2021-05-29, MAE is:5.66 & sMAPE is:10.35% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :7.53 & 15.16% & 1.05\n",
      "for 2021-05-30, MAE is:12.88 & sMAPE is:43.75% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :7.56 & 15.35% & 1.05\n",
      "for 2021-05-31, MAE is:7.51 & sMAPE is:11.35% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :7.56 & 15.33% & 1.04\n",
      "for 2021-06-01, MAE is:7.10 & sMAPE is:10.32% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :7.56 & 15.29% & 1.04\n",
      "for 2021-06-02, MAE is:6.45 & sMAPE is:9.80% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :7.55 & 15.26% & 1.04\n",
      "for 2021-06-03, MAE is:4.66 & sMAPE is:7.10% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :7.53 & 15.20% & 1.04\n",
      "for 2021-06-04, MAE is:4.96 & sMAPE is:7.14% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :7.52 & 15.15% & 1.04\n",
      "for 2021-06-05, MAE is:2.65 & sMAPE is:4.54% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :7.48 & 15.08% & 1.04\n",
      "for 2021-06-06, MAE is:4.07 & sMAPE is:7.46% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :7.46 & 15.03% & 1.03\n",
      "for 2021-06-07, MAE is:8.41 & sMAPE is:11.90% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :7.47 & 15.01% & 1.03\n",
      "for 2021-06-08, MAE is:7.20 & sMAPE is:9.69% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :7.47 & 14.98% & 1.03\n",
      "for 2021-06-09, MAE is:4.68 & sMAPE is:6.09% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :7.45 & 14.93% & 1.03\n",
      "for 2021-06-10, MAE is:5.97 & sMAPE is:8.00% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :7.44 & 14.88% & 1.03\n",
      "for 2021-06-11, MAE is:4.91 & sMAPE is:6.64% & rMAE is:1.73 ||| daily mean of MAE & sMAPE & rMAE till now are :7.42 & 14.83% & 1.03\n",
      "for 2021-06-12, MAE is:16.40 & sMAPE is:41.04% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :7.48 & 14.99% & 1.03\n",
      "for 2021-06-13, MAE is:29.85 & sMAPE is:80.66% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :7.62 & 15.39% & 1.03\n",
      "for 2021-06-14, MAE is:10.98 & sMAPE is:15.87% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :7.64 & 15.40% & 1.03\n",
      "for 2021-06-15, MAE is:7.79 & sMAPE is:9.18% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :7.64 & 15.36% & 1.03\n",
      "for 2021-06-16, MAE is:8.07 & sMAPE is:9.54% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :7.64 & 15.32% & 1.03\n",
      "for 2021-06-17, MAE is:8.53 & sMAPE is:10.31% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :7.65 & 15.29% & 1.04\n",
      "for 2021-06-18, MAE is:6.96 & sMAPE is:8.42% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :7.64 & 15.25% & 1.04\n",
      "for 2021-06-19, MAE is:7.07 & sMAPE is:10.14% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :7.64 & 15.22% & 1.03\n",
      "for 2021-06-20, MAE is:10.23 & sMAPE is:20.52% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :7.65 & 15.25% & 1.03\n",
      "for 2021-06-21, MAE is:3.97 & sMAPE is:5.10% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :7.63 & 15.20% & 1.02\n",
      "for 2021-06-22, MAE is:4.45 & sMAPE is:5.48% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :7.61 & 15.14% & 1.02\n",
      "for 2021-06-23, MAE is:12.60 & sMAPE is:15.09% & rMAE is:2.04 ||| daily mean of MAE & sMAPE & rMAE till now are :7.64 & 15.14% & 1.03\n",
      "for 2021-06-24, MAE is:8.09 & sMAPE is:9.30% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :7.64 & 15.11% & 1.03\n",
      "for 2021-06-25, MAE is:5.63 & sMAPE is:6.56% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :7.63 & 15.06% & 1.03\n",
      "for 2021-06-26, MAE is:4.74 & sMAPE is:6.44% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :7.62 & 15.01% & 1.03\n",
      "for 2021-06-27, MAE is:11.01 & sMAPE is:19.61% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :7.64 & 15.03% & 1.03\n",
      "for 2021-06-28, MAE is:4.81 & sMAPE is:5.95% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :7.62 & 14.98% & 1.03\n",
      "for 2021-06-29, MAE is:6.96 & sMAPE is:8.02% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :7.62 & 14.94% & 1.02\n",
      "for 2021-06-30, MAE is:3.18 & sMAPE is:3.64% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :7.59 & 14.88% & 1.02\n",
      "for 2021-07-01, MAE is:3.34 & sMAPE is:3.98% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :7.57 & 14.82% & 1.02\n",
      "for 2021-07-02, MAE is:12.39 & sMAPE is:13.83% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :7.60 & 14.82% & 1.02\n",
      "for 2021-07-03, MAE is:4.11 & sMAPE is:4.96% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :7.58 & 14.76% & 1.02\n",
      "for 2021-07-04, MAE is:7.11 & sMAPE is:8.89% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :7.57 & 14.73% & 1.02\n",
      "for 2021-07-05, MAE is:3.67 & sMAPE is:3.98% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :7.55 & 14.67% & 1.01\n",
      "for 2021-07-06, MAE is:5.79 & sMAPE is:6.70% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :7.54 & 14.63% & 1.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-07-07, MAE is:12.61 & sMAPE is:13.14% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :7.57 & 14.62% & 1.02\n",
      "for 2021-07-08, MAE is:3.50 & sMAPE is:3.66% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :7.55 & 14.56% & 1.01\n",
      "for 2021-07-09, MAE is:4.59 & sMAPE is:5.19% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :7.53 & 14.52% & 1.01\n",
      "for 2021-07-10, MAE is:5.48 & sMAPE is:6.80% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :7.52 & 14.48% & 1.01\n",
      "for 2021-07-11, MAE is:4.27 & sMAPE is:5.56% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :7.51 & 14.43% & 1.01\n",
      "for 2021-07-12, MAE is:5.50 & sMAPE is:5.96% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :7.49 & 14.38% & 1.01\n",
      "for 2021-07-13, MAE is:6.73 & sMAPE is:7.55% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :7.49 & 14.35% & 1.01\n",
      "for 2021-07-14, MAE is:5.18 & sMAPE is:6.20% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :7.48 & 14.31% & 1.01\n",
      "for 2021-07-15, MAE is:12.21 & sMAPE is:15.17% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :7.50 & 14.31% & 1.01\n",
      "for 2021-07-16, MAE is:5.86 & sMAPE is:7.13% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :7.49 & 14.28% & 1.01\n",
      "for 2021-07-17, MAE is:10.28 & sMAPE is:15.79% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :7.51 & 14.28% & 1.01\n",
      "for 2021-07-18, MAE is:21.68 & sMAPE is:52.92% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :7.58 & 14.48% & 1.01\n",
      "for 2021-07-19, MAE is:10.73 & sMAPE is:13.49% & rMAE is:1.97 ||| daily mean of MAE & sMAPE & rMAE till now are :7.60 & 14.47% & 1.01\n",
      "for 2021-07-20, MAE is:8.91 & sMAPE is:9.99% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :7.60 & 14.45% & 1.01\n",
      "for 2021-07-21, MAE is:7.67 & sMAPE is:8.15% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :7.60 & 14.42% & 1.01\n",
      "for 2021-07-22, MAE is:7.10 & sMAPE is:7.94% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :7.60 & 14.39% & 1.01\n",
      "for 2021-07-23, MAE is:5.34 & sMAPE is:6.30% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :7.59 & 14.35% & 1.02\n",
      "for 2021-07-24, MAE is:4.30 & sMAPE is:5.82% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :7.57 & 14.31% & 1.01\n",
      "for 2021-07-25, MAE is:8.17 & sMAPE is:12.49% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :7.58 & 14.30% & 1.01\n",
      "for 2021-07-26, MAE is:5.37 & sMAPE is:6.42% & rMAE is:1.93 ||| daily mean of MAE & sMAPE & rMAE till now are :7.57 & 14.26% & 1.02\n",
      "for 2021-07-27, MAE is:5.14 & sMAPE is:6.22% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :7.55 & 14.22% & 1.01\n",
      "for 2021-07-28, MAE is:7.11 & sMAPE is:9.61% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :7.55 & 14.20% & 1.01\n",
      "for 2021-07-29, MAE is:15.59 & sMAPE is:25.27% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :7.59 & 14.25% & 1.01\n",
      "for 2021-07-30, MAE is:13.32 & sMAPE is:19.67% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :7.62 & 14.28% & 1.01\n",
      "for 2021-07-31, MAE is:28.25 & sMAPE is:77.22% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :7.71 & 14.57% & 1.01\n",
      "for 2021-08-01, MAE is:9.95 & sMAPE is:18.17% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :7.72 & 14.59% & 1.01\n",
      "for 2021-08-02, MAE is:9.10 & sMAPE is:12.33% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :7.73 & 14.58% & 1.01\n",
      "for 2021-08-03, MAE is:16.76 & sMAPE is:20.71% & rMAE is:2.59 ||| daily mean of MAE & sMAPE & rMAE till now are :7.77 & 14.61% & 1.01\n",
      "for 2021-08-04, MAE is:12.21 & sMAPE is:14.12% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :7.79 & 14.61% & 1.01\n",
      "for 2021-08-05, MAE is:8.08 & sMAPE is:9.58% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :7.80 & 14.58% & 1.01\n",
      "for 2021-08-06, MAE is:6.78 & sMAPE is:9.19% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :7.79 & 14.56% & 1.01\n",
      "for 2021-08-07, MAE is:9.02 & sMAPE is:14.82% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :7.80 & 14.56% & 1.00\n",
      "for 2021-08-08, MAE is:48.24 & sMAPE is:133.96% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :7.98 & 15.10% & 1.00\n",
      "for 2021-08-09, MAE is:21.15 & sMAPE is:34.92% & rMAE is:2.90 ||| daily mean of MAE & sMAPE & rMAE till now are :8.04 & 15.19% & 1.01\n",
      "for 2021-08-10, MAE is:13.22 & sMAPE is:15.55% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :8.06 & 15.19% & 1.02\n",
      "for 2021-08-11, MAE is:14.24 & sMAPE is:14.72% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :8.09 & 15.19% & 1.02\n",
      "for 2021-08-12, MAE is:13.45 & sMAPE is:13.18% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :8.11 & 15.18% & 1.02\n",
      "for 2021-08-13, MAE is:8.20 & sMAPE is:8.87% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :8.11 & 15.15% & 1.01\n",
      "for 2021-08-14, MAE is:11.01 & sMAPE is:17.37% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :8.13 & 15.16% & 1.01\n",
      "for 2021-08-15, MAE is:11.58 & sMAPE is:23.91% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :8.14 & 15.20% & 1.01\n",
      "for 2021-08-16, MAE is:11.21 & sMAPE is:15.42% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :8.16 & 15.20% & 1.01\n",
      "for 2021-08-17, MAE is:11.41 & sMAPE is:21.80% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :8.17 & 15.23% & 1.01\n",
      "for 2021-08-18, MAE is:10.99 & sMAPE is:14.26% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :8.18 & 15.23% & 1.01\n",
      "for 2021-08-19, MAE is:19.35 & sMAPE is:21.31% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :8.23 & 15.25% & 1.01\n",
      "for 2021-08-20, MAE is:10.37 & sMAPE is:10.88% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :8.24 & 15.24% & 1.01\n",
      "for 2021-08-21, MAE is:7.33 & sMAPE is:8.30% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :8.24 & 15.21% & 1.01\n",
      "for 2021-08-22, MAE is:2.83 & sMAPE is:3.63% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :8.21 & 15.16% & 1.00\n",
      "for 2021-08-23, MAE is:16.58 & sMAPE is:18.46% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :8.25 & 15.17% & 1.00\n",
      "for 2021-08-24, MAE is:8.32 & sMAPE is:8.60% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :8.25 & 15.14% & 1.00\n",
      "for 2021-08-25, MAE is:6.32 & sMAPE is:7.31% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :8.24 & 15.11% & 1.00\n",
      "for 2021-08-26, MAE is:9.25 & sMAPE is:10.55% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :8.25 & 15.09% & 1.00\n",
      "for 2021-08-27, MAE is:11.55 & sMAPE is:12.63% & rMAE is:2.56 ||| daily mean of MAE & sMAPE & rMAE till now are :8.26 & 15.08% & 1.00\n",
      "for 2021-08-28, MAE is:6.61 & sMAPE is:7.98% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :8.25 & 15.05% & 1.00\n",
      "for 2021-08-29, MAE is:12.51 & sMAPE is:15.72% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :8.27 & 15.05% & 1.00\n",
      "for 2021-08-30, MAE is:11.88 & sMAPE is:12.09% & rMAE is:2.37 ||| daily mean of MAE & sMAPE & rMAE till now are :8.28 & 15.04% & 1.01\n",
      "for 2021-08-31, MAE is:21.30 & sMAPE is:20.13% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :8.34 & 15.06% & 1.01\n",
      "for 2021-09-01, MAE is:16.09 & sMAPE is:14.61% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :8.37 & 15.06% & 1.01\n",
      "for 2021-09-02, MAE is:13.35 & sMAPE is:11.59% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :8.39 & 15.05% & 1.01\n",
      "for 2021-09-03, MAE is:9.54 & sMAPE is:8.55% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :8.40 & 15.02% & 1.01\n",
      "for 2021-09-04, MAE is:12.05 & sMAPE is:11.66% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :8.41 & 15.01% & 1.00\n",
      "for 2021-09-05, MAE is:13.86 & sMAPE is:13.61% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :8.43 & 15.00% & 1.00\n",
      "for 2021-09-06, MAE is:10.99 & sMAPE is:9.02% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :8.44 & 14.98% & 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-09-07, MAE is:9.62 & sMAPE is:7.82% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :8.45 & 14.95% & 1.00\n",
      "for 2021-09-08, MAE is:12.73 & sMAPE is:10.20% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :8.46 & 14.93% & 1.00\n",
      "for 2021-09-09, MAE is:18.79 & sMAPE is:14.94% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :8.51 & 14.93% & 1.00\n",
      "for 2021-09-10, MAE is:17.69 & sMAPE is:13.55% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :8.54 & 14.92% & 1.00\n",
      "for 2021-09-11, MAE is:11.34 & sMAPE is:9.40% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :8.55 & 14.90% & 1.00\n",
      "for 2021-09-12, MAE is:13.68 & sMAPE is:12.29% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :8.57 & 14.89% & 1.00\n",
      "for 2021-09-13, MAE is:17.93 & sMAPE is:13.47% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :8.61 & 14.89% & 1.00\n",
      "for 2021-09-14, MAE is:20.22 & sMAPE is:14.02% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :8.65 & 14.88% & 1.00\n",
      "for 2021-09-15, MAE is:26.86 & sMAPE is:17.23% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :8.72 & 14.89% & 1.00\n",
      "for 2021-09-16, MAE is:28.88 & sMAPE is:18.12% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :8.80 & 14.90% & 1.00\n",
      "for 2021-09-17, MAE is:11.33 & sMAPE is:6.95% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :8.81 & 14.87% & 1.00\n",
      "for 2021-09-18, MAE is:11.93 & sMAPE is:8.57% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :8.82 & 14.85% & 1.00\n",
      "for 2021-09-19, MAE is:11.18 & sMAPE is:9.62% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :8.83 & 14.83% & 0.99\n",
      "for 2021-09-20, MAE is:17.25 & sMAPE is:12.18% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :8.87 & 14.82% & 0.99\n",
      "for 2021-09-21, MAE is:13.52 & sMAPE is:8.76% & rMAE is:2.61 ||| daily mean of MAE & sMAPE & rMAE till now are :8.88 & 14.80% & 1.00\n",
      "for 2021-09-22, MAE is:15.24 & sMAPE is:10.31% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :8.91 & 14.78% & 1.00\n",
      "for 2021-09-23, MAE is:12.64 & sMAPE is:10.17% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :8.92 & 14.76% & 1.00\n",
      "for 2021-09-24, MAE is:18.45 & sMAPE is:14.48% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :8.96 & 14.76% & 1.00\n",
      "for 2021-09-25, MAE is:15.22 & sMAPE is:10.48% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :8.98 & 14.75% & 1.00\n",
      "for 2021-09-26, MAE is:21.81 & sMAPE is:16.27% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :9.03 & 14.75% & 1.00\n",
      "for 2021-09-27, MAE is:14.63 & sMAPE is:10.18% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :9.05 & 14.73% & 1.00\n",
      "for 2021-09-28, MAE is:24.97 & sMAPE is:15.18% & rMAE is:1.62 ||| daily mean of MAE & sMAPE & rMAE till now are :9.11 & 14.74% & 1.00\n",
      "for 2021-09-29, MAE is:15.73 & sMAPE is:10.09% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :9.13 & 14.72% & 1.00\n",
      "for 2021-09-30, MAE is:13.91 & sMAPE is:8.49% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :9.15 & 14.70% & 1.00\n",
      "for 2021-10-01, MAE is:18.48 & sMAPE is:11.54% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :9.18 & 14.68% & 1.00\n",
      "for 2021-10-02, MAE is:15.70 & sMAPE is:10.77% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :9.21 & 14.67% & 1.00\n",
      "for 2021-10-03, MAE is:45.52 & sMAPE is:55.64% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :9.34 & 14.82% & 1.00\n",
      "for 2021-10-04, MAE is:41.00 & sMAPE is:26.83% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :9.45 & 14.86% & 1.00\n",
      "for 2021-10-05, MAE is:23.18 & sMAPE is:14.53% & rMAE is:1.86 ||| daily mean of MAE & sMAPE & rMAE till now are :9.50 & 14.86% & 1.00\n",
      "for 2021-10-06, MAE is:56.50 & sMAPE is:32.72% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :9.67 & 14.92% & 1.01\n",
      "for 2021-10-07, MAE is:99.47 & sMAPE is:40.58% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :9.99 & 15.02% & 1.01\n",
      "for 2021-10-08, MAE is:32.06 & sMAPE is:14.72% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :10.07 & 15.01% & 1.00\n",
      "for 2021-10-09, MAE is:17.74 & sMAPE is:10.00% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :10.10 & 15.00% & 1.00\n",
      "for 2021-10-10, MAE is:34.05 & sMAPE is:20.87% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :10.18 & 15.02% & 1.00\n",
      "for 2021-10-11, MAE is:23.56 & sMAPE is:12.90% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :10.23 & 15.01% & 1.00\n",
      "for 2021-10-12, MAE is:26.17 & sMAPE is:13.44% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :10.28 & 15.01% & 1.00\n",
      "for 2021-10-13, MAE is:20.67 & sMAPE is:10.03% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :10.32 & 14.99% & 1.00\n",
      "for 2021-10-14, MAE is:16.82 & sMAPE is:9.10% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :10.34 & 14.97% & 0.99\n",
      "for 2021-10-15, MAE is:22.04 & sMAPE is:10.93% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :10.38 & 14.95% & 1.00\n",
      "for 2021-10-16, MAE is:21.29 & sMAPE is:11.38% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :10.42 & 14.94% & 1.00\n",
      "for 2021-10-17, MAE is:19.16 & sMAPE is:11.06% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :10.45 & 14.93% & 1.00\n",
      "for 2021-10-18, MAE is:24.11 & sMAPE is:11.08% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :10.50 & 14.91% & 1.00\n",
      "for 2021-10-19, MAE is:29.72 & sMAPE is:14.48% & rMAE is:1.75 ||| daily mean of MAE & sMAPE & rMAE till now are :10.56 & 14.91% & 1.00\n",
      "for 2021-10-20, MAE is:12.64 & sMAPE is:6.04% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :10.57 & 14.88% & 1.00\n",
      "for 2021-10-21, MAE is:15.22 & sMAPE is:7.20% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :10.59 & 14.86% & 1.00\n",
      "for 2021-10-22, MAE is:21.99 & sMAPE is:10.12% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :10.63 & 14.84% & 1.00\n",
      "for 2021-10-23, MAE is:16.66 & sMAPE is:7.96% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :10.65 & 14.82% & 1.00\n",
      "for 2021-10-24, MAE is:16.39 & sMAPE is:8.84% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :10.67 & 14.80% & 1.00\n",
      "for 2021-10-25, MAE is:24.25 & sMAPE is:11.03% & rMAE is:3.08 ||| daily mean of MAE & sMAPE & rMAE till now are :10.71 & 14.78% & 1.01\n",
      "for 2021-10-26, MAE is:18.80 & sMAPE is:8.68% & rMAE is:2.74 ||| daily mean of MAE & sMAPE & rMAE till now are :10.74 & 14.76% & 1.01\n",
      "for 2021-10-27, MAE is:18.85 & sMAPE is:8.47% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :10.77 & 14.74% & 1.01\n",
      "for 2021-10-28, MAE is:16.00 & sMAPE is:7.39% & rMAE is:2.08 ||| daily mean of MAE & sMAPE & rMAE till now are :10.78 & 14.72% & 1.02\n",
      "for 2021-10-29, MAE is:9.56 & sMAPE is:4.65% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :10.78 & 14.69% & 1.01\n",
      "for 2021-10-30, MAE is:12.90 & sMAPE is:7.08% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :10.79 & 14.66% & 1.01\n",
      "for 2021-10-31, MAE is:12.07 & sMAPE is:7.05% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :10.79 & 14.63% & 1.01\n",
      "for 2021-11-01, MAE is:7.99 & sMAPE is:4.71% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :10.78 & 14.60% & 1.01\n",
      "for 2021-11-02, MAE is:41.42 & sMAPE is:21.22% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :10.88 & 14.62% & 1.01\n",
      "for 2021-11-03, MAE is:22.64 & sMAPE is:10.62% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :10.92 & 14.61% & 1.01\n",
      "for 2021-11-04, MAE is:13.71 & sMAPE is:7.22% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :10.93 & 14.59% & 1.01\n",
      "for 2021-11-05, MAE is:24.86 & sMAPE is:13.74% & rMAE is:3.24 ||| daily mean of MAE & sMAPE & rMAE till now are :10.97 & 14.58% & 1.01\n",
      "for 2021-11-06, MAE is:16.01 & sMAPE is:9.06% & rMAE is:2.34 ||| daily mean of MAE & sMAPE & rMAE till now are :10.99 & 14.57% & 1.02\n",
      "for 2021-11-07, MAE is:10.36 & sMAPE is:6.22% & rMAE is:2.18 ||| daily mean of MAE & sMAPE & rMAE till now are :10.99 & 14.54% & 1.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-11-08, MAE is:33.17 & sMAPE is:17.04% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :11.06 & 14.55% & 1.02\n",
      "for 2021-11-09, MAE is:19.00 & sMAPE is:9.35% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :11.08 & 14.53% & 1.02\n",
      "for 2021-11-10, MAE is:17.99 & sMAPE is:7.90% & rMAE is:2.03 ||| daily mean of MAE & sMAPE & rMAE till now are :11.11 & 14.51% & 1.02\n",
      "for 2021-11-11, MAE is:14.22 & sMAPE is:7.22% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :11.12 & 14.49% & 1.03\n",
      "for 2021-11-12, MAE is:14.03 & sMAPE is:7.55% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :11.13 & 14.46% & 1.03\n",
      "for 2021-11-13, MAE is:16.74 & sMAPE is:9.32% & rMAE is:2.63 ||| daily mean of MAE & sMAPE & rMAE till now are :11.14 & 14.45% & 1.03\n",
      "for 2021-11-14, MAE is:7.81 & sMAPE is:4.36% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :11.13 & 14.42% & 1.03\n",
      "for 2021-11-15, MAE is:36.83 & sMAPE is:17.27% & rMAE is:2.36 ||| daily mean of MAE & sMAPE & rMAE till now are :11.21 & 14.43% & 1.04\n",
      "for 2021-11-16, MAE is:38.74 & sMAPE is:16.97% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :11.30 & 14.43% & 1.04\n",
      "for 2021-11-17, MAE is:45.19 & sMAPE is:20.57% & rMAE is:1.91 ||| daily mean of MAE & sMAPE & rMAE till now are :11.41 & 14.45% & 1.04\n",
      "for 2021-11-18, MAE is:49.81 & sMAPE is:21.84% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :11.52 & 14.48% & 1.04\n",
      "for 2021-11-19, MAE is:20.01 & sMAPE is:8.61% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :11.55 & 14.46% & 1.04\n",
      "for 2021-11-20, MAE is:16.05 & sMAPE is:7.23% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :11.56 & 14.44% & 1.04\n",
      "for 2021-11-21, MAE is:10.32 & sMAPE is:4.59% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :11.56 & 14.41% & 1.03\n",
      "for 2021-11-22, MAE is:32.86 & sMAPE is:13.10% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :11.63 & 14.40% & 1.03\n",
      "for 2021-11-23, MAE is:43.54 & sMAPE is:16.52% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :11.72 & 14.41% & 1.03\n",
      "for 2021-11-24, MAE is:65.80 & sMAPE is:22.41% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :11.89 & 14.43% & 1.03\n",
      "for 2021-11-25, MAE is:28.56 & sMAPE is:9.57% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :11.94 & 14.42% & 1.03\n",
      "for 2021-11-26, MAE is:24.06 & sMAPE is:8.76% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :11.98 & 14.40% & 1.03\n",
      "for 2021-11-27, MAE is:11.02 & sMAPE is:4.59% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :11.97 & 14.37% & 1.03\n",
      "for 2021-11-28, MAE is:12.04 & sMAPE is:5.38% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :11.97 & 14.34% & 1.03\n",
      "for 2021-11-29, MAE is:63.47 & sMAPE is:22.15% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :12.13 & 14.37% & 1.03\n",
      "for 2021-11-30, MAE is:18.18 & sMAPE is:6.44% & rMAE is:1.62 ||| daily mean of MAE & sMAPE & rMAE till now are :12.15 & 14.34% & 1.03\n",
      "for 2021-12-01, MAE is:14.10 & sMAPE is:5.52% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :12.15 & 14.32% & 1.03\n",
      "for 2021-12-02, MAE is:34.95 & sMAPE is:11.78% & rMAE is:2.23 ||| daily mean of MAE & sMAPE & rMAE till now are :12.22 & 14.31% & 1.04\n",
      "for 2021-12-03, MAE is:27.43 & sMAPE is:9.08% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :12.26 & 14.29% & 1.04\n",
      "for 2021-12-04, MAE is:13.20 & sMAPE is:5.51% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :12.27 & 14.27% & 1.04\n",
      "for 2021-12-05, MAE is:17.79 & sMAPE is:8.12% & rMAE is:2.68 ||| daily mean of MAE & sMAPE & rMAE till now are :12.28 & 14.25% & 1.04\n",
      "for 2021-12-06, MAE is:41.00 & sMAPE is:14.14% & rMAE is:2.41 ||| daily mean of MAE & sMAPE & rMAE till now are :12.37 & 14.25% & 1.05\n",
      "for 2021-12-07, MAE is:31.01 & sMAPE is:11.84% & rMAE is:2.21 ||| daily mean of MAE & sMAPE & rMAE till now are :12.42 & 14.24% & 1.05\n",
      "for 2021-12-08, MAE is:11.79 & sMAPE is:4.75% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :12.42 & 14.21% & 1.05\n",
      "for 2021-12-09, MAE is:38.63 & sMAPE is:13.53% & rMAE is:2.11 ||| daily mean of MAE & sMAPE & rMAE till now are :12.50 & 14.21% & 1.05\n",
      "for 2021-12-10, MAE is:21.89 & sMAPE is:8.06% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :12.52 & 14.19% & 1.05\n",
      "for 2021-12-11, MAE is:12.33 & sMAPE is:5.07% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :12.52 & 14.17% & 1.05\n",
      "for 2021-12-12, MAE is:14.32 & sMAPE is:6.00% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :12.53 & 14.14% & 1.05\n",
      "for 2021-12-13, MAE is:31.59 & sMAPE is:11.21% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :12.58 & 14.14% & 1.05\n",
      "for 2021-12-14, MAE is:58.74 & sMAPE is:19.19% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :12.72 & 14.15% & 1.05\n",
      "for 2021-12-15, MAE is:41.35 & sMAPE is:12.99% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :12.80 & 14.15% & 1.05\n",
      "for 2021-12-16, MAE is:69.48 & sMAPE is:20.26% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :12.96 & 14.16% & 1.05\n",
      "for 2021-12-17, MAE is:40.79 & sMAPE is:11.27% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :13.04 & 14.16% & 1.05\n",
      "for 2021-12-18, MAE is:9.10 & sMAPE is:2.88% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :13.03 & 14.12% & 1.04\n",
      "for 2021-12-19, MAE is:48.34 & sMAPE is:15.17% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :13.13 & 14.13% & 1.04\n",
      "for 2021-12-20, MAE is:65.29 & sMAPE is:16.99% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :13.28 & 14.14% & 1.04\n",
      "for 2021-12-21, MAE is:50.47 & sMAPE is:12.18% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :13.38 & 14.13% & 1.04\n",
      "for 2021-12-22, MAE is:59.24 & sMAPE is:13.68% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :13.51 & 14.13% & 1.04\n",
      "for 2021-12-23, MAE is:26.51 & sMAPE is:6.68% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :13.55 & 14.11% & 1.04\n",
      "for 2021-12-24, MAE is:17.42 & sMAPE is:4.62% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :13.56 & 14.08% & 1.04\n",
      "for 2021-12-25, MAE is:116.40 & sMAPE is:45.30% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :13.84 & 14.17% & 1.04\n",
      "for 2021-12-26, MAE is:56.84 & sMAPE is:28.36% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :13.96 & 14.21% & 1.03\n",
      "for 2021-12-27, MAE is:50.77 & sMAPE is:24.49% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :14.07 & 14.24% & 1.03\n",
      "for 2021-12-28, MAE is:33.90 & sMAPE is:17.16% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :14.12 & 14.24% & 1.03\n",
      "for 2021-12-29, MAE is:37.18 & sMAPE is:21.72% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :14.18 & 14.26% & 1.03\n",
      "for 2021-12-30, MAE is:40.37 & sMAPE is:31.67% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :14.26 & 14.31% & 1.03\n",
      "for 2021-12-31, MAE is:17.69 & sMAPE is:11.09% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :14.26 & 14.30% & 1.02\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:29:28,953]\u001b[0m A new study created in RDB with name: CH_2022\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:30:01,179]\u001b[0m Trial 0 finished with value: 56.14797236072284 and parameters: {'n_hidden': 3, 'learning_rate': 0.002709321693472089, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19178558679832725, 'dropout_rate_Layer_2': 0.11451703577921207, 'dropout_rate_Layer_3': 0.17078856581127577, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.018587926612175416, 'l1_Layer_2': 0.00019425896877340213, 'l1_Layer_3': 0.0005208039498072244, 'n_units_Layer_1': 280, 'n_units_Layer_2': 245, 'n_units_Layer_3': 300}. Best is trial 0 with value: 56.14797236072284.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.15 | sMAPE for Validation Set is: 45.16% | rMAE for Validation Set is: 2.67\n",
      "MAE for Test Set is: 214.50 | sMAPE for Test Set is: 112.14% | rMAE for Test Set is: 3.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:30:09,682]\u001b[0m Trial 2 finished with value: 41.397187475953906 and parameters: {'n_hidden': 3, 'learning_rate': 0.003788532154366262, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20098978147372482, 'dropout_rate_Layer_2': 0.03647227487769609, 'dropout_rate_Layer_3': 0.14568846420086584, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.50446412989955e-05, 'l1_Layer_2': 0.004939813600372821, 'l1_Layer_3': 0.0007816192598996198, 'n_units_Layer_1': 275, 'n_units_Layer_2': 295, 'n_units_Layer_3': 250}. Best is trial 2 with value: 41.397187475953906.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.40 | sMAPE for Validation Set is: 31.94% | rMAE for Validation Set is: 1.97\n",
      "MAE for Test Set is: 168.99 | sMAPE for Test Set is: 75.88% | rMAE for Test Set is: 2.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:30:38,442]\u001b[0m Trial 3 finished with value: 52.46099130031117 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006752202125569493, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22391762013472968, 'dropout_rate_Layer_2': 0.21479267793523632, 'dropout_rate_Layer_3': 0.3887963422697515, 'dropout_rate_Layer_4': 0.26825241367008645, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0009443286698416212, 'l1_Layer_2': 0.00022800074215361394, 'l1_Layer_3': 0.030494886957123518, 'l1_Layer_4': 0.03849838282626157, 'n_units_Layer_1': 235, 'n_units_Layer_2': 215, 'n_units_Layer_3': 290, 'n_units_Layer_4': 110}. Best is trial 2 with value: 41.397187475953906.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.46 | sMAPE for Validation Set is: 41.37% | rMAE for Validation Set is: 2.49\n",
      "MAE for Test Set is: 204.08 | sMAPE for Test Set is: 102.76% | rMAE for Test Set is: 3.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:30:41,522]\u001b[0m Trial 4 finished with value: 49.871566160946145 and parameters: {'n_hidden': 4, 'learning_rate': 0.00314909123546517, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07560476584293037, 'dropout_rate_Layer_2': 0.056916823190351275, 'dropout_rate_Layer_3': 0.0331775630617547, 'dropout_rate_Layer_4': 0.37352587345186467, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0010933914248839208, 'l1_Layer_2': 9.036928693019234e-05, 'l1_Layer_3': 0.0012752004189173283, 'l1_Layer_4': 0.0062435070145901205, 'n_units_Layer_1': 260, 'n_units_Layer_2': 130, 'n_units_Layer_3': 65, 'n_units_Layer_4': 105}. Best is trial 2 with value: 41.397187475953906.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.87 | sMAPE for Validation Set is: 38.37% | rMAE for Validation Set is: 2.37\n",
      "MAE for Test Set is: 199.16 | sMAPE for Test Set is: 98.68% | rMAE for Test Set is: 3.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:30:48,251]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:30:55,347]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:31:01,057]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:31:04,555]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:31:08,213]\u001b[0m Trial 1 finished with value: 50.188182945269226 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005682674792300733, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3530615190387945, 'dropout_rate_Layer_2': 0.33543481478223613, 'dropout_rate_Layer_3': 0.18788478185655122, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.358364015170012e-05, 'l1_Layer_2': 0.0016852862171375395, 'l1_Layer_3': 0.021400969746645803, 'n_units_Layer_1': 50, 'n_units_Layer_2': 275, 'n_units_Layer_3': 280}. Best is trial 2 with value: 41.397187475953906.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:31:08,288]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.19 | sMAPE for Validation Set is: 39.34% | rMAE for Validation Set is: 2.38\n",
      "MAE for Test Set is: 194.90 | sMAPE for Test Set is: 95.02% | rMAE for Test Set is: 3.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:31:14,679]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:31:17,774]\u001b[0m Trial 7 finished with value: 12.296765922478903 and parameters: {'n_hidden': 3, 'learning_rate': 0.003974555227784801, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08263240117559012, 'dropout_rate_Layer_2': 0.1681007616397403, 'dropout_rate_Layer_3': 0.051902095848459465, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002943091265564819, 'l1_Layer_2': 0.0032755386112459962, 'l1_Layer_3': 0.0798252963554153, 'n_units_Layer_1': 175, 'n_units_Layer_2': 190, 'n_units_Layer_3': 80}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.30 | sMAPE for Validation Set is: 12.71% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 33.74 | sMAPE for Test Set is: 13.23% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:31:18,302]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:31:21,206]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:31:24,543]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:31:27,112]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:31:30,427]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:31:31,980]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:31:33,986]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:31:37,040]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:31:40,418]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:31:40,935]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:31:43,889]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:31:48,806]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:31:51,279]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:31:56,796]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:32:03,760]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:32:08,286]\u001b[0m Trial 5 finished with value: 52.55829319382068 and parameters: {'n_hidden': 3, 'learning_rate': 0.01895480955720864, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09927140094792275, 'dropout_rate_Layer_2': 0.17943778207527783, 'dropout_rate_Layer_3': 0.17232544568385047, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.013706725237928315, 'l1_Layer_2': 0.00012705868400304264, 'l1_Layer_3': 0.0070965540764219475, 'n_units_Layer_1': 75, 'n_units_Layer_2': 235, 'n_units_Layer_3': 145}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.56 | sMAPE for Validation Set is: 41.90% | rMAE for Validation Set is: 2.50\n",
      "MAE for Test Set is: 206.87 | sMAPE for Test Set is: 105.02% | rMAE for Test Set is: 3.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:32:10,532]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:32:18,653]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:32:35,106]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:32:37,807]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:32:43,164]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:32:48,657]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:32:55,014]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:33:01,662]\u001b[0m Trial 36 finished with value: 13.634503017848209 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036748356682815195, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1888923406143576, 'dropout_rate_Layer_2': 0.07915956767432136, 'dropout_rate_Layer_3': 0.37886142543588297, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0628734988363198, 'l1_Layer_2': 0.00020350320812823883, 'l1_Layer_3': 0.007826941699032383, 'n_units_Layer_1': 285, 'n_units_Layer_2': 185, 'n_units_Layer_3': 295}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.63 | sMAPE for Validation Set is: 14.19% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 37.63 | sMAPE for Test Set is: 14.77% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:33:09,546]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:33:14,896]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:33:15,140]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:33:22,885]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:33:23,027]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 63.74 | sMAPE for Validation Set is: 55.33% | rMAE for Validation Set is: 3.03\n",
      "MAE for Test Set is: 227.37 | sMAPE for Test Set is: 124.86% | rMAE for Test Set is: 3.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:33:25,841]\u001b[0m Trial 24 finished with value: 63.7406861689104 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006783232268022256, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24611156938360346, 'dropout_rate_Layer_2': 0.19856561757464564, 'dropout_rate_Layer_3': 0.250503029986693, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001112916242803068, 'l1_Layer_2': 0.03412827777301984, 'l1_Layer_3': 0.03515515292899037, 'n_units_Layer_1': 115, 'n_units_Layer_2': 135, 'n_units_Layer_3': 220}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:33:34,839]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:33:38,035]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:33:45,079]\u001b[0m Trial 46 finished with value: 15.728300811032343 and parameters: {'n_hidden': 3, 'learning_rate': 0.03141934472797704, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25551797919767766, 'dropout_rate_Layer_2': 0.004004980824286658, 'dropout_rate_Layer_3': 0.36011329917912216, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.06507920903748135, 'l1_Layer_2': 0.00015090143136394275, 'l1_Layer_3': 0.01061942774067512, 'n_units_Layer_1': 300, 'n_units_Layer_2': 195, 'n_units_Layer_3': 295}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.73 | sMAPE for Validation Set is: 15.48% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 44.67 | sMAPE for Test Set is: 17.07% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:33:49,021]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:33:56,272]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:34:00,350]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:34:02,023]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:34:12,264]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:34:12,923]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:34:18,605]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:34:19,077]\u001b[0m Trial 27 finished with value: 51.72579559970834 and parameters: {'n_hidden': 3, 'learning_rate': 0.00809240318689592, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16952039383036738, 'dropout_rate_Layer_2': 0.3048070906674988, 'dropout_rate_Layer_3': 0.13520343199831597, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.986610677641533e-05, 'l1_Layer_2': 0.027768026096488093, 'l1_Layer_3': 0.00036644399101481165, 'n_units_Layer_1': 155, 'n_units_Layer_2': 245, 'n_units_Layer_3': 280}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.73 | sMAPE for Validation Set is: 40.77% | rMAE for Validation Set is: 2.46\n",
      "MAE for Test Set is: 200.85 | sMAPE for Test Set is: 100.57% | rMAE for Test Set is: 3.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:34:23,428]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:34:26,619]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:34:29,126]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:34:29,689]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:34:33,789]\u001b[0m Trial 51 finished with value: 13.253494964398485 and parameters: {'n_hidden': 4, 'learning_rate': 0.002184586632312171, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20754078533263437, 'dropout_rate_Layer_2': 0.2286122472442577, 'dropout_rate_Layer_3': 0.0484902104471423, 'dropout_rate_Layer_4': 0.13673206214054826, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.6713684337797487e-05, 'l1_Layer_2': 7.816976502089656e-05, 'l1_Layer_3': 1.1903520422338991e-05, 'l1_Layer_4': 0.0040549854852719135, 'n_units_Layer_1': 215, 'n_units_Layer_2': 225, 'n_units_Layer_3': 270, 'n_units_Layer_4': 300}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.25 | sMAPE for Validation Set is: 14.24% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 35.75 | sMAPE for Test Set is: 13.99% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:34:35,494]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:34:38,981]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:34:41,231]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:34:45,824]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:34:47,231]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:34:55,375]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:35:00,379]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:35:00,587]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:35:07,834]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:35:11,662]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:35:13,802]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:35:18,435]\u001b[0m Trial 62 finished with value: 52.878308244180516 and parameters: {'n_hidden': 4, 'learning_rate': 0.02274575094358148, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0714354413563626, 'dropout_rate_Layer_2': 0.38357782842787397, 'dropout_rate_Layer_3': 0.0796313687522974, 'dropout_rate_Layer_4': 0.22793539443484678, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.322025429819455e-05, 'l1_Layer_2': 0.0015097214025657382, 'l1_Layer_3': 0.00012571519894132997, 'l1_Layer_4': 3.898021173775532e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 210, 'n_units_Layer_3': 180, 'n_units_Layer_4': 85}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.88 | sMAPE for Validation Set is: 45.68% | rMAE for Validation Set is: 2.51\n",
      "MAE for Test Set is: 189.63 | sMAPE for Test Set is: 92.80% | rMAE for Test Set is: 2.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:35:21,321]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:35:22,397]\u001b[0m Trial 67 finished with value: 52.52580812868903 and parameters: {'n_hidden': 4, 'learning_rate': 0.02205009829776907, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3267341617711603, 'dropout_rate_Layer_2': 0.025660408261418955, 'dropout_rate_Layer_3': 0.23268058106174566, 'dropout_rate_Layer_4': 0.23120694173239392, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.007224826929210406, 'l1_Layer_2': 0.00016896867509157476, 'l1_Layer_3': 3.6150448785503366e-05, 'l1_Layer_4': 0.000686257824214335, 'n_units_Layer_1': 250, 'n_units_Layer_2': 70, 'n_units_Layer_3': 80, 'n_units_Layer_4': 180}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.53 | sMAPE for Validation Set is: 41.44% | rMAE for Validation Set is: 2.49\n",
      "MAE for Test Set is: 203.36 | sMAPE for Test Set is: 102.43% | rMAE for Test Set is: 3.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:35:27,555]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:35:30,764]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:35:32,483]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:35:35,928]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:35:38,078]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:35:40,627]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:35:43,525]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:35:44,296]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:35:44,312]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:35:48,224]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:35:53,136]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:35:58,151]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:36:01,328]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:36:04,066]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:36:08,051]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:36:10,203]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:36:12,313]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:36:12,677]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:36:15,134]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:36:19,739]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:36:19,977]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:36:20,202]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:36:20,550]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:36:28,763]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:36:33,582]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:36:38,075]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:36:38,198]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:36:38,385]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:36:45,921]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:36:59,130]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:36:59,221]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:37:03,440]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:37:04,260]\u001b[0m Trial 95 finished with value: 44.18773649371093 and parameters: {'n_hidden': 3, 'learning_rate': 0.02937087382429902, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2897021982394428, 'dropout_rate_Layer_2': 0.15510818785405106, 'dropout_rate_Layer_3': 0.16926222317917455, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.8376298653187272e-05, 'l1_Layer_2': 0.06349555704985861, 'l1_Layer_3': 0.0010371603746787178, 'n_units_Layer_1': 110, 'n_units_Layer_2': 215, 'n_units_Layer_3': 210}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.19 | sMAPE for Validation Set is: 33.78% | rMAE for Validation Set is: 2.10\n",
      "MAE for Test Set is: 177.59 | sMAPE for Test Set is: 81.93% | rMAE for Test Set is: 2.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:37:08,381]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:37:12,343]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:37:12,513]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:37:18,867]\u001b[0m Trial 109 finished with value: 78.62413565999748 and parameters: {'n_hidden': 4, 'learning_rate': 0.017249058058859533, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21316012742869517, 'dropout_rate_Layer_2': 0.11403698793779081, 'dropout_rate_Layer_3': 0.33601997971245334, 'dropout_rate_Layer_4': 0.34222885732794406, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.004427142238075402, 'l1_Layer_2': 0.0022087975462873484, 'l1_Layer_3': 8.174975796189486e-05, 'l1_Layer_4': 0.00013165614376661283, 'n_units_Layer_1': 240, 'n_units_Layer_2': 255, 'n_units_Layer_3': 200, 'n_units_Layer_4': 55}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 78.62 | sMAPE for Validation Set is: 81.00% | rMAE for Validation Set is: 3.73\n",
      "MAE for Test Set is: 245.44 | sMAPE for Test Set is: 144.55% | rMAE for Test Set is: 3.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:37:20,778]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:37:22,110]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:37:27,498]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:37:27,791]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:37:31,313]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:37:34,567]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:37:37,009]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:37:38,569]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:37:40,690]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:37:46,033]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:37:46,498]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:37:47,965]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:37:54,189]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:37:54,405]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:37:56,551]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:38:02,791]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:38:04,244]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:38:04,535]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:38:04,687]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:38:09,589]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:38:11,132]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:38:17,982]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:38:19,941]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:38:24,576]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:38:25,144]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:38:29,087]\u001b[0m Trial 130 finished with value: 51.78634149437149 and parameters: {'n_hidden': 4, 'learning_rate': 0.015230847182842365, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3392566930828723, 'dropout_rate_Layer_2': 0.01503988258162159, 'dropout_rate_Layer_3': 0.20722454521428516, 'dropout_rate_Layer_4': 0.23152072710618404, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 7.455956127454046e-05, 'l1_Layer_2': 3.462465518310989e-05, 'l1_Layer_3': 0.0019564133886191986, 'l1_Layer_4': 0.00015875133672701397, 'n_units_Layer_1': 265, 'n_units_Layer_2': 270, 'n_units_Layer_3': 80, 'n_units_Layer_4': 235}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.79 | sMAPE for Validation Set is: 41.42% | rMAE for Validation Set is: 2.46\n",
      "MAE for Test Set is: 197.92 | sMAPE for Test Set is: 97.74% | rMAE for Test Set is: 3.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:38:30,057]\u001b[0m Trial 131 finished with value: 49.25264561385859 and parameters: {'n_hidden': 4, 'learning_rate': 0.015638514787634755, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32881354350760167, 'dropout_rate_Layer_2': 0.014167551280588626, 'dropout_rate_Layer_3': 0.2105623194007928, 'dropout_rate_Layer_4': 0.2323846199102297, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 9.469167308485386e-05, 'l1_Layer_2': 3.9176731503463155e-05, 'l1_Layer_3': 0.00040696554025528264, 'l1_Layer_4': 0.00015068598412006258, 'n_units_Layer_1': 265, 'n_units_Layer_2': 265, 'n_units_Layer_3': 95, 'n_units_Layer_4': 240}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.25 | sMAPE for Validation Set is: 40.03% | rMAE for Validation Set is: 2.34\n",
      "MAE for Test Set is: 179.52 | sMAPE for Test Set is: 83.65% | rMAE for Test Set is: 2.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:38:34,252]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:38:34,340]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:38:34,772]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:38:39,632]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:38:46,924]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:38:50,759]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:38:56,377]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:39:09,223]\u001b[0m Trial 146 finished with value: 13.321857570456393 and parameters: {'n_hidden': 3, 'learning_rate': 0.004873863202882261, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14690485048872295, 'dropout_rate_Layer_2': 0.09744721302352718, 'dropout_rate_Layer_3': 0.3355486043851748, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.026166747766146692, 'l1_Layer_2': 0.011734587077171102, 'l1_Layer_3': 0.005436239854712465, 'n_units_Layer_1': 300, 'n_units_Layer_2': 180, 'n_units_Layer_3': 155}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.32 | sMAPE for Validation Set is: 13.81% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 36.85 | sMAPE for Test Set is: 14.49% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:39:14,671]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:39:19,229]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:39:21,987]\u001b[0m Trial 143 finished with value: 47.886602615990455 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025844616987918253, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2896817883242102, 'dropout_rate_Layer_2': 0.2258213600974988, 'dropout_rate_Layer_3': 0.2411645384862423, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0549438762906351e-05, 'l1_Layer_2': 0.001425840882718124, 'l1_Layer_3': 0.013391144853512858, 'n_units_Layer_1': 50, 'n_units_Layer_2': 230, 'n_units_Layer_3': 300}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.89 | sMAPE for Validation Set is: 37.93% | rMAE for Validation Set is: 2.27\n",
      "MAE for Test Set is: 187.60 | sMAPE for Test Set is: 89.24% | rMAE for Test Set is: 2.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:39:26,232]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:39:29,835]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:39:32,137]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:39:40,901]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:39:44,432]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:39:48,618]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:39:53,096]\u001b[0m Trial 152 finished with value: 42.43946969876742 and parameters: {'n_hidden': 3, 'learning_rate': 0.003655991650999101, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3973808172581715, 'dropout_rate_Layer_2': 0.04201648875775948, 'dropout_rate_Layer_3': 0.35411265073520154, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.061549473507963526, 'l1_Layer_2': 7.853507038017821e-05, 'l1_Layer_3': 0.011473676651059984, 'n_units_Layer_1': 235, 'n_units_Layer_2': 295, 'n_units_Layer_3': 125}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.44 | sMAPE for Validation Set is: 33.16% | rMAE for Validation Set is: 2.02\n",
      "MAE for Test Set is: 169.01 | sMAPE for Test Set is: 75.65% | rMAE for Test Set is: 2.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:40:00,859]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:40:10,151]\u001b[0m Trial 156 finished with value: 51.62973754877041 and parameters: {'n_hidden': 4, 'learning_rate': 0.016645898172107158, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3177652452258828, 'dropout_rate_Layer_2': 0.22276317106463822, 'dropout_rate_Layer_3': 0.24636227891810752, 'dropout_rate_Layer_4': 0.22176598955253346, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.93201804881699e-05, 'l1_Layer_2': 3.656078373097194e-05, 'l1_Layer_3': 0.0005455295223966754, 'l1_Layer_4': 0.0001442287207485203, 'n_units_Layer_1': 255, 'n_units_Layer_2': 285, 'n_units_Layer_3': 95, 'n_units_Layer_4': 260}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.63 | sMAPE for Validation Set is: 40.91% | rMAE for Validation Set is: 2.45\n",
      "MAE for Test Set is: 199.54 | sMAPE for Test Set is: 99.13% | rMAE for Test Set is: 3.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:40:13,438]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:40:18,299]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:40:24,147]\u001b[0m Trial 144 finished with value: 30.887670007005084 and parameters: {'n_hidden': 4, 'learning_rate': 0.01298088306163399, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3759082311270964, 'dropout_rate_Layer_2': 0.046795324231318894, 'dropout_rate_Layer_3': 0.12672003907101945, 'dropout_rate_Layer_4': 0.2731109488607231, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.455015111324286e-05, 'l1_Layer_2': 7.202811644414738e-05, 'l1_Layer_3': 0.0016478964199489361, 'l1_Layer_4': 2.077690092917267e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 115, 'n_units_Layer_3': 75, 'n_units_Layer_4': 195}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.89 | sMAPE for Validation Set is: 24.04% | rMAE for Validation Set is: 1.47\n",
      "MAE for Test Set is: 135.11 | sMAPE for Test Set is: 54.44% | rMAE for Test Set is: 2.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:40:38,717]\u001b[0m Trial 161 finished with value: 51.4216374037376 and parameters: {'n_hidden': 4, 'learning_rate': 0.012552860026622873, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3206660967061268, 'dropout_rate_Layer_2': 0.0009186088300331928, 'dropout_rate_Layer_3': 0.2544691033239143, 'dropout_rate_Layer_4': 0.23871432179994384, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.368451150618572e-05, 'l1_Layer_2': 2.582952393430361e-05, 'l1_Layer_3': 0.0006025147859288321, 'l1_Layer_4': 9.693928676539439e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 290, 'n_units_Layer_3': 65, 'n_units_Layer_4': 230}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.42 | sMAPE for Validation Set is: 41.10% | rMAE for Validation Set is: 2.44\n",
      "MAE for Test Set is: 193.82 | sMAPE for Test Set is: 94.62% | rMAE for Test Set is: 3.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:40:42,061]\u001b[0m Trial 162 finished with value: 53.87723891511448 and parameters: {'n_hidden': 4, 'learning_rate': 0.012534012501256402, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2744478418350548, 'dropout_rate_Layer_2': 0.3990624862308174, 'dropout_rate_Layer_3': 0.11466250150046939, 'dropout_rate_Layer_4': 0.23535492437718, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.5619914383919924e-05, 'l1_Layer_2': 6.258919577164242e-05, 'l1_Layer_3': 0.0006212655810693666, 'l1_Layer_4': 1.799158138850155e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 120, 'n_units_Layer_3': 65, 'n_units_Layer_4': 225}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.88 | sMAPE for Validation Set is: 43.82% | rMAE for Validation Set is: 2.56\n",
      "MAE for Test Set is: 203.34 | sMAPE for Test Set is: 102.40% | rMAE for Test Set is: 3.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:40:43,991]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:40:48,580]\u001b[0m Trial 141 finished with value: 31.574896029791134 and parameters: {'n_hidden': 4, 'learning_rate': 0.014100717008845659, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36949199867765875, 'dropout_rate_Layer_2': 0.0649525951521872, 'dropout_rate_Layer_3': 0.13808017162778677, 'dropout_rate_Layer_4': 0.2738341876209483, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.9409942988615513e-05, 'l1_Layer_2': 2.473099330003542e-05, 'l1_Layer_3': 0.002142361686584096, 'l1_Layer_4': 0.0028872412861093424, 'n_units_Layer_1': 280, 'n_units_Layer_2': 240, 'n_units_Layer_3': 75, 'n_units_Layer_4': 145}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 31.57 | sMAPE for Validation Set is: 26.53% | rMAE for Validation Set is: 1.50\n",
      "MAE for Test Set is: 121.22 | sMAPE for Test Set is: 49.19% | rMAE for Test Set is: 1.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:40:49,935]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:40:54,326]\u001b[0m Trial 159 finished with value: 51.16553651104649 and parameters: {'n_hidden': 3, 'learning_rate': 0.003319172043223654, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19756087490305416, 'dropout_rate_Layer_2': 0.13746019716377328, 'dropout_rate_Layer_3': 0.0703774276204503, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.04271791086535803, 'l1_Layer_2': 1.6186540911382465e-05, 'l1_Layer_3': 0.0016984380721153636, 'n_units_Layer_1': 280, 'n_units_Layer_2': 175, 'n_units_Layer_3': 300}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.17 | sMAPE for Validation Set is: 39.80% | rMAE for Validation Set is: 2.43\n",
      "MAE for Test Set is: 202.08 | sMAPE for Test Set is: 101.18% | rMAE for Test Set is: 3.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:40:58,644]\u001b[0m Trial 164 finished with value: 12.41325579578428 and parameters: {'n_hidden': 3, 'learning_rate': 0.005623777032757465, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20341368133535037, 'dropout_rate_Layer_2': 0.16006416974876758, 'dropout_rate_Layer_3': 0.2548206070823269, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002335135569794412, 'l1_Layer_2': 2.3008072146093967e-05, 'l1_Layer_3': 0.00544367849201021, 'n_units_Layer_1': 290, 'n_units_Layer_2': 135, 'n_units_Layer_3': 210}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.41 | sMAPE for Validation Set is: 12.88% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 34.85 | sMAPE for Test Set is: 13.46% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:40:59,225]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:41:03,921]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:41:04,197]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 63.20 | sMAPE for Validation Set is: 54.91% | rMAE for Validation Set is: 3.00\n",
      "MAE for Test Set is: 225.38 | sMAPE for Test Set is: 122.86% | rMAE for Test Set is: 3.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:41:06,371]\u001b[0m Trial 166 finished with value: 63.19637051840734 and parameters: {'n_hidden': 3, 'learning_rate': 0.025009678169909746, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3106974477281512, 'dropout_rate_Layer_2': 0.2568229286578258, 'dropout_rate_Layer_3': 0.39310073427517767, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0009123288355504933, 'l1_Layer_2': 0.03617358216698602, 'l1_Layer_3': 0.0017961046772080277, 'n_units_Layer_1': 255, 'n_units_Layer_2': 295, 'n_units_Layer_3': 125}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:41:14,733]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:41:15,275]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:41:21,026]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:41:22,213]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:41:28,633]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:41:30,956]\u001b[0m Trial 173 finished with value: 13.728507730574583 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034867031795407385, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.253718076018221, 'dropout_rate_Layer_2': 0.05683855065212238, 'dropout_rate_Layer_3': 0.03360601010512281, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.569465436916551e-05, 'l1_Layer_2': 3.0050858301409734e-05, 'l1_Layer_3': 0.002030158304633509, 'n_units_Layer_1': 210, 'n_units_Layer_2': 130, 'n_units_Layer_3': 125}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.73 | sMAPE for Validation Set is: 14.48% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 36.44 | sMAPE for Test Set is: 13.95% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:41:39,008]\u001b[0m Trial 178 finished with value: 71.08924074505073 and parameters: {'n_hidden': 4, 'learning_rate': 0.06756656245460646, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30118520209025373, 'dropout_rate_Layer_2': 0.08265145234139828, 'dropout_rate_Layer_3': 0.3459974795989347, 'dropout_rate_Layer_4': 0.3982639055006998, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0001356379420874999, 'l1_Layer_2': 0.0005385440756626087, 'l1_Layer_3': 3.019606556679037e-05, 'l1_Layer_4': 0.027575329093178464, 'n_units_Layer_1': 260, 'n_units_Layer_2': 300, 'n_units_Layer_3': 140, 'n_units_Layer_4': 135}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 71.09 | sMAPE for Validation Set is: 67.18% | rMAE for Validation Set is: 3.38\n",
      "MAE for Test Set is: 236.93 | sMAPE for Test Set is: 135.11% | rMAE for Test Set is: 3.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:41:40,539]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:41:44,458]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:41:50,013]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:41:56,921]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:42:00,989]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:42:03,921]\u001b[0m Trial 176 finished with value: 60.678077006819535 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027988642019644468, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24747325087507432, 'dropout_rate_Layer_2': 0.15748892704924577, 'dropout_rate_Layer_3': 0.2657677205541207, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 6.650873874222372e-05, 'l1_Layer_2': 3.9984507866389475e-05, 'l1_Layer_3': 0.000891293163359967, 'n_units_Layer_1': 95, 'n_units_Layer_2': 215, 'n_units_Layer_3': 235}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 60.68 | sMAPE for Validation Set is: 51.32% | rMAE for Validation Set is: 2.88\n",
      "MAE for Test Set is: 222.18 | sMAPE for Test Set is: 119.65% | rMAE for Test Set is: 3.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:42:08,547]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:42:09,538]\u001b[0m Trial 170 finished with value: 40.20151123339016 and parameters: {'n_hidden': 4, 'learning_rate': 0.012996320281463927, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36391153831225564, 'dropout_rate_Layer_2': 0.3752466671701854, 'dropout_rate_Layer_3': 0.11535395172564095, 'dropout_rate_Layer_4': 0.3011807460353625, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.205009251101525e-05, 'l1_Layer_2': 2.8151540655898854e-05, 'l1_Layer_3': 0.0031510591862949212, 'l1_Layer_4': 1.6844849560795197e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 280, 'n_units_Layer_3': 80, 'n_units_Layer_4': 215}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 40.20 | sMAPE for Validation Set is: 31.68% | rMAE for Validation Set is: 1.91\n",
      "MAE for Test Set is: 159.27 | sMAPE for Test Set is: 70.02% | rMAE for Test Set is: 2.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:42:14,181]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:42:19,959]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:42:22,907]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:42:23,581]\u001b[0m Trial 183 finished with value: 57.677976807446896 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034312101566926555, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22179055053026492, 'dropout_rate_Layer_2': 0.15620988151281426, 'dropout_rate_Layer_3': 0.25754751841257995, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 7.042359796724489e-05, 'l1_Layer_2': 1.3063340488041633e-05, 'l1_Layer_3': 0.0008784330528260998, 'n_units_Layer_1': 95, 'n_units_Layer_2': 50, 'n_units_Layer_3': 230}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.68 | sMAPE for Validation Set is: 47.15% | rMAE for Validation Set is: 2.74\n",
      "MAE for Test Set is: 217.50 | sMAPE for Test Set is: 115.10% | rMAE for Test Set is: 3.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:42:29,088]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:42:29,242]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:42:34,972]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:42:39,550]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:42:41,715]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:42:54,260]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:42:58,353]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:42:58,866]\u001b[0m Trial 197 finished with value: 49.388827232302226 and parameters: {'n_hidden': 4, 'learning_rate': 0.012783688224973425, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36844346458148014, 'dropout_rate_Layer_2': 0.3720065788182274, 'dropout_rate_Layer_3': 0.09574003972672819, 'dropout_rate_Layer_4': 0.26859673736082706, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.3763044198033545e-05, 'l1_Layer_2': 8.167762461327997e-05, 'l1_Layer_3': 0.0033824671230597257, 'l1_Layer_4': 3.82824315145683e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 270, 'n_units_Layer_3': 70, 'n_units_Layer_4': 225}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.39 | sMAPE for Validation Set is: 39.63% | rMAE for Validation Set is: 2.35\n",
      "MAE for Test Set is: 184.09 | sMAPE for Test Set is: 86.80% | rMAE for Test Set is: 2.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:43:03,223]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:43:10,956]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:43:12,562]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:43:16,307]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:43:16,809]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:43:20,229]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:43:20,491]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:43:25,026]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:43:25,200]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:43:29,897]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:43:32,261]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:43:35,360]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:43:37,267]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:43:40,683]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:43:42,470]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:43:46,392]\u001b[0m Trial 208 finished with value: 51.01363388788267 and parameters: {'n_hidden': 4, 'learning_rate': 0.02467763363122006, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38630723373556547, 'dropout_rate_Layer_2': 0.07525422384057553, 'dropout_rate_Layer_3': 0.26188336218943387, 'dropout_rate_Layer_4': 0.3548466290311082, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.8722457705932544e-05, 'l1_Layer_2': 2.7381336245133395e-05, 'l1_Layer_3': 0.014221377493766903, 'l1_Layer_4': 5.694856053566757e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 265, 'n_units_Layer_3': 50, 'n_units_Layer_4': 220}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.01 | sMAPE for Validation Set is: 44.59% | rMAE for Validation Set is: 2.42\n",
      "MAE for Test Set is: 174.47 | sMAPE for Test Set is: 81.05% | rMAE for Test Set is: 2.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:43:51,791]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:43:55,613]\u001b[0m Trial 206 finished with value: 14.341895617133412 and parameters: {'n_hidden': 3, 'learning_rate': 0.0049974663807791355, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11423675979356829, 'dropout_rate_Layer_2': 0.10038881212663478, 'dropout_rate_Layer_3': 0.14132337245832613, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0097401342670376e-05, 'l1_Layer_2': 0.005542889280865706, 'l1_Layer_3': 0.002034508243713841, 'n_units_Layer_1': 75, 'n_units_Layer_2': 300, 'n_units_Layer_3': 255}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.34 | sMAPE for Validation Set is: 14.47% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 40.53 | sMAPE for Test Set is: 15.68% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:43:59,554]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:44:02,238]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:44:02,607]\u001b[0m Trial 215 finished with value: 15.134677066696424 and parameters: {'n_hidden': 3, 'learning_rate': 0.027285690720217713, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0823840640414942, 'dropout_rate_Layer_2': 0.24898768191961673, 'dropout_rate_Layer_3': 0.14420903308294622, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.78856446025278e-05, 'l1_Layer_2': 0.00586219515926133, 'l1_Layer_3': 0.0021093083859559793, 'n_units_Layer_1': 75, 'n_units_Layer_2': 255, 'n_units_Layer_3': 255}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.13 | sMAPE for Validation Set is: 14.65% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 40.86 | sMAPE for Test Set is: 15.88% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:44:03,597]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:44:10,551]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:44:15,216]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:44:23,742]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:44:24,340]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.41 | sMAPE for Validation Set is: 44.09% | rMAE for Validation Set is: 2.58\n",
      "MAE for Test Set is: 204.68 | sMAPE for Test Set is: 103.50% | rMAE for Test Set is: 3.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:44:29,182]\u001b[0m Trial 222 finished with value: 54.405976591651886 and parameters: {'n_hidden': 4, 'learning_rate': 0.025971229071013822, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3869480251620408, 'dropout_rate_Layer_2': 0.007005203939701001, 'dropout_rate_Layer_3': 0.2719333335087564, 'dropout_rate_Layer_4': 0.3358232882414165, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.7746407724511644e-05, 'l1_Layer_2': 2.7747921375428712e-05, 'l1_Layer_3': 0.0050522600211741365, 'l1_Layer_4': 0.00013542119213530912, 'n_units_Layer_1': 295, 'n_units_Layer_2': 275, 'n_units_Layer_3': 60, 'n_units_Layer_4': 165}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:44:33,512]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:44:35,448]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:44:39,782]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:44:47,471]\u001b[0m Trial 226 finished with value: 16.181981634774022 and parameters: {'n_hidden': 3, 'learning_rate': 0.02626465998027861, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0577355025893275, 'dropout_rate_Layer_2': 0.10297068777812157, 'dropout_rate_Layer_3': 0.14149396303180725, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.1184967374213116e-05, 'l1_Layer_2': 0.006169360986679304, 'l1_Layer_3': 0.002426610314167599, 'n_units_Layer_1': 80, 'n_units_Layer_2': 295, 'n_units_Layer_3': 205}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.18 | sMAPE for Validation Set is: 15.76% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 44.30 | sMAPE for Test Set is: 17.59% | rMAE for Test Set is: 0.70\n",
      "MAE for Validation Set is: 13.74 | sMAPE for Validation Set is: 14.31% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 39.57 | sMAPE for Test Set is: 14.82% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:44:47,600]\u001b[0m Trial 220 finished with value: 13.73536103965184 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014064520144206091, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11934590910995324, 'dropout_rate_Layer_2': 0.20815577218422998, 'dropout_rate_Layer_3': 0.07701685861996689, 'dropout_rate_Layer_4': 0.1502981063703693, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 8.410414385519569e-05, 'l1_Layer_2': 0.00030797445316626274, 'l1_Layer_3': 1.0556869821521444e-05, 'l1_Layer_4': 0.002042469350156655, 'n_units_Layer_1': 280, 'n_units_Layer_2': 210, 'n_units_Layer_3': 300, 'n_units_Layer_4': 205}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:44:52,653]\u001b[0m Trial 229 finished with value: 48.27844184141917 and parameters: {'n_hidden': 4, 'learning_rate': 0.01787434984575093, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3097130178759389, 'dropout_rate_Layer_2': 0.04799988592940675, 'dropout_rate_Layer_3': 0.11902228966115119, 'dropout_rate_Layer_4': 0.3598670680739061, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.7935999050698242e-05, 'l1_Layer_2': 4.423826934621578e-05, 'l1_Layer_3': 0.0004972673275144651, 'l1_Layer_4': 5.732568147312332e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 225, 'n_units_Layer_3': 70, 'n_units_Layer_4': 210}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 48.28 | sMAPE for Validation Set is: 44.24% | rMAE for Validation Set is: 2.29\n",
      "MAE for Test Set is: 168.30 | sMAPE for Test Set is: 76.08% | rMAE for Test Set is: 2.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:44:55,800]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:44:56,072]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.69 | sMAPE for Validation Set is: 14.50% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 38.86 | sMAPE for Test Set is: 14.90% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:44:59,261]\u001b[0m Trial 230 finished with value: 13.68890591848718 and parameters: {'n_hidden': 3, 'learning_rate': 0.003459545402440479, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27148651742318564, 'dropout_rate_Layer_2': 0.1675614783664033, 'dropout_rate_Layer_3': 0.36053770246429906, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002838486012982749, 'l1_Layer_2': 9.129978630323069e-05, 'l1_Layer_3': 0.03607715893081267, 'n_units_Layer_1': 295, 'n_units_Layer_2': 160, 'n_units_Layer_3': 285}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:45:06,473]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:45:12,593]\u001b[0m Trial 233 finished with value: 18.165464801353227 and parameters: {'n_hidden': 3, 'learning_rate': 0.0060651742879096315, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007678696931435733, 'dropout_rate_Layer_2': 0.10670043921647415, 'dropout_rate_Layer_3': 0.06458234898112983, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010293181529558912, 'l1_Layer_2': 0.021388602942695123, 'l1_Layer_3': 0.00273310549913679, 'n_units_Layer_1': 75, 'n_units_Layer_2': 295, 'n_units_Layer_3': 250}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.17 | sMAPE for Validation Set is: 17.23% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 55.63 | sMAPE for Test Set is: 20.08% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:45:17,072]\u001b[0m Trial 235 finished with value: 48.479628770774035 and parameters: {'n_hidden': 4, 'learning_rate': 0.021368598206577955, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2947031036354488, 'dropout_rate_Layer_2': 0.02286570745394692, 'dropout_rate_Layer_3': 0.040199837372129565, 'dropout_rate_Layer_4': 0.35397017211709686, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.8345411356512057e-05, 'l1_Layer_2': 2.9989099679221034e-05, 'l1_Layer_3': 0.00029392241809699096, 'l1_Layer_4': 7.333892599605667e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 225, 'n_units_Layer_3': 75, 'n_units_Layer_4': 190}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 48.48 | sMAPE for Validation Set is: 43.79% | rMAE for Validation Set is: 2.30\n",
      "MAE for Test Set is: 141.26 | sMAPE for Test Set is: 58.25% | rMAE for Test Set is: 2.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:45:17,599]\u001b[0m Trial 234 finished with value: 49.8055050006112 and parameters: {'n_hidden': 4, 'learning_rate': 0.015067743778720919, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14328819437881818, 'dropout_rate_Layer_2': 0.0801580531681941, 'dropout_rate_Layer_3': 0.2277773637449141, 'dropout_rate_Layer_4': 0.36618946325580154, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.8912044647978932e-05, 'l1_Layer_2': 3.0668931868044025e-05, 'l1_Layer_3': 0.0003787430362533714, 'l1_Layer_4': 6.345605365809481e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 230, 'n_units_Layer_3': 75, 'n_units_Layer_4': 190}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.81 | sMAPE for Validation Set is: 39.27% | rMAE for Validation Set is: 2.36\n",
      "MAE for Test Set is: 194.39 | sMAPE for Test Set is: 94.85% | rMAE for Test Set is: 3.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:45:24,407]\u001b[0m Trial 237 finished with value: 44.532319994763064 and parameters: {'n_hidden': 4, 'learning_rate': 0.022112783596434416, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29555129770934274, 'dropout_rate_Layer_2': 0.019476394190869103, 'dropout_rate_Layer_3': 0.25180265081690306, 'dropout_rate_Layer_4': 0.38205608280131914, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.9040726088561703e-05, 'l1_Layer_2': 1.696225822541181e-05, 'l1_Layer_3': 0.00042868125735457074, 'l1_Layer_4': 6.725165104035674e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 225, 'n_units_Layer_3': 75, 'n_units_Layer_4': 220}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.53 | sMAPE for Validation Set is: 34.29% | rMAE for Validation Set is: 2.11\n",
      "MAE for Test Set is: 178.89 | sMAPE for Test Set is: 82.89% | rMAE for Test Set is: 2.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:45:26,125]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:45:32,935]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:45:37,113]\u001b[0m Trial 238 finished with value: 15.221741958561333 and parameters: {'n_hidden': 3, 'learning_rate': 0.011526308106225503, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10124404886510498, 'dropout_rate_Layer_2': 0.07014850796658248, 'dropout_rate_Layer_3': 0.13312540022484856, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.2193845287422096e-05, 'l1_Layer_2': 0.010173020108224316, 'l1_Layer_3': 0.007685242325372137, 'n_units_Layer_1': 180, 'n_units_Layer_2': 265, 'n_units_Layer_3': 205}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.22 | sMAPE for Validation Set is: 15.47% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 43.56 | sMAPE for Test Set is: 16.97% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:45:37,946]\u001b[0m Trial 240 finished with value: 50.08646344549468 and parameters: {'n_hidden': 4, 'learning_rate': 0.015351696089729056, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3601980121982806, 'dropout_rate_Layer_2': 0.04059892257544068, 'dropout_rate_Layer_3': 0.040267875004676726, 'dropout_rate_Layer_4': 0.36436885805225366, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.981137601566543e-05, 'l1_Layer_2': 1.8998295824948203e-05, 'l1_Layer_3': 0.0002745673374013691, 'l1_Layer_4': 6.3946224956955e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 230, 'n_units_Layer_3': 75, 'n_units_Layer_4': 205}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.09 | sMAPE for Validation Set is: 39.97% | rMAE for Validation Set is: 2.38\n",
      "MAE for Test Set is: 189.46 | sMAPE for Test Set is: 90.81% | rMAE for Test Set is: 2.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:45:39,078]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:45:39,639]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:45:42,202]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:45:48,990]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:45:51,198]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:45:55,501]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:46:05,417]\u001b[0m Trial 250 finished with value: 46.02741311550807 and parameters: {'n_hidden': 4, 'learning_rate': 0.01743946839082244, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1063213880893484, 'dropout_rate_Layer_2': 0.023756056352739183, 'dropout_rate_Layer_3': 0.04608396189399459, 'dropout_rate_Layer_4': 0.367335912723061, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.917132469987546e-05, 'l1_Layer_2': 3.204183643062471e-05, 'l1_Layer_3': 0.0002420862725224069, 'l1_Layer_4': 7.51962802263897e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 225, 'n_units_Layer_3': 65, 'n_units_Layer_4': 215}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.03 | sMAPE for Validation Set is: 37.35% | rMAE for Validation Set is: 2.19\n",
      "MAE for Test Set is: 173.32 | sMAPE for Test Set is: 79.33% | rMAE for Test Set is: 2.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:46:10,211]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:46:13,075]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:46:15,118]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:46:15,884]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:46:22,472]\u001b[0m Trial 252 finished with value: 12.731481715429652 and parameters: {'n_hidden': 3, 'learning_rate': 0.01345491292553843, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1170440075766232, 'dropout_rate_Layer_2': 0.026323098018272123, 'dropout_rate_Layer_3': 0.0889240158474075, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001447825921689439, 'l1_Layer_2': 0.015971963750452442, 'l1_Layer_3': 0.006058452102232698, 'n_units_Layer_1': 175, 'n_units_Layer_2': 255, 'n_units_Layer_3': 270}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.73 | sMAPE for Validation Set is: 13.01% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 34.76 | sMAPE for Test Set is: 13.78% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:46:22,931]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:46:29,927]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:46:30,918]\u001b[0m Trial 254 finished with value: 49.92140183957955 and parameters: {'n_hidden': 4, 'learning_rate': 0.01829740525529139, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12059921820463324, 'dropout_rate_Layer_2': 0.023281910268600832, 'dropout_rate_Layer_3': 0.053192948513830385, 'dropout_rate_Layer_4': 0.37062626070085974, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.000748725035649e-05, 'l1_Layer_2': 2.3829828351970213e-05, 'l1_Layer_3': 0.0002539704232221827, 'l1_Layer_4': 5.369628355294794e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 230, 'n_units_Layer_3': 65, 'n_units_Layer_4': 190}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.92 | sMAPE for Validation Set is: 39.67% | rMAE for Validation Set is: 2.37\n",
      "MAE for Test Set is: 192.04 | sMAPE for Test Set is: 93.04% | rMAE for Test Set is: 3.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:46:36,563]\u001b[0m Trial 256 finished with value: 45.60536929280232 and parameters: {'n_hidden': 4, 'learning_rate': 0.018548249018938777, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10196650664257788, 'dropout_rate_Layer_2': 0.02281701530146227, 'dropout_rate_Layer_3': 0.061280651066199204, 'dropout_rate_Layer_4': 0.3687897603913797, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.9416624952872396e-05, 'l1_Layer_2': 2.3110806553628102e-05, 'l1_Layer_3': 0.0003174252859731574, 'l1_Layer_4': 6.548215119067167e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 230, 'n_units_Layer_3': 60, 'n_units_Layer_4': 190}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.61 | sMAPE for Validation Set is: 36.27% | rMAE for Validation Set is: 2.17\n",
      "MAE for Test Set is: 172.86 | sMAPE for Test Set is: 78.57% | rMAE for Test Set is: 2.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:46:38,544]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:46:43,240]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:46:46,360]\u001b[0m Trial 257 finished with value: 14.11989362433414 and parameters: {'n_hidden': 4, 'learning_rate': 0.007294989152764849, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11055182498934846, 'dropout_rate_Layer_2': 0.2693345589677387, 'dropout_rate_Layer_3': 0.25036844452738877, 'dropout_rate_Layer_4': 0.23727489366716925, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0017007775653467777, 'l1_Layer_2': 1.1768876419397836e-05, 'l1_Layer_3': 0.00010184955557010786, 'l1_Layer_4': 0.0074129786732334115, 'n_units_Layer_1': 225, 'n_units_Layer_2': 105, 'n_units_Layer_3': 300, 'n_units_Layer_4': 135}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.12 | sMAPE for Validation Set is: 15.20% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 40.54 | sMAPE for Test Set is: 15.37% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:46:50,910]\u001b[0m Trial 259 finished with value: 44.54823184723378 and parameters: {'n_hidden': 4, 'learning_rate': 0.022496113156475695, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0895256167836018, 'dropout_rate_Layer_2': 0.043588444825689146, 'dropout_rate_Layer_3': 0.13732433063558164, 'dropout_rate_Layer_4': 0.3351269418109561, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.4422711206859852e-05, 'l1_Layer_2': 1.4629991088705228e-05, 'l1_Layer_3': 0.0002083900882187053, 'l1_Layer_4': 7.088151247575111e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 240, 'n_units_Layer_3': 55, 'n_units_Layer_4': 195}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.55 | sMAPE for Validation Set is: 52.11% | rMAE for Validation Set is: 2.12\n",
      "MAE for Test Set is: 129.88 | sMAPE for Test Set is: 51.35% | rMAE for Test Set is: 2.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:46:54,604]\u001b[0m Trial 261 finished with value: 46.382975352947604 and parameters: {'n_hidden': 4, 'learning_rate': 0.021503556522891386, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09355941296189886, 'dropout_rate_Layer_2': 0.04315782598727415, 'dropout_rate_Layer_3': 0.04336681121049685, 'dropout_rate_Layer_4': 0.3672778901885609, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.3185776674185955e-05, 'l1_Layer_2': 1.4397042171750268e-05, 'l1_Layer_3': 0.00019729811929574312, 'l1_Layer_4': 6.961553586516729e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 240, 'n_units_Layer_3': 80, 'n_units_Layer_4': 190}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.38 | sMAPE for Validation Set is: 38.76% | rMAE for Validation Set is: 2.20\n",
      "MAE for Test Set is: 168.29 | sMAPE for Test Set is: 75.48% | rMAE for Test Set is: 2.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:46:55,635]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:46:57,246]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:47:00,685]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:47:06,029]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:47:09,370]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:47:13,870]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:47:14,135]\u001b[0m Trial 267 finished with value: 13.286130291452176 and parameters: {'n_hidden': 3, 'learning_rate': 0.005096092098993599, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25270706169532975, 'dropout_rate_Layer_2': 0.09860755635660468, 'dropout_rate_Layer_3': 0.3914618779854886, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0033159175814350024, 'l1_Layer_2': 5.2965641612129046e-05, 'l1_Layer_3': 0.03131905715965538, 'n_units_Layer_1': 295, 'n_units_Layer_2': 115, 'n_units_Layer_3': 285}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.29 | sMAPE for Validation Set is: 13.97% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 38.78 | sMAPE for Test Set is: 14.78% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:47:20,197]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.25 | sMAPE for Validation Set is: 14.43% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 40.41 | sMAPE for Test Set is: 15.57% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:47:21,979]\u001b[0m Trial 263 finished with value: 14.249497699604353 and parameters: {'n_hidden': 4, 'learning_rate': 0.008230495005547523, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12388389554350665, 'dropout_rate_Layer_2': 0.25083718523684395, 'dropout_rate_Layer_3': 0.24269273670030284, 'dropout_rate_Layer_4': 0.2199886456160805, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0022581353900948094, 'l1_Layer_2': 0.00013657315789565035, 'l1_Layer_3': 6.626947522717487e-05, 'l1_Layer_4': 0.008908030809688322, 'n_units_Layer_1': 225, 'n_units_Layer_2': 95, 'n_units_Layer_3': 300, 'n_units_Layer_4': 135}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:47:25,998]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:47:26,286]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:47:28,355]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:47:33,611]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:47:34,047]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:47:35,069]\u001b[0m Trial 268 finished with value: 14.002821798138115 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017408687997029662, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3386063843877748, 'dropout_rate_Layer_2': 0.17837292110737454, 'dropout_rate_Layer_3': 0.0928318699034521, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.109447729341632e-05, 'l1_Layer_2': 0.0001491086906740764, 'l1_Layer_3': 0.00445249461030272, 'n_units_Layer_1': 170, 'n_units_Layer_2': 180, 'n_units_Layer_3': 230}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.00 | sMAPE for Validation Set is: 14.40% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 40.65 | sMAPE for Test Set is: 15.32% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:47:41,163]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:47:42,376]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:47:46,087]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:47:47,845]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:47:51,248]\u001b[0m Trial 276 finished with value: 12.58940048382935 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030116039925338497, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29690154117049705, 'dropout_rate_Layer_2': 0.03925412040052709, 'dropout_rate_Layer_3': 0.3743859743598319, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001990835868626502, 'l1_Layer_2': 5.371345337970986e-05, 'l1_Layer_3': 0.026419735538909528, 'n_units_Layer_1': 295, 'n_units_Layer_2': 105, 'n_units_Layer_3': 65}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.59 | sMAPE for Validation Set is: 13.01% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 33.21 | sMAPE for Test Set is: 13.11% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:47:53,469]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:47:54,216]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:48:00,218]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:48:02,885]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 48.02 | sMAPE for Validation Set is: 40.46% | rMAE for Validation Set is: 2.28\n",
      "MAE for Test Set is: 151.42 | sMAPE for Test Set is: 64.14% | rMAE for Test Set is: 2.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:48:04,554]\u001b[0m Trial 283 finished with value: 48.0151829478744 and parameters: {'n_hidden': 4, 'learning_rate': 0.018733449201390785, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07898108883538453, 'dropout_rate_Layer_2': 0.06111059597124491, 'dropout_rate_Layer_3': 0.07792589194772728, 'dropout_rate_Layer_4': 0.3833717395148102, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.605532504557418e-05, 'l1_Layer_2': 2.9742637868243428e-05, 'l1_Layer_3': 0.0004457239234438145, 'l1_Layer_4': 4.096348323971542e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 240, 'n_units_Layer_3': 55, 'n_units_Layer_4': 190}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:48:05,840]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:48:09,006]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:48:13,408]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:48:19,134]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:48:24,511]\u001b[0m Trial 292 finished with value: 38.142089477233604 and parameters: {'n_hidden': 4, 'learning_rate': 0.022651183702930438, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10310232899065246, 'dropout_rate_Layer_2': 0.08553034802172071, 'dropout_rate_Layer_3': 0.09807332545016821, 'dropout_rate_Layer_4': 0.3821766560088066, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.4326415281523026e-05, 'l1_Layer_2': 7.114877748963393e-05, 'l1_Layer_3': 0.00018579660102173526, 'l1_Layer_4': 2.9463033242509693e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 245, 'n_units_Layer_3': 65, 'n_units_Layer_4': 180}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 38.14 | sMAPE for Validation Set is: 31.93% | rMAE for Validation Set is: 1.81\n",
      "MAE for Test Set is: 137.50 | sMAPE for Test Set is: 56.99% | rMAE for Test Set is: 2.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:48:27,225]\u001b[0m Trial 293 finished with value: 45.609438907648375 and parameters: {'n_hidden': 4, 'learning_rate': 0.021520715488232815, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06644976902729519, 'dropout_rate_Layer_2': 0.010917527135973468, 'dropout_rate_Layer_3': 0.09525161428154263, 'dropout_rate_Layer_4': 0.3870396271480021, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.262019851104992e-05, 'l1_Layer_2': 4.952425744742203e-05, 'l1_Layer_3': 0.0002078669072020611, 'l1_Layer_4': 1.3178611615541673e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 245, 'n_units_Layer_3': 65, 'n_units_Layer_4': 185}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.61 | sMAPE for Validation Set is: 38.56% | rMAE for Validation Set is: 2.17\n",
      "MAE for Test Set is: 144.82 | sMAPE for Test Set is: 62.22% | rMAE for Test Set is: 2.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:48:30,056]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:48:30,444]\u001b[0m Trial 294 finished with value: 43.05000446852913 and parameters: {'n_hidden': 4, 'learning_rate': 0.022046353668950365, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10098923812178877, 'dropout_rate_Layer_2': 0.08218762779690048, 'dropout_rate_Layer_3': 0.06744327098445782, 'dropout_rate_Layer_4': 0.391066574917422, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.120319089239894e-05, 'l1_Layer_2': 4.7666556063830575e-05, 'l1_Layer_3': 0.00022877681441130647, 'l1_Layer_4': 8.43477285468734e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 230, 'n_units_Layer_3': 60, 'n_units_Layer_4': 205}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.05 | sMAPE for Validation Set is: 39.01% | rMAE for Validation Set is: 2.04\n",
      "MAE for Test Set is: 151.88 | sMAPE for Test Set is: 65.19% | rMAE for Test Set is: 2.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:48:32,198]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:48:37,866]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:48:38,455]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:48:39,024]\u001b[0m Trial 295 finished with value: 47.694972001630504 and parameters: {'n_hidden': 4, 'learning_rate': 0.020504674735881058, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10420866701681188, 'dropout_rate_Layer_2': 0.08676105284565952, 'dropout_rate_Layer_3': 0.07002687869643401, 'dropout_rate_Layer_4': 0.37900175548012643, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.241509599881409e-05, 'l1_Layer_2': 2.5776066256439525e-05, 'l1_Layer_3': 0.00020424720126081263, 'l1_Layer_4': 8.46333486411382e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 230, 'n_units_Layer_3': 85, 'n_units_Layer_4': 180}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.69 | sMAPE for Validation Set is: 39.31% | rMAE for Validation Set is: 2.26\n",
      "MAE for Test Set is: 167.25 | sMAPE for Test Set is: 74.77% | rMAE for Test Set is: 2.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:48:40,568]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:48:47,677]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:48:47,979]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:48:52,956]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:48:56,190]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:48:59,333]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:49:05,177]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:49:08,391]\u001b[0m Trial 306 finished with value: 48.02275823548907 and parameters: {'n_hidden': 4, 'learning_rate': 0.020035576407373915, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07949544197840253, 'dropout_rate_Layer_2': 0.07535744662219904, 'dropout_rate_Layer_3': 0.06992741305141201, 'dropout_rate_Layer_4': 0.35481044425273994, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.3462586253813825e-05, 'l1_Layer_2': 2.8213525812972758e-05, 'l1_Layer_3': 0.003150932040174256, 'l1_Layer_4': 8.671037982046894e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 220, 'n_units_Layer_3': 70, 'n_units_Layer_4': 185}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 48.02 | sMAPE for Validation Set is: 39.77% | rMAE for Validation Set is: 2.28\n",
      "MAE for Test Set is: 166.82 | sMAPE for Test Set is: 74.83% | rMAE for Test Set is: 2.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:49:08,677]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:49:12,904]\u001b[0m Trial 307 finished with value: 47.87048804094866 and parameters: {'n_hidden': 4, 'learning_rate': 0.02013915819402413, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0770952393012433, 'dropout_rate_Layer_2': 0.005782509306690945, 'dropout_rate_Layer_3': 0.06660640206869474, 'dropout_rate_Layer_4': 0.3722494930474309, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.3429240403240726e-05, 'l1_Layer_2': 3.120059398581382e-05, 'l1_Layer_3': 0.00039375335620566305, 'l1_Layer_4': 0.00011263265846489683, 'n_units_Layer_1': 295, 'n_units_Layer_2': 220, 'n_units_Layer_3': 70, 'n_units_Layer_4': 175}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.87 | sMAPE for Validation Set is: 41.12% | rMAE for Validation Set is: 2.27\n",
      "MAE for Test Set is: 169.79 | sMAPE for Test Set is: 76.40% | rMAE for Test Set is: 2.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:49:13,931]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:49:19,402]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:49:19,607]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:49:19,801]\u001b[0m Trial 309 finished with value: 46.27183946572507 and parameters: {'n_hidden': 4, 'learning_rate': 0.020328598563731447, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11016010132057681, 'dropout_rate_Layer_2': 0.06955856528079844, 'dropout_rate_Layer_3': 0.09537446840798469, 'dropout_rate_Layer_4': 0.38575053132334314, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.277351834924464e-05, 'l1_Layer_2': 3.0429732472408e-05, 'l1_Layer_3': 0.0003967400783310451, 'l1_Layer_4': 8.451059478409172e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 220, 'n_units_Layer_3': 70, 'n_units_Layer_4': 175}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.27 | sMAPE for Validation Set is: 38.95% | rMAE for Validation Set is: 2.20\n",
      "MAE for Test Set is: 171.57 | sMAPE for Test Set is: 77.38% | rMAE for Test Set is: 2.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:49:28,489]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:49:31,880]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:49:39,836]\u001b[0m Trial 318 finished with value: 61.01875339932504 and parameters: {'n_hidden': 4, 'learning_rate': 0.00981913683492699, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18389980663042538, 'dropout_rate_Layer_2': 0.14357616344203447, 'dropout_rate_Layer_3': 0.08300483830600021, 'dropout_rate_Layer_4': 0.02749651195786118, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.000517830699514589, 'l1_Layer_2': 0.0004533993221595538, 'l1_Layer_3': 0.0017625001089167484, 'l1_Layer_4': 0.005442628525938814, 'n_units_Layer_1': 180, 'n_units_Layer_2': 155, 'n_units_Layer_3': 145, 'n_units_Layer_4': 215}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:49:39,951]\u001b[0m Trial 316 finished with value: 46.77275838125934 and parameters: {'n_hidden': 4, 'learning_rate': 0.023405681041432872, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.032163971318872185, 'dropout_rate_Layer_2': 0.07060920113117548, 'dropout_rate_Layer_3': 0.07280956491818984, 'dropout_rate_Layer_4': 0.3858033265115809, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.314781560900462e-05, 'l1_Layer_2': 2.5917205975202293e-05, 'l1_Layer_3': 0.00017694129661221532, 'l1_Layer_4': 9.34143524406597e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 220, 'n_units_Layer_3': 50, 'n_units_Layer_4': 155}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 61.02 | sMAPE for Validation Set is: 51.37% | rMAE for Validation Set is: 2.90\n",
      "MAE for Test Set is: 223.45 | sMAPE for Test Set is: 120.88% | rMAE for Test Set is: 3.51\n",
      "MAE for Validation Set is: 46.77 | sMAPE for Validation Set is: 38.73% | rMAE for Validation Set is: 2.22\n",
      "MAE for Test Set is: 173.74 | sMAPE for Test Set is: 79.16% | rMAE for Test Set is: 2.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:49:44,280]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:49:47,686]\u001b[0m Trial 312 finished with value: 37.94080976310389 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005955456200680997, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009528941490527167, 'dropout_rate_Layer_2': 0.3243825672737555, 'dropout_rate_Layer_3': 0.23209539306010463, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03974816564582363, 'l1_Layer_2': 0.0004530031981643808, 'l1_Layer_3': 0.00010481547063054095, 'n_units_Layer_1': 150, 'n_units_Layer_2': 265, 'n_units_Layer_3': 80}. Best is trial 7 with value: 12.296765922478903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.94 | sMAPE for Validation Set is: 28.51% | rMAE for Validation Set is: 1.80\n",
      "MAE for Test Set is: 158.75 | sMAPE for Test Set is: 69.34% | rMAE for Test Set is: 2.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:49:48,015]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:49:53,712]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:49:55,480]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:49:59,523]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:50:02,402]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:50:03,358]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:50:09,178]\u001b[0m Trial 320 finished with value: 12.067315111506586 and parameters: {'n_hidden': 3, 'learning_rate': 0.004507135089582712, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14704480056642227, 'dropout_rate_Layer_2': 0.026176059743740647, 'dropout_rate_Layer_3': 0.06624941770663453, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013891475157174282, 'l1_Layer_2': 0.032449307607150604, 'l1_Layer_3': 0.0004304480803882838, 'n_units_Layer_1': 295, 'n_units_Layer_2': 255, 'n_units_Layer_3': 270}. Best is trial 320 with value: 12.067315111506586.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.07 | sMAPE for Validation Set is: 12.23% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 33.33 | sMAPE for Test Set is: 13.09% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:50:12,776]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:50:14,367]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:50:19,822]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:50:22,858]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:50:25,489]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:50:30,192]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:50:34,366]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:50:38,577]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:50:45,242]\u001b[0m Trial 334 finished with value: 76.17851740767837 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017758865940342727, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008444476183665195, 'dropout_rate_Layer_2': 0.22928695126991974, 'dropout_rate_Layer_3': 0.09615391903916111, 'dropout_rate_Layer_4': 0.3546441641461208, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.09186788701605501, 'l1_Layer_2': 6.934726730043955e-05, 'l1_Layer_3': 0.001151959100307415, 'l1_Layer_4': 2.1317862821191247e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 200, 'n_units_Layer_3': 285, 'n_units_Layer_4': 170}. Best is trial 320 with value: 12.067315111506586.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 76.18 | sMAPE for Validation Set is: 76.32% | rMAE for Validation Set is: 3.62\n",
      "MAE for Test Set is: 242.82 | sMAPE for Test Set is: 141.60% | rMAE for Test Set is: 3.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:50:50,315]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:51:03,374]\u001b[0m Trial 340 finished with value: 50.28102424592279 and parameters: {'n_hidden': 3, 'learning_rate': 0.02574649866152622, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.260988493498071, 'dropout_rate_Layer_2': 0.08454691085962555, 'dropout_rate_Layer_3': 0.12577939199350596, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.756746923042123e-05, 'l1_Layer_2': 1.9907609049464332e-05, 'l1_Layer_3': 0.00016785798380873377, 'n_units_Layer_1': 280, 'n_units_Layer_2': 230, 'n_units_Layer_3': 60}. Best is trial 320 with value: 12.067315111506586.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.28 | sMAPE for Validation Set is: 40.75% | rMAE for Validation Set is: 2.39\n",
      "MAE for Test Set is: 185.55 | sMAPE for Test Set is: 87.65% | rMAE for Test Set is: 2.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:51:06,863]\u001b[0m Trial 322 finished with value: 15.85249966418055 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009185637036649853, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15809821919574357, 'dropout_rate_Layer_2': 0.0007860922921260061, 'dropout_rate_Layer_3': 0.19586889078450823, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010426978592498372, 'l1_Layer_2': 0.0010091472981797064, 'l1_Layer_3': 0.009944349424592934, 'n_units_Layer_1': 255, 'n_units_Layer_2': 195, 'n_units_Layer_3': 225}. Best is trial 320 with value: 12.067315111506586.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.85 | sMAPE for Validation Set is: 16.05% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 41.99 | sMAPE for Test Set is: 16.25% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:51:08,307]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:51:14,049]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:51:18,547]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:51:20,683]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:51:24,517]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:51:26,672]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:51:31,426]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:51:32,182]\u001b[0m Trial 329 finished with value: 12.287301031482064 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008890596917945923, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16760191785778203, 'dropout_rate_Layer_2': 0.16904064023094606, 'dropout_rate_Layer_3': 0.1658946668844668, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010118348101254565, 'l1_Layer_2': 0.0008971183842684, 'l1_Layer_3': 0.005737723353092576, 'n_units_Layer_1': 300, 'n_units_Layer_2': 195, 'n_units_Layer_3': 95}. Best is trial 320 with value: 12.067315111506586.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.29 | sMAPE for Validation Set is: 13.06% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 40.89 | sMAPE for Test Set is: 14.54% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:51:38,470]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:51:43,087]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:51:47,346]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:51:51,509]\u001b[0m Trial 338 finished with value: 16.39286070531529 and parameters: {'n_hidden': 3, 'learning_rate': 0.005371852316472666, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23881364892213286, 'dropout_rate_Layer_2': 0.18153585574453385, 'dropout_rate_Layer_3': 0.19412030266511093, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.102162449905327e-05, 'l1_Layer_2': 0.02291081888391683, 'l1_Layer_3': 0.004850829731572807, 'n_units_Layer_1': 265, 'n_units_Layer_2': 195, 'n_units_Layer_3': 90}. Best is trial 320 with value: 12.067315111506586.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.39 | sMAPE for Validation Set is: 16.14% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 46.48 | sMAPE for Test Set is: 18.41% | rMAE for Test Set is: 0.73\n",
      "MAE for Validation Set is: 79.11 | sMAPE for Validation Set is: 82.16% | rMAE for Validation Set is: 3.76\n",
      "MAE for Test Set is: 245.97 | sMAPE for Test Set is: 145.28% | rMAE for Test Set is: 3.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:51:51,706]\u001b[0m Trial 348 finished with value: 79.10945240197458 and parameters: {'n_hidden': 4, 'learning_rate': 0.003257863482497242, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04785972707101119, 'dropout_rate_Layer_2': 0.3610914054764169, 'dropout_rate_Layer_3': 0.20618112872447192, 'dropout_rate_Layer_4': 0.03090847258791638, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00933277753576635, 'l1_Layer_2': 0.015656903988355064, 'l1_Layer_3': 0.00022588761664540434, 'l1_Layer_4': 3.959205007690413e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 100, 'n_units_Layer_3': 85, 'n_units_Layer_4': 145}. Best is trial 320 with value: 12.067315111506586.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:51:52,012]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:51:55,692]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:52:01,908]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:52:02,638]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:52:08,816]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:52:09,000]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:52:15,434]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:52:16,182]\u001b[0m Trial 356 finished with value: 12.607288009556532 and parameters: {'n_hidden': 3, 'learning_rate': 0.004782924710601155, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13788226529268274, 'dropout_rate_Layer_2': 0.00383172905088508, 'dropout_rate_Layer_3': 0.062061950854497824, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00043243679165941783, 'l1_Layer_2': 0.03875772309144646, 'l1_Layer_3': 0.00014448367827000423, 'n_units_Layer_1': 280, 'n_units_Layer_2': 280, 'n_units_Layer_3': 275}. Best is trial 320 with value: 12.067315111506586.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.61 | sMAPE for Validation Set is: 12.61% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 34.98 | sMAPE for Test Set is: 13.67% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:52:21,949]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:52:21,991]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:52:27,027]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:52:27,748]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:52:28,138]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:52:35,246]\u001b[0m Trial 358 finished with value: 12.871203336555865 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005985163809900843, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1357857557937419, 'dropout_rate_Layer_2': 0.0025487710367948745, 'dropout_rate_Layer_3': 0.06977667511641099, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004605891232072086, 'l1_Layer_2': 0.036445530293855846, 'l1_Layer_3': 0.0001199814589894554, 'n_units_Layer_1': 295, 'n_units_Layer_2': 275, 'n_units_Layer_3': 275}. Best is trial 320 with value: 12.067315111506586.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.87 | sMAPE for Validation Set is: 12.97% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 36.30 | sMAPE for Test Set is: 14.33% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:52:39,078]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:52:39,349]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:52:41,900]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:52:48,722]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:52:53,105]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:52:53,411]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:53:00,285]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:53:03,594]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:53:08,982]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:53:13,975]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:53:18,586]\u001b[0m Trial 376 finished with value: 12.391663109949848 and parameters: {'n_hidden': 3, 'learning_rate': 0.002755619286661873, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1609652030922113, 'dropout_rate_Layer_2': 0.17613348227570752, 'dropout_rate_Layer_3': 0.3760850614534228, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008137734531229486, 'l1_Layer_2': 0.00011080067215661327, 'l1_Layer_3': 0.00030457216716514514, 'n_units_Layer_1': 295, 'n_units_Layer_2': 125, 'n_units_Layer_3': 285}. Best is trial 320 with value: 12.067315111506586.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.39 | sMAPE for Validation Set is: 12.87% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 34.74 | sMAPE for Test Set is: 13.49% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:53:22,417]\u001b[0m Trial 370 finished with value: 48.72466801507513 and parameters: {'n_hidden': 3, 'learning_rate': 0.000579755036206789, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1314550268629273, 'dropout_rate_Layer_2': 0.39506355381248015, 'dropout_rate_Layer_3': 0.007865342633245065, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005216301914151469, 'l1_Layer_2': 0.003616939127438083, 'l1_Layer_3': 1.1764690331823164e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 55, 'n_units_Layer_3': 55}. Best is trial 320 with value: 12.067315111506586.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 48.72 | sMAPE for Validation Set is: 37.49% | rMAE for Validation Set is: 2.31\n",
      "MAE for Test Set is: 193.66 | sMAPE for Test Set is: 94.13% | rMAE for Test Set is: 3.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:53:23,077]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:53:24,730]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:53:29,732]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:53:33,114]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:53:35,677]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.59 | sMAPE for Validation Set is: 15.17% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 50.93 | sMAPE for Test Set is: 17.41% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:53:36,758]\u001b[0m Trial 379 finished with value: 15.593802360476062 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009616158111914848, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14862184276843013, 'dropout_rate_Layer_2': 0.16033402644344877, 'dropout_rate_Layer_3': 0.1282943482903453, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.448100439713032e-05, 'l1_Layer_2': 0.0007683998275185367, 'l1_Layer_3': 0.030471069624644766, 'n_units_Layer_1': 300, 'n_units_Layer_2': 270, 'n_units_Layer_3': 85}. Best is trial 320 with value: 12.067315111506586.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:53:42,673]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:53:46,185]\u001b[0m Trial 383 finished with value: 15.123541790670965 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009974282244740562, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14734327624408933, 'dropout_rate_Layer_2': 0.14760497186202307, 'dropout_rate_Layer_3': 0.11640604717902756, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.019472386474199e-05, 'l1_Layer_2': 0.0009192538249999278, 'l1_Layer_3': 0.03370518434857765, 'n_units_Layer_1': 300, 'n_units_Layer_2': 270, 'n_units_Layer_3': 90}. Best is trial 320 with value: 12.067315111506586.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.12 | sMAPE for Validation Set is: 16.71% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 41.54 | sMAPE for Test Set is: 15.15% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:53:46,395]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:53:47,059]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:53:51,373]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:53:56,179]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:53:56,328]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:53:56,857]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:54:02,719]\u001b[0m Trial 385 finished with value: 13.486789366652845 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008254947874782728, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13751765157298174, 'dropout_rate_Layer_2': 0.035129872322411104, 'dropout_rate_Layer_3': 0.06713962716246201, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0018528463767898554, 'l1_Layer_2': 0.041888914229877026, 'l1_Layer_3': 0.00013302572482907872, 'n_units_Layer_1': 295, 'n_units_Layer_2': 260, 'n_units_Layer_3': 275}. Best is trial 320 with value: 12.067315111506586.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.49 | sMAPE for Validation Set is: 13.70% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 38.24 | sMAPE for Test Set is: 15.12% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:54:05,708]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:54:06,414]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:54:10,037]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:54:13,820]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:54:14,530]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:54:18,283]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:54:22,044]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:54:25,009]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:54:25,965]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:54:29,921]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:54:32,400]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:54:33,726]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:54:36,473]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:54:41,930]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:54:46,273]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:54:50,875]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:54:53,732]\u001b[0m Trial 407 finished with value: 50.10561744060929 and parameters: {'n_hidden': 4, 'learning_rate': 0.01832207099161639, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0973988233362352, 'dropout_rate_Layer_2': 0.019548637953094132, 'dropout_rate_Layer_3': 0.04340968174671048, 'dropout_rate_Layer_4': 0.37347803546025415, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.8987869189029836e-05, 'l1_Layer_2': 2.710803344153571e-05, 'l1_Layer_3': 0.00023805860096781222, 'l1_Layer_4': 6.933288492910091e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 230, 'n_units_Layer_3': 65, 'n_units_Layer_4': 195}. Best is trial 320 with value: 12.067315111506586.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.11 | sMAPE for Validation Set is: 41.83% | rMAE for Validation Set is: 2.38\n",
      "MAE for Test Set is: 165.79 | sMAPE for Test Set is: 73.37% | rMAE for Test Set is: 2.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:54:56,508]\u001b[0m Trial 406 finished with value: 12.151922297273492 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019903672139002407, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18681459573357936, 'dropout_rate_Layer_2': 0.024303258837578598, 'dropout_rate_Layer_3': 0.0018034584241012133, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00035874636758358343, 'l1_Layer_2': 0.012530638091959569, 'l1_Layer_3': 2.5737340803727396e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 235, 'n_units_Layer_3': 295}. Best is trial 320 with value: 12.067315111506586.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.15 | sMAPE for Validation Set is: 12.45% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 34.20 | sMAPE for Test Set is: 13.33% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:55:00,344]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:55:02,493]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:55:07,735]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:55:08,009]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:55:15,079]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:55:15,699]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:55:25,909]\u001b[0m Trial 412 finished with value: 11.661750043588421 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016392590812569512, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1853123698736329, 'dropout_rate_Layer_2': 0.025856271103868983, 'dropout_rate_Layer_3': 0.0014005073594696993, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014508858823016093, 'l1_Layer_2': 0.015366460291532937, 'l1_Layer_3': 2.9321409222642493e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 235, 'n_units_Layer_3': 270}. Best is trial 412 with value: 11.661750043588421.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.66 | sMAPE for Validation Set is: 11.87% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 32.86 | sMAPE for Test Set is: 12.85% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:55:36,682]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:55:37,628]\u001b[0m Trial 408 finished with value: 12.084957795001051 and parameters: {'n_hidden': 3, 'learning_rate': 0.002048884494862863, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18961774243658355, 'dropout_rate_Layer_2': 0.22093329364350853, 'dropout_rate_Layer_3': 0.23237121261291743, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006817119440064816, 'l1_Layer_2': 1.8897434527294028e-05, 'l1_Layer_3': 0.0021091164589523677, 'n_units_Layer_1': 170, 'n_units_Layer_2': 165, 'n_units_Layer_3': 270}. Best is trial 412 with value: 11.661750043588421.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.08 | sMAPE for Validation Set is: 12.48% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 35.72 | sMAPE for Test Set is: 13.51% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:55:41,803]\u001b[0m Trial 420 finished with value: 12.493221160126799 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021940811174165557, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2059209113472058, 'dropout_rate_Layer_2': 0.03802080063722191, 'dropout_rate_Layer_3': 0.030629884650757964, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015519302463908114, 'l1_Layer_2': 0.02522254482084627, 'l1_Layer_3': 4.048447402174672e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 230, 'n_units_Layer_3': 270}. Best is trial 412 with value: 11.661750043588421.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.49 | sMAPE for Validation Set is: 12.78% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 35.37 | sMAPE for Test Set is: 13.67% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:55:45,085]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:55:48,012]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:55:50,388]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:55:54,412]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:55:58,900]\u001b[0m Trial 422 finished with value: 12.24982194105784 and parameters: {'n_hidden': 3, 'learning_rate': 0.004290337969577017, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2811801257957797, 'dropout_rate_Layer_2': 0.13757764201797723, 'dropout_rate_Layer_3': 0.38270430783170145, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0030257854902228, 'l1_Layer_2': 4.072062557748701e-05, 'l1_Layer_3': 0.00015598575096925242, 'n_units_Layer_1': 275, 'n_units_Layer_2': 160, 'n_units_Layer_3': 280}. Best is trial 412 with value: 11.661750043588421.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.25 | sMAPE for Validation Set is: 12.73% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 35.28 | sMAPE for Test Set is: 13.67% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:56:02,086]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:56:05,157]\u001b[0m Trial 421 finished with value: 12.659371389987527 and parameters: {'n_hidden': 3, 'learning_rate': 0.005023724094311081, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19739670126038122, 'dropout_rate_Layer_2': 0.22475288894602102, 'dropout_rate_Layer_3': 0.2454731896251425, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006807579470530584, 'l1_Layer_2': 1.1139032442753843e-05, 'l1_Layer_3': 0.0019093301413934712, 'n_units_Layer_1': 205, 'n_units_Layer_2': 165, 'n_units_Layer_3': 70}. Best is trial 412 with value: 11.661750043588421.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.66 | sMAPE for Validation Set is: 13.84% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 35.57 | sMAPE for Test Set is: 13.40% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:56:09,120]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:56:09,608]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:56:09,661]\u001b[0m Trial 427 finished with value: 46.2780255773572 and parameters: {'n_hidden': 4, 'learning_rate': 0.01578532252624639, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3665675093218829, 'dropout_rate_Layer_2': 0.04249769505753473, 'dropout_rate_Layer_3': 0.040669789029645353, 'dropout_rate_Layer_4': 0.3569422567901854, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.0329310204663573e-05, 'l1_Layer_2': 1.5588652683861578e-05, 'l1_Layer_3': 0.00025484604383771523, 'l1_Layer_4': 6.552221315760494e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 230, 'n_units_Layer_3': 75, 'n_units_Layer_4': 205}. Best is trial 412 with value: 11.661750043588421.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.28 | sMAPE for Validation Set is: 36.88% | rMAE for Validation Set is: 2.20\n",
      "MAE for Test Set is: 175.60 | sMAPE for Test Set is: 81.02% | rMAE for Test Set is: 2.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:56:19,308]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:56:23,693]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:56:29,463]\u001b[0m Trial 431 finished with value: 13.423513083715456 and parameters: {'n_hidden': 3, 'learning_rate': 0.002197399242629091, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2394147973398139, 'dropout_rate_Layer_2': 0.041176223639391676, 'dropout_rate_Layer_3': 0.025780231593863563, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00402931358050504, 'l1_Layer_2': 0.023975340778918393, 'l1_Layer_3': 1.1448162365286141e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 200, 'n_units_Layer_3': 165}. Best is trial 412 with value: 11.661750043588421.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.42 | sMAPE for Validation Set is: 13.45% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 37.69 | sMAPE for Test Set is: 14.76% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:56:32,373]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:56:34,814]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:56:41,526]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:56:41,550]\u001b[0m Trial 436 finished with value: 47.134747153670425 and parameters: {'n_hidden': 4, 'learning_rate': 0.022351175381178878, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09332222911618344, 'dropout_rate_Layer_2': 0.07608752942542141, 'dropout_rate_Layer_3': 0.07472918096511025, 'dropout_rate_Layer_4': 0.35900050581361287, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.6061901966815294e-05, 'l1_Layer_2': 2.528739735319002e-05, 'l1_Layer_3': 0.0004079047002041794, 'l1_Layer_4': 8.437844832312501e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 230, 'n_units_Layer_3': 50, 'n_units_Layer_4': 215}. Best is trial 412 with value: 11.661750043588421.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.13 | sMAPE for Validation Set is: 37.12% | rMAE for Validation Set is: 2.24\n",
      "MAE for Test Set is: 179.20 | sMAPE for Test Set is: 83.37% | rMAE for Test Set is: 2.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:56:45,218]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:56:49,850]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:56:49,924]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:56:50,043]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:56:52,041]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:56:59,142]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:57:00,284]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:57:01,679]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:57:04,141]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:57:05,518]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:57:10,151]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:57:13,829]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:57:16,187]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:57:16,619]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:57:16,943]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:57:17,353]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:57:25,860]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:57:28,474]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:57:30,791]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:57:34,567]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:57:39,240]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:57:39,613]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:57:46,667]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:57:46,859]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:57:53,675]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:57:59,311]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:58:03,147]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:58:04,708]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:58:07,232]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:58:10,419]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:58:15,039]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:58:15,504]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:58:22,951]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:58:23,131]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:58:30,830]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:58:35,358]\u001b[0m Trial 470 finished with value: 12.175386850927127 and parameters: {'n_hidden': 3, 'learning_rate': 0.001270982436305911, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20104122255005863, 'dropout_rate_Layer_2': 0.05375366891651541, 'dropout_rate_Layer_3': 0.11079340382135716, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00026577023785863104, 'l1_Layer_2': 0.026639933218694397, 'l1_Layer_3': 5.180312309755366e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 280, 'n_units_Layer_3': 265}. Best is trial 412 with value: 11.661750043588421.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.18 | sMAPE for Validation Set is: 12.43% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 33.36 | sMAPE for Test Set is: 13.07% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:58:47,744]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:58:48,551]\u001b[0m Trial 476 finished with value: 12.394053307449795 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013531668792934614, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19921160640789312, 'dropout_rate_Layer_2': 0.05312078361736788, 'dropout_rate_Layer_3': 0.016570294060828623, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002305800131671679, 'l1_Layer_2': 0.0243000947324382, 'l1_Layer_3': 5.67319865303308e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 275, 'n_units_Layer_3': 245}. Best is trial 412 with value: 11.661750043588421.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.39 | sMAPE for Validation Set is: 12.63% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 34.35 | sMAPE for Test Set is: 13.47% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:58:53,354]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:58:53,385]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:59:01,371]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:59:04,200]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:59:09,257]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:59:16,549]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:59:27,043]\u001b[0m Trial 456 finished with value: 12.356842937247492 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005010839050570392, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03497390224609706, 'dropout_rate_Layer_2': 0.12469258624129893, 'dropout_rate_Layer_3': 0.17070698751053198, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009016024338808808, 'l1_Layer_2': 0.040243401207457175, 'l1_Layer_3': 0.0005162954322382202, 'n_units_Layer_1': 155, 'n_units_Layer_2': 150, 'n_units_Layer_3': 150}. Best is trial 412 with value: 11.661750043588421.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.36 | sMAPE for Validation Set is: 12.63% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 34.81 | sMAPE for Test Set is: 13.57% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:59:31,350]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:59:36,656]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:59:41,152]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:59:48,820]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:59:53,185]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:59:57,496]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:00:00,671]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:00:04,594]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:00:09,407]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:00:10,890]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:00:15,437]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:00:19,240]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:00:27,144]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:00:33,126]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:00:35,417]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:00:35,843]\u001b[0m Trial 496 finished with value: 12.027697039440802 and parameters: {'n_hidden': 3, 'learning_rate': 0.001979699905997885, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1562215645348107, 'dropout_rate_Layer_2': 0.16316882653535672, 'dropout_rate_Layer_3': 0.3619903092084597, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009956110082750549, 'l1_Layer_2': 0.005541813003064399, 'l1_Layer_3': 0.0037415206864520175, 'n_units_Layer_1': 295, 'n_units_Layer_2': 95, 'n_units_Layer_3': 275}. Best is trial 412 with value: 11.661750043588421.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.03 | sMAPE for Validation Set is: 12.47% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 33.96 | sMAPE for Test Set is: 13.22% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:00:39,887]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:00:43,115]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:00:43,440]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:00:49,260]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:00:49,584]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:01:06,159]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:01:06,162]\u001b[0m Trial 506 finished with value: 11.940229920843683 and parameters: {'n_hidden': 3, 'learning_rate': 0.003499101318648045, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17831713482937814, 'dropout_rate_Layer_2': 0.33713971634084655, 'dropout_rate_Layer_3': 0.01731620376394851, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.7819290735528e-05, 'l1_Layer_2': 0.0025444699681916676, 'l1_Layer_3': 0.00039651248226138015, 'n_units_Layer_1': 235, 'n_units_Layer_2': 290, 'n_units_Layer_3': 215}. Best is trial 412 with value: 11.661750043588421.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.94 | sMAPE for Validation Set is: 12.10% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 32.05 | sMAPE for Test Set is: 12.52% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:01:12,477]\u001b[0m Trial 503 finished with value: 12.889092300413262 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012147348342854618, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.046606072437412514, 'dropout_rate_Layer_2': 0.20056215460785623, 'dropout_rate_Layer_3': 0.3999278736840175, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0023921111906034503, 'l1_Layer_2': 0.00516640327650279, 'l1_Layer_3': 0.0006468007505528574, 'n_units_Layer_1': 125, 'n_units_Layer_2': 150, 'n_units_Layer_3': 205}. Best is trial 412 with value: 11.661750043588421.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.89 | sMAPE for Validation Set is: 13.16% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 35.09 | sMAPE for Test Set is: 13.68% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:01:16,145]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:01:20,027]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:01:24,907]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:01:29,437]\u001b[0m Trial 509 finished with value: 43.90045415860092 and parameters: {'n_hidden': 4, 'learning_rate': 0.016911248890330955, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13196756978132404, 'dropout_rate_Layer_2': 0.069452546683472, 'dropout_rate_Layer_3': 0.02714354703044258, 'dropout_rate_Layer_4': 0.3361790511246639, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.1950361527125037e-05, 'l1_Layer_2': 5.1780516699001126e-05, 'l1_Layer_3': 0.000256141623893755, 'l1_Layer_4': 5.483378170215944e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 220, 'n_units_Layer_3': 65, 'n_units_Layer_4': 230}. Best is trial 412 with value: 11.661750043588421.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.90 | sMAPE for Validation Set is: 34.04% | rMAE for Validation Set is: 2.08\n",
      "MAE for Test Set is: 176.07 | sMAPE for Test Set is: 81.07% | rMAE for Test Set is: 2.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:01:32,572]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:01:33,648]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:01:37,492]\u001b[0m Trial 512 finished with value: 44.296734343796025 and parameters: {'n_hidden': 4, 'learning_rate': 0.022615546618419514, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07835163905445514, 'dropout_rate_Layer_2': 0.00021904560137605417, 'dropout_rate_Layer_3': 0.2128534348544822, 'dropout_rate_Layer_4': 0.33958790243519965, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.264485626746406e-05, 'l1_Layer_2': 3.2390443156842575e-05, 'l1_Layer_3': 0.004739178181300383, 'l1_Layer_4': 0.0007932329290129307, 'n_units_Layer_1': 290, 'n_units_Layer_2': 235, 'n_units_Layer_3': 65, 'n_units_Layer_4': 220}. Best is trial 412 with value: 11.661750043588421.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.30 | sMAPE for Validation Set is: 39.05% | rMAE for Validation Set is: 2.10\n",
      "MAE for Test Set is: 118.45 | sMAPE for Test Set is: 45.97% | rMAE for Test Set is: 1.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:01:42,721]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:01:45,856]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:01:48,667]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:01:49,506]\u001b[0m Trial 514 finished with value: 49.709400609485535 and parameters: {'n_hidden': 4, 'learning_rate': 0.015782696605775158, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13477109203019588, 'dropout_rate_Layer_2': 0.07127563902993886, 'dropout_rate_Layer_3': 0.11083314361228613, 'dropout_rate_Layer_4': 0.3384843916880795, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.0954543004269557e-05, 'l1_Layer_2': 1.0135459192037547e-05, 'l1_Layer_3': 0.0002714023553224464, 'l1_Layer_4': 4.5290758995560813e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 215, 'n_units_Layer_3': 60, 'n_units_Layer_4': 225}. Best is trial 412 with value: 11.661750043588421.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.71 | sMAPE for Validation Set is: 39.82% | rMAE for Validation Set is: 2.36\n",
      "MAE for Test Set is: 192.77 | sMAPE for Test Set is: 93.60% | rMAE for Test Set is: 3.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:01:50,140]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:01:55,755]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:01:58,694]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:02:01,294]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:02:07,663]\u001b[0m Trial 518 finished with value: 11.57173557284158 and parameters: {'n_hidden': 3, 'learning_rate': 0.005400199270496326, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14397120252942783, 'dropout_rate_Layer_2': 0.16263729356851148, 'dropout_rate_Layer_3': 0.3823459718104894, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0010084280723958632, 'l1_Layer_2': 0.005719232819203334, 'l1_Layer_3': 6.446140098286713e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 150, 'n_units_Layer_3': 300}. Best is trial 518 with value: 11.57173557284158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.57 | sMAPE for Validation Set is: 12.09% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 33.98 | sMAPE for Test Set is: 13.01% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:02:08,166]\u001b[0m Trial 521 finished with value: 47.75793074930402 and parameters: {'n_hidden': 4, 'learning_rate': 0.02038150557319199, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33879999028325286, 'dropout_rate_Layer_2': 0.011988363382691965, 'dropout_rate_Layer_3': 0.09341642954319697, 'dropout_rate_Layer_4': 0.3415416042643633, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.4157735161274125e-05, 'l1_Layer_2': 3.7712686968021335e-05, 'l1_Layer_3': 0.005525347024421705, 'l1_Layer_4': 3.2500398665236196e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 225, 'n_units_Layer_3': 50, 'n_units_Layer_4': 235}. Best is trial 518 with value: 11.57173557284158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.76 | sMAPE for Validation Set is: 38.96% | rMAE for Validation Set is: 2.27\n",
      "MAE for Test Set is: 179.89 | sMAPE for Test Set is: 83.95% | rMAE for Test Set is: 2.82\n",
      "MAE for Validation Set is: 49.02 | sMAPE for Validation Set is: 38.74% | rMAE for Validation Set is: 2.33\n",
      "MAE for Test Set is: 188.52 | sMAPE for Test Set is: 90.17% | rMAE for Test Set is: 2.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:02:14,053]\u001b[0m Trial 524 finished with value: 49.024538161341695 and parameters: {'n_hidden': 4, 'learning_rate': 0.02180825822225923, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38185962992790984, 'dropout_rate_Layer_2': 0.0132300725614104, 'dropout_rate_Layer_3': 0.3027534374979459, 'dropout_rate_Layer_4': 0.34721668971305214, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.4728767756233394e-05, 'l1_Layer_2': 2.7180275044273046e-05, 'l1_Layer_3': 0.004550246071393638, 'l1_Layer_4': 0.001419984403300157, 'n_units_Layer_1': 290, 'n_units_Layer_2': 245, 'n_units_Layer_3': 65, 'n_units_Layer_4': 215}. Best is trial 518 with value: 11.57173557284158.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:02:16,286]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:02:17,810]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:02:19,855]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:02:23,396]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:02:25,181]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:02:27,481]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.00 | sMAPE for Validation Set is: 11.97% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 31.65 | sMAPE for Test Set is: 12.34% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:02:30,871]\u001b[0m Trial 525 finished with value: 12.004132788176866 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023881521508159025, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19085175296068457, 'dropout_rate_Layer_2': 0.3146519332586089, 'dropout_rate_Layer_3': 0.01870111650402919, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.306967123216856e-05, 'l1_Layer_2': 0.0009190951697688647, 'l1_Layer_3': 0.00022747986661433264, 'n_units_Layer_1': 255, 'n_units_Layer_2': 265, 'n_units_Layer_3': 290}. Best is trial 518 with value: 11.57173557284158.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:02:33,667]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:02:35,869]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:02:36,856]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:02:37,792]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:02:44,058]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:02:46,713]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:02:50,348]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:02:51,124]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:02:52,009]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:02:54,431]\u001b[0m Trial 538 finished with value: 44.43937110596585 and parameters: {'n_hidden': 4, 'learning_rate': 0.025625342395103046, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33536193617267035, 'dropout_rate_Layer_2': 0.038049822657612226, 'dropout_rate_Layer_3': 0.13648829036003376, 'dropout_rate_Layer_4': 0.3310426997718898, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.3779469904913239e-05, 'l1_Layer_2': 1.4733717033589606e-05, 'l1_Layer_3': 0.003655787224350881, 'l1_Layer_4': 7.997105005052901e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 235, 'n_units_Layer_3': 50, 'n_units_Layer_4': 205}. Best is trial 518 with value: 11.57173557284158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.44 | sMAPE for Validation Set is: 37.38% | rMAE for Validation Set is: 2.11\n",
      "MAE for Test Set is: 167.74 | sMAPE for Test Set is: 75.17% | rMAE for Test Set is: 2.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:02:54,595]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:02:56,739]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:02:58,811]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:03:04,804]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:03:05,976]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:03:08,179]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:03:14,623]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:03:15,021]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:03:15,610]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:03:23,013]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:03:23,365]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:03:24,046]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:03:29,543]\u001b[0m Trial 551 finished with value: 12.30944036798104 and parameters: {'n_hidden': 3, 'learning_rate': 0.006296621241969634, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21667080364094443, 'dropout_rate_Layer_2': 0.32362563181530407, 'dropout_rate_Layer_3': 0.10877065496858088, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.895558288336841e-05, 'l1_Layer_2': 0.00021729604934392008, 'l1_Layer_3': 0.0006097123471908741, 'n_units_Layer_1': 290, 'n_units_Layer_2': 250, 'n_units_Layer_3': 160}. Best is trial 518 with value: 11.57173557284158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.31 | sMAPE for Validation Set is: 12.37% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 34.48 | sMAPE for Test Set is: 13.15% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:03:30,457]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:03:32,202]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:03:34,670]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:03:37,851]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:03:37,982]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:03:42,976]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:03:47,651]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:03:47,938]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:03:53,814]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:03:54,029]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:03:59,913]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:04:04,145]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:04:07,154]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:04:07,667]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:04:09,940]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:04:13,446]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:04:17,852]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:04:18,672]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:04:19,510]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:04:21,552]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:04:23,718]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:04:25,937]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:04:28,242]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:04:30,381]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:04:34,373]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:04:36,329]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:04:39,354]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:04:39,784]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:04:43,217]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:04:48,306]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:04:51,411]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:04:51,487]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:04:52,627]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:04:53,209]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:04:57,427]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:05:00,307]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:05:03,557]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:05:04,168]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:05:07,072]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:05:10,848]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:05:12,713]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:05:16,613]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:05:22,025]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:05:22,840]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:05:25,723]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:05:29,209]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:05:32,748]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:05:33,636]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:05:35,022]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:05:38,969]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:05:41,759]\u001b[0m Trial 599 finished with value: 12.170183391366814 and parameters: {'n_hidden': 3, 'learning_rate': 0.005593321121841792, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15892761141167472, 'dropout_rate_Layer_2': 0.010808246114793595, 'dropout_rate_Layer_3': 0.38532523950687575, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005711787283749406, 'l1_Layer_2': 0.010686477408073311, 'l1_Layer_3': 0.00015251692451712093, 'n_units_Layer_1': 265, 'n_units_Layer_2': 160, 'n_units_Layer_3': 195}. Best is trial 518 with value: 11.57173557284158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.17 | sMAPE for Validation Set is: 12.49% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 34.14 | sMAPE for Test Set is: 13.32% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:05:42,639]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:05:43,830]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:05:50,981]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:05:51,122]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:05:51,865]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:05:58,870]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:06:01,653]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:06:01,955]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:06:05,172]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:06:08,448]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:06:11,710]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:06:15,418]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:06:17,695]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:06:20,450]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:06:24,657]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:06:27,424]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:06:29,415]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:06:31,076]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:06:33,123]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:06:34,984]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:06:42,367]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:06:43,339]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:06:44,595]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:06:51,488]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:06:51,783]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:06:52,026]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:06:58,787]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:07:01,811]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:07:02,848]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:07:04,759]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:07:08,341]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:07:10,957]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.10 | sMAPE for Validation Set is: 12.48% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 33.81 | sMAPE for Test Set is: 12.97% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:07:11,548]\u001b[0m Trial 633 finished with value: 12.096469384314185 and parameters: {'n_hidden': 3, 'learning_rate': 0.008128390663500107, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2289406848395113, 'dropout_rate_Layer_2': 0.32554390611372863, 'dropout_rate_Layer_3': 0.15423642840615084, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.1940383238115066e-05, 'l1_Layer_2': 7.843052491249965e-05, 'l1_Layer_3': 3.282633436943497e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 290, 'n_units_Layer_3': 165}. Best is trial 518 with value: 11.57173557284158.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:07:11,775]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:07:13,622]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:07:23,087]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:07:24,208]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:07:28,569]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:07:34,160]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:07:34,519]\u001b[0m Trial 641 finished with value: 50.176981215733385 and parameters: {'n_hidden': 4, 'learning_rate': 0.013884401743837245, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05250869354858965, 'dropout_rate_Layer_2': 0.0005346868712140496, 'dropout_rate_Layer_3': 0.12236137685695363, 'dropout_rate_Layer_4': 0.3221431156747792, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.7519506200432143e-05, 'l1_Layer_2': 2.782417435815695e-05, 'l1_Layer_3': 0.00025068875332516255, 'l1_Layer_4': 0.00010501273051906428, 'n_units_Layer_1': 240, 'n_units_Layer_2': 230, 'n_units_Layer_3': 50, 'n_units_Layer_4': 190}. Best is trial 518 with value: 11.57173557284158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.18 | sMAPE for Validation Set is: 40.69% | rMAE for Validation Set is: 2.38\n",
      "MAE for Test Set is: 186.18 | sMAPE for Test Set is: 88.87% | rMAE for Test Set is: 2.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:07:38,904]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:07:42,975]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:07:52,056]\u001b[0m Trial 644 finished with value: 36.437550847987666 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005004415827737806, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14677214862473387, 'dropout_rate_Layer_2': 0.3957674539989094, 'dropout_rate_Layer_3': 0.008580032843190482, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0028828842620176915, 'l1_Layer_2': 0.008240047335222992, 'l1_Layer_3': 5.0516071410758094e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 250, 'n_units_Layer_3': 105}. Best is trial 518 with value: 11.57173557284158.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:07:52,192]\u001b[0m Trial 649 finished with value: 46.212288196836106 and parameters: {'n_hidden': 4, 'learning_rate': 0.01654777140275177, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31136702218075507, 'dropout_rate_Layer_2': 0.016647510683374417, 'dropout_rate_Layer_3': 0.06405361819936685, 'dropout_rate_Layer_4': 0.35687942904013586, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.37887358052424e-05, 'l1_Layer_2': 3.6696364554035175e-05, 'l1_Layer_3': 0.0001831582759163446, 'l1_Layer_4': 2.3162359273421678e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 220, 'n_units_Layer_3': 85, 'n_units_Layer_4': 230}. Best is trial 518 with value: 11.57173557284158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.44 | sMAPE for Validation Set is: 27.28% | rMAE for Validation Set is: 1.73\n",
      "MAE for Test Set is: 156.47 | sMAPE for Test Set is: 67.25% | rMAE for Test Set is: 2.46\n",
      "MAE for Validation Set is: 46.21 | sMAPE for Validation Set is: 36.53% | rMAE for Validation Set is: 2.19\n",
      "MAE for Test Set is: 180.54 | sMAPE for Test Set is: 84.05% | rMAE for Test Set is: 2.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:07:58,510]\u001b[0m Trial 651 finished with value: 47.14244220942869 and parameters: {'n_hidden': 4, 'learning_rate': 0.01641981753768292, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3737398216374053, 'dropout_rate_Layer_2': 0.01830772505748777, 'dropout_rate_Layer_3': 0.033589225973517725, 'dropout_rate_Layer_4': 0.35620052983296924, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.5665665047736952e-05, 'l1_Layer_2': 3.646931058972661e-05, 'l1_Layer_3': 0.0001275033697970617, 'l1_Layer_4': 2.425586128089986e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 220, 'n_units_Layer_3': 85, 'n_units_Layer_4': 205}. Best is trial 518 with value: 11.57173557284158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.14 | sMAPE for Validation Set is: 38.73% | rMAE for Validation Set is: 2.24\n",
      "MAE for Test Set is: 169.20 | sMAPE for Test Set is: 76.44% | rMAE for Test Set is: 2.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:08:02,352]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:08:07,430]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:08:13,010]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:08:16,133]\u001b[0m Trial 654 finished with value: 47.08641973993548 and parameters: {'n_hidden': 4, 'learning_rate': 0.016282394309151026, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37353410192428227, 'dropout_rate_Layer_2': 0.015784878769245832, 'dropout_rate_Layer_3': 0.06245367866282813, 'dropout_rate_Layer_4': 0.3369050959855009, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.494287982558727e-05, 'l1_Layer_2': 3.8011017192076836e-05, 'l1_Layer_3': 0.0001182980286510284, 'l1_Layer_4': 2.3483668108613184e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 220, 'n_units_Layer_3': 90, 'n_units_Layer_4': 230}. Best is trial 518 with value: 11.57173557284158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.09 | sMAPE for Validation Set is: 37.05% | rMAE for Validation Set is: 2.24\n",
      "MAE for Test Set is: 187.36 | sMAPE for Test Set is: 89.46% | rMAE for Test Set is: 2.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:08:23,552]\u001b[0m Trial 647 finished with value: 42.79145103490996 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007760744830596972, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15478743482313764, 'dropout_rate_Layer_2': 0.3981992230427081, 'dropout_rate_Layer_3': 0.02196214659404097, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002475267413613093, 'l1_Layer_2': 0.008093090416784167, 'l1_Layer_3': 4.8980533651283925e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 260, 'n_units_Layer_3': 185}. Best is trial 518 with value: 11.57173557284158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.79 | sMAPE for Validation Set is: 31.69% | rMAE for Validation Set is: 2.03\n",
      "MAE for Test Set is: 178.23 | sMAPE for Test Set is: 82.45% | rMAE for Test Set is: 2.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:08:26,333]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:08:33,852]\u001b[0m Trial 657 finished with value: 48.694789831287174 and parameters: {'n_hidden': 4, 'learning_rate': 0.015044962480956483, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.360513472434978, 'dropout_rate_Layer_2': 0.018891578544190293, 'dropout_rate_Layer_3': 0.06641041085479454, 'dropout_rate_Layer_4': 0.33558531219391347, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.714056887629537e-05, 'l1_Layer_2': 2.1692940835205284e-05, 'l1_Layer_3': 0.000141073323921961, 'l1_Layer_4': 2.027975429506586e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 235, 'n_units_Layer_3': 105, 'n_units_Layer_4': 230}. Best is trial 518 with value: 11.57173557284158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 48.69 | sMAPE for Validation Set is: 40.40% | rMAE for Validation Set is: 2.31\n",
      "MAE for Test Set is: 181.40 | sMAPE for Test Set is: 85.24% | rMAE for Test Set is: 2.85\n",
      "MAE for Validation Set is: 48.02 | sMAPE for Validation Set is: 36.31% | rMAE for Validation Set is: 2.28\n",
      "MAE for Test Set is: 194.51 | sMAPE for Test Set is: 94.75% | rMAE for Test Set is: 3.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:08:38,231]\u001b[0m Trial 653 finished with value: 48.01991650626646 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011939816720213502, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24877306703808305, 'dropout_rate_Layer_2': 0.3224597543216975, 'dropout_rate_Layer_3': 0.13644650015496942, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0021560448942491185, 'l1_Layer_2': 0.010341082190722823, 'l1_Layer_3': 7.053881253929246e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 255, 'n_units_Layer_3': 110}. Best is trial 518 with value: 11.57173557284158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.70 | sMAPE for Validation Set is: 13.09% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 35.30 | sMAPE for Test Set is: 13.79% | rMAE for Test Set is: 0.55\n",
      "MAE for Validation Set is: 43.23 | sMAPE for Validation Set is: 38.18% | rMAE for Validation Set is: 2.05\n",
      "MAE for Test Set is: 154.79 | sMAPE for Test Set is: 67.48% | rMAE for Test Set is: 2.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:08:41,054]\u001b[0m Trial 660 finished with value: 12.69580371788316 and parameters: {'n_hidden': 3, 'learning_rate': 0.005189222764388362, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2667799644502119, 'dropout_rate_Layer_2': 0.28972036613591345, 'dropout_rate_Layer_3': 0.15395967973579117, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4861282566180305e-05, 'l1_Layer_2': 2.6146632760854462e-05, 'l1_Layer_3': 6.884773566625369e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 300, 'n_units_Layer_3': 300}. Best is trial 518 with value: 11.57173557284158.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:08:41,065]\u001b[0m Trial 659 finished with value: 43.23386059823844 and parameters: {'n_hidden': 4, 'learning_rate': 0.014919539281196537, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3749562429714014, 'dropout_rate_Layer_2': 0.01640528444675764, 'dropout_rate_Layer_3': 0.058417168630225516, 'dropout_rate_Layer_4': 0.33782122008218984, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.693498921790476e-05, 'l1_Layer_2': 3.779562956722262e-05, 'l1_Layer_3': 9.62024736932319e-05, 'l1_Layer_4': 2.471855044441921e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 235, 'n_units_Layer_3': 95, 'n_units_Layer_4': 235}. Best is trial 518 with value: 11.57173557284158.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:08:42,452]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:08:42,744]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:08:50,265]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:08:50,519]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:08:50,997]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:08:51,052]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:08:55,537]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:09:00,025]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:09:02,179]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:09:02,487]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:09:03,588]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:09:07,765]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:09:13,651]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:09:14,213]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:09:15,339]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:09:23,192]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:09:24,007]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:09:28,723]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:09:29,146]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:09:36,360]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:09:37,487]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:09:37,651]\u001b[0m Trial 677 finished with value: 44.68113472301866 and parameters: {'n_hidden': 4, 'learning_rate': 0.01720692355332331, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37046439884221727, 'dropout_rate_Layer_2': 0.03246669494578634, 'dropout_rate_Layer_3': 0.04592060626369846, 'dropout_rate_Layer_4': 0.330096985268521, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.2647450956137654e-05, 'l1_Layer_2': 1.5296770424909125e-05, 'l1_Layer_3': 0.00016002697913445628, 'l1_Layer_4': 1.5657692722337025e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 215, 'n_units_Layer_3': 80, 'n_units_Layer_4': 230}. Best is trial 518 with value: 11.57173557284158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.68 | sMAPE for Validation Set is: 35.52% | rMAE for Validation Set is: 2.12\n",
      "MAE for Test Set is: 181.20 | sMAPE for Test Set is: 84.47% | rMAE for Test Set is: 2.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:09:40,806]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:09:48,545]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:09:52,239]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:09:54,510]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:09:58,447]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:10:00,560]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:10:01,006]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:10:01,912]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:10:08,433]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:10:08,799]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:10:09,646]\u001b[0m Trial 675 finished with value: 32.67451616868404 and parameters: {'n_hidden': 4, 'learning_rate': 0.016454398828337137, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36310501172865217, 'dropout_rate_Layer_2': 0.006863871191875405, 'dropout_rate_Layer_3': 0.04753468172089503, 'dropout_rate_Layer_4': 0.31360558758166235, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.8801553728432045e-05, 'l1_Layer_2': 1.3715094690427591e-05, 'l1_Layer_3': 9.793638930314027e-05, 'l1_Layer_4': 2.6964689072315908e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 235, 'n_units_Layer_3': 80, 'n_units_Layer_4': 225}. Best is trial 518 with value: 11.57173557284158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.67 | sMAPE for Validation Set is: 25.31% | rMAE for Validation Set is: 1.55\n",
      "MAE for Test Set is: 140.37 | sMAPE for Test Set is: 57.63% | rMAE for Test Set is: 2.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:10:11,563]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:10:18,093]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:10:19,331]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:10:21,915]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:10:24,487]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:10:25,194]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:10:27,209]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:10:31,514]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:10:35,737]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:10:39,432]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:10:39,775]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:10:40,724]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:10:46,949]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:10:49,882]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:10:52,730]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:10:56,333]\u001b[0m Trial 703 finished with value: 12.294239383107902 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014792039794088996, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16260773471519874, 'dropout_rate_Layer_2': 0.16111306327839248, 'dropout_rate_Layer_3': 0.04688253340045506, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003205909586947959, 'l1_Layer_2': 0.00013157260972125788, 'l1_Layer_3': 0.00795831366886658, 'n_units_Layer_1': 270, 'n_units_Layer_2': 130, 'n_units_Layer_3': 290}. Best is trial 518 with value: 11.57173557284158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.29 | sMAPE for Validation Set is: 12.78% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 34.36 | sMAPE for Test Set is: 13.54% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:10:57,166]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:11:02,491]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:11:06,425]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:11:06,540]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:11:09,493]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:11:13,748]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:11:17,472]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:11:17,550]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:11:25,332]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:11:26,824]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:11:33,955]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:11:42,760]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:11:47,914]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:11:48,433]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:11:54,765]\u001b[0m Trial 711 finished with value: 12.36642368198551 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008163511863570001, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.030519037550503558, 'dropout_rate_Layer_2': 0.2791223491707237, 'dropout_rate_Layer_3': 0.13302785100132813, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003387782977584205, 'l1_Layer_2': 0.0037614856763851265, 'l1_Layer_3': 0.0034266274957772663, 'n_units_Layer_1': 100, 'n_units_Layer_2': 160, 'n_units_Layer_3': 250}. Best is trial 518 with value: 11.57173557284158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.37 | sMAPE for Validation Set is: 12.52% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 32.46 | sMAPE for Test Set is: 12.91% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:11:59,079]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:12:05,421]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:12:05,838]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:12:11,092]\u001b[0m Trial 727 finished with value: 46.10723290788284 and parameters: {'n_hidden': 4, 'learning_rate': 0.017859516267912028, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3659629196359707, 'dropout_rate_Layer_2': 0.07621108947090381, 'dropout_rate_Layer_3': 0.04739908477841929, 'dropout_rate_Layer_4': 0.3514252484660484, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 6.501563989167119e-05, 'l1_Layer_2': 2.752734270353783e-05, 'l1_Layer_3': 0.00018414362259421967, 'l1_Layer_4': 2.608150864728855e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 240, 'n_units_Layer_3': 85, 'n_units_Layer_4': 230}. Best is trial 518 with value: 11.57173557284158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.11 | sMAPE for Validation Set is: 37.74% | rMAE for Validation Set is: 2.19\n",
      "MAE for Test Set is: 161.01 | sMAPE for Test Set is: 70.79% | rMAE for Test Set is: 2.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:12:16,203]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:12:25,549]\u001b[0m Trial 726 finished with value: 12.215084413354402 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024402869367932435, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19060276940796034, 'dropout_rate_Layer_2': 0.18246957369219363, 'dropout_rate_Layer_3': 0.01945955039827154, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004779269525323929, 'l1_Layer_2': 0.00019951539919442387, 'l1_Layer_3': 0.00886180151901872, 'n_units_Layer_1': 290, 'n_units_Layer_2': 155, 'n_units_Layer_3': 135}. Best is trial 518 with value: 11.57173557284158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.22 | sMAPE for Validation Set is: 12.70% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 35.33 | sMAPE for Test Set is: 13.56% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:12:31,104]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:12:33,945]\u001b[0m Trial 731 finished with value: 12.235389680720353 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011404195396041092, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14244754677314453, 'dropout_rate_Layer_2': 0.1727829722328521, 'dropout_rate_Layer_3': 0.00303082411973965, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0038719124459249076, 'l1_Layer_2': 8.988859258468998e-05, 'l1_Layer_3': 0.009603893895338812, 'n_units_Layer_1': 255, 'n_units_Layer_2': 135, 'n_units_Layer_3': 290}. Best is trial 518 with value: 11.57173557284158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.24 | sMAPE for Validation Set is: 12.80% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 34.98 | sMAPE for Test Set is: 13.48% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:12:39,095]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:12:48,717]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:12:53,355]\u001b[0m Trial 734 finished with value: 17.744230947583304 and parameters: {'n_hidden': 4, 'learning_rate': 0.005224213296728356, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24406910869620457, 'dropout_rate_Layer_2': 0.3423811574717891, 'dropout_rate_Layer_3': 0.29939931371071493, 'dropout_rate_Layer_4': 0.16020487379219597, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.02272048138247536, 'l1_Layer_2': 0.0001223177202634699, 'l1_Layer_3': 0.00010570967858201778, 'l1_Layer_4': 0.0002429471306368098, 'n_units_Layer_1': 220, 'n_units_Layer_2': 275, 'n_units_Layer_3': 80, 'n_units_Layer_4': 280}. Best is trial 518 with value: 11.57173557284158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.74 | sMAPE for Validation Set is: 16.68% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 51.78 | sMAPE for Test Set is: 20.35% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:12:55,828]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:12:58,388]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:12:58,701]\u001b[0m Trial 735 finished with value: 12.352441769356611 and parameters: {'n_hidden': 3, 'learning_rate': 0.002328643695307537, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1853534203629696, 'dropout_rate_Layer_2': 0.1976764488723361, 'dropout_rate_Layer_3': 0.020273096486980825, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0068049347453217664, 'l1_Layer_2': 0.0001676576814615909, 'l1_Layer_3': 0.007912883656503849, 'n_units_Layer_1': 295, 'n_units_Layer_2': 150, 'n_units_Layer_3': 140}. Best is trial 518 with value: 11.57173557284158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.35 | sMAPE for Validation Set is: 12.96% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 35.85 | sMAPE for Test Set is: 13.84% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:13:00,628]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:13:07,921]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:13:12,375]\u001b[0m Trial 737 finished with value: 12.198636998677387 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017197707264900604, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11956756520607209, 'dropout_rate_Layer_2': 0.19597079398754352, 'dropout_rate_Layer_3': 0.03437980264748376, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005453177715233398, 'l1_Layer_2': 7.582511553608372e-05, 'l1_Layer_3': 0.00923835167814417, 'n_units_Layer_1': 240, 'n_units_Layer_2': 155, 'n_units_Layer_3': 275}. Best is trial 518 with value: 11.57173557284158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.20 | sMAPE for Validation Set is: 12.57% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 33.50 | sMAPE for Test Set is: 13.23% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:13:13,426]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:13:15,175]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:13:15,806]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:13:17,378]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:13:21,811]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:13:27,172]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:13:27,278]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:13:28,268]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:13:35,887]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:13:36,156]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:13:41,819]\u001b[0m Trial 748 finished with value: 11.497627058251167 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020510649581831422, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14864507885308997, 'dropout_rate_Layer_2': 0.029216391145402684, 'dropout_rate_Layer_3': 0.010059977804377826, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00026910008308961953, 'l1_Layer_2': 0.00017605050752327172, 'l1_Layer_3': 6.331723483208733e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 245, 'n_units_Layer_3': 295}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.50 | sMAPE for Validation Set is: 11.76% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 32.37 | sMAPE for Test Set is: 12.56% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:13:45,909]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:13:47,492]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:13:51,517]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:13:53,347]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:13:58,167]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:14:01,425]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:14:07,451]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:14:08,057]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:14:15,812]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:14:20,580]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:14:22,562]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:14:23,926]\u001b[0m Trial 762 finished with value: 18.89659593687821 and parameters: {'n_hidden': 4, 'learning_rate': 0.015737585793620452, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29667766050224753, 'dropout_rate_Layer_2': 0.3515424054003283, 'dropout_rate_Layer_3': 0.3116643285765593, 'dropout_rate_Layer_4': 0.1687723844445752, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.07332564185391541, 'l1_Layer_2': 2.952081604612386e-05, 'l1_Layer_3': 0.00010276859236538381, 'l1_Layer_4': 0.0002513761063663481, 'n_units_Layer_1': 195, 'n_units_Layer_2': 280, 'n_units_Layer_3': 105, 'n_units_Layer_4': 280}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.90 | sMAPE for Validation Set is: 17.92% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 57.16 | sMAPE for Test Set is: 21.53% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:14:25,169]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:14:31,897]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:14:32,979]\u001b[0m Trial 764 finished with value: 11.724785955986718 and parameters: {'n_hidden': 3, 'learning_rate': 0.002159388027827193, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15005888332031553, 'dropout_rate_Layer_2': 0.036204019036736035, 'dropout_rate_Layer_3': 0.027830208973770528, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00040696184441605125, 'l1_Layer_2': 1.7926875315830323e-05, 'l1_Layer_3': 0.00010973420425542443, 'n_units_Layer_1': 150, 'n_units_Layer_2': 210, 'n_units_Layer_3': 295}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.72 | sMAPE for Validation Set is: 11.99% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 33.72 | sMAPE for Test Set is: 13.08% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:14:39,527]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:14:41,485]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:14:44,999]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:14:49,339]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:14:52,800]\u001b[0m Trial 771 finished with value: 40.39522660597937 and parameters: {'n_hidden': 4, 'learning_rate': 0.019437269625832115, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.368455127549181, 'dropout_rate_Layer_2': 0.016822705966524517, 'dropout_rate_Layer_3': 0.041290956291100425, 'dropout_rate_Layer_4': 0.3674341759469964, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.00165233752975e-05, 'l1_Layer_2': 0.0001421627887453458, 'l1_Layer_3': 9.013218539155784e-05, 'l1_Layer_4': 4.016961856214095e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 230, 'n_units_Layer_3': 100, 'n_units_Layer_4': 225}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 40.40 | sMAPE for Validation Set is: 32.84% | rMAE for Validation Set is: 1.92\n",
      "MAE for Test Set is: 157.25 | sMAPE for Test Set is: 67.98% | rMAE for Test Set is: 2.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:15:00,432]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:15:03,155]\u001b[0m Trial 768 finished with value: 11.631661021918115 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021147913043131393, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14667910250408034, 'dropout_rate_Layer_2': 0.02803808563610313, 'dropout_rate_Layer_3': 0.024484171245606322, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002526960069320813, 'l1_Layer_2': 0.011910222535002983, 'l1_Layer_3': 0.0001011360603965144, 'n_units_Layer_1': 190, 'n_units_Layer_2': 235, 'n_units_Layer_3': 295}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.63 | sMAPE for Validation Set is: 11.92% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 32.14 | sMAPE for Test Set is: 12.63% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:15:07,962]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:15:08,163]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:15:14,450]\u001b[0m Trial 775 finished with value: 18.93685791251824 and parameters: {'n_hidden': 4, 'learning_rate': 0.02680419671096539, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30276287134565244, 'dropout_rate_Layer_2': 0.28928907927824354, 'dropout_rate_Layer_3': 0.3107325673710587, 'dropout_rate_Layer_4': 0.16540245836713668, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.05480234848889908, 'l1_Layer_2': 1.1191803591094815e-05, 'l1_Layer_3': 3.17072821894481e-05, 'l1_Layer_4': 0.0002076910402225919, 'n_units_Layer_1': 195, 'n_units_Layer_2': 285, 'n_units_Layer_3': 115, 'n_units_Layer_4': 295}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.94 | sMAPE for Validation Set is: 18.87% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 53.52 | sMAPE for Test Set is: 20.89% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:15:14,910]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:15:15,286]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.51 | sMAPE for Validation Set is: 11.83% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 32.35 | sMAPE for Test Set is: 12.66% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:15:21,291]\u001b[0m Trial 773 finished with value: 11.507360440517047 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020957121049666374, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15143030569529461, 'dropout_rate_Layer_2': 0.025705866373749296, 'dropout_rate_Layer_3': 0.025931778341137586, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004895912735933055, 'l1_Layer_2': 1.0303686090460685e-05, 'l1_Layer_3': 9.5643854597284e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 205, 'n_units_Layer_3': 295}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:15:23,584]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:15:25,130]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:15:28,946]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:15:32,105]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:15:37,740]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:15:49,521]\u001b[0m Trial 786 finished with value: 11.647377988359784 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025094917732906654, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14093069317024323, 'dropout_rate_Layer_2': 0.008061576905432587, 'dropout_rate_Layer_3': 0.022203569610388187, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004330516782405527, 'l1_Layer_2': 2.241289162762359e-05, 'l1_Layer_3': 0.00016676322290048144, 'n_units_Layer_1': 160, 'n_units_Layer_2': 205, 'n_units_Layer_3': 295}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.65 | sMAPE for Validation Set is: 11.96% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 33.23 | sMAPE for Test Set is: 12.96% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:15:54,270]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:15:59,220]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:16:03,987]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:16:11,558]\u001b[0m Trial 787 finished with value: 11.515789060050992 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017259340812079786, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10920201753368076, 'dropout_rate_Layer_2': 0.00674745586840985, 'dropout_rate_Layer_3': 0.012152583120733144, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004443302656229374, 'l1_Layer_2': 1.9461340322293596e-05, 'l1_Layer_3': 0.000154337423121804, 'n_units_Layer_1': 165, 'n_units_Layer_2': 210, 'n_units_Layer_3': 295}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.52 | sMAPE for Validation Set is: 11.83% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 31.24 | sMAPE for Test Set is: 12.38% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:16:12,515]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:16:13,061]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:16:18,687]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:16:19,191]\u001b[0m Trial 782 finished with value: 12.593259644623794 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008146410804617475, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.010248343603409323, 'dropout_rate_Layer_2': 0.2879641545611897, 'dropout_rate_Layer_3': 0.1384498717574651, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00026290432331180783, 'l1_Layer_2': 0.003714008009284487, 'l1_Layer_3': 0.0032934435575964604, 'n_units_Layer_1': 75, 'n_units_Layer_2': 150, 'n_units_Layer_3': 275}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.59 | sMAPE for Validation Set is: 12.66% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 32.43 | sMAPE for Test Set is: 12.89% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:16:19,905]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:16:27,434]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:16:33,193]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:16:40,215]\u001b[0m Trial 798 finished with value: 48.18107570191918 and parameters: {'n_hidden': 4, 'learning_rate': 0.01895831833911869, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37882665024268625, 'dropout_rate_Layer_2': 0.012682355809840706, 'dropout_rate_Layer_3': 0.15914131388585218, 'dropout_rate_Layer_4': 0.36111770659824455, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.038585246959743e-05, 'l1_Layer_2': 0.00019995911458760014, 'l1_Layer_3': 4.533803538933897e-05, 'l1_Layer_4': 3.0127734258983664e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 170, 'n_units_Layer_3': 70, 'n_units_Layer_4': 230}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 48.18 | sMAPE for Validation Set is: 37.91% | rMAE for Validation Set is: 2.29\n",
      "MAE for Test Set is: 189.62 | sMAPE for Test Set is: 90.95% | rMAE for Test Set is: 2.98\n",
      "MAE for Validation Set is: 47.70 | sMAPE for Validation Set is: 38.54% | rMAE for Validation Set is: 2.26\n",
      "MAE for Test Set is: 177.65 | sMAPE for Test Set is: 81.82% | rMAE for Test Set is: 2.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:16:40,453]\u001b[0m Trial 799 finished with value: 47.69928813734922 and parameters: {'n_hidden': 4, 'learning_rate': 0.01906836292965735, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34047423556039713, 'dropout_rate_Layer_2': 0.014260421337876444, 'dropout_rate_Layer_3': 0.1433349556543623, 'dropout_rate_Layer_4': 0.38840026372707886, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.0164845320219274e-05, 'l1_Layer_2': 0.00017184054764590641, 'l1_Layer_3': 9.971395462300929e-05, 'l1_Layer_4': 3.1999070119477834e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 180, 'n_units_Layer_3': 70, 'n_units_Layer_4': 225}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:16:43,592]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:16:48,501]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:16:51,783]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:16:54,559]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:16:59,542]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:16:59,823]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.48 | sMAPE for Validation Set is: 12.86% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 34.85 | sMAPE for Test Set is: 13.55% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:17:03,574]\u001b[0m Trial 802 finished with value: 12.484189083287616 and parameters: {'n_hidden': 3, 'learning_rate': 0.005113285470044551, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16674675229360023, 'dropout_rate_Layer_2': 0.17995629573928026, 'dropout_rate_Layer_3': 0.015002544096448439, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00288052459725429, 'l1_Layer_2': 0.00011839803058568478, 'l1_Layer_3': 0.0013331872911285269, 'n_units_Layer_1': 290, 'n_units_Layer_2': 150, 'n_units_Layer_3': 285}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:17:08,162]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:17:11,025]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:17:14,171]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:17:16,077]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:17:20,664]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:17:21,469]\u001b[0m Trial 809 finished with value: 12.182122969494186 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015984087477178997, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09397036174147017, 'dropout_rate_Layer_2': 0.00932903985900378, 'dropout_rate_Layer_3': 0.023200014639890434, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007973742250280296, 'l1_Layer_2': 2.580525092057307e-05, 'l1_Layer_3': 0.0001508600225675539, 'n_units_Layer_1': 160, 'n_units_Layer_2': 180, 'n_units_Layer_3': 300}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.18 | sMAPE for Validation Set is: 12.37% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 34.28 | sMAPE for Test Set is: 13.34% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:17:25,059]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:17:26,909]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:17:30,035]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:17:34,873]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:17:39,712]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:17:46,790]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:17:50,167]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:17:54,342]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:17:55,008]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:18:02,050]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:18:02,371]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:18:05,486]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:18:08,918]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:18:12,202]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:18:14,616]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:18:16,664]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:18:21,417]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:18:23,834]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:18:25,748]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:18:27,658]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:18:28,569]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:18:31,983]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:18:32,071]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:18:40,272]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:18:40,726]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:18:41,578]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:18:47,104]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:18:48,875]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:18:50,630]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:18:54,602]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:18:58,693]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:18:59,589]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:19:04,000]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:19:06,179]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:19:07,902]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:19:13,938]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:19:18,366]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:19:24,737]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:19:24,912]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:19:25,917]\u001b[0m Trial 842 finished with value: 12.208294338638334 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034944720399923334, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25247034383140565, 'dropout_rate_Layer_2': 0.00041205216954448565, 'dropout_rate_Layer_3': 0.02799858081443129, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0024723705882027723, 'l1_Layer_2': 1.551044367719525e-05, 'l1_Layer_3': 0.05113558478559422, 'n_units_Layer_1': 300, 'n_units_Layer_2': 135, 'n_units_Layer_3': 60}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.21 | sMAPE for Validation Set is: 12.74% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 36.36 | sMAPE for Test Set is: 13.84% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:19:31,907]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:19:35,000]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:19:36,488]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:19:42,081]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:19:44,365]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:19:44,903]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:19:51,968]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:19:53,281]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:19:59,615]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:20:04,360]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:20:05,137]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:20:12,113]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:20:17,865]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:20:21,344]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:20:32,444]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:20:35,617]\u001b[0m Trial 864 finished with value: 33.05958474594343 and parameters: {'n_hidden': 4, 'learning_rate': 0.014234215069712043, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12082780774566138, 'dropout_rate_Layer_2': 0.22352886430901464, 'dropout_rate_Layer_3': 0.04290167305713919, 'dropout_rate_Layer_4': 0.3161202017433159, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.587650648436046e-05, 'l1_Layer_2': 2.29788904485508e-05, 'l1_Layer_3': 0.00026798020496550173, 'l1_Layer_4': 4.59546752558153e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 240, 'n_units_Layer_3': 60, 'n_units_Layer_4': 215}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.06 | sMAPE for Validation Set is: 24.80% | rMAE for Validation Set is: 1.57\n",
      "MAE for Test Set is: 140.16 | sMAPE for Test Set is: 57.88% | rMAE for Test Set is: 2.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:20:41,021]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:20:46,730]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:20:50,622]\u001b[0m Trial 871 finished with value: 51.92497585994571 and parameters: {'n_hidden': 4, 'learning_rate': 0.023711194589996487, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3086731915450009, 'dropout_rate_Layer_2': 0.28052819392402567, 'dropout_rate_Layer_3': 0.30806695403345374, 'dropout_rate_Layer_4': 0.16880072644007246, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.08019878993424477, 'l1_Layer_2': 1.0116192905956375e-05, 'l1_Layer_3': 2.4436641858994758e-05, 'l1_Layer_4': 0.00021345588603442127, 'n_units_Layer_1': 235, 'n_units_Layer_2': 285, 'n_units_Layer_3': 165, 'n_units_Layer_4': 295}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.92 | sMAPE for Validation Set is: 42.27% | rMAE for Validation Set is: 2.47\n",
      "MAE for Test Set is: 199.27 | sMAPE for Test Set is: 99.05% | rMAE for Test Set is: 3.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:20:50,817]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:20:54,845]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:21:01,332]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:21:05,861]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:21:06,049]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:21:06,399]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:21:06,789]\u001b[0m Trial 875 finished with value: 35.006097951947645 and parameters: {'n_hidden': 3, 'learning_rate': 0.046602655429099644, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21741668957475485, 'dropout_rate_Layer_2': 0.13424490645819964, 'dropout_rate_Layer_3': 0.2642972465897207, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0015919646610119895, 'l1_Layer_2': 0.003116745074432046, 'l1_Layer_3': 0.0002259177793230141, 'n_units_Layer_1': 145, 'n_units_Layer_2': 185, 'n_units_Layer_3': 290}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 35.01 | sMAPE for Validation Set is: 32.48% | rMAE for Validation Set is: 1.66\n",
      "MAE for Test Set is: 104.62 | sMAPE for Test Set is: 44.59% | rMAE for Test Set is: 1.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:21:11,750]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:21:13,714]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:21:17,887]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:21:24,166]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:21:24,225]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:21:25,113]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:21:28,346]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:21:34,167]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:21:37,639]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:21:41,584]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:21:45,443]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:21:47,791]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:21:51,935]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:21:52,474]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:21:59,815]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:22:03,141]\u001b[0m Trial 890 finished with value: 16.286893292334714 and parameters: {'n_hidden': 4, 'learning_rate': 0.014233577647495535, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35699141843932336, 'dropout_rate_Layer_2': 0.3595170014633953, 'dropout_rate_Layer_3': 0.39680932202688035, 'dropout_rate_Layer_4': 0.13428309616339368, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.016596445729338966, 'l1_Layer_2': 3.603136751710862e-05, 'l1_Layer_3': 0.0005881659150267113, 'l1_Layer_4': 0.00022678369701301177, 'n_units_Layer_1': 195, 'n_units_Layer_2': 230, 'n_units_Layer_3': 115, 'n_units_Layer_4': 245}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.29 | sMAPE for Validation Set is: 15.73% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 51.85 | sMAPE for Test Set is: 18.31% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:22:05,177]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:22:05,993]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:22:08,176]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:22:14,309]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:22:18,763]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:22:19,564]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:22:23,813]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:22:29,492]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:22:30,341]\u001b[0m Trial 900 finished with value: 47.04218913294083 and parameters: {'n_hidden': 4, 'learning_rate': 0.017686936247294355, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37278264790984716, 'dropout_rate_Layer_2': 0.04805005887811507, 'dropout_rate_Layer_3': 0.2257279388427983, 'dropout_rate_Layer_4': 0.310859643432868, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.9942884271378184e-05, 'l1_Layer_2': 6.405070046920618e-05, 'l1_Layer_3': 0.00031944756942511523, 'l1_Layer_4': 3.128850872445832e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 235, 'n_units_Layer_3': 75, 'n_units_Layer_4': 190}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.04 | sMAPE for Validation Set is: 37.45% | rMAE for Validation Set is: 2.23\n",
      "MAE for Test Set is: 179.05 | sMAPE for Test Set is: 83.13% | rMAE for Test Set is: 2.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:22:34,552]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:22:37,010]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:22:41,130]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:22:44,267]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:22:47,698]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:22:48,409]\u001b[0m Trial 904 finished with value: 11.71319511774976 and parameters: {'n_hidden': 3, 'learning_rate': 0.0039062484193575545, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15089593906824847, 'dropout_rate_Layer_2': 0.022127475557783063, 'dropout_rate_Layer_3': 0.020363436175374575, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005205714028967145, 'l1_Layer_2': 0.0018093382844187819, 'l1_Layer_3': 0.00010162662216063951, 'n_units_Layer_1': 140, 'n_units_Layer_2': 210, 'n_units_Layer_3': 270}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:22:48,445]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.71 | sMAPE for Validation Set is: 11.99% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 33.52 | sMAPE for Test Set is: 13.11% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:22:52,738]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:22:59,899]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:23:00,946]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:23:07,391]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:23:07,455]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:23:08,172]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:23:08,604]\u001b[0m Trial 887 finished with value: 29.962430865600343 and parameters: {'n_hidden': 4, 'learning_rate': 0.01545951895133042, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38032791345930994, 'dropout_rate_Layer_2': 0.014833763460444762, 'dropout_rate_Layer_3': 0.22995875863685716, 'dropout_rate_Layer_4': 0.29401289889044674, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.322994104866182e-05, 'l1_Layer_2': 1.3572358931850643e-05, 'l1_Layer_3': 1.3754833720890554e-05, 'l1_Layer_4': 1.4609956476774362e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 210, 'n_units_Layer_3': 80, 'n_units_Layer_4': 195}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.96 | sMAPE for Validation Set is: 23.15% | rMAE for Validation Set is: 1.42\n",
      "MAE for Test Set is: 127.46 | sMAPE for Test Set is: 50.40% | rMAE for Test Set is: 2.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:23:12,401]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:23:17,925]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:23:26,022]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:23:28,713]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:23:32,448]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:23:41,406]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:23:44,793]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:23:45,209]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:23:51,441]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:24:00,977]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:24:03,841]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:24:08,571]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:24:11,752]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:24:16,926]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:24:22,066]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:24:25,436]\u001b[0m Trial 921 finished with value: 26.016082950739445 and parameters: {'n_hidden': 4, 'learning_rate': 0.0139867995014544, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11431435679098695, 'dropout_rate_Layer_2': 0.34869578152026753, 'dropout_rate_Layer_3': 0.24476588942177016, 'dropout_rate_Layer_4': 0.2747831373868658, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.3156757210196243e-05, 'l1_Layer_2': 1.121211812734458e-05, 'l1_Layer_3': 3.4325892518433855e-05, 'l1_Layer_4': 1.3902584807859651e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 205, 'n_units_Layer_3': 80, 'n_units_Layer_4': 200}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.02 | sMAPE for Validation Set is: 21.86% | rMAE for Validation Set is: 1.24\n",
      "MAE for Test Set is: 94.32 | sMAPE for Test Set is: 34.15% | rMAE for Test Set is: 1.48\n",
      "MAE for Validation Set is: 13.62 | sMAPE for Validation Set is: 13.56% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 35.55 | sMAPE for Test Set is: 14.23% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:24:27,964]\u001b[0m Trial 932 finished with value: 13.623231979695111 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008324908785700015, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0025191321487708085, 'dropout_rate_Layer_2': 0.2838142482569509, 'dropout_rate_Layer_3': 0.09825573200779918, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00028656251666102025, 'l1_Layer_2': 0.003308215324517222, 'l1_Layer_3': 0.002794286578039626, 'n_units_Layer_1': 185, 'n_units_Layer_2': 165, 'n_units_Layer_3': 275}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:24:32,109]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:24:42,913]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:24:49,007]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:25:02,014]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:25:34,538]\u001b[0m Trial 934 finished with value: 29.94624176115963 and parameters: {'n_hidden': 4, 'learning_rate': 0.015981248779230274, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3792030572020505, 'dropout_rate_Layer_2': 0.09589635043293958, 'dropout_rate_Layer_3': 0.35730270628954286, 'dropout_rate_Layer_4': 0.10799412074210421, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.5392738013398126e-05, 'l1_Layer_2': 1.94607502874892e-05, 'l1_Layer_3': 2.7531930236602894e-05, 'l1_Layer_4': 9.426281806287439e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 225, 'n_units_Layer_3': 70, 'n_units_Layer_4': 165}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.95 | sMAPE for Validation Set is: 23.63% | rMAE for Validation Set is: 1.42\n",
      "MAE for Test Set is: 124.71 | sMAPE for Test Set is: 49.66% | rMAE for Test Set is: 1.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:25:38,545]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:25:46,456]\u001b[0m Trial 938 finished with value: 23.553761205984006 and parameters: {'n_hidden': 4, 'learning_rate': 0.011426456843344271, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12220421900678188, 'dropout_rate_Layer_2': 0.01664911971177588, 'dropout_rate_Layer_3': 0.2623595013391268, 'dropout_rate_Layer_4': 0.2823902844020911, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.166709676005718e-05, 'l1_Layer_2': 1.0539983020490299e-05, 'l1_Layer_3': 1.3192018159474011e-05, 'l1_Layer_4': 1.164634742583721e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 200, 'n_units_Layer_3': 80, 'n_units_Layer_4': 195}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.55 | sMAPE for Validation Set is: 20.26% | rMAE for Validation Set is: 1.12\n",
      "MAE for Test Set is: 75.79 | sMAPE for Test Set is: 27.62% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:25:52,977]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:26:08,137]\u001b[0m Trial 944 finished with value: 15.01945878525242 and parameters: {'n_hidden': 4, 'learning_rate': 0.013331913601668393, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38282381297256685, 'dropout_rate_Layer_2': 0.353492649277775, 'dropout_rate_Layer_3': 0.39219152990028977, 'dropout_rate_Layer_4': 0.10316910516203001, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.016082538486193003, 'l1_Layer_2': 3.91994132400542e-05, 'l1_Layer_3': 0.0006078558496110262, 'l1_Layer_4': 0.0002842046469866909, 'n_units_Layer_1': 225, 'n_units_Layer_2': 225, 'n_units_Layer_3': 130, 'n_units_Layer_4': 235}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.02 | sMAPE for Validation Set is: 15.15% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 42.67 | sMAPE for Test Set is: 16.82% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:26:14,384]\u001b[0m Trial 942 finished with value: 26.947413157701934 and parameters: {'n_hidden': 4, 'learning_rate': 0.014429890632263928, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10355835932606348, 'dropout_rate_Layer_2': 0.018065020069014646, 'dropout_rate_Layer_3': 0.24214132809177735, 'dropout_rate_Layer_4': 0.2573363048539704, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.4660340259680774e-05, 'l1_Layer_2': 1.0373723028190835e-05, 'l1_Layer_3': 2.0522870461778305e-05, 'l1_Layer_4': 1.5168349495286272e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 55, 'n_units_Layer_3': 75, 'n_units_Layer_4': 205}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.95 | sMAPE for Validation Set is: 21.95% | rMAE for Validation Set is: 1.28\n",
      "MAE for Test Set is: 104.00 | sMAPE for Test Set is: 39.06% | rMAE for Test Set is: 1.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:26:22,057]\u001b[0m Trial 943 finished with value: 15.41854154157017 and parameters: {'n_hidden': 4, 'learning_rate': 0.005110732032958498, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37631302133998884, 'dropout_rate_Layer_2': 0.3618315228855046, 'dropout_rate_Layer_3': 0.39767267590092964, 'dropout_rate_Layer_4': 0.10264592432295722, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.018480969924378518, 'l1_Layer_2': 3.2070018011164144e-05, 'l1_Layer_3': 0.0006180865069460384, 'l1_Layer_4': 0.00028035240642212955, 'n_units_Layer_1': 295, 'n_units_Layer_2': 225, 'n_units_Layer_3': 125, 'n_units_Layer_4': 240}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.42 | sMAPE for Validation Set is: 15.62% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 45.10 | sMAPE for Test Set is: 17.40% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:26:42,553]\u001b[0m Trial 949 finished with value: 11.54580739048828 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032961453677793893, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14626366773047517, 'dropout_rate_Layer_2': 0.02122828150852065, 'dropout_rate_Layer_3': 0.3732624201923675, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004965683009112829, 'l1_Layer_2': 1.0052866967297665e-05, 'l1_Layer_3': 0.00023005973365237742, 'n_units_Layer_1': 185, 'n_units_Layer_2': 210, 'n_units_Layer_3': 270}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.55 | sMAPE for Validation Set is: 11.58% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 31.04 | sMAPE for Test Set is: 12.32% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:26:46,482]\u001b[0m Trial 946 finished with value: 26.010038796225967 and parameters: {'n_hidden': 4, 'learning_rate': 0.008859116492814414, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12317465294694212, 'dropout_rate_Layer_2': 0.10565130624155006, 'dropout_rate_Layer_3': 0.2608266330473293, 'dropout_rate_Layer_4': 0.09981802000025398, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.6137202053315933e-05, 'l1_Layer_2': 1.0352456274576966e-05, 'l1_Layer_3': 1.1631669096230982e-05, 'l1_Layer_4': 1.2955557737665326e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 215, 'n_units_Layer_3': 70, 'n_units_Layer_4': 190}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.01 | sMAPE for Validation Set is: 22.11% | rMAE for Validation Set is: 1.24\n",
      "MAE for Test Set is: 98.30 | sMAPE for Test Set is: 36.34% | rMAE for Test Set is: 1.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:26:53,578]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:26:56,816]\u001b[0m Trial 950 finished with value: 11.771295606570535 and parameters: {'n_hidden': 3, 'learning_rate': 0.003459674191298242, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07378338827476187, 'dropout_rate_Layer_2': 0.022964602186455848, 'dropout_rate_Layer_3': 0.2865951176462963, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003895834032891047, 'l1_Layer_2': 1.1555791931369239e-05, 'l1_Layer_3': 0.00013908287303101142, 'n_units_Layer_1': 185, 'n_units_Layer_2': 195, 'n_units_Layer_3': 270}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.77 | sMAPE for Validation Set is: 12.31% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 32.59 | sMAPE for Test Set is: 12.87% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:27:00,949]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:27:05,711]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:27:14,226]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:27:26,402]\u001b[0m Trial 947 finished with value: 23.851577774932256 and parameters: {'n_hidden': 4, 'learning_rate': 0.01341964243359326, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12365967033487699, 'dropout_rate_Layer_2': 0.3503648433763743, 'dropout_rate_Layer_3': 0.33520564815508874, 'dropout_rate_Layer_4': 0.08134328758078109, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.862116491171861e-05, 'l1_Layer_2': 1.4026026175903136e-05, 'l1_Layer_3': 2.3658210407672465e-05, 'l1_Layer_4': 1.1854990332911362e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 215, 'n_units_Layer_3': 70, 'n_units_Layer_4': 195}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.85 | sMAPE for Validation Set is: 20.45% | rMAE for Validation Set is: 1.13\n",
      "MAE for Test Set is: 83.44 | sMAPE for Test Set is: 29.67% | rMAE for Test Set is: 1.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:27:47,749]\u001b[0m Trial 957 finished with value: 17.663869299284794 and parameters: {'n_hidden': 4, 'learning_rate': 0.012904420035154872, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38484375095615303, 'dropout_rate_Layer_2': 0.3670033241170102, 'dropout_rate_Layer_3': 0.3996960143011523, 'dropout_rate_Layer_4': 0.08374738575926699, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.017594717854909535, 'l1_Layer_2': 3.7811638329847274e-05, 'l1_Layer_3': 0.003730162978431517, 'l1_Layer_4': 0.0013526407276023865, 'n_units_Layer_1': 300, 'n_units_Layer_2': 225, 'n_units_Layer_3': 130, 'n_units_Layer_4': 220}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.66 | sMAPE for Validation Set is: 17.16% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 50.74 | sMAPE for Test Set is: 19.99% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:27:48,583]\u001b[0m Trial 953 finished with value: 23.40094658556819 and parameters: {'n_hidden': 4, 'learning_rate': 0.010471547234066392, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12312924181171318, 'dropout_rate_Layer_2': 0.11542222559002473, 'dropout_rate_Layer_3': 0.23983385948884406, 'dropout_rate_Layer_4': 0.0895372836249346, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.917737470814165e-05, 'l1_Layer_2': 1.0105683222133019e-05, 'l1_Layer_3': 2.4887272100760808e-05, 'l1_Layer_4': 1.1786470961915758e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 50, 'n_units_Layer_3': 70, 'n_units_Layer_4': 195}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.40 | sMAPE for Validation Set is: 19.47% | rMAE for Validation Set is: 1.11\n",
      "MAE for Test Set is: 95.05 | sMAPE for Test Set is: 34.39% | rMAE for Test Set is: 1.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:28:02,450]\u001b[0m Trial 951 finished with value: 32.79528545101706 and parameters: {'n_hidden': 4, 'learning_rate': 0.007640908869736533, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13462664081095493, 'dropout_rate_Layer_2': 0.103943462446403, 'dropout_rate_Layer_3': 0.2618594362579943, 'dropout_rate_Layer_4': 0.27573654889372007, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.509647539622223e-05, 'l1_Layer_2': 1.0151703383526743e-05, 'l1_Layer_3': 2.2873700840589423e-05, 'l1_Layer_4': 1.01272261279888e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 205, 'n_units_Layer_3': 70, 'n_units_Layer_4': 195}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.80 | sMAPE for Validation Set is: 25.96% | rMAE for Validation Set is: 1.56\n",
      "MAE for Test Set is: 121.03 | sMAPE for Test Set is: 47.43% | rMAE for Test Set is: 1.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:28:14,291]\u001b[0m Trial 956 finished with value: 23.394986195182444 and parameters: {'n_hidden': 4, 'learning_rate': 0.011646812158352476, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1251351380354707, 'dropout_rate_Layer_2': 0.11039902307986121, 'dropout_rate_Layer_3': 0.2577878776552646, 'dropout_rate_Layer_4': 0.07956968125440961, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.6282885721036662e-05, 'l1_Layer_2': 1.1338094695913238e-05, 'l1_Layer_3': 2.223073282634606e-05, 'l1_Layer_4': 1.0028402759037704e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 110, 'n_units_Layer_3': 75, 'n_units_Layer_4': 195}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.39 | sMAPE for Validation Set is: 19.89% | rMAE for Validation Set is: 1.11\n",
      "MAE for Test Set is: 101.57 | sMAPE for Test Set is: 37.91% | rMAE for Test Set is: 1.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:28:49,125]\u001b[0m Trial 959 finished with value: 21.662798214154094 and parameters: {'n_hidden': 4, 'learning_rate': 0.008300240668398209, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13553113831439734, 'dropout_rate_Layer_2': 0.10716260214367818, 'dropout_rate_Layer_3': 0.3310155813209991, 'dropout_rate_Layer_4': 0.08521478569554165, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.937008616251922e-05, 'l1_Layer_2': 1.0543718306217475e-05, 'l1_Layer_3': 2.5889448810146188e-05, 'l1_Layer_4': 1.0488326174043309e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 55, 'n_units_Layer_3': 70, 'n_units_Layer_4': 195}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.66 | sMAPE for Validation Set is: 18.84% | rMAE for Validation Set is: 1.03\n",
      "MAE for Test Set is: 79.54 | sMAPE for Test Set is: 28.15% | rMAE for Test Set is: 1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:28:52,001]\u001b[0m Trial 958 finished with value: 12.123009982677367 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010147204053423079, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05746868570077675, 'dropout_rate_Layer_2': 0.3073785323087923, 'dropout_rate_Layer_3': 0.13699804192213408, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011959814401382445, 'l1_Layer_2': 0.002521580419661222, 'l1_Layer_3': 0.003946110635468869, 'n_units_Layer_1': 70, 'n_units_Layer_2': 145, 'n_units_Layer_3': 275}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.12 | sMAPE for Validation Set is: 12.52% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 33.34 | sMAPE for Test Set is: 13.19% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:28:53,934]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.48 | sMAPE for Validation Set is: 19.53% | rMAE for Validation Set is: 1.02\n",
      "MAE for Test Set is: 79.27 | sMAPE for Test Set is: 28.33% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:28:55,964]\u001b[0m Trial 960 finished with value: 21.477804410257818 and parameters: {'n_hidden': 4, 'learning_rate': 0.008564252564381182, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14492995306725598, 'dropout_rate_Layer_2': 0.12074289206253107, 'dropout_rate_Layer_3': 0.38669817338028845, 'dropout_rate_Layer_4': 0.08027827863274867, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.110864464304552e-05, 'l1_Layer_2': 1.0579940101216005e-05, 'l1_Layer_3': 2.714400206658828e-05, 'l1_Layer_4': 1.0675883782212759e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 200, 'n_units_Layer_3': 70, 'n_units_Layer_4': 195}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:28:57,293]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:29:02,739]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:29:05,264]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:29:07,604]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:29:12,890]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:29:13,614]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:29:19,293]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:29:26,152]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:29:30,991]\u001b[0m Trial 961 finished with value: 25.15730471793944 and parameters: {'n_hidden': 4, 'learning_rate': 0.00832959934630724, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13470530852661414, 'dropout_rate_Layer_2': 0.33860732397869986, 'dropout_rate_Layer_3': 0.2659102176928305, 'dropout_rate_Layer_4': 0.08445145646432795, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.493384351240397e-05, 'l1_Layer_2': 1.0683325484602675e-05, 'l1_Layer_3': 2.4043417362432744e-05, 'l1_Layer_4': 1.066258145071543e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 50, 'n_units_Layer_3': 75, 'n_units_Layer_4': 195}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.16 | sMAPE for Validation Set is: 20.99% | rMAE for Validation Set is: 1.19\n",
      "MAE for Test Set is: 101.86 | sMAPE for Test Set is: 37.77% | rMAE for Test Set is: 1.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:29:59,586]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:30:14,279]\u001b[0m Trial 971 finished with value: 22.387792433813292 and parameters: {'n_hidden': 4, 'learning_rate': 0.007194738939207449, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13143879159137495, 'dropout_rate_Layer_2': 0.11459220169975302, 'dropout_rate_Layer_3': 0.26270559594500964, 'dropout_rate_Layer_4': 0.09318860385841912, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.242950774977928e-05, 'l1_Layer_2': 1.0041387843064916e-05, 'l1_Layer_3': 2.853577195016506e-05, 'l1_Layer_4': 1.0752687217239715e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 50, 'n_units_Layer_3': 75, 'n_units_Layer_4': 195}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.39 | sMAPE for Validation Set is: 19.95% | rMAE for Validation Set is: 1.06\n",
      "MAE for Test Set is: 81.33 | sMAPE for Test Set is: 28.65% | rMAE for Test Set is: 1.28\n",
      "MAE for Validation Set is: 22.72 | sMAPE for Validation Set is: 19.53% | rMAE for Validation Set is: 1.08\n",
      "MAE for Test Set is: 95.59 | sMAPE for Test Set is: 34.55% | rMAE for Test Set is: 1.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:30:18,928]\u001b[0m Trial 969 finished with value: 22.72010108100635 and parameters: {'n_hidden': 4, 'learning_rate': 0.009272929744180081, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1415436800801442, 'dropout_rate_Layer_2': 0.104571846693628, 'dropout_rate_Layer_3': 0.26397517050734876, 'dropout_rate_Layer_4': 0.08475389409733694, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 6.62319970278385e-05, 'l1_Layer_2': 1.1136692234208121e-05, 'l1_Layer_3': 3.0524780690477936e-05, 'l1_Layer_4': 1.0582539142039223e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 50, 'n_units_Layer_3': 75, 'n_units_Layer_4': 195}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:30:19,452]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:30:20,051]\u001b[0m Trial 974 finished with value: 12.449715800818117 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016055821004228798, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06325762627001998, 'dropout_rate_Layer_2': 0.3177832353953006, 'dropout_rate_Layer_3': 0.12156640427996546, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.947640930587261e-05, 'l1_Layer_2': 0.002596744891333291, 'l1_Layer_3': 0.005540438611568907, 'n_units_Layer_1': 80, 'n_units_Layer_2': 50, 'n_units_Layer_3': 260}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.45 | sMAPE for Validation Set is: 12.76% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 34.26 | sMAPE for Test Set is: 13.35% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:30:28,278]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:30:29,405]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:30:37,148]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:30:42,740]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:30:43,403]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:30:56,788]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:31:02,114]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:31:19,459]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:31:50,022]\u001b[0m Trial 980 finished with value: 24.26951119807401 and parameters: {'n_hidden': 4, 'learning_rate': 0.007612015300309782, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13230328181914588, 'dropout_rate_Layer_2': 0.11728562095704739, 'dropout_rate_Layer_3': 0.26045287173561044, 'dropout_rate_Layer_4': 0.09732823989330826, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.165446656636088e-05, 'l1_Layer_2': 1.002270877166737e-05, 'l1_Layer_3': 2.4862009668109578e-05, 'l1_Layer_4': 1.0630126831302425e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 50, 'n_units_Layer_3': 125, 'n_units_Layer_4': 200}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.27 | sMAPE for Validation Set is: 21.54% | rMAE for Validation Set is: 1.15\n",
      "MAE for Test Set is: 95.36 | sMAPE for Test Set is: 35.46% | rMAE for Test Set is: 1.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:31:55,287]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:32:00,412]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:32:00,550]\u001b[0m Trial 984 finished with value: 24.65029937347914 and parameters: {'n_hidden': 4, 'learning_rate': 0.00918551420132241, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13976278069432505, 'dropout_rate_Layer_2': 0.10930459143457628, 'dropout_rate_Layer_3': 0.2606666235303407, 'dropout_rate_Layer_4': 0.09282792364258763, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 8.800542193715357e-05, 'l1_Layer_2': 1.0052395106512862e-05, 'l1_Layer_3': 1.8629613399905516e-05, 'l1_Layer_4': 1.2565999374612254e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 50, 'n_units_Layer_3': 70, 'n_units_Layer_4': 200}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.65 | sMAPE for Validation Set is: 21.83% | rMAE for Validation Set is: 1.17\n",
      "MAE for Test Set is: 83.41 | sMAPE for Test Set is: 30.60% | rMAE for Test Set is: 1.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:32:11,002]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:32:11,196]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:32:19,648]\u001b[0m Trial 987 finished with value: 25.444345217772256 and parameters: {'n_hidden': 4, 'learning_rate': 0.008197659615334692, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1590796852212422, 'dropout_rate_Layer_2': 0.33984431157960426, 'dropout_rate_Layer_3': 0.32622351330018595, 'dropout_rate_Layer_4': 0.09637491880085598, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.456389441779005e-05, 'l1_Layer_2': 1.2051476891387339e-05, 'l1_Layer_3': 2.8472999102345843e-05, 'l1_Layer_4': 1.2589215405324717e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 50, 'n_units_Layer_3': 75, 'n_units_Layer_4': 190}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.44 | sMAPE for Validation Set is: 21.53% | rMAE for Validation Set is: 1.21\n",
      "MAE for Test Set is: 92.17 | sMAPE for Test Set is: 33.04% | rMAE for Test Set is: 1.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:32:24,036]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:32:55,892]\u001b[0m Trial 993 finished with value: 20.86377392533549 and parameters: {'n_hidden': 4, 'learning_rate': 0.007716606872244542, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1288158628326548, 'dropout_rate_Layer_2': 0.12775779184875183, 'dropout_rate_Layer_3': 0.269830033393182, 'dropout_rate_Layer_4': 0.08233794936612482, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.0889394638221394e-05, 'l1_Layer_2': 1.0371546280961955e-05, 'l1_Layer_3': 3.033781101279001e-05, 'l1_Layer_4': 1.2088321127022558e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 50, 'n_units_Layer_3': 75, 'n_units_Layer_4': 190}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.86 | sMAPE for Validation Set is: 18.55% | rMAE for Validation Set is: 0.99\n",
      "MAE for Test Set is: 79.30 | sMAPE for Test Set is: 28.34% | rMAE for Test Set is: 1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:32:59,820]\u001b[0m Trial 994 finished with value: 25.808257120912078 and parameters: {'n_hidden': 4, 'learning_rate': 0.00777267533973709, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1622725505078092, 'dropout_rate_Layer_2': 0.33820519553621237, 'dropout_rate_Layer_3': 0.3245866436602156, 'dropout_rate_Layer_4': 0.08353966116624002, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 8.880449610520161e-05, 'l1_Layer_2': 1.0022568666681847e-05, 'l1_Layer_3': 2.9502716218272423e-05, 'l1_Layer_4': 1.225139538431045e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 50, 'n_units_Layer_3': 75, 'n_units_Layer_4': 190}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.81 | sMAPE for Validation Set is: 22.11% | rMAE for Validation Set is: 1.23\n",
      "MAE for Test Set is: 94.49 | sMAPE for Test Set is: 33.97% | rMAE for Test Set is: 1.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:33:04,073]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:33:08,627]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:33:12,533]\u001b[0m Trial 986 finished with value: 11.959528812296567 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021766270099727995, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13045872708733852, 'dropout_rate_Layer_2': 0.3064545375442345, 'dropout_rate_Layer_3': 0.034659144803345594, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011461537481385495, 'l1_Layer_2': 0.00021648802087877414, 'l1_Layer_3': 0.008260602847745463, 'n_units_Layer_1': 285, 'n_units_Layer_2': 200, 'n_units_Layer_3': 285}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.96 | sMAPE for Validation Set is: 12.41% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 33.75 | sMAPE for Test Set is: 13.23% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:33:13,348]\u001b[0m Trial 995 finished with value: 23.920260252366518 and parameters: {'n_hidden': 4, 'learning_rate': 0.007824210917801585, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15112390959389402, 'dropout_rate_Layer_2': 0.10645956863055443, 'dropout_rate_Layer_3': 0.3235656532810189, 'dropout_rate_Layer_4': 0.08249873872228035, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 8.0440726111328e-05, 'l1_Layer_2': 1.0237175881366104e-05, 'l1_Layer_3': 3.260899204793597e-05, 'l1_Layer_4': 1.2164098382025866e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 50, 'n_units_Layer_3': 140, 'n_units_Layer_4': 190}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.92 | sMAPE for Validation Set is: 19.85% | rMAE for Validation Set is: 1.14\n",
      "MAE for Test Set is: 106.43 | sMAPE for Test Set is: 39.73% | rMAE for Test Set is: 1.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:33:24,579]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:33:30,733]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:33:32,594]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:33:57,046]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:34:06,709]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:34:11,217]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:34:20,459]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:34:31,443]\u001b[0m Trial 1004 finished with value: 26.97659138583604 and parameters: {'n_hidden': 4, 'learning_rate': 0.009287592881667788, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1504083984402997, 'dropout_rate_Layer_2': 0.11901357304512927, 'dropout_rate_Layer_3': 0.32982697936122335, 'dropout_rate_Layer_4': 0.10870031514906828, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00013252614808579845, 'l1_Layer_2': 1.2458794134613839e-05, 'l1_Layer_3': 4.0702378030756374e-05, 'l1_Layer_4': 1.3598996058248998e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 65, 'n_units_Layer_3': 155, 'n_units_Layer_4': 195}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.98 | sMAPE for Validation Set is: 22.77% | rMAE for Validation Set is: 1.28\n",
      "MAE for Test Set is: 99.45 | sMAPE for Test Set is: 36.64% | rMAE for Test Set is: 1.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:34:38,439]\u001b[0m Trial 999 finished with value: 12.253903744908909 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020225192442663528, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12241827949622573, 'dropout_rate_Layer_2': 0.2955742694599566, 'dropout_rate_Layer_3': 0.1061177143857703, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010975123688001934, 'l1_Layer_2': 0.0005096260835408617, 'l1_Layer_3': 0.009356936710958944, 'n_units_Layer_1': 65, 'n_units_Layer_2': 220, 'n_units_Layer_3': 55}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.25 | sMAPE for Validation Set is: 12.81% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 35.14 | sMAPE for Test Set is: 13.48% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:34:38,691]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:34:58,771]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:35:02,586]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:35:06,805]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:35:26,882]\u001b[0m Trial 1013 finished with value: 12.596040500022847 and parameters: {'n_hidden': 3, 'learning_rate': 0.001951805496662481, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14560983765655708, 'dropout_rate_Layer_2': 0.07229423280571855, 'dropout_rate_Layer_3': 0.0890594840323687, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006594070196142471, 'l1_Layer_2': 0.00011403908747742333, 'l1_Layer_3': 0.0075769686682144255, 'n_units_Layer_1': 295, 'n_units_Layer_2': 130, 'n_units_Layer_3': 290}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.60 | sMAPE for Validation Set is: 13.11% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 37.17 | sMAPE for Test Set is: 14.14% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:35:30,908]\u001b[0m Trial 1008 finished with value: 20.93796851181229 and parameters: {'n_hidden': 4, 'learning_rate': 0.008401191448253862, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13964867349924368, 'dropout_rate_Layer_2': 0.12300612560071486, 'dropout_rate_Layer_3': 0.2656193093907146, 'dropout_rate_Layer_4': 0.10133106601776957, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00012701504987921032, 'l1_Layer_2': 1.2423937271618583e-05, 'l1_Layer_3': 2.348495022501678e-05, 'l1_Layer_4': 1.3849217849078748e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 65, 'n_units_Layer_3': 150, 'n_units_Layer_4': 195}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.94 | sMAPE for Validation Set is: 18.68% | rMAE for Validation Set is: 0.99\n",
      "MAE for Test Set is: 71.34 | sMAPE for Test Set is: 25.74% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:35:34,303]\u001b[0m Trial 1011 finished with value: 24.34150483228197 and parameters: {'n_hidden': 4, 'learning_rate': 0.008286950112950324, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13701772385614253, 'dropout_rate_Layer_2': 0.12615857233434874, 'dropout_rate_Layer_3': 0.33540099341171237, 'dropout_rate_Layer_4': 0.10406136468337124, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 8.389131931868002e-05, 'l1_Layer_2': 1.2217250527394108e-05, 'l1_Layer_3': 2.5694730123800898e-05, 'l1_Layer_4': 1.2048209477894134e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 60, 'n_units_Layer_3': 185, 'n_units_Layer_4': 190}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.34 | sMAPE for Validation Set is: 21.26% | rMAE for Validation Set is: 1.16\n",
      "MAE for Test Set is: 80.16 | sMAPE for Test Set is: 28.33% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:35:35,432]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:35:36,625]\u001b[0m Trial 1014 finished with value: 12.604854954367909 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014242810308724345, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15207948888087067, 'dropout_rate_Layer_2': 0.06869533251158005, 'dropout_rate_Layer_3': 0.021273258257599736, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0068933008149048534, 'l1_Layer_2': 0.00011021933106843167, 'l1_Layer_3': 0.007255503292410388, 'n_units_Layer_1': 295, 'n_units_Layer_2': 130, 'n_units_Layer_3': 290}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.60 | sMAPE for Validation Set is: 12.95% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 36.46 | sMAPE for Test Set is: 14.01% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:35:45,285]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:35:51,089]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:35:57,862]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:36:02,908]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:36:09,472]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:36:17,874]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:36:22,083]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:36:27,038]\u001b[0m Trial 1017 finished with value: 25.642525684926756 and parameters: {'n_hidden': 4, 'learning_rate': 0.009746315347117738, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14821953794363826, 'dropout_rate_Layer_2': 0.13920622313300482, 'dropout_rate_Layer_3': 0.3301218753092546, 'dropout_rate_Layer_4': 0.09940275400399821, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 9.583104093373207e-05, 'l1_Layer_2': 1.2288503272492421e-05, 'l1_Layer_3': 3.357835772631204e-05, 'l1_Layer_4': 1.4197709643672326e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 70, 'n_units_Layer_3': 175, 'n_units_Layer_4': 185}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.64 | sMAPE for Validation Set is: 21.88% | rMAE for Validation Set is: 1.22\n",
      "MAE for Test Set is: 99.06 | sMAPE for Test Set is: 36.56% | rMAE for Test Set is: 1.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:36:42,685]\u001b[0m Trial 1026 finished with value: 11.587350262219237 and parameters: {'n_hidden': 3, 'learning_rate': 0.0040156859450183255, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15036965664806398, 'dropout_rate_Layer_2': 0.017571436174524658, 'dropout_rate_Layer_3': 0.36827119522194063, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00021552552761777024, 'l1_Layer_2': 1.5641104681628544e-05, 'l1_Layer_3': 0.000251153756708213, 'n_units_Layer_1': 130, 'n_units_Layer_2': 190, 'n_units_Layer_3': 295}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.59 | sMAPE for Validation Set is: 11.87% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 31.51 | sMAPE for Test Set is: 12.44% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:36:46,155]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:36:52,634]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:36:53,117]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:37:01,816]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:37:04,499]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:37:11,716]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:37:14,618]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:37:20,548]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:37:23,750]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:37:31,124]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:37:31,578]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:37:39,728]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:37:46,599]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:37:51,432]\u001b[0m Trial 1027 finished with value: 22.518125412921446 and parameters: {'n_hidden': 4, 'learning_rate': 0.007108738390877142, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16487388064373085, 'dropout_rate_Layer_2': 0.11841471482416747, 'dropout_rate_Layer_3': 0.3224452035436667, 'dropout_rate_Layer_4': 0.06966139571961394, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000156785540034996, 'l1_Layer_2': 1.2874791375398092e-05, 'l1_Layer_3': 2.6369403107200155e-05, 'l1_Layer_4': 1.187413759433845e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 60, 'n_units_Layer_3': 175, 'n_units_Layer_4': 190}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.52 | sMAPE for Validation Set is: 19.08% | rMAE for Validation Set is: 1.07\n",
      "MAE for Test Set is: 95.10 | sMAPE for Test Set is: 34.16% | rMAE for Test Set is: 1.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:37:51,959]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:38:09,811]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:38:14,511]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:38:18,844]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:38:32,582]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:38:32,605]\u001b[0m Trial 1037 finished with value: 20.6811737639056 and parameters: {'n_hidden': 4, 'learning_rate': 0.007978538952891353, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14852912163280882, 'dropout_rate_Layer_2': 0.10818431350724186, 'dropout_rate_Layer_3': 0.30602108459908745, 'dropout_rate_Layer_4': 0.0815115391378449, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00010746084552964729, 'l1_Layer_2': 1.1804348346897911e-05, 'l1_Layer_3': 3.420083777975233e-05, 'l1_Layer_4': 1.1980033610848587e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 60, 'n_units_Layer_3': 145, 'n_units_Layer_4': 195}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.68 | sMAPE for Validation Set is: 18.25% | rMAE for Validation Set is: 0.98\n",
      "MAE for Test Set is: 76.14 | sMAPE for Test Set is: 26.96% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:38:38,824]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:38:39,340]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:38:41,502]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:38:47,035]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:38:53,823]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:38:54,906]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:39:01,263]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:39:01,996]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:39:04,017]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:39:15,005]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:39:17,755]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:39:24,940]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:39:30,421]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:39:37,547]\u001b[0m Trial 1056 finished with value: 40.87711300323351 and parameters: {'n_hidden': 4, 'learning_rate': 0.008931633327214384, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16115010819669404, 'dropout_rate_Layer_2': 0.11023034030042883, 'dropout_rate_Layer_3': 0.32131228230232955, 'dropout_rate_Layer_4': 0.08806518042040931, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00012706033608178495, 'l1_Layer_2': 1.0013322721172597e-05, 'l1_Layer_3': 2.3917238359435022e-05, 'l1_Layer_4': 1.2517287769440488e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 50, 'n_units_Layer_3': 180, 'n_units_Layer_4': 200}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 40.88 | sMAPE for Validation Set is: 31.47% | rMAE for Validation Set is: 1.94\n",
      "MAE for Test Set is: 160.33 | sMAPE for Test Set is: 70.36% | rMAE for Test Set is: 2.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:39:41,043]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:39:46,027]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:39:48,811]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:39:52,827]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:39:55,645]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:40:02,006]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:40:08,064]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:40:11,617]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:40:15,253]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:40:47,638]\u001b[0m Trial 1068 finished with value: 65.84437493594221 and parameters: {'n_hidden': 4, 'learning_rate': 0.03563051897908839, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3581404155879743, 'dropout_rate_Layer_2': 0.2373145787935855, 'dropout_rate_Layer_3': 0.3698111565424219, 'dropout_rate_Layer_4': 0.09433349062944844, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.013234726345380242, 'l1_Layer_2': 3.098571781121892e-05, 'l1_Layer_3': 0.01350153751367659, 'l1_Layer_4': 6.760512042470501e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 195, 'n_units_Layer_3': 155, 'n_units_Layer_4': 230}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 65.84 | sMAPE for Validation Set is: 58.90% | rMAE for Validation Set is: 3.13\n",
      "MAE for Test Set is: 229.13 | sMAPE for Test Set is: 126.30% | rMAE for Test Set is: 3.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:40:48,646]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:40:55,872]\u001b[0m Trial 1067 finished with value: 26.559656157271593 and parameters: {'n_hidden': 4, 'learning_rate': 0.008226915637224864, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1527444627112805, 'dropout_rate_Layer_2': 0.11767195361623939, 'dropout_rate_Layer_3': 0.3609936780360925, 'dropout_rate_Layer_4': 0.10036100277676434, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 6.208513756967607e-05, 'l1_Layer_2': 1.4040682417128173e-05, 'l1_Layer_3': 2.8576057880434758e-05, 'l1_Layer_4': 1.0043663175694471e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 70, 'n_units_Layer_3': 145, 'n_units_Layer_4': 195}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.56 | sMAPE for Validation Set is: 22.25% | rMAE for Validation Set is: 1.26\n",
      "MAE for Test Set is: 88.42 | sMAPE for Test Set is: 32.41% | rMAE for Test Set is: 1.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:41:00,107]\u001b[0m Trial 1071 finished with value: 24.695942301945536 and parameters: {'n_hidden': 4, 'learning_rate': 0.00795596186227061, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14958972990661454, 'dropout_rate_Layer_2': 0.12337758708135198, 'dropout_rate_Layer_3': 0.30611174081750037, 'dropout_rate_Layer_4': 0.10022716048366176, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 6.164314473599357e-05, 'l1_Layer_2': 1.4142313115323564e-05, 'l1_Layer_3': 2.7953787105565175e-05, 'l1_Layer_4': 1.555087805447211e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 50, 'n_units_Layer_3': 140, 'n_units_Layer_4': 195}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.70 | sMAPE for Validation Set is: 21.03% | rMAE for Validation Set is: 1.17\n",
      "MAE for Test Set is: 99.42 | sMAPE for Test Set is: 36.65% | rMAE for Test Set is: 1.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:41:00,811]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:41:05,635]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:41:13,660]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:41:13,985]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:41:14,237]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:41:20,832]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:41:24,650]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:41:28,506]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:41:33,307]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:41:44,548]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:41:44,832]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:41:54,136]\u001b[0m Trial 1072 finished with value: 22.779471428443156 and parameters: {'n_hidden': 4, 'learning_rate': 0.006498978188762999, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15211382496053644, 'dropout_rate_Layer_2': 0.12237417135661478, 'dropout_rate_Layer_3': 0.2658299793254763, 'dropout_rate_Layer_4': 0.07919938342160412, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.9712125068813874e-05, 'l1_Layer_2': 1.4597336396030651e-05, 'l1_Layer_3': 4.790543175820001e-05, 'l1_Layer_4': 1.6253812489659162e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 70, 'n_units_Layer_3': 170, 'n_units_Layer_4': 195}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.78 | sMAPE for Validation Set is: 20.91% | rMAE for Validation Set is: 1.08\n",
      "MAE for Test Set is: 77.97 | sMAPE for Test Set is: 27.78% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:41:57,289]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:42:02,175]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:42:08,621]\u001b[0m Trial 1084 finished with value: 61.153048837393584 and parameters: {'n_hidden': 4, 'learning_rate': 0.006274639945206814, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.350001803420858, 'dropout_rate_Layer_2': 0.37039336686412244, 'dropout_rate_Layer_3': 0.3677440241959147, 'dropout_rate_Layer_4': 0.09081856542772469, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.011030767702017013, 'l1_Layer_2': 7.091663930095497e-05, 'l1_Layer_3': 0.0006079623875289996, 'l1_Layer_4': 0.0005761695389675745, 'n_units_Layer_1': 300, 'n_units_Layer_2': 235, 'n_units_Layer_3': 190, 'n_units_Layer_4': 245}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 61.15 | sMAPE for Validation Set is: 52.08% | rMAE for Validation Set is: 2.90\n",
      "MAE for Test Set is: 222.15 | sMAPE for Test Set is: 119.64% | rMAE for Test Set is: 3.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:42:09,395]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:42:09,820]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:42:24,676]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:42:30,057]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:42:39,052]\u001b[0m Trial 1091 finished with value: 18.497826735267424 and parameters: {'n_hidden': 4, 'learning_rate': 0.012266214806715602, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39944567202415016, 'dropout_rate_Layer_2': 0.3737388231375141, 'dropout_rate_Layer_3': 0.39670643509455944, 'dropout_rate_Layer_4': 0.09257537076545366, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0189577059582677, 'l1_Layer_2': 3.4468073643446555e-05, 'l1_Layer_3': 0.005255902909347231, 'l1_Layer_4': 0.0016004200800779158, 'n_units_Layer_1': 295, 'n_units_Layer_2': 225, 'n_units_Layer_3': 130, 'n_units_Layer_4': 200}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.50 | sMAPE for Validation Set is: 18.04% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 52.07 | sMAPE for Test Set is: 18.83% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:42:46,127]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:42:51,290]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:42:52,170]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:42:53,165]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:43:00,238]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:43:07,243]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:43:12,350]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:43:19,229]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:43:24,176]\u001b[0m Trial 1098 finished with value: 15.00821375134715 and parameters: {'n_hidden': 4, 'learning_rate': 0.004512043791712878, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3577012989114408, 'dropout_rate_Layer_2': 0.31168564641808016, 'dropout_rate_Layer_3': 0.3704474212685638, 'dropout_rate_Layer_4': 0.09698063337010122, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.005193933524395478, 'l1_Layer_2': 5.588516509535493e-05, 'l1_Layer_3': 0.0028940843955793725, 'l1_Layer_4': 0.0005897833802436928, 'n_units_Layer_1': 280, 'n_units_Layer_2': 230, 'n_units_Layer_3': 130, 'n_units_Layer_4': 250}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.01 | sMAPE for Validation Set is: 15.66% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 42.10 | sMAPE for Test Set is: 16.27% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:43:27,710]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:43:29,504]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:43:36,154]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:43:36,910]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:43:40,480]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:43:45,560]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:43:50,022]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:43:51,106]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:43:59,421]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:44:01,906]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:44:07,265]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:44:07,440]\u001b[0m Trial 1094 finished with value: 11.893273062803672 and parameters: {'n_hidden': 3, 'learning_rate': 0.001970804253903218, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08357355473378758, 'dropout_rate_Layer_2': 0.30970384150601316, 'dropout_rate_Layer_3': 0.10472932050519157, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002112382279479322, 'l1_Layer_2': 0.0011233232372129035, 'l1_Layer_3': 0.0037762313488456465, 'n_units_Layer_1': 70, 'n_units_Layer_2': 215, 'n_units_Layer_3': 95}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.89 | sMAPE for Validation Set is: 12.15% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 32.57 | sMAPE for Test Set is: 12.75% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:44:15,985]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:44:21,925]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:44:26,728]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:44:27,569]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:44:36,460]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:44:41,673]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:44:44,833]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:44:55,195]\u001b[0m Trial 1109 finished with value: 12.233275415120403 and parameters: {'n_hidden': 3, 'learning_rate': 0.002064691074927559, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08328498953860743, 'dropout_rate_Layer_2': 0.30630177457937624, 'dropout_rate_Layer_3': 0.11214933225763218, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011773909736164063, 'l1_Layer_2': 0.00014137749805576762, 'l1_Layer_3': 0.01780278740772996, 'n_units_Layer_1': 65, 'n_units_Layer_2': 220, 'n_units_Layer_3': 95}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.23 | sMAPE for Validation Set is: 12.51% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 35.52 | sMAPE for Test Set is: 13.79% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:44:56,027]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:45:06,597]\u001b[0m Trial 1114 finished with value: 21.68784595200913 and parameters: {'n_hidden': 4, 'learning_rate': 0.009333799934104827, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1530377320753512, 'dropout_rate_Layer_2': 0.1481562970226394, 'dropout_rate_Layer_3': 0.3348292177687505, 'dropout_rate_Layer_4': 0.08931147362117348, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.899400023214741e-05, 'l1_Layer_2': 1.2732654754708848e-05, 'l1_Layer_3': 3.9336526407491474e-05, 'l1_Layer_4': 1.3871549815241414e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 70, 'n_units_Layer_3': 150, 'n_units_Layer_4': 190}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.69 | sMAPE for Validation Set is: 19.44% | rMAE for Validation Set is: 1.03\n",
      "MAE for Test Set is: 80.67 | sMAPE for Test Set is: 28.95% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:45:11,987]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:45:15,529]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:45:15,871]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:45:20,586]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:45:23,758]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:45:29,708]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:45:31,616]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:45:33,126]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:45:38,576]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:45:41,913]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:45:44,420]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:45:44,519]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:45:47,001]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:45:57,817]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:46:01,655]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:46:16,434]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:46:23,258]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:46:23,829]\u001b[0m Trial 1138 finished with value: 16.364314176428028 and parameters: {'n_hidden': 4, 'learning_rate': 0.004800594186533342, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34508650417766257, 'dropout_rate_Layer_2': 0.308952136471363, 'dropout_rate_Layer_3': 0.3587461536162353, 'dropout_rate_Layer_4': 0.11119916437858504, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0065122673912356805, 'l1_Layer_2': 0.00019559577826076927, 'l1_Layer_3': 0.08555773800474964, 'l1_Layer_4': 8.548766316592486e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 195, 'n_units_Layer_3': 150, 'n_units_Layer_4': 255}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.36 | sMAPE for Validation Set is: 16.94% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 46.40 | sMAPE for Test Set is: 18.14% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:46:30,093]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:46:31,195]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:46:31,545]\u001b[0m Trial 1133 finished with value: 11.805352220162334 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019579216437499605, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12721467353015797, 'dropout_rate_Layer_2': 0.30081373836778275, 'dropout_rate_Layer_3': 0.10065518342899794, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011178274965193259, 'l1_Layer_2': 0.0010669769854844216, 'l1_Layer_3': 0.003954980336616063, 'n_units_Layer_1': 65, 'n_units_Layer_2': 220, 'n_units_Layer_3': 115}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.81 | sMAPE for Validation Set is: 12.21% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 32.33 | sMAPE for Test Set is: 12.71% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:46:32,412]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:46:42,628]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:46:43,123]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:46:44,370]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:46:51,311]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:46:52,872]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:46:55,820]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:46:56,482]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:46:57,550]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:46:58,553]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:47:06,950]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:47:19,728]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:47:24,304]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:47:31,548]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:47:39,489]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:47:46,351]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:47:49,654]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:47:57,458]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:48:00,813]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:48:06,698]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:48:09,969]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:48:15,407]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:48:18,920]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:48:24,712]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:48:27,946]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.59 | sMAPE for Validation Set is: 21.42% | rMAE for Validation Set is: 1.22\n",
      "MAE for Test Set is: 101.58 | sMAPE for Test Set is: 37.95% | rMAE for Test Set is: 1.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:48:31,008]\u001b[0m Trial 1155 finished with value: 25.594459341828827 and parameters: {'n_hidden': 4, 'learning_rate': 0.0083837717093177, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12522873520715888, 'dropout_rate_Layer_2': 0.12201811611740791, 'dropout_rate_Layer_3': 0.24437098822411482, 'dropout_rate_Layer_4': 0.09425148249030724, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 6.572909969034292e-05, 'l1_Layer_2': 1.6307356343601922e-05, 'l1_Layer_3': 1.8713302640113306e-05, 'l1_Layer_4': 1.174641447538222e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 50, 'n_units_Layer_3': 190, 'n_units_Layer_4': 190}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:48:33,219]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:48:34,214]\u001b[0m Trial 1157 finished with value: 22.46777427616954 and parameters: {'n_hidden': 4, 'learning_rate': 0.007847932960278824, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1603293573476496, 'dropout_rate_Layer_2': 0.12249823316951683, 'dropout_rate_Layer_3': 0.24787235641935168, 'dropout_rate_Layer_4': 0.09434908100624509, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 6.962601575837414e-05, 'l1_Layer_2': 1.002962440082272e-05, 'l1_Layer_3': 1.9285250136215952e-05, 'l1_Layer_4': 1.526828875975202e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 80, 'n_units_Layer_3': 130, 'n_units_Layer_4': 185}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.47 | sMAPE for Validation Set is: 19.86% | rMAE for Validation Set is: 1.07\n",
      "MAE for Test Set is: 81.36 | sMAPE for Test Set is: 28.64% | rMAE for Test Set is: 1.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:48:37,325]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:48:41,664]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:48:49,587]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:48:54,231]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:48:54,678]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:49:04,529]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:49:07,411]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:49:13,830]\u001b[0m Trial 1174 finished with value: 12.365612187181327 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019348536424224495, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1354564815538201, 'dropout_rate_Layer_2': 0.30387146578447644, 'dropout_rate_Layer_3': 0.10646412687423532, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012697846645998113, 'l1_Layer_2': 0.00015867243691521711, 'l1_Layer_3': 0.004124073919988945, 'n_units_Layer_1': 65, 'n_units_Layer_2': 230, 'n_units_Layer_3': 115}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.37 | sMAPE for Validation Set is: 12.90% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 34.97 | sMAPE for Test Set is: 13.61% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:49:14,168]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:49:14,471]\u001b[0m Trial 1175 finished with value: 12.350636243465004 and parameters: {'n_hidden': 3, 'learning_rate': 0.001994541537343751, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08874153063789822, 'dropout_rate_Layer_2': 0.3023541041579928, 'dropout_rate_Layer_3': 0.060038810341121976, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001175889070566718, 'l1_Layer_2': 0.00014895654153585061, 'l1_Layer_3': 0.008448176669292633, 'n_units_Layer_1': 65, 'n_units_Layer_2': 250, 'n_units_Layer_3': 120}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.35 | sMAPE for Validation Set is: 12.87% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 32.88 | sMAPE for Test Set is: 13.02% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:49:14,631]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:49:23,559]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:49:25,764]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:49:26,566]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:49:29,923]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:49:40,122]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:49:40,705]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:49:48,200]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:49:52,577]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:49:58,121]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:49:58,785]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:50:04,894]\u001b[0m Trial 1189 finished with value: 15.467558022983916 and parameters: {'n_hidden': 4, 'learning_rate': 0.004439257085490201, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.331969015819436, 'dropout_rate_Layer_2': 0.31533321673608267, 'dropout_rate_Layer_3': 0.3790251599517242, 'dropout_rate_Layer_4': 0.23705135986444759, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00112497119431646, 'l1_Layer_2': 1.8680177022038874e-05, 'l1_Layer_3': 0.0008655016286199417, 'l1_Layer_4': 0.0005512404430843274, 'n_units_Layer_1': 265, 'n_units_Layer_2': 160, 'n_units_Layer_3': 130, 'n_units_Layer_4': 255}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.47 | sMAPE for Validation Set is: 15.63% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 48.45 | sMAPE for Test Set is: 17.73% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:50:19,558]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:50:24,220]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:50:31,356]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:50:37,872]\u001b[0m Trial 1196 finished with value: 12.485011785025923 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026160130775462623, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11308898617538345, 'dropout_rate_Layer_2': 0.3152575845903803, 'dropout_rate_Layer_3': 0.08901318485718646, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00019879302471009075, 'l1_Layer_2': 0.00025400749759996676, 'l1_Layer_3': 0.017840559128648886, 'n_units_Layer_1': 50, 'n_units_Layer_2': 220, 'n_units_Layer_3': 140}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.49 | sMAPE for Validation Set is: 13.21% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 33.19 | sMAPE for Test Set is: 12.88% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:50:54,494]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:51:01,500]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:51:06,347]\u001b[0m Trial 1197 finished with value: 11.872046915246122 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016241504150891514, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11430952660869695, 'dropout_rate_Layer_2': 0.3204602605412432, 'dropout_rate_Layer_3': 0.08724168548998573, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002064737488970764, 'l1_Layer_2': 0.0011383589465280171, 'l1_Layer_3': 0.0024096365027321503, 'n_units_Layer_1': 50, 'n_units_Layer_2': 220, 'n_units_Layer_3': 135}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.87 | sMAPE for Validation Set is: 12.08% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 32.33 | sMAPE for Test Set is: 12.64% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:51:10,762]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:51:15,500]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:51:18,797]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:51:21,432]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:51:25,841]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:51:33,814]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:51:37,368]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:51:37,801]\u001b[0m Trial 1200 finished with value: 25.01517030299487 and parameters: {'n_hidden': 4, 'learning_rate': 0.006812880446299438, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15743870976236762, 'dropout_rate_Layer_2': 0.138173866815909, 'dropout_rate_Layer_3': 0.3213686685401344, 'dropout_rate_Layer_4': 0.10704500604693845, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00015522777859679193, 'l1_Layer_2': 1.6129715805514645e-05, 'l1_Layer_3': 2.5024522689668802e-05, 'l1_Layer_4': 1.0047194728471336e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 55, 'n_units_Layer_3': 135, 'n_units_Layer_4': 180}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.02 | sMAPE for Validation Set is: 20.84% | rMAE for Validation Set is: 1.19\n",
      "MAE for Test Set is: 97.87 | sMAPE for Test Set is: 35.40% | rMAE for Test Set is: 1.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:51:43,672]\u001b[0m Trial 1201 finished with value: 24.361723354035913 and parameters: {'n_hidden': 4, 'learning_rate': 0.006903243999785275, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1339088670280121, 'dropout_rate_Layer_2': 0.16549851014629938, 'dropout_rate_Layer_3': 0.3391110897455677, 'dropout_rate_Layer_4': 0.1056365297016299, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 6.462540059576764e-05, 'l1_Layer_2': 1.5384355472689184e-05, 'l1_Layer_3': 2.623282494757449e-05, 'l1_Layer_4': 1.5805665669364667e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 55, 'n_units_Layer_3': 180, 'n_units_Layer_4': 200}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.36 | sMAPE for Validation Set is: 21.83% | rMAE for Validation Set is: 1.16\n",
      "MAE for Test Set is: 99.56 | sMAPE for Test Set is: 36.09% | rMAE for Test Set is: 1.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:51:49,367]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:51:57,108]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:52:01,086]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:52:10,431]\u001b[0m Trial 1208 finished with value: 23.94544768795177 and parameters: {'n_hidden': 4, 'learning_rate': 0.008969973043404031, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14040002628150447, 'dropout_rate_Layer_2': 0.3147268289520729, 'dropout_rate_Layer_3': 0.3258848127205355, 'dropout_rate_Layer_4': 0.07510096009426684, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.2859081380921124e-05, 'l1_Layer_2': 1.1815020890114065e-05, 'l1_Layer_3': 1.679399489295751e-05, 'l1_Layer_4': 1.6274487783704654e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 50, 'n_units_Layer_3': 135, 'n_units_Layer_4': 200}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.95 | sMAPE for Validation Set is: 20.32% | rMAE for Validation Set is: 1.14\n",
      "MAE for Test Set is: 99.13 | sMAPE for Test Set is: 36.16% | rMAE for Test Set is: 1.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:52:11,778]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:52:13,431]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:52:23,020]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:52:26,478]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:52:28,544]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:52:35,427]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:52:36,088]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:52:36,149]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:52:45,346]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:52:49,239]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:52:50,739]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:52:57,695]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:53:00,590]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:53:04,940]\u001b[0m Trial 1213 finished with value: 23.290759500125265 and parameters: {'n_hidden': 4, 'learning_rate': 0.005422661289171061, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12803622043220692, 'dropout_rate_Layer_2': 0.12047221754210442, 'dropout_rate_Layer_3': 0.24821305954263764, 'dropout_rate_Layer_4': 0.11264196250296375, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0001462899561756755, 'l1_Layer_2': 1.565444637479452e-05, 'l1_Layer_3': 1.7967148509257388e-05, 'l1_Layer_4': 1.0200667584699945e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 60, 'n_units_Layer_3': 130, 'n_units_Layer_4': 205}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.29 | sMAPE for Validation Set is: 20.76% | rMAE for Validation Set is: 1.11\n",
      "MAE for Test Set is: 73.34 | sMAPE for Test Set is: 25.98% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:53:07,042]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:53:08,480]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:53:15,451]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:53:16,706]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:53:20,914]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:53:27,786]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:53:28,393]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:53:34,342]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:53:36,593]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:53:40,755]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:53:48,920]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:53:54,281]\u001b[0m Trial 1224 finished with value: 23.856524848715996 and parameters: {'n_hidden': 4, 'learning_rate': 0.007139134574415336, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14394400459937146, 'dropout_rate_Layer_2': 0.10522118927639215, 'dropout_rate_Layer_3': 0.33462496171825556, 'dropout_rate_Layer_4': 0.08108900052637566, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.210120581131384e-05, 'l1_Layer_2': 1.1919628776484163e-05, 'l1_Layer_3': 1.784970469729083e-05, 'l1_Layer_4': 1.4120785012389838e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 50, 'n_units_Layer_3': 130, 'n_units_Layer_4': 200}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.86 | sMAPE for Validation Set is: 20.25% | rMAE for Validation Set is: 1.13\n",
      "MAE for Test Set is: 86.77 | sMAPE for Test Set is: 31.58% | rMAE for Test Set is: 1.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:53:58,510]\u001b[0m Trial 1240 finished with value: 63.68905731286416 and parameters: {'n_hidden': 4, 'learning_rate': 0.004367478583425351, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.335774797049157, 'dropout_rate_Layer_2': 0.18973112800130298, 'dropout_rate_Layer_3': 0.3411883269091916, 'dropout_rate_Layer_4': 0.23100537965393597, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.001296965265741425, 'l1_Layer_2': 1.7328939612112438e-05, 'l1_Layer_3': 0.011005477182715754, 'l1_Layer_4': 0.000634536682506147, 'n_units_Layer_1': 265, 'n_units_Layer_2': 155, 'n_units_Layer_3': 135, 'n_units_Layer_4': 260}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 63.69 | sMAPE for Validation Set is: 55.28% | rMAE for Validation Set is: 3.02\n",
      "MAE for Test Set is: 227.36 | sMAPE for Test Set is: 124.88% | rMAE for Test Set is: 3.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:54:05,515]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:54:12,077]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:54:15,387]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:54:19,402]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:54:19,994]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:54:20,120]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.60 | sMAPE for Validation Set is: 11.89% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 33.69 | sMAPE for Test Set is: 13.13% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:54:22,591]\u001b[0m Trial 1243 finished with value: 11.596915489708245 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024967487984772674, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18101462717907882, 'dropout_rate_Layer_2': 0.00638834193587675, 'dropout_rate_Layer_3': 0.016243314380891934, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.545308187767127e-05, 'l1_Layer_2': 0.0026827665297815325, 'l1_Layer_3': 0.00021237657212135413, 'n_units_Layer_1': 170, 'n_units_Layer_2': 245, 'n_units_Layer_3': 290}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:54:32,944]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:54:37,907]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:54:40,973]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:54:45,568]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:54:50,010]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:54:57,671]\u001b[0m Trial 1250 finished with value: 11.719336990617506 and parameters: {'n_hidden': 3, 'learning_rate': 0.002421240330081313, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1829512316645607, 'dropout_rate_Layer_2': 0.008019095307160107, 'dropout_rate_Layer_3': 0.0336218255677299, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013962565797337134, 'l1_Layer_2': 0.002767822847190769, 'l1_Layer_3': 0.00013921548250751215, 'n_units_Layer_1': 155, 'n_units_Layer_2': 195, 'n_units_Layer_3': 290}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.72 | sMAPE for Validation Set is: 11.93% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 33.64 | sMAPE for Test Set is: 13.15% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:54:58,838]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:55:02,227]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:55:02,853]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:55:04,886]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:55:13,030]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:55:30,627]\u001b[0m Trial 1262 finished with value: 13.652618003557516 and parameters: {'n_hidden': 4, 'learning_rate': 0.007542111086517581, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2779384576443532, 'dropout_rate_Layer_2': 0.23075014187388704, 'dropout_rate_Layer_3': 0.37579937024417315, 'dropout_rate_Layer_4': 0.2255473864496628, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0012270030005488105, 'l1_Layer_2': 8.027681397013518e-05, 'l1_Layer_3': 0.002583778183446179, 'l1_Layer_4': 0.0006136554233719959, 'n_units_Layer_1': 240, 'n_units_Layer_2': 165, 'n_units_Layer_3': 150, 'n_units_Layer_4': 190}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.65 | sMAPE for Validation Set is: 13.63% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 41.68 | sMAPE for Test Set is: 15.68% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:55:37,559]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:55:44,464]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:55:55,442]\u001b[0m Trial 1254 finished with value: 23.506443853182944 and parameters: {'n_hidden': 4, 'learning_rate': 0.006653550154362367, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13334651886725885, 'dropout_rate_Layer_2': 0.10664371411061152, 'dropout_rate_Layer_3': 0.363442757191313, 'dropout_rate_Layer_4': 0.12880447751503554, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 6.717063009667054e-05, 'l1_Layer_2': 1.854501280356252e-05, 'l1_Layer_3': 2.5878589385019243e-05, 'l1_Layer_4': 1.9066504738012738e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 60, 'n_units_Layer_3': 140, 'n_units_Layer_4': 200}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.51 | sMAPE for Validation Set is: 20.02% | rMAE for Validation Set is: 1.12\n",
      "MAE for Test Set is: 83.06 | sMAPE for Test Set is: 29.18% | rMAE for Test Set is: 1.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:56:01,890]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:56:06,978]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 61.49 | sMAPE for Validation Set is: 52.27% | rMAE for Validation Set is: 2.92\n",
      "MAE for Test Set is: 224.13 | sMAPE for Test Set is: 121.64% | rMAE for Test Set is: 3.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:56:10,507]\u001b[0m Trial 1265 finished with value: 61.49435990156852 and parameters: {'n_hidden': 4, 'learning_rate': 0.008008972825665405, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2584693002829027, 'dropout_rate_Layer_2': 0.21945039828126914, 'dropout_rate_Layer_3': 0.3303866009077734, 'dropout_rate_Layer_4': 0.03900644781740681, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0007109925390911675, 'l1_Layer_2': 7.080533623991736e-05, 'l1_Layer_3': 0.0028294119443191424, 'l1_Layer_4': 0.0025506386774772874, 'n_units_Layer_1': 235, 'n_units_Layer_2': 180, 'n_units_Layer_3': 160, 'n_units_Layer_4': 190}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:56:16,114]\u001b[0m Trial 1259 finished with value: 24.762130356669644 and parameters: {'n_hidden': 4, 'learning_rate': 0.007698091159103925, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12364700395600997, 'dropout_rate_Layer_2': 0.12118325195730724, 'dropout_rate_Layer_3': 0.34427575535618726, 'dropout_rate_Layer_4': 0.1265041095947013, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 9.434022274706342e-05, 'l1_Layer_2': 1.1858648307403905e-05, 'l1_Layer_3': 4.6484649898190904e-05, 'l1_Layer_4': 1.7262123338851893e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 50, 'n_units_Layer_3': 140, 'n_units_Layer_4': 200}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.76 | sMAPE for Validation Set is: 21.01% | rMAE for Validation Set is: 1.18\n",
      "MAE for Test Set is: 78.20 | sMAPE for Test Set is: 28.00% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:56:16,423]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:56:19,167]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:56:27,032]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:56:27,659]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:56:35,578]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:56:42,650]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:56:48,207]\u001b[0m Trial 1274 finished with value: 61.81116288505675 and parameters: {'n_hidden': 4, 'learning_rate': 0.009314579238402388, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37198102124469834, 'dropout_rate_Layer_2': 0.11126096369943796, 'dropout_rate_Layer_3': 0.3559354579857135, 'dropout_rate_Layer_4': 0.2933660484720176, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0016741377510516462, 'l1_Layer_2': 0.0002144750592557228, 'l1_Layer_3': 0.0011740533505106114, 'l1_Layer_4': 0.005454477649446945, 'n_units_Layer_1': 245, 'n_units_Layer_2': 135, 'n_units_Layer_3': 185, 'n_units_Layer_4': 175}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 61.81 | sMAPE for Validation Set is: 52.32% | rMAE for Validation Set is: 2.93\n",
      "MAE for Test Set is: 224.74 | sMAPE for Test Set is: 122.15% | rMAE for Test Set is: 3.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:56:50,833]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:56:52,962]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:57:02,289]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:57:09,232]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:57:15,782]\u001b[0m Trial 1261 finished with value: 11.770525934585203 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014801209593444502, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06153591986054324, 'dropout_rate_Layer_2': 0.292972746003593, 'dropout_rate_Layer_3': 0.04489703470764195, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.742836649928941e-05, 'l1_Layer_2': 0.0009805563820937107, 'l1_Layer_3': 0.0015333320161076366, 'n_units_Layer_1': 70, 'n_units_Layer_2': 225, 'n_units_Layer_3': 100}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.77 | sMAPE for Validation Set is: 12.11% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 31.18 | sMAPE for Test Set is: 12.44% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:57:16,935]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:57:27,952]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:57:28,461]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:57:38,073]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:57:43,226]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:57:54,964]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:57:59,528]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:58:03,162]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:58:08,224]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:58:10,535]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:58:13,029]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:58:19,818]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:58:20,235]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:58:30,694]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:58:31,051]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:58:41,324]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:58:43,125]\u001b[0m Trial 1287 finished with value: 23.38910577023717 and parameters: {'n_hidden': 4, 'learning_rate': 0.007042356248011231, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1254523742640483, 'dropout_rate_Layer_2': 0.12780036091996, 'dropout_rate_Layer_3': 0.24287734717149248, 'dropout_rate_Layer_4': 0.06131014071533305, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.1726015681525223e-05, 'l1_Layer_2': 1.8848415891334503e-05, 'l1_Layer_3': 1.5769941201228182e-05, 'l1_Layer_4': 1.579131231143609e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 65, 'n_units_Layer_3': 135, 'n_units_Layer_4': 195}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.39 | sMAPE for Validation Set is: 20.00% | rMAE for Validation Set is: 1.11\n",
      "MAE for Test Set is: 93.20 | sMAPE for Test Set is: 33.41% | rMAE for Test Set is: 1.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:58:50,273]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:58:50,521]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.71 | sMAPE for Validation Set is: 11.94% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 32.85 | sMAPE for Test Set is: 12.89% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:58:56,718]\u001b[0m Trial 1277 finished with value: 11.705128053224731 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013862381119007703, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.063250251819615, 'dropout_rate_Layer_2': 0.2976642755573521, 'dropout_rate_Layer_3': 0.07903731443245367, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.739431783558395e-05, 'l1_Layer_2': 0.0006220386828220422, 'l1_Layer_3': 0.0016411907668926456, 'n_units_Layer_1': 70, 'n_units_Layer_2': 230, 'n_units_Layer_3': 95}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.97 | sMAPE for Validation Set is: 14.24% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 40.06 | sMAPE for Test Set is: 15.34% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:58:57,260]\u001b[0m Trial 1296 finished with value: 13.974596555068729 and parameters: {'n_hidden': 4, 'learning_rate': 0.006114591568934739, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.285372494676683, 'dropout_rate_Layer_2': 0.010021294690231441, 'dropout_rate_Layer_3': 0.377233552403326, 'dropout_rate_Layer_4': 0.20638671104579398, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.004579194184820226, 'l1_Layer_2': 0.00010865672567659965, 'l1_Layer_3': 0.002423356072694232, 'l1_Layer_4': 9.420171499417713e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 170, 'n_units_Layer_3': 220, 'n_units_Layer_4': 205}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:59:08,427]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:59:11,935]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:59:12,144]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:59:23,161]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:59:26,120]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:59:36,215]\u001b[0m Trial 1307 finished with value: 74.655936816494 and parameters: {'n_hidden': 4, 'learning_rate': 0.04844360530210966, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27618248198460577, 'dropout_rate_Layer_2': 0.16220969213121322, 'dropout_rate_Layer_3': 0.28285805457835433, 'dropout_rate_Layer_4': 0.20645165042267147, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005984989989867678, 'l1_Layer_2': 0.0010973147948519376, 'l1_Layer_3': 0.02020845721755834, 'l1_Layer_4': 9.137788698376789e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 130, 'n_units_Layer_3': 235, 'n_units_Layer_4': 200}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 74.66 | sMAPE for Validation Set is: 74.66% | rMAE for Validation Set is: 3.54\n",
      "MAE for Test Set is: 219.26 | sMAPE for Test Set is: 100.05% | rMAE for Test Set is: 3.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:59:44,946]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:59:47,451]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:59:49,750]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:59:57,229]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:00:04,049]\u001b[0m Trial 1301 finished with value: 20.660388320588975 and parameters: {'n_hidden': 4, 'learning_rate': 0.00657743405967333, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11709939020285728, 'dropout_rate_Layer_2': 0.150370653536495, 'dropout_rate_Layer_3': 0.23326564172576641, 'dropout_rate_Layer_4': 0.05290635154583752, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.2453006348561076e-05, 'l1_Layer_2': 1.8073052009376316e-05, 'l1_Layer_3': 1.3309148709544747e-05, 'l1_Layer_4': 1.1371719461314841e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 65, 'n_units_Layer_3': 130, 'n_units_Layer_4': 205}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.66 | sMAPE for Validation Set is: 18.73% | rMAE for Validation Set is: 0.98\n",
      "MAE for Test Set is: 83.77 | sMAPE for Test Set is: 29.42% | rMAE for Test Set is: 1.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 08:00:18,957]\u001b[0m Trial 1313 finished with value: 14.07918463212374 and parameters: {'n_hidden': 4, 'learning_rate': 0.006501454189142756, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32351395754588547, 'dropout_rate_Layer_2': 0.0013003273641990724, 'dropout_rate_Layer_3': 0.37838892265681184, 'dropout_rate_Layer_4': 0.20532465100842173, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0035861295921156377, 'l1_Layer_2': 9.341448890633139e-05, 'l1_Layer_3': 0.002909017932024923, 'l1_Layer_4': 0.0005816372570251214, 'n_units_Layer_1': 285, 'n_units_Layer_2': 210, 'n_units_Layer_3': 220, 'n_units_Layer_4': 225}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.08 | sMAPE for Validation Set is: 14.19% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 41.54 | sMAPE for Test Set is: 15.96% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 08:00:23,811]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:00:30,020]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:00:30,343]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:00:30,721]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:00:37,966]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:00:38,179]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:00:39,478]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:00:51,661]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:00:56,963]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:00:58,499]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:01:03,775]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:01:11,371]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:01:11,473]\u001b[0m Trial 1311 finished with value: 11.974073341572085 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015336642456426428, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06827811606071361, 'dropout_rate_Layer_2': 0.2674314409061228, 'dropout_rate_Layer_3': 0.07485801648429603, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.993694852557365e-05, 'l1_Layer_2': 0.0020247029502702125, 'l1_Layer_3': 0.000950419446750532, 'n_units_Layer_1': 85, 'n_units_Layer_2': 235, 'n_units_Layer_3': 130}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.97 | sMAPE for Validation Set is: 12.22% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 33.75 | sMAPE for Test Set is: 13.27% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 08:01:14,770]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:01:20,937]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:01:24,388]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:01:33,659]\u001b[0m Trial 1327 finished with value: 11.770782798770641 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023849257089141687, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14993590590425762, 'dropout_rate_Layer_2': 0.03788092707136047, 'dropout_rate_Layer_3': 0.04201108619523908, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00034960606560904833, 'l1_Layer_2': 1.757812300751678e-05, 'l1_Layer_3': 0.00019340401880585034, 'n_units_Layer_1': 170, 'n_units_Layer_2': 210, 'n_units_Layer_3': 290}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.77 | sMAPE for Validation Set is: 12.02% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 33.02 | sMAPE for Test Set is: 12.97% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 08:01:39,508]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:01:43,645]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:02:08,230]\u001b[0m Trial 1324 finished with value: 21.453058156727412 and parameters: {'n_hidden': 4, 'learning_rate': 0.006904744076616974, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1267417050905859, 'dropout_rate_Layer_2': 0.18478604517664907, 'dropout_rate_Layer_3': 0.22361362329913168, 'dropout_rate_Layer_4': 0.05776142992893431, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.77922550925495e-05, 'l1_Layer_2': 1.580761036321454e-05, 'l1_Layer_3': 1.4151745291300767e-05, 'l1_Layer_4': 1.709398662296794e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 65, 'n_units_Layer_3': 125, 'n_units_Layer_4': 210}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.45 | sMAPE for Validation Set is: 18.42% | rMAE for Validation Set is: 1.02\n",
      "MAE for Test Set is: 93.11 | sMAPE for Test Set is: 33.28% | rMAE for Test Set is: 1.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 08:02:13,244]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:02:16,889]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:02:19,310]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:02:21,347]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:02:27,621]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:02:31,374]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:02:43,720]\u001b[0m Trial 1337 finished with value: 11.665991631415524 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025698971304760196, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16365695185150048, 'dropout_rate_Layer_2': 0.011154923672775284, 'dropout_rate_Layer_3': 0.03184504893907094, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003228250654412766, 'l1_Layer_2': 0.0019443408436515303, 'l1_Layer_3': 0.00026819203950071124, 'n_units_Layer_1': 175, 'n_units_Layer_2': 210, 'n_units_Layer_3': 295}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.67 | sMAPE for Validation Set is: 11.93% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 32.42 | sMAPE for Test Set is: 12.81% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 08:02:48,673]\u001b[0m Trial 1338 finished with value: 15.302742014810361 and parameters: {'n_hidden': 4, 'learning_rate': 0.010835513823185303, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21759767471060926, 'dropout_rate_Layer_2': 0.0044653436514887545, 'dropout_rate_Layer_3': 0.33836108607135074, 'dropout_rate_Layer_4': 0.20710025872764473, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.003973984837076523, 'l1_Layer_2': 0.00011989194205024545, 'l1_Layer_3': 0.002321020647642213, 'l1_Layer_4': 0.0007537475577536059, 'n_units_Layer_1': 280, 'n_units_Layer_2': 170, 'n_units_Layer_3': 210, 'n_units_Layer_4': 215}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.30 | sMAPE for Validation Set is: 15.18% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 43.13 | sMAPE for Test Set is: 16.53% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 08:02:51,958]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:02:57,890]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:03:00,748]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:03:08,754]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:03:08,997]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:03:15,994]\u001b[0m Trial 1334 finished with value: 20.955825038932996 and parameters: {'n_hidden': 4, 'learning_rate': 0.007705479007834623, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13417429465559183, 'dropout_rate_Layer_2': 0.11915148142691558, 'dropout_rate_Layer_3': 0.2245671881825835, 'dropout_rate_Layer_4': 0.05955313070106983, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.535351443230013e-05, 'l1_Layer_2': 1.583507293209214e-05, 'l1_Layer_3': 1.940915657668352e-05, 'l1_Layer_4': 1.2004603304187268e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 70, 'n_units_Layer_3': 140, 'n_units_Layer_4': 195}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.96 | sMAPE for Validation Set is: 19.58% | rMAE for Validation Set is: 1.00\n",
      "MAE for Test Set is: 76.09 | sMAPE for Test Set is: 26.94% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 08:03:18,956]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:03:25,031]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:03:30,574]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:03:38,313]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:03:40,735]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:03:49,164]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:03:52,337]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:03:53,749]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:04:01,872]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:04:04,371]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:04:05,657]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:04:10,365]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:04:14,341]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:04:17,744]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:04:19,063]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:04:21,205]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:04:26,560]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:04:28,971]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:04:31,704]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:04:36,653]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:04:44,693]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:04:46,857]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:04:49,029]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:04:53,835]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:05:05,031]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:05:08,157]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:05:09,088]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:05:17,661]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:05:20,849]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:05:27,699]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:05:30,556]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:05:32,462]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:05:37,545]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:05:45,261]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:05:48,743]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:05:57,413]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:06:04,316]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:06:11,830]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:06:13,932]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:06:18,971]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:06:22,584]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:06:26,618]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:06:31,476]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:06:42,200]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:06:44,579]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:06:48,246]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:06:50,551]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:06:55,048]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:06:55,354]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:06:58,661]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:07:07,650]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:07:10,042]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:07:10,631]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:07:16,341]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:07:16,562]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:07:23,656]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:07:23,801]\u001b[0m Trial 1400 finished with value: 12.110409801809924 and parameters: {'n_hidden': 3, 'learning_rate': 0.002034153800440927, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18364148116537884, 'dropout_rate_Layer_2': 0.04172045980710357, 'dropout_rate_Layer_3': 0.032837874461615374, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00029213906558356805, 'l1_Layer_2': 1.7087251762290612e-05, 'l1_Layer_3': 0.0001832313655023489, 'n_units_Layer_1': 180, 'n_units_Layer_2': 210, 'n_units_Layer_3': 300}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.11 | sMAPE for Validation Set is: 12.35% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 33.93 | sMAPE for Test Set is: 13.44% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 08:07:27,183]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.82 | sMAPE for Validation Set is: 12.09% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 33.17 | sMAPE for Test Set is: 12.87% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 08:07:32,995]\u001b[0m Trial 1402 finished with value: 11.817119242083871 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020408310971104103, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1271172597068262, 'dropout_rate_Layer_2': 0.0008557907028494162, 'dropout_rate_Layer_3': 0.031351176151620336, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006694768570518703, 'l1_Layer_2': 1.7055623557175653e-05, 'l1_Layer_3': 3.700098589348142e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 205, 'n_units_Layer_3': 300}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:07:37,740]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:07:43,540]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:07:44,674]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:08:03,258]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:08:03,940]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:08:10,810]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:08:13,373]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:08:18,447]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:08:21,896]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:08:27,056]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:08:27,397]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:08:27,744]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:08:31,225]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:08:38,625]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:08:39,184]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:08:41,359]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:08:50,646]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:08:51,422]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:08:52,372]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:08:54,339]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:09:03,683]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:09:11,470]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:09:18,520]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:09:24,842]\u001b[0m Trial 1427 finished with value: 12.806006088070367 and parameters: {'n_hidden': 3, 'learning_rate': 0.004904231629957788, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2354384021350123, 'dropout_rate_Layer_2': 0.14105758368570928, 'dropout_rate_Layer_3': 0.36734895094734377, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0022599266505019234, 'l1_Layer_2': 0.0002919460498229461, 'l1_Layer_3': 0.00024621320965780724, 'n_units_Layer_1': 255, 'n_units_Layer_2': 155, 'n_units_Layer_3': 275}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.81 | sMAPE for Validation Set is: 13.16% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 36.39 | sMAPE for Test Set is: 14.01% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 08:09:25,185]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:09:25,957]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:09:35,375]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:09:37,882]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:09:42,652]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:09:48,281]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:09:59,059]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:10:06,168]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:10:11,622]\u001b[0m Trial 1437 finished with value: 11.587615931828816 and parameters: {'n_hidden': 3, 'learning_rate': 0.003167510366360815, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16551014618355198, 'dropout_rate_Layer_2': 0.009546173448421883, 'dropout_rate_Layer_3': 0.3775599764376267, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004102553839168297, 'l1_Layer_2': 1.4479945866180727e-05, 'l1_Layer_3': 0.0001071896982529472, 'n_units_Layer_1': 165, 'n_units_Layer_2': 190, 'n_units_Layer_3': 270}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.59 | sMAPE for Validation Set is: 11.76% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 31.66 | sMAPE for Test Set is: 12.44% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 08:10:13,248]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:10:21,268]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:10:25,406]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:10:25,876]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:10:35,159]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:10:35,952]\u001b[0m Trial 1442 finished with value: 11.549813802237841 and parameters: {'n_hidden': 3, 'learning_rate': 0.003123996723178383, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1742042413327443, 'dropout_rate_Layer_2': 0.010007971691632839, 'dropout_rate_Layer_3': 0.37413912443028907, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004200151380533223, 'l1_Layer_2': 1.3845933098183852e-05, 'l1_Layer_3': 0.00010257113507174359, 'n_units_Layer_1': 160, 'n_units_Layer_2': 190, 'n_units_Layer_3': 280}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.55 | sMAPE for Validation Set is: 11.86% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 32.70 | sMAPE for Test Set is: 12.88% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 08:10:46,059]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:10:50,761]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:10:57,881]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:10:58,250]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:11:00,157]\u001b[0m Trial 1445 finished with value: 12.26905526101256 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017669061150532587, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12843802273840946, 'dropout_rate_Layer_2': 0.3110798995789335, 'dropout_rate_Layer_3': 0.05461025629146421, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.100274521988098e-05, 'l1_Layer_2': 0.0008927647418183591, 'l1_Layer_3': 0.0015900314367065433, 'n_units_Layer_1': 70, 'n_units_Layer_2': 200, 'n_units_Layer_3': 110}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.27 | sMAPE for Validation Set is: 12.22% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 34.66 | sMAPE for Test Set is: 13.25% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 08:11:09,573]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:11:12,361]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:11:13,911]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:11:20,316]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:11:24,483]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:11:29,840]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:11:30,064]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:11:42,383]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:11:45,372]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:11:53,650]\u001b[0m Trial 1457 finished with value: 11.75340855970507 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028226486058275505, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17467154916966862, 'dropout_rate_Layer_2': 0.027743654939375112, 'dropout_rate_Layer_3': 0.3772645969279554, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002436700712185375, 'l1_Layer_2': 0.0010741320666095323, 'l1_Layer_3': 5.993553084596846e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 190, 'n_units_Layer_3': 260}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.75 | sMAPE for Validation Set is: 12.06% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 34.33 | sMAPE for Test Set is: 13.37% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 08:11:55,671]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:11:58,782]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:12:02,018]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:12:07,482]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:12:08,700]\u001b[0m Trial 1446 finished with value: 12.768433357528245 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017028052291914472, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1321816873083143, 'dropout_rate_Layer_2': 0.31354229699038483, 'dropout_rate_Layer_3': 0.12323902052679939, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.4259122941258274e-05, 'l1_Layer_2': 0.0049533097723148956, 'l1_Layer_3': 0.006636810444287648, 'n_units_Layer_1': 70, 'n_units_Layer_2': 190, 'n_units_Layer_3': 105}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.77 | sMAPE for Validation Set is: 13.08% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 35.23 | sMAPE for Test Set is: 13.68% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 08:12:18,228]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:12:18,796]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:12:24,996]\u001b[0m Trial 1464 finished with value: 14.32175594303195 and parameters: {'n_hidden': 4, 'learning_rate': 0.006741082708550543, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27884063319514674, 'dropout_rate_Layer_2': 0.012112675118972866, 'dropout_rate_Layer_3': 0.3720200388274021, 'dropout_rate_Layer_4': 0.27009208039368804, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0051287252749330475, 'l1_Layer_2': 7.394963827858447e-05, 'l1_Layer_3': 0.00820453724790078, 'l1_Layer_4': 0.00011486153851067664, 'n_units_Layer_1': 230, 'n_units_Layer_2': 210, 'n_units_Layer_3': 245, 'n_units_Layer_4': 190}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.32 | sMAPE for Validation Set is: 14.29% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 41.44 | sMAPE for Test Set is: 15.59% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 08:12:25,093]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:12:32,950]\u001b[0m Trial 1460 finished with value: 23.844616035269627 and parameters: {'n_hidden': 4, 'learning_rate': 0.006639671017789829, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.127982780224159, 'dropout_rate_Layer_2': 0.10285310499535011, 'dropout_rate_Layer_3': 0.2106785295389922, 'dropout_rate_Layer_4': 0.09614746817916986, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00010557107891198172, 'l1_Layer_2': 1.1679263075036003e-05, 'l1_Layer_3': 2.4745481580746196e-05, 'l1_Layer_4': 1.3895603079781436e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 70, 'n_units_Layer_3': 135, 'n_units_Layer_4': 210}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.84 | sMAPE for Validation Set is: 19.37% | rMAE for Validation Set is: 1.13\n",
      "MAE for Test Set is: 99.18 | sMAPE for Test Set is: 35.94% | rMAE for Test Set is: 1.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 08:12:34,959]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:12:37,319]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:12:41,860]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:12:48,116]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:12:50,204]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:12:54,531]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:13:00,686]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:13:05,270]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:13:09,728]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:13:09,842]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:13:15,651]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:13:19,565]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:13:24,233]\u001b[0m Trial 1473 finished with value: 11.595953090461718 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024688091114848073, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08946217184472646, 'dropout_rate_Layer_2': 0.34772745722962034, 'dropout_rate_Layer_3': 0.033157854327671245, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00038207270567589815, 'l1_Layer_2': 2.4972429900103594e-05, 'l1_Layer_3': 0.002763784712536945, 'n_units_Layer_1': 85, 'n_units_Layer_2': 210, 'n_units_Layer_3': 125}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.60 | sMAPE for Validation Set is: 11.87% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 32.15 | sMAPE for Test Set is: 12.60% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 08:13:27,765]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:13:27,909]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:13:37,301]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:13:40,573]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:13:45,579]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:13:49,538]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:13:56,900]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:13:59,263]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:14:01,928]\u001b[0m Trial 1487 finished with value: 41.9622560515306 and parameters: {'n_hidden': 4, 'learning_rate': 0.006873321542080581, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12961610868830833, 'dropout_rate_Layer_2': 0.11688738142984734, 'dropout_rate_Layer_3': 0.20280392421559837, 'dropout_rate_Layer_4': 0.20418345951859734, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00010452920453364508, 'l1_Layer_2': 1.0060113527874468e-05, 'l1_Layer_3': 5.61684914741164e-05, 'l1_Layer_4': 1.47356001676156e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 65, 'n_units_Layer_3': 170, 'n_units_Layer_4': 200}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.96 | sMAPE for Validation Set is: 32.46% | rMAE for Validation Set is: 1.99\n",
      "MAE for Test Set is: 162.41 | sMAPE for Test Set is: 72.04% | rMAE for Test Set is: 2.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 08:14:05,865]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:14:10,117]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:14:10,790]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:14:17,159]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:14:22,590]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:14:27,418]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:14:28,502]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:14:30,759]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:14:32,143]\u001b[0m Trial 1495 finished with value: 11.820594642530828 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033594781517879676, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10869879135172619, 'dropout_rate_Layer_2': 0.3438041646734238, 'dropout_rate_Layer_3': 0.03445795609144661, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004295277197738542, 'l1_Layer_2': 2.7098526071184482e-05, 'l1_Layer_3': 0.0029547240478480946, 'n_units_Layer_1': 100, 'n_units_Layer_2': 215, 'n_units_Layer_3': 135}. Best is trial 748 with value: 11.497627058251167.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.82 | sMAPE for Validation Set is: 12.11% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 34.50 | sMAPE for Test Set is: 13.40% | rMAE for Test Set is: 0.54\n",
      "for 2022-01-01, MAE is:59.21 & sMAPE is:57.76% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :59.21 & 57.76% & 0.50\n",
      "for 2022-01-02, MAE is:49.82 & sMAPE is:57.99% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :54.51 & 57.88% & 0.46\n",
      "for 2022-01-03, MAE is:74.22 & sMAPE is:66.23% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :61.08 & 60.66% & 0.86\n",
      "for 2022-01-04, MAE is:28.78 & sMAPE is:17.75% & rMAE is:1.82 ||| daily mean of MAE & sMAPE & rMAE till now are :53.01 & 49.93% & 1.10\n",
      "for 2022-01-05, MAE is:42.27 & sMAPE is:25.28% & rMAE is:2.41 ||| daily mean of MAE & sMAPE & rMAE till now are :50.86 & 45.00% & 1.36\n",
      "for 2022-01-06, MAE is:48.38 & sMAPE is:23.91% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :50.45 & 41.49% & 1.24\n",
      "for 2022-01-07, MAE is:39.72 & sMAPE is:18.68% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :48.91 & 38.23% & 1.14\n",
      "for 2022-01-08, MAE is:29.37 & sMAPE is:14.24% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :46.47 & 35.23% & 1.02\n",
      "for 2022-01-09, MAE is:26.91 & sMAPE is:13.57% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :44.30 & 32.82% & 0.93\n",
      "for 2022-01-10, MAE is:58.69 & sMAPE is:23.71% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :45.74 & 31.91% & 0.89\n",
      "for 2022-01-11, MAE is:31.28 & sMAPE is:12.17% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :44.42 & 30.12% & 0.84\n",
      "for 2022-01-12, MAE is:26.72 & sMAPE is:10.67% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :42.95 & 28.50% & 0.80\n",
      "for 2022-01-13, MAE is:17.40 & sMAPE is:7.42% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :40.98 & 26.88% & 0.82\n",
      "for 2022-01-14, MAE is:16.53 & sMAPE is:7.32% & rMAE is:2.14 ||| daily mean of MAE & sMAPE & rMAE till now are :39.24 & 25.48% & 0.91\n",
      "for 2022-01-15, MAE is:15.33 & sMAPE is:6.74% & rMAE is:1.81 ||| daily mean of MAE & sMAPE & rMAE till now are :37.64 & 24.23% & 0.97\n",
      "for 2022-01-16, MAE is:12.37 & sMAPE is:5.77% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :36.06 & 23.08% & 0.98\n",
      "for 2022-01-17, MAE is:27.38 & sMAPE is:10.98% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :35.55 & 22.36% & 1.02\n",
      "for 2022-01-18, MAE is:22.61 & sMAPE is:9.30% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :34.83 & 21.64% & 1.03\n",
      "for 2022-01-19, MAE is:13.73 & sMAPE is:6.06% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :33.72 & 20.82% & 1.01\n",
      "for 2022-01-20, MAE is:12.67 & sMAPE is:5.63% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :32.67 & 20.06% & 1.03\n",
      "for 2022-01-21, MAE is:16.07 & sMAPE is:7.36% & rMAE is:2.28 ||| daily mean of MAE & sMAPE & rMAE till now are :31.88 & 19.45% & 1.09\n",
      "for 2022-01-22, MAE is:13.07 & sMAPE is:6.24% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :31.02 & 18.85% & 1.06\n",
      "for 2022-01-23, MAE is:10.19 & sMAPE is:4.91% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :30.12 & 18.25% & 1.07\n",
      "for 2022-01-24, MAE is:32.80 & sMAPE is:13.45% & rMAE is:2.32 ||| daily mean of MAE & sMAPE & rMAE till now are :30.23 & 18.05% & 1.12\n",
      "for 2022-01-25, MAE is:35.46 & sMAPE is:12.97% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :30.44 & 17.84% & 1.13\n",
      "for 2022-01-26, MAE is:30.30 & sMAPE is:11.31% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :30.43 & 17.59% & 1.11\n",
      "for 2022-01-27, MAE is:24.95 & sMAPE is:9.14% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :30.23 & 17.28% & 1.09\n",
      "for 2022-01-28, MAE is:21.37 & sMAPE is:8.38% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :29.91 & 16.96% & 1.07\n",
      "for 2022-01-29, MAE is:17.41 & sMAPE is:7.31% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :29.48 & 16.63% & 1.06\n",
      "for 2022-01-30, MAE is:14.42 & sMAPE is:6.45% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :28.98 & 16.29% & 1.04\n",
      "for 2022-01-31, MAE is:18.84 & sMAPE is:7.80% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :28.65 & 16.02% & 1.04\n",
      "for 2022-02-01, MAE is:28.28 & sMAPE is:11.60% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :28.64 & 15.88% & 1.03\n",
      "for 2022-02-02, MAE is:17.33 & sMAPE is:7.43% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :28.30 & 15.62% & 1.01\n",
      "for 2022-02-03, MAE is:21.10 & sMAPE is:9.16% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :28.09 & 15.43% & 0.99\n",
      "for 2022-02-04, MAE is:16.40 & sMAPE is:7.47% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :27.75 & 15.20% & 0.97\n",
      "for 2022-02-05, MAE is:22.52 & sMAPE is:10.60% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :27.61 & 15.08% & 0.97\n",
      "for 2022-02-06, MAE is:18.64 & sMAPE is:9.03% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :27.37 & 14.91% & 0.96\n",
      "for 2022-02-07, MAE is:20.83 & sMAPE is:10.72% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :27.19 & 14.80% & 0.95\n",
      "for 2022-02-08, MAE is:13.38 & sMAPE is:6.39% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :26.84 & 14.59% & 0.95\n",
      "for 2022-02-09, MAE is:16.28 & sMAPE is:7.73% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :26.58 & 14.42% & 0.95\n",
      "for 2022-02-10, MAE is:13.71 & sMAPE is:6.57% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :26.26 & 14.22% & 0.96\n",
      "for 2022-02-11, MAE is:16.41 & sMAPE is:7.99% & rMAE is:2.33 ||| daily mean of MAE & sMAPE & rMAE till now are :26.03 & 14.08% & 1.00\n",
      "for 2022-02-12, MAE is:13.66 & sMAPE is:6.87% & rMAE is:2.00 ||| daily mean of MAE & sMAPE & rMAE till now are :25.74 & 13.91% & 1.02\n",
      "for 2022-02-13, MAE is:15.74 & sMAPE is:8.59% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :25.51 & 13.79% & 1.01\n",
      "for 2022-02-14, MAE is:17.19 & sMAPE is:8.61% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :25.33 & 13.67% & 1.02\n",
      "for 2022-02-15, MAE is:15.14 & sMAPE is:7.48% & rMAE is:2.07 ||| daily mean of MAE & sMAPE & rMAE till now are :25.11 & 13.54% & 1.04\n",
      "for 2022-02-16, MAE is:13.76 & sMAPE is:6.76% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :24.86 & 13.39% & 1.04\n",
      "for 2022-02-17, MAE is:16.63 & sMAPE is:8.56% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :24.69 & 13.29% & 1.03\n",
      "for 2022-02-18, MAE is:13.25 & sMAPE is:7.38% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :24.46 & 13.17% & 1.02\n",
      "for 2022-02-19, MAE is:16.06 & sMAPE is:9.27% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :24.29 & 13.09% & 1.02\n",
      "for 2022-02-20, MAE is:18.36 & sMAPE is:10.66% & rMAE is:2.15 ||| daily mean of MAE & sMAPE & rMAE till now are :24.18 & 13.05% & 1.05\n",
      "for 2022-02-21, MAE is:12.34 & sMAPE is:6.51% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :23.95 & 12.92% & 1.04\n",
      "for 2022-02-22, MAE is:14.19 & sMAPE is:7.67% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :23.76 & 12.82% & 1.03\n",
      "for 2022-02-23, MAE is:18.52 & sMAPE is:10.21% & rMAE is:1.90 ||| daily mean of MAE & sMAPE & rMAE till now are :23.67 & 12.77% & 1.05\n",
      "for 2022-02-24, MAE is:30.10 & sMAPE is:15.54% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :23.78 & 12.82% & 1.05\n",
      "for 2022-02-25, MAE is:65.93 & sMAPE is:28.59% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :24.54 & 13.11% & 1.05\n",
      "for 2022-02-26, MAE is:23.65 & sMAPE is:9.78% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :24.52 & 13.05% & 1.04\n",
      "for 2022-02-27, MAE is:25.80 & sMAPE is:12.23% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :24.54 & 13.03% & 1.03\n",
      "for 2022-02-28, MAE is:32.03 & sMAPE is:12.53% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :24.67 & 13.02% & 1.02\n",
      "for 2022-03-01, MAE is:39.50 & sMAPE is:14.11% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :24.92 & 13.04% & 1.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-03-02, MAE is:29.06 & sMAPE is:10.31% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :24.98 & 13.00% & 1.00\n",
      "for 2022-03-03, MAE is:70.29 & sMAPE is:23.76% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :25.72 & 13.17% & 1.00\n",
      "for 2022-03-04, MAE is:92.99 & sMAPE is:27.35% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :26.78 & 13.40% & 0.99\n",
      "for 2022-03-05, MAE is:29.04 & sMAPE is:8.26% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :26.82 & 13.32% & 0.98\n",
      "for 2022-03-06, MAE is:38.25 & sMAPE is:11.03% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :26.99 & 13.28% & 0.97\n",
      "for 2022-03-07, MAE is:60.49 & sMAPE is:15.45% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :27.50 & 13.31% & 0.96\n",
      "for 2022-03-08, MAE is:167.00 & sMAPE is:33.97% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :29.58 & 13.62% & 0.96\n",
      "for 2022-03-09, MAE is:62.54 & sMAPE is:12.17% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :30.07 & 13.60% & 0.94\n",
      "for 2022-03-10, MAE is:89.44 & sMAPE is:20.77% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :30.93 & 13.70% & 0.95\n",
      "for 2022-03-11, MAE is:56.19 & sMAPE is:14.58% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :31.29 & 13.72% & 0.96\n",
      "for 2022-03-12, MAE is:127.44 & sMAPE is:38.09% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :32.64 & 14.06% & 0.97\n",
      "for 2022-03-13, MAE is:29.65 & sMAPE is:10.00% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :32.60 & 14.00% & 0.96\n",
      "for 2022-03-14, MAE is:32.55 & sMAPE is:9.95% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :32.60 & 13.95% & 0.95\n",
      "for 2022-03-15, MAE is:56.15 & sMAPE is:17.47% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :32.92 & 14.00% & 0.94\n",
      "for 2022-03-16, MAE is:43.64 & sMAPE is:13.84% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :33.06 & 13.99% & 0.93\n",
      "for 2022-03-17, MAE is:26.95 & sMAPE is:9.64% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :32.98 & 13.94% & 0.92\n",
      "for 2022-03-18, MAE is:24.32 & sMAPE is:9.39% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :32.87 & 13.88% & 0.91\n",
      "for 2022-03-19, MAE is:18.97 & sMAPE is:8.41% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :32.69 & 13.81% & 0.91\n",
      "for 2022-03-20, MAE is:20.56 & sMAPE is:8.71% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :32.54 & 13.74% & 0.90\n",
      "for 2022-03-21, MAE is:26.86 & sMAPE is:10.36% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :32.47 & 13.70% & 0.90\n",
      "for 2022-03-22, MAE is:28.78 & sMAPE is:11.04% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :32.42 & 13.67% & 0.89\n",
      "for 2022-03-23, MAE is:31.11 & sMAPE is:12.35% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :32.41 & 13.65% & 0.89\n",
      "for 2022-03-24, MAE is:28.10 & sMAPE is:11.05% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :32.35 & 13.62% & 0.89\n",
      "for 2022-03-25, MAE is:36.61 & sMAPE is:14.58% & rMAE is:1.92 ||| daily mean of MAE & sMAPE & rMAE till now are :32.40 & 13.63% & 0.90\n",
      "for 2022-03-26, MAE is:25.41 & sMAPE is:11.19% & rMAE is:1.82 ||| daily mean of MAE & sMAPE & rMAE till now are :32.32 & 13.60% & 0.92\n",
      "for 2022-03-27, MAE is:27.20 & sMAPE is:15.82% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :32.26 & 13.63% & 0.91\n",
      "for 2022-03-28, MAE is:22.95 & sMAPE is:9.26% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :32.16 & 13.58% & 0.91\n",
      "for 2022-03-29, MAE is:20.72 & sMAPE is:8.13% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :32.03 & 13.52% & 0.91\n",
      "for 2022-03-30, MAE is:47.67 & sMAPE is:18.30% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :32.20 & 13.57% & 0.92\n",
      "for 2022-03-31, MAE is:39.48 & sMAPE is:14.09% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :32.28 & 13.58% & 0.91\n",
      "for 2022-04-01, MAE is:53.57 & sMAPE is:17.71% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :32.52 & 13.62% & 0.91\n",
      "for 2022-04-02, MAE is:26.29 & sMAPE is:9.00% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :32.45 & 13.57% & 0.91\n",
      "for 2022-04-03, MAE is:26.25 & sMAPE is:9.06% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :32.38 & 13.52% & 0.90\n",
      "for 2022-04-04, MAE is:30.16 & sMAPE is:9.05% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :32.36 & 13.48% & 0.89\n",
      "for 2022-04-05, MAE is:26.71 & sMAPE is:8.10% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :32.30 & 13.42% & 0.89\n",
      "for 2022-04-06, MAE is:30.25 & sMAPE is:10.40% & rMAE is:1.83 ||| daily mean of MAE & sMAPE & rMAE till now are :32.28 & 13.39% & 0.90\n",
      "for 2022-04-07, MAE is:34.51 & sMAPE is:14.23% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :32.30 & 13.40% & 0.89\n",
      "for 2022-04-08, MAE is:13.52 & sMAPE is:5.38% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :32.11 & 13.31% & 0.89\n",
      "for 2022-04-09, MAE is:10.86 & sMAPE is:4.70% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :31.89 & 13.23% & 0.88\n",
      "for 2022-04-10, MAE is:66.20 & sMAPE is:38.55% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :32.24 & 13.48% & 0.88\n",
      "for 2022-04-11, MAE is:27.26 & sMAPE is:11.02% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :32.19 & 13.46% & 0.87\n",
      "for 2022-04-12, MAE is:16.24 & sMAPE is:6.71% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :32.03 & 13.39% & 0.86\n",
      "for 2022-04-13, MAE is:17.26 & sMAPE is:6.92% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :31.89 & 13.33% & 0.86\n",
      "for 2022-04-14, MAE is:18.93 & sMAPE is:8.15% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :31.76 & 13.28% & 0.86\n",
      "for 2022-04-15, MAE is:13.45 & sMAPE is:6.74% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :31.59 & 13.22% & 0.85\n",
      "for 2022-04-16, MAE is:48.91 & sMAPE is:34.90% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :31.75 & 13.42% & 0.85\n",
      "for 2022-04-17, MAE is:52.93 & sMAPE is:55.31% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :31.95 & 13.81% & 0.85\n",
      "for 2022-04-18, MAE is:55.81 & sMAPE is:48.84% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :32.17 & 14.14% & 0.85\n",
      "for 2022-04-19, MAE is:37.17 & sMAPE is:19.57% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :32.22 & 14.19% & 0.85\n",
      "for 2022-04-20, MAE is:14.56 & sMAPE is:6.78% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :32.06 & 14.12% & 0.84\n",
      "for 2022-04-21, MAE is:15.10 & sMAPE is:7.37% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :31.90 & 14.06% & 0.84\n",
      "for 2022-04-22, MAE is:16.45 & sMAPE is:8.71% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :31.77 & 14.01% & 0.84\n",
      "for 2022-04-23, MAE is:10.16 & sMAPE is:6.71% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :31.57 & 13.95% & 0.84\n",
      "for 2022-04-24, MAE is:23.17 & sMAPE is:16.93% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :31.50 & 13.97% & 0.83\n",
      "for 2022-04-25, MAE is:37.47 & sMAPE is:18.74% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :31.55 & 14.01% & 0.83\n",
      "for 2022-04-26, MAE is:24.46 & sMAPE is:10.74% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :31.49 & 13.98% & 0.83\n",
      "for 2022-04-27, MAE is:19.34 & sMAPE is:8.53% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :31.39 & 13.94% & 0.83\n",
      "for 2022-04-28, MAE is:29.17 & sMAPE is:12.60% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :31.37 & 13.93% & 0.83\n",
      "for 2022-04-29, MAE is:18.23 & sMAPE is:8.01% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :31.26 & 13.88% & 0.83\n",
      "for 2022-04-30, MAE is:11.61 & sMAPE is:6.02% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :31.09 & 13.81% & 0.82\n",
      "for 2022-05-01, MAE is:13.65 & sMAPE is:7.54% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :30.95 & 13.76% & 0.82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-05-02, MAE is:17.36 & sMAPE is:8.06% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :30.84 & 13.71% & 0.82\n",
      "for 2022-05-03, MAE is:18.41 & sMAPE is:8.22% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :30.74 & 13.67% & 0.82\n",
      "for 2022-05-04, MAE is:15.53 & sMAPE is:6.95% & rMAE is:1.92 ||| daily mean of MAE & sMAPE & rMAE till now are :30.62 & 13.61% & 0.83\n",
      "for 2022-05-05, MAE is:13.93 & sMAPE is:6.06% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :30.48 & 13.55% & 0.83\n",
      "for 2022-05-06, MAE is:13.38 & sMAPE is:5.98% & rMAE is:2.21 ||| daily mean of MAE & sMAPE & rMAE till now are :30.35 & 13.49% & 0.84\n",
      "for 2022-05-07, MAE is:12.72 & sMAPE is:6.39% & rMAE is:2.07 ||| daily mean of MAE & sMAPE & rMAE till now are :30.21 & 13.44% & 0.85\n",
      "for 2022-05-08, MAE is:26.89 & sMAPE is:17.04% & rMAE is:1.91 ||| daily mean of MAE & sMAPE & rMAE till now are :30.18 & 13.47% & 0.86\n",
      "for 2022-05-09, MAE is:15.75 & sMAPE is:7.43% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :30.07 & 13.42% & 0.87\n",
      "for 2022-05-10, MAE is:16.90 & sMAPE is:7.42% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :29.97 & 13.37% & 0.87\n",
      "for 2022-05-11, MAE is:21.39 & sMAPE is:10.34% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :29.90 & 13.35% & 0.87\n",
      "for 2022-05-12, MAE is:11.68 & sMAPE is:5.93% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :29.77 & 13.29% & 0.86\n",
      "for 2022-05-13, MAE is:13.86 & sMAPE is:6.84% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :29.65 & 13.24% & 0.86\n",
      "for 2022-05-14, MAE is:16.58 & sMAPE is:9.55% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :29.55 & 13.22% & 0.86\n",
      "for 2022-05-15, MAE is:35.50 & sMAPE is:28.77% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :29.59 & 13.33% & 0.87\n",
      "for 2022-05-16, MAE is:17.55 & sMAPE is:9.29% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :29.50 & 13.30% & 0.87\n",
      "for 2022-05-17, MAE is:21.99 & sMAPE is:10.11% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :29.45 & 13.28% & 0.87\n",
      "for 2022-05-18, MAE is:23.18 & sMAPE is:10.80% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :29.40 & 13.26% & 0.88\n",
      "for 2022-05-19, MAE is:15.73 & sMAPE is:7.30% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :29.30 & 13.22% & 0.88\n",
      "for 2022-05-20, MAE is:15.85 & sMAPE is:7.56% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :29.21 & 13.18% & 0.88\n",
      "for 2022-05-21, MAE is:9.68 & sMAPE is:5.68% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :29.07 & 13.13% & 0.88\n",
      "for 2022-05-22, MAE is:13.14 & sMAPE is:8.76% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :28.96 & 13.09% & 0.88\n",
      "for 2022-05-23, MAE is:15.19 & sMAPE is:7.84% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :28.86 & 13.06% & 0.88\n",
      "for 2022-05-24, MAE is:15.02 & sMAPE is:8.50% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :28.77 & 13.03% & 0.87\n",
      "for 2022-05-25, MAE is:24.64 & sMAPE is:13.41% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :28.74 & 13.03% & 0.87\n",
      "for 2022-05-26, MAE is:15.99 & sMAPE is:9.88% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :28.65 & 13.01% & 0.87\n",
      "for 2022-05-27, MAE is:12.80 & sMAPE is:8.26% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :28.54 & 12.97% & 0.87\n",
      "for 2022-05-28, MAE is:12.40 & sMAPE is:8.15% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :28.43 & 12.94% & 0.86\n",
      "for 2022-05-29, MAE is:18.85 & sMAPE is:11.94% & rMAE is:1.79 ||| daily mean of MAE & sMAPE & rMAE till now are :28.37 & 12.94% & 0.87\n",
      "for 2022-05-30, MAE is:31.40 & sMAPE is:15.10% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :28.39 & 12.95% & 0.87\n",
      "for 2022-05-31, MAE is:19.10 & sMAPE is:8.87% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :28.33 & 12.92% & 0.87\n",
      "for 2022-06-01, MAE is:11.79 & sMAPE is:5.32% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :28.22 & 12.87% & 0.86\n",
      "for 2022-06-02, MAE is:14.26 & sMAPE is:7.14% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :28.13 & 12.84% & 0.86\n",
      "for 2022-06-03, MAE is:9.37 & sMAPE is:4.85% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :28.01 & 12.78% & 0.86\n",
      "for 2022-06-04, MAE is:8.50 & sMAPE is:5.03% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :27.88 & 12.73% & 0.86\n",
      "for 2022-06-05, MAE is:11.49 & sMAPE is:7.02% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :27.77 & 12.70% & 0.85\n",
      "for 2022-06-06, MAE is:19.79 & sMAPE is:10.82% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :27.72 & 12.68% & 0.85\n",
      "for 2022-06-07, MAE is:10.21 & sMAPE is:5.36% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :27.61 & 12.64% & 0.85\n",
      "for 2022-06-08, MAE is:13.61 & sMAPE is:6.82% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :27.52 & 12.60% & 0.85\n",
      "for 2022-06-09, MAE is:7.07 & sMAPE is:3.79% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :27.40 & 12.55% & 0.84\n",
      "for 2022-06-10, MAE is:12.83 & sMAPE is:6.68% & rMAE is:2.84 ||| daily mean of MAE & sMAPE & rMAE till now are :27.31 & 12.51% & 0.86\n",
      "for 2022-06-11, MAE is:8.27 & sMAPE is:4.85% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :27.19 & 12.46% & 0.86\n",
      "for 2022-06-12, MAE is:15.65 & sMAPE is:10.01% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :27.12 & 12.45% & 0.86\n",
      "for 2022-06-13, MAE is:28.10 & sMAPE is:15.04% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :27.12 & 12.46% & 0.86\n",
      "for 2022-06-14, MAE is:13.71 & sMAPE is:6.47% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :27.04 & 12.43% & 0.86\n",
      "for 2022-06-15, MAE is:11.32 & sMAPE is:5.15% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :26.95 & 12.38% & 0.85\n",
      "for 2022-06-16, MAE is:32.32 & sMAPE is:14.14% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :26.98 & 12.39% & 0.85\n",
      "for 2022-06-17, MAE is:77.41 & sMAPE is:28.62% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :27.28 & 12.49% & 0.85\n",
      "for 2022-06-18, MAE is:24.34 & sMAPE is:8.95% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :27.26 & 12.47% & 0.85\n",
      "for 2022-06-19, MAE is:22.28 & sMAPE is:9.15% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :27.23 & 12.45% & 0.84\n",
      "for 2022-06-20, MAE is:43.70 & sMAPE is:15.25% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :27.33 & 12.47% & 0.84\n",
      "for 2022-06-21, MAE is:32.99 & sMAPE is:10.19% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :27.36 & 12.45% & 0.84\n",
      "for 2022-06-22, MAE is:65.09 & sMAPE is:17.98% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :27.58 & 12.49% & 0.84\n",
      "for 2022-06-23, MAE is:24.93 & sMAPE is:7.03% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :27.57 & 12.45% & 0.83\n",
      "for 2022-06-24, MAE is:22.46 & sMAPE is:6.53% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :27.54 & 12.42% & 0.84\n",
      "for 2022-06-25, MAE is:20.91 & sMAPE is:7.18% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :27.50 & 12.39% & 0.84\n",
      "for 2022-06-26, MAE is:13.53 & sMAPE is:5.03% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :27.42 & 12.35% & 0.84\n",
      "for 2022-06-27, MAE is:33.12 & sMAPE is:10.43% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :27.45 & 12.34% & 0.84\n",
      "for 2022-06-28, MAE is:30.72 & sMAPE is:8.53% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :27.47 & 12.32% & 0.84\n",
      "for 2022-06-29, MAE is:13.95 & sMAPE is:3.95% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :27.40 & 12.27% & 0.84\n",
      "for 2022-06-30, MAE is:18.89 & sMAPE is:5.33% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :27.35 & 12.23% & 0.84\n",
      "for 2022-07-01, MAE is:17.55 & sMAPE is:5.04% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :27.29 & 12.19% & 0.84\n",
      "for 2022-07-02, MAE is:26.41 & sMAPE is:8.91% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :27.29 & 12.17% & 0.84\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-07-03, MAE is:72.14 & sMAPE is:29.88% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :27.53 & 12.27% & 0.84\n",
      "for 2022-07-04, MAE is:39.08 & sMAPE is:12.32% & rMAE is:2.13 ||| daily mean of MAE & sMAPE & rMAE till now are :27.60 & 12.27% & 0.85\n",
      "for 2022-07-05, MAE is:18.32 & sMAPE is:5.03% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :27.55 & 12.23% & 0.85\n",
      "for 2022-07-06, MAE is:25.62 & sMAPE is:6.97% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :27.54 & 12.20% & 0.85\n",
      "for 2022-07-07, MAE is:17.53 & sMAPE is:4.86% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :27.48 & 12.16% & 0.85\n",
      "for 2022-07-08, MAE is:61.18 & sMAPE is:16.76% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :27.66 & 12.19% & 0.85\n",
      "for 2022-07-09, MAE is:28.93 & sMAPE is:8.00% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :27.67 & 12.17% & 0.85\n",
      "for 2022-07-10, MAE is:27.33 & sMAPE is:9.41% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :27.67 & 12.15% & 0.85\n",
      "for 2022-07-11, MAE is:33.23 & sMAPE is:8.53% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :27.69 & 12.13% & 0.85\n",
      "for 2022-07-12, MAE is:19.00 & sMAPE is:4.66% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :27.65 & 12.10% & 0.84\n",
      "for 2022-07-13, MAE is:25.59 & sMAPE is:6.23% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :27.64 & 12.06% & 0.84\n",
      "for 2022-07-14, MAE is:20.86 & sMAPE is:5.36% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :27.60 & 12.03% & 0.84\n",
      "for 2022-07-15, MAE is:23.43 & sMAPE is:6.13% & rMAE is:1.92 ||| daily mean of MAE & sMAPE & rMAE till now are :27.58 & 12.00% & 0.85\n",
      "for 2022-07-16, MAE is:25.19 & sMAPE is:6.78% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :27.57 & 11.97% & 0.85\n",
      "for 2022-07-17, MAE is:105.58 & sMAPE is:42.22% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :27.96 & 12.13% & 0.85\n",
      "for 2022-07-18, MAE is:79.54 & sMAPE is:19.68% & rMAE is:2.55 ||| daily mean of MAE & sMAPE & rMAE till now are :28.22 & 12.16% & 0.86\n",
      "for 2022-07-19, MAE is:23.24 & sMAPE is:5.43% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :28.20 & 12.13% & 0.86\n",
      "for 2022-07-20, MAE is:34.54 & sMAPE is:8.15% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :28.23 & 12.11% & 0.86\n",
      "for 2022-07-21, MAE is:33.97 & sMAPE is:8.00% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :28.26 & 12.09% & 0.86\n",
      "for 2022-07-22, MAE is:31.47 & sMAPE is:7.77% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :28.27 & 12.07% & 0.86\n",
      "for 2022-07-23, MAE is:47.27 & sMAPE is:12.61% & rMAE is:3.26 ||| daily mean of MAE & sMAPE & rMAE till now are :28.37 & 12.07% & 0.87\n",
      "for 2022-07-24, MAE is:31.12 & sMAPE is:9.66% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :28.38 & 12.06% & 0.87\n",
      "for 2022-07-25, MAE is:17.61 & sMAPE is:4.58% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :28.33 & 12.02% & 0.87\n",
      "for 2022-07-26, MAE is:36.78 & sMAPE is:8.59% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :28.37 & 12.01% & 0.87\n",
      "for 2022-07-27, MAE is:36.34 & sMAPE is:8.18% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :28.41 & 11.99% & 0.87\n",
      "for 2022-07-28, MAE is:72.66 & sMAPE is:14.66% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :28.62 & 12.00% & 0.87\n",
      "for 2022-07-29, MAE is:25.25 & sMAPE is:5.22% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :28.60 & 11.97% & 0.87\n",
      "for 2022-07-30, MAE is:44.68 & sMAPE is:10.69% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :28.68 & 11.96% & 0.87\n",
      "for 2022-07-31, MAE is:53.00 & sMAPE is:16.06% & rMAE is:1.73 ||| daily mean of MAE & sMAPE & rMAE till now are :28.79 & 11.98% & 0.88\n",
      "for 2022-08-01, MAE is:57.13 & sMAPE is:13.49% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :28.93 & 11.99% & 0.88\n",
      "for 2022-08-02, MAE is:24.09 & sMAPE is:5.26% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :28.91 & 11.96% & 0.87\n",
      "for 2022-08-03, MAE is:35.68 & sMAPE is:7.74% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :28.94 & 11.94% & 0.88\n",
      "for 2022-08-04, MAE is:28.69 & sMAPE is:6.36% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :28.94 & 11.91% & 0.87\n",
      "for 2022-08-05, MAE is:29.71 & sMAPE is:6.98% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :28.94 & 11.89% & 0.87\n",
      "for 2022-08-06, MAE is:49.97 & sMAPE is:16.43% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :29.04 & 11.91% & 0.87\n",
      "for 2022-08-07, MAE is:78.93 & sMAPE is:31.18% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :29.26 & 12.00% & 0.87\n",
      "for 2022-08-08, MAE is:40.73 & sMAPE is:11.94% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :29.32 & 12.00% & 0.87\n",
      "for 2022-08-09, MAE is:37.21 & sMAPE is:10.14% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :29.35 & 11.99% & 0.87\n",
      "for 2022-08-10, MAE is:35.22 & sMAPE is:10.36% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :29.38 & 11.98% & 0.86\n",
      "for 2022-08-11, MAE is:33.51 & sMAPE is:9.31% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :29.40 & 11.97% & 0.86\n",
      "for 2022-08-12, MAE is:55.06 & sMAPE is:13.82% & rMAE is:2.23 ||| daily mean of MAE & sMAPE & rMAE till now are :29.51 & 11.98% & 0.87\n",
      "for 2022-08-13, MAE is:34.49 & sMAPE is:8.74% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :29.53 & 11.97% & 0.87\n",
      "for 2022-08-14, MAE is:34.34 & sMAPE is:10.26% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :29.55 & 11.96% & 0.86\n",
      "for 2022-08-15, MAE is:32.05 & sMAPE is:7.89% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :29.57 & 11.94% & 0.86\n",
      "for 2022-08-16, MAE is:81.68 & sMAPE is:17.38% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :29.79 & 11.96% & 0.86\n",
      "for 2022-08-17, MAE is:54.45 & sMAPE is:10.42% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :29.90 & 11.96% & 0.86\n",
      "for 2022-08-18, MAE is:43.61 & sMAPE is:8.02% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :29.96 & 11.94% & 0.85\n",
      "for 2022-08-19, MAE is:18.80 & sMAPE is:3.65% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :29.91 & 11.90% & 0.85\n",
      "for 2022-08-20, MAE is:29.99 & sMAPE is:6.40% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :29.91 & 11.88% & 0.85\n",
      "for 2022-08-21, MAE is:61.96 & sMAPE is:15.41% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :30.05 & 11.90% & 0.85\n",
      "for 2022-08-22, MAE is:79.87 & sMAPE is:14.98% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :30.26 & 11.91% & 0.85\n",
      "for 2022-08-23, MAE is:65.14 & sMAPE is:10.86% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :30.41 & 11.90% & 0.85\n",
      "for 2022-08-24, MAE is:47.38 & sMAPE is:7.60% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :30.48 & 11.89% & 0.85\n",
      "for 2022-08-25, MAE is:30.80 & sMAPE is:4.94% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :30.49 & 11.86% & 0.85\n",
      "for 2022-08-26, MAE is:108.55 & sMAPE is:16.91% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :30.81 & 11.88% & 0.84\n",
      "for 2022-08-27, MAE is:69.17 & sMAPE is:11.19% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :30.97 & 11.87% & 0.84\n",
      "for 2022-08-28, MAE is:39.00 & sMAPE is:6.72% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :31.01 & 11.85% & 0.84\n",
      "for 2022-08-29, MAE is:71.00 & sMAPE is:10.72% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :31.17 & 11.85% & 0.84\n",
      "for 2022-08-30, MAE is:54.66 & sMAPE is:7.81% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :31.27 & 11.83% & 0.84\n",
      "for 2022-08-31, MAE is:48.56 & sMAPE is:7.16% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :31.34 & 11.81% & 0.84\n",
      "for 2022-09-01, MAE is:46.69 & sMAPE is:7.27% & rMAE is:2.41 ||| daily mean of MAE & sMAPE & rMAE till now are :31.40 & 11.79% & 0.84\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-09-02, MAE is:85.27 & sMAPE is:14.90% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :31.62 & 11.81% & 0.84\n",
      "for 2022-09-03, MAE is:73.67 & sMAPE is:15.79% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :31.79 & 11.82% & 0.84\n",
      "for 2022-09-04, MAE is:91.31 & sMAPE is:23.41% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :32.04 & 11.87% & 0.84\n",
      "for 2022-09-05, MAE is:78.86 & sMAPE is:17.99% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :32.22 & 11.89% & 0.84\n",
      "for 2022-09-06, MAE is:42.66 & sMAPE is:7.86% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :32.27 & 11.88% & 0.84\n",
      "for 2022-09-07, MAE is:54.38 & sMAPE is:10.64% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :32.36 & 11.87% & 0.83\n",
      "for 2022-09-08, MAE is:75.25 & sMAPE is:16.29% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :32.53 & 11.89% & 0.83\n",
      "for 2022-09-09, MAE is:44.64 & sMAPE is:11.65% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :32.57 & 11.89% & 0.83\n",
      "for 2022-09-10, MAE is:30.23 & sMAPE is:8.27% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :32.56 & 11.88% & 0.83\n",
      "for 2022-09-11, MAE is:29.52 & sMAPE is:8.21% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :32.55 & 11.86% & 0.83\n",
      "for 2022-09-12, MAE is:32.22 & sMAPE is:7.46% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :32.55 & 11.84% & 0.83\n",
      "for 2022-09-13, MAE is:31.16 & sMAPE is:7.26% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :32.55 & 11.83% & 0.83\n",
      "for 2022-09-14, MAE is:45.41 & sMAPE is:10.04% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :32.60 & 11.82% & 0.83\n",
      "for 2022-09-15, MAE is:40.27 & sMAPE is:9.14% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :32.63 & 11.81% & 0.83\n",
      "for 2022-09-16, MAE is:36.83 & sMAPE is:8.65% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :32.64 & 11.80% & 0.83\n",
      "for 2022-09-17, MAE is:84.44 & sMAPE is:25.91% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :32.84 & 11.85% & 0.83\n",
      "for 2022-09-18, MAE is:70.79 & sMAPE is:26.59% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :32.99 & 11.91% & 0.83\n",
      "for 2022-09-19, MAE is:41.66 & sMAPE is:13.38% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :33.02 & 11.91% & 0.82\n",
      "for 2022-09-20, MAE is:58.23 & sMAPE is:15.40% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :33.12 & 11.93% & 0.83\n",
      "for 2022-09-21, MAE is:50.43 & sMAPE is:12.46% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :33.18 & 11.93% & 0.83\n",
      "for 2022-09-22, MAE is:42.88 & sMAPE is:9.96% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :33.22 & 11.92% & 0.82\n",
      "for 2022-09-23, MAE is:34.76 & sMAPE is:9.49% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :33.22 & 11.91% & 0.82\n",
      "for 2022-09-24, MAE is:28.91 & sMAPE is:8.09% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :33.21 & 11.90% & 0.82\n",
      "for 2022-09-25, MAE is:52.36 & sMAPE is:17.27% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :33.28 & 11.92% & 0.82\n",
      "for 2022-09-26, MAE is:26.93 & sMAPE is:7.92% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :33.26 & 11.90% & 0.82\n",
      "for 2022-09-27, MAE is:25.97 & sMAPE is:7.70% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :33.23 & 11.89% & 0.82\n",
      "for 2022-09-28, MAE is:83.29 & sMAPE is:20.45% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :33.41 & 11.92% & 0.82\n",
      "for 2022-09-29, MAE is:36.02 & sMAPE is:8.12% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :33.42 & 11.90% & 0.82\n",
      "for 2022-09-30, MAE is:76.67 & sMAPE is:20.00% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :33.58 & 11.93% & 0.83\n",
      "for 2022-10-01, MAE is:76.53 & sMAPE is:27.48% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :33.74 & 11.99% & 0.82\n",
      "for 2022-10-02, MAE is:43.79 & sMAPE is:23.00% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :33.77 & 12.03% & 0.82\n",
      "for 2022-10-03, MAE is:73.43 & sMAPE is:29.87% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :33.92 & 12.10% & 0.83\n",
      "for 2022-10-04, MAE is:34.82 & sMAPE is:11.51% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :33.92 & 12.09% & 0.83\n",
      "for 2022-10-05, MAE is:71.33 & sMAPE is:30.02% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :34.06 & 12.16% & 0.82\n",
      "for 2022-10-06, MAE is:31.33 & sMAPE is:12.80% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :34.05 & 12.16% & 0.82\n",
      "for 2022-10-07, MAE is:38.38 & sMAPE is:14.40% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :34.06 & 12.17% & 0.82\n",
      "for 2022-10-08, MAE is:14.55 & sMAPE is:6.00% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :33.99 & 12.15% & 0.82\n",
      "for 2022-10-09, MAE is:58.13 & sMAPE is:33.65% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :34.08 & 12.22% & 0.82\n",
      "for 2022-10-10, MAE is:42.01 & sMAPE is:21.62% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :34.11 & 12.26% & 0.82\n",
      "for 2022-10-11, MAE is:35.33 & sMAPE is:14.03% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :34.11 & 12.26% & 0.82\n",
      "for 2022-10-12, MAE is:38.52 & sMAPE is:12.73% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :34.13 & 12.26% & 0.82\n",
      "for 2022-10-13, MAE is:39.19 & sMAPE is:15.84% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :34.14 & 12.28% & 0.82\n",
      "for 2022-10-14, MAE is:34.24 & sMAPE is:13.40% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :34.14 & 12.28% & 0.82\n",
      "for 2022-10-15, MAE is:55.69 & sMAPE is:29.17% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :34.22 & 12.34% & 0.82\n",
      "for 2022-10-16, MAE is:46.19 & sMAPE is:35.89% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :34.26 & 12.42% & 0.82\n",
      "for 2022-10-17, MAE is:25.58 & sMAPE is:14.89% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :34.23 & 12.43% & 0.82\n",
      "for 2022-10-18, MAE is:26.75 & sMAPE is:13.21% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :34.20 & 12.43% & 0.82\n",
      "for 2022-10-19, MAE is:35.47 & sMAPE is:20.66% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :34.21 & 12.46% & 0.82\n",
      "for 2022-10-20, MAE is:14.53 & sMAPE is:9.72% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :34.14 & 12.45% & 0.82\n",
      "for 2022-10-21, MAE is:24.93 & sMAPE is:15.30% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :34.11 & 12.46% & 0.82\n",
      "for 2022-10-22, MAE is:14.69 & sMAPE is:10.54% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :34.04 & 12.45% & 0.81\n",
      "for 2022-10-23, MAE is:24.72 & sMAPE is:22.37% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :34.01 & 12.49% & 0.81\n",
      "for 2022-10-24, MAE is:32.05 & sMAPE is:33.65% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :34.01 & 12.56% & 0.81\n",
      "for 2022-10-25, MAE is:17.47 & sMAPE is:17.93% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :33.95 & 12.58% & 0.81\n",
      "for 2022-10-26, MAE is:18.23 & sMAPE is:14.95% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :33.90 & 12.58% & 0.81\n",
      "for 2022-10-27, MAE is:10.64 & sMAPE is:9.33% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :33.82 & 12.57% & 0.81\n",
      "for 2022-10-28, MAE is:9.11 & sMAPE is:8.44% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :33.74 & 12.56% & 0.80\n",
      "for 2022-10-29, MAE is:10.34 & sMAPE is:10.54% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :33.66 & 12.55% & 0.80\n",
      "for 2022-10-30, MAE is:14.92 & sMAPE is:16.07% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :33.60 & 12.56% & 0.80\n",
      "for 2022-10-31, MAE is:17.30 & sMAPE is:13.43% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :33.55 & 12.57% & 0.80\n",
      "for 2022-11-01, MAE is:13.43 & sMAPE is:9.92% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :33.48 & 12.56% & 0.80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-11-02, MAE is:20.53 & sMAPE is:17.23% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :33.44 & 12.57% & 0.80\n",
      "for 2022-11-03, MAE is:10.88 & sMAPE is:8.60% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :33.36 & 12.56% & 0.80\n",
      "for 2022-11-04, MAE is:63.59 & sMAPE is:39.56% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :33.46 & 12.65% & 0.80\n",
      "for 2022-11-05, MAE is:24.65 & sMAPE is:15.89% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :33.43 & 12.66% & 0.80\n",
      "for 2022-11-06, MAE is:17.31 & sMAPE is:14.81% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :33.38 & 12.67% & 0.80\n",
      "for 2022-11-07, MAE is:17.34 & sMAPE is:11.44% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :33.33 & 12.66% & 0.80\n",
      "for 2022-11-08, MAE is:13.35 & sMAPE is:8.84% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :33.27 & 12.65% & 0.80\n",
      "for 2022-11-09, MAE is:30.31 & sMAPE is:18.80% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :33.26 & 12.67% & 0.80\n",
      "for 2022-11-10, MAE is:21.16 & sMAPE is:11.94% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :33.22 & 12.67% & 0.80\n",
      "for 2022-11-11, MAE is:14.22 & sMAPE is:7.85% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :33.16 & 12.65% & 0.80\n",
      "for 2022-11-12, MAE is:26.41 & sMAPE is:15.14% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :33.14 & 12.66% & 0.80\n",
      "for 2022-11-13, MAE is:13.57 & sMAPE is:7.86% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :33.07 & 12.64% & 0.80\n",
      "for 2022-11-14, MAE is:16.54 & sMAPE is:7.98% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :33.02 & 12.63% & 0.80\n",
      "for 2022-11-15, MAE is:30.06 & sMAPE is:14.45% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :33.01 & 12.64% & 0.80\n",
      "for 2022-11-16, MAE is:38.44 & sMAPE is:16.39% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :33.03 & 12.65% & 0.80\n",
      "for 2022-11-17, MAE is:19.44 & sMAPE is:8.16% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :32.99 & 12.63% & 0.79\n",
      "for 2022-11-18, MAE is:14.42 & sMAPE is:5.99% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :32.93 & 12.61% & 0.79\n",
      "for 2022-11-19, MAE is:23.84 & sMAPE is:10.00% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :32.90 & 12.60% & 0.79\n",
      "for 2022-11-20, MAE is:28.50 & sMAPE is:12.65% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :32.89 & 12.60% & 0.79\n",
      "for 2022-11-21, MAE is:42.53 & sMAPE is:17.14% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :32.92 & 12.62% & 0.79\n",
      "for 2022-11-22, MAE is:20.67 & sMAPE is:8.49% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :32.88 & 12.61% & 0.79\n",
      "for 2022-11-23, MAE is:14.80 & sMAPE is:6.49% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :32.83 & 12.59% & 0.79\n",
      "for 2022-11-24, MAE is:44.03 & sMAPE is:17.35% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :32.86 & 12.60% & 0.79\n",
      "for 2022-11-25, MAE is:32.19 & sMAPE is:11.45% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :32.86 & 12.60% & 0.79\n",
      "for 2022-11-26, MAE is:33.13 & sMAPE is:12.63% & rMAE is:1.62 ||| daily mean of MAE & sMAPE & rMAE till now are :32.86 & 12.60% & 0.80\n",
      "for 2022-11-27, MAE is:42.52 & sMAPE is:20.30% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :32.89 & 12.62% & 0.80\n",
      "for 2022-11-28, MAE is:36.86 & sMAPE is:11.85% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :32.90 & 12.62% & 0.80\n",
      "for 2022-11-29, MAE is:63.23 & sMAPE is:17.17% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :32.99 & 12.63% & 0.80\n",
      "for 2022-11-30, MAE is:51.50 & sMAPE is:13.05% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :33.05 & 12.63% & 0.79\n",
      "for 2022-12-01, MAE is:50.42 & sMAPE is:12.54% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :33.10 & 12.63% & 0.79\n",
      "for 2022-12-02, MAE is:35.06 & sMAPE is:8.81% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :33.10 & 12.62% & 0.79\n",
      "for 2022-12-03, MAE is:49.21 & sMAPE is:14.43% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :33.15 & 12.63% & 0.79\n",
      "for 2022-12-04, MAE is:13.91 & sMAPE is:4.47% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :33.09 & 12.60% & 0.79\n",
      "for 2022-12-05, MAE is:43.83 & sMAPE is:11.48% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :33.13 & 12.60% & 0.79\n",
      "for 2022-12-06, MAE is:27.28 & sMAPE is:7.03% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :33.11 & 12.58% & 0.79\n",
      "for 2022-12-07, MAE is:22.92 & sMAPE is:5.69% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :33.08 & 12.56% & 0.79\n",
      "for 2022-12-08, MAE is:19.51 & sMAPE is:4.85% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :33.04 & 12.54% & 0.79\n",
      "for 2022-12-09, MAE is:39.57 & sMAPE is:9.46% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :33.06 & 12.53% & 0.79\n",
      "for 2022-12-10, MAE is:24.83 & sMAPE is:6.55% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :33.03 & 12.52% & 0.79\n",
      "for 2022-12-11, MAE is:17.28 & sMAPE is:4.73% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :32.99 & 12.49% & 0.79\n",
      "for 2022-12-12, MAE is:44.31 & sMAPE is:10.34% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :33.02 & 12.49% & 0.79\n",
      "for 2022-12-13, MAE is:49.19 & sMAPE is:11.69% & rMAE is:1.91 ||| daily mean of MAE & sMAPE & rMAE till now are :33.07 & 12.48% & 0.79\n",
      "for 2022-12-14, MAE is:50.85 & sMAPE is:11.55% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :33.12 & 12.48% & 0.79\n",
      "for 2022-12-15, MAE is:31.28 & sMAPE is:7.79% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :33.11 & 12.47% & 0.79\n",
      "for 2022-12-16, MAE is:57.43 & sMAPE is:13.71% & rMAE is:2.17 ||| daily mean of MAE & sMAPE & rMAE till now are :33.18 & 12.47% & 0.80\n",
      "for 2022-12-17, MAE is:96.60 & sMAPE is:27.64% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :33.36 & 12.51% & 0.80\n",
      "for 2022-12-18, MAE is:36.76 & sMAPE is:12.48% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :33.37 & 12.51% & 0.80\n",
      "for 2022-12-19, MAE is:30.19 & sMAPE is:10.02% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :33.36 & 12.51% & 0.80\n",
      "for 2022-12-20, MAE is:38.31 & sMAPE is:13.40% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :33.38 & 12.51% & 0.79\n",
      "for 2022-12-21, MAE is:15.25 & sMAPE is:6.58% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :33.33 & 12.49% & 0.79\n",
      "for 2022-12-22, MAE is:23.30 & sMAPE is:10.00% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :33.30 & 12.49% & 0.79\n",
      "for 2022-12-23, MAE is:17.93 & sMAPE is:8.78% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :33.26 & 12.48% & 0.79\n",
      "for 2022-12-24, MAE is:27.75 & sMAPE is:20.16% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :33.24 & 12.50% & 0.79\n",
      "for 2022-12-25, MAE is:50.78 & sMAPE is:46.64% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :33.29 & 12.59% & 0.79\n",
      "for 2022-12-26, MAE is:53.73 & sMAPE is:70.74% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :33.35 & 12.75% & 0.78\n",
      "for 2022-12-27, MAE is:54.54 & sMAPE is:50.03% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :33.41 & 12.86% & 0.78\n",
      "for 2022-12-28, MAE is:46.47 & sMAPE is:50.12% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :33.44 & 12.96% & 0.78\n",
      "for 2022-12-29, MAE is:28.00 & sMAPE is:58.01% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :33.43 & 13.08% & 0.78\n",
      "for 2022-12-30, MAE is:26.67 & sMAPE is:74.31% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :33.41 & 13.25% & 0.78\n",
      "for 2022-12-31, MAE is:12.61 & sMAPE is:98.69% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :33.35 & 13.49% & 0.78\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 08:59:03,932]\u001b[0m A new study created in RDB with name: CH_2023\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:59:35,257]\u001b[0m Trial 0 finished with value: 57.400519156891086 and parameters: {'n_hidden': 3, 'learning_rate': 0.005413161211021855, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1209017880021261, 'dropout_rate_Layer_2': 0.30996917389276174, 'dropout_rate_Layer_3': 0.3452802000212863, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.013234947732414067, 'l1_Layer_2': 9.804492057229497e-05, 'l1_Layer_3': 0.0008531748546838678, 'n_units_Layer_1': 260, 'n_units_Layer_2': 60, 'n_units_Layer_3': 250}. Best is trial 0 with value: 57.400519156891086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.40 | sMAPE for Validation Set is: 19.79% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 13.59 | sMAPE for Test Set is: 14.81% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 08:59:40,971]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:59:44,374]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:59:47,748]\u001b[0m Trial 2 finished with value: 88.58276783328705 and parameters: {'n_hidden': 3, 'learning_rate': 0.031475825377767726, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.329647726350239, 'dropout_rate_Layer_2': 0.16112884430732138, 'dropout_rate_Layer_3': 0.0077831594194093245, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.002562507044175802, 'l1_Layer_2': 1.0778344113497802e-05, 'l1_Layer_3': 0.022013733645654985, 'n_units_Layer_1': 115, 'n_units_Layer_2': 105, 'n_units_Layer_3': 215}. Best is trial 0 with value: 57.400519156891086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 88.58 | sMAPE for Validation Set is: 31.77% | rMAE for Validation Set is: 1.39\n",
      "MAE for Test Set is: 40.85 | sMAPE for Test Set is: 30.81% | rMAE for Test Set is: 2.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 08:59:49,805]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 08:59:56,934]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:00:06,702]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:00:09,868]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:00:12,936]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:00:17,350]\u001b[0m Trial 7 finished with value: 64.41136708668046 and parameters: {'n_hidden': 4, 'learning_rate': 0.001074961772889279, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14876035271831506, 'dropout_rate_Layer_2': 0.2786683882089688, 'dropout_rate_Layer_3': 0.2087722813818408, 'dropout_rate_Layer_4': 0.3974111432800137, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0010022959047824454, 'l1_Layer_2': 0.002603083586663916, 'l1_Layer_3': 0.010389336716331727, 'l1_Layer_4': 0.01987564666940665, 'n_units_Layer_1': 160, 'n_units_Layer_2': 275, 'n_units_Layer_3': 175, 'n_units_Layer_4': 145}. Best is trial 0 with value: 57.400519156891086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 64.41 | sMAPE for Validation Set is: 22.13% | rMAE for Validation Set is: 1.01\n",
      "MAE for Test Set is: 17.05 | sMAPE for Test Set is: 16.93% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:00:21,656]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:00:24,160]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:00:25,864]\u001b[0m Trial 3 finished with value: 33.34691630922438 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013967960806068735, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07933641543896958, 'dropout_rate_Layer_2': 0.14437691497213626, 'dropout_rate_Layer_3': 0.06752252139486181, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.4379791996232883e-05, 'l1_Layer_2': 0.0024898025421844893, 'l1_Layer_3': 0.0004996599911079064, 'n_units_Layer_1': 95, 'n_units_Layer_2': 210, 'n_units_Layer_3': 295}. Best is trial 3 with value: 33.34691630922438.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.35 | sMAPE for Validation Set is: 12.62% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 12.39 | sMAPE for Test Set is: 13.78% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:00:27,742]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:00:27,925]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:00:29,825]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:00:35,533]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:00:35,836]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:00:36,198]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:00:42,210]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:00:43,864]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:00:48,299]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:00:50,078]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:00:56,865]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:01:00,299]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:01:04,835]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:01:08,517]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:01:08,817]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:01:14,808]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:01:18,302]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:01:21,576]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:01:23,153]\u001b[0m Trial 32 finished with value: 89.1667294556424 and parameters: {'n_hidden': 3, 'learning_rate': 0.09864302221685899, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22810939366265887, 'dropout_rate_Layer_2': 0.03851385907034746, 'dropout_rate_Layer_3': 0.0776405913311431, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.2369436122838522e-05, 'l1_Layer_2': 0.03865120203330373, 'l1_Layer_3': 0.003919947963287002, 'n_units_Layer_1': 265, 'n_units_Layer_2': 200, 'n_units_Layer_3': 135}. Best is trial 3 with value: 33.34691630922438.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 89.17 | sMAPE for Validation Set is: 32.03% | rMAE for Validation Set is: 1.40\n",
      "MAE for Test Set is: 32.36 | sMAPE for Test Set is: 29.62% | rMAE for Test Set is: 1.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:01:25,415]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:01:27,596]\u001b[0m Trial 23 finished with value: 102.9659614630829 and parameters: {'n_hidden': 4, 'learning_rate': 0.05386643398937014, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39562875833420785, 'dropout_rate_Layer_2': 0.010712627528723307, 'dropout_rate_Layer_3': 0.1642143051779531, 'dropout_rate_Layer_4': 0.26630304208398553, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.014041113650329798, 'l1_Layer_2': 0.003967726408361034, 'l1_Layer_3': 0.004660977547514283, 'l1_Layer_4': 2.179641766109856e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 285, 'n_units_Layer_3': 195, 'n_units_Layer_4': 155}. Best is trial 3 with value: 33.34691630922438.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 102.97 | sMAPE for Validation Set is: 37.59% | rMAE for Validation Set is: 1.62\n",
      "MAE for Test Set is: 60.13 | sMAPE for Test Set is: 42.58% | rMAE for Test Set is: 3.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:01:29,280]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:01:31,298]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:01:32,668]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:01:34,486]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:01:37,344]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:01:41,527]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:01:41,850]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:01:46,265]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:01:50,043]\u001b[0m Trial 1 finished with value: 75.52508226435499 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036668942388668473, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0303648180508429, 'dropout_rate_Layer_2': 0.10632849692498719, 'dropout_rate_Layer_3': 0.12990294726635807, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 1.9449872848958146e-05, 'l1_Layer_2': 0.0013249991340849492, 'l1_Layer_3': 0.000614994556862515, 'n_units_Layer_1': 105, 'n_units_Layer_2': 105, 'n_units_Layer_3': 195}. Best is trial 3 with value: 33.34691630922438.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 75.53 | sMAPE for Validation Set is: 28.06% | rMAE for Validation Set is: 1.19\n",
      "MAE for Test Set is: 53.47 | sMAPE for Test Set is: 34.25% | rMAE for Test Set is: 2.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:01:50,379]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:01:50,656]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:01:57,044]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:01:57,281]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:01:57,356]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:01:59,037]\u001b[0m Trial 44 finished with value: 142.73910329394278 and parameters: {'n_hidden': 4, 'learning_rate': 0.0846688609831506, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08763928313647602, 'dropout_rate_Layer_2': 0.2844614698686447, 'dropout_rate_Layer_3': 0.3867518319146487, 'dropout_rate_Layer_4': 0.1718629389204204, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.03224907554527299, 'l1_Layer_2': 0.010046598491130711, 'l1_Layer_3': 0.00017500105522738868, 'l1_Layer_4': 0.006830718112636627, 'n_units_Layer_1': 125, 'n_units_Layer_2': 270, 'n_units_Layer_3': 155, 'n_units_Layer_4': 135}. Best is trial 3 with value: 33.34691630922438.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 142.74 | sMAPE for Validation Set is: 58.96% | rMAE for Validation Set is: 2.24\n",
      "MAE for Test Set is: 26.18 | sMAPE for Test Set is: 26.50% | rMAE for Test Set is: 1.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:02:05,428]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:02:05,636]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:02:05,983]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:02:11,909]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:02:15,557]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:02:18,162]\u001b[0m Trial 49 finished with value: 93.92206512463603 and parameters: {'n_hidden': 3, 'learning_rate': 0.020478129820303746, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16103236458027267, 'dropout_rate_Layer_2': 0.021706054872632885, 'dropout_rate_Layer_3': 0.17427395389908887, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001241412749065356, 'l1_Layer_2': 0.06874769538454412, 'l1_Layer_3': 0.014434802629633169, 'n_units_Layer_1': 165, 'n_units_Layer_2': 250, 'n_units_Layer_3': 180}. Best is trial 3 with value: 33.34691630922438.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 93.92 | sMAPE for Validation Set is: 33.81% | rMAE for Validation Set is: 1.47\n",
      "MAE for Test Set is: 42.52 | sMAPE for Test Set is: 30.80% | rMAE for Test Set is: 2.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:02:18,726]\u001b[0m Trial 53 finished with value: 98.57039234859319 and parameters: {'n_hidden': 3, 'learning_rate': 0.03344247720062428, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1526585052822328, 'dropout_rate_Layer_2': 0.09679418568203149, 'dropout_rate_Layer_3': 0.32974691026588415, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001086739202492509, 'l1_Layer_2': 9.375839077123592e-05, 'l1_Layer_3': 0.00160054617668022, 'n_units_Layer_1': 160, 'n_units_Layer_2': 255, 'n_units_Layer_3': 240}. Best is trial 3 with value: 33.34691630922438.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 98.57 | sMAPE for Validation Set is: 36.22% | rMAE for Validation Set is: 1.55\n",
      "MAE for Test Set is: 28.91 | sMAPE for Test Set is: 32.88% | rMAE for Test Set is: 1.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:02:22,821]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:02:29,490]\u001b[0m Trial 54 finished with value: 84.21930860249468 and parameters: {'n_hidden': 3, 'learning_rate': 0.0072503130323590854, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11700614021012049, 'dropout_rate_Layer_2': 0.18753462094161988, 'dropout_rate_Layer_3': 0.09269251301520783, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00029326436998357205, 'l1_Layer_2': 3.0270555588702377e-05, 'l1_Layer_3': 5.646151496320434e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 225, 'n_units_Layer_3': 125}. Best is trial 3 with value: 33.34691630922438.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 84.22 | sMAPE for Validation Set is: 30.18% | rMAE for Validation Set is: 1.32\n",
      "MAE for Test Set is: 43.37 | sMAPE for Test Set is: 30.75% | rMAE for Test Set is: 2.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:02:34,541]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:02:38,130]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:02:40,299]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:02:40,643]\u001b[0m Trial 60 finished with value: 52.59416546195579 and parameters: {'n_hidden': 3, 'learning_rate': 0.009591818091776281, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0854946822099299, 'dropout_rate_Layer_2': 0.13227523508302402, 'dropout_rate_Layer_3': 0.15463378071449924, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00864181540144359, 'l1_Layer_2': 0.003568527480988111, 'l1_Layer_3': 0.000413585964920897, 'n_units_Layer_1': 220, 'n_units_Layer_2': 270, 'n_units_Layer_3': 150}. Best is trial 3 with value: 33.34691630922438.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.59 | sMAPE for Validation Set is: 18.65% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 14.84 | sMAPE for Test Set is: 15.56% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:02:46,654]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:02:51,075]\u001b[0m Trial 58 finished with value: 33.37548032156804 and parameters: {'n_hidden': 3, 'learning_rate': 0.01688732418335112, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24939156235547008, 'dropout_rate_Layer_2': 0.014746584163318366, 'dropout_rate_Layer_3': 0.252332650289569, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01096209677738536, 'l1_Layer_2': 0.00011115351329543836, 'l1_Layer_3': 0.00024009580449565747, 'n_units_Layer_1': 145, 'n_units_Layer_2': 190, 'n_units_Layer_3': 205}. Best is trial 3 with value: 33.34691630922438.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.38 | sMAPE for Validation Set is: 13.07% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 12.57 | sMAPE for Test Set is: 13.86% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:02:52,475]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:02:58,163]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 34.77 | sMAPE for Validation Set is: 13.61% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 15.37 | sMAPE for Test Set is: 16.68% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:02:59,931]\u001b[0m Trial 65 finished with value: 34.76514795472058 and parameters: {'n_hidden': 3, 'learning_rate': 0.01607473890774856, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25545643205833574, 'dropout_rate_Layer_2': 0.31911236832756673, 'dropout_rate_Layer_3': 0.24993141617279369, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00028313958686827063, 'l1_Layer_2': 9.365393134681456e-05, 'l1_Layer_3': 0.04316801166155545, 'n_units_Layer_1': 135, 'n_units_Layer_2': 195, 'n_units_Layer_3': 205}. Best is trial 3 with value: 33.34691630922438.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:03:03,213]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:03:05,283]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:03:07,731]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:03:08,349]\u001b[0m Trial 63 finished with value: 34.53807581818082 and parameters: {'n_hidden': 3, 'learning_rate': 0.018162020797689953, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22751983860277813, 'dropout_rate_Layer_2': 0.3197651471550968, 'dropout_rate_Layer_3': 0.2268052912771268, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011645680460954009, 'l1_Layer_2': 0.00011203806713980157, 'l1_Layer_3': 0.035574175411098495, 'n_units_Layer_1': 145, 'n_units_Layer_2': 150, 'n_units_Layer_3': 205}. Best is trial 3 with value: 33.34691630922438.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:03:08,491]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 34.54 | sMAPE for Validation Set is: 13.84% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 16.95 | sMAPE for Test Set is: 17.70% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:03:10,530]\u001b[0m Trial 67 finished with value: 35.83115497960281 and parameters: {'n_hidden': 3, 'learning_rate': 0.013704148000411294, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2989845935372197, 'dropout_rate_Layer_2': 0.03021286694124412, 'dropout_rate_Layer_3': 0.2735396244618725, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01605424587868161, 'l1_Layer_2': 6.419801510587121e-05, 'l1_Layer_3': 1.8342765356116657e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 150, 'n_units_Layer_3': 170}. Best is trial 3 with value: 33.34691630922438.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 35.83 | sMAPE for Validation Set is: 13.84% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 14.78 | sMAPE for Test Set is: 16.22% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:03:13,615]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:03:17,420]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:03:19,028]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:03:24,378]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:03:27,769]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:03:33,429]\u001b[0m Trial 76 finished with value: 35.19459978211081 and parameters: {'n_hidden': 3, 'learning_rate': 0.011047491779930108, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2531641297922457, 'dropout_rate_Layer_2': 0.028340876698757806, 'dropout_rate_Layer_3': 0.27026658575171586, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.032583185212975575, 'l1_Layer_2': 5.410141870572644e-05, 'l1_Layer_3': 4.035852500361074e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 180, 'n_units_Layer_3': 90}. Best is trial 3 with value: 33.34691630922438.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 35.19 | sMAPE for Validation Set is: 13.67% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 14.08 | sMAPE for Test Set is: 15.73% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:03:36,299]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:03:39,127]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:03:41,634]\u001b[0m Trial 79 finished with value: 32.58427326684558 and parameters: {'n_hidden': 3, 'learning_rate': 0.0076475839943566165, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2632867823846778, 'dropout_rate_Layer_2': 0.01981308534019467, 'dropout_rate_Layer_3': 0.2209275103644429, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005723973141181339, 'l1_Layer_2': 4.710945097748095e-05, 'l1_Layer_3': 0.00016264240746035623, 'n_units_Layer_1': 125, 'n_units_Layer_2': 215, 'n_units_Layer_3': 95}. Best is trial 79 with value: 32.58427326684558.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.58 | sMAPE for Validation Set is: 12.79% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 13.39 | sMAPE for Test Set is: 14.38% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:03:44,898]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:03:46,795]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:03:48,327]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:03:50,289]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:03:53,688]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:03:55,257]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:03:58,111]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:04:01,004]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:04:02,313]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:04:05,528]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:04:07,611]\u001b[0m Trial 83 finished with value: 33.28715779040778 and parameters: {'n_hidden': 3, 'learning_rate': 0.007509099860845121, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2962339075514165, 'dropout_rate_Layer_2': 0.020803259720316117, 'dropout_rate_Layer_3': 0.32067727462909895, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.015445684436880363, 'l1_Layer_2': 1.7596762781922876e-05, 'l1_Layer_3': 0.0001330634004058962, 'n_units_Layer_1': 215, 'n_units_Layer_2': 145, 'n_units_Layer_3': 85}. Best is trial 79 with value: 32.58427326684558.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.29 | sMAPE for Validation Set is: 13.02% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 13.47 | sMAPE for Test Set is: 14.80% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:04:10,307]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:04:10,818]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:04:12,665]\u001b[0m Trial 81 finished with value: 36.90598033514325 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007579048084601214, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3470766147595501, 'dropout_rate_Layer_2': 0.129947109203507, 'dropout_rate_Layer_3': 0.08641280680638919, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.012570750916586932, 'l1_Layer_2': 0.07572631882330418, 'l1_Layer_3': 0.00300427693554299, 'n_units_Layer_1': 270, 'n_units_Layer_2': 165, 'n_units_Layer_3': 200}. Best is trial 79 with value: 32.58427326684558.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.91 | sMAPE for Validation Set is: 14.38% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 17.45 | sMAPE for Test Set is: 17.12% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:04:14,018]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:04:17,995]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:04:20,164]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:04:20,466]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:04:22,460]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:04:22,572]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:04:26,672]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:04:28,715]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:04:29,108]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:04:29,209]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:04:30,496]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:04:34,755]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:04:35,852]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:04:39,151]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:04:39,688]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:04:42,496]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:04:42,744]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:04:45,488]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:04:47,037]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:04:49,407]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:04:50,874]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:04:51,026]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:04:51,528]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:04:52,143]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:04:58,431]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:05:01,948]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:05:03,026]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:05:07,592]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:05:09,908]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:05:12,779]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:05:13,204]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:05:13,558]\u001b[0m Trial 125 finished with value: 97.85169021602894 and parameters: {'n_hidden': 4, 'learning_rate': 0.08706951662286219, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30687880697449627, 'dropout_rate_Layer_2': 0.032249040843209544, 'dropout_rate_Layer_3': 0.01050127489658883, 'dropout_rate_Layer_4': 0.16261150158520876, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.011196565387693197, 'l1_Layer_2': 0.02346808669321962, 'l1_Layer_3': 9.069640565824205e-05, 'l1_Layer_4': 0.00012616195802628934, 'n_units_Layer_1': 120, 'n_units_Layer_2': 300, 'n_units_Layer_3': 175, 'n_units_Layer_4': 265}. Best is trial 79 with value: 32.58427326684558.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 97.85 | sMAPE for Validation Set is: 35.22% | rMAE for Validation Set is: 1.54\n",
      "MAE for Test Set is: 73.08 | sMAPE for Test Set is: 47.11% | rMAE for Test Set is: 3.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:05:16,147]\u001b[0m Trial 124 finished with value: 82.73703627713344 and parameters: {'n_hidden': 4, 'learning_rate': 0.013475239079158905, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17787253497994404, 'dropout_rate_Layer_2': 0.13688640413884112, 'dropout_rate_Layer_3': 0.12295026294989203, 'dropout_rate_Layer_4': 0.2834391653412341, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 8.84903517150506e-05, 'l1_Layer_2': 7.479774584611825e-05, 'l1_Layer_3': 2.194368632164465e-05, 'l1_Layer_4': 1.015685801696264e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 55, 'n_units_Layer_3': 270, 'n_units_Layer_4': 215}. Best is trial 79 with value: 32.58427326684558.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 82.74 | sMAPE for Validation Set is: 29.89% | rMAE for Validation Set is: 1.30\n",
      "MAE for Test Set is: 72.60 | sMAPE for Test Set is: 51.73% | rMAE for Test Set is: 3.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:05:19,529]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:05:24,903]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:05:25,524]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:05:29,038]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:05:29,643]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:05:34,322]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:05:35,262]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:05:39,684]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:05:40,072]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:05:46,640]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:05:59,340]\u001b[0m Trial 142 finished with value: 34.45887481449703 and parameters: {'n_hidden': 3, 'learning_rate': 0.04327472900572495, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13888033356746263, 'dropout_rate_Layer_2': 0.21055116078975666, 'dropout_rate_Layer_3': 0.057877421685551725, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.933975752809372e-05, 'l1_Layer_2': 0.008408202641460853, 'l1_Layer_3': 1.2657054649414379e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 220, 'n_units_Layer_3': 70}. Best is trial 79 with value: 32.58427326684558.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 34.46 | sMAPE for Validation Set is: 13.46% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.22 | sMAPE for Test Set is: 15.14% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:06:06,079]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:06:08,734]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:06:10,682]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:06:13,944]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:06:16,784]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:06:19,914]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:06:42,666]\u001b[0m Trial 145 finished with value: 34.505983571802 and parameters: {'n_hidden': 3, 'learning_rate': 0.021399792634446663, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14464954428016064, 'dropout_rate_Layer_2': 0.08051606198367936, 'dropout_rate_Layer_3': 0.042389717970962325, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018632828408782407, 'l1_Layer_2': 0.005759828391707566, 'l1_Layer_3': 0.0056337144919604756, 'n_units_Layer_1': 295, 'n_units_Layer_2': 190, 'n_units_Layer_3': 210}. Best is trial 79 with value: 32.58427326684558.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 34.51 | sMAPE for Validation Set is: 13.67% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.98 | sMAPE for Test Set is: 15.84% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:06:48,512]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:06:55,240]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:06:58,340]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:07:06,721]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:07:32,512]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:07:34,098]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:07:41,082]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:07:43,171]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:07:44,295]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:07:51,848]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:07:52,152]\u001b[0m Trial 133 finished with value: 69.83808030122263 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005082206470804715, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24291516298919913, 'dropout_rate_Layer_2': 0.17952167082221185, 'dropout_rate_Layer_3': 0.07416181856358381, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0004180425741778575, 'l1_Layer_2': 0.001168123464501971, 'l1_Layer_3': 0.00028732554305132554, 'n_units_Layer_1': 265, 'n_units_Layer_2': 50, 'n_units_Layer_3': 300}. Best is trial 79 with value: 32.58427326684558.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 69.84 | sMAPE for Validation Set is: 24.31% | rMAE for Validation Set is: 1.10\n",
      "MAE for Test Set is: 14.61 | sMAPE for Test Set is: 15.95% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:07:56,048]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:07:59,511]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:07:59,938]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:08:05,646]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:08:09,139]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:08:17,024]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:08:19,891]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:08:31,532]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:08:32,081]\u001b[0m Trial 164 finished with value: 32.32912605727851 and parameters: {'n_hidden': 3, 'learning_rate': 0.013738262168139672, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15934488891919618, 'dropout_rate_Layer_2': 0.09958450264517646, 'dropout_rate_Layer_3': 0.12942245556131488, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0021054321433392883, 'l1_Layer_2': 0.006088417739847441, 'l1_Layer_3': 0.019366130118277664, 'n_units_Layer_1': 270, 'n_units_Layer_2': 190, 'n_units_Layer_3': 240}. Best is trial 164 with value: 32.32912605727851.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.33 | sMAPE for Validation Set is: 13.01% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 13.77 | sMAPE for Test Set is: 14.82% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:08:35,588]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:08:37,989]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:08:41,290]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:09:02,734]\u001b[0m Trial 140 finished with value: 36.077297147195 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005320045377738735, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2808436257999631, 'dropout_rate_Layer_2': 0.16620800454366236, 'dropout_rate_Layer_3': 0.1878378129646427, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.009224024834940423, 'l1_Layer_2': 0.0110262177464917, 'l1_Layer_3': 0.01381954023837568, 'n_units_Layer_1': 265, 'n_units_Layer_2': 65, 'n_units_Layer_3': 300}. Best is trial 164 with value: 32.32912605727851.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.08 | sMAPE for Validation Set is: 13.89% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 16.55 | sMAPE for Test Set is: 16.96% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:09:15,973]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:09:17,947]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:09:20,062]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:09:22,461]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:09:25,163]\u001b[0m Trial 173 finished with value: 53.81653529817165 and parameters: {'n_hidden': 4, 'learning_rate': 0.01218572776926729, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22162153000536128, 'dropout_rate_Layer_2': 0.14102787834679673, 'dropout_rate_Layer_3': 0.2516464249921703, 'dropout_rate_Layer_4': 0.03681523104972544, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00044531363737655645, 'l1_Layer_2': 0.00023947246900255079, 'l1_Layer_3': 0.00837195958771686, 'l1_Layer_4': 0.008356985717164403, 'n_units_Layer_1': 130, 'n_units_Layer_2': 265, 'n_units_Layer_3': 160, 'n_units_Layer_4': 265}. Best is trial 164 with value: 32.32912605727851.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.82 | sMAPE for Validation Set is: 19.91% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 25.07 | sMAPE for Test Set is: 22.56% | rMAE for Test Set is: 1.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:09:25,483]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:09:30,460]\u001b[0m Trial 158 finished with value: 40.85203647455467 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019238206488336905, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33950098082361885, 'dropout_rate_Layer_2': 0.37526134773728453, 'dropout_rate_Layer_3': 0.21020297529973073, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.026195838208788447, 'l1_Layer_2': 0.008332079884781159, 'l1_Layer_3': 0.005999863311087198, 'n_units_Layer_1': 280, 'n_units_Layer_2': 295, 'n_units_Layer_3': 160}. Best is trial 164 with value: 32.32912605727851.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 40.85 | sMAPE for Validation Set is: 15.81% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 17.88 | sMAPE for Test Set is: 18.12% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:09:31,066]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:09:32,943]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:09:38,406]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:09:39,591]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:09:45,434]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:09:45,715]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:09:50,941]\u001b[0m Trial 184 finished with value: 91.59675943316029 and parameters: {'n_hidden': 4, 'learning_rate': 0.01011743734836622, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38969717052041, 'dropout_rate_Layer_2': 0.31210040430006103, 'dropout_rate_Layer_3': 0.0877163160618376, 'dropout_rate_Layer_4': 0.13140703727988878, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.07277246267679084, 'l1_Layer_2': 0.000397806447247639, 'l1_Layer_3': 1.6469499643646123e-05, 'l1_Layer_4': 0.0006637565134250971, 'n_units_Layer_1': 255, 'n_units_Layer_2': 240, 'n_units_Layer_3': 180, 'n_units_Layer_4': 300}. Best is trial 164 with value: 32.32912605727851.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 91.60 | sMAPE for Validation Set is: 32.85% | rMAE for Validation Set is: 1.44\n",
      "MAE for Test Set is: 44.05 | sMAPE for Test Set is: 32.75% | rMAE for Test Set is: 2.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:09:51,222]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:09:51,863]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:09:52,502]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:09:55,914]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:09:58,716]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:10:00,663]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:10:00,781]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:10:05,341]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:10:10,602]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:10:10,899]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:10:16,093]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:10:19,915]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:10:25,948]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:10:34,416]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:10:41,932]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:10:44,081]\u001b[0m Trial 193 finished with value: 33.731430236915855 and parameters: {'n_hidden': 3, 'learning_rate': 0.008710770401419465, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2726353806007101, 'dropout_rate_Layer_2': 0.3322323230975312, 'dropout_rate_Layer_3': 0.07469108811238404, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0037735293285836636, 'l1_Layer_2': 0.00020212217988014263, 'l1_Layer_3': 0.038899315694707455, 'n_units_Layer_1': 110, 'n_units_Layer_2': 160, 'n_units_Layer_3': 80}. Best is trial 164 with value: 32.32912605727851.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.73 | sMAPE for Validation Set is: 13.26% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 13.35 | sMAPE for Test Set is: 14.62% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:10:45,621]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:10:46,298]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:10:50,825]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:10:55,149]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:10:57,868]\u001b[0m Trial 197 finished with value: 31.164280678138166 and parameters: {'n_hidden': 3, 'learning_rate': 0.001630810967072816, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07036731670391294, 'dropout_rate_Layer_2': 0.2563059124785336, 'dropout_rate_Layer_3': 0.35132708776122207, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00037649979354549887, 'l1_Layer_2': 0.0001661654806572643, 'l1_Layer_3': 0.0003182362396238056, 'n_units_Layer_1': 275, 'n_units_Layer_2': 210, 'n_units_Layer_3': 210}. Best is trial 197 with value: 31.164280678138166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 31.16 | sMAPE for Validation Set is: 12.43% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 12.80 | sMAPE for Test Set is: 14.09% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:11:10,827]\u001b[0m Trial 205 finished with value: 33.00611154908796 and parameters: {'n_hidden': 3, 'learning_rate': 0.0047116748995282435, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11943664703533764, 'dropout_rate_Layer_2': 0.0474519417446789, 'dropout_rate_Layer_3': 0.11338501157154944, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009527660274197199, 'l1_Layer_2': 0.05586698456628651, 'l1_Layer_3': 0.0067056197721401655, 'n_units_Layer_1': 290, 'n_units_Layer_2': 170, 'n_units_Layer_3': 150}. Best is trial 197 with value: 31.164280678138166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.01 | sMAPE for Validation Set is: 13.03% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 12.49 | sMAPE for Test Set is: 13.89% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:11:18,378]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:11:25,038]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:11:28,065]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:11:37,735]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:11:42,390]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:11:45,833]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:11:48,884]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:11:59,715]\u001b[0m Trial 204 finished with value: 30.60971467513168 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008639154665095662, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12491020699590538, 'dropout_rate_Layer_2': 0.05087617201591629, 'dropout_rate_Layer_3': 0.11545710603344829, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1960218119633723e-05, 'l1_Layer_2': 0.05781193843386623, 'l1_Layer_3': 0.000974677651157894, 'n_units_Layer_1': 300, 'n_units_Layer_2': 170, 'n_units_Layer_3': 155}. Best is trial 204 with value: 30.60971467513168.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.61 | sMAPE for Validation Set is: 12.07% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 11.35 | sMAPE for Test Set is: 12.82% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:12:03,334]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:12:07,363]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:12:07,922]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:12:14,297]\u001b[0m Trial 208 finished with value: 29.4150097326815 and parameters: {'n_hidden': 3, 'learning_rate': 0.004873853253816608, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27623655860524754, 'dropout_rate_Layer_2': 0.19510145278288052, 'dropout_rate_Layer_3': 0.011665174814517898, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.5959241320581032e-05, 'l1_Layer_2': 4.903107305829239e-05, 'l1_Layer_3': 2.0169073332189557e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 70, 'n_units_Layer_3': 65}. Best is trial 208 with value: 29.4150097326815.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.42 | sMAPE for Validation Set is: 11.51% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 12.09 | sMAPE for Test Set is: 13.49% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:12:14,662]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:12:15,016]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:12:20,605]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:12:21,222]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:12:25,752]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:12:25,834]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:12:38,202]\u001b[0m Trial 212 finished with value: 28.72900007827766 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007869102480489297, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12244833781792962, 'dropout_rate_Layer_2': 0.09328004866828599, 'dropout_rate_Layer_3': 0.12018812933997655, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009742761604463271, 'l1_Layer_2': 0.016424722664866085, 'l1_Layer_3': 0.0011152865442872239, 'n_units_Layer_1': 300, 'n_units_Layer_2': 175, 'n_units_Layer_3': 155}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.73 | sMAPE for Validation Set is: 11.40% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 11.33 | sMAPE for Test Set is: 12.76% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:12:55,889]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:13:10,210]\u001b[0m Trial 228 finished with value: 50.127159435824524 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015251251532140471, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2670830331954543, 'dropout_rate_Layer_2': 0.14830441897336524, 'dropout_rate_Layer_3': 0.129886315561515, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.8983168855857815e-05, 'l1_Layer_2': 0.006383946233355394, 'l1_Layer_3': 1.9766999288648902e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 210, 'n_units_Layer_3': 300}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.13 | sMAPE for Validation Set is: 17.28% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 13.60 | sMAPE for Test Set is: 15.06% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:13:10,710]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:13:15,486]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:13:15,676]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:13:20,543]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:13:22,802]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:13:28,854]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:13:29,102]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:13:34,437]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:13:37,237]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:13:37,474]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:13:39,144]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:13:42,492]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:13:44,892]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:13:45,398]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:13:51,156]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:13:54,464]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:14:11,951]\u001b[0m Trial 232 finished with value: 29.40786462685249 and parameters: {'n_hidden': 3, 'learning_rate': 0.005595430746895011, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2503076126419083, 'dropout_rate_Layer_2': 0.14286695746374783, 'dropout_rate_Layer_3': 0.0032215291030667195, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.2655677207283634e-05, 'l1_Layer_2': 1.7229039727060296e-05, 'l1_Layer_3': 1.3087252806662155e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 95, 'n_units_Layer_3': 95}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.41 | sMAPE for Validation Set is: 11.53% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 11.70 | sMAPE for Test Set is: 13.21% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:14:14,990]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:14:20,537]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:14:34,811]\u001b[0m Trial 243 finished with value: 98.85102117877655 and parameters: {'n_hidden': 3, 'learning_rate': 0.010013874513599696, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38571868231650946, 'dropout_rate_Layer_2': 0.37315802042705815, 'dropout_rate_Layer_3': 0.13345398086174468, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0012628877564973629, 'l1_Layer_2': 0.04922403077479295, 'l1_Layer_3': 0.0016980655667944756, 'n_units_Layer_1': 145, 'n_units_Layer_2': 290, 'n_units_Layer_3': 60}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 98.85 | sMAPE for Validation Set is: 35.87% | rMAE for Validation Set is: 1.55\n",
      "MAE for Test Set is: 47.23 | sMAPE for Test Set is: 33.62% | rMAE for Test Set is: 2.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:14:40,636]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:14:43,482]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:14:46,845]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:14:50,372]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:14:50,954]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:14:56,970]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:14:57,125]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:15:04,040]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:15:05,747]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:15:07,978]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:15:29,933]\u001b[0m Trial 247 finished with value: 60.67085152087932 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005169466103936797, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2581607549842427, 'dropout_rate_Layer_2': 0.39197189722729175, 'dropout_rate_Layer_3': 0.08979562065644191, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005727882249253829, 'l1_Layer_2': 0.002189550260357919, 'l1_Layer_3': 0.0041950678966061914, 'n_units_Layer_1': 300, 'n_units_Layer_2': 140, 'n_units_Layer_3': 225}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 60.67 | sMAPE for Validation Set is: 20.87% | rMAE for Validation Set is: 0.95\n",
      "MAE for Test Set is: 15.32 | sMAPE for Test Set is: 15.75% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:15:32,649]\u001b[0m Trial 253 finished with value: 28.991322035132395 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017132685099686652, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09976627147208655, 'dropout_rate_Layer_2': 0.049533483363523007, 'dropout_rate_Layer_3': 0.12336031101806254, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.454650421025395e-05, 'l1_Layer_2': 0.02571894622278462, 'l1_Layer_3': 0.0011637388401771487, 'n_units_Layer_1': 275, 'n_units_Layer_2': 130, 'n_units_Layer_3': 130}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.99 | sMAPE for Validation Set is: 11.53% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 12.30 | sMAPE for Test Set is: 13.60% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:15:35,712]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:15:39,832]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:15:53,295]\u001b[0m Trial 260 finished with value: 29.37740462240116 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019517215579543923, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09960600208811954, 'dropout_rate_Layer_2': 0.08755267469861289, 'dropout_rate_Layer_3': 0.024344548916221894, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.081029391774182e-05, 'l1_Layer_2': 0.09700276796982191, 'l1_Layer_3': 6.566437653779002e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 145, 'n_units_Layer_3': 170}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.38 | sMAPE for Validation Set is: 11.65% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 11.80 | sMAPE for Test Set is: 13.10% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:15:57,205]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:16:02,217]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:16:11,260]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:16:17,214]\u001b[0m Trial 261 finished with value: 44.945883502711574 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005108698444865002, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3797866208645259, 'dropout_rate_Layer_2': 0.18002565455693648, 'dropout_rate_Layer_3': 0.11279638459585609, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0741773621429259, 'l1_Layer_2': 0.003050698214832854, 'l1_Layer_3': 0.005212378212467225, 'n_units_Layer_1': 295, 'n_units_Layer_2': 125, 'n_units_Layer_3': 225}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.95 | sMAPE for Validation Set is: 16.86% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 18.97 | sMAPE for Test Set is: 19.36% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:16:19,018]\u001b[0m Trial 262 finished with value: 30.04569471394771 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019398985426468127, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09754227263538803, 'dropout_rate_Layer_2': 0.08847796184257506, 'dropout_rate_Layer_3': 0.019348357900365414, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.980018428657695e-05, 'l1_Layer_2': 0.014985337376479382, 'l1_Layer_3': 0.006180580016339381, 'n_units_Layer_1': 300, 'n_units_Layer_2': 150, 'n_units_Layer_3': 170}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.05 | sMAPE for Validation Set is: 11.96% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 13.70 | sMAPE for Test Set is: 14.34% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:16:21,358]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:16:25,277]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:16:37,299]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:16:38,328]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:17:25,352]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:17:29,331]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:17:33,126]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:17:33,777]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:17:36,770]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:17:37,900]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:17:42,677]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:17:43,020]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:17:47,028]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:17:53,107]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:17:55,787]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:17:55,904]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:17:58,080]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:18:04,389]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:18:05,814]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:18:10,185]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:18:12,373]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:18:30,759]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:18:37,690]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:18:50,613]\u001b[0m Trial 290 finished with value: 69.44062228911416 and parameters: {'n_hidden': 3, 'learning_rate': 0.003647741736654737, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11204551155743864, 'dropout_rate_Layer_2': 0.28847878252714226, 'dropout_rate_Layer_3': 0.25797367672764976, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0006709544260440004, 'l1_Layer_2': 0.00020192665283493073, 'l1_Layer_3': 0.00034472300716896937, 'n_units_Layer_1': 225, 'n_units_Layer_2': 85, 'n_units_Layer_3': 300}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 69.44 | sMAPE for Validation Set is: 24.17% | rMAE for Validation Set is: 1.09\n",
      "MAE for Test Set is: 23.40 | sMAPE for Test Set is: 19.98% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:18:52,249]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:18:55,739]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:18:57,791]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:18:58,374]\u001b[0m Trial 291 finished with value: 68.90001194891762 and parameters: {'n_hidden': 3, 'learning_rate': 0.0037663418460931568, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08164250384443536, 'dropout_rate_Layer_2': 0.2654260326286178, 'dropout_rate_Layer_3': 0.24401727941992224, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.3992263472683315e-05, 'l1_Layer_2': 0.00011694418265345734, 'l1_Layer_3': 0.00031748232593597814, 'n_units_Layer_1': 220, 'n_units_Layer_2': 85, 'n_units_Layer_3': 300}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 68.90 | sMAPE for Validation Set is: 23.99% | rMAE for Validation Set is: 1.08\n",
      "MAE for Test Set is: 26.06 | sMAPE for Test Set is: 21.66% | rMAE for Test Set is: 1.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:19:02,895]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:19:03,228]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:19:05,997]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:19:08,246]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:19:11,924]\u001b[0m Trial 293 finished with value: 30.768455209891886 and parameters: {'n_hidden': 3, 'learning_rate': 0.000982812561696755, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07113408012558554, 'dropout_rate_Layer_2': 0.14724842098366397, 'dropout_rate_Layer_3': 0.1840541143005319, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0508817311598913e-05, 'l1_Layer_2': 0.040313347166122566, 'l1_Layer_3': 1.6933945633543687e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 115, 'n_units_Layer_3': 130}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.77 | sMAPE for Validation Set is: 12.07% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 12.70 | sMAPE for Test Set is: 13.77% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:19:17,529]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:19:17,658]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:19:31,929]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:19:34,236]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:19:39,676]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:19:41,586]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:19:44,312]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:19:45,919]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:19:47,501]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:19:50,399]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:19:50,882]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:19:51,546]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:19:56,030]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:19:56,863]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:19:57,656]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:20:03,572]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:20:08,692]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:20:14,125]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:20:18,059]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:20:18,147]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:20:22,727]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:20:23,853]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:20:26,803]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:20:29,965]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:20:31,730]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:20:36,144]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:20:37,904]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:20:42,252]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:20:42,440]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:20:45,775]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:20:50,253]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:20:53,046]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:20:53,958]\u001b[0m Trial 320 finished with value: 33.08502927876939 and parameters: {'n_hidden': 4, 'learning_rate': 0.011677654021473948, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3825314924693047, 'dropout_rate_Layer_2': 0.3565942860858758, 'dropout_rate_Layer_3': 0.3970025629142835, 'dropout_rate_Layer_4': 0.022688708499937815, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00020165214454723814, 'l1_Layer_2': 0.00028382848149376556, 'l1_Layer_3': 0.0005312056242656691, 'l1_Layer_4': 0.0013572282752414714, 'n_units_Layer_1': 270, 'n_units_Layer_2': 245, 'n_units_Layer_3': 255, 'n_units_Layer_4': 185}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.09 | sMAPE for Validation Set is: 12.88% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 12.74 | sMAPE for Test Set is: 13.80% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:20:56,979]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:21:23,244]\u001b[0m Trial 338 finished with value: 32.62498881772466 and parameters: {'n_hidden': 4, 'learning_rate': 0.012003479378931875, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1587141173041116, 'dropout_rate_Layer_2': 0.35328365119103705, 'dropout_rate_Layer_3': 0.39900981916676037, 'dropout_rate_Layer_4': 0.002426086214020764, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00015336197589302134, 'l1_Layer_2': 0.00029803809201413956, 'l1_Layer_3': 0.00037666149519722375, 'l1_Layer_4': 0.0012245912404365016, 'n_units_Layer_1': 50, 'n_units_Layer_2': 300, 'n_units_Layer_3': 265, 'n_units_Layer_4': 190}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.62 | sMAPE for Validation Set is: 12.98% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 14.16 | sMAPE for Test Set is: 15.13% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:21:29,020]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:21:31,762]\u001b[0m Trial 334 finished with value: 29.596684510756692 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010587166301573236, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09403593587265918, 'dropout_rate_Layer_2': 0.114422340983457, 'dropout_rate_Layer_3': 0.17035433158542165, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.251223323405782e-05, 'l1_Layer_2': 0.014613909709917609, 'l1_Layer_3': 1.0138297893176608e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 145, 'n_units_Layer_3': 140}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.60 | sMAPE for Validation Set is: 11.69% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 12.28 | sMAPE for Test Set is: 13.43% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:21:39,275]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:21:41,614]\u001b[0m Trial 337 finished with value: 29.14658531764366 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010279232891839763, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06988515092727555, 'dropout_rate_Layer_2': 0.1076952903169279, 'dropout_rate_Layer_3': 0.10422179046204919, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.527721211160747e-05, 'l1_Layer_2': 0.014245357645292956, 'l1_Layer_3': 8.097358976636683e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 145, 'n_units_Layer_3': 135}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.15 | sMAPE for Validation Set is: 11.54% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 12.30 | sMAPE for Test Set is: 13.42% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:21:44,501]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:21:46,674]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:21:49,390]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:22:01,539]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:22:03,193]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:22:06,827]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:22:08,222]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:22:08,411]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:22:11,169]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:22:14,384]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:22:15,154]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:22:19,004]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:22:19,650]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:22:19,789]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:22:24,904]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:22:30,161]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:22:33,535]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:22:37,063]\u001b[0m Trial 353 finished with value: 80.75117738721978 and parameters: {'n_hidden': 3, 'learning_rate': 0.06937592309896695, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0009267494440608759, 'dropout_rate_Layer_2': 0.0096797154816895, 'dropout_rate_Layer_3': 0.0005937162184658507, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.3836880341665217e-05, 'l1_Layer_2': 0.0019806187466578154, 'l1_Layer_3': 0.04394399374351553, 'n_units_Layer_1': 55, 'n_units_Layer_2': 145, 'n_units_Layer_3': 55}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 80.75 | sMAPE for Validation Set is: 29.29% | rMAE for Validation Set is: 1.27\n",
      "MAE for Test Set is: 47.69 | sMAPE for Test Set is: 33.09% | rMAE for Test Set is: 2.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:22:39,843]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:22:42,631]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:22:47,858]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:22:48,028]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:22:48,270]\u001b[0m Trial 357 finished with value: 30.51454845030658 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018232775660436882, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01819203927699589, 'dropout_rate_Layer_2': 0.07484901397162226, 'dropout_rate_Layer_3': 0.07804635382146403, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.689495046064765e-05, 'l1_Layer_2': 0.01588250919516483, 'l1_Layer_3': 9.783728188699796e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 170, 'n_units_Layer_3': 155}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.51 | sMAPE for Validation Set is: 12.08% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 11.99 | sMAPE for Test Set is: 13.06% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:22:50,982]\u001b[0m Trial 360 finished with value: 30.83831025239032 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036704259167927517, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.021808003597336117, 'dropout_rate_Layer_2': 0.07419164386872894, 'dropout_rate_Layer_3': 0.07391969513887905, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.572447897365824e-05, 'l1_Layer_2': 0.015009990172462916, 'l1_Layer_3': 8.604676675440103e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 130, 'n_units_Layer_3': 165}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.84 | sMAPE for Validation Set is: 12.20% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 11.58 | sMAPE for Test Set is: 12.97% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:22:53,586]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:22:54,589]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:22:55,133]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:22:55,673]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:23:02,737]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:23:04,792]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:23:05,294]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:23:05,935]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:23:06,825]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:23:11,547]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:23:14,005]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:23:14,190]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:23:14,275]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:23:22,150]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:23:26,814]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:23:30,729]\u001b[0m Trial 377 finished with value: 33.76279961198846 and parameters: {'n_hidden': 4, 'learning_rate': 0.006873594704771194, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14272063768567006, 'dropout_rate_Layer_2': 0.38312010842929534, 'dropout_rate_Layer_3': 0.3513153946517475, 'dropout_rate_Layer_4': 0.09212986068524281, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0016924735463496752, 'l1_Layer_2': 0.0005236960308998295, 'l1_Layer_3': 0.0001991001966397896, 'l1_Layer_4': 0.004198214731065721, 'n_units_Layer_1': 195, 'n_units_Layer_2': 280, 'n_units_Layer_3': 270, 'n_units_Layer_4': 230}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.76 | sMAPE for Validation Set is: 13.17% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 15.18 | sMAPE for Test Set is: 16.15% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:23:31,472]\u001b[0m Trial 378 finished with value: 36.89318283226681 and parameters: {'n_hidden': 3, 'learning_rate': 0.002812974509832445, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13916667294261903, 'dropout_rate_Layer_2': 0.24666269563838258, 'dropout_rate_Layer_3': 0.2645139299799964, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005935408921300425, 'l1_Layer_2': 0.012394112606256955, 'l1_Layer_3': 0.001054091446999337, 'n_units_Layer_1': 60, 'n_units_Layer_2': 160, 'n_units_Layer_3': 220}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.89 | sMAPE for Validation Set is: 14.37% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 14.53 | sMAPE for Test Set is: 15.84% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:23:36,593]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:23:40,121]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:23:52,060]\u001b[0m Trial 382 finished with value: 30.0324323657993 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015076256604481069, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13887813315398767, 'dropout_rate_Layer_2': 0.024181528146215756, 'dropout_rate_Layer_3': 0.055693696036506896, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.527963896592341e-05, 'l1_Layer_2': 0.007258257356662512, 'l1_Layer_3': 0.0007606369225975405, 'n_units_Layer_1': 300, 'n_units_Layer_2': 155, 'n_units_Layer_3': 155}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.03 | sMAPE for Validation Set is: 11.93% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.75 | sMAPE for Test Set is: 12.91% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:23:52,673]\u001b[0m Trial 386 finished with value: 31.21860759959763 and parameters: {'n_hidden': 3, 'learning_rate': 0.005268149645957074, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26577389463111245, 'dropout_rate_Layer_2': 0.12047909085986735, 'dropout_rate_Layer_3': 0.03677213751177749, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003489782750224443, 'l1_Layer_2': 0.00014297627159469295, 'l1_Layer_3': 0.00013422804151596554, 'n_units_Layer_1': 105, 'n_units_Layer_2': 60, 'n_units_Layer_3': 70}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 31.22 | sMAPE for Validation Set is: 12.27% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 12.34 | sMAPE for Test Set is: 13.63% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:23:53,602]\u001b[0m Trial 383 finished with value: 35.35746495728164 and parameters: {'n_hidden': 4, 'learning_rate': 0.01385104187359555, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20975622519092846, 'dropout_rate_Layer_2': 0.36139031497909235, 'dropout_rate_Layer_3': 0.3934678371667229, 'dropout_rate_Layer_4': 0.01919262797542312, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00017920626375424547, 'l1_Layer_2': 0.00031080501235670777, 'l1_Layer_3': 0.0006859520541374629, 'l1_Layer_4': 0.0003410512278676912, 'n_units_Layer_1': 60, 'n_units_Layer_2': 250, 'n_units_Layer_3': 250, 'n_units_Layer_4': 155}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 35.36 | sMAPE for Validation Set is: 14.40% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 18.67 | sMAPE for Test Set is: 19.53% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:23:56,569]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:23:59,025]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:23:59,610]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:24:03,871]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:24:07,645]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:24:17,124]\u001b[0m Trial 380 finished with value: 28.983653703730422 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007836938098895911, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13491032480656875, 'dropout_rate_Layer_2': 0.12728186655174195, 'dropout_rate_Layer_3': 0.05557447283220231, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016187228891546298, 'l1_Layer_2': 0.007600927487056285, 'l1_Layer_3': 2.869222034844662e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 155, 'n_units_Layer_3': 145}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.98 | sMAPE for Validation Set is: 11.60% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 12.06 | sMAPE for Test Set is: 13.10% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:24:20,226]\u001b[0m Trial 390 finished with value: 31.606234227918378 and parameters: {'n_hidden': 3, 'learning_rate': 0.004670050855765631, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26277068754239846, 'dropout_rate_Layer_2': 0.09380184520576348, 'dropout_rate_Layer_3': 0.018998136492906093, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002475410999162539, 'l1_Layer_2': 0.00018476917103358543, 'l1_Layer_3': 0.00010807875703782902, 'n_units_Layer_1': 100, 'n_units_Layer_2': 160, 'n_units_Layer_3': 70}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 31.61 | sMAPE for Validation Set is: 12.38% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 15.04 | sMAPE for Test Set is: 15.48% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:24:21,002]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:24:31,481]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:24:31,583]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.24 | sMAPE for Validation Set is: 14.11% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 16.79 | sMAPE for Test Set is: 16.67% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:24:35,463]\u001b[0m Trial 394 finished with value: 36.244257600578294 and parameters: {'n_hidden': 3, 'learning_rate': 0.03784066488091758, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1294478861723637, 'dropout_rate_Layer_2': 0.24552319444850706, 'dropout_rate_Layer_3': 0.282531514274006, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003562455974965388, 'l1_Layer_2': 0.02127231616935902, 'l1_Layer_3': 0.0003344372924201363, 'n_units_Layer_1': 50, 'n_units_Layer_2': 155, 'n_units_Layer_3': 225}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:24:38,675]\u001b[0m Trial 396 finished with value: 36.47815607900726 and parameters: {'n_hidden': 4, 'learning_rate': 0.014070004234712307, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1212598403370529, 'dropout_rate_Layer_2': 0.3324799919785747, 'dropout_rate_Layer_3': 0.39975039037077054, 'dropout_rate_Layer_4': 0.004025656455303731, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00027522414367704007, 'l1_Layer_2': 6.2313829260074e-05, 'l1_Layer_3': 0.0005743683410947777, 'l1_Layer_4': 0.002537212701723081, 'n_units_Layer_1': 275, 'n_units_Layer_2': 230, 'n_units_Layer_3': 270, 'n_units_Layer_4': 160}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.48 | sMAPE for Validation Set is: 14.25% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 16.45 | sMAPE for Test Set is: 16.98% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:24:39,289]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:24:39,606]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:24:39,872]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:24:42,567]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:24:46,934]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:24:47,864]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:24:48,796]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:24:51,469]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:24:54,714]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:24:57,357]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:24:57,658]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:25:02,261]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:25:04,244]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:25:06,863]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:25:07,176]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:25:10,777]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:25:14,699]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:25:18,537]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:25:21,230]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:25:25,062]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:25:30,842]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:25:33,692]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:25:37,746]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:25:43,127]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:25:46,248]\u001b[0m Trial 407 finished with value: 45.20421091131214 and parameters: {'n_hidden': 4, 'learning_rate': 0.009900996614566634, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18356107365604032, 'dropout_rate_Layer_2': 0.22235619762525816, 'dropout_rate_Layer_3': 0.35716228865871297, 'dropout_rate_Layer_4': 0.10017822667640275, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 6.156619546119206e-05, 'l1_Layer_2': 0.00023764094004696338, 'l1_Layer_3': 0.0016195650959272838, 'l1_Layer_4': 0.00016011727494590473, 'n_units_Layer_1': 245, 'n_units_Layer_2': 275, 'n_units_Layer_3': 210, 'n_units_Layer_4': 215}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.20 | sMAPE for Validation Set is: 16.52% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 20.35 | sMAPE for Test Set is: 21.42% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:25:46,693]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.93 | sMAPE for Validation Set is: 12.23% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.36 | sMAPE for Test Set is: 14.27% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:25:48,158]\u001b[0m Trial 418 finished with value: 30.93430928554393 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015112248474519468, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05705884105822405, 'dropout_rate_Layer_2': 0.06045222078717788, 'dropout_rate_Layer_3': 0.0622626619046073, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.2558773002173916e-05, 'l1_Layer_2': 0.010976698834886093, 'l1_Layer_3': 0.0006586789775399634, 'n_units_Layer_1': 280, 'n_units_Layer_2': 160, 'n_units_Layer_3': 170}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:25:51,087]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:25:53,085]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:25:54,191]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:25:55,223]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:25:59,882]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:26:01,498]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:26:04,555]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:26:08,331]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:26:11,244]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:26:16,030]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:26:21,303]\u001b[0m Trial 432 finished with value: 30.127984019782065 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030238414938569677, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10304321143891926, 'dropout_rate_Layer_2': 0.08254049324809257, 'dropout_rate_Layer_3': 0.08913211404836123, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.396007564704259e-05, 'l1_Layer_2': 0.019932906446387795, 'l1_Layer_3': 6.582736651871019e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 135, 'n_units_Layer_3': 155}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.13 | sMAPE for Validation Set is: 11.93% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 10.85 | sMAPE for Test Set is: 12.44% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:26:23,758]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:26:24,385]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:26:26,244]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:26:28,776]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:26:30,270]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:26:30,837]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:26:31,604]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:26:38,071]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:26:38,568]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:26:47,385]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:26:56,775]\u001b[0m Trial 444 finished with value: 30.427256529593155 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025293388970424745, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10921230493102696, 'dropout_rate_Layer_2': 0.0981900083314133, 'dropout_rate_Layer_3': 0.08984587607957886, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.1085749985833965e-05, 'l1_Layer_2': 0.00710083807189691, 'l1_Layer_3': 5.9955080032416876e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 130, 'n_units_Layer_3': 140}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.43 | sMAPE for Validation Set is: 11.90% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 11.41 | sMAPE for Test Set is: 12.74% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:27:00,823]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:27:01,288]\u001b[0m Trial 447 finished with value: 36.20091400020394 and parameters: {'n_hidden': 3, 'learning_rate': 0.03595186860733391, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05288891154607636, 'dropout_rate_Layer_2': 0.2270568669495478, 'dropout_rate_Layer_3': 0.33635129778264916, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015394168486355957, 'l1_Layer_2': 0.0018337613537162312, 'l1_Layer_3': 0.00016485179208180486, 'n_units_Layer_1': 80, 'n_units_Layer_2': 120, 'n_units_Layer_3': 225}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.20 | sMAPE for Validation Set is: 14.15% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 15.12 | sMAPE for Test Set is: 15.59% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:27:05,561]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:27:06,050]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:27:07,974]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:27:13,178]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:27:13,399]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:27:17,636]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:27:24,866]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:27:41,197]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:27:44,153]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:27:44,919]\u001b[0m Trial 458 finished with value: 30.262618544665575 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020960955104169757, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08387916960442872, 'dropout_rate_Layer_2': 0.006853762464735635, 'dropout_rate_Layer_3': 0.12290118767232314, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.0241204740163953e-05, 'l1_Layer_2': 1.2897729825890581e-05, 'l1_Layer_3': 6.974077742118829e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 150, 'n_units_Layer_3': 175}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.26 | sMAPE for Validation Set is: 12.14% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 11.26 | sMAPE for Test Set is: 12.50% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:27:47,177]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:27:51,165]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:27:51,723]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:27:52,083]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:27:57,300]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:27:57,862]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:27:58,499]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:28:04,366]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:28:04,987]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:28:05,590]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:28:08,389]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:28:09,683]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:28:10,019]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:28:10,638]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:28:13,794]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:28:17,247]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:28:19,085]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:28:24,694]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:28:29,101]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:28:33,557]\u001b[0m Trial 479 finished with value: 53.137129354317096 and parameters: {'n_hidden': 3, 'learning_rate': 0.004638501651060903, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07338496548228592, 'dropout_rate_Layer_2': 0.2835566866963771, 'dropout_rate_Layer_3': 0.22878358238566102, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00041721026339728516, 'l1_Layer_2': 0.05877869139141092, 'l1_Layer_3': 0.00023107999344174567, 'n_units_Layer_1': 240, 'n_units_Layer_2': 125, 'n_units_Layer_3': 215}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.14 | sMAPE for Validation Set is: 19.40% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 26.81 | sMAPE for Test Set is: 22.59% | rMAE for Test Set is: 1.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:28:48,136]\u001b[0m Trial 481 finished with value: 29.84400830582311 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027633238095148677, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10610931027441756, 'dropout_rate_Layer_2': 0.04281881999933775, 'dropout_rate_Layer_3': 0.0015654891916890706, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.6848024935132555e-05, 'l1_Layer_2': 1.9200143121608548e-05, 'l1_Layer_3': 0.00013007000675748369, 'n_units_Layer_1': 270, 'n_units_Layer_2': 145, 'n_units_Layer_3': 180}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.84 | sMAPE for Validation Set is: 11.92% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.86 | sMAPE for Test Set is: 13.13% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:28:52,743]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:28:52,855]\u001b[0m Trial 475 finished with value: 29.347412710083262 and parameters: {'n_hidden': 3, 'learning_rate': 0.002085447821925049, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08148899781743234, 'dropout_rate_Layer_2': 0.010295554876328068, 'dropout_rate_Layer_3': 0.12101712134105298, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.689638923703022e-05, 'l1_Layer_2': 0.01880970885040539, 'l1_Layer_3': 6.564983511501294e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 150, 'n_units_Layer_3': 175}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.35 | sMAPE for Validation Set is: 11.84% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 11.04 | sMAPE for Test Set is: 12.29% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:28:57,459]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:29:01,034]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:29:04,548]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:29:04,775]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:29:08,839]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:29:10,504]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:29:11,345]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:29:12,134]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:29:17,239]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:29:18,076]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:29:18,837]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:29:23,867]\u001b[0m Trial 490 finished with value: 69.58680759017916 and parameters: {'n_hidden': 3, 'learning_rate': 0.028093671167125796, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04548522210712482, 'dropout_rate_Layer_2': 0.05950807619504406, 'dropout_rate_Layer_3': 0.383070689476255, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.559369693504344e-05, 'l1_Layer_2': 0.0018760705341203637, 'l1_Layer_3': 0.00010389800222056297, 'n_units_Layer_1': 90, 'n_units_Layer_2': 115, 'n_units_Layer_3': 90}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 69.59 | sMAPE for Validation Set is: 24.73% | rMAE for Validation Set is: 1.09\n",
      "MAE for Test Set is: 37.45 | sMAPE for Test Set is: 27.81% | rMAE for Test Set is: 1.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:29:24,356]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:29:25,024]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:29:29,272]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:29:31,094]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:29:33,808]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:29:34,373]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:29:38,620]\u001b[0m Trial 496 finished with value: 51.74338986441188 and parameters: {'n_hidden': 3, 'learning_rate': 0.010170142716475396, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.012998922003768745, 'dropout_rate_Layer_2': 0.28711713724880955, 'dropout_rate_Layer_3': 0.3611482214703616, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00043410286768072595, 'l1_Layer_2': 0.07765744660364655, 'l1_Layer_3': 0.0002727176237546565, 'n_units_Layer_1': 235, 'n_units_Layer_2': 120, 'n_units_Layer_3': 190}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.74 | sMAPE for Validation Set is: 18.73% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 20.70 | sMAPE for Test Set is: 19.51% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:29:40,170]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:29:43,449]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:29:43,649]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:29:48,786]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:29:51,324]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:29:57,179]\u001b[0m Trial 502 finished with value: 33.368810705517035 and parameters: {'n_hidden': 4, 'learning_rate': 0.007120835688273736, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15204937515020434, 'dropout_rate_Layer_2': 0.39928182828457814, 'dropout_rate_Layer_3': 0.345230254530004, 'dropout_rate_Layer_4': 0.047346065338666435, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0012679334794342798, 'l1_Layer_2': 0.0007426658807961859, 'l1_Layer_3': 0.0001365627567911111, 'l1_Layer_4': 0.004319630552599317, 'n_units_Layer_1': 185, 'n_units_Layer_2': 260, 'n_units_Layer_3': 255, 'n_units_Layer_4': 245}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.37 | sMAPE for Validation Set is: 12.96% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 13.19 | sMAPE for Test Set is: 14.40% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:30:00,499]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:30:03,525]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:30:04,441]\u001b[0m Trial 498 finished with value: 31.555519107360414 and parameters: {'n_hidden': 4, 'learning_rate': 0.0072836088058882385, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14407122180825585, 'dropout_rate_Layer_2': 0.3985172091965348, 'dropout_rate_Layer_3': 0.3441887465870446, 'dropout_rate_Layer_4': 0.05545866362618087, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.001565627170375191, 'l1_Layer_2': 0.0007118790832210548, 'l1_Layer_3': 0.00014841074454465013, 'l1_Layer_4': 0.0045031854491441965, 'n_units_Layer_1': 190, 'n_units_Layer_2': 245, 'n_units_Layer_3': 260, 'n_units_Layer_4': 240}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 31.56 | sMAPE for Validation Set is: 12.47% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 14.15 | sMAPE for Test Set is: 15.27% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:30:04,631]\u001b[0m Trial 509 finished with value: 51.251354213036194 and parameters: {'n_hidden': 3, 'learning_rate': 0.009818039168663249, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.002687037825179312, 'dropout_rate_Layer_2': 0.2780753012143333, 'dropout_rate_Layer_3': 0.3805348863271555, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004357779903751348, 'l1_Layer_2': 0.08025241444983591, 'l1_Layer_3': 0.0002617571776689585, 'n_units_Layer_1': 240, 'n_units_Layer_2': 125, 'n_units_Layer_3': 215}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.25 | sMAPE for Validation Set is: 18.75% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 23.81 | sMAPE for Test Set is: 20.72% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:30:06,666]\u001b[0m Trial 508 finished with value: 50.838880786611604 and parameters: {'n_hidden': 3, 'learning_rate': 0.01167837313762673, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.031744585592604374, 'dropout_rate_Layer_2': 0.28230034737481846, 'dropout_rate_Layer_3': 0.37522176941886676, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003996833896014119, 'l1_Layer_2': 0.08926425356557878, 'l1_Layer_3': 0.00024259577780805968, 'n_units_Layer_1': 240, 'n_units_Layer_2': 120, 'n_units_Layer_3': 190}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.84 | sMAPE for Validation Set is: 19.03% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 27.19 | sMAPE for Test Set is: 22.48% | rMAE for Test Set is: 1.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:30:11,273]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:30:11,658]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:30:11,674]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:30:12,135]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:30:20,813]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:30:22,301]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:30:25,262]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:30:28,436]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:30:30,354]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:30:32,078]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:30:32,936]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:30:36,363]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:30:37,270]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:30:40,204]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:30:42,650]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:30:45,331]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:30:46,018]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:30:50,673]\u001b[0m Trial 524 finished with value: 49.367520632912544 and parameters: {'n_hidden': 3, 'learning_rate': 0.009101172878728081, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0054494988055200635, 'dropout_rate_Layer_2': 0.2799165089596744, 'dropout_rate_Layer_3': 0.36735806757982364, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004410128167509313, 'l1_Layer_2': 0.09167653828789978, 'l1_Layer_3': 6.574392446290034e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 130, 'n_units_Layer_3': 215}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.37 | sMAPE for Validation Set is: 18.35% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 26.92 | sMAPE for Test Set is: 22.64% | rMAE for Test Set is: 1.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:30:51,470]\u001b[0m Trial 528 finished with value: 54.154888584769196 and parameters: {'n_hidden': 3, 'learning_rate': 0.009687775569791281, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 1.3178785114127765e-05, 'dropout_rate_Layer_2': 0.2896582319999559, 'dropout_rate_Layer_3': 0.37291686917775335, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004618977422587815, 'l1_Layer_2': 0.08694335515116458, 'l1_Layer_3': 8.111937849635965e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 130, 'n_units_Layer_3': 215}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.15 | sMAPE for Validation Set is: 19.68% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 22.06 | sMAPE for Test Set is: 19.45% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:30:55,744]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:31:00,926]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:31:01,842]\u001b[0m Trial 532 finished with value: 52.52484383362853 and parameters: {'n_hidden': 3, 'learning_rate': 0.008010135775522502, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0007613485832228296, 'dropout_rate_Layer_2': 0.28672234302620375, 'dropout_rate_Layer_3': 0.3706912683404012, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000467566173633706, 'l1_Layer_2': 0.07903440677485679, 'l1_Layer_3': 5.857515507170273e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 125, 'n_units_Layer_3': 190}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.52 | sMAPE for Validation Set is: 19.33% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 28.71 | sMAPE for Test Set is: 23.69% | rMAE for Test Set is: 1.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:31:05,094]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:31:10,127]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:31:13,026]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:31:13,566]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:31:14,095]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:31:18,518]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:31:20,176]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:31:22,801]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:31:23,101]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:31:24,837]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:31:27,463]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:31:30,541]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:31:30,813]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:31:31,633]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:31:34,808]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:31:38,468]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:31:39,112]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:31:44,280]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:31:44,329]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:31:48,523]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:31:49,120]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:31:49,236]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:31:51,824]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:31:56,875]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:31:59,249]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:32:00,987]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:32:01,491]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:32:03,646]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:32:08,758]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:32:09,116]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:32:12,086]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:32:12,642]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:32:14,724]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:32:15,998]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:32:20,999]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:32:22,013]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:32:30,832]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:32:36,175]\u001b[0m Trial 568 finished with value: 29.464408497419665 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020170231617907745, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08796535552962767, 'dropout_rate_Layer_2': 0.0035950695189313313, 'dropout_rate_Layer_3': 0.11855348622971618, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.9217919505261666e-05, 'l1_Layer_2': 1.2991024114727562e-05, 'l1_Layer_3': 0.0001053718464436253, 'n_units_Layer_1': 270, 'n_units_Layer_2': 150, 'n_units_Layer_3': 175}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.46 | sMAPE for Validation Set is: 11.95% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 11.55 | sMAPE for Test Set is: 12.76% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:32:37,043]\u001b[0m Trial 569 finished with value: 31.94128312387058 and parameters: {'n_hidden': 3, 'learning_rate': 0.004396301057490341, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2601788678013561, 'dropout_rate_Layer_2': 0.034735301687642384, 'dropout_rate_Layer_3': 0.2759513390256405, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.017135261236973707, 'l1_Layer_2': 4.37773979929803e-05, 'l1_Layer_3': 0.0007498795528419718, 'n_units_Layer_1': 80, 'n_units_Layer_2': 155, 'n_units_Layer_3': 210}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 31.94 | sMAPE for Validation Set is: 12.58% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 13.75 | sMAPE for Test Set is: 15.34% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:32:42,107]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:32:42,715]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:32:47,080]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:32:48,191]\u001b[0m Trial 573 finished with value: 29.968488440513614 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021254678371931406, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08628041636971936, 'dropout_rate_Layer_2': 0.05655444977018767, 'dropout_rate_Layer_3': 0.09533785461488747, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.4032142762793694e-05, 'l1_Layer_2': 1.5042173738511834e-05, 'l1_Layer_3': 0.00010740654312070932, 'n_units_Layer_1': 255, 'n_units_Layer_2': 135, 'n_units_Layer_3': 195}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.97 | sMAPE for Validation Set is: 12.06% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 13.69 | sMAPE for Test Set is: 14.28% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:32:52,783]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:32:55,771]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:32:56,705]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:32:56,831]\u001b[0m Trial 574 finished with value: 30.409239508461912 and parameters: {'n_hidden': 3, 'learning_rate': 0.004024524872724544, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09589157440784232, 'dropout_rate_Layer_2': 0.007635873303520516, 'dropout_rate_Layer_3': 0.07204667273140586, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.3183766620299842e-05, 'l1_Layer_2': 1.8290783497419764e-05, 'l1_Layer_3': 6.362997502812536e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 165, 'n_units_Layer_3': 180}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.41 | sMAPE for Validation Set is: 12.18% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 11.43 | sMAPE for Test Set is: 12.94% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:33:00,827]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:33:04,471]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:33:04,813]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:33:06,587]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:33:09,534]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:33:11,217]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:33:11,599]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:33:12,486]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:33:16,156]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:33:18,280]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:33:21,918]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:33:23,667]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:33:25,909]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:33:31,305]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:33:34,500]\u001b[0m Trial 595 finished with value: 52.784251384273354 and parameters: {'n_hidden': 3, 'learning_rate': 0.006351989239429881, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01684973196379822, 'dropout_rate_Layer_2': 0.2702816774218054, 'dropout_rate_Layer_3': 0.3374816405053458, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00045075544811240434, 'l1_Layer_2': 0.04596531183207262, 'l1_Layer_3': 0.00016649767702960384, 'n_units_Layer_1': 200, 'n_units_Layer_2': 140, 'n_units_Layer_3': 140}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.78 | sMAPE for Validation Set is: 18.92% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 20.30 | sMAPE for Test Set is: 18.99% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:33:37,880]\u001b[0m Trial 586 finished with value: 29.365813390813504 and parameters: {'n_hidden': 3, 'learning_rate': 0.001462169194632951, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11100093906745165, 'dropout_rate_Layer_2': 0.06936050604932363, 'dropout_rate_Layer_3': 0.07998483115872265, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010388292113063896, 'l1_Layer_2': 2.3574303730126958e-05, 'l1_Layer_3': 0.00022136240659224266, 'n_units_Layer_1': 260, 'n_units_Layer_2': 175, 'n_units_Layer_3': 195}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.37 | sMAPE for Validation Set is: 11.84% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 11.85 | sMAPE for Test Set is: 13.03% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:33:42,121]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:33:44,459]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:33:46,852]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:33:49,676]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:33:53,619]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:33:54,573]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:33:57,791]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:33:59,768]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:34:00,123]\u001b[0m Trial 597 finished with value: 30.87903352331627 and parameters: {'n_hidden': 3, 'learning_rate': 0.00416953745107914, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22345012139306103, 'dropout_rate_Layer_2': 0.33851902145475665, 'dropout_rate_Layer_3': 0.3367094332942454, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005939376681146276, 'l1_Layer_2': 0.00017392168296570187, 'l1_Layer_3': 6.279126001234674e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 240, 'n_units_Layer_3': 220}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.88 | sMAPE for Validation Set is: 12.22% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 12.72 | sMAPE for Test Set is: 13.58% | rMAE for Test Set is: 0.66\n",
      "MAE for Validation Set is: 31.60 | sMAPE for Validation Set is: 12.43% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 12.49 | sMAPE for Test Set is: 13.91% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:34:00,234]\u001b[0m Trial 598 finished with value: 31.603315929629506 and parameters: {'n_hidden': 3, 'learning_rate': 0.010897125662339566, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24420389340251353, 'dropout_rate_Layer_2': 0.02464637649913286, 'dropout_rate_Layer_3': 0.26222520936842625, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.2206372505947567e-05, 'l1_Layer_2': 2.9471467406047246e-05, 'l1_Layer_3': 0.00012201619659777298, 'n_units_Layer_1': 90, 'n_units_Layer_2': 150, 'n_units_Layer_3': 240}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:34:07,766]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:34:12,236]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:34:14,169]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:34:18,510]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:34:22,564]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:34:26,123]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:34:29,849]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:34:35,788]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:34:36,586]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:34:40,522]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:34:44,025]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:34:44,074]\u001b[0m Trial 613 finished with value: 29.9261061004287 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018645476463185313, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11892482422504458, 'dropout_rate_Layer_2': 0.04558331282024422, 'dropout_rate_Layer_3': 0.09186930685883334, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00019000617028365761, 'l1_Layer_2': 2.319108614898852e-05, 'l1_Layer_3': 0.00011077015482828971, 'n_units_Layer_1': 260, 'n_units_Layer_2': 175, 'n_units_Layer_3': 215}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.93 | sMAPE for Validation Set is: 12.06% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 12.11 | sMAPE for Test Set is: 13.09% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:34:44,805]\u001b[0m Trial 616 finished with value: 31.880828437982775 and parameters: {'n_hidden': 3, 'learning_rate': 0.003833038471436424, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28393900231235075, 'dropout_rate_Layer_2': 0.03477319385852842, 'dropout_rate_Layer_3': 0.3348660270379292, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00862972127517817, 'l1_Layer_2': 1.512929566819612e-05, 'l1_Layer_3': 8.095834964333548e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 265, 'n_units_Layer_3': 190}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 31.88 | sMAPE for Validation Set is: 12.85% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 14.99 | sMAPE for Test Set is: 15.83% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:34:52,393]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:34:55,302]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:35:02,243]\u001b[0m Trial 623 finished with value: 54.5248377500566 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036658891957590516, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08246877883631991, 'dropout_rate_Layer_2': 0.196763283884549, 'dropout_rate_Layer_3': 0.358744603650357, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005570549159050554, 'l1_Layer_2': 0.015352241736682211, 'l1_Layer_3': 0.0002922898810307497, 'n_units_Layer_1': 280, 'n_units_Layer_2': 135, 'n_units_Layer_3': 220}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.52 | sMAPE for Validation Set is: 19.61% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 17.99 | sMAPE for Test Set is: 17.01% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:35:06,792]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:35:08,075]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:35:09,515]\u001b[0m Trial 619 finished with value: 47.89485990138915 and parameters: {'n_hidden': 3, 'learning_rate': 0.005732149313062202, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02743681771526338, 'dropout_rate_Layer_2': 0.15824943820078444, 'dropout_rate_Layer_3': 0.3580433945178799, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0022150617106174316, 'l1_Layer_2': 0.06436472096453916, 'l1_Layer_3': 6.63925581274913e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 105, 'n_units_Layer_3': 155}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.89 | sMAPE for Validation Set is: 17.77% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 20.26 | sMAPE for Test Set is: 18.67% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:35:13,912]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:35:22,175]\u001b[0m Trial 624 finished with value: 29.530394925298637 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010580272891868784, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16624361895581255, 'dropout_rate_Layer_2': 0.032844359054590176, 'dropout_rate_Layer_3': 0.07976003967675965, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.396048350039683e-05, 'l1_Layer_2': 2.9610486720492123e-05, 'l1_Layer_3': 0.0011992420902992977, 'n_units_Layer_1': 260, 'n_units_Layer_2': 190, 'n_units_Layer_3': 215}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.53 | sMAPE for Validation Set is: 12.10% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 11.55 | sMAPE for Test Set is: 12.82% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:35:25,621]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:35:26,736]\u001b[0m Trial 629 finished with value: 34.860138827338126 and parameters: {'n_hidden': 3, 'learning_rate': 0.002052429160930772, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29527799793231413, 'dropout_rate_Layer_2': 0.04466892966412905, 'dropout_rate_Layer_3': 0.34495007304666275, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0024433316998203154, 'l1_Layer_2': 0.00014421009638151288, 'l1_Layer_3': 8.119478968434535e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 295, 'n_units_Layer_3': 185}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 34.86 | sMAPE for Validation Set is: 14.33% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 20.22 | sMAPE for Test Set is: 21.62% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:35:31,912]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:35:35,134]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:35:39,476]\u001b[0m Trial 630 finished with value: 34.796153036735575 and parameters: {'n_hidden': 3, 'learning_rate': 0.029388142567377207, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05376541675617073, 'dropout_rate_Layer_2': 0.22862442720474174, 'dropout_rate_Layer_3': 0.0033404592247867626, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0022848386416797124, 'l1_Layer_2': 0.0007273748550431736, 'l1_Layer_3': 6.737881186501725e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 180, 'n_units_Layer_3': 215}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 34.80 | sMAPE for Validation Set is: 13.59% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 12.67 | sMAPE for Test Set is: 13.78% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:35:42,625]\u001b[0m Trial 627 finished with value: 30.652099855305767 and parameters: {'n_hidden': 3, 'learning_rate': 0.000924414752937467, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13351965095429652, 'dropout_rate_Layer_2': 0.3814097801462566, 'dropout_rate_Layer_3': 0.11608125689013711, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000221547165284538, 'l1_Layer_2': 1.614632212329381e-05, 'l1_Layer_3': 0.0011999687425961337, 'n_units_Layer_1': 265, 'n_units_Layer_2': 180, 'n_units_Layer_3': 215}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.65 | sMAPE for Validation Set is: 12.30% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 11.97 | sMAPE for Test Set is: 13.27% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:35:46,750]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:35:51,086]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:35:53,530]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:35:56,795]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:36:02,557]\u001b[0m Trial 633 finished with value: 33.0609826329922 and parameters: {'n_hidden': 3, 'learning_rate': 0.026605983719791792, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06016200209558885, 'dropout_rate_Layer_2': 0.210177320268633, 'dropout_rate_Layer_3': 0.001954021749835881, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0018690548579673215, 'l1_Layer_2': 0.0007107519225318368, 'l1_Layer_3': 0.0003508705150105565, 'n_units_Layer_1': 180, 'n_units_Layer_2': 195, 'n_units_Layer_3': 220}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.06 | sMAPE for Validation Set is: 13.02% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 19.45 | sMAPE for Test Set is: 18.42% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:36:05,768]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:36:06,199]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:36:10,335]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:36:14,173]\u001b[0m Trial 641 finished with value: 35.69735027215557 and parameters: {'n_hidden': 3, 'learning_rate': 0.003632097058634814, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34114260434433985, 'dropout_rate_Layer_2': 0.06825802740766068, 'dropout_rate_Layer_3': 0.33306883878928306, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.031176059575245777, 'l1_Layer_2': 1.287812916743355e-05, 'l1_Layer_3': 0.000128686463674001, 'n_units_Layer_1': 120, 'n_units_Layer_2': 260, 'n_units_Layer_3': 220}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 35.70 | sMAPE for Validation Set is: 14.26% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 17.48 | sMAPE for Test Set is: 18.40% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:36:18,147]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:36:20,342]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:36:23,377]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:36:26,773]\u001b[0m Trial 645 finished with value: 35.47101278786331 and parameters: {'n_hidden': 3, 'learning_rate': 0.003688752755363227, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3307164329402512, 'dropout_rate_Layer_2': 0.08199454489265423, 'dropout_rate_Layer_3': 0.33448861359892856, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.027409695260601823, 'l1_Layer_2': 1.8975884019822545e-05, 'l1_Layer_3': 0.00010366227997888361, 'n_units_Layer_1': 110, 'n_units_Layer_2': 265, 'n_units_Layer_3': 220}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 35.47 | sMAPE for Validation Set is: 13.88% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 16.49 | sMAPE for Test Set is: 17.25% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:36:27,725]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:36:30,855]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:36:33,203]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:36:37,291]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:36:40,199]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:36:43,125]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.84 | sMAPE for Validation Set is: 18.76% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 25.63 | sMAPE for Test Set is: 21.78% | rMAE for Test Set is: 1.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:36:45,279]\u001b[0m Trial 647 finished with value: 50.84134225989186 and parameters: {'n_hidden': 3, 'learning_rate': 0.01259098434046453, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06194536854020133, 'dropout_rate_Layer_2': 0.26269040017585127, 'dropout_rate_Layer_3': 0.33446841034613517, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008721436682423937, 'l1_Layer_2': 0.07527725396021108, 'l1_Layer_3': 2.8894523258283858e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 120, 'n_units_Layer_3': 200}. Best is trial 212 with value: 28.72900007827766.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:36:48,101]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:36:51,240]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:36:53,663]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:36:54,730]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:36:54,847]\u001b[0m Trial 644 finished with value: 28.554237307871745 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012834138976669674, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0789753713512392, 'dropout_rate_Layer_2': 0.06357000483359175, 'dropout_rate_Layer_3': 0.1960013489772114, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015492168805886447, 'l1_Layer_2': 4.8832760896287495e-05, 'l1_Layer_3': 9.768754545067066e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 215, 'n_units_Layer_3': 190}. Best is trial 644 with value: 28.554237307871745.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.55 | sMAPE for Validation Set is: 11.27% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 10.36 | sMAPE for Test Set is: 11.86% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:37:00,422]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:37:00,989]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:37:01,580]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:37:06,101]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:37:08,175]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:37:08,713]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:37:10,715]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:37:12,100]\u001b[0m Trial 655 finished with value: 30.129540226384023 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012460044853475165, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20060156818016775, 'dropout_rate_Layer_2': 0.06907096205564732, 'dropout_rate_Layer_3': 0.09643320914681297, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.731356132572708e-05, 'l1_Layer_2': 5.800636773236176e-05, 'l1_Layer_3': 0.0016136437625705487, 'n_units_Layer_1': 265, 'n_units_Layer_2': 185, 'n_units_Layer_3': 190}. Best is trial 644 with value: 28.554237307871745.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.13 | sMAPE for Validation Set is: 12.21% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 12.10 | sMAPE for Test Set is: 13.15% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:37:15,201]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:37:17,300]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:37:19,840]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:37:21,760]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:37:22,184]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:37:22,977]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:37:27,334]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:37:27,571]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:37:27,647]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:37:30,960]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:37:35,503]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:37:36,211]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:37:37,814]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:37:39,893]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:37:42,639]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:37:45,520]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:37:45,713]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:37:50,672]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:37:55,199]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:37:55,403]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:37:55,725]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:38:01,403]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:38:02,206]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:38:03,946]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:38:05,936]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:38:08,823]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:38:12,034]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:38:15,512]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:38:19,855]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:38:23,956]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:38:28,142]\u001b[0m Trial 696 finished with value: 48.96430297588724 and parameters: {'n_hidden': 3, 'learning_rate': 0.013269227402502784, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04866037339671578, 'dropout_rate_Layer_2': 0.1302741137113442, 'dropout_rate_Layer_3': 0.3067269605960562, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003598192329047268, 'l1_Layer_2': 0.03226493370469489, 'l1_Layer_3': 2.933458783141177e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 115, 'n_units_Layer_3': 180}. Best is trial 644 with value: 28.554237307871745.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 48.96 | sMAPE for Validation Set is: 18.16% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 26.21 | sMAPE for Test Set is: 22.03% | rMAE for Test Set is: 1.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:38:31,748]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:38:32,138]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:38:32,198]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:38:38,060]\u001b[0m Trial 698 finished with value: 92.26186107823747 and parameters: {'n_hidden': 3, 'learning_rate': 0.019777222892221245, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1937186098969435, 'dropout_rate_Layer_2': 0.08994738468622418, 'dropout_rate_Layer_3': 0.043627534548496605, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 9.028591183163664e-05, 'l1_Layer_2': 0.00018742479672176056, 'l1_Layer_3': 0.002548529295871263, 'n_units_Layer_1': 175, 'n_units_Layer_2': 195, 'n_units_Layer_3': 110}. Best is trial 644 with value: 28.554237307871745.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 92.26 | sMAPE for Validation Set is: 33.08% | rMAE for Validation Set is: 1.45\n",
      "MAE for Test Set is: 45.64 | sMAPE for Test Set is: 33.67% | rMAE for Test Set is: 2.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:38:41,366]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:38:47,022]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:38:47,910]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:38:52,377]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:38:52,522]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:38:52,850]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:38:53,031]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:39:00,200]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:39:01,098]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:39:02,626]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:39:04,718]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:39:05,815]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:39:06,900]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:39:10,563]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:39:11,456]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:39:16,571]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:39:17,347]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:39:19,475]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:39:23,799]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:39:27,611]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:39:27,721]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:39:27,863]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:39:33,761]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:39:35,454]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:39:35,931]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:39:40,955]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:39:41,323]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:39:41,409]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:39:41,683]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:39:47,302]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:39:47,554]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:39:49,381]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:39:49,607]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:39:52,829]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:39:52,939]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:39:56,044]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:39:56,339]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:40:02,981]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:40:03,132]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:40:03,545]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:40:03,694]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:40:11,956]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:40:14,100]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:40:17,654]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:40:18,995]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:40:22,916]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:40:27,800]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:40:35,036]\u001b[0m Trial 745 finished with value: 33.687396729982545 and parameters: {'n_hidden': 3, 'learning_rate': 0.001899510344985864, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27240955820523727, 'dropout_rate_Layer_2': 0.04758741985400235, 'dropout_rate_Layer_3': 0.3981295593162175, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001373906680312931, 'l1_Layer_2': 9.600277660433433e-05, 'l1_Layer_3': 0.00046659987341962834, 'n_units_Layer_1': 130, 'n_units_Layer_2': 60, 'n_units_Layer_3': 60}. Best is trial 644 with value: 28.554237307871745.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.69 | sMAPE for Validation Set is: 13.22% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 15.91 | sMAPE for Test Set is: 17.59% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:40:40,284]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:40:42,764]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:40:45,147]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:40:48,277]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:40:50,099]\u001b[0m Trial 752 finished with value: 29.941072620217806 and parameters: {'n_hidden': 3, 'learning_rate': 0.003738782977941945, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2647914242167601, 'dropout_rate_Layer_2': 0.026866937048598112, 'dropout_rate_Layer_3': 0.0007141460535803335, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.9475869966450906e-05, 'l1_Layer_2': 1.8403245529679185e-05, 'l1_Layer_3': 2.8760338519930036e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 60, 'n_units_Layer_3': 200}. Best is trial 644 with value: 28.554237307871745.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.94 | sMAPE for Validation Set is: 11.84% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 12.71 | sMAPE for Test Set is: 13.82% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:40:53,055]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:40:56,430]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:40:59,416]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:41:00,264]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:41:04,271]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:41:09,702]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:41:10,372]\u001b[0m Trial 761 finished with value: 233.3316583379109 and parameters: {'n_hidden': 4, 'learning_rate': 0.0668919681304795, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09721024611792858, 'dropout_rate_Layer_2': 0.29155064424085797, 'dropout_rate_Layer_3': 0.18252251907163566, 'dropout_rate_Layer_4': 0.35993482988388786, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.006627680319712426, 'l1_Layer_2': 0.00432394877649739, 'l1_Layer_3': 0.016977989317264273, 'l1_Layer_4': 1.2112237831861412e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 225, 'n_units_Layer_3': 185, 'n_units_Layer_4': 50}. Best is trial 644 with value: 28.554237307871745.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 233.33 | sMAPE for Validation Set is: 131.04% | rMAE for Validation Set is: 3.66\n",
      "MAE for Test Set is: 72.78 | sMAPE for Test Set is: 81.15% | rMAE for Test Set is: 3.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:41:16,217]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:41:16,796]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:41:22,374]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:41:26,300]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:41:31,405]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:41:37,141]\u001b[0m Trial 767 finished with value: 51.53085436572352 and parameters: {'n_hidden': 3, 'learning_rate': 0.014965621597119652, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008259271674660347, 'dropout_rate_Layer_2': 0.25589598450341283, 'dropout_rate_Layer_3': 0.3523581892869219, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005841322168945398, 'l1_Layer_2': 0.07334820604998347, 'l1_Layer_3': 0.0004274368400700701, 'n_units_Layer_1': 250, 'n_units_Layer_2': 120, 'n_units_Layer_3': 180}. Best is trial 644 with value: 28.554237307871745.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.53 | sMAPE for Validation Set is: 18.68% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 21.40 | sMAPE for Test Set is: 19.63% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:41:40,019]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:41:42,880]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:41:43,457]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:41:47,986]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:41:49,129]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:41:52,845]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:41:55,712]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:42:00,158]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.73 | sMAPE for Validation Set is: 11.51% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 13.02 | sMAPE for Test Set is: 14.19% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:42:02,438]\u001b[0m Trial 762 finished with value: 28.73157144330733 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011484406683002386, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25235867381330707, 'dropout_rate_Layer_2': 0.047531253410110975, 'dropout_rate_Layer_3': 0.0009819336640776348, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.112315259471043e-05, 'l1_Layer_2': 0.00013901628815688176, 'l1_Layer_3': 0.0005513401874513126, 'n_units_Layer_1': 130, 'n_units_Layer_2': 60, 'n_units_Layer_3': 60}. Best is trial 644 with value: 28.554237307871745.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:42:08,242]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:42:08,687]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:42:14,587]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:42:22,248]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:42:27,203]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:42:37,640]\u001b[0m Trial 784 finished with value: 33.90309822938517 and parameters: {'n_hidden': 3, 'learning_rate': 0.02135709462740921, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.057917648855603875, 'dropout_rate_Layer_2': 0.21518682963706798, 'dropout_rate_Layer_3': 0.01729883113262054, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0025377117411047702, 'l1_Layer_2': 0.0006040702906336777, 'l1_Layer_3': 3.635600887015901e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 180, 'n_units_Layer_3': 205}. Best is trial 644 with value: 28.554237307871745.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.90 | sMAPE for Validation Set is: 13.39% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 13.64 | sMAPE for Test Set is: 14.52% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:42:39,906]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:42:41,761]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:42:42,911]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:42:47,693]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:42:47,788]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:42:53,480]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:43:04,430]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:43:08,223]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:43:08,815]\u001b[0m Trial 785 finished with value: 33.13666435627964 and parameters: {'n_hidden': 3, 'learning_rate': 0.022880949677542606, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.053518056269993446, 'dropout_rate_Layer_2': 0.21713573477715262, 'dropout_rate_Layer_3': 0.006251916304308911, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002397171268200319, 'l1_Layer_2': 0.0005817662107911423, 'l1_Layer_3': 4.320961706683723e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 175, 'n_units_Layer_3': 205}. Best is trial 644 with value: 28.554237307871745.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.14 | sMAPE for Validation Set is: 12.96% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 12.36 | sMAPE for Test Set is: 13.28% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:43:13,293]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:43:31,587]\u001b[0m Trial 795 finished with value: 30.244432783881603 and parameters: {'n_hidden': 3, 'learning_rate': 0.00669167701762638, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06702959995009888, 'dropout_rate_Layer_2': 0.009163163727813617, 'dropout_rate_Layer_3': 0.07668317105519536, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002728918282707106, 'l1_Layer_2': 0.0007463159848358935, 'l1_Layer_3': 3.7477332697444024e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 170, 'n_units_Layer_3': 140}. Best is trial 644 with value: 28.554237307871745.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.24 | sMAPE for Validation Set is: 11.85% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 10.70 | sMAPE for Test Set is: 12.11% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:43:36,339]\u001b[0m Trial 794 finished with value: 47.301039355524864 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019008925669504737, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009032980052697318, 'dropout_rate_Layer_2': 0.2626741594413405, 'dropout_rate_Layer_3': 0.3082269863862118, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005427250032158083, 'l1_Layer_2': 0.052407996971230913, 'l1_Layer_3': 2.4421730649854555e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 110, 'n_units_Layer_3': 180}. Best is trial 644 with value: 28.554237307871745.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.30 | sMAPE for Validation Set is: 17.04% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 19.74 | sMAPE for Test Set is: 18.39% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:43:48,900]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:43:51,523]\u001b[0m Trial 791 finished with value: 30.720606302811007 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013218081725984146, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24714341865393757, 'dropout_rate_Layer_2': 0.07107264378846746, 'dropout_rate_Layer_3': 0.346493075877136, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002400438954013956, 'l1_Layer_2': 1.6920487764541624e-05, 'l1_Layer_3': 0.0003672172610829336, 'n_units_Layer_1': 135, 'n_units_Layer_2': 55, 'n_units_Layer_3': 75}. Best is trial 644 with value: 28.554237307871745.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.72 | sMAPE for Validation Set is: 12.02% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 14.62 | sMAPE for Test Set is: 15.44% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:43:52,666]\u001b[0m Trial 798 finished with value: 36.89228568382547 and parameters: {'n_hidden': 3, 'learning_rate': 0.005110861791225829, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03502194750026107, 'dropout_rate_Layer_2': 0.27015804954190026, 'dropout_rate_Layer_3': 0.028064391675195168, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01062166577152983, 'l1_Layer_2': 0.0007307748304231626, 'l1_Layer_3': 4.520937495345065e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 180, 'n_units_Layer_3': 200}. Best is trial 644 with value: 28.554237307871745.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.89 | sMAPE for Validation Set is: 14.26% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 14.42 | sMAPE for Test Set is: 15.26% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:43:55,125]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:44:01,312]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:44:05,280]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:44:11,936]\u001b[0m Trial 800 finished with value: 48.0259760012529 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025854426775442797, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02903039295087486, 'dropout_rate_Layer_2': 0.1416579697867195, 'dropout_rate_Layer_3': 0.27138887998651273, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0020330391224202917, 'l1_Layer_2': 0.008792207788439942, 'l1_Layer_3': 3.180374080882065e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 105, 'n_units_Layer_3': 225}. Best is trial 644 with value: 28.554237307871745.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 48.03 | sMAPE for Validation Set is: 17.32% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 18.23 | sMAPE for Test Set is: 17.35% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:44:19,649]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:44:25,392]\u001b[0m Trial 796 finished with value: 28.702923901200958 and parameters: {'n_hidden': 3, 'learning_rate': 0.001262879717588129, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2477918237711218, 'dropout_rate_Layer_2': 0.05706129241709627, 'dropout_rate_Layer_3': 0.39884746910051927, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016494710637615102, 'l1_Layer_2': 1.9078202935261924e-05, 'l1_Layer_3': 0.00031303011444170953, 'n_units_Layer_1': 150, 'n_units_Layer_2': 60, 'n_units_Layer_3': 155}. Best is trial 644 with value: 28.554237307871745.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.70 | sMAPE for Validation Set is: 11.46% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 13.92 | sMAPE for Test Set is: 15.16% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:44:28,399]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:44:36,821]\u001b[0m Trial 804 finished with value: 32.758214001034005 and parameters: {'n_hidden': 4, 'learning_rate': 0.008616119745664058, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0008702204614169928, 'dropout_rate_Layer_2': 0.2898072271688642, 'dropout_rate_Layer_3': 0.38739935047532625, 'dropout_rate_Layer_4': 0.21210144130272168, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00026166209722228655, 'l1_Layer_2': 0.0011888473771533093, 'l1_Layer_3': 0.0001678287462031553, 'l1_Layer_4': 4.871024276176182e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 220, 'n_units_Layer_3': 280, 'n_units_Layer_4': 150}. Best is trial 644 with value: 28.554237307871745.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.76 | sMAPE for Validation Set is: 13.01% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 13.00 | sMAPE for Test Set is: 14.02% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:44:44,836]\u001b[0m Trial 807 finished with value: 34.21522458527563 and parameters: {'n_hidden': 4, 'learning_rate': 0.008355718374714952, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13367867645129183, 'dropout_rate_Layer_2': 0.37282492967237185, 'dropout_rate_Layer_3': 0.3377392189052717, 'dropout_rate_Layer_4': 0.0402935138316301, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00026314672478014087, 'l1_Layer_2': 0.0010901027787534568, 'l1_Layer_3': 0.0011569810716790696, 'l1_Layer_4': 0.015779811683361313, 'n_units_Layer_1': 95, 'n_units_Layer_2': 220, 'n_units_Layer_3': 275, 'n_units_Layer_4': 195}. Best is trial 644 with value: 28.554237307871745.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 34.22 | sMAPE for Validation Set is: 13.60% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 16.45 | sMAPE for Test Set is: 16.97% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:44:56,086]\u001b[0m Trial 808 finished with value: 32.43793952124967 and parameters: {'n_hidden': 3, 'learning_rate': 0.018719850518750202, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07519843413522624, 'dropout_rate_Layer_2': 0.1674834893174061, 'dropout_rate_Layer_3': 0.08941196734015375, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009894205238664602, 'l1_Layer_2': 0.0003718943294633813, 'l1_Layer_3': 0.00036889265560912125, 'n_units_Layer_1': 160, 'n_units_Layer_2': 125, 'n_units_Layer_3': 250}. Best is trial 644 with value: 28.554237307871745.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.44 | sMAPE for Validation Set is: 12.89% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 12.47 | sMAPE for Test Set is: 13.66% | rMAE for Test Set is: 0.64\n",
      "MAE for Validation Set is: 34.34 | sMAPE for Validation Set is: 13.58% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 16.74 | sMAPE for Test Set is: 16.91% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:44:56,239]\u001b[0m Trial 809 finished with value: 34.335637691398354 and parameters: {'n_hidden': 3, 'learning_rate': 0.019626731236232285, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08107506676380241, 'dropout_rate_Layer_2': 0.171988634340673, 'dropout_rate_Layer_3': 0.08756043262882358, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008050520038606326, 'l1_Layer_2': 0.0004665432875325188, 'l1_Layer_3': 0.0005235466561106248, 'n_units_Layer_1': 155, 'n_units_Layer_2': 120, 'n_units_Layer_3': 250}. Best is trial 644 with value: 28.554237307871745.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:45:01,753]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:45:06,462]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:45:10,201]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:45:14,093]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:45:18,488]\u001b[0m Trial 810 finished with value: 44.94731063565729 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014131824394049103, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05624878845507403, 'dropout_rate_Layer_2': 0.13439830849746875, 'dropout_rate_Layer_3': 0.26803692906756554, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002783104236168013, 'l1_Layer_2': 0.016894204760691544, 'l1_Layer_3': 2.628067044618625e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 90, 'n_units_Layer_3': 225}. Best is trial 644 with value: 28.554237307871745.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.95 | sMAPE for Validation Set is: 16.51% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 21.03 | sMAPE for Test Set is: 19.10% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:45:21,257]\u001b[0m Trial 812 finished with value: 37.3170668017176 and parameters: {'n_hidden': 3, 'learning_rate': 0.05030906736210712, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15421184553789477, 'dropout_rate_Layer_2': 0.10124901543611452, 'dropout_rate_Layer_3': 0.07786520213470406, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00021947020333452108, 'l1_Layer_2': 6.675228683793237e-05, 'l1_Layer_3': 0.0002255999716109194, 'n_units_Layer_1': 235, 'n_units_Layer_2': 140, 'n_units_Layer_3': 250}. Best is trial 644 with value: 28.554237307871745.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.32 | sMAPE for Validation Set is: 14.96% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 14.87 | sMAPE for Test Set is: 15.68% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:45:28,702]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:45:32,397]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:45:36,229]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:45:38,229]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:45:42,839]\u001b[0m Trial 814 finished with value: 31.46835307780147 and parameters: {'n_hidden': 3, 'learning_rate': 0.000903812504188165, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24785358911181157, 'dropout_rate_Layer_2': 0.05970552468735296, 'dropout_rate_Layer_3': 0.38044618779612893, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002204491811010857, 'l1_Layer_2': 1.2130407928698894e-05, 'l1_Layer_3': 0.0005119129022903093, 'n_units_Layer_1': 160, 'n_units_Layer_2': 55, 'n_units_Layer_3': 140}. Best is trial 644 with value: 28.554237307871745.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:45:42,861]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 31.47 | sMAPE for Validation Set is: 12.33% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 14.53 | sMAPE for Test Set is: 15.62% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:45:47,902]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:45:48,050]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:45:48,295]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:45:48,663]\u001b[0m Trial 816 finished with value: 44.346925425325246 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024500487123115975, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05781973250138905, 'dropout_rate_Layer_2': 0.16917561794902214, 'dropout_rate_Layer_3': 0.2704032323853506, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0021048741019741076, 'l1_Layer_2': 0.007232846694601778, 'l1_Layer_3': 2.3362405030748393e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 105, 'n_units_Layer_3': 230}. Best is trial 644 with value: 28.554237307871745.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.35 | sMAPE for Validation Set is: 16.13% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 16.04 | sMAPE for Test Set is: 15.70% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:45:58,016]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:46:00,836]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:46:04,168]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:46:06,886]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.92 | sMAPE for Validation Set is: 13.44% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 13.28 | sMAPE for Test Set is: 14.66% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:46:12,021]\u001b[0m Trial 826 finished with value: 33.917226773444945 and parameters: {'n_hidden': 3, 'learning_rate': 0.017607762209424373, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.028402318488783634, 'dropout_rate_Layer_2': 0.27655867024401043, 'dropout_rate_Layer_3': 0.36503231266779385, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005682399220282953, 'l1_Layer_2': 0.0035511393612132707, 'l1_Layer_3': 0.00017709672431304713, 'n_units_Layer_1': 110, 'n_units_Layer_2': 185, 'n_units_Layer_3': 295}. Best is trial 644 with value: 28.554237307871745.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:46:12,160]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:46:20,965]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:46:28,136]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:46:28,814]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:46:28,887]\u001b[0m Trial 829 finished with value: 45.43584880994019 and parameters: {'n_hidden': 3, 'learning_rate': 0.00189380401509816, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05429645595763643, 'dropout_rate_Layer_2': 0.13828460069067744, 'dropout_rate_Layer_3': 0.2698162327470075, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0019704522263511476, 'l1_Layer_2': 0.013143126482589263, 'l1_Layer_3': 2.3809825604430767e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 85, 'n_units_Layer_3': 230}. Best is trial 644 with value: 28.554237307871745.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.44 | sMAPE for Validation Set is: 16.60% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 15.65 | sMAPE for Test Set is: 15.69% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:46:29,751]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:46:37,418]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:46:41,123]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:46:41,678]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:46:46,165]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:46:46,343]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:46:46,776]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:46:53,058]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:46:53,182]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:46:53,795]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:47:00,521]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:47:00,735]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:47:06,168]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:47:06,418]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:47:17,290]\u001b[0m Trial 851 finished with value: 65.43896207649614 and parameters: {'n_hidden': 3, 'learning_rate': 0.016014229610782665, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.017866024179397436, 'dropout_rate_Layer_2': 0.12079698716677537, 'dropout_rate_Layer_3': 0.1130595778487814, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.010498117837316301, 'l1_Layer_2': 0.0012700438601053997, 'l1_Layer_3': 0.0007393865410721295, 'n_units_Layer_1': 105, 'n_units_Layer_2': 90, 'n_units_Layer_3': 285}. Best is trial 644 with value: 28.554237307871745.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 65.44 | sMAPE for Validation Set is: 22.92% | rMAE for Validation Set is: 1.03\n",
      "MAE for Test Set is: 30.66 | sMAPE for Test Set is: 26.49% | rMAE for Test Set is: 1.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:47:19,577]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:47:21,850]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:47:23,222]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:47:28,822]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:47:30,961]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:47:33,718]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:47:35,645]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:47:38,998]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:47:39,865]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:47:40,144]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.81 | sMAPE for Validation Set is: 11.01% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 10.23 | sMAPE for Test Set is: 11.71% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:47:45,804]\u001b[0m Trial 836 finished with value: 27.81487376292019 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019400117726094482, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21652406893169757, 'dropout_rate_Layer_2': 0.06670444983233956, 'dropout_rate_Layer_3': 0.1253714761995581, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.9811719637148178e-05, 'l1_Layer_2': 0.000295122692619206, 'l1_Layer_3': 0.0005596010621293875, 'n_units_Layer_1': 255, 'n_units_Layer_2': 140, 'n_units_Layer_3': 190}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:47:48,162]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:47:48,211]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:47:49,472]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:47:55,408]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:47:56,220]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:48:02,120]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:48:05,841]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:48:09,972]\u001b[0m Trial 865 finished with value: 78.89743504563303 and parameters: {'n_hidden': 3, 'learning_rate': 0.0266538464028703, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10296677498190557, 'dropout_rate_Layer_2': 0.16699156509841023, 'dropout_rate_Layer_3': 0.03114755990966514, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007488179498721582, 'l1_Layer_2': 0.003530284940012589, 'l1_Layer_3': 9.903508917071851e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 135, 'n_units_Layer_3': 240}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 78.90 | sMAPE for Validation Set is: 28.11% | rMAE for Validation Set is: 1.24\n",
      "MAE for Test Set is: 59.33 | sMAPE for Test Set is: 39.75% | rMAE for Test Set is: 3.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:48:14,006]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.63 | sMAPE for Validation Set is: 11.90% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 12.74 | sMAPE for Test Set is: 14.07% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:48:15,917]\u001b[0m Trial 861 finished with value: 29.63295112283092 and parameters: {'n_hidden': 3, 'learning_rate': 0.001604838115988629, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27927029895315164, 'dropout_rate_Layer_2': 0.008849653889240765, 'dropout_rate_Layer_3': 0.3162819952417638, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.272045983020082e-05, 'l1_Layer_2': 0.00012957281952923243, 'l1_Layer_3': 0.0005199142335553241, 'n_units_Layer_1': 150, 'n_units_Layer_2': 65, 'n_units_Layer_3': 75}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:48:20,190]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:48:20,772]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:48:26,084]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:48:26,114]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:48:26,820]\u001b[0m Trial 871 finished with value: 48.67657624596324 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015602855063427264, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05041009256899045, 'dropout_rate_Layer_2': 0.14136484947008798, 'dropout_rate_Layer_3': 0.2949938271128459, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0030929044946995644, 'l1_Layer_2': 0.007247294966578145, 'l1_Layer_3': 4.8337853298755874e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 80, 'n_units_Layer_3': 225}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 48.68 | sMAPE for Validation Set is: 17.20% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 17.90 | sMAPE for Test Set is: 17.32% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:48:32,596]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:48:33,722]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:48:37,838]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:48:38,013]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:48:42,406]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:48:43,001]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:48:46,722]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:48:47,445]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:48:47,647]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:48:53,825]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:48:54,259]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:48:56,409]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:49:00,281]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:49:02,566]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:49:03,612]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:49:04,804]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:49:07,439]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:49:10,585]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:49:11,664]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:49:12,404]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:49:15,243]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:49:18,942]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:49:20,310]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:49:20,926]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:49:27,097]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:49:31,136]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:49:34,582]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:49:35,706]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:49:41,035]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:49:44,086]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:49:47,388]\u001b[0m Trial 901 finished with value: 47.695996009091424 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014432288260020415, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0874900796027352, 'dropout_rate_Layer_2': 0.15316200308660233, 'dropout_rate_Layer_3': 0.27452963196599156, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002851477160797273, 'l1_Layer_2': 0.005431700080418171, 'l1_Layer_3': 1.7319173325827708e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 105, 'n_units_Layer_3': 260}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.70 | sMAPE for Validation Set is: 17.34% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 19.92 | sMAPE for Test Set is: 18.44% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:49:48,856]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:49:52,942]\u001b[0m Trial 903 finished with value: 30.921807903914925 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008556006883670011, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09079948120019712, 'dropout_rate_Layer_2': 0.030398744282119423, 'dropout_rate_Layer_3': 0.08186701850580294, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0010696350068435051, 'l1_Layer_2': 0.00015836607893342743, 'l1_Layer_3': 0.0005622558547842363, 'n_units_Layer_1': 230, 'n_units_Layer_2': 185, 'n_units_Layer_3': 140}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:49:53,002]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.92 | sMAPE for Validation Set is: 12.28% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 11.04 | sMAPE for Test Set is: 12.52% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:49:53,144]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:49:59,004]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:50:01,864]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:50:01,993]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:50:02,842]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:50:09,451]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:50:11,648]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:50:14,464]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:50:17,229]\u001b[0m Trial 909 finished with value: 33.98117234126149 and parameters: {'n_hidden': 4, 'learning_rate': 0.026759091076456507, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3961458355966341, 'dropout_rate_Layer_2': 0.38695946733030623, 'dropout_rate_Layer_3': 0.39654004575893576, 'dropout_rate_Layer_4': 0.0274847166644962, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0014932681607733788, 'l1_Layer_2': 5.1223477188943695e-05, 'l1_Layer_3': 0.0006168989762614781, 'l1_Layer_4': 0.007600997469263795, 'n_units_Layer_1': 80, 'n_units_Layer_2': 245, 'n_units_Layer_3': 215, 'n_units_Layer_4': 275}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.98 | sMAPE for Validation Set is: 13.39% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.37 | sMAPE for Test Set is: 15.58% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:50:21,205]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:50:23,638]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:50:26,282]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:50:31,830]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:50:35,346]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:50:36,698]\u001b[0m Trial 919 finished with value: 30.645830842840383 and parameters: {'n_hidden': 3, 'learning_rate': 0.00165811733281353, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06528853361886441, 'dropout_rate_Layer_2': 0.013274440492848694, 'dropout_rate_Layer_3': 0.10660130554912586, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.302136782014334e-05, 'l1_Layer_2': 0.00038268104028705256, 'l1_Layer_3': 5.1247491041991715e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 145, 'n_units_Layer_3': 135}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.65 | sMAPE for Validation Set is: 12.54% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 11.53 | sMAPE for Test Set is: 12.80% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:50:41,564]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:50:41,755]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:50:51,754]\u001b[0m Trial 916 finished with value: 34.077752742358875 and parameters: {'n_hidden': 4, 'learning_rate': 0.009117471400989901, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27449791883724867, 'dropout_rate_Layer_2': 0.38793532167410444, 'dropout_rate_Layer_3': 0.3965469155979876, 'dropout_rate_Layer_4': 0.036465751109872796, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00010114286596634202, 'l1_Layer_2': 9.826833463339731e-05, 'l1_Layer_3': 0.0006476735408206504, 'l1_Layer_4': 0.007309563762238, 'n_units_Layer_1': 80, 'n_units_Layer_2': 250, 'n_units_Layer_3': 275, 'n_units_Layer_4': 270}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 34.08 | sMAPE for Validation Set is: 13.54% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.72 | sMAPE for Test Set is: 15.58% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:50:55,605]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:50:59,665]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:51:05,518]\u001b[0m Trial 924 finished with value: 33.82616826873474 and parameters: {'n_hidden': 4, 'learning_rate': 0.008965094698515952, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16841228344327602, 'dropout_rate_Layer_2': 0.32432259417764797, 'dropout_rate_Layer_3': 0.34790628616598945, 'dropout_rate_Layer_4': 0.2655943905162567, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003280046772425167, 'l1_Layer_2': 0.0003837249720154964, 'l1_Layer_3': 0.00018078669769175832, 'l1_Layer_4': 0.00029778399128978466, 'n_units_Layer_1': 175, 'n_units_Layer_2': 265, 'n_units_Layer_3': 265, 'n_units_Layer_4': 180}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.83 | sMAPE for Validation Set is: 13.35% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.11 | sMAPE for Test Set is: 14.98% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:51:05,862]\u001b[0m Trial 929 finished with value: 62.23854630109762 and parameters: {'n_hidden': 4, 'learning_rate': 0.007680788641196575, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07779355076340808, 'dropout_rate_Layer_2': 0.25966422781588566, 'dropout_rate_Layer_3': 0.15524985961706214, 'dropout_rate_Layer_4': 0.004520853591142016, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.004183049740098832, 'l1_Layer_2': 0.0003131436104841584, 'l1_Layer_3': 0.00019527946174358792, 'l1_Layer_4': 0.0002562442672284733, 'n_units_Layer_1': 130, 'n_units_Layer_2': 95, 'n_units_Layer_3': 195, 'n_units_Layer_4': 80}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 62.24 | sMAPE for Validation Set is: 21.29% | rMAE for Validation Set is: 0.98\n",
      "MAE for Test Set is: 24.64 | sMAPE for Test Set is: 24.71% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:51:11,706]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:51:12,469]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:51:18,520]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:51:21,363]\u001b[0m Trial 933 finished with value: 60.30258836911377 and parameters: {'n_hidden': 4, 'learning_rate': 0.08436056898904322, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07331355312534044, 'dropout_rate_Layer_2': 0.1949441662683149, 'dropout_rate_Layer_3': 0.06184167364558416, 'dropout_rate_Layer_4': 0.0013767015956914208, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0015023328268130038, 'l1_Layer_2': 0.0002789734632832246, 'l1_Layer_3': 0.00020577600476480922, 'l1_Layer_4': 0.00016001313459908812, 'n_units_Layer_1': 205, 'n_units_Layer_2': 100, 'n_units_Layer_3': 195, 'n_units_Layer_4': 125}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 60.30 | sMAPE for Validation Set is: 21.28% | rMAE for Validation Set is: 0.95\n",
      "MAE for Test Set is: 26.26 | sMAPE for Test Set is: 23.43% | rMAE for Test Set is: 1.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:51:21,720]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:51:23,073]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:51:27,933]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:51:29,556]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:51:30,159]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:51:37,365]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:51:37,708]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:51:38,235]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:51:39,184]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:51:46,013]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:51:48,991]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:51:49,935]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:51:51,742]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:51:54,509]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:51:58,531]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:51:59,046]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:52:03,263]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:52:05,704]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:52:06,986]\u001b[0m Trial 948 finished with value: 46.43928080033103 and parameters: {'n_hidden': 3, 'learning_rate': 0.001849136656490089, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06998999479810084, 'dropout_rate_Layer_2': 0.16498220059344074, 'dropout_rate_Layer_3': 0.2538701017140268, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002532775672574909, 'l1_Layer_2': 0.006470884934788177, 'l1_Layer_3': 2.2628667475224253e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 90, 'n_units_Layer_3': 245}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.44 | sMAPE for Validation Set is: 16.52% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 15.86 | sMAPE for Test Set is: 16.16% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:52:12,370]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:52:12,709]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:52:14,895]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:52:20,627]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:52:20,761]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:52:29,190]\u001b[0m Trial 954 finished with value: 30.135582398435925 and parameters: {'n_hidden': 3, 'learning_rate': 0.006428863705451204, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2613301819817986, 'dropout_rate_Layer_2': 0.01467229307701265, 'dropout_rate_Layer_3': 0.016099180293460618, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.8758584507612692e-05, 'l1_Layer_2': 2.8227887225109657e-05, 'l1_Layer_3': 1.0068576779628879e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 50, 'n_units_Layer_3': 205}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.14 | sMAPE for Validation Set is: 12.05% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 14.49 | sMAPE for Test Set is: 16.75% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:52:35,310]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:52:39,903]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:52:40,679]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:52:46,272]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:52:46,695]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.36 | sMAPE for Validation Set is: 11.67% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 11.78 | sMAPE for Test Set is: 13.01% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:52:46,718]\u001b[0m Trial 959 finished with value: 29.3578644532154 and parameters: {'n_hidden': 3, 'learning_rate': 0.001896148508927616, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21171417528947717, 'dropout_rate_Layer_2': 0.18704623898249198, 'dropout_rate_Layer_3': 0.25050778016627606, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013730770778793541, 'l1_Layer_2': 0.002877030884887715, 'l1_Layer_3': 1.2381625405090663e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 90, 'n_units_Layer_3': 240}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:52:55,271]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:52:55,330]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:53:01,638]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:53:01,988]\u001b[0m Trial 970 finished with value: 81.11884994197824 and parameters: {'n_hidden': 4, 'learning_rate': 0.007636957426823425, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20389377315158205, 'dropout_rate_Layer_2': 0.2887137839320932, 'dropout_rate_Layer_3': 0.36190871411847947, 'dropout_rate_Layer_4': 0.2965661000525755, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00015606880995970956, 'l1_Layer_2': 1.0015357130147078e-05, 'l1_Layer_3': 9.785635100687768e-05, 'l1_Layer_4': 0.0007557692636417335, 'n_units_Layer_1': 230, 'n_units_Layer_2': 115, 'n_units_Layer_3': 290, 'n_units_Layer_4': 135}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 81.12 | sMAPE for Validation Set is: 28.89% | rMAE for Validation Set is: 1.27\n",
      "MAE for Test Set is: 47.59 | sMAPE for Test Set is: 34.47% | rMAE for Test Set is: 2.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:53:02,144]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:53:03,090]\u001b[0m Trial 962 finished with value: 28.819915260092063 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018849150904523325, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09175849628828235, 'dropout_rate_Layer_2': 0.18558808216850214, 'dropout_rate_Layer_3': 0.25444781442439574, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013655485585935248, 'l1_Layer_2': 0.0019029643768612085, 'l1_Layer_3': 1.2568094608657562e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 95, 'n_units_Layer_3': 250}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.82 | sMAPE for Validation Set is: 11.43% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 11.04 | sMAPE for Test Set is: 12.44% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:53:11,860]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:53:13,224]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:53:13,529]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:53:16,170]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:53:18,169]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:53:23,474]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:53:28,531]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:53:29,701]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:53:31,122]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:53:32,884]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:53:39,068]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:53:39,141]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:53:41,102]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:53:49,150]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:53:49,269]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:53:50,359]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:53:57,561]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:54:04,366]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:54:08,322]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:54:13,642]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:54:18,365]\u001b[0m Trial 990 finished with value: 33.98758558383423 and parameters: {'n_hidden': 3, 'learning_rate': 0.017893640427896453, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0335513278697125, 'dropout_rate_Layer_2': 0.21153125064166273, 'dropout_rate_Layer_3': 0.015111059870158776, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0026161393326286217, 'l1_Layer_2': 0.0009412064171754463, 'l1_Layer_3': 3.394956367297165e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 170, 'n_units_Layer_3': 210}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.99 | sMAPE for Validation Set is: 13.38% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.50 | sMAPE for Test Set is: 15.03% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:54:23,211]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:54:27,449]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:54:31,316]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:54:34,777]\u001b[0m Trial 986 finished with value: 29.06500129359394 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018603460971424032, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20977762176870246, 'dropout_rate_Layer_2': 0.18539139240312777, 'dropout_rate_Layer_3': 0.25465638522409173, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013495175952749337, 'l1_Layer_2': 0.001872698863585184, 'l1_Layer_3': 1.210048610161895e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 90, 'n_units_Layer_3': 260}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.07 | sMAPE for Validation Set is: 11.46% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 11.16 | sMAPE for Test Set is: 12.79% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:54:39,988]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:54:43,939]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:54:46,733]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:54:48,473]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:54:50,003]\u001b[0m Trial 996 finished with value: 33.56723367501016 and parameters: {'n_hidden': 3, 'learning_rate': 0.020511505266984836, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03474170037938899, 'dropout_rate_Layer_2': 0.2137753912364749, 'dropout_rate_Layer_3': 0.013373128014504031, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002966070548454814, 'l1_Layer_2': 0.000874405195802987, 'l1_Layer_3': 2.8358481967709278e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 165, 'n_units_Layer_3': 210}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.57 | sMAPE for Validation Set is: 13.07% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.68 | sMAPE for Test Set is: 14.87% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:54:53,600]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:54:57,614]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:54:57,967]\u001b[0m Trial 991 finished with value: 28.49890093117675 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018659216363252358, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13102603432041388, 'dropout_rate_Layer_2': 0.18858848034444847, 'dropout_rate_Layer_3': 0.25589675527118655, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013736467808443328, 'l1_Layer_2': 0.0019904462178453523, 'l1_Layer_3': 1.2961582853275806e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 90, 'n_units_Layer_3': 255}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.50 | sMAPE for Validation Set is: 11.18% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 10.82 | sMAPE for Test Set is: 12.25% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:54:58,408]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:55:04,428]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:55:11,008]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:55:12,497]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:55:15,883]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:55:17,251]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:55:21,896]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:55:26,238]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:55:26,428]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.76 | sMAPE for Validation Set is: 11.78% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.12 | sMAPE for Test Set is: 12.56% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:55:31,195]\u001b[0m Trial 1010 finished with value: 29.76322431147875 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011865799325113074, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12617494284328842, 'dropout_rate_Layer_2': 0.03954137139390167, 'dropout_rate_Layer_3': 0.07223423577421229, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005424326917158422, 'l1_Layer_2': 1.1605415852971478e-05, 'l1_Layer_3': 0.001600400482977632, 'n_units_Layer_1': 270, 'n_units_Layer_2': 160, 'n_units_Layer_3': 175}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:55:33,947]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:55:37,059]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:55:40,435]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:55:42,658]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:55:47,162]\u001b[0m Trial 1007 finished with value: 28.83333078788867 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018806338884977043, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15616379511892925, 'dropout_rate_Layer_2': 0.18674785572480415, 'dropout_rate_Layer_3': 0.2562138492268789, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013196906517082304, 'l1_Layer_2': 0.0017805983825893766, 'l1_Layer_3': 1.262800049891263e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 70, 'n_units_Layer_3': 245}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.83 | sMAPE for Validation Set is: 11.36% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 11.35 | sMAPE for Test Set is: 12.64% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:55:50,648]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:55:54,457]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:55:56,652]\u001b[0m Trial 1019 finished with value: 29.56897754070701 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011274553738077576, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13182054452233408, 'dropout_rate_Layer_2': 0.034243273639920316, 'dropout_rate_Layer_3': 0.05938807780410288, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.018487422600271e-05, 'l1_Layer_2': 1.038304109611912e-05, 'l1_Layer_3': 0.0019071036736789434, 'n_units_Layer_1': 270, 'n_units_Layer_2': 155, 'n_units_Layer_3': 175}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.57 | sMAPE for Validation Set is: 11.88% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 12.56 | sMAPE for Test Set is: 13.65% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:56:00,690]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:56:05,251]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:56:15,839]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:56:21,939]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:56:25,874]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:56:26,942]\u001b[0m Trial 1029 finished with value: 34.628260811995744 and parameters: {'n_hidden': 3, 'learning_rate': 0.052470842710155466, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11090594545386209, 'dropout_rate_Layer_2': 0.2888379338774529, 'dropout_rate_Layer_3': 0.00042495721164044313, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00036828131731336073, 'l1_Layer_2': 0.00012039139022296052, 'l1_Layer_3': 9.301868753470061e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 195, 'n_units_Layer_3': 245}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 34.63 | sMAPE for Validation Set is: 13.74% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 21.26 | sMAPE for Test Set is: 20.11% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:56:29,020]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:56:31,379]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:56:37,292]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:56:38,490]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:56:43,805]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:56:46,088]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:56:48,290]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:56:48,689]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:56:52,190]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:56:56,557]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:57:01,113]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.09 | sMAPE for Validation Set is: 11.20% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 11.70 | sMAPE for Test Set is: 13.18% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:57:03,302]\u001b[0m Trial 1022 finished with value: 28.085306863429604 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012144338041986547, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.190337020033214, 'dropout_rate_Layer_2': 0.05363890328346996, 'dropout_rate_Layer_3': 0.0488045383781628, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011191367973582915, 'l1_Layer_2': 3.742503239235996e-05, 'l1_Layer_3': 0.0008630356353033222, 'n_units_Layer_1': 95, 'n_units_Layer_2': 65, 'n_units_Layer_3': 65}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:57:07,294]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:57:09,481]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:57:24,957]\u001b[0m Trial 1046 finished with value: 31.04447977764868 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021057597851212076, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13796568163201683, 'dropout_rate_Layer_2': 0.18573420568594162, 'dropout_rate_Layer_3': 0.256783040400736, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013551492447981012, 'l1_Layer_2': 0.001977955854123352, 'l1_Layer_3': 1.2200677902450959e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 70, 'n_units_Layer_3': 250}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 31.04 | sMAPE for Validation Set is: 12.21% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 12.45 | sMAPE for Test Set is: 13.86% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:57:32,585]\u001b[0m Trial 1047 finished with value: 30.266439283147204 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008587189950121748, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10735390822621829, 'dropout_rate_Layer_2': 0.05339185269796222, 'dropout_rate_Layer_3': 0.035464533547563085, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.22394639678962e-05, 'l1_Layer_2': 1.2349108467491882e-05, 'l1_Layer_3': 0.0019639126224578777, 'n_units_Layer_1': 285, 'n_units_Layer_2': 175, 'n_units_Layer_3': 200}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.27 | sMAPE for Validation Set is: 12.25% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 11.95 | sMAPE for Test Set is: 13.29% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:57:35,380]\u001b[0m Trial 1041 finished with value: 29.172864867135797 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020767705145211483, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15058467047170285, 'dropout_rate_Layer_2': 0.18352682981556095, 'dropout_rate_Layer_3': 0.2580782933866301, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001298368553127912, 'l1_Layer_2': 0.001685745971272005, 'l1_Layer_3': 1.2190588144053877e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 70, 'n_units_Layer_3': 255}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.17 | sMAPE for Validation Set is: 11.48% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 11.18 | sMAPE for Test Set is: 12.55% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:57:39,425]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:57:40,211]\u001b[0m Trial 1040 finished with value: 29.038217813835463 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018799759752218784, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20929893969557492, 'dropout_rate_Layer_2': 0.1875076375513342, 'dropout_rate_Layer_3': 0.2521861647741919, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012747893827525876, 'l1_Layer_2': 0.001755363346252132, 'l1_Layer_3': 1.3402551544040806e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 70, 'n_units_Layer_3': 245}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.04 | sMAPE for Validation Set is: 11.39% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 11.24 | sMAPE for Test Set is: 12.73% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:57:44,843]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:57:55,740]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:57:55,931]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:58:01,380]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:58:01,840]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:58:05,322]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:58:07,531]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:58:07,597]\u001b[0m Trial 1052 finished with value: 31.344016148440218 and parameters: {'n_hidden': 3, 'learning_rate': 0.00322887159486443, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.179228694909238, 'dropout_rate_Layer_2': 0.1889587778495864, 'dropout_rate_Layer_3': 0.23922934018212896, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001359037721837713, 'l1_Layer_2': 0.0019306806400936692, 'l1_Layer_3': 1.190602412075813e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 55, 'n_units_Layer_3': 255}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 31.34 | sMAPE for Validation Set is: 12.36% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 12.75 | sMAPE for Test Set is: 13.90% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:58:08,417]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:58:15,184]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:58:15,286]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:58:17,184]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:58:17,341]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:58:25,333]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:58:25,746]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:58:28,759]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:58:28,917]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:58:31,075]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:58:31,867]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:58:39,556]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:58:40,036]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:58:40,963]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:58:45,863]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:58:50,540]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:58:51,326]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:58:51,874]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:58:57,131]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:58:58,914]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:59:01,613]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:59:04,535]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:59:08,607]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:59:14,004]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:59:16,804]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:59:20,718]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:59:26,372]\u001b[0m Trial 1084 finished with value: 33.19206433969281 and parameters: {'n_hidden': 3, 'learning_rate': 0.011400411906709625, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11961809328467414, 'dropout_rate_Layer_2': 0.3129790333320827, 'dropout_rate_Layer_3': 0.35316818220683466, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.53513689932636e-05, 'l1_Layer_2': 0.0005201959542147043, 'l1_Layer_3': 0.0010160425169759056, 'n_units_Layer_1': 215, 'n_units_Layer_2': 270, 'n_units_Layer_3': 210}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.19 | sMAPE for Validation Set is: 13.10% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 15.02 | sMAPE for Test Set is: 16.47% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:59:29,758]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:59:32,211]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:59:32,443]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:59:35,392]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:59:39,709]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:59:42,767]\u001b[0m Trial 1081 finished with value: 29.623859146302863 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020991186199782355, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21003810495573894, 'dropout_rate_Layer_2': 0.20194390699383713, 'dropout_rate_Layer_3': 0.2183520795592946, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013929069419653815, 'l1_Layer_2': 0.0028500630708047535, 'l1_Layer_3': 1.2379665475505711e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 65, 'n_units_Layer_3': 275}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.62 | sMAPE for Validation Set is: 11.67% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.50 | sMAPE for Test Set is: 12.80% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 09:59:45,576]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:59:49,986]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:59:50,778]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 09:59:54,791]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:00:00,740]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:00:09,008]\u001b[0m Trial 1090 finished with value: 61.129839516778226 and parameters: {'n_hidden': 3, 'learning_rate': 0.013463825664185037, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02865955474090708, 'dropout_rate_Layer_2': 0.19594057235773035, 'dropout_rate_Layer_3': 0.06995460693869511, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.01417552992307943, 'l1_Layer_2': 2.9426256731078168e-05, 'l1_Layer_3': 2.5662877043480798e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 170, 'n_units_Layer_3': 270}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 61.13 | sMAPE for Validation Set is: 21.61% | rMAE for Validation Set is: 0.96\n",
      "MAE for Test Set is: 15.18 | sMAPE for Test Set is: 15.78% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:00:12,634]\u001b[0m Trial 1093 finished with value: 29.557707917257392 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031206840828954838, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17770522575751505, 'dropout_rate_Layer_2': 0.2032778988161915, 'dropout_rate_Layer_3': 0.23882206660017394, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009773016656853815, 'l1_Layer_2': 0.00190881643415293, 'l1_Layer_3': 1.463194204336964e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 70, 'n_units_Layer_3': 270}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.56 | sMAPE for Validation Set is: 11.64% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 11.51 | sMAPE for Test Set is: 12.98% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:00:18,576]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:00:27,192]\u001b[0m Trial 1098 finished with value: 30.549231106014002 and parameters: {'n_hidden': 3, 'learning_rate': 0.000763164799275211, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10739256360841448, 'dropout_rate_Layer_2': 0.050074985569345115, 'dropout_rate_Layer_3': 0.033984200008839484, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.923004718646719e-05, 'l1_Layer_2': 1.1360484559793779e-05, 'l1_Layer_3': 0.0017207659836605649, 'n_units_Layer_1': 280, 'n_units_Layer_2': 175, 'n_units_Layer_3': 200}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.55 | sMAPE for Validation Set is: 12.39% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 10.69 | sMAPE for Test Set is: 12.35% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:00:36,363]\u001b[0m Trial 1096 finished with value: 29.177620989266273 and parameters: {'n_hidden': 3, 'learning_rate': 0.001720921023659963, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15122748115601398, 'dropout_rate_Layer_2': 0.21875959751960788, 'dropout_rate_Layer_3': 0.2426348100654397, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007088083002826452, 'l1_Layer_2': 0.0021401583209840662, 'l1_Layer_3': 1.32458395406864e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 60, 'n_units_Layer_3': 265}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.18 | sMAPE for Validation Set is: 11.48% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 11.22 | sMAPE for Test Set is: 12.64% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:00:37,132]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:00:41,956]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:00:43,721]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:00:51,379]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:00:54,833]\u001b[0m Trial 1099 finished with value: 36.452247725119136 and parameters: {'n_hidden': 3, 'learning_rate': 0.005915229601572723, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.171272294939858, 'dropout_rate_Layer_2': 0.16058642876307286, 'dropout_rate_Layer_3': 0.10631230518957019, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000239010050132304, 'l1_Layer_2': 0.0011825207721334913, 'l1_Layer_3': 0.0011645649997276543, 'n_units_Layer_1': 145, 'n_units_Layer_2': 160, 'n_units_Layer_3': 235}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.45 | sMAPE for Validation Set is: 14.32% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 15.58 | sMAPE for Test Set is: 15.23% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:01:00,345]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:01:02,346]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:01:06,710]\u001b[0m Trial 1101 finished with value: 28.369530894490207 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028128102289405738, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1545578566301209, 'dropout_rate_Layer_2': 0.2163633092195122, 'dropout_rate_Layer_3': 0.24482408579048326, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.002341755738756e-05, 'l1_Layer_2': 0.002103465465677933, 'l1_Layer_3': 1.3264506154889029e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 55, 'n_units_Layer_3': 270}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.37 | sMAPE for Validation Set is: 11.17% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 10.97 | sMAPE for Test Set is: 12.39% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:01:09,803]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:01:12,977]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:01:16,666]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:01:17,396]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:01:26,354]\u001b[0m Trial 1106 finished with value: 29.35931325997942 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027299422217434157, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15554500636378757, 'dropout_rate_Layer_2': 0.21824688768219128, 'dropout_rate_Layer_3': 0.2393824625651727, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007134329131185549, 'l1_Layer_2': 0.00199283531632985, 'l1_Layer_3': 1.375095050696699e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 55, 'n_units_Layer_3': 270}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.36 | sMAPE for Validation Set is: 11.61% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 11.52 | sMAPE for Test Set is: 13.00% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:01:26,989]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:01:31,780]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:01:34,344]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:01:37,606]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:01:39,771]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:01:42,800]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:01:43,579]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:01:49,323]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:01:49,714]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:01:56,561]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:01:57,587]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:02:02,868]\u001b[0m Trial 1114 finished with value: 52.53806243726884 and parameters: {'n_hidden': 3, 'learning_rate': 0.00833899675672085, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07131894349269013, 'dropout_rate_Layer_2': 0.19260726660838887, 'dropout_rate_Layer_3': 0.029881650430218887, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0010591210041742051, 'l1_Layer_2': 0.002712841830702402, 'l1_Layer_3': 1.0070667618867436e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 130, 'n_units_Layer_3': 145}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.54 | sMAPE for Validation Set is: 19.86% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 13.92 | sMAPE for Test Set is: 14.96% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:02:03,072]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:02:03,285]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:02:10,958]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:02:11,168]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:02:11,451]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:02:19,364]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:02:19,921]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:02:25,183]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:02:26,086]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:02:31,361]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:02:33,955]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:02:37,626]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:02:40,605]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:02:44,885]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:02:45,135]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:02:51,430]\u001b[0m Trial 1139 finished with value: 36.20402230782216 and parameters: {'n_hidden': 3, 'learning_rate': 0.023854935410831668, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1103107485248377, 'dropout_rate_Layer_2': 0.34274015849913403, 'dropout_rate_Layer_3': 0.3596434682086302, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.471846938994722e-05, 'l1_Layer_2': 0.0005303134104970408, 'l1_Layer_3': 0.000252566926669793, 'n_units_Layer_1': 165, 'n_units_Layer_2': 255, 'n_units_Layer_3': 205}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.20 | sMAPE for Validation Set is: 14.19% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 15.95 | sMAPE for Test Set is: 17.01% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:02:53,104]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:02:56,317]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:02:58,529]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:03:00,544]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:03:04,207]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:03:04,800]\u001b[0m Trial 1142 finished with value: 34.46816380470603 and parameters: {'n_hidden': 3, 'learning_rate': 0.013066507969020353, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14854262547565264, 'dropout_rate_Layer_2': 0.34047947951593666, 'dropout_rate_Layer_3': 0.3576425449258362, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.175314782763852e-05, 'l1_Layer_2': 0.0005062871743653963, 'l1_Layer_3': 0.0038034041877579253, 'n_units_Layer_1': 190, 'n_units_Layer_2': 255, 'n_units_Layer_3': 210}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 34.47 | sMAPE for Validation Set is: 13.66% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 16.41 | sMAPE for Test Set is: 17.82% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:03:05,735]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:03:16,699]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:03:19,979]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:03:21,641]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:03:25,618]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:03:26,049]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:03:26,374]\u001b[0m Trial 1147 finished with value: 32.11928353634182 and parameters: {'n_hidden': 3, 'learning_rate': 0.012584590754258286, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13472627958130867, 'dropout_rate_Layer_2': 0.2656029068568669, 'dropout_rate_Layer_3': 0.37465705407776556, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000128809857000572, 'l1_Layer_2': 0.00014014234807678525, 'l1_Layer_3': 0.0033152438372156773, 'n_units_Layer_1': 180, 'n_units_Layer_2': 265, 'n_units_Layer_3': 220}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.12 | sMAPE for Validation Set is: 12.46% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 14.15 | sMAPE for Test Set is: 15.71% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:03:32,884]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:03:33,612]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:03:38,613]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:03:39,249]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:03:44,070]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:03:49,329]\u001b[0m Trial 1155 finished with value: 31.292461840560318 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031996345940502177, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22714805204231564, 'dropout_rate_Layer_2': 0.26376947654462085, 'dropout_rate_Layer_3': 0.3802935182156771, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00019014072036484787, 'l1_Layer_2': 0.00014101023414943157, 'l1_Layer_3': 0.0016264190366282333, 'n_units_Layer_1': 175, 'n_units_Layer_2': 230, 'n_units_Layer_3': 225}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 31.29 | sMAPE for Validation Set is: 12.23% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 12.67 | sMAPE for Test Set is: 14.09% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:03:53,881]\u001b[0m Trial 1149 finished with value: 28.38245923328944 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016442980853988072, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12922220167688483, 'dropout_rate_Layer_2': 0.19942344245130397, 'dropout_rate_Layer_3': 0.2060768690553241, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005483903107028378, 'l1_Layer_2': 0.0015102454911732149, 'l1_Layer_3': 1.681105073703131e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 75, 'n_units_Layer_3': 240}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.38 | sMAPE for Validation Set is: 11.18% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 10.83 | sMAPE for Test Set is: 12.30% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:03:58,014]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:04:01,961]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:04:02,194]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:04:06,840]\u001b[0m Trial 1162 finished with value: 31.99765649187276 and parameters: {'n_hidden': 3, 'learning_rate': 0.02479259146427854, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22302760015094258, 'dropout_rate_Layer_2': 0.12517051593341083, 'dropout_rate_Layer_3': 0.2227972321355018, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001835677168934512, 'l1_Layer_2': 0.0001605402709898784, 'l1_Layer_3': 0.0003643121156854077, 'n_units_Layer_1': 300, 'n_units_Layer_2': 60, 'n_units_Layer_3': 175}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.00 | sMAPE for Validation Set is: 12.63% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 13.54 | sMAPE for Test Set is: 14.77% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:04:07,249]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:04:08,745]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:04:13,923]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:04:14,631]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:04:16,042]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:04:22,523]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:04:25,245]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:04:27,856]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:04:28,557]\u001b[0m Trial 1163 finished with value: 30.321183047973904 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022300333371015756, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22238836520215774, 'dropout_rate_Layer_2': 0.26509074746848493, 'dropout_rate_Layer_3': 0.37710936333832523, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013428851995885983, 'l1_Layer_2': 0.000128906277399501, 'l1_Layer_3': 0.005921016491612154, 'n_units_Layer_1': 175, 'n_units_Layer_2': 215, 'n_units_Layer_3': 225}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.32 | sMAPE for Validation Set is: 11.99% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 13.30 | sMAPE for Test Set is: 14.94% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:04:29,551]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:04:39,498]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:04:39,776]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:04:45,219]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:04:46,428]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:04:50,538]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:04:51,335]\u001b[0m Trial 1173 finished with value: 67.27871611089013 and parameters: {'n_hidden': 3, 'learning_rate': 0.03292025698073943, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23489606226801366, 'dropout_rate_Layer_2': 0.11648812288967611, 'dropout_rate_Layer_3': 0.21361743433468686, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0005196991128051743, 'l1_Layer_2': 6.892358074639964e-05, 'l1_Layer_3': 0.0032952866456856128, 'n_units_Layer_1': 270, 'n_units_Layer_2': 55, 'n_units_Layer_3': 165}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 67.28 | sMAPE for Validation Set is: 23.66% | rMAE for Validation Set is: 1.06\n",
      "MAE for Test Set is: 28.37 | sMAPE for Test Set is: 27.59% | rMAE for Test Set is: 1.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:04:52,211]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:04:56,984]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:05:00,868]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:05:01,821]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:05:03,451]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:05:07,585]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:05:09,988]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:05:14,673]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:05:15,527]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:05:16,103]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:05:23,003]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:05:26,995]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:05:27,679]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:05:33,717]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:05:35,355]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:05:40,072]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:05:41,477]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:05:43,922]\u001b[0m Trial 1192 finished with value: 32.66059489821145 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030438800025302634, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22524068423037244, 'dropout_rate_Layer_2': 0.26845806747063, 'dropout_rate_Layer_3': 0.37475026822054786, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012675669542424548, 'l1_Layer_2': 7.774602038755625e-05, 'l1_Layer_3': 0.007584574428891423, 'n_units_Layer_1': 180, 'n_units_Layer_2': 50, 'n_units_Layer_3': 220}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.66 | sMAPE for Validation Set is: 12.97% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 12.93 | sMAPE for Test Set is: 14.38% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:05:44,161]\u001b[0m Trial 1193 finished with value: 32.73072886248541 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022495575815621844, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22542870583801455, 'dropout_rate_Layer_2': 0.2681965949922365, 'dropout_rate_Layer_3': 0.3736087011645263, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013611558295574866, 'l1_Layer_2': 7.485218324879177e-05, 'l1_Layer_3': 0.006304162173090031, 'n_units_Layer_1': 185, 'n_units_Layer_2': 230, 'n_units_Layer_3': 225}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.73 | sMAPE for Validation Set is: 12.95% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 13.50 | sMAPE for Test Set is: 14.37% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:05:44,585]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:05:47,428]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:05:56,195]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:05:58,840]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:06:01,002]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:06:03,729]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:06:03,882]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:06:05,882]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:06:11,224]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:06:12,208]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:06:13,001]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:06:29,425]\u001b[0m Trial 1202 finished with value: 28.55201242480309 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016779007527618758, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1274499502576954, 'dropout_rate_Layer_2': 0.17606415073812454, 'dropout_rate_Layer_3': 0.2596698183964413, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005342434536481656, 'l1_Layer_2': 0.0015123367304165807, 'l1_Layer_3': 2.0029503419551506e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 75, 'n_units_Layer_3': 245}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.55 | sMAPE for Validation Set is: 11.27% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 10.90 | sMAPE for Test Set is: 12.40% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:06:35,862]\u001b[0m Trial 1212 finished with value: 29.631741448549803 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009166682779517283, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08091241273476342, 'dropout_rate_Layer_2': 0.10678080231847949, 'dropout_rate_Layer_3': 0.12161173169504505, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011520586119687247, 'l1_Layer_2': 3.580332755180078e-05, 'l1_Layer_3': 3.0974628796265956e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 150, 'n_units_Layer_3': 195}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.63 | sMAPE for Validation Set is: 11.84% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.05 | sMAPE for Test Set is: 12.52% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:06:36,434]\u001b[0m Trial 1213 finished with value: 29.20268797107249 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018175877766269924, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09245215499044225, 'dropout_rate_Layer_2': 0.13160805279518872, 'dropout_rate_Layer_3': 0.011373519365186905, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00036835726877743085, 'l1_Layer_2': 1.3896202787466322e-05, 'l1_Layer_3': 0.0001989016997888843, 'n_units_Layer_1': 230, 'n_units_Layer_2': 250, 'n_units_Layer_3': 195}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.20 | sMAPE for Validation Set is: 11.79% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 11.93 | sMAPE for Test Set is: 13.13% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:06:39,653]\u001b[0m Trial 1214 finished with value: 29.604136196008607 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008852708154068307, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.062390414634287544, 'dropout_rate_Layer_2': 0.0001213760668000944, 'dropout_rate_Layer_3': 0.2076206578384747, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012769802881348446, 'l1_Layer_2': 2.540889717062978e-05, 'l1_Layer_3': 7.553464057297097e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 150, 'n_units_Layer_3': 195}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.60 | sMAPE for Validation Set is: 11.86% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 11.37 | sMAPE for Test Set is: 12.73% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:06:44,154]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:06:45,655]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:06:48,991]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:06:52,510]\u001b[0m Trial 1215 finished with value: 31.23186958404449 and parameters: {'n_hidden': 3, 'learning_rate': 0.0046082603362315655, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24630058498254423, 'dropout_rate_Layer_2': 0.08759362619737904, 'dropout_rate_Layer_3': 0.02946923075694865, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.361959855950947e-05, 'l1_Layer_2': 1.4725531116784007e-05, 'l1_Layer_3': 0.000526320528171653, 'n_units_Layer_1': 125, 'n_units_Layer_2': 65, 'n_units_Layer_3': 50}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 31.23 | sMAPE for Validation Set is: 12.27% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 12.12 | sMAPE for Test Set is: 13.41% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:06:53,086]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:06:59,535]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:07:00,490]\u001b[0m Trial 1217 finished with value: 36.09445770085191 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013981232374904483, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2714008463511224, 'dropout_rate_Layer_2': 0.23743206417167922, 'dropout_rate_Layer_3': 0.3068757245182469, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001814189275098075, 'l1_Layer_2': 0.00014459864338269124, 'l1_Layer_3': 0.01719768404911699, 'n_units_Layer_1': 150, 'n_units_Layer_2': 290, 'n_units_Layer_3': 175}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.09 | sMAPE for Validation Set is: 14.45% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 19.18 | sMAPE for Test Set is: 19.32% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:07:13,015]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:07:21,252]\u001b[0m Trial 1220 finished with value: 28.599195240490502 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016766224302488435, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12157254957412086, 'dropout_rate_Layer_2': 0.1762914015044891, 'dropout_rate_Layer_3': 0.2040232039399499, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005973943521550383, 'l1_Layer_2': 0.0015213625292214337, 'l1_Layer_3': 1.0143997206371285e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 75, 'n_units_Layer_3': 240}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.60 | sMAPE for Validation Set is: 11.30% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 11.12 | sMAPE for Test Set is: 12.50% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:07:25,315]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:07:29,777]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:07:35,838]\u001b[0m Trial 1228 finished with value: 77.59424597343254 and parameters: {'n_hidden': 3, 'learning_rate': 0.014694212088049106, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23162518132839924, 'dropout_rate_Layer_2': 0.06537351853153976, 'dropout_rate_Layer_3': 0.22967813749163085, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004884812587400943, 'l1_Layer_2': 0.00016757850084326526, 'l1_Layer_3': 0.00032945518563613774, 'n_units_Layer_1': 290, 'n_units_Layer_2': 80, 'n_units_Layer_3': 135}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 77.59 | sMAPE for Validation Set is: 34.35% | rMAE for Validation Set is: 1.22\n",
      "MAE for Test Set is: 88.97 | sMAPE for Test Set is: 114.94% | rMAE for Test Set is: 4.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:07:40,745]\u001b[0m Trial 1222 finished with value: 28.035655692140097 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016954381522056479, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1259520205228376, 'dropout_rate_Layer_2': 0.17504703211506228, 'dropout_rate_Layer_3': 0.20437179835981495, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005621509691721805, 'l1_Layer_2': 0.0014793511195205227, 'l1_Layer_3': 1.9904564101558675e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 75, 'n_units_Layer_3': 240}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.04 | sMAPE for Validation Set is: 11.05% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 10.70 | sMAPE for Test Set is: 12.33% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:07:45,930]\u001b[0m Trial 1224 finished with value: 28.280846795951135 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016839090766660066, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12741240731283598, 'dropout_rate_Layer_2': 0.23485411425688207, 'dropout_rate_Layer_3': 0.20988854181526592, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005845533954148995, 'l1_Layer_2': 0.0014367484351969968, 'l1_Layer_3': 1.989485655331608e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 75, 'n_units_Layer_3': 240}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.28 | sMAPE for Validation Set is: 11.16% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 10.88 | sMAPE for Test Set is: 12.43% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:07:50,593]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:07:51,086]\u001b[0m Trial 1229 finished with value: 32.287066971034754 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034561605689575276, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2193054138910908, 'dropout_rate_Layer_2': 0.2265006164651015, 'dropout_rate_Layer_3': 0.3410503545021768, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012869277729585045, 'l1_Layer_2': 8.282863698824624e-05, 'l1_Layer_3': 0.006147134721159755, 'n_units_Layer_1': 175, 'n_units_Layer_2': 145, 'n_units_Layer_3': 215}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.29 | sMAPE for Validation Set is: 12.73% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 13.92 | sMAPE for Test Set is: 14.66% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:07:56,857]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:08:01,233]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:08:05,636]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:08:07,884]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:08:10,855]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:08:15,317]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:08:19,981]\u001b[0m Trial 1231 finished with value: 28.748756277890294 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016334568730265065, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1250474360043545, 'dropout_rate_Layer_2': 0.1763679053516178, 'dropout_rate_Layer_3': 0.20503966244125021, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000548634346463209, 'l1_Layer_2': 0.001468652032598378, 'l1_Layer_3': 2.0493070241585496e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 75, 'n_units_Layer_3': 240}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.75 | sMAPE for Validation Set is: 11.37% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 11.10 | sMAPE for Test Set is: 12.66% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:08:20,493]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:08:27,241]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:08:31,323]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:08:35,505]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:08:42,103]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:08:42,114]\u001b[0m Trial 1234 finished with value: 28.33864723952567 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016485672354595816, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12966144614735164, 'dropout_rate_Layer_2': 0.1765221590205531, 'dropout_rate_Layer_3': 0.20260791422253463, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005408018940948856, 'l1_Layer_2': 0.0006030619131508752, 'l1_Layer_3': 1.8947870252998285e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 75, 'n_units_Layer_3': 240}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.34 | sMAPE for Validation Set is: 11.21% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 10.98 | sMAPE for Test Set is: 12.46% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:08:44,010]\u001b[0m Trial 1238 finished with value: 29.06237668233655 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015374099537882144, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06865651433616261, 'dropout_rate_Layer_2': 0.11873604997712037, 'dropout_rate_Layer_3': 0.001878799881853958, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00026152854468405813, 'l1_Layer_2': 4.326792135834623e-05, 'l1_Layer_3': 0.00024675929478282314, 'n_units_Layer_1': 220, 'n_units_Layer_2': 285, 'n_units_Layer_3': 195}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.06 | sMAPE for Validation Set is: 11.70% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 12.38 | sMAPE for Test Set is: 13.42% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:08:51,064]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:08:51,929]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:08:54,093]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:08:55,994]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:08:59,732]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.08 | sMAPE for Validation Set is: 12.16% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 14.87 | sMAPE for Test Set is: 15.95% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:09:00,950]\u001b[0m Trial 1242 finished with value: 30.08337138423707 and parameters: {'n_hidden': 3, 'learning_rate': 0.005461134196604583, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22748283468470004, 'dropout_rate_Layer_2': 0.0966195207316971, 'dropout_rate_Layer_3': 0.21792140269174046, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.1235968269471217e-05, 'l1_Layer_2': 1.9434569896138514e-05, 'l1_Layer_3': 0.00035944325358003553, 'n_units_Layer_1': 85, 'n_units_Layer_2': 50, 'n_units_Layer_3': 60}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:09:01,453]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:09:10,172]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:09:10,224]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:09:16,157]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:09:19,557]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:09:23,318]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.88 | sMAPE for Validation Set is: 12.88% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 13.56 | sMAPE for Test Set is: 14.60% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:09:25,622]\u001b[0m Trial 1252 finished with value: 32.875211556255266 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034205178047630644, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21641798262744885, 'dropout_rate_Layer_2': 0.21533460781282293, 'dropout_rate_Layer_3': 0.34070445488505774, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003810605970303451, 'l1_Layer_2': 0.00011199465686048274, 'l1_Layer_3': 0.0032150185639980506, 'n_units_Layer_1': 165, 'n_units_Layer_2': 150, 'n_units_Layer_3': 190}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:09:27,902]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:09:32,026]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:09:33,017]\u001b[0m Trial 1256 finished with value: 32.23733349290418 and parameters: {'n_hidden': 3, 'learning_rate': 0.00325275261908401, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21403035124278355, 'dropout_rate_Layer_2': 0.21464423427398588, 'dropout_rate_Layer_3': 0.33449035340679123, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003920608025734195, 'l1_Layer_2': 0.00022855197445997665, 'l1_Layer_3': 0.002441687247488145, 'n_units_Layer_1': 170, 'n_units_Layer_2': 155, 'n_units_Layer_3': 185}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.24 | sMAPE for Validation Set is: 12.84% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 12.49 | sMAPE for Test Set is: 13.76% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:09:37,108]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:09:42,287]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:09:42,534]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:09:48,681]\u001b[0m Trial 1254 finished with value: 28.560676719691724 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010367793293184402, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1248945593271049, 'dropout_rate_Layer_2': 0.1710896334602394, 'dropout_rate_Layer_3': 0.20406772249420324, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005869117460929634, 'l1_Layer_2': 0.0006779443837191402, 'l1_Layer_3': 2.0268361614215727e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 75, 'n_units_Layer_3': 240}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.56 | sMAPE for Validation Set is: 11.28% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 11.21 | sMAPE for Test Set is: 12.57% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:09:51,778]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:09:52,229]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:09:57,217]\u001b[0m Trial 1264 finished with value: 31.539377520737037 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024372080869245736, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23271454989613646, 'dropout_rate_Layer_2': 0.22758969560607498, 'dropout_rate_Layer_3': 0.3363428915453914, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011224326945905493, 'l1_Layer_2': 4.721805625265552e-05, 'l1_Layer_3': 0.0047674229324877635, 'n_units_Layer_1': 200, 'n_units_Layer_2': 135, 'n_units_Layer_3': 200}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 31.54 | sMAPE for Validation Set is: 12.40% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 13.13 | sMAPE for Test Set is: 14.20% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:09:59,794]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:10:00,806]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:10:06,369]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:10:06,781]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:10:12,880]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:10:16,269]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:10:21,261]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:10:26,438]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:10:26,481]\u001b[0m Trial 1274 finished with value: 32.53806020540454 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024450596915965247, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2446379021524374, 'dropout_rate_Layer_2': 0.23411212302513715, 'dropout_rate_Layer_3': 0.3248607970688326, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00021694438212901658, 'l1_Layer_2': 0.00019616281754756667, 'l1_Layer_3': 0.0016939421245096026, 'n_units_Layer_1': 195, 'n_units_Layer_2': 120, 'n_units_Layer_3': 185}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.54 | sMAPE for Validation Set is: 12.81% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 13.61 | sMAPE for Test Set is: 14.49% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:10:33,083]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:10:35,487]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:10:35,940]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:10:40,958]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:10:41,895]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:10:42,076]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:10:49,335]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:10:50,145]\u001b[0m Trial 1278 finished with value: 38.333596811756294 and parameters: {'n_hidden': 3, 'learning_rate': 0.09980756462845453, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2656530897237412, 'dropout_rate_Layer_2': 0.1428745394233795, 'dropout_rate_Layer_3': 0.15023447169591164, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.05841483967887993, 'l1_Layer_2': 0.0004897270548697716, 'l1_Layer_3': 0.0005722768888923039, 'n_units_Layer_1': 240, 'n_units_Layer_2': 65, 'n_units_Layer_3': 175}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 38.33 | sMAPE for Validation Set is: 15.06% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 15.79 | sMAPE for Test Set is: 16.71% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:10:50,382]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:10:50,428]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:10:59,277]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:11:02,479]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:11:04,180]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:11:07,463]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:11:08,877]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:11:12,657]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:11:17,405]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:11:17,702]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:11:22,715]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:11:28,826]\u001b[0m Trial 1289 finished with value: 28.115623863324995 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013513807961307903, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0912871252764801, 'dropout_rate_Layer_2': 0.1079385454261219, 'dropout_rate_Layer_3': 0.1979677218080634, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001904692638522008, 'l1_Layer_2': 3.958022764727528e-05, 'l1_Layer_3': 0.00017120276480555655, 'n_units_Layer_1': 265, 'n_units_Layer_2': 280, 'n_units_Layer_3': 195}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.12 | sMAPE for Validation Set is: 11.49% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 11.23 | sMAPE for Test Set is: 12.61% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:11:32,843]\u001b[0m Trial 1290 finished with value: 28.399685757040306 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013365140689466496, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0908811353884109, 'dropout_rate_Layer_2': 0.11465816772247187, 'dropout_rate_Layer_3': 0.18012863457419181, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00019466861051641786, 'l1_Layer_2': 3.96763378399864e-05, 'l1_Layer_3': 0.0001497351469321106, 'n_units_Layer_1': 265, 'n_units_Layer_2': 250, 'n_units_Layer_3': 195}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.40 | sMAPE for Validation Set is: 11.48% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 11.35 | sMAPE for Test Set is: 12.64% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:11:36,238]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:11:40,966]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:11:42,246]\u001b[0m Trial 1299 finished with value: 33.668675803747476 and parameters: {'n_hidden': 3, 'learning_rate': 0.010916749396053426, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0920150509444724, 'dropout_rate_Layer_2': 0.12685850945892052, 'dropout_rate_Layer_3': 0.2863194881008423, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001804835568092821, 'l1_Layer_2': 4.37893089073905e-05, 'l1_Layer_3': 6.518492760049149e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 210, 'n_units_Layer_3': 185}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.67 | sMAPE for Validation Set is: 13.29% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 16.46 | sMAPE for Test Set is: 15.95% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:11:59,784]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:12:03,417]\u001b[0m Trial 1297 finished with value: 28.350300066079285 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010554233211686008, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11247791557221232, 'dropout_rate_Layer_2': 0.1733489949608452, 'dropout_rate_Layer_3': 0.20569992831964257, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00030219118558367256, 'l1_Layer_2': 0.0006445695760350739, 'l1_Layer_3': 1.9900029460620273e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 75, 'n_units_Layer_3': 245}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.35 | sMAPE for Validation Set is: 11.21% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 10.74 | sMAPE for Test Set is: 12.38% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:12:04,581]\u001b[0m Trial 1301 finished with value: 28.883531697345433 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010567530238621123, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11712471234443834, 'dropout_rate_Layer_2': 0.17060354449216525, 'dropout_rate_Layer_3': 0.19762710514161347, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003483901121483678, 'l1_Layer_2': 0.0007692283013356033, 'l1_Layer_3': 1.9724587861047733e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 75, 'n_units_Layer_3': 245}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.88 | sMAPE for Validation Set is: 11.40% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 11.43 | sMAPE for Test Set is: 12.84% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:12:09,402]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:12:11,959]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:12:13,394]\u001b[0m Trial 1303 finished with value: 34.3155765915361 and parameters: {'n_hidden': 3, 'learning_rate': 0.025298682081586466, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11869539898954397, 'dropout_rate_Layer_2': 0.236182153921062, 'dropout_rate_Layer_3': 0.2940398014406681, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0020393000256212555, 'l1_Layer_2': 4.358515008249471e-05, 'l1_Layer_3': 6.185002948543475e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 150, 'n_units_Layer_3': 230}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 34.32 | sMAPE for Validation Set is: 13.38% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 15.40 | sMAPE for Test Set is: 15.15% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:12:17,517]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:12:21,621]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:12:22,011]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:12:28,511]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:12:28,778]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:12:34,108]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:12:34,797]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:12:49,820]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:12:51,126]\u001b[0m Trial 1316 finished with value: 32.526334893636864 and parameters: {'n_hidden': 3, 'learning_rate': 0.002777405507351559, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2613730009929918, 'dropout_rate_Layer_2': 0.2563870360665047, 'dropout_rate_Layer_3': 0.29904606603708367, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011120648768121973, 'l1_Layer_2': 3.2092330852947785e-05, 'l1_Layer_3': 0.004300932422762315, 'n_units_Layer_1': 170, 'n_units_Layer_2': 105, 'n_units_Layer_3': 200}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.53 | sMAPE for Validation Set is: 12.85% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 13.16 | sMAPE for Test Set is: 14.68% | rMAE for Test Set is: 0.68\n",
      "MAE for Validation Set is: 28.02 | sMAPE for Validation Set is: 11.06% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 10.99 | sMAPE for Test Set is: 12.40% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:12:52,940]\u001b[0m Trial 1308 finished with value: 28.022275817016872 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012571694010659945, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11794757023370331, 'dropout_rate_Layer_2': 0.19569879628385461, 'dropout_rate_Layer_3': 0.2009151694779021, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00035737055221093315, 'l1_Layer_2': 0.000886056651768971, 'l1_Layer_3': 2.081955197607065e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 80, 'n_units_Layer_3': 235}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:12:54,612]\u001b[0m Trial 1310 finished with value: 28.357033058768224 and parameters: {'n_hidden': 3, 'learning_rate': 0.001301789466610931, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12793690850176104, 'dropout_rate_Layer_2': 0.2361513471182184, 'dropout_rate_Layer_3': 0.2007678477604995, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003480820002185447, 'l1_Layer_2': 0.00041181625464332164, 'l1_Layer_3': 2.0247184341749715e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 80, 'n_units_Layer_3': 235}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.36 | sMAPE for Validation Set is: 11.21% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 10.88 | sMAPE for Test Set is: 12.41% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:13:01,511]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:13:05,067]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:13:05,511]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:13:10,971]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:13:11,151]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:13:17,049]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:13:20,284]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:13:24,347]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:13:25,748]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:13:30,398]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:13:38,671]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:13:38,998]\u001b[0m Trial 1325 finished with value: 29.106232326301562 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009543860349293031, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08108106121548858, 'dropout_rate_Layer_2': 0.13436684191248702, 'dropout_rate_Layer_3': 0.2097476543841446, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00016878427828256778, 'l1_Layer_2': 2.2323478104928094e-05, 'l1_Layer_3': 0.00012364622751095903, 'n_units_Layer_1': 270, 'n_units_Layer_2': 255, 'n_units_Layer_3': 130}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.11 | sMAPE for Validation Set is: 11.76% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 12.08 | sMAPE for Test Set is: 13.34% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:13:44,620]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:13:44,994]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:13:45,163]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:13:52,555]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:13:57,640]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:14:02,002]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:14:06,552]\u001b[0m Trial 1329 finished with value: 28.52669813785397 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012300344689090352, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12862593338431824, 'dropout_rate_Layer_2': 0.22765161184564614, 'dropout_rate_Layer_3': 0.18052766089991135, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003166970546521651, 'l1_Layer_2': 0.00035853747482937474, 'l1_Layer_3': 1.696125097305866e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 80, 'n_units_Layer_3': 235}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.53 | sMAPE for Validation Set is: 11.23% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 10.72 | sMAPE for Test Set is: 12.28% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:14:08,759]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:14:11,123]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:14:15,048]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:14:15,326]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.72 | sMAPE for Validation Set is: 11.96% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.57 | sMAPE for Test Set is: 13.14% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:14:18,603]\u001b[0m Trial 1335 finished with value: 29.721974612800768 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009048654009004516, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07175682546484256, 'dropout_rate_Layer_2': 0.13528629408028162, 'dropout_rate_Layer_3': 0.22093765686668265, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00019640976303581244, 'l1_Layer_2': 3.703748414946243e-05, 'l1_Layer_3': 0.00015904674927378408, 'n_units_Layer_1': 270, 'n_units_Layer_2': 255, 'n_units_Layer_3': 120}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:14:23,425]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:14:27,317]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:14:31,216]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:14:35,131]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:14:39,712]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:14:40,158]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:14:44,885]\u001b[0m Trial 1339 finished with value: 28.17233581012861 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012478400086500527, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12706498096915464, 'dropout_rate_Layer_2': 0.22657437041220146, 'dropout_rate_Layer_3': 0.20811205751092546, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00027086907695511434, 'l1_Layer_2': 0.00029251519100785236, 'l1_Layer_3': 1.7343209636363512e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 80, 'n_units_Layer_3': 235}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.17 | sMAPE for Validation Set is: 11.16% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 11.06 | sMAPE for Test Set is: 12.46% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:14:50,860]\u001b[0m Trial 1344 finished with value: 28.50500697354975 and parameters: {'n_hidden': 3, 'learning_rate': 0.001526610610003982, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13307995930429417, 'dropout_rate_Layer_2': 0.19507626704054243, 'dropout_rate_Layer_3': 0.14588867050862672, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00033908544876635197, 'l1_Layer_2': 0.0006093519110483092, 'l1_Layer_3': 2.721976913796238e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 80, 'n_units_Layer_3': 235}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.51 | sMAPE for Validation Set is: 11.28% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 10.83 | sMAPE for Test Set is: 12.33% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:14:55,419]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:14:55,770]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:15:00,883]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:15:01,935]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:15:08,018]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:15:11,353]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:15:16,298]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:15:17,449]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:15:22,951]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.30 | sMAPE for Validation Set is: 11.21% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 10.90 | sMAPE for Test Set is: 12.51% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:15:27,186]\u001b[0m Trial 1351 finished with value: 28.304737390802973 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015281190613840258, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1244033852694473, 'dropout_rate_Layer_2': 0.2093648314795526, 'dropout_rate_Layer_3': 0.19149977546694932, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005277823702038117, 'l1_Layer_2': 0.0005980446240684708, 'l1_Layer_3': 2.789219851635801e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 80, 'n_units_Layer_3': 235}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:15:31,043]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:15:37,443]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:15:40,792]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:15:41,662]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:15:45,656]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:15:46,387]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:15:52,199]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:15:52,586]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:15:58,465]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:15:59,998]\u001b[0m Trial 1355 finished with value: 28.04001692541568 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008251311119073922, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1331942003149257, 'dropout_rate_Layer_2': 0.21063585506066027, 'dropout_rate_Layer_3': 0.19158429572441488, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001962172600715065, 'l1_Layer_2': 0.000602631323073702, 'l1_Layer_3': 3.448148463971347e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 95, 'n_units_Layer_3': 235}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.04 | sMAPE for Validation Set is: 11.11% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 10.78 | sMAPE for Test Set is: 12.39% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:16:03,350]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:16:10,137]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:16:16,858]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:16:17,145]\u001b[0m Trial 1370 finished with value: 35.292140960853196 and parameters: {'n_hidden': 3, 'learning_rate': 0.04330305054948444, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26932109857384423, 'dropout_rate_Layer_2': 0.14690320592971332, 'dropout_rate_Layer_3': 0.18085669305235305, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010986972093092835, 'l1_Layer_2': 0.00034443413256899394, 'l1_Layer_3': 0.00031634535076361834, 'n_units_Layer_1': 300, 'n_units_Layer_2': 210, 'n_units_Layer_3': 175}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 35.29 | sMAPE for Validation Set is: 13.71% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 13.77 | sMAPE for Test Set is: 14.44% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:16:22,657]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:16:23,010]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:16:24,601]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:16:24,795]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:16:32,405]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:16:33,729]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:16:37,138]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:16:39,968]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:16:44,624]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:16:47,489]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:16:51,022]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:16:51,507]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:16:51,507]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:16:55,596]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:17:00,047]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:17:01,522]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:17:06,542]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:17:07,517]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:17:12,703]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:17:15,087]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:17:16,054]\u001b[0m Trial 1388 finished with value: 31.727145340305025 and parameters: {'n_hidden': 3, 'learning_rate': 0.003188257404600355, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20443720784495006, 'dropout_rate_Layer_2': 0.20845908980628333, 'dropout_rate_Layer_3': 0.26101506164193206, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007592878770915295, 'l1_Layer_2': 5.476864679208283e-05, 'l1_Layer_3': 0.0023780677530595923, 'n_units_Layer_1': 200, 'n_units_Layer_2': 165, 'n_units_Layer_3': 155}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 31.73 | sMAPE for Validation Set is: 12.35% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 14.16 | sMAPE for Test Set is: 15.32% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:17:18,218]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:17:22,177]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.09 | sMAPE for Validation Set is: 12.43% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 13.10 | sMAPE for Test Set is: 14.22% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:17:24,764]\u001b[0m Trial 1389 finished with value: 32.090127179476134 and parameters: {'n_hidden': 3, 'learning_rate': 0.005366434693133736, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2371536228793979, 'dropout_rate_Layer_2': 0.24269987272693472, 'dropout_rate_Layer_3': 0.3497853201168147, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.014495985178580438, 'l1_Layer_2': 5.556164999307687e-05, 'l1_Layer_3': 0.002633820000999083, 'n_units_Layer_1': 200, 'n_units_Layer_2': 160, 'n_units_Layer_3': 225}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:17:29,114]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:17:33,984]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:17:37,645]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:17:46,757]\u001b[0m Trial 1400 finished with value: 66.437173349107 and parameters: {'n_hidden': 3, 'learning_rate': 0.022643796986905225, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.020460837820390272, 'dropout_rate_Layer_2': 0.20999724008771292, 'dropout_rate_Layer_3': 0.23104781545600553, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00755242536866084, 'l1_Layer_2': 0.00020988277853244456, 'l1_Layer_3': 2.002496158480327e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 240, 'n_units_Layer_3': 255}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 66.44 | sMAPE for Validation Set is: 22.96% | rMAE for Validation Set is: 1.04\n",
      "MAE for Test Set is: 18.35 | sMAPE for Test Set is: 17.68% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:17:47,445]\u001b[0m Trial 1398 finished with value: 28.44744814323092 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010004037895518117, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0819297405690925, 'dropout_rate_Layer_2': 0.13687669272816094, 'dropout_rate_Layer_3': 0.13221491510567593, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014552628063596977, 'l1_Layer_2': 1.566262606205466e-05, 'l1_Layer_3': 0.00010537404175321613, 'n_units_Layer_1': 265, 'n_units_Layer_2': 240, 'n_units_Layer_3': 120}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.45 | sMAPE for Validation Set is: 11.46% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 11.45 | sMAPE for Test Set is: 12.78% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:17:53,164]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:17:53,625]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:17:56,735]\u001b[0m Trial 1399 finished with value: 28.787236381873516 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009297334668533103, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0836550486346021, 'dropout_rate_Layer_2': 0.10273473107308159, 'dropout_rate_Layer_3': 0.2399231362026133, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014743728770854827, 'l1_Layer_2': 3.074026062828311e-05, 'l1_Layer_3': 0.00011569053148394878, 'n_units_Layer_1': 265, 'n_units_Layer_2': 280, 'n_units_Layer_3': 120}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.79 | sMAPE for Validation Set is: 11.76% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.48 | sMAPE for Test Set is: 14.92% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:18:00,691]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:18:03,743]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:18:08,250]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:18:12,538]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:18:18,075]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:18:18,582]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:18:23,272]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:18:27,651]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:18:28,509]\u001b[0m Trial 1411 finished with value: 31.84993603219755 and parameters: {'n_hidden': 3, 'learning_rate': 0.004945554666880776, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2056366482964367, 'dropout_rate_Layer_2': 0.24249283859126997, 'dropout_rate_Layer_3': 0.26105466664885746, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01594853017979567, 'l1_Layer_2': 3.071681104732991e-05, 'l1_Layer_3': 0.0030830227279403564, 'n_units_Layer_1': 205, 'n_units_Layer_2': 175, 'n_units_Layer_3': 225}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 31.85 | sMAPE for Validation Set is: 12.56% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 14.25 | sMAPE for Test Set is: 15.17% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:18:33,790]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:18:37,573]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:18:38,275]\u001b[0m Trial 1407 finished with value: 31.2553170659067 and parameters: {'n_hidden': 3, 'learning_rate': 0.005005398915776278, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20143889777445917, 'dropout_rate_Layer_2': 0.24493544148556198, 'dropout_rate_Layer_3': 0.26076745442964167, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.020239470932426437, 'l1_Layer_2': 2.864267194177242e-05, 'l1_Layer_3': 0.0031537583374631807, 'n_units_Layer_1': 200, 'n_units_Layer_2': 160, 'n_units_Layer_3': 140}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 31.26 | sMAPE for Validation Set is: 12.45% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 14.53 | sMAPE for Test Set is: 15.62% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:18:38,633]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:18:45,019]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:18:47,536]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:18:48,038]\u001b[0m Trial 1415 finished with value: 32.90663627377658 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021619030180797093, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20425384267190533, 'dropout_rate_Layer_2': 0.2766463604779373, 'dropout_rate_Layer_3': 0.24448193568520074, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.015267149971483825, 'l1_Layer_2': 3.267713225254327e-05, 'l1_Layer_3': 0.0031102352266290873, 'n_units_Layer_1': 200, 'n_units_Layer_2': 170, 'n_units_Layer_3': 225}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.91 | sMAPE for Validation Set is: 12.87% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 14.41 | sMAPE for Test Set is: 15.75% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:19:08,549]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:19:11,052]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:19:15,704]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:19:16,420]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.18 | sMAPE for Validation Set is: 12.61% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 13.70 | sMAPE for Test Set is: 15.13% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:19:21,224]\u001b[0m Trial 1423 finished with value: 32.1753534555968 and parameters: {'n_hidden': 3, 'learning_rate': 0.004585639215284083, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22966113484510325, 'dropout_rate_Layer_2': 0.06972219006843133, 'dropout_rate_Layer_3': 0.01635813759195518, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.710578849250775e-05, 'l1_Layer_2': 0.00029711509392147875, 'l1_Layer_3': 0.0014396189310294707, 'n_units_Layer_1': 290, 'n_units_Layer_2': 160, 'n_units_Layer_3': 90}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:19:22,178]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:19:22,224]\u001b[0m Trial 1425 finished with value: 28.321579630438524 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011739569475803001, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1398950453542025, 'dropout_rate_Layer_2': 0.21044403756151622, 'dropout_rate_Layer_3': 0.14590026993325866, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023842672268742262, 'l1_Layer_2': 0.00046607471899559556, 'l1_Layer_3': 2.6689226566858107e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 95, 'n_units_Layer_3': 230}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.32 | sMAPE for Validation Set is: 11.19% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 10.99 | sMAPE for Test Set is: 12.41% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:19:24,435]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:19:31,235]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:19:35,534]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:19:36,011]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:19:41,652]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:19:42,396]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:19:50,339]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:20:04,398]\u001b[0m Trial 1434 finished with value: 28.757043621517877 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008789270663611017, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08652857028551823, 'dropout_rate_Layer_2': 0.09646757717731982, 'dropout_rate_Layer_3': 0.17644648790896433, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010754193959730471, 'l1_Layer_2': 1.4123799792939535e-05, 'l1_Layer_3': 8.890748079271049e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 250, 'n_units_Layer_3': 125}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.76 | sMAPE for Validation Set is: 11.58% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 11.36 | sMAPE for Test Set is: 12.82% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:20:15,387]\u001b[0m Trial 1433 finished with value: 31.344306364492326 and parameters: {'n_hidden': 3, 'learning_rate': 0.003961988615359624, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22184912624220288, 'dropout_rate_Layer_2': 0.07350220223880494, 'dropout_rate_Layer_3': 0.02704299889761751, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.344563573806405e-05, 'l1_Layer_2': 0.0001817534854457742, 'l1_Layer_3': 0.01035232932911444, 'n_units_Layer_1': 280, 'n_units_Layer_2': 170, 'n_units_Layer_3': 95}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 31.34 | sMAPE for Validation Set is: 12.29% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.29 | sMAPE for Test Set is: 14.97% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:20:22,364]\u001b[0m Trial 1437 finished with value: 31.973710268098767 and parameters: {'n_hidden': 3, 'learning_rate': 0.004457795760243016, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22907732022098903, 'dropout_rate_Layer_2': 0.06790081688948496, 'dropout_rate_Layer_3': 0.018447319281134397, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.50628759709228e-05, 'l1_Layer_2': 0.00023297477916406982, 'l1_Layer_3': 0.00042876928979087127, 'n_units_Layer_1': 275, 'n_units_Layer_2': 180, 'n_units_Layer_3': 95}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 31.97 | sMAPE for Validation Set is: 12.58% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 13.74 | sMAPE for Test Set is: 14.79% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:20:27,943]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:20:31,146]\u001b[0m Trial 1439 finished with value: 31.08513722391324 and parameters: {'n_hidden': 3, 'learning_rate': 0.004771375727142878, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2251726988739278, 'dropout_rate_Layer_2': 0.06806597138660336, 'dropout_rate_Layer_3': 0.015030817537718899, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.49505043264942e-05, 'l1_Layer_2': 0.00017168460162555536, 'l1_Layer_3': 7.789622426949577e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 180, 'n_units_Layer_3': 90}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 31.09 | sMAPE for Validation Set is: 12.44% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.73 | sMAPE for Test Set is: 14.71% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:20:34,957]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:20:44,219]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:20:48,190]\u001b[0m Trial 1441 finished with value: 29.214347875238133 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008035710680812023, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08405777146701489, 'dropout_rate_Layer_2': 0.09333639874158084, 'dropout_rate_Layer_3': 0.1802480686328677, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001043914815327883, 'l1_Layer_2': 1.3582797391684045e-05, 'l1_Layer_3': 7.772002108410237e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 250, 'n_units_Layer_3': 120}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.21 | sMAPE for Validation Set is: 11.75% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 12.02 | sMAPE for Test Set is: 13.31% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:20:50,691]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:20:55,124]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:20:57,507]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:21:03,626]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:21:07,334]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:21:11,077]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:21:13,886]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:21:19,507]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:21:19,544]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:21:21,441]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:21:27,657]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:21:28,408]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:21:31,471]\u001b[0m Trial 1451 finished with value: 33.223850409420734 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018666146875738034, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18698200114368527, 'dropout_rate_Layer_2': 0.2057869352020484, 'dropout_rate_Layer_3': 0.222824101231283, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.018971562573995977, 'l1_Layer_2': 1.659322128117328e-05, 'l1_Layer_3': 0.003793269553822039, 'n_units_Layer_1': 210, 'n_units_Layer_2': 180, 'n_units_Layer_3': 150}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.22 | sMAPE for Validation Set is: 13.00% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 15.08 | sMAPE for Test Set is: 15.61% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:21:36,824]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:21:40,065]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:21:56,942]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:21:57,857]\u001b[0m Trial 1460 finished with value: 29.136383631739978 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007616923074835945, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07119492567826183, 'dropout_rate_Layer_2': 0.09149320412796887, 'dropout_rate_Layer_3': 0.18959894501359525, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.259554830472968e-05, 'l1_Layer_2': 3.752689579990969e-05, 'l1_Layer_3': 7.655442916092632e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 245, 'n_units_Layer_3': 115}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.14 | sMAPE for Validation Set is: 11.73% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 12.14 | sMAPE for Test Set is: 13.26% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:22:04,740]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:22:10,675]\u001b[0m Trial 1462 finished with value: 28.161607809290015 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014905514000245665, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11798602369089058, 'dropout_rate_Layer_2': 0.21223480652720111, 'dropout_rate_Layer_3': 0.16611379818691063, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015892608038796068, 'l1_Layer_2': 0.000449222420961981, 'l1_Layer_3': 5.044551403522015e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 95, 'n_units_Layer_3': 225}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.16 | sMAPE for Validation Set is: 11.13% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 10.93 | sMAPE for Test Set is: 12.35% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:22:20,059]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:22:25,507]\u001b[0m Trial 1464 finished with value: 37.112157451746846 and parameters: {'n_hidden': 3, 'learning_rate': 0.013730304665189267, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3264319132561664, 'dropout_rate_Layer_2': 0.3129348865748659, 'dropout_rate_Layer_3': 0.03909098961374366, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003404266915990315, 'l1_Layer_2': 0.00011783013202702308, 'l1_Layer_3': 0.00011686622163882085, 'n_units_Layer_1': 215, 'n_units_Layer_2': 190, 'n_units_Layer_3': 295}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.11 | sMAPE for Validation Set is: 14.48% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 13.43 | sMAPE for Test Set is: 14.36% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:22:31,559]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:22:37,032]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:22:42,654]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:22:43,712]\u001b[0m Trial 1463 finished with value: 27.981947917124632 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008406865077747581, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11886393621264772, 'dropout_rate_Layer_2': 0.21019060606476664, 'dropout_rate_Layer_3': 0.17186639028406253, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015118185419829897, 'l1_Layer_2': 0.00042830540231799047, 'l1_Layer_3': 4.662249138923572e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 95, 'n_units_Layer_3': 225}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.98 | sMAPE for Validation Set is: 11.01% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 10.61 | sMAPE for Test Set is: 12.10% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:22:49,612]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:22:52,584]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:22:55,140]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:23:04,638]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:23:08,469]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:23:12,912]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:23:22,263]\u001b[0m Trial 1478 finished with value: 78.60238808138963 and parameters: {'n_hidden': 3, 'learning_rate': 0.03768577530411879, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06284282854541032, 'dropout_rate_Layer_2': 0.2609258790160307, 'dropout_rate_Layer_3': 0.015418727426386447, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.018637413793087896, 'l1_Layer_2': 0.0009706898760157457, 'l1_Layer_3': 0.0014980733871045092, 'n_units_Layer_1': 190, 'n_units_Layer_2': 110, 'n_units_Layer_3': 215}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 78.60 | sMAPE for Validation Set is: 28.08% | rMAE for Validation Set is: 1.23\n",
      "MAE for Test Set is: 20.50 | sMAPE for Test Set is: 21.67% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:23:26,041]\u001b[0m Trial 1473 finished with value: 29.352952389459592 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009529416212079979, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09741727559255488, 'dropout_rate_Layer_2': 0.0882539635698312, 'dropout_rate_Layer_3': 0.2857520835505347, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011502858330750483, 'l1_Layer_2': 4.276399265513961e-05, 'l1_Layer_3': 8.305001197618586e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 235, 'n_units_Layer_3': 115}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.35 | sMAPE for Validation Set is: 11.86% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 11.59 | sMAPE for Test Set is: 13.06% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:23:29,552]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:23:31,455]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:23:37,675]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 31.61 | sMAPE for Validation Set is: 12.35% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 12.73 | sMAPE for Test Set is: 14.06% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:23:38,937]\u001b[0m Trial 1476 finished with value: 31.61174249497206 and parameters: {'n_hidden': 3, 'learning_rate': 0.0037946397200028835, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2354743525019284, 'dropout_rate_Layer_2': 0.06872337127202786, 'dropout_rate_Layer_3': 0.009152957015422302, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.4887357016212206e-05, 'l1_Layer_2': 0.0002133890498679796, 'l1_Layer_3': 0.0001147944417356457, 'n_units_Layer_1': 280, 'n_units_Layer_2': 160, 'n_units_Layer_3': 95}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:23:40,705]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:23:46,061]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:23:49,593]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:23:50,140]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:23:59,132]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:24:03,549]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:24:07,642]\u001b[0m Trial 1483 finished with value: 29.33519862982925 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014529448671168096, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14177798304879985, 'dropout_rate_Layer_2': 0.2513478695088176, 'dropout_rate_Layer_3': 0.15192812719095414, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011517723067720126, 'l1_Layer_2': 0.0008820174272278695, 'l1_Layer_3': 4.143704101622827e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 95, 'n_units_Layer_3': 210}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.34 | sMAPE for Validation Set is: 11.51% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 11.53 | sMAPE for Test Set is: 12.90% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:24:10,817]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:24:13,551]\u001b[0m Trial 1477 finished with value: 29.573317718079636 and parameters: {'n_hidden': 3, 'learning_rate': 0.003074527348923671, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23479052921993612, 'dropout_rate_Layer_2': 0.07072460990312855, 'dropout_rate_Layer_3': 0.03916236890671425, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.554657150767954e-05, 'l1_Layer_2': 0.0002206589863978563, 'l1_Layer_3': 0.00010447480178773153, 'n_units_Layer_1': 285, 'n_units_Layer_2': 160, 'n_units_Layer_3': 80}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.57 | sMAPE for Validation Set is: 11.78% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 13.65 | sMAPE for Test Set is: 14.92% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:24:18,259]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:24:33,902]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:24:38,125]\u001b[0m Trial 1487 finished with value: 32.810101981873395 and parameters: {'n_hidden': 3, 'learning_rate': 0.003189201792459658, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2146504251227095, 'dropout_rate_Layer_2': 0.07008515171755336, 'dropout_rate_Layer_3': 0.006857462022499901, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.857754673128715e-05, 'l1_Layer_2': 0.0003940574381379001, 'l1_Layer_3': 8.673074407388941e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 170, 'n_units_Layer_3': 95}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.81 | sMAPE for Validation Set is: 12.92% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 13.57 | sMAPE for Test Set is: 14.32% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:24:44,399]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:24:44,575]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:24:50,777]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:25:01,198]\u001b[0m Trial 1494 finished with value: 29.850452413541202 and parameters: {'n_hidden': 3, 'learning_rate': 0.00365035602752279, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2239523102096726, 'dropout_rate_Layer_2': 0.07274111546924698, 'dropout_rate_Layer_3': 0.02232680521035557, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.883303567089959e-05, 'l1_Layer_2': 0.00028591501168052057, 'l1_Layer_3': 8.895970713624295e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 165, 'n_units_Layer_3': 95}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.85 | sMAPE for Validation Set is: 12.06% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 14.87 | sMAPE for Test Set is: 16.84% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:25:14,822]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 10:25:34,931]\u001b[0m Trial 1499 finished with value: 74.08966647446489 and parameters: {'n_hidden': 4, 'learning_rate': 0.016711672662405253, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1550036767986739, 'dropout_rate_Layer_2': 0.17399138313333, 'dropout_rate_Layer_3': 0.06296488040803616, 'dropout_rate_Layer_4': 0.39579152005975016, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00035544750939146586, 'l1_Layer_2': 0.001613923103967573, 'l1_Layer_3': 0.000831938227360658, 'l1_Layer_4': 0.08305862140255584, 'n_units_Layer_1': 130, 'n_units_Layer_2': 260, 'n_units_Layer_3': 190, 'n_units_Layer_4': 205}. Best is trial 836 with value: 27.81487376292019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 74.09 | sMAPE for Validation Set is: 25.90% | rMAE for Validation Set is: 1.16\n",
      "MAE for Test Set is: 35.48 | sMAPE for Test Set is: 38.52% | rMAE for Test Set is: 1.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 10:25:41,059]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2023-01-01, MAE is:9.47 & sMAPE is:112.50% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :9.47 & 112.50% & 0.11\n",
      "for 2023-01-02, MAE is:98.05 & sMAPE is:177.76% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :53.76 & 145.13% & 0.96\n",
      "for 2023-01-03, MAE is:35.56 & sMAPE is:27.09% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :47.69 & 105.78% & 1.07\n",
      "for 2023-01-04, MAE is:12.80 & sMAPE is:10.01% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :38.97 & 81.84% & 0.86\n",
      "for 2023-01-05, MAE is:16.52 & sMAPE is:11.97% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :34.48 & 67.87% & 0.72\n",
      "for 2023-01-06, MAE is:6.92 & sMAPE is:5.40% & rMAE is:0.07 ||| daily mean of MAE & sMAPE & rMAE till now are :29.89 & 57.46% & 0.61\n",
      "for 2023-01-07, MAE is:38.83 & sMAPE is:30.18% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :31.16 & 53.56% & 0.56\n",
      "for 2023-01-08, MAE is:6.66 & sMAPE is:4.95% & rMAE is:0.05 ||| daily mean of MAE & sMAPE & rMAE till now are :28.10 & 47.48% & 0.50\n",
      "for 2023-01-09, MAE is:18.93 & sMAPE is:17.39% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :27.08 & 44.14% & 0.50\n",
      "for 2023-01-10, MAE is:16.68 & sMAPE is:11.67% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :26.04 & 40.89% & 0.58\n",
      "for 2023-01-11, MAE is:25.13 & sMAPE is:15.73% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :25.96 & 38.61% & 0.59\n",
      "for 2023-01-12, MAE is:9.71 & sMAPE is:5.79% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :24.60 & 35.87% & 0.56\n",
      "for 2023-01-13, MAE is:12.20 & sMAPE is:7.36% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :23.65 & 33.68% & 0.54\n",
      "for 2023-01-14, MAE is:14.73 & sMAPE is:9.71% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :23.01 & 31.97% & 0.58\n",
      "for 2023-01-15, MAE is:10.27 & sMAPE is:6.77% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :22.16 & 30.29% & 0.57\n",
      "for 2023-01-16, MAE is:23.15 & sMAPE is:17.11% & rMAE is:1.88 ||| daily mean of MAE & sMAPE & rMAE till now are :22.23 & 29.46% & 0.65\n",
      "for 2023-01-17, MAE is:26.90 & sMAPE is:16.59% & rMAE is:1.96 ||| daily mean of MAE & sMAPE & rMAE till now are :22.50 & 28.71% & 0.73\n",
      "for 2023-01-18, MAE is:18.14 & sMAPE is:11.34% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :22.26 & 27.74% & 0.77\n",
      "for 2023-01-19, MAE is:22.72 & sMAPE is:14.17% & rMAE is:3.82 ||| daily mean of MAE & sMAPE & rMAE till now are :22.28 & 27.03% & 0.93\n",
      "for 2023-01-20, MAE is:36.44 & sMAPE is:21.38% & rMAE is:2.07 ||| daily mean of MAE & sMAPE & rMAE till now are :22.99 & 26.74% & 0.99\n",
      "for 2023-01-21, MAE is:7.21 & sMAPE is:4.63% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :22.24 & 25.69% & 1.01\n",
      "for 2023-01-22, MAE is:28.19 & sMAPE is:17.91% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :22.51 & 25.34% & 1.04\n",
      "for 2023-01-23, MAE is:21.64 & sMAPE is:10.40% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :22.47 & 24.69% & 1.01\n",
      "for 2023-01-24, MAE is:18.96 & sMAPE is:9.32% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :22.32 & 24.05% & 0.99\n",
      "for 2023-01-25, MAE is:14.96 & sMAPE is:8.01% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :22.03 & 23.41% & 0.99\n",
      "for 2023-01-26, MAE is:18.65 & sMAPE is:11.16% & rMAE is:2.77 ||| daily mean of MAE & sMAPE & rMAE till now are :21.90 & 22.93% & 1.06\n",
      "for 2023-01-27, MAE is:18.83 & sMAPE is:11.29% & rMAE is:1.79 ||| daily mean of MAE & sMAPE & rMAE till now are :21.79 & 22.50% & 1.08\n",
      "for 2023-01-28, MAE is:4.60 & sMAPE is:2.91% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :21.17 & 21.80% & 1.09\n",
      "for 2023-01-29, MAE is:16.51 & sMAPE is:11.83% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :21.01 & 21.46% & 1.08\n",
      "for 2023-01-30, MAE is:10.15 & sMAPE is:6.62% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :20.65 & 20.96% & 1.05\n",
      "for 2023-01-31, MAE is:11.46 & sMAPE is:7.39% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :20.35 & 20.53% & 1.03\n",
      "for 2023-02-01, MAE is:10.91 & sMAPE is:7.09% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :20.06 & 20.11% & 1.01\n",
      "for 2023-02-02, MAE is:23.19 & sMAPE is:15.17% & rMAE is:1.77 ||| daily mean of MAE & sMAPE & rMAE till now are :20.15 & 19.96% & 1.03\n",
      "for 2023-02-03, MAE is:18.94 & sMAPE is:12.47% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :20.12 & 19.74% & 1.04\n",
      "for 2023-02-04, MAE is:16.08 & sMAPE is:11.28% & rMAE is:2.32 ||| daily mean of MAE & sMAPE & rMAE till now are :20.00 & 19.50% & 1.07\n",
      "for 2023-02-05, MAE is:6.67 & sMAPE is:4.77% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :19.63 & 19.09% & 1.06\n",
      "for 2023-02-06, MAE is:36.62 & sMAPE is:22.89% & rMAE is:2.67 ||| daily mean of MAE & sMAPE & rMAE till now are :20.09 & 19.19% & 1.10\n",
      "for 2023-02-07, MAE is:16.51 & sMAPE is:9.45% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :20.00 & 18.93% & 1.11\n",
      "for 2023-02-08, MAE is:16.61 & sMAPE is:10.00% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :19.91 & 18.70% & 1.12\n",
      "for 2023-02-09, MAE is:10.68 & sMAPE is:6.63% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :19.68 & 18.40% & 1.13\n",
      "for 2023-02-10, MAE is:17.92 & sMAPE is:11.73% & rMAE is:3.31 ||| daily mean of MAE & sMAPE & rMAE till now are :19.64 & 18.24% & 1.18\n",
      "for 2023-02-11, MAE is:21.22 & sMAPE is:14.72% & rMAE is:3.56 ||| daily mean of MAE & sMAPE & rMAE till now are :19.67 & 18.16% & 1.24\n",
      "for 2023-02-12, MAE is:12.08 & sMAPE is:8.61% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :19.50 & 17.93% & 1.24\n",
      "for 2023-02-13, MAE is:16.37 & sMAPE is:10.17% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :19.43 & 17.76% & 1.24\n",
      "for 2023-02-14, MAE is:16.84 & sMAPE is:10.22% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :19.37 & 17.59% & 1.24\n",
      "for 2023-02-15, MAE is:13.47 & sMAPE is:8.71% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :19.24 & 17.40% & 1.23\n",
      "for 2023-02-16, MAE is:14.15 & sMAPE is:9.63% & rMAE is:2.20 ||| daily mean of MAE & sMAPE & rMAE till now are :19.13 & 17.23% & 1.25\n",
      "for 2023-02-17, MAE is:11.45 & sMAPE is:7.79% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :18.97 & 17.04% & 1.25\n",
      "for 2023-02-18, MAE is:9.45 & sMAPE is:6.95% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :18.78 & 16.83% & 1.24\n",
      "for 2023-02-19, MAE is:11.14 & sMAPE is:8.72% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :18.63 & 16.67% & 1.23\n",
      "for 2023-02-20, MAE is:9.44 & sMAPE is:6.87% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :18.44 & 16.48% & 1.21\n",
      "for 2023-02-21, MAE is:18.22 & sMAPE is:13.10% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :18.44 & 16.41% & 1.21\n",
      "for 2023-02-22, MAE is:14.35 & sMAPE is:9.96% & rMAE is:1.94 ||| daily mean of MAE & sMAPE & rMAE till now are :18.36 & 16.29% & 1.23\n",
      "for 2023-02-23, MAE is:13.36 & sMAPE is:9.25% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :18.27 & 16.16% & 1.23\n",
      "for 2023-02-24, MAE is:18.42 & sMAPE is:13.59% & rMAE is:2.18 ||| daily mean of MAE & sMAPE & rMAE till now are :18.27 & 16.11% & 1.24\n",
      "for 2023-02-25, MAE is:18.11 & sMAPE is:13.85% & rMAE is:3.62 ||| daily mean of MAE & sMAPE & rMAE till now are :18.27 & 16.07% & 1.29\n",
      "for 2023-02-26, MAE is:13.07 & sMAPE is:11.17% & rMAE is:1.78 ||| daily mean of MAE & sMAPE & rMAE till now are :18.18 & 15.99% & 1.30\n",
      "for 2023-02-27, MAE is:9.77 & sMAPE is:6.38% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :18.03 & 15.82% & 1.29\n",
      "for 2023-02-28, MAE is:14.85 & sMAPE is:9.57% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :17.98 & 15.71% & 1.29\n",
      "for 2023-03-01, MAE is:10.91 & sMAPE is:7.23% & rMAE is:1.86 ||| daily mean of MAE & sMAPE & rMAE till now are :17.86 & 15.57% & 1.30\n",
      "for 2023-03-02, MAE is:9.59 & sMAPE is:6.25% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :17.73 & 15.42% & 1.29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2023-03-03, MAE is:11.71 & sMAPE is:7.83% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :17.63 & 15.30% & 1.29\n",
      "for 2023-03-04, MAE is:12.19 & sMAPE is:8.96% & rMAE is:2.71 ||| daily mean of MAE & sMAPE & rMAE till now are :17.54 & 15.20% & 1.31\n",
      "for 2023-03-05, MAE is:10.22 & sMAPE is:7.79% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :17.43 & 15.08% & 1.31\n",
      "for 2023-03-06, MAE is:15.25 & sMAPE is:10.10% & rMAE is:2.46 ||| daily mean of MAE & sMAPE & rMAE till now are :17.40 & 15.00% & 1.33\n",
      "for 2023-03-07, MAE is:6.62 & sMAPE is:4.45% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :17.23 & 14.84% & 1.31\n",
      "for 2023-03-08, MAE is:12.33 & sMAPE is:8.80% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :17.16 & 14.75% & 1.31\n",
      "for 2023-03-09, MAE is:11.72 & sMAPE is:8.94% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :17.08 & 14.67% & 1.30\n",
      "for 2023-03-10, MAE is:10.74 & sMAPE is:9.02% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :16.99 & 14.59% & 1.28\n",
      "for 2023-03-11, MAE is:27.35 & sMAPE is:23.70% & rMAE is:2.04 ||| daily mean of MAE & sMAPE & rMAE till now are :17.14 & 14.72% & 1.29\n",
      "for 2023-03-12, MAE is:13.30 & sMAPE is:12.33% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :17.08 & 14.68% & 1.28\n",
      "for 2023-03-13, MAE is:10.89 & sMAPE is:9.01% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :17.00 & 14.60% & 1.27\n",
      "for 2023-03-14, MAE is:13.08 & sMAPE is:10.63% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :16.94 & 14.55% & 1.26\n",
      "for 2023-03-15, MAE is:11.45 & sMAPE is:8.50% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :16.87 & 14.47% & 1.26\n",
      "for 2023-03-16, MAE is:13.04 & sMAPE is:10.35% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :16.82 & 14.41% & 1.26\n",
      "for 2023-03-17, MAE is:10.77 & sMAPE is:9.88% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :16.74 & 14.35% & 1.26\n",
      "for 2023-03-18, MAE is:14.53 & sMAPE is:15.32% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :16.71 & 14.37% & 1.25\n",
      "for 2023-03-19, MAE is:18.85 & sMAPE is:17.76% & rMAE is:2.97 ||| daily mean of MAE & sMAPE & rMAE till now are :16.74 & 14.41% & 1.27\n",
      "for 2023-03-20, MAE is:10.15 & sMAPE is:8.24% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :16.65 & 14.33% & 1.27\n",
      "for 2023-03-21, MAE is:9.30 & sMAPE is:7.77% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :16.56 & 14.25% & 1.27\n",
      "for 2023-03-22, MAE is:10.84 & sMAPE is:9.67% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :16.49 & 14.19% & 1.26\n",
      "for 2023-03-23, MAE is:8.75 & sMAPE is:7.99% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :16.40 & 14.12% & 1.25\n",
      "for 2023-03-24, MAE is:11.68 & sMAPE is:10.92% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :16.34 & 14.08% & 1.25\n",
      "for 2023-03-25, MAE is:17.19 & sMAPE is:27.67% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :16.35 & 14.24% & 1.24\n",
      "for 2023-03-26, MAE is:18.41 & sMAPE is:21.37% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :16.37 & 14.32% & 1.24\n",
      "for 2023-03-27, MAE is:13.94 & sMAPE is:12.71% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :16.34 & 14.31% & 1.24\n",
      "for 2023-03-28, MAE is:19.08 & sMAPE is:16.47% & rMAE is:2.39 ||| daily mean of MAE & sMAPE & rMAE till now are :16.38 & 14.33% & 1.25\n",
      "for 2023-03-29, MAE is:14.41 & sMAPE is:12.48% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :16.35 & 14.31% & 1.26\n",
      "for 2023-03-30, MAE is:17.93 & sMAPE is:17.50% & rMAE is:2.67 ||| daily mean of MAE & sMAPE & rMAE till now are :16.37 & 14.35% & 1.27\n",
      "for 2023-03-31, MAE is:10.57 & sMAPE is:9.96% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :16.31 & 14.30% & 1.27\n",
      "for 2023-04-01, MAE is:11.93 & sMAPE is:15.73% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :16.26 & 14.31% & 1.27\n",
      "for 2023-04-02, MAE is:23.74 & sMAPE is:28.25% & rMAE is:2.17 ||| daily mean of MAE & sMAPE & rMAE till now are :16.34 & 14.46% & 1.28\n",
      "for 2023-04-03, MAE is:18.19 & sMAPE is:14.67% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :16.36 & 14.47% & 1.28\n",
      "for 2023-04-04, MAE is:16.91 & sMAPE is:12.16% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :16.37 & 14.44% & 1.28\n",
      "for 2023-04-05, MAE is:14.80 & sMAPE is:10.29% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :16.35 & 14.40% & 1.27\n",
      "for 2023-04-06, MAE is:9.44 & sMAPE is:7.07% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :16.28 & 14.32% & 1.26\n",
      "for 2023-04-07, MAE is:7.32 & sMAPE is:6.12% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :16.19 & 14.24% & 1.26\n",
      "for 2023-04-08, MAE is:23.09 & sMAPE is:20.46% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :16.26 & 14.30% & 1.25\n",
      "for 2023-04-09, MAE is:13.84 & sMAPE is:15.59% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :16.23 & 14.31% & 1.25\n",
      "for 2023-04-10, MAE is:39.06 & sMAPE is:66.10% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :16.46 & 14.83% & 1.25\n",
      "for 2023-04-11, MAE is:27.35 & sMAPE is:24.60% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :16.57 & 14.93% & 1.25\n",
      "for 2023-04-12, MAE is:10.17 & sMAPE is:8.02% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :16.50 & 14.86% & 1.24\n",
      "for 2023-04-13, MAE is:22.22 & sMAPE is:17.20% & rMAE is:1.88 ||| daily mean of MAE & sMAPE & rMAE till now are :16.56 & 14.88% & 1.25\n",
      "for 2023-04-14, MAE is:12.74 & sMAPE is:9.19% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :16.52 & 14.83% & 1.24\n",
      "for 2023-04-15, MAE is:9.35 & sMAPE is:8.00% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :16.46 & 14.76% & 1.25\n",
      "for 2023-04-16, MAE is:10.38 & sMAPE is:9.65% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :16.40 & 14.72% & 1.24\n",
      "for 2023-04-17, MAE is:29.79 & sMAPE is:26.51% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :16.52 & 14.83% & 1.24\n",
      "for 2023-04-18, MAE is:9.66 & sMAPE is:7.99% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :16.46 & 14.76% & 1.24\n",
      "for 2023-04-19, MAE is:13.44 & sMAPE is:11.74% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :16.43 & 14.73% & 1.24\n",
      "for 2023-04-20, MAE is:20.93 & sMAPE is:17.31% & rMAE is:2.41 ||| daily mean of MAE & sMAPE & rMAE till now are :16.47 & 14.76% & 1.25\n",
      "for 2023-04-21, MAE is:10.75 & sMAPE is:8.73% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :16.42 & 14.70% & 1.25\n",
      "for 2023-04-22, MAE is:13.73 & sMAPE is:13.89% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :16.40 & 14.70% & 1.25\n",
      "for 2023-04-23, MAE is:23.97 & sMAPE is:40.39% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :16.46 & 14.92% & 1.24\n",
      "for 2023-04-24, MAE is:8.09 & sMAPE is:7.34% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :16.39 & 14.86% & 1.24\n",
      "for 2023-04-25, MAE is:13.58 & sMAPE is:11.88% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :16.37 & 14.83% & 1.24\n",
      "for 2023-04-26, MAE is:14.28 & sMAPE is:12.31% & rMAE is:2.07 ||| daily mean of MAE & sMAPE & rMAE till now are :16.35 & 14.81% & 1.24\n",
      "for 2023-04-27, MAE is:10.39 & sMAPE is:8.94% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :16.30 & 14.76% & 1.24\n",
      "for 2023-04-28, MAE is:9.13 & sMAPE is:8.63% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :16.24 & 14.71% & 1.23\n",
      "for 2023-04-29, MAE is:8.69 & sMAPE is:9.40% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :16.17 & 14.66% & 1.23\n",
      "for 2023-04-30, MAE is:22.49 & sMAPE is:41.92% & rMAE is:2.43 ||| daily mean of MAE & sMAPE & rMAE till now are :16.23 & 14.89% & 1.24\n",
      "for 2023-05-01, MAE is:11.46 & sMAPE is:13.25% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :16.19 & 14.88% & 1.23\n",
      "for 2023-05-02, MAE is:6.60 & sMAPE is:6.47% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :16.11 & 14.81% & 1.23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2023-05-03, MAE is:12.51 & sMAPE is:12.49% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :16.08 & 14.79% & 1.22\n",
      "for 2023-05-04, MAE is:9.13 & sMAPE is:9.80% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :16.02 & 14.75% & 1.22\n",
      "for 2023-05-05, MAE is:13.32 & sMAPE is:14.97% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :16.00 & 14.75% & 1.21\n",
      "for 2023-05-06, MAE is:8.87 & sMAPE is:11.71% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :15.94 & 14.73% & 1.21\n",
      "for 2023-05-07, MAE is:13.87 & sMAPE is:25.04% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :15.93 & 14.81% & 1.21\n",
      "for 2023-05-08, MAE is:20.45 & sMAPE is:25.39% & rMAE is:2.26 ||| daily mean of MAE & sMAPE & rMAE till now are :15.96 & 14.89% & 1.22\n",
      "for 2023-05-09, MAE is:9.72 & sMAPE is:10.24% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :15.92 & 14.85% & 1.22\n",
      "for 2023-05-10, MAE is:18.63 & sMAPE is:19.19% & rMAE is:2.20 ||| daily mean of MAE & sMAPE & rMAE till now are :15.94 & 14.89% & 1.23\n",
      "for 2023-05-11, MAE is:11.96 & sMAPE is:10.92% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :15.91 & 14.86% & 1.22\n",
      "for 2023-05-12, MAE is:8.02 & sMAPE is:7.91% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :15.85 & 14.80% & 1.22\n",
      "for 2023-05-13, MAE is:19.39 & sMAPE is:24.90% & rMAE is:3.41 ||| daily mean of MAE & sMAPE & rMAE till now are :15.87 & 14.88% & 1.24\n",
      "for 2023-05-14, MAE is:23.69 & sMAPE is:44.54% & rMAE is:2.00 ||| daily mean of MAE & sMAPE & rMAE till now are :15.93 & 15.10% & 1.24\n",
      "for 2023-05-15, MAE is:14.77 & sMAPE is:14.88% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :15.92 & 15.10% & 1.24\n",
      "for 2023-05-16, MAE is:11.91 & sMAPE is:12.48% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :15.89 & 15.08% & 1.25\n",
      "for 2023-05-17, MAE is:12.80 & sMAPE is:13.92% & rMAE is:1.90 ||| daily mean of MAE & sMAPE & rMAE till now are :15.87 & 15.07% & 1.25\n",
      "for 2023-05-18, MAE is:20.80 & sMAPE is:34.19% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :15.91 & 15.21% & 1.25\n",
      "for 2023-05-19, MAE is:11.43 & sMAPE is:13.28% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :15.87 & 15.20% & 1.25\n",
      "for 2023-05-20, MAE is:6.11 & sMAPE is:8.12% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :15.80 & 15.15% & 1.24\n",
      "for 2023-05-21, MAE is:27.29 & sMAPE is:74.27% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :15.89 & 15.57% & 1.24\n",
      "for 2023-05-22, MAE is:28.47 & sMAPE is:36.85% & rMAE is:2.15 ||| daily mean of MAE & sMAPE & rMAE till now are :15.97 & 15.72% & 1.25\n",
      "for 2023-05-23, MAE is:10.57 & sMAPE is:12.23% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :15.94 & 15.69% & 1.24\n",
      "for 2023-05-24, MAE is:18.72 & sMAPE is:21.34% & rMAE is:3.18 ||| daily mean of MAE & sMAPE & rMAE till now are :15.96 & 15.73% & 1.26\n",
      "for 2023-05-25, MAE is:10.65 & sMAPE is:12.24% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :15.92 & 15.71% & 1.25\n",
      "for 2023-05-26, MAE is:14.15 & sMAPE is:18.58% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :15.91 & 15.73% & 1.25\n",
      "for 2023-05-27, MAE is:20.46 & sMAPE is:48.99% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :15.94 & 15.95% & 1.25\n",
      "for 2023-05-28, MAE is:27.59 & sMAPE is:79.68% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :16.02 & 16.38% & 1.25\n",
      "for 2023-05-29, MAE is:13.35 & sMAPE is:42.97% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :16.00 & 16.56% & 1.25\n",
      "for 2023-05-30, MAE is:20.02 & sMAPE is:27.38% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :16.03 & 16.63% & 1.25\n",
      "for 2023-05-31, MAE is:18.74 & sMAPE is:27.97% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :16.04 & 16.71% & 1.25\n",
      "for 2023-06-01, MAE is:15.07 & sMAPE is:26.98% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :16.04 & 16.78% & 1.24\n",
      "for 2023-06-02, MAE is:15.32 & sMAPE is:25.67% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :16.03 & 16.83% & 1.24\n",
      "for 2023-06-03, MAE is:18.39 & sMAPE is:59.42% & rMAE is:2.36 ||| daily mean of MAE & sMAPE & rMAE till now are :16.05 & 17.11% & 1.25\n",
      "for 2023-06-04, MAE is:26.72 & sMAPE is:83.51% & rMAE is:3.10 ||| daily mean of MAE & sMAPE & rMAE till now are :16.12 & 17.54% & 1.26\n",
      "for 2023-06-05, MAE is:21.09 & sMAPE is:31.30% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :16.15 & 17.63% & 1.26\n",
      "for 2023-06-06, MAE is:7.11 & sMAPE is:8.28% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :16.09 & 17.57% & 1.25\n",
      "for 2023-06-07, MAE is:18.32 & sMAPE is:22.34% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :16.10 & 17.60% & 1.25\n",
      "for 2023-06-08, MAE is:8.25 & sMAPE is:10.79% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :16.06 & 17.56% & 1.25\n",
      "for 2023-06-09, MAE is:12.08 & sMAPE is:15.49% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :16.03 & 17.54% & 1.25\n",
      "for 2023-06-10, MAE is:15.24 & sMAPE is:37.18% & rMAE is:2.12 ||| daily mean of MAE & sMAPE & rMAE till now are :16.03 & 17.66% & 1.25\n",
      "for 2023-06-11, MAE is:19.17 & sMAPE is:71.92% & rMAE is:1.86 ||| daily mean of MAE & sMAPE & rMAE till now are :16.05 & 18.00% & 1.26\n",
      "for 2023-06-12, MAE is:22.59 & sMAPE is:25.96% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :16.09 & 18.05% & 1.26\n",
      "for 2023-06-13, MAE is:10.62 & sMAPE is:10.91% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :16.05 & 18.00% & 1.26\n",
      "for 2023-06-14, MAE is:14.87 & sMAPE is:15.76% & rMAE is:2.23 ||| daily mean of MAE & sMAPE & rMAE till now are :16.04 & 17.99% & 1.26\n",
      "for 2023-06-15, MAE is:21.15 & sMAPE is:20.38% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :16.08 & 18.01% & 1.26\n",
      "for 2023-06-16, MAE is:19.30 & sMAPE is:16.78% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :16.09 & 18.00% & 1.25\n",
      "for 2023-06-17, MAE is:11.32 & sMAPE is:13.43% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :16.07 & 17.97% & 1.25\n",
      "for 2023-06-18, MAE is:19.41 & sMAPE is:27.95% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :16.09 & 18.03% & 1.24\n",
      "for 2023-06-19, MAE is:12.19 & sMAPE is:9.69% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :16.06 & 17.98% & 1.24\n",
      "for 2023-06-20, MAE is:15.93 & sMAPE is:12.81% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :16.06 & 17.95% & 1.24\n",
      "for 2023-06-21, MAE is:15.48 & sMAPE is:12.31% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :16.06 & 17.92% & 1.23\n",
      "for 2023-06-22, MAE is:8.51 & sMAPE is:6.53% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :16.02 & 17.85% & 1.23\n",
      "for 2023-06-23, MAE is:9.06 & sMAPE is:8.24% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :15.98 & 17.80% & 1.23\n",
      "for 2023-06-24, MAE is:14.84 & sMAPE is:24.48% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :15.97 & 17.84% & 1.23\n",
      "for 2023-06-25, MAE is:21.07 & sMAPE is:47.71% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :16.00 & 18.00% & 1.22\n",
      "for 2023-06-26, MAE is:7.74 & sMAPE is:8.17% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :15.95 & 17.95% & 1.22\n",
      "for 2023-06-27, MAE is:10.31 & sMAPE is:10.10% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :15.92 & 17.91% & 1.22\n",
      "for 2023-06-28, MAE is:9.68 & sMAPE is:8.95% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :15.88 & 17.86% & 1.21\n",
      "for 2023-06-29, MAE is:6.38 & sMAPE is:5.80% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :15.83 & 17.79% & 1.21\n",
      "for 2023-06-30, MAE is:7.97 & sMAPE is:7.94% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :15.79 & 17.73% & 1.21\n",
      "CPU times: total: 1d 20h 5min 34s\n",
      "Wall time: 19h 45min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for zone in zones:\n",
    "    large_scale_predictor(zone, first_year=2018, last_year=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
